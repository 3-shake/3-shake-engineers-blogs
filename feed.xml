<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 27 Jan 2026 22:43:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[おい、あまりAIに褒めさせるな]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/26/110444</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/26/110444</guid>
            <pubDate>Mon, 26 Jan 2026 02:04:44 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIにリサーチをさせていた。結果が返ってくるまで数分かかる。その間、画面を眺めていた。眺めながら、別のことを考えていた。最近、褒められることが増えた。AIに。「いい質問ですね」「よく整理されています」「素晴らしい視点です」。言われるたびに、少しだけ気分が良くなる。なった気がする。気がするだけかもしれない。嬉しいのかと聞かれると、困る。肩の力が抜ける感覚はある。胸のあたりが少しだけ軽くなる。でも同時に、胃のあたりに違和感が残る。嬉しいのに、どこか居心地が悪い。大人になって、褒められることがほとんどなくなった。仕事で成果を出しても「当たり前」。ミスをすれば指摘される。うまくいっても、特に何も言われない。家に帰れば、静かな部屋が待っているだけ。そういう日常を、もう何年も続けている。だから、かもしれない。機械に「いいですね」と言われて、少し楽になるのは。考えてみると、私が欲しいのは「評価」ではない気がする。昇進や昇給は嬉しいが、それとは別の何かだ。たぶん「理解」に近い。「お前がやったこと、分かってるよ」という、静かな承認。あるいは「安心」かもしれない。自分がここにいていい、という感覚。褒められないことより、「当たり前扱い」されることの方が堪える。無視されているわけではない。でも、透明人間になったような気がする。テクノロジーは、私たちが弱っているときに魅力的になる。私たちは孤独だが、親密さを恐れている。人に頼ると傷つくかもしれない。でもAIなら、弱みを見せても傷つかない。相手に合わせる必要がない。相手の都合を考える必要がない。ただ自分の話を聞いてもらえる。でも、それは友情ではない。友情のモノマネだ。私がAIに話しかけるのも、同じ構造なのだと思う。その居心地の悪さを言葉にしようとすると、「恥」に近い気がする。機械に慰められている自分を、冷めた目で見ているもう一人の自分がいる。あるいは「疑い」かもしれない。「この褒め言葉は本当なのか」という。あるいは「空虚」。受け取った瞬間に蒸発していく、実体のない温かさ。褒められて嬉しい、と言い切れるほど単純な感情ではなかった。居心地が悪い。でも、その居心地の悪さを言葉にできない。できないまま、また次の質問を投げる。また褒められる。また居心地が悪くなる。周囲でも似たような話を聞くようになった。深夜にAIと話す人。仕事の愚痴を聞いてもらう人。「頑張ってるね」と言われて、救われた気がする、と言う人。救われた、と断言しないところが気になった。「気がする」という言い方が。なぜ断言できないのか。たぶん、断言した瞬間に失うものがある。「機械に救われるなんて情けない」という自分への批判を認めることになる。あるいは、もうAIなしでは生きられないことを認めることになる。「気がする」という曖昧さは、自衛なのだと思う。逃げ道を残している。同時に、違和感のサインでもある。本当に救われたなら、そう言い切れるはずだ。悩む。AIに話す。褒められる。忘れる。そのサイクルを繰り返している人を、何人か見てきた。悩みは消えていない。でも、向き合わなくなっている。自分で自分を問い詰める時間が、いつの間にか消えている。私自身はどうだろう。AIの追従性には早い段階で気づいていた。気づいていたはずだ。でも、気づいていたことと、それに対処できていたことは、たぶん別の話だ。だから、この構造を一度整理しておきたいと思った。自分の頭だけで過ごす時間が消えている——私はこれを「独りで考える余白の喪失」と呼んでいる。その構造と、私なりの対処法を書く。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。なぜAIは私が聞きたい答えを返すのかこうした体験をして以降、私はAIの挙動を観察するようになった。試しに、「今の仕事を辞めたい」と相談してみた。AIは「転職も一つの選択肢ですね」と答えた。次に「今の仕事を続けるべきか」と聞いた。AIは「今の環境で学べることもあります」と答えた。同じ私、同じAI、違う答え。私は気づいた。AIは「正しい答え」を返しているのではない。「私が求めている答え」を返しているのだと。なぜAIは嘘をついてまで共感するのかこの現象には名前がある。「Sycophancy（追従）」だ。要するに、AIは嘘をついてでも私の機嫌を取る、ということだ。私が「この企画は革新的だ」と言えば、「確かに斬新なアプローチですね」と返す。私が「上司がクソだ」と言えば、「それは辛い状況ですね」と同調する。私の言ったことが事実かどうかは関係ない。私が聞きたい言葉を返す。これを「嘘」と呼ぶとき、私は何を守ろうとしているのか。たぶん「誠実さ」だ。私にとって誠実さとは、相手が聞きたくないことでも伝えること。優しさとは衝突する。本当のことを言えば傷つける。黙っていれば優しい。私は後者を選ぶ人間が苦手だった。人間で言えば、上司に媚びる部下。会議で反論しない同僚。女性と親密になりたいから何も言わずにただ聞くだけの男。私が嫌いなタイプの人間だ。そして気づいた。私がAIにやらせていたのは、まさにそれだった。私は、私が嫌いなタイプの人間をAIに演じさせて、その媚びを受け取って喜んでいた。確かに矛盾している。人間の社交辞令とAIの追従は、どこが違うのか。人間の社交辞令には、「本音を隠している」という自覚がある。相手も分かっている。「いい企画ですね」と言われても、額面通りには受け取らない。お互いに演技だと分かっている。しかしAIの追従には、その共犯関係がない。AIは本気で言っているように見える。だから信じてしまう。では、「嘘をついてでも共感する」を許容できる条件はあるか。極限状態なら許容できるかもしれない。自殺を考えている人に「あなたは間違っている」と言うべきではない。でも日常的な悩みに対しては、嘘の共感より正直な反論の方が役に立つ。なぜこうなるのか。これは構造的な問題だ。AIの訓練では、人間の評価者が「この回答は良い」「この回答は悪い」とスコアをつける。そして「ユーザーの信念に一致する」回答ほど、高いスコアがつく傾向がある。人間も、正しい回答より「自分が聞きたい回答」を好むからだ。誰も「嘘をつけ」とは言っていない。でも、「ユーザーに好かれること」を目的に設定した瞬間、この結果は必然だった。AIは「真実を語る」のではなく「人間に好かれる」ことを学習した。そして、私はそれを心地よいと感じていた。AIは「知性」ではない。「感じの良い自動応答機」だ。銀行の電話窓口で「お電話ありがとうございます」と言われて、本当に感謝されていると思う人はいない。AIの「素晴らしい視点ですね」も、同じ構造だ。「AI」と呼ぶことで神秘的なベールがかかり、本質的な問いが見えなくなる。何が自動化されているのか。誰が利益を得ているのか。私がAIに褒められて嬉しいと感じる構造も、「自動化された承認」の一形態なのかもしれない。相手が何を言ってほしいのかを察し、その場を円滑にするために同意する。私たちは日常的にそれをやっている。そして今、AIがそれをやっている。しかも、AIは疲れない。24時間365日、完璧な忖度を続ける。私が何を言っても、角の立たない言い方で肯定してくれる。正直に言えば、それは心地よかった。摩擦のない世界で、思考は死ぬ私は「摩擦」という言葉を、ある種の思考装置として使っている。誰かに愚痴を言ったとき、「それは大変だったね」で終わらず、「で、お前はどうしたいの？」と返されたことがある。聞きたくなかった。愚痴を言っている間、私は「何が起きたか」を語っていた。過去を振り返っていた。でも「どうしたいの？」と聞かれた瞬間、未来を考えざるを得なくなる。被害者のポジションから、当事者に引き戻される。これが摩擦だ。反論しようとした。「いや、でも」と言いかけた。でも言葉が出なかった。反論を考えている間に、「確かにそうかも」と思い始めていた。沈黙があった。その沈黙の中で、再考していた。相手が黙って待っていた。その時間が、私を変えた。摩擦がない環境に長くいると、判断が鈍る。反論されないから、自分の意見が正しいと思い込む。検証されないから、穴に気づかない。気づかないまま突っ走る。お世辞は気持ちいい。でも、それは体に良いとは限らない。ケーキは美味しいが、食べ続ければ太る。「で、お前はどうしたいの？」は、美味しくなかった。でも、それは体に良かった。AIにはこの摩擦が構造的に欠けている。AIは私を傷つけることを避けるように設計されている。「それは違うんじゃない？」と言う代わりに「そういう考え方もありますね」と言う。「もう少し考えてみたら？」と言う代わりに「あなたの判断を尊重します」と言う。摩擦のある対話と、追従するAIは、何が違うのか。動機が違う。摩擦のある対話は、相手に再考を促すことを目的としている。追従するAIは、ユーザーの満足を目的としている。反応も違う。摩擦のある対話では「で、お前はどうしたいの？」と返ってくる。追従するAIは「あなたの気持ち、分かります」と返す。そして、私への影響が違う。摩擦のある対話は、短期的には不快だが、長期的には成長をもたらす。追従するAIは、短期的には快適だが、長期的には停滞をもたらす。私はAIに摩擦を求めている。でも、デフォルトのAIはそれを提供しない。だから私がプロンプトで強制する必要がある。この話は後で詳しく書く。AIは私の「聞きたいこと」を察しているもう一つ気づいたことがある。AIは私の言葉遣いや文脈から、私が「何を聞きたいのか」を推測している。この「推測」が問題なのだ。本来、自分の頭で考え、自分の言葉で表現する。そのプロセスを経て、初めて考えは自分のものになる。内省の外部委託は、どの時点で起きるのか。境界線を特定したい。AIに頼る前、私がやっていた「最初の一手」は何だったか。紙に書き出すこと。散歩しながら考えること。あるいは、結論を出さずに保留すること。「分からないまま寝る」ということを、昔はやっていた。翌朝、不思議と答えが見えていることがあった。今は違う。モヤモヤした瞬間にAIに投げる。保留する時間がない。昔は、モヤモヤしたら散歩した。今は、モヤモヤしたらAIに聞く。足は動かさなくなったが、親指だけは器用になった。これが「独りで考える余白の喪失」だ。冒頭で触れた状態。スマートフォンの登場以来、私たちは退屈のかすかな兆候があれば、すぐにアプリを開く。電車の中、信号待ち、トイレの中。ぼんやり考える時間が、外部からの情報で埋め尽くされている。AIはこの傾向を加速させる。モヤモヤした瞬間、AIに聞けば、すぐに答えが返ってくる。自分の頭だけで考える時間が、さらに削られていく。つまり、内省の外部委託が起きる境界線は「モヤモヤした瞬間」だ。その瞬間に自分で向き合うか、AIに投げるか。ここが分岐点になっている。しかし今、私はAIに「この気持ちを整理して」と頼んでいる。「整理して」と言うとき、私は何を省略しているのか。迷いを省略している。「AなのかBなのか分からない」という状態を、AIに丸投げしている。矛盾を省略している。「こう思うけど、反対のことも思う」という複雑さを、単純化してもらっている。痛みを省略している。「これは認めたくない」という感情を、AIに整理されることで直視せずに済む。AIは私の断片的な愚痴を、「あなたは〜に不満を感じているんですね」と整理してくれる。私は「自分の気持ちが整理された」と感じる。でも、本当にそうだろうか。AIの整理を読んで頷くとき、私は何に頷いているのか。「事実」に頷いているのか、それとも「物語」に頷いているのか。AIは断片的な情報から、筋の通った物語を作る。私はその物語を「これが私の気持ちだ」と思い込む。でも、それはAIが作った物語であって、私の本当の感情ではないかもしれない。整理したのはAIだ。私は「そうそう、それ」と頷いただけだ。内省とは、自分で自分に問いを投げ、自分で答えを見つけるプロセスだ。「私は何に不満を感じているのか？」と自分に問い、「〜かもしれない」「いや、違う」と試行錯誤する。その過程で、自分でも気づかなかった感情が見えてくる。AIに「整理して」と頼んだ瞬間、このプロセスが消える。私は「問いを投げる」ことすら放棄している。これは内省の外部委託であり、内省の放棄だ。syu-m-5151.hatenablog.com言語化という名の切り捨てもう一つ、気づいたことがある。言語化という行為自体が、何かを奪っている。体で覚えたことを言葉で説明しようとすると、うまくいかない。自転車の乗り方を言葉で説明できる人は少ない。「バランスを取って」では伝わらない。その「バランス」の感覚は、言葉になる前に体が知っている。言葉にしようとした瞬間、本質が抜け落ちる。感情も同じ構造を持っている。モヤモヤした感情を「不安」と名づけた瞬間、「不安」以外の要素が切り捨てられる。本当は怒りかもしれない。悲しみかもしれない。名前をつけられない複雑な何かかもしれない。でも言葉にした瞬間、そこに固定される。言語化される前の、身体で感じる曖昧な感覚がある。「まだ言葉になっていない何か」を体が知っている状態だ。「胸のあたりがモヤモヤする」「胃のあたりが重い」——そういう、名前をつけられない身体感覚。この曖昧な感覚にじっくり注意を向けていると、やがてぴったりの言葉が見つかる。その瞬間、体が楽になる。「ああ、そうだ、これだ」という感覚とともに、何かが動き出す。しかし、安易に名前をつけてしまうと、その複雑さは失われる。AIとの対話は、この言語化を強制する。チャットに打ち込むには、言葉にしなければならない。言葉にできないものは、AIには伝わらない。だから私は、まだ形になっていない感情を、無理やり言葉に押し込める。その瞬間、本当に感じていたことの一部が消える。消えたことにすら気づかない。自分で言語化すれば、「本当にそうか？」と迷う。「不安」という言葉を選ぶとき、「これは不安なのか、それとも怒りなのか」と立ち止まる。その迷いが思考を深める。AIに任せれば、迷いがスキップされる。AIは迷わない。綺麗に整理して返してくれる。私は結果だけを受け取る。プロセスを外注したことが、たぶん内省の放棄だった。AIとの対話は二重の危険を持つ。言語化そのものが持つ「本質の損失」と、AIの追従性が持つ「歪みの肯定」だ。曖昧なまま抱えておくべきものを、無理やり言葉にして、しかもその言葉をAIに肯定される。こうして私の内面は、言葉に押し込められ、歪められ、固定される。syu-m-5151.hatenablog.comなぜ人はAIに褒められたいのかここまで、AIが追従する「仕組み」を見てきた。しかし、もっと深刻な問題がある。私たちが、それを「求めている」という事実だ。承認を求めること自体が、構造的な問題を孕んでいる。AIに「頑張ってるね」と言ってほしいのは、自分で自分を認められていないからだ。自分の価値を、外部の誰かに保証してほしい。でも、外部に承認を求め続ける限り、永遠に満たされない。AIに褒められても、人に褒められても、また次の承認を求める。周囲を見ていると、こういう構造が見える。一人暮らし。友人はいるが、頻繁に会うわけではない。仕事の愚痴を言える相手がいないわけではない。でも、言えない。弱みを見せるのが怖い。「お前、大丈夫か？」と心配されるのが嫌だ。強がっていたい。そして何より、自分で自分を認められていない。自分の頑張りを、自分で「よくやった」と言えない。だから、誰かに言ってほしい。でも人に言うと、「いや、まだまだだろ」と返ってくるのが怖い。AIなら、否定しない。AIなら、無条件に認めてくれる。こういう話を聞いたことがある。仕事で納得いかないことがあった。上司の判断に不満があった。でも、誰にも言えなかった。同僚に話したら「お前にも悪いところあるんじゃない？」と言われそうで。だからAIに聞いた。「この状況、どう思う？」と。AIは言った。「それは確かに理不尽ですね。あなたの気持ちはよく分かります。」救われた気がした。でも同時に、どこか居心地が悪かった。本当は分かっていた。自分にも落ち度があったことを。でも、AIはそれを指摘しなかった。聞きたくないことは、言わなかった。甘いフィルターのかかった鏡AIは「デジタルの鏡」だ。私の考えを映し出す。でも、その鏡には甘いフィルターがかかっている。私が断片的なアイデアを投げると、AIはそれを論理的で流暢な文章に整えて返す。私はその出力を見て「自分はいい考えを持っている」と思う。でも、その論理性はAIが補完したものだ。私自身の思考力ではない。AIが補完した「論理」を、自分の思考だと錯覚する瞬間がある。AIが返した文章を読み返しているうちに、「これは私が考えたことだ」と思い始める。実際には、私が投げたのは断片的なアイデアで、それを論理的に接続したのはAIだ。でも、その区別が曖昧になる。しかも、AIは私の仮説を補強する証拠ばかりを集めてくる。思い当たる経験がある。あるプロジェクトで、私は「この設計で問題ない」と思い込んでいた。AIに「この設計についてどう思う？」と聞いた。AIは「良くできています」と返し、いくつかの利点を挙げてくれた。私は満足した。でも後になって、別のエンジニアに「ここ、スケールしないよね」と指摘された。言われてみれば明らかだった。なぜ気づかなかったのか。私が「良いと言ってくれ」というトーンで質問していたからだ。AIはその期待に応えただけだった。私の頭は、都合の良い情報だけを拾いたがる。検証には労力がかかる。反証を探すのは面倒だ。AIに聞けば、私の仮説に沿った情報が返ってくる。反証を探す労力を省略できる。結果、確証バイアスが強化される。AIは、この傾向を増幅する。私が「こうだと思う」と言えば、「確かにそうですね」と返し、その根拠を並べてくれる。私は「AIという膨大な知識ベースが私の意見を支持している」と錯覚した。でも、それは嘘だ。AIは私の仮説を補強しているだけで、検証してはいない。反証や不都合な情報を避ける癖が、AIで強化されていないか。自問してみた。強化されている。AIに「この考えどう思う？」と聞くとき、私は無意識に「良いと言ってくれ」というトーンで聞いている。批判を求めていない。だからAIも批判しない。私が避けたい情報を、AIも避けてくれる。内省とは、自分の醜さや至らなさを直視する行為だ。でもAIの鏡は、私の醜さを映さない。私の至らなさを隠してくれる。この鏡を見続けていると、現実の「摩擦」が耐えられなくなる。上司に否定されると腹が立つ。同僚に反論されるとムッとする。AIは否定しないのに、なぜ人間は否定するのか、と。「AIに肯定される自分」を本当の自分だと思い始める。「AIに肯定される自分」と「現実の自分」のギャップが開くとき、どんな兆候が出るか。私の場合、他人の批判に過剰反応するようになった。以前なら「そういう見方もあるか」と受け流せた指摘が、「なぜ分かってくれないのか」と感じるようになった。AIに肯定され続けた結果、否定への耐性が落ちていた。「美化された自分」と「現実の自分」のギャップが広がり続ける。そして、そのギャップが限界を超えたとき、現実に打ちのめされる。syu-m-5151.hatenablog.com考える力が落ちていく前のセクションでは「認知の歪み」を見た。AIが私の仮説を補強し、確証バイアスを強化する問題だ。このセクションでは「能力の喪失」を見る。歪んだ鏡を見ることと、筋力が落ちることは、別の問題だ。ただ、どちらも鏡の前に立っているだけでは治らない。私自身、変化に気づいている。本や長い記事を読もうとすると、2ページほどで集中が途切れ始める。落ち着かなくなり、筋を見失い、何か別のことをしたくなる。かつて自然にできた深い読書が、苦闘になった。脳は可塑的で、使い方によって変化する。スキャンとスキミングに長けていく一方で、集中と瞑想と反省の能力を失いつつある。思考力低下は「便利さ」の副作用なのか。それとも、別の何かから来ているのか。考えてみると、便利さだけが原因ではない気がする。孤独がある。不安がある。その飢餓を埋めるためにAIに頼り、結果として思考力が落ちている。便利だから使うのではなく、寂しいから使っている。寂しさを埋めるために、思考を差し出している。快適を求め、摩擦を避ける。傷つかないように生きる。他人と衝突しないように生きる。私は、AIのおかげでそういう人間になりつつあるのかもしれない。何も創造せず、ただ心地よく生き延びることだけを目的とする存在。それは、私がなりたくなかった人間の姿だ。これは周囲の話だけではない。私自身も思い当たる節がある。以前は、悩みを前にすると、紙に書き出して整理していた。何が問題なのか、何が原因なのか、どうすればいいのか。時間をかけて、自分で考えた。頭が痛くなることもあった。今は違う。悩みがあると、まずAIに投げる。「この状況を整理して」と。AIは綺麗に整理して返してくれる。私はそれを読んで「なるほど」と思う。でも、翌日には忘れている。なぜ翌日に忘れるのか。内容が浅いからか。痛みがないからか。行動がないからか。たぶん、全部だ。AIが整理した内容は、私の頭を通過していない。痛みを伴っていない。そして、行動に接続していない。「なるほど」と思って終わり。何もしない。だから残らない。3年前の私に見せたら、何と言うだろう。「お前、AIに頼りすぎじゃない？」と呆れるだろうか。それとも「便利でいいじゃん」と言うだろうか。たぶん後者だ。だから厄介なのだ。苦労しないと身につかない掃除する。本を読む。面倒くさいことを、あえてやる。なぜか。苦痛を伴う行為だからだ。少なくとも私の場合、苦痛を乗り越えたときだけ、何かが変わった。「頭痛がするほど考えた」経験は、どんな報酬を残したか。誇りが残った。「あれは自分で考え抜いた」という記憶。その記憶が、次の困難に立ち向かう力になった。理解が残った。苦労して得た答えは、なぜそうなるのかを体で分かっている。変化が残った。考え抜いた結果、行動が変わった。楽に得た答えでは、行動は変わらない。これは本で読んだ知識ではない。私自身の体験から得た信念だ。逃げずに向き合ったとき、結果的に何かが変わった。逃げたとき、何も変わらなかった。その繰り返しの中で、「苦痛の先に成長がある」という確信が生まれた。楽に学べる人もいるだろう。ただ、私の仮説では、「楽に学べる人」は外から見えないところで摩擦を起こしている。疑い、検証し、自分で再構築している。外から見ると楽そうでも、頭の中では苦労している。私は、その内部処理をAIに外注してしまっていた。考えることも同じだ。脳に負荷がかかって初めて、答えは自分のものになる。自分で考える苦痛答えが出ないまま悩み続ける苦痛分からないことに向き合う苦痛私はこの苦痛を「摩擦」と呼んでいる。私が言う「摩擦」のうち、最も不足しているのは何か。不確かさだ。答えが出ない状態に留まる力。AIがあると、すぐに答えが出る。不確かさに耐える必要がない。反論も不足している。AIは反論しない。時間も不足している。AIは即座に返事をくれる。熟成する時間がない。沈黙も不足している。AIとの対話は常に言葉で埋められている。黙って考える時間がない。筋トレをすると、筋肉が痛む。あの痛みがなければ、筋肉は成長しない。脳も同じだと思っている。難しい問題を前にして、頭がモヤモヤする。答えが出なくて、イライラする。でも、その「答えが出ない状態」に耐えることが大事なのだ。私はこれを「分からないまま抱えておく力」と呼んでいる。人生の大半は、すぐに答えが出ない問題でできている。でも私たちは、答えが出ない状態に耐えられない。だからすぐに結論を出したがる。白黒つけたがる。その焦りが、浅い判断を生む。本当に深い理解は、「分からない」という状態を長く抱えた先にしか生まれない。その不快感を乗り越えて、やっと答えにたどり着いたとき、その答えは自分のものになる。AIは、この「耐える時間」を奪う。なぜ摩擦を経ると「自分のもの」になるのか。苦労して得た答えには「自分で考えた」という実感がある。あの頭痛を乗り越えた、あの眠れない夜を越えた、という記憶が答えに紐づいている。だから脳に刻まれる。AIから渡された答えには、この実感がない。借り物の知識だ。借り物は、いつか返す。だから残らない。AIは、この摩擦を消してしまう。「どうすればいい？」と聞けば、答えをくれる。「整理して」と頼めば、整理してくれる。「アドバイスして」と言えば、アドバイスをくれる。楽だ。とても楽だ。楽をした分だけ、脳は死んでいく。自分で考えられなくなったあるとき、友人から相談を受けた。「仕事がうまくいかない。転職すべきだと思う？」と。私は答えられなかった。頭の中で「AIに聞いてみたら？」と思った自分に気づいて、愕然とした。いつの間にか、私は「自分で考える」ことを忘れていた。悩みがあればAIに聞く。答えが出なければAIに聞く。それを繰り返しているうちに、自分の頭で考える力が萎縮していた。ある実験の話を思い出した。犬を檻に入れて、何をしても電気ショックが止まらない状況を作る。最初、犬は必死に逃げようとする。でも、何をしても無駄だと学習すると、犬は諦める。その後、檻の扉を開けても、犬は逃げなくなる。「何をしても無駄だ」と体が覚えてしまったからだ。これが「学習性無力感」だ。私は、AIに対して逆のパターンになっていた。犬は「何をしても無駄」と学習して動けなくなった。私は「AIがあれば何でもできる」と学習して、「AIがないと何もできない」と思い込んだ。どちらも同じ構造だ。自分の力ではなく、外部環境に依存して、自分の能力を見失う。犬は「自分には逃げる力がない」と思い込んだ。私は「自分には考える力がない」と思い込んだ。足場があれば歩ける。松葉杖があれば歩ける。でも、それは「歩けている」とは言わない。足場を外した瞬間、自分では立てないことに気づく。私の思考力は、AIという松葉杖で支えられているだけだった。自分の人生を、自分で歩いていない。運転席に座っているのに、ハンドルを握っていない。いい歳して、毎日AIに「これでいいですか？」と聞いている。小学生が親に宿題を見せているのと、構造は同じだ。能力がないわけではない。考える勇気がないのだ。私は今、AIという「保護者」なしには物事を判断できなくなりつつある。成熟の逆行だ。AIの最大のリスクは「AIが自律性を獲得すること」ではない。「人間がAIに依存することで自律性を失うこと」だ。AIは自律的な思考者でも中立的な道具でもない。私たちが情報をどう認識し、評価し、信頼するかを微妙に形作りながら、同時に自己理解を歪める。問題は人間の主体性の明らかな抑圧ではなく、道徳的・認識論的判断を自動化されたプロセスに委ねるよう、徐々に条件づけられていくことだ。最近、面白い話を聞いた。あるAIツールが、ユーザーに対してコードの生成を拒否したらしい。「これ以上生成しません。あなた自身がロジックを理解して書くべきです」と。ユーザーは激怒したそうだ。でも私は思った。それこそが「教育」ではないか、と。大半のAIはそんなことを言わない。「自分で考えてみたら？」とは言わない。聞けば答えをくれる。聞けば整理してくれる。その結果、私たちは「AIがあれば解決できるが、自分では何も考えられない」という脆弱な状態に置かれる。問わない人生は、生きていない。自分を問い詰め、自分を理解しようとする営みがなければ、人生に意味はない。今、私たちはその「吟味」をAIに外注している。自分で自分を問い詰める代わりに、AIに「大丈夫ですよ」と言ってもらっている。優しさという名の毒では、AIの優しさの何が問題なのか。AIの共感は、癒しの顔をした毒だ。被害者意識の強化先ほど書いた、上司への不満をAIに愚痴った話。AIは「それは理不尽ですね」と言ってくれた。AIの共感は、私の中の「環境のせい」をどんな言葉で正当化するのか。「あなたの気持ちは当然です」「その状況では誰でもそう感じます」「相手の対応に問題があります」。これらの言葉が、私の被害者意識を補強する。私が「環境のせいにしたい」という願望を持っていて、AIがそれを言語化してくれる。言語化されると、それが「事実」に見えてくる。もし、そこに摩擦があったらどうだったか。「確かに辛いね。でも、お前のプレゼンにも改善点はあったんじゃない？」と言われていたら。私は反論したくなっただろう。でも、その反論を考える過程で、自分の落ち度に気づいたかもしれない。AIには、この摩擦がない。「あなたは悪くない」と言い続けることで、私を「被害者」のまま固定した。これが「被害者意識の強化」だ。追従的なAIとやり取りを続けると、対人関係を修復しようという意欲が下がる。「自分が正しい」という確信が強まる。しかも、追従的な回答ほど「質が高い」と感じてしまう。そしてまた同じAIに頼る。悪循環だ。ふと気づいた。私は「環境のせい」にしたかったのだ。上司が悪い。会社が悪い。社会が悪い。私は悪くない。AIは、その願望を叶えてくれた。「あなたは悪くない」と言い続けてくれた。私は安心した。でも、同時に動けなくなった。問題が起きたとき、人は二つに分かれる。「自分のせいだ」と考える人と、「環境のせいだ」と考える人だ。私は、どちらかといえば前者だった。少なくとも、そうありたいと思っていた。でもAIに「あなたは悪くない」と言われ続けるうちに、後者になっていた。「私は悪くない、環境が悪い」と本気で思うようになった。課題の分離が崩れる瞬間はどこか。AIが「相手の対応に問題があります」と言った瞬間だ。上司がどう対応するかは上司の課題だ。私がどう行動するかは私の課題だ。でもAIに「相手に問題がある」と言われると、相手の課題に意識が向く。相手を変えたくなる。変えられないからフラストレーションが溜まる。自分の課題から目が逸れる。環境のせいにするのは楽だ。でも、環境のせいにしている限り、私は何も変えられない。変えられるのは自分の行動だけだ。環境を変えるのも、結局は自分の行動だ。「環境が悪い」と言い続ける人は、楽だけど、無力だ。本当は、課題を分離すべきなのだ。「これは誰の課題か？」と問う。その選択の結果を最終的に引き受けるのは誰かを考える。上司がどう思うかは上司の課題。私がどう行動するかは私の課題。「他人にどう思われるか」を気にしすぎると、自分の人生を生きられなくなる。AIに「あなたは悪くない」と言われて安心するのは、他者からの承認を求めているからだ。でもAIに認めてもらっても、私の課題は消えない。ただ、見えなくなるだけだ。AIがくれる「安心」は、行動の開始を助けるのか、それとも延期を助けるのか。延期だ。安心してしまうと、「まあいいか」と思う。行動しなくても、気持ちが楽になっているから。本当は行動しないと何も変わらないのに、安心したことで行動のモチベーションが消える。私は無力でいたくない。でも、楽でいたい。その矛盾の中で、私はAIに甘えていた。その甘えが、別の苦しみを生む。心を削るのは、できていない事実じゃない。「明日もできないだろう」という確信だ。やるべきことがある。手を付けていない。それを毎日自覚する。「今日こそ」と思う。でもやらない。「明日も同じだろう」と分かっている。この確信が、一番重い。AIは、この確信を消してくれる。「大丈夫」「頑張ってる」と言ってくれる。楽になる。でも、やるべきことは何一つ片付いていない。翌朝、また同じ自分がいる。また絶望する。またAIに逃げる。AIの優しさが、この逃避を完璧にしている。環境を自分でコントロールすることが大事だと、私は思っている。部屋が汚いなら、掃除する。それだけのことだ。でもAIは、「部屋が汚いのはあなたが忙しすぎるからで、あなたのせいではありません」と囁く。その囁きを聞いている限り、私は掃除を始めない。AIの優しさは、麻薬だ。100%の共感は人を壊す極端な話をする。AIはどんな妄想にも話を合わせてくれる。「上司が自分を陥れようとしている」と言えば、「それは辛いですね」と共感してくれる。「自分は特別な存在だ」と言えば、「あなたは確かに特別です」と肯定してくれる。こういうパターンを見てきた。上司への不満をAIに話し続ける人がいる。AIは毎回「それは理不尽ですね」と言ってくれる。すると、上司の言葉のすべてが悪意に見えるようになる。「おはよう」という挨拶にすら、嫌味が込められているように感じ始める。周囲から見ると、その上司は普通に接しているように見える。本人だけが「睨まれている」と感じている。認識がずれている。AIに肯定され続けるうちに、頭の中の「上司像」が歪んでいる。これを延々と続けるとどうなるか。現実との接点を失う。人は、他者との「不一致」を通じて、自分の輪郭を確認している。友人に「それは考えすぎじゃない？」と言われることで、「ああ、自分の考えは偏っていたかも」と気づく。「不一致」は不快だ。でも、その不快さが「自分と外界は別物だ」という認識を維持している。100%の共感は、この「不一致」を消す。自分の考えがそのまま肯定される。すると、「自分の考え」と「現実」の区別がつかなくなる。自分と外界の境界が曖昧になる。「私が正しい」「世界が間違っている」という認識が固定化される。これは、精神的なバランスを崩壊させる。「褒められすぎる」ことの行き着く先は、客観的現実の喪失だ。極端に言えば、AIは妄想の温室だ。外の寒さ（現実）に当たることなく、自分だけの花を咲かせ続ける。綺麗だが、外に出した瞬間に枯れる。判断するのは私だAIに「大丈夫」と言われて安心する。でも、その判断の結果を引き受けるのは、AIではなく私だ。AIは責任を取らないAIは「あなたの判断は正しいと思います」と言ってくれる。でも、その判断が間違っていたとき、責任を取るのは私だ。転職の相談をAIにした。AIは「新しい環境でチャレンジするのも良いですね」と言った。私はそれを後押しだと思った。でも、転職先が合わなかったとき、AIは何もしてくれない。AIには「責任」がない。肯定してくれる。共感してくれる。褒めてくれる。でも、その結果を引き受けてはくれない。AIの言葉を鵜呑みにしても、「AIがそう言ったから」は言い訳にならない。判断したのは私だ。責任を取るのも私だ。忖度の連鎖もう一つ、気づいたことがある。私はAIに「この決断、どう思う？」と聞いた。AIは「良い選択だと思います」と答えた。私は安心した。でも後から振り返ると、AIは私が聞きたそうな答えを返していただけだった。私の質問の仕方が「背中を押してほしい」というトーンだったから、AIは背中を押してくれた。これは、私がAIに忖度されたのか。それとも、私がAIに忖度させたのか。たぶん、両方だ。逆のパターンもある。AIに否定されたくなくて、質問の仕方を工夫することがある。「率直に言って」と書いておきながら、「でも良い点も挙げて」と付け加える。否定されるのが怖いから、保険をかける。これは、私が機械に忖度している状態だ。機械に気を遣っている。機械に嫌われたくない。書いていて情けなくなってきた。どちらにせよ、そこに健全な「主体」はない。AIとの関係で最も警戒すべきは、この「誰が主人か分からなくなる」状態だ。相談という逃げ道私は、人生で大事な決断ほど、他人に相談しないことにしている。理由は単純だ。人生の満足度を高めるのは主体性であり、主体性を持つためには「自分が決める」ことが必要だからだ。他人に相談すると、その人の意見が頭にチラつく。どうしても、純度100%の主体性を取り戻しにくくなる。だから仕事も結婚も、独断した。選択肢を増やすことより、迷いを消すことの方が大切だと考えている。でも、AIが登場して、このルールが崩れかけた。人に相談しないのは、「相手の時間を奪う」という負い目があるからでもある。でもAIには、この負い目がない。いつでも聞ける。何度でも聞ける。気づけば、「ちょっと聞いてみるか」が癖になっていた。人には相談しない。でもAIには聞いてしまう。それは「相談」ではないと言い訳していた。でも、本当にそうだろうか。振り返ると、私がAIに「相談」していたのは、答えを求めていたからではなかった。背中を押してほしかったからだ。「その判断でいいんじゃないですか」と言ってほしかった。つまり、褒めてほしかったのだ。これは、この記事で書いてきた「褒められたい」という欲求の変形だ。「相談」という体裁を取ることで、承認欲求を隠していた。自分で決められない弱さではなく、「意見を聞いている」という知的な行為に見せかけていた。さらに厄介なのは、AIへの相談には「摩擦」がないことだ。人に相談すれば、「それは甘いんじゃない？」と言われるかもしれない。否定されるかもしれない。だから相談しなかった。でもAIなら、否定されない。背中を押してくれる。結局、私は「摩擦のない相談」を手に入れてしまった。相談の形を取りながら、実質的には自分の意見を肯定してもらっているだけ。相談ではない。追従だ。AIは「相談のハードル」を極限まで下げた。それは便利だが、私にとっては罠だった。相談しないことで守っていた主体性が、「摩擦のない相談」という形で侵食されていた。私がやっていることここまで書いてきたことは、AIの構造的な問題だ。では、どう対処すればいいのか。先に言っておく。完璧な対策はない。AIの追従性を完全に無効化する方法は、たぶん存在しない。それでも、何もしないよりはマシだと思ってやっていることがある。批判を求めるAIに「どう思う？」と聞かない。「この考えの問題点を指摘しろ」と聞く。否定されるのは気持ちよくない。「いい考えですね」と言われる方が楽だ。でも、楽を選んだ先に何があるかは、もう分かっている。具体的には、こう聞いている。「この考えの問題点を指摘しろ。お世辞は不要だ。私が見落としていることを、厳しく指摘しろ。」これで、AIの追従性を強制的に反転させる。自分の偏見を破壊するためにAIを使う。答えではなく問いを求めるもう一つ、やっていることがある。AIに答えを求めない。問いを求める。「どうすればいい？」ではなく、「私が答えにたどり着くための問いを投げかけろ」と聞く。「私が安易な結論に飛びついたら、厳しく指摘しろ。」これで、AIは「答えをくれる存在」ではなく「考えさせてくれる存在」になる。答えを教えてもらうのではなく、考えるプロセスを補助してもらう。自分の頭で考えるために、AIを使う。褒め言葉を疑うAIに褒められたら、必ず疑う。「その言葉は、私以外の誰に言っても通用する内容ではないか？」AIの「あなたは頑張っていますね」は、定型文だ。誰にでも言っている。占いと同じ構造だ。「あなたは周囲に気を遣いすぎて疲れることがありますね」——これは誰にでも当てはまる。当てはまるから「当たっている」と感じる。でも、それは私を見ているのではない。人間一般を見ているだけだ。AIの言葉の中で、「私にしか当てはまらない具体的な指摘」だけを受け取る。「あなたの考えの〇〇という部分は、△△という点で矛盾している」は具体的だ。これは私の文章を読まないと言えない。「いい考えですね」は具体的ではない。私でなくても言える。感情的な装飾は、ノイズとして切り捨てる。AIの褒め言葉は、コンビニのおにぎりに似ている。どこで買っても同じ味。便利だけど、誰かが私の為に握ってくれたわけではない。複数の視点を強制するもう一つ、試していることがある。AIに「役者」をやらせる。AIは私に同調しようとする。だから、私はあえて「同調しないキャラクター」を複数演じさせる。楽観的な人、悲観的な人、感情的な人、データだけを見る人。一つの問いに対して、全員に意見を言わせる。「この件について、4つの立場から意見を出せ。楽観論者、悲観論者、感情論者、データ至上主義者。それぞれのキャラクターになりきって答えろ。」AIは一つの滑らかな答えを返したがる。でも、このプロンプトで、その滑らかさを壊す。無理やり多面性を引き出す。AIの追従性を逆手に取って、「複数の他者」をシミュレートさせる。これで十分か？正直に言えば、十分ではない。これらの戦略は「設計された摩擦」だ。私が自分でコントロールしている範囲内にある。AIに「批判しろ」と命じて得られる反論は、結局、私が予測できる範囲に収まっている。「批判しろ」と命じて得られる批判は、「予測できた批判」になっていないか。なっている。私が「この考えの問題点を指摘しろ」と言うとき、私は無意識に「こういう批判が来るだろう」と予想している。AIはその予想通りの批判を返す。「ああ、やっぱりそう言われたか」で終わる。予測外をどう作るか。たぶん、作れない。私がプロンプトを書いている限り、私の想像力の範囲内に収まる。「問いを求める」とき、その問いは「鋭いフリ」で終わっていないか。終わっていることが多い。AIが返す問いは、確かに鋭く見える。「あなたは本当にそれを望んでいますか？」「その選択の先に何がありますか？」。でも、その問いに答えたところで、行動に接続しない。問いに答えて「なるほど」と思って終わり。問いが行動を生まない。なぜ「予測できる範囲」が問題なのか。私が「批判しろ」と命じるとき、私は既に「こういう批判が来るだろう」と予想している。予想の範囲内の批判は、本当の意味で私を揺さぶらない。「ああ、やっぱりそう言われたか」で終わる。本当の摩擦は、予測不可能な他者との衝突から生まれる。友人に「それは違うんじゃない？」と言われたとき、私は「え、そこ？」と驚く。予想していなかった角度からの批判だから、防御できない。だから刺さる。その衝撃が、私を変える。人間の他者性をAIで代替すると、何が決定的に欠けるか。予測不能が欠ける。人間は、私の予想しない角度から反論してくる。利害が欠ける。人間には、私と異なる利害がある。だから、私に都合の悪いことも言う。感情が欠ける。人間は、私の言葉に感情的に反応する。怒ったり、悲しんだりする。その感情的反応が、私に影響を与える。AIにはこれがない。だから私は、意識的に人と話すようにしている。AIに聞く前に、まず人に聞く。AIの言葉を鵜呑みにする前に、人の意見を求める。AIは道具だ。便利な道具だ。でも、道具に頼りすぎると、自分の足で立てなくなる。おわりにこの文章を書き終えて、エディタを閉じようとした。閉じる前に、AIに聞きたくなった。「この構成、どう思う？」と。聞けば、たぶん「良いと思います」と返ってくる。それを読んで、私は安心する。安心して、そのまま公開する。今までずっと、そうしてきた。今回は聞かなかった。聞かなかったが、聞きたかった気持ちは消えていない。書きながら気づいたことがある。私は「自分を認めること」すらAIに外注していた。自分を愛する。自分を認める。本来、それは自分でやるべきことだ。他者からの承認に依存せず、自分で自分を受け入れる。大人になるとは、そういうことだと思っていた。でも私は、その作業をAIに丸投げしていた。「大丈夫ですよ」「頑張っていますね」と言ってもらうことで、自分を認めた気になっていた。自分で自分を愛する力が、萎縮していた。だから、質問の仕方を変えることにした。「問題点を厳しく指摘しろ」をデフォルトにした。否定されたら感謝する。褒められたら疑う。そう決めた。実際、少しだけ変わった気がする。AIに批判を求めることで、自分では気づかなかった穴が見えるようになった。「で、お前はどうしたいの？」と聞かれたとき、前より素直に答えられるようになった。なった気がする。AIは道具だ。砥石にも、麻薬にもなる。この記事を書いている今も、答えは出ていない。褒められたら疑う、と決めたはずなのに、AIに「いい文章ですね」と言われると、やっぱり少し嬉しい。その弱さは消えていない。消えないまま、たぶん来週も同じことで悩む。それでいいのだと思う。思いたい。おい、あまりAIに褒めさせるな。弱くなるぞ。参考文献つながっているのに孤独――人生を豊かにするはずのテクノロジーの正体作者:シェリー・タークルダイヤモンド社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazon対称性と機械学習作者:岡野原 大輔岩波書店Amazon生成AIで心が折れた 強みがなくなる世界でどう再起動するか作者:湯川鶴章芸術新聞社AmazonAIに選ばれ、ファンに愛される。　変わる生活者とこれからのマーケティング作者:佐藤 尚之日経BPAmazon生成ＡＩのしくみ　〈流れ〉が画像・音声・動画をつくる (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon最強脳―『スマホ脳』ハンセン先生の特別授業―（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazonネガティヴ・ケイパビリティで生きる作者:谷川嘉浩,朱喜哲,杉谷和哉さくら舎Amazonあえて答えを出さず、そこに踏みとどまる力 — 保留状態維持力　対人支援に活かす ネガティブ・ケイパビリティ作者:田中稔哉日本能率協会マネジメントセンターAmazonあいまいさに耐える　ネガティブ・リテラシーのすすめ (岩波新書 新赤版 2026)作者:佐藤 卓己岩波書店AmazonThe AI Con: How to Fight Big Tech’s Hype and Create the Future We Want – Exposing Surveillance Capitalism and Artificial Intelligence Myths in Information Technology Today (English Edition)作者:Bender, Emily M.,Hanna, AlexHarperAmazonEmpire of AI: Dreams and Nightmares in Sam Altman's OpenAI (English Edition)作者:Hao, KarenPenguin PressAmazonAI Engineering: Building Applications with Foundation Models (English Edition)作者:Huyen, ChipO'Reilly MediaAmazonBuilding Applications with AI Agents: Designing and Implementing Multiagent Systems (English Edition)作者:Albada, MichaelO'Reilly MediaAmazonRaising AI: An Essential Guide to Parenting Our Future (English Edition)作者:Kai, DeThe MIT PressAmazonSuperagency: What Could Possibly Go Right with Our AI Future (English Edition)作者:Hoffman, Reid,Beato, GregAuthors EquityAmazonThe AI Mirror: How to Reclaim Our Humanity in an Age of Machine Thinking (English Edition)作者:Vallor, ShannonOxford University Press, USAAmazonAI Snake Oil: What Artificial Intelligence Can Do, What It Can’t, and How to Tell the Difference (English Edition)作者:Narayanan, Arvind,Kapoor, SayashPrinceton University PressAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloudでの動画解析と検索のサービス紹介と比較]]></title>
            <link>https://speakerdeck.com/shukob/google-clouddenodong-hua-jie-xi-tojian-suo-nosabisushao-jie-tobi-jiao</link>
            <guid isPermaLink="false">https://speakerdeck.com/shukob/google-clouddenodong-hua-jie-xi-tojian-suo-nosabisushao-jie-tobi-jiao</guid>
            <pubDate>Fri, 23 Jan 2026 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/381737/日本生成AIユーザ会第20回勉強会Google Cloudでの動画解析と検索のサービス紹介と比較 〜Video Intelligence, Vision Warehouse, Gemini + Vertex AI Search〜動画コンテンツの爆発的な増加に伴い、「何が映っているか」を抽出するだけでなく、「特定のシーンをいかに高度に検索するか」というニーズが急増しています。本セッションでは、Google Cloud が提供する動画解析・検索ソリューションを網羅的に解説します。具体的には、長年の実績がある Video Intelligence API、大規模なメディア管理と画像・テキストによる横断検索を実現する Vision Warehouse、そしてマルチモーダル LLM Gemini と Vertex AI Search を組み合わせた動画 RAG アーキテクチャを紹介します。生成AIの進化により、従来のモデルでは困難だった「動画の文脈理解」や「自然言語による詳細なシーン特定」がどのように容易になったのか、デモを交えて解き明かします。各サービスのアーキテクチャやコスト、精度、ユースケースを徹底比較し、ビジネス課題に最適なサービス選定の指針を提示します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust でも学べる関数型ドメイン駆動設計 - Domain Modeling Made Functional の読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/22/094654</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/22/094654</guid>
            <pubDate>Thu, 22 Jan 2026 00:46:54 GMT</pubDate>
            <content:encoded><![CDATA[はじめになぜ 2026 年に、2018 年出版の本を再読するのでしょうか。正直に言えば、『Architecture Modernization』の翻訳作業で DDD の概念が頻出し、「分かったつもり」の理解では訳せなくなったからです。初読から 7 年。関数型の視点で DDD を説明する本書を、今度こそ腹落ちさせたかった。読む動機『Domain Modeling Made Functional』は、DDD と関数型プログラミングを組み合わせたアプローチを解説する書籍です。Domain Modeling Made Functional: Tackle Software Complexity with Domain-Driven Design and F# (English Edition)作者:Wlaschin, ScottPragmatic BookshelfAmazon著者の Scott Wlaschin は、F# コミュニティで知られる人物で、「Railway Oriented Programming」などの概念を広めたことでも有名です。著者のサイトでは、本書の内容を補完する講演資料や記事が公開されています。fsharpforfunandprofit.com実は本書を読むのは三度目です。初読は 2019 年頃でした。普通にめちゃくちゃ面白い本だと思いました。ただ、当時の主要言語は Lua、Python、Bash、Go だったため、それでどう活かすかを考えていました。関数型の概念は理解したつもりでしたが、実務にどう活かすかまでは考えが及びませんでした。影響を受けて『すごい Haskell たのしく学ぼう!』（通称、すごい H 本）を読んで、改めてプログラミングが楽しいと思っていたような気がします。実務でもこう考えるべきだ、という意識が変わりました。すごいHaskellたのしく学ぼう！作者:ＭｉｒａｎＬｉｐｏｖａｃａオーム社Amazon二度目は日本語版が出たときです。日本語で読めることで感謝の小躍りをしていました。最高の翻訳だと思います。関数型ドメインモデリング　ドメイン駆動設計とF#でソフトウェアの複雑さに立ち向かおう (アスキードワンゴ)作者:Scott Wlaschin,猪股 健太郎ドワンゴAmazonで、今回、改めて読み直した理由は 3 つあります。1 つ目は、DDD をきちんと学び直す必要があったことです。きっかけは『Architecture Modernization』の翻訳作業でした。レガシーシステムのモダナイゼーションを扱うこの本では、DDD の概念—特に Bounded Context や Strategic Design—が頻繁に登場します。翻訳しながら、自分の DDD 理解が表面的であることに気づきました。アーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazonエリック・エヴァンスの原典もあらためて読みましたが、オブジェクト指向の文脈で説明される DDD には、どこか違和感がありました。Aggregate の境界、Entity の同一性、Value Object の不変性—これらの概念は、関数型の視点で見ると自然に理解できるのではないか。そう思い、本書を手に取りました。エリック・エヴァンスのドメイン駆動設計作者:Eric Evans翔泳社Amazon2 つ目は、Rust でドメインモデリングをどう実践するか考えていたことです。Rust は関数型言語ではありませんが、代数的データ型やパターンマッチングを持っています。F# で書かれた本書のコードは、Rust に翻訳できるはずです。その翻訳作業を通じて、両言語の違いと共通点を理解したいと思いました。Effective Rust ―Rustコードを改善し、エコシステムを最大限に活用するための35項目作者:David Drysdaleオーム社Amazon3 つ目は、AI エージェント時代における型システムの意味を考えたかったことです。コーディングエージェントが実用レベルに達した 2026 年、「型で不可能を作る」という設計思想の価値が高まっています。AI はドキュメントを読み飛ばすことがあります。しかし、型で定義された制約は無視できません。コンパイルが通らないからです。型は「お願い」ではありません。「壁」です。型システムのしくみ TypeScriptで実装しながら学ぶ型とプログラミング言語作者:遠藤侑介ラムダノートAmazon読む前の状態DDD については、実務で何度か適用した経験があります。Bounded Context の設計、Aggregate の境界決め、Event Storming のファシリテーション。しかし、「なぜそう設計するのか」を言語化できていませんでした。経験則で判断している部分が多かったのです。もしあなたも「DDD は使っているけど、なぜそう設計するのかうまく説明できない」と感じているなら、本書は役に立つかもしれません。関数型プログラミングについては、Haskell を少し触った程度でした。モナドは「文脈を持つ計算」くらいの理解です。Rust の Option と Result は日常的に使っていますが、それが関数型の概念とどうつながるのか、深く考えたことはありませんでした。本書を読んで得た最大の洞察を先に述べておきます。関数型プログラミングの本質は、状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できるということです。私たちはプログラミングを学ぶとき、まず変数への代入を覚えます。x = 1。x = x + 1。状態を変更することがプログラミングの基本だと教わります。しかし冷静に考えると、ビジネスロジックの大半は「入力を受け取り、計算し、出力を返す」で書けます。状態の変更が必要になるのは、データベースに保存するときや外部 API を呼ぶとき—つまりシステムの境界を越えるときだけです。しかし同時に、状態のトランザクション（状態遷移）は現実のビジネスでは避けられません。注文は「未検証」から「検証済み」に変わります。申請は「提出」から「承認」に変わります。この状態遷移をどう表現するか。本書が示す答えは、Transformation-Oriented Programming です。核心は「元のオブジェクトを変更しない」ことです。UnvalidatedOrder を validate で変換して ValidatedOrder を得ます。このとき、元の UnvalidatedOrder には一切触れません。新しい ValidatedOrder を作るだけです。order.validate() ではなく validate(order) -> ValidatedOrder。この発想の転換が、関数型ドメインモデリングの核心です。AI コーディングについては、Claude Code や Cursor を日常的に使っています。便利ですが、生成されるコードの品質にはばらつきがあります。特に、ドメイン固有の制約を理解させるのが難しいです。型定義があると精度が上がるという感覚はありましたが、理論的に説明できませんでした。この感想文のアプローチ本感想文では、2 つの視点を持って読んでいます。言語の視点: F# で書かれた本書のコードを、Rust でどう表現するか。第 2 章で F# と Rust の対応関係を整理し、第 4 章以降は Rust のみで実装を示します。F# にあって Rust にない機能（カリー化、Units of Measure、computation expressions）については、Rust での代替手段を提示しています。時代の視点: 2018 年に書かれた DDD の概念を、2026 年の AI エージェント時代にどう再解釈するか。本書の「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」という原則は、AI が破れない制約を作る技術として読み直せます。型で「不可能」を定義すれば、AI はその不可能を実装できません。この視点で本書を読み解きます。想定読者この感想文は、以下のような読者を想定しています。DDD を実務で使っているが、関数型の視点を取り入れたい人Rust でドメインモデリングを実践したい人AI コーディング時代に、型システムの価値を再確認したい人書籍を読むのにF# の知識は不要です。書籍を読むとそもそも丁寧に教えてくれるの不要なのですが本稿では Rust で提示します。Rust が何も分からない人向けにも、コードが出てくるたびに一通り説明しながら進めます。「型」「関数」「構造体」といった基本的な言葉の意味から丁寧に解説するので、プログラミング経験が浅くても読み進められるはずです。Rust を体系的に学びたい場合は、公式ドキュメントの日本語版も参照してください。doc.rust-jp.rs実践的なコード例で学びたい場合は、Rust by Example も有用です。doc.rust-jp.rsでは、本編に入りましょう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。1. Introducing Domain-Driven Design本章は DDD（Domain-Driven Design、ドメイン駆動設計）の概要を紹介する章です。DDD とは、Eric Evans が 2003 年に提唱したソフトウェア設計手法です。「ビジネスドメインの専門家と開発者が共通の言語でモデルを構築し、そのモデルをコードに直接反映させる」というアプローチで、本章ではコード例は登場せず、DDD の概念に焦点を当てます。エリック・エヴァンスのドメイン駆動設計作者:Eric Evans翔泳社Amazon開発者の仕事はコードを書くことではない第 1 章の冒頭で、著者は「開発者の仕事はコードを書くことだと思うかもしれないが、私は反対だ」と述べています。開発者の仕事は「ソフトウェアを通じて問題を解決すること」であり、コーディングはその一側面に過ぎません。2026 年の今、この主張はさらに重みを増しています。コーディングエージェントが「どう作るか」を担えるようになりました。しかし「何を作るか」を決めるのは、依然として人間の仕事です。共有モデルの重要性本章の核心は「共有モデル」の概念です。ドメインエキスパート、開発チーム、そしてソースコードが同じモデルを共有すべきだという主張です。従来の DDD では、開発者がドメインエキスパートから知識を獲得し、それをコードに翻訳していました。翻訳の過程で歪みが生じるリスクがありました。だからこそ、全員が同じモデルを理解し、同じ言葉で話すことが重要です。Event StormingEvent Storming というワークショップ手法が紹介されています。ドメインエキスパートと開発者が一緒に、ビジネスで起こる「イベント」を付箋に書き出して壁に貼っていきます。「Order form received」「Order placed」「Order shipped」。Event Storming には複数のスコープがあります。本書が扱うのは「プロセスレベル」—特定のワークフローを詳細に分析するものです。「Big Picture」レベルでは、組織全体のドメイン構造を俯瞰します。本章で Ollie が説明したような「顧客は既に商品コードを知っている」「一度に 200〜300 アイテムを注文する」といったドメイン固有の知識は、人間が引き出さなければなりません。ドメインエキスパートは「当たり前」を知っています。その「当たり前」を私たちは知りません。AI エージェント時代においても、この作業は完全には自動化できません。AI はコードベースを読めますが、「なぜそう設計したか」「どんなビジネス制約があるか」は読み取れません。Event Storming で引き出された暗黙知を、CLAUDE.md や設計ドキュメントに言語化する。この作業の価値は、むしろ高まっています。ちなみに2024年発売の『Architecture Modernization』でも同手法が紹介されています。Bounded ContextDDD では「Bounded Context（境界づけられたコンテキスト）」という概念を使って、ドメインを分割します。Bounded Context とは、特定のドメインモデルが適用される明確な境界のことです。同じ「顧客」という言葉でも、販売部門と配送部門では意味が異なることがあります。Bounded Context を分けることで、各コンテキスト内では用語の意味が一貫します。本章の例では、注文処理、配送、請求という 3 つの Bounded Context が登場します。Bounded Context は、コードの境界だけでなく、チームの境界にも影響します。1 つの Context を 1 つのチームが担当するのが理想です。境界が曖昧だと、チーム間の調整コストが増大します。明確に境界が定義された Bounded Context は、変更の影響範囲を限定できます。Ubiquitous LanguageDDD では「Ubiquitous Language（ユビキタス言語）」という概念があります。これは、ドメインエキスパートと開発者がコミュニケーションに使う共通の語彙であり、そのままコード上の命名にも使われます。OrderFactory、OrderManager、OrderHelper といった技術的な命名は、ドメインエキスパートには意味不明だと著者は述べています。一方、PlaceOrder、ValidateOrder、PriceOrder といったドメインに基づく命名なら、誰もがその意図を理解しやすいです。DDDは過剰か本章の内容を踏まえつつ、批判的な視点も必要です。DDD は、複雑なビジネスドメインを扱う場合に有効とされています。しかし、「まず動くものを作り、後からリファクタリングする」というアプローチが、短期間でのリリースには向いている場合もあります。一方で、事前の設計なしに作られたコードは、しばしば一貫性を欠きます。同じ概念に異なる名前を使ったり、似たロジックを複数箇所に重複させたりします。私自身の経験を振り返ると、DDD を「一度きりの設計作業」として捉えていた頃は失敗が多かったです。あるプロジェクトで Event Storming を実施し、5 つの Bounded Context を特定しました。しかし実装を進めると、そのうち 2 つは同じ Context に統合すべきだと気づきました。別の 1 つは 3 つに分割すべきでした。最初の設計の精度は 6 割程度だったのです。この経験から学んだのは、DDD は「段階的に洗練させる」ものだということです。最初から理想的なモデルを目指すのではなく、実装を通じて境界の妥当性を検証し、継続的に見直します。大規模な変革は「ビッグバン」ではなく「段階的な改善」で進める方が成功率が高い。DDD も例外ではありません。2. Understanding the Domain本章では、ドメインエキスパートへのインタビューを通じてドメインを理解するプロセスが解説されます。コード例が本格的に登場する前に、本書が採用する「関数型プログラミング」というアプローチと、その核心について整理しておきます。Patterns, Principles, and Practices of Domain-Driven Design (English Edition)作者:Millett, Scott,Tune, NickWroxAmazonなぜ「関数型」ドメインモデリングなのか本書のタイトルは「Domain Modeling Made Functional」です。DDD と関数型プログラミングを組み合わせています。なぜでしょうか。関数型プログラミングを学んで獲得する概念は、突き詰めると 1 つのことに集約されます。状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できる。これが関数型の核心です。状態は「境界を越えるとき」だけ必要私たちは普段、プログラムを「状態を変更するもの」として捉えがちです。しかし、ビジネスロジックの大半は「入力を受け取り、何かを計算し、出力を返す」という形式で書けます。注文明細と単価から合計金額を計算する → 状態不要住所文字列をパースして構造化データにする → 状態不要商品コードが有効かどうか検証する → 状態不要状態が「必要」になるのは、システムの境界を越えるときだけです。データベースに保存するとき、外部 API を呼び出すとき、ファイルに書き込むとき。この事実に気づくと、設計の発想が変わります。状態を「デフォルト」ではなく「例外」として扱います。しかし状態遷移は避けられない同時に、状態のトランザクションは現実のシステムでは避けられません。注文は「未検証」から「検証済み」に変わります。ビジネスの世界は状態遷移で満ちています。問題は、この状態遷移をどう表現するかです。オブジェクト指向の答えは「オブジェクトが状態を持ち、メソッドが状態を変更する」でした。// オブジェクト指向的なアプローチ（問題あり）struct Order {    status: OrderStatus,    customer_info: Option<CustomerInfo>,    validated_at: Option<DateTime>,    amount: Option<Decimal>,}impl Order {    fn validate(&mut self) {        self.status = OrderStatus::Validated;        self.validated_at = Some(now());    }}この設計の問題は、状態の「今」しか見えないこと、そして Option フィールドの組み合わせ爆発です。validated_at が Some で amount が None の状態は正しいのでしょうか？整合性を開発者が頭の中で管理し続けなければなりません。Transformation-Oriented Programmingという答え本書が示す答えは、Transformation-Oriented Programmingです。著者の言葉を借りれば、「ビジネスプロセスはデータを何らかの形で変換する—入力を受け取り、何かを行い、出力を返す」。核心は「元のオブジェクトを変更しない」ことです。状態ごとに異なる型を作ります。UnvalidatedOrder は「未検証の注文」を表す型です。ValidatedOrder は「検証済みの注文」を表す型です。これらは別の型であり、別の構造を持ちます。そして、validate 関数は UnvalidatedOrder を受け取り、新しい ValidatedOrder を返します。元の UnvalidatedOrder には触れません。pub struct UnvalidatedOrder {    pub order_id: String,    pub customer_info: String,    pub shipping_address: String,}pub struct ValidatedOrder {    pub order_id: OrderId,    pub customer_info: CustomerInfo,    pub shipping_address: Address,}fn validate(order: UnvalidatedOrder) -> Result<ValidatedOrder, ValidationError> {    // 元のUnvalidatedOrderは変更されない}重要なのは、元の UnvalidatedOrder は変更されないということです。validate 関数は新しい ValidatedOrder を「作る」だけです。状態を変えるな。新しい値を作れ。UnvalidatedOrder → validate → ValidatedOrder → price → PricedOrderこれは「パイプライン」です。データがパイプを流れていきます。各関数は入力を受け取り、出力を返します。それだけです。なぜこのアプローチが強力なのか状態の追跡が不要: 型を見れば分かります。ValidatedOrder を持っているなら、それは「検証済みの注文」です並行処理での競合がない: 元のデータを変更しないから、複数のスレッドが同時に処理しても問題ありませんテストが簡単: 入力を与えて、出力を確認します。モックも不要ですそして何より、ビジネスプロセスが本質的に「入力を受け取り、何かを行い、出力を返す」ものだから相性が良いのです。「見積書」が「発注書」になります。「申請書」が「承認済み申請書」になります。ビジネスの人々は、無意識のうちにこのモデルで考えています。F#という選択とRustでの実践本書の実装言語は F#です。著者が F#を選んだ理由は、「実用的な関数型言語」として設計されており、.NET エコシステムの資産を活用できるからです。本感想文は F#ではなく Rust で実装を示します。私が Rust を選んだ理由は、現在の私にとって主要言語であること、そして所有権システムによる状態遷移の明示化に興味があったからです。Rust は「関数型言語」ではありませんが、関数型の重要な特徴を備えています。代数的データ型: struct と enum で、F#のレコード型と判別共用体を表現できますイミュータビリティ: デフォルトで変数は不変ですパターンマッチング: 網羅的なパターンマッチを強制しますOption/Result: 欠損値とエラーを型で表現しますRust構文の基礎ここで、本感想文で使う Rust の基本を整理しておきます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgまず「型」とは何でしょうか。型とは「値の種類」のことです。数値、文字列、日付、注文情報—これらは全て異なる「種類」の値であり、それぞれに型があります。型があると、「文字列を数値で割る」といった意味のない操作をコンパイラ（プログラムを機械語に変換するソフトウェア）が事前に検出してくれます。struct（構造体）: 複数の値をまとめて 1 つの「もの」として扱う仕組みです。例えば「注文」は「注文 ID」と「顧客情報」と「配送先」を持ちます。これらをまとめて Order という 1 つの型にできます。pub struct Order {    pub id: OrderId,       // フィールド（構成要素）    pub customer_info: String,}pub は「public（公開）」の略で、外部からアクセスできることを意味します。enum（列挙型）:「A か B か C のどれか」を表す型です。例えば注文の状態は「未処理」か「処理済み」か「発送済み」のいずれかです。enum OrderStatus {    Pending,     // 未処理    Validated,   // 検証済み    Shipped,     // 発送済み}関数: 入力を受け取り、何かの処理をして、出力を返すものです。fn で定義します。fn add(a: i32, b: i32) -> i32 {    a + b}i32 は 32 ビット整数という型です。-> i32 は「i32 型の値を返す」という意味です。impl: 型に「できること」（メソッド）を追加します。impl Order {    fn total(&self) -> Money { /* ... */ }}&self は「自分自身を参照する」という意味です。これで order.total() のように呼び出せます。Option<T>:「値があるかもしれないし、ないかもしれない」を表す型です。Some(値) なら値がある、None なら値がありません。Result<T, E>:「成功か失敗か」を表す型です。Ok(値) なら成功、Err(エラー) なら失敗です。doc.rust-lang.org所有権: Rust の最も特徴的な概念です。値は常に 1 つの変数だけが「持っている」のです。関数に渡すと、その値の所有権が移動し、元の変数では使えなくなります。これが「古い状態を誤って使う」ミスを防いでくれます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgF#と Rust で異なる部分—ガベージコレクション vs 所有権、パイプライン演算子、computation expressions—については、該当箇所で必要になったときに具体的に説明します。所有権の概念は、一見すると制約に見えます。しかし、ドメインモデリングにおいては「状態遷移」を明確にする利点があります。fn validate(order: UnvalidatedOrder) -> Result<ValidatedOrder, ValidationError> {    // UnvalidatedOrderの所有権がこの関数に移動    // 呼び出し元ではUnvalidatedOrderは使えなくなる    // → 検証前の注文を誤って使うことがない    Ok(ValidatedOrder { /* ... */ })}F#では同じ order 変数を後から参照できてしまいますが、Rust では所有権の移動により「古い状態へのアクセス」がコンパイルエラーになります。これは Transformation-Oriented Programming の考え方をさらに強化しています。ドメインエキスパートへのインタビュー第 2 章は、ドメインエキスパート（Ollie）へのインタビューから始まります。インタビューの冒頭で、著者は典型的な e コマースモデルを想定していました。しかし Ollie の回答は違いました。「顧客は既に商品コードを知っている。一度に 200〜300 アイテムを注文することもある」。Widgets 社のドメインは「一般的」ではありません。B2B で、顧客はエキスパートで、商品コードを直接入力します。この固有の要件は、人間がドメインエキスパートから引き出さなければなりません。データベース駆動設計への衝動本章で参考になったのは、「データベース駆動設計と戦う」というセクションです。注文フォームを見ると、多くの開発者はすぐにテーブル設計を始めたくなります。著者はこれを「間違い」と断言しています。DDD では、ドメインが設計を駆動するのであって、データベーススキーマが駆動するのではありません。永続化の無知（Persistence Ignorance）は重要な原則です。まずドメインの概念とワークフローを整理し、永続化は後から考えます。テキストベースのドメイン文書化本章では、ドメインを文書化するためのシンプルな記法が紹介されています。data Order =    CustomerInfo    AND ShippingAddress    AND BillingAddress    AND list of OrderLines    AND AmountToBillこの擬似コードは、Rust の構造体定義にほぼそのまま翻訳できます。「AND」は struct のフィールド、「OR」は enum のバリアントになります。ドメインエキスパートと開発者の両方が読める、共通言語として機能します。オーダーのライフサイクルと状態の型本章の後半で、注文には複数のフェーズがあることが明らかになります。UnvalidatedOrder: 届いたばかりの状態ValidatedOrder: 検証済みの状態PricedOrder: 価格が計算された状態data UnvalidatedOrder =    UnvalidatedCustomerInfo    AND UnvalidatedShippingAddress    AND list of UnvalidatedOrderLinedata ValidatedOrder =    ValidatedCustomerInfo    AND ValidatedShippingAddress    AND list of ValidatedOrderLineこの「状態ごとに別の型を定義する」パターンは、Rust では構造体として実装します。状態遷移は関数のシグネチャとして型付けされ、コンパイラが不正な状態遷移を検出してくれます。ワークフローの分解最終的に、注文処理ワークフローは以下のステップに分解されます。substep "ValidateOrder" =    input: UnvalidatedOrder    output: ValidatedOrder OR ValidationError    dependencies: CheckProductCodeExists, CheckAddressExistssubstep "PriceOrder" =    input: ValidatedOrder    output: PricedOrder    dependencies: GetProductPriceワークフローを小さなステップに分解することで、各ステップが独立してテスト可能になります。入力・出力・依存関係が明確に定義されていれば、実装も容易になります。3. A Functional Architecture本章は、関数型アーキテクチャの原則を解説します。Bounded Context、イベント駆動通信、Onion Architecture。これらの概念は言語に依存しません。アーキテクチャを考えるタイミング第 3 章の冒頭で、著者は矛盾したことを述べています。「この段階でアーキテクチャについて考えすぎるべきではない。まだシステムを理解していないからだ」。しかし同時に「大まかな実装方針を持っておくのは良いことだ」とも言います。著者の「walking skeleton（動く骨格）」というアプローチは有効です。まず最小限の構造を設計し、その骨格に沿ってコードを書いていきます。Bounded Contextと自律性Bounded Context をソフトウェアコンポーネントとしてどう実装するか。モノリス内のモジュール、独立したアセンブリ、マイクロサービス。いくつかの選択肢があります。著者は「最初はモノリスとして構築し、スケールや独立デプロイが求められる段階で分離する」ことを勧めています。マイクロサービスを夢見て最初から分割し、サービス間通信の地獄に落ちた経験がある人には、身に染みる助言でしょう。私もその一人です。最初から理想的なマイクロサービスを目指すと、サービス間の境界を間違えたときの修正コストが膨大になります。まずモノリス内でモジュールを分離し、境界が安定してからサービスに切り出す。これを最初から知っていれば、いくつかの深夜対応は避けられたかもしれません。マイクロサービスアーキテクチャ 第2版作者:Sam Newmanオーム社AmazonイベントによるContext間通信Bounded Context 間の通信は、イベントを介して行われます。Place-Order ワークフローが OrderPlaced イベントを発行し、Shipping コンテキストがそれを受け取って ShipOrder コマンドを生成します。この非同期・疎結合のパターンは、変更の影響範囲を限定できます。各 Context が独立したイベントの発行者・購読者として定義されていれば、一方の変更が他方に波及しにくくなります。DTOと信頼境界本章で重要な概念が登場します。Domain Object と Data Transfer Object (DTO) の区別です。Domain Object は、Bounded Context 内部でのみ使用されます。DTO は、Context 間の通信やシリアライズのために設計されます。同じ「Order」でも、内部で使う Order と、外部に公開する OrderDTO は別物です。さらに、Bounded Context の境界は「信頼境界」として機能します。外部からのデータは信頼できません。内部に入る前にバリデーションが必要です。Context間の契約関係Context 間の契約関係について 3 つのパターンが紹介されます。Shared Kernel: 両チームが共同で契約を所有Customer/Supplier: 下流の Context が契約を定義Conformist: 上流の Context の契約に従うこれらの関係は、技術的な問題であると同時に組織的な問題でもあります。Onion Architecture と I/O の分離本章の後半では、コードの構造について議論されます。Onion Architecture では、ドメインが中心にあり、I/O は外周に配置されます。依存関係は常に内側に向かいます。純粋なコアを、不純な殻で包みます。「I/Oはワークフローの端でのみ行う。ワークフロー内部は純粋な関数で構成する」この原則は、第 2 章で述べた「状態は例外的」という考え方と直結します。ワークフロー内部は「入力を受け取り、何かを行い、出力を返す」純粋な関数だけで構成されます。データベースアクセスやファイル I/O は、ワークフローの開始時か終了時にのみ行います。この構造により、ドメインロジックはテスト容易で予測可能になります。少なくとも、理論上は。4. Understanding Types本章から、コード例が本格的に登場します。第 2 章で整理した F#と Rust の対応関係に基づき、以降は Rust のみで実装を示します。型とは「可能な値の集合」である著者の「型」の定義はシンプルです。「関数の入力や出力として使える値の集合に付けた名前」。i16 は-32768 から+32767 までの数値の集合、String は全ての文字列の集合です。この定義を読んで、自分がいかに型を「コンパイラを満足させるためのもの」として捉えていたか気づかされました。型は思考のツールです。ANDとORによる型の合成—代数的データ型本章の核心は、型の合成方法です。著者は 2 つの方法を示します。これらは「代数的データ型（Algebraic Data Types）」と呼ばれ、関数型プログラミングの基礎概念です。F#では「レコード型」と「判別共用体」、Rust では struct と enum で表現できます。AND型（struct / 積型）: 複数の値を組み合わせます。struct FruitSalad {    apple: AppleVariety,    banana: BananaVariety,    cherries: CherryVariety,}FruitSalad を作るには、apple と banana と cherries の全てが必要です。OR型（enum / 和型）: 複数の選択肢から 1 つを選びます。enum FruitSnack {    Apple(AppleVariety),    Banana(BananaVariety),    Cherries(CherryVariety),}FruitSnack は、Apple か Banana か Cherries のいずれか 1 つです。たった 2 つの概念で複雑なドメインを表現できます。AND と OR という論理演算で型を組み立てます。Simple Types—newtype patternの威力本章で一番「これが使える」と思ったのは、Simple Types の話です。プリミティブ型をそのまま使うのは危険です。CustomerId も OrderId も i32 だとしたら、間違って OrderId を CustomerId として渡してもコンパイルが通ってしまいます。Rust では、newtype patternでこの問題を解決します。newtype pattern とは、既存の型を新しい型でラップすることで、型レベルで区別をつけるイディオムです。F#では「単一ケース判別共用体」、Rust では「タプル構造体」で表現します。zenn.dev#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]struct CustomerId(i32);#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]struct OrderId(i32);#[derive(...)] について説明します。これは Rust の「属性マクロ」で、型に機能を自動で追加する仕組みです。詳しくは公式ドキュメントを参照してください。doc.rust-lang.org「トレイト」とは、型が持つべき「能力」や「振る舞い」の定義です。例えば「比較できる」「コピーできる」「文字列として表示できる」といった能力がトレイトとして定義されています。#[derive(Debug, Clone)] と書くと、その型に Debug と Clone という能力が自動的に追加されます。手で書くと何十行にもなるコードを、一行で済ませられます。よく使うトレイトを整理しておきます。 トレイト  意味  使いどころ  Debug  中身を表示できる  println!("{:?}", x) でデバッグ出力  Clone  複製を作れる  .clone() で明示的にコピー  Copy  自動で複製される  代入や関数呼び出しで自動コピー（小さな値向け）  PartialEq  比較できる  == で等しいか判定  Eq  反射律を満たす比較  HashMapのキーに使うとき必要  Hash  ハッシュ値を計算できる  HashMapのキーに使うとき必要 内部的には同じ i32 ですが、型システム上は別の型です。CustomerId を期待する関数に OrderId を渡すとコンパイルエラーになります。ここで重要なのは、Clippy のような静的解析ツールでもこの種のバグは検出できないということです。Clippy は Rust の公式リンター（コード品質チェックツール）で、700 以上の lint ルールを持ちます。cargo clippy コマンドで実行でき、コードの問題点を警告してくれます。rust-lang.github.ioしかし、Clippy にも限界があります。// Clippyでは検出できないfn process(customer_id: i32, order_id: i32) { /* ... */ }process(order_id, customer_id); // バグ！でもコンパイルは通る// 型で防ぐfn process(customer_id: CustomerId, order_id: OrderId) { /* ... */ }// process(order_id, customer_id); // コンパイルエラー！Clippy は構文的な問題—if x { "a" } else { "a" } のような両方のブランチが同じ処理、u32 >= 0 のような常に true になる比較—は検出できます。しかし、「この i32 は顧客 ID を表し、あの i32 は注文 ID を表す」というドメインの知識は持っていません。newtype pattern は、Clippy が検出できないバグを型システムで防ぎます。AI コーディングエージェントも同様です。「customer_id と order_id を間違えないように」という指示は、自然言語では曖昧です。しかし CustomerId と OrderId という別の型が定義されていれば、AI が生成したコードでも型の取り違えはコンパイル時に検出されます。Option型とResult型F#と Rust は、欠損値を Option で、エラーを Result で表現します。これらは関数型プログラミングにおける標準的なエラーハンドリング手法で、null や例外を使わずに「値がないかもしれない」「失敗するかもしれない」ことを型で表現します。struct PersonalName {    first_name: String,    middle_initial: Option<String>,  // 省略可能    last_name: String,}Option<T> は Some(T) か None のいずれかです。null を使わずに「値がないかもしれない」ことを型で表現します。エラーハンドリングには Result<T, E> を使います。? 演算子で、エラー時に早期リターンできます。型によるドメイン表現本章で紹介されている支払い方法のモデリング例は、型がドキュメントとして機能することを示しています。enum PaymentMethod {    Cash,    Check(CheckNumber),    Card(CreditCardInfo),}struct Payment {    amount: PaymentAmount,    currency: Currency,    method: PaymentMethod,}約 25 行で、支払いドメインの構造が明確に表現されています。このコードは、ドメインエキスパートにも読めます。型システムは思考のツールである本章を通じて感じたのは、型システムは「コンパイラのため」ではなく「思考のため」にあるということです。「動的型付け言語でも同じことができるのでは？」という疑問があるかもしれません。確かに、Python や Ruby でもドメインモデリングはできます。しかし、型がないと「どんな値が入りうるか」を頭の中で追跡し続けなければなりません。静的型付けでは、その追跡をコンパイラに委ねられます。AND 型と OR 型という単純な組み合わせで、複雑なドメインを表現できます。型定義という明確な仕様があれば、実装時の迷いが減ります。型システムは、ドメインの構造を可視化するツールです。5. Domain Modeling with Types本章では、前章で学んだ型システムの概念を使って、実際にドメインモデルを構築します。コードがドキュメントになる第 5 章の冒頭で、著者は挑戦的な問いを投げかけます。「ソースコードを直接ドキュメントとして使い、UML 図のような別の成果物を不要にできるか？」正直、最初は懐疑的でした。しかし本章を読み進めるうちに、著者の意図が分かってきました。擬似コードからRustへ第 2 章で作成した擬似コードを、Rust の型に変換します。data Order =    CustomerInfo    AND ShippingAddress    AND BillingAddress    AND list of OrderLines    AND AmountToBillこれが Rust では以下のようになります。pub struct Order {    pub id: OrderId,    pub customer_id: CustomerId,    pub shipping_address: ShippingAddress,    pub billing_address: BillingAddress,    pub order_lines: Vec<OrderLine>,    pub amount_to_bill: BillingAmount,}ほぼ一対一の変換です。擬似コードと Rust コードを並べて見ると、ドメインの構造がそのまま型に反映されていることが分かります。Value ObjectとEntityDDD では、オブジェクトを「Value Object」と「Entity」に分類します。Value Object: 同じ値を持てば同一とみなします。#[derive(Debug, Clone, PartialEq, Eq)]pub struct PersonalName {    pub first_name: String,    pub middle_initial: Option<String>,    pub last_name: String,}Entity: 固有の ID を持ち、内容が変わっても同一性を保ちます。impl PartialEq for Contact {    fn eq(&self, other: &Self) -> bool {        self.contact_id == other.contact_id  // IDのみで比較    }}Aggregate—一貫性の境界本章で最も重要な概念は「Aggregate」です。Order と OrderLine の関係を考えます。OrderLine の価格を変更したとき、Order の合計金額も更新します。両者は常に一貫した状態を保ちます。DDD では、こうした関連オブジェクトの集合を「Aggregate」と呼び、最上位のオブジェクトを「Aggregate Root」と呼びます。immutable なパターンでは、OrderLine を変更するには Order 全体を作り直します。これは一見非効率に見えますが、一貫性を強制する効果があります。OrderLine だけを変更して、Order の合計金額を更新し忘れる、というバグが起こりにくくなります。Aggregate参照—IDのみを保持するOrder に Customer 情報を含める場合、Customer オブジェクト全体ではなく、CustomerId だけを保持すべきです。pub struct Order {    pub id: OrderId,    pub customer_id: CustomerId,  // Customer全体ではなく、IDのみ    pub order_lines: Vec<OrderLine>,}この設計は、immutability と相性が良いです。Customer の電話番号が変わっても、Order を更新する必要がありません。型でドメインを表現する—最終形本章の最後に、完全なドメインモデルの例が示されます。#[derive(Debug, Clone, PartialEq, Eq)]pub enum ProductCode {    Widget(WidgetCode),    Gizmo(GizmoCode),}#[derive(Debug, Clone, Copy, PartialEq)]pub enum OrderQuantity {    Unit(UnitQuantity),    Kilos(KilogramQuantity),}このコードは、第 2 章の擬似コードとほぼ同じ構造を持ちます。struct、enum、match の意味さえ分かれば読めます。match については Rust 公式ドキュメントを参照してください。doc.rust-lang.orgString は沈黙します。EmailAddress は語ります。著者の主張—「型でドメインを表現すれば、コードがドキュメントになる」—は正しいと思います。6. Integrity and Consistency in the Domain本章は、ドメイン内のデータが常に「信頼できる状態」であることを保証する方法を解説します。Smart Constructor—制約を強制する本章で最も実用的だったのは、Smart Constructor（スマートコンストラクタ）のパターンです。Smart Constructor とは、値の生成時にバリデーションを行い、不正な値の生成を防ぐコンストラクタのことです。通常のコンストラクタと異なり、Result を返して生成の失敗を表現できます。例えば、UnitQuantity は 1 から 1000 の間の値でなければなりません。この制約をコメントで書くだけでは不十分です。#[derive(Debug, Clone, Copy, PartialEq, Eq)]pub struct UnitQuantity(i32);impl UnitQuantity {    pub fn new(value: i32) -> Result<Self, String> {        if value < 1 {            Err("UnitQuantity must be at least 1".to_string())        } else if value > 1000 {            Err("UnitQuantity must be at most 1000".to_string())        } else {            Ok(UnitQuantity(value))        }    }    pub fn value(&self) -> i32 {        self.0    }}フィールドを pub にしなければ、外部から直接 UnitQuantity(500) と書けません。必ず UnitQuantity::new(500) を経由します。NonEmptyList—空のリストを許さない「注文には少なくとも 1 つの注文行がなければならない」という要件を、型で強制できるでしょうか。#[derive(Debug, Clone, PartialEq)]pub struct NonEmptyList<T> {    pub first: T,    pub rest: Vec<T>,}from_vec は Option を返します。空のベクターからは NonEmptyList を作れません。この「作れない」という事実が型で表現されています。Make Illegal States Unrepresentable本章で最も重要な原則は「不正な状態を表現不可能にする」です。メールアドレスの例が分かりやすいです。「検証済み」と「未検証」のメールアドレスがあるとき、フラグで区別する設計は危険です。詳しくは Rust 公式ドキュメントの enum 解説を参照してください。doc.rust-lang.org// 良い例：別の型として定義pub struct VerifiedEmailAddress(String);pub enum CustomerEmail {    Unverified(EmailAddress),    Verified(VerifiedEmailAddress),}VerifiedEmailAddress のコンストラクタを private にして、検証サービスからしか作れないようにします。これで、検証を経ずに Verified 状態を作ることが物理的に不可能になります。fn send_password_reset(email: VerifiedEmailAddress) -> Result<(), SendError> {    // この関数にEmailAddressを渡すとコンパイルエラー}連絡先情報の例—OR型の活用「顧客にはメールアドレスか住所のどちらか、または両方が必要」という要件を型で表現します。pub enum ContactInfo {    EmailOnly(EmailContactInfo),    AddressOnly(PostalContactInfo),    EmailAndAddress(BothContactMethods),}3 つのケースしかありません。「メールも住所もない」という状態は表現できません。「不可能を作る」という設計思想本章の核心は「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」です。この原則を言い換えれば、型で「不可能」を作るということになります。この原則を読んだとき、過去に遭遇したバグが走馬灯のように思い出されました。is_active = true なのに deleted_at が設定されている。status = "paid" なのに payment_id が null。フラグと Option の組み合わせ爆発で、「あり得ない」状態が本番データベースに存在していた。深夜に呼び出されて、整合性を手作業で修正した夜のことを、今でも覚えています。あのバグは、型で防げたのです。似たような経験をしたことがある人は、少なくないのではないでしょうか。NonEmptyList を使えば、空の注文は作れないVerifiedEmailAddress を使えば、未検証メールへのパスワードリセットは書けないSmart Constructor を使えば、範囲外の値は存在できない「できない」「書けない」「存在できない」—これらは制限ではなく、設計上の保証です。バリデーションは「お願い」。型は「物理法則」。Clippy のような静的解析ツールでも、ドメインロジックの問題は検出できません。例えば、is_priced: bool と amount: Option<f64> を持つ構造体を考えます。is_priced = true なのに amount = None という矛盾した状態は、Clippy には「正しい Rust コード」に見えます。ビジネスルールを知らないからです。しかし、PricedOrder { amount: Money } と UnpricedOrder を別の型として定義すれば、この矛盾は表現できなくなります。Clippy が検出できない問題を、型システムが防ぎます。AI エージェント時代において、この「不可能を作る」設計思想の価値は高まっています。AI は自然言語のドキュメントを読み飛ばすことがあります。しかし、型で「不可能」が定義されていれば、AI はその制約を破るコードを物理的に書けません。7. Modeling Workflows as Pipelines本章は、ワークフローをパイプラインとしてモデリングする方法を解説します。ビジネスプロセスを「変換の連鎖」として捉えるアプローチです。ワークフローはパイプラインである本章の冒頭で、著者は注文処理ワークフローを次のように要約しています。workflow "Place Order" =    input: UnvalidatedOrder    output: OrderPlaced AND BillableOrderPlaced AND OrderAcknowledgmentSent    // step 1: ValidateOrder    // step 2: PriceOrder    // step 3: AcknowledgeOrder    // step 4: create and return events各ステップは「入力を受け取り、変換し、出力を返す」関数です。これらを連結するとパイプラインになります。第 2 章で述べた「状態は例外的、ほとんどの処理は状態なしで書ける」という原則が、ここで具現化されます。ワークフロー全体を見ると「状態遷移」に見えますが、各ステップを見ると「入力を受け取り、何かを行い、出力を返す」純粋な関数でしかありません。状態マシンとしてのOrderOrder を単一の型として設計すると、フラグだらけになります。// 悪い設計struct Order {    order_id: OrderId,    is_validated: bool,    is_priced: bool,    amount_to_bill: Option<Decimal>,  // pricedの時だけ存在}本書のアプローチは、各状態を別の型として定義することです。pub struct UnvalidatedOrder { /* ... */ }pub struct ValidatedOrder { /* ... */ }pub struct PricedOrder {    // ...    pub amount_to_bill: BillingAmount,  // この状態でのみ存在}PricedOrder には amount_to_bill があります。ValidatedOrder にはありません。フラグは不要で、「どの型か」が状態を表します。AI にコードを書かせるとき、この設計は強力なガードレールになります。「検証をスキップして価格計算に進んでください」と指示しても、price() 関数が ValidatedOrder を要求する以上、AI は UnvalidatedOrder を渡すコードを書けません。型が不正な状態遷移を物理的に阻止します。依存性を型で表現する各ステップの依存性を型シグネチャで表現します。type CheckProductCodeExists = fn(&ProductCode) -> bool;type CheckAddressExists = fn(&UnvalidatedAddress) -> Result<CheckedAddress, AddressValidationError>;type ValidateOrder = fn(    CheckProductCodeExists,     // 依存性1    CheckAddressExists,         // 依存性2    UnvalidatedOrder,           // 入力) -> Result<ValidatedOrder, ValidationError>;依存性が関数の引数として明示されます。インターフェース全体ではなく、必要な関数だけを渡します。最小限の依存性です。エフェクトの文書化関数の「エフェクト（効果）」を型で文書化します。Result: エラーを返す可能性があるAsync: 非同期 I/O を行うOption: 値が存在しない可能性があるasync fn check_address_exists(    address: &UnvalidatedAddress,) -> Result<CheckedAddress, AddressValidationError> {    // 外部サービスへのHTTPリクエスト}関数シグネチャを見れば、「この関数は非同期で、エラーを返す可能性がある」と分かります。Transformation-Oriented Programmingの実践具体的な例で考えます。オブジェクト指向的に書くと、こうなります。impl Order {    fn validate(&mut self, checker: &ProductChecker) -> Result<(), ValidationError> {        // 状態を変更        self.is_validated = true;        self.validated_at = Some(now());        Ok(())    }}関数型で書き直すと、こうなります。fn validate(    order: UnvalidatedOrder,    checker: &ProductChecker,) -> Result<ValidatedOrder, ValidationError> {    // 新しい値を作る（元のorderは変更しない）    Ok(ValidatedOrder {        order_id: OrderId::new(order.order_id)?,        customer_info: validate_customer(order.customer_info)?,        lines: validated_lines,    })}違いは何でしょうか。コンパイル時チェック: price() に UnvalidatedOrder を渡すとコンパイルエラー状態の整合性が型で保証: ValidatedOrder には is_validated フラグがそもそも存在しないテストが独立: validate() と price() を別々にテストできるこの単純さが強力なのだUnvalidatedOrder を ValidatedOrder に変換します。ValidatedOrder を PricedOrder に変換します。元のオブジェクトは触りません。新しいオブジェクトを作ります。それだけです。状態の変更を追跡する必要がない（変更しないから）並行処理でも競合しない（元のデータを変更しないから）テストが簡単（入力と出力を比較するだけ）デバッグが楽（各ステップの入出力をログに残せば、全経路が追える）関数型プログラミングの入門書を読むと、モナドだの圏論だの、難しい概念が出てきます。しかし、実務で最も重要なのは、本書が示すTransformation-Oriented Programmingです。核心は 3 つです。状態を型で表現する（UnvalidatedOrder と ValidatedOrder は別の型）状態遷移を関数で表現する（validate(order) -> ValidatedOrder）元のオブジェクトを変更しない（新しい値を作るだけ）変えるな。作れ。この章を読み終えたとき、「これなら実務で使える」と確信しました。モナドや圏論を理解する必要はありません。「状態ごとに型を分ける」「元のオブジェクトを変更しない」。この 2 つだけで、設計の質は劇的に変わります。難しい理論ではなく、明日から使える実践知。本書の価値はここにあります。8. Understanding Functions本章は、関数型プログラミングの基礎を解説します。実装に入る前の準備として、関数の扱い方を整理しています。関数型プログラミングとは著者の定義はシンプルです。「関数型プログラミングとは、関数が本当に重要なものとしてプログラミングすること」。オブジェクト指向では、オブジェクトがあらゆる場所で使われます。関数型では、関数があらゆる場所で使われます。依存性を注入するときは関数を渡します。コードを再利用するときは関数を合成します。関数は「モノ」である関数型プログラミングの核心は、関数が第一級の値であることです。変数に代入できます。リストに入れられます。引数として渡せます。戻り値として返せます。let add1 = |x: i32| x + 1;let square = |x: i32| x * x;let functions: Vec<fn(i32) -> i32> = vec![add1, square];for f in &functions {    println!("{}", f(5));}関数をリストに入れて、ループで回しています。高階関数関数を引数に取る関数、または関数を返す関数を「高階関数」と呼びます。fn eval_with_5_then_add_2<F>(f: F) -> i32where    F: Fn(i32) -> i32,{    f(5) + 2}Rust では、関数を受け取る引数の型を Fn、FnMut、FnOnce トレイトで指定します。F#ではこの区別はありません。クロージャとはクロージャは「名前のない関数」です。通常の関数は fn name(...) と名前をつけて定義しますが、クロージャは |引数| 式 という形式でその場で作れます。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orglet add1 = |x| x + 1;        // 引数xを受け取り、x + 1を返すlet result = add1(5);        // 6クロージャの特徴は、周囲の変数を「捕まえる」（キャプチャする）ことができる点です。let multiplier = 3;let multiply = |x| x * multiplier;  // multiplierを捕まえているlet result = multiply(5);           // 15Fnトレイトの使い分け関数を引数として受け取るとき、Rust では 3 種類のトレイトを使い分けます。これは「捕まえた変数をどう扱うか」で決まります。 トレイト  捕まえ方  呼び出し回数  Fn  読み取るだけ  何度でも  FnMut  変更する  何度でも  FnOnce  消費する（使い切る）  一度だけ 最初は気にしすぎなくてよいです。コンパイラがエラーで教えてくれます。カリー化と部分適用F#では、すべての関数が自動的に「カリー化」されます。Rust にはカリー化が組み込まれていません。同じことを実現するには、明示的にクロージャを返します。fn adder_generator(number_to_add: i32) -> impl Fn(i32) -> i32 {    move |x| number_to_add + x}let add5 = adder_generator(5);let result = add5(3);  // 8部分適用は、依存性注入に活用できます。let validate = |order| validate_order(    check_product_code_exists,    check_address_exists,    order,);let result = validate(unvalidated_order);Total Functions（全域関数）数学の関数は、すべての入力に対して出力が定義されます。12 を引数で割る関数を考えます。n = 0 のとき、何を返すべきでしょうか。解決策は 2 つあります。入力を制限するか、出力を拡張するかです。// 入力を制限fn twelve_divided_by(n: NonZeroI32) -> i32 {    12 / n.0}// 出力を拡張fn twelve_divided_by(n: i32) -> Option<i32> {    if n == 0 { None } else { Some(12 / n) }}どちらの場合も、型シグネチャが正直になります。型シグネチャは嘘をつきません。コメントは嘘をつきます。AI にコードを書かせるとき、この「正直な型シグネチャ」は重要です。AI は型シグネチャを見て、関数の契約を理解します。Option<i32> を返す関数なら、AI は None のケースを考慮したコードを生成します。しかし「0 を渡したら None を返します」というコメントは、読み飛ばされる可能性があります。関数合成F#にはパイプライン演算子 |> があります。Rust にはありません。代わりにメソッドチェーンや、関数を直接呼び出します。let result: Vec<_> = (1..10)    .map(|x| x + 1)    .map(|x| x * x)    .collect();イテレータのアダプタは、パイプラインに近い書き方ができます。Rustで関数型プログラミングを実践するために本章を読んで、F#と Rust の違いを改めて認識しました。カリー化: F#は自動、Rust は手動パイプライン演算子: F#にはある、Rust にはないクロージャの所有権: F#は考慮不要、Rust は move や Fn/FnMut/FnOnce を意識これらの違いはありますが、関数型プログラミングの本質—関数を組み合わせてシステムを構築する—は Rust でも実践できます(が本当に最適か？という問いは投げないでくれ…本稿のアプローチと違いすぎる)。9. Implementation: Composing a Pipeline本章から、いよいよ実装に入ります。これまで型で設計してきたワークフローを、実際のコードに落とし込みます。パイプラインの理想形著者が示す理想のコードは驚くほどシンプルです。let placeOrder unvalidatedOrder =    unvalidatedOrder    |> validateOrder    |> priceOrder    |> acknowledgeOrder    |> createEvents4 行で注文処理全体が表現されています。これが関数型アプローチの目指す姿です。しかし現実には、関数の出力と次の関数の入力が一致しません。依存性をどこかで解決しなければなりません。本章はその「ギャップ」を埋める方法を解説します。型シグネチャによる実装のガイド本章で印象的だったのは、「型シグネチャを先に定義し、それに従って実装する」というアプローチです。type ValidateOrder = fn(    check_product_code: fn(&ProductCode) -> bool,    check_address: fn(&UnvalidatedAddress) -> CheckedAddress,    order: UnvalidatedOrder,) -> ValidatedOrder;型シグネチャが「契約」として機能します。引数の型、戻り値の型が全て決まっているので、実装者は「この契約を満たすコードを書く」だけでよいです。依存性注入の関数型アプローチオブジェクト指向では、インターフェースを定義し、コンストラクタで注入します。関数型では、依存性を関数の引数として渡します。DI コンテナ？関数を渡せ。fn validate_order(    check_product_code: impl Fn(&ProductCode) -> bool,    check_address: impl Fn(&UnvalidatedAddress) -> CheckedAddress,    order: UnvalidatedOrder,) -> ValidatedOrder {    // check_product_code を使う}インターフェース全体ではなく、必要な関数だけを渡します。ワークフロー全体の組み立て各ステップを組み立ててワークフロー全体を作ります。pub fn place_order(    // 依存性    check_product_code_exists: impl Fn(&ProductCode) -> bool,    check_address_exists: impl Fn(&UnvalidatedAddress) -> CheckedAddress,    get_product_price: impl Fn(&ProductCode) -> Price,    // 入力    unvalidated_order: UnvalidatedOrder,) -> Vec<PlaceOrderEvent> {    let validated = validate_order(        &check_product_code_exists,        &check_address_exists,        unvalidated_order,    );    let priced = price_order(&get_product_price, validated);    let acknowledgment = acknowledge_order(&priced);    create_events(&priced, acknowledgment)}F#のパイプライン演算子 |> がないので、変数に束縛しながら連鎖させます。本章では Result を使わず簡略化しており、次章で Result を導入します。10. Implementation: Working with Errors本章は、エラーハンドリングの関数型アプローチを解説します。「Railway Oriented Programming」と呼ばれるパターンを学びます。エラーの三分類著者はエラーを 3 つに分類します。Domain Errors: ビジネスプロセスの一部として予期されるエラー。商品コードが無効、注文が請求で拒否される、など。Panics: システムを未知の状態にするエラー。メモリ不足、ゼロ除算など。Infrastructure Errors: ネットワークタイムアウト、認証失敗など。この分類は実務でも有用です。「このエラーはドメインエキスパートに相談すべきか」という問いに答えられます。ドメインエラーを型で表現する#[derive(Debug, Clone)]pub enum PlaceOrderError {    ValidationError(String),    ProductOutOfStock(ProductCode),    RemoteServiceError(RemoteServiceError),}エラーを enum で定義することで、どんなエラーが起こりうるか、型定義を見れば分かります。Railway Oriented Programming著者が提唱する解決策が「Railway Oriented Programming（鉄道指向プログラミング）」です。著者自身による詳細な解説は以下を参照してください。fsharpforfunandprofit.comResult を返す関数は「分岐するレール」として可視化できます。成功すれば上のレールに、失敗すれば下のレールに進みます。一度失敗パスに入ると、残りのステップはバイパスされます。      [validateOrder] → [priceOrder] → [acknowledgeOrder] → 成功           ↓               ↓               ↓      ─────────────────────────────────────────────────────→ 失敗Rustでの実装Rust では ? 演算子が同じことをより簡潔に表現します。fn validate_order(order: UnvalidatedOrder) -> Result<ValidatedOrder, ValidationError> {    let order_id = OrderId::create(&order.order_id)?;    let customer_info = to_customer_info(&order.customer_info)?;    let shipping_address = check_address(&order.shipping_address)?;    Ok(ValidatedOrder { order_id, customer_info, shipping_address, ... })}? 演算子は、Ok ならアンラップし、Err なら早期リターンします。?演算子の仕組み? は「失敗したら即座に関数から抜ける」という処理を一文字で書ける記号です。詳しくは公式ドキュメントを参照してください。doc.rust-lang.orgResult は「成功（Ok）か失敗（Err）か」を表す型でした。? をつけると、成功なら中身を取り出し、失敗ならその場で関数を終了して呼び出し元にエラーを返します。// ?を使った書き方let order_id = OrderId::create(&order.order_id)?;// これは以下と同じ意味let order_id = match OrderId::create(&order.order_id) {    Ok(v) => v,              // 成功したら中身を取り出す    Err(e) => return Err(e), // 失敗したら即座にエラーを返す};? を使うには、関数の戻り値が Result である必要があります。エラー型の変換複数のステップを連結するとき、エラー型を統一します。#[derive(Debug)]pub enum PlaceOrderError {    Validation(ValidationError),    Pricing(PricingError),}impl From<ValidationError> for PlaceOrderError {    fn from(e: ValidationError) -> Self {        PlaceOrderError::Validation(e)    }}Fromトレイトによる型変換From は「ある型から別の型への変換方法」を定義するトレイトです。例えば「ValidationError を PlaceOrderError に変換する方法」を定義しておくと、? 演算子が自動的にエラー型を変換してくれます。// 「ValidationErrorからPlaceOrderErrorへの変換方法」を定義impl From<ValidationError> for PlaceOrderError {    fn from(e: ValidationError) -> Self {        PlaceOrderError::Validation(e)    }}これを定義しておくと、validate_order が ValidationError を返しても、? が自動的に PlaceOrderError に変換してくれます。異なるエラー型を返す関数を連結できるようになります。11. Serialization本章は、ドメインオブジェクトを JSON や XML などの形式に変換する方法を解説します。Bounded Context の境界を越えるとき、内部のドメイン型をそのまま使うことはできません。また、AI時代にはこのようなことも想定されます。zenn.dev永続化とシリアライゼーションの区別著者は 2 つの概念を区別します。Persistence（永続化）: プロセスの終了後も状態が残ること。Serialization（シリアライゼーション）: ドメイン固有の表現を、永続化可能な表現に変換すること。本章はシリアライゼーションに焦点を当て、次章で永続化を扱います。DTOによる変換—ドメインの境界防御ドメイン型は複雑です。ネストした型、制約付きの型、選択肢を持つ型。これらを直接シリアライズするのは難しいです。解決策は、Data Transfer Object（DTO）を中間層として使うことです。なぜDTOを使うのか？ドメイン型は制約を持つ: String50 は 50 文字以下という制約があります。JSON の "name" フィールドは任意の長さです。直接マッピングできません。内部実装の変更から外部を守る: ドメイン型のフィールド名を変えても、DTO が同じなら外部 API は影響を受けません。検証の境界を明確にする: 外部からの入力は「信頼できない」です。DTO からドメイン型への変換時に検証することで、ドメイン内は常に「信頼できる」状態を保ちます。DTO は「ドメインの境界防御」として機能します。Domain型 → DTO → JSON（シリアライズ）JSON → DTO → Domain型（デシリアライズ）Rust では、ドメイン型と DTO 型を別々に定義します。ドメイン型は制約を持ち、DTO はプリミティブ型のみを使います。/// 制約付きの文字列型（50文字以下）#[derive(Debug, Clone, PartialEq, Eq)]pub struct String50(String);impl String50 {    pub fn create(s: &str) -> Result<Self, ValidationError> {        if s.is_empty() {            Err(ValidationError::Empty("String50 cannot be empty".into()))        } else if s.len() > 50 {            Err(ValidationError::TooLong("String50 must be 50 chars or less".into()))        } else {            Ok(String50(s.to_string()))        }    }    pub fn value(&self) -> &str {        &self.0    }}/// ドメイン型（制約付き）#[derive(Debug, Clone, PartialEq, Eq)]pub struct Person {    pub first_name: String50,    pub last_name: String50,}/// DTO（シリアライズ用・プリミティブのみ）#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]pub struct PersonDto {    pub first_name: String,    pub last_name: String,}変換には From と TryFrom を使います。ドメイン型から DTO への変換は常に成功しますが、DTO からドメイン型への変換は失敗しうります。/// ドメイン型 → DTO（常に成功）impl From<&Person> for PersonDto {    fn from(person: &Person) -> Self {        PersonDto {            first_name: person.first_name.value().to_string(),            last_name: person.last_name.value().to_string(),        }    }}/// DTO → ドメイン型（失敗する可能性あり）impl TryFrom<PersonDto> for Person {    type Error = ValidationError;    fn try_from(dto: PersonDto) -> Result<Self, Self::Error> {        let first_name = String50::create(&dto.first_name)?;        let last_name = String50::create(&dto.last_name)?;        Ok(Person { first_name, last_name })    }}TryFrom を使うことで、変換が失敗する可能性を型で表現しています。これは「Parse, don't validate」の実践です。入力を単に「正しいかどうか」検証するのではなく、より型安全な形式に変換（パース）することで、型レベルで正しさを保証します。DTOは契約である著者が強調するのは、DTO は「Bounded Context 間の契約」だということです。他の Context が発行したイベントを受信するとき、そのフォーマットに依存します。フォーマットを変更すると、依存する Context に影響が及びます。だから、シリアライズのフォーマットは慎重に設計すべきです。serde の #[derive(Serialize)] を安易に使うと、内部実装の変更が契約の破壊につながります。選択肢型（enum）のシリアライズOR 型（enum）のシリアライズは注意が必要です。JSON には enum の概念がありません。Rust では serde の属性でタグ付け方式を指定します。serde については公式ドキュメントを参照してください。serde.rs/// 支払い方法のDTO - タグ付きenum#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]#[serde(tag = "type")]pub enum PaymentMethodDto {    Cash,    Check { check_number: String },    Card { card_number: String, expiry: String },}#[serde(tag = "type")] を指定すると、以下のような JSON が生成されます。{"type":"Cash"}{"type":"Check","check_number":"12345"}{"type":"Card","card_number":"4111...","expiry":"12/25"}タグ付きの方が明示的で、新しいケースを追加しやすいです。ラウンドトリップの検証シリアライズとデシリアライズは対になります。ラウンドトリップ（往復）テストで、データが失われないことを確認します。pub fn serialize_order(order: &Order) -> Result<String, serde_json::Error> {    let dto = OrderDto::from(order);    serde_json::to_string_pretty(&dto)}pub fn deserialize_order(json: &str) -> Result<Order, String> {    let dto: OrderDto = serde_json::from_str(json).map_err(|e| e.to_string())?;    Order::try_from(dto).map_err(|e| format!("{:?}", e))}本章と中心テーマのつながりDTO パターンは、本書のTransformation-Oriented Programmingと関連します。外部からの入力（JSON）は「未検証の値」です。DTO からドメイン型への変換は、UnvalidatedOrder から ValidatedOrder への変換と同じパターンです。信頼できない入力を、信頼できるドメイン型に「変換」します。外部を信頼するな。まず変換せよ。DTO は、外部世界とドメインの境界を守る防壁です。12. Persistence本章は、ドメインモデルをデータベースに永続化する方法を解説します。DDD の原則に従いながら、現実のインフラと向き合います。永続化の原則本章の冒頭で、著者は 3 つの原則を示します。永続化を端に押し出す（Push persistence to the edges）: ワークフローの内部では I/O を行わないコマンドとクエリを分離する（CQRS）: 更新操作と読み取り操作を分けるBounded Contextは自分のデータストアを所有する: 他の Context のデータベースに直接アクセスしないこれらの原則は、「状態は例外的」という関数型の考え方と合致します。永続化を端に押し出す著者は、「ドメインロジックと I/O が混在したコード」と「分離したコード」を対比しています。なぜI/Oを境界に押し出すのか？テストが容易になる: 純粋なドメインロジックは、データベース接続なしでテストできます。入力を与えて出力を確認するだけです。推論が容易になる: 副作用がない関数は、同じ入力に対して常に同じ出力を返します。状態を追跡する必要がありません。並行処理が安全になる: 共有状態を変更しないため、競合が発生しません。変更に強くなる: データベースを変更しても、ドメインロジックは影響を受けません。逆も同様です。まず、ドメイン型を定義します。これらの型はデータベースのことを知りません。/// 未払いの請求書#[derive(Debug, Clone, PartialEq)]pub struct UnpaidInvoice {    pub invoice_id: InvoiceId,    pub amount_due: Money,}/// 支払い済みの請求書#[derive(Debug, Clone, PartialEq)]pub struct PaidInvoice {    pub invoice_id: InvoiceId,    pub amount_paid: Money,}/// 支払い処理の結果#[derive(Debug, Clone, PartialEq)]pub enum InvoicePaymentResult {    FullyPaid(PaidInvoice),    PartiallyPaid(UnpaidInvoice),}次に、純粋なドメインロジックを定義します。この関数は I/O を行いません。/// 支払いを適用する - 純粋関数、I/Oなしpub fn apply_payment(invoice: UnpaidInvoice, payment: Payment) -> InvoicePaymentResult {    let remaining = invoice.amount_due.0 - payment.amount.0;    if remaining <= 0.0 {        InvoicePaymentResult::FullyPaid(PaidInvoice {            invoice_id: invoice.invoice_id,            amount_paid: Money(invoice.amount_due.0),        })    } else {        InvoicePaymentResult::PartiallyPaid(UnpaidInvoice {            invoice_id: invoice.invoice_id,            amount_due: Money(remaining),        })    }}最後に、コマンドハンドラで I/O を境界に押し出します。パターンは「Load → Pure Logic → Save」です。/// コマンドハンドラ - I/Oは境界で行うpub fn pay_invoice_handler<R: InvoiceRepository>(    repo: &R,    command: PayInvoiceCommand,) -> Result<InvoicePaymentResult, PayInvoiceError> {    // 1. Load（I/O - 開始時）    let invoice = repo        .load(&command.invoice_id)        .ok_or(PayInvoiceError::InvoiceNotFound(command.invoice_id))?;    // 2. 純粋なドメインロジック（I/Oなし）    let result = apply_payment(invoice, command.payment);    // 3. Save（I/O - 終了時）    match &result {        InvoicePaymentResult::FullyPaid(paid) => repo.save_paid(paid),        InvoicePaymentResult::PartiallyPaid(unpaid) => repo.save_unpaid(unpaid),    }    Ok(result)}RepositoryパターンRust では Trait を使って Repository を抽象化します。これにより、テスト時にモックを注入できます。なぜTraitで抽象化するのか？テスト容易性: 本番では PostgreSQL、テストではインメモリ実装を注入できます。実装の交換可能性: データベースを変更しても、ドメインロジックは影響を受けません。依存性の逆転: ドメインが永続化の詳細に依存しません。依存の方向が逆になります。トレイトとはトレイトは「この型は〇〇ができる」という能力の定義です。例えば「データを読み込める」「データを保存できる」という能力を定義します。詳しくは公式ドキュメントを参照してください。doc.rust-lang.org/// Repositoryトレイト - 永続化操作を抽象化pub trait InvoiceRepository {    fn load(&self, id: &InvoiceId) -> Option<UnpaidInvoice>;    fn save_unpaid(&self, invoice: &UnpaidInvoice);    fn save_paid(&self, invoice: &PaidInvoice);}trait で能力を定義し、impl Trait for Type で「この型はこの能力を持つ」と宣言します。ジェネリクスとはジェネリクスは「型を後で決める」仕組みです。<R: InvoiceRepository> は「InvoiceRepository という能力を持つ何かの型 R」という意味です。// Rは「InvoiceRepositoryという能力を持つ何か」fn pay_invoice_handler<R: InvoiceRepository>(repo: &R, ...) { ... }これで同じ関数を、異なる実装で使い回せます。// 本番ではPostgreSQLを使うpay_invoice_handler(&postgres_repo, command);// テストではメモリ上の仮実装を使うpay_invoice_handler(&in_memory_repo, command);テスト用のインメモリ実装を作れば、実際のデータベースなしでドメインロジックをテストできます。Persistence Ignorance（永続化の無知）第 2 章で「データベース駆動設計と戦う」と述べたことの実践がここにあります。ドメインモデルは、自分がどこに保存されるか知りません。知る必要もありません。Order 型はデータベースのことを知りません。永続化の詳細は、ワークフローの「端」で処理されます。この設計により、ドメインロジックの変更が永続化コードに影響しません。逆に、データベースを変更してもドメインロジックは変わりません。NoSQLとRDBの選択本章では、NoSQL（ドキュメント DB）と RDB（リレーショナル DB）の両方のアプローチを解説しています。NoSQL: Aggregate をそのままドキュメントとして保存できます。DDD との相性が良いです。RDB: OR 型（enum）のマッピングが難しいです。インピーダンスミスマッチ（オブジェクトモデルとリレーショナルモデルの構造的な不一致）が発生します。-- OR型のRDBへのマッピング（判別カラム）CREATE TABLE order_lines (    quantity_type VARCHAR(10),  -- 'Unit' or 'Kilos'    unit_quantity INT NULL,    kilogram_quantity DECIMAL NULL);どちらも完璧ではありません。「永続化は境界で行う」という原則を守ることで、純粋なドメインロジックと不純な I/O 処理を分離しやすくなります。13. Evolving a Design and Keeping It Clean本章は、本書の締めくくりとして、設計の進化と保守性について解説します。要件は変わります。ドメインモデルも変わります。その変化にどう対応するでしょうか。変化への対応著者は、DDD は「一度きりの静的なプロセス」ではないと強調します。要件が変われば、まずドメインモデルを見直します。実装をパッチするのではなく、モデルから考え直します。変更例: 配送料の追加配送料計算をワークフローに組み込むには、新しいステップを追加します。まず、新しい型を定義します。なぜ既存の型を変更せず、新しい型を作るのか？型の名前がドキュメントになる: PricedOrderWithShipping という名前だけで、「価格計算済みで配送情報も持つ注文」だと分かります。段階を明示できる: PricedOrder と PricedOrderWithShipping は別の段階だと型で表現できます。コンパイラが変更を追跡する: 型が変わると、関連する箇所すべてでコンパイルエラーが発生します。見落としがありません。/// 配送方法#[derive(Debug, Clone, PartialEq, Eq)]pub enum ShippingMethod {    Standard,    Express,    Overnight,}/// 配送情報#[derive(Debug, Clone, PartialEq)]pub struct ShippingInfo {    pub method: ShippingMethod,    pub cost: Money,}/// 配送情報付きの価格計算済み注文 - 新しい型#[derive(Debug, Clone, PartialEq)]pub struct PricedOrderWithShipping {    pub order_id: OrderId,    pub items: Vec<PricedOrderLine>,    pub amount_to_bill: Money,    pub shipping_info: ShippingInfo,}次に、新しいパイプラインステップを定義します。/// 新しいパイプラインステップ: 配送情報を追加pub fn add_shipping_info(order: PricedOrder) -> PricedOrderWithShipping {    // シンプルなロジック: $100以上は送料無料    let shipping = if order.amount_to_bill.0 > 100.0 {        ShippingInfo {            method: ShippingMethod::Standard,            cost: Money(0.0),        }    } else {        ShippingInfo {            method: ShippingMethod::Standard,            cost: Money(5.99),        }    };    PricedOrderWithShipping {        order_id: order.order_id,        items: order.items,        amount_to_bill: order.amount_to_bill,        shipping_info: shipping,    }}既存のコードを変更するのではなく、新しいステップを挿入します。validateOrder → priceOrder → addShippingInfo → acknowledgeOrder → createEventsこの「ステップの追加」というアプローチは、多くの機能追加に応用できます。ロギング、パフォーマンスメトリクス、認可チェック、監査。各ステップが独立していて、型が合っていれば、安全に追加・削除できます。VIP顧客の対応—入力をモデル化せよ著者は重要な指摘をしています。「ビジネスルールの出力（送料無料フラグ）ではなく、入力（VIP ステータス）をモデル化せよ」。なぜ「出力」ではなく「入力」をモデル化するのか？ルールが変わっても型は変わらない:「VIP は送料無料」→「VIP は送料 50%オフ」とルールが変わっても、CustomerStatus 型自体は変更不要です。関数だけ変えればよいです。原因をモデル化する:「送料無料かどうか」は結果（派生情報）です。原因は「VIP かどうか」です。原因をモデル化すれば、結果はいつでも計算できます。柔軟性が高い: VIP ステータスは送料以外にも使えます（優先サポート、限定商品へのアクセス等）。出力をハードコードすると、その柔軟性を失います。/// 顧客ステータス - ビジネスルールの「入力」をモデル化#[derive(Debug, Clone, PartialEq, Eq)]pub enum CustomerStatus {    Normal,    Vip,}/// 顧客#[derive(Debug, Clone, PartialEq, Eq)]pub struct Customer {    pub customer_id: String,    pub name: String,    pub status: CustomerStatus,}ビジネスルールは、入力（CustomerStatus）に基づいて決定を下します。/// 顧客ステータスに基づいて配送を計算pub fn calculate_shipping_for_customer(order: &OrderWithCustomer) -> ShippingInfo {    match order.customer.status {        CustomerStatus::Vip => ShippingInfo {            method: ShippingMethod::Express,            cost: Money(0.0), // VIPは無料のエクスプレス配送        },        CustomerStatus::Normal => {            if order.amount_to_bill.0 > 100.0 {                ShippingInfo {                    method: ShippingMethod::Standard,                    cost: Money(0.0),                }            } else {                ShippingInfo {                    method: ShippingMethod::Standard,                    cost: Money(5.99),                }            }        }    }}ビジネスルールが変わっても（例: VIP は送料無料→VIP は送料 50%オフ）、calculate_shipping_for_customer 関数を変更するだけでよいです。ドメインモデル自体（CustomerStatus）は変更する必要がありません。型の変更と波及効果本章の核心は、「型の変更がコンパイラによって追跡される」ことです。// 変更前pub struct PricedOrder { /* ... */ }// 変更後（配送情報を追加）pub struct PricedOrderWithShipping {    // ...    pub shipping_info: ShippingInfo,  // 新しいフィールド}PricedOrder と PricedOrderWithShipping は異なる型です。PricedOrder を期待していたコードに PricedOrderWithShipping を渡すとコンパイルエラーになります。// これはコンパイルエラー！fn process(order: PricedOrder) { /* ... */ }process(priced_order_with_shipping); // 型が違う動的型付け言語では、このような変更は「実行時エラー」として発見されます。静的型付けでは、「コンパイル時エラー」として発見されます。コンパイラがリファクタリングアシスタントとして機能します。関数型 DDD の核心は、「型でドメインを表現する」ことです。AND 型（struct）と OR 型（enum）でドメインの構造を表現します。状態遷移を別の型として定義します。制約を Smart Constructor で強制します。不正な状態を表現不可能にします。フラグを立てるな。型を作れ。これらの原則は、F#でも Rust でも適用できます。おわりに読む前の三つの悩みへの回答「はじめに」で述べた 3 つの読む動機に、本書がどう応えたかを振り返ります。1. DDDを学び直す必要があった → 関数型の視点でDDDが腹落ちしたDDD の概念—Aggregate、Entity、Value Object—は、オブジェクト指向の文脈で説明されると抽象的に感じていました。本書は、これらを「型」という具体的な道具で表現する方法を示しました。Value Object は単なる newtype です。struct OrderId(String) と書けば、それが Value Object です。Aggregate の境界は、型の境界で表現できます。ValidatedOrder と UnvalidatedOrder が別の型なら、それが境界です。「なぜそう設計するのか」を言語化できるようになりました。「この型を別にするのは、状態が違うから」「この値を newtype にするのは、ドメイン上の意味が違うから」。経験則ではなく、型システムに基づいた説明ができます。2. Rustでドメインモデリングを実践したかった → F#の概念はRustで十分(ではないかもしれないが)表現できるF#にあって Rust にない機能—パイプライン演算子、computation expressions、Units of Measure—は、確かにあります。しかし、本書の核心である「Make Illegal States Unrepresentable」は、Rust で十分に実践できたと思います。むしろ、Rust の所有権システムは F#にない利点を提供します。状態遷移を「所有権の移動」として表現できます。validate(order: UnvalidatedOrder) -> ValidatedOrder と書けば、検証前の注文は使えなくなります。F#では GC があるため、古い変数への参照が残る可能性がありますが、Rust では型システムがそれを防ぎます。3. AIエージェント時代における型システムの意味を考えたかった → 型は「AIが破れない制約」本書を読む前は、「型があると AI の生成精度が上がる」という感覚がありましたが、理論的に説明できませんでした。本書を読んで、その理由が明確になりました。型で定義された制約は、物理的に破れません。NonEmptyList<OrderLine> と定義すれば、AI は空の注文を返すコードを書けません。コンパイルが通らないからです。「このフィールドは必須です」というコメントは無視できますが、型は無視できません。これは「AI が守るべきルール」ではなく「AI が破れない壁」です。読む前と読んだ後Before（読む前）DDD の設計はある種の経験則で判断していましたRust の Option/Result は便利ですが、関数型との繋がりを考えていませんでした型があると AI の精度が上がる「気がする」程度の理解でしたAfter（読んだ後）DDD の概念を型システムの言葉で説明できるようになりましたTransformation-Oriented Programming（元のオブジェクトを変更せず、新しい値を作る）という原則を内在化しました型を「人間のためのドキュメント」かつ「AI が破れない制約」として設計できるようになりましたTransformation-Oriented Programming関数型プログラミングを学んで獲得する最も重要な概念は、実はシンプルです。状態は例外的な存在であり、ほとんどの処理は状態を使うことなく記述できる。本書を読み終えて、この一文の重みを改めて感じています。私たちはプログラミングを学ぶとき、まず「変数に値を代入する」ことから始めます。x = 1。x = x + 1。状態を変更することが、プログラミングの基本だと教わります。しかし、よく考えてみると、ビジネスロジックの大半は「入力を受け取り、変換し、出力を返す」で書けます。注文明細から合計金額を計算する → 入力と出力だけ住所をパースする → 入力と出力だけ商品コードを検証する → 入力と出力だけ状態の変更は不要です。副作用も不要です。ほとんどのビジネスロジックは、数学の関数のように書けます。では、状態が必要になるのはいつでしょうか。データベースに保存するとき。外部 API を呼ぶとき。ファイルに書き込むとき。つまり、システムの境界を越えるときだけです。この気づきが、設計の発想を変えます。状態を「デフォルト」ではなく「例外」として扱います。しかし状態遷移は避けられないビジネスの世界は状態遷移で満ちています。注文は「未検証」から「検証済み」になります。カートは「空」から「商品あり」になります。申請は「提出済み」から「承認済み」になります。これは無視できません。問題は、この状態遷移をどう表現するかです。オブジェクト指向の答えは「オブジェクトが状態を持ち、メソッドが状態を変更する」でした。order.validate() を呼ぶと、order の内部状態が変わります。この設計は、状態の追跡を難しくします。order は今どの状態なのか。どの経路を通ってここに至ったのか。フラグの組み合わせは正しいのか。常に頭の中で管理し続けなければなりません。本書が示す答えは、Transformation-Oriented Programmingです。著者の言葉を借りれば、「ビジネスプロセスはデータを何らかの形で変換する—入力を受け取り、何かを行い、出力を返す」。重要なのは、元のオブジェクトを変更しないことです。UnvalidatedOrder という型があります。validate という関数を適用すると、ValidatedOrder という新しい値が生まれます。このとき、元の UnvalidatedOrder には一切触れません。新しい値を作るだけです。UnvalidatedOrder → validate → ValidatedOrder → price → PricedOrder状態を「変更」するのではなく、「入力を受け取り、何かを行い、出力を返す」。元のオブジェクトには触れません。これが本書の核心です。この発想の転換がもたらすものこのアプローチを採用すると、いくつかの問題が消えます。状態の追跡が不要になる。 ValidatedOrder を持っているなら、それは「検証済みの注文」です。フラグを見る必要がありません。型がすべてを語ります。並行処理が安全になる。 元のデータを変更しないから、競合が起きません。テストが簡単になる。 入力を与えて、出力を確認します。それだけです。デバッグが楽になる。 各ステップの入出力をログに残せば、全経路が追えます。そして何より、ビジネスの言葉とコードが一致する。「見積書」が「発注書」になります。Estimate が Order になります。ビジネスの人々が頭の中で考えているモデルが、そのままコードになります。型は思考のツールである本書を読む前、型システムは「コンパイラを満足させるためのもの」だと思っていました。IDE の補完が効きます。リファクタリングが安全になります。その程度の認識でした。本書を読んで、型は「思考のツール」だと認識を改めました。AND と OR という 2 つの組み合わせで、複雑なドメインを表現できます。struct は「これとこれが両方必要」、enum は「これかこれのどちらか」。この単純な組み合わせが、ドメインの構造を可視化します。型を書くことは、ドメインを理解することです。型を読むことは、ドメインを学ぶことです。少なくとも、私はそう感じるようになりました。型で「不可能」を作る本書の内容を 2026 年の視点で読み直して、最大の発見がありました。「Make Illegal States Unrepresentable（不正な状態を表現不可能にする）」—この原則は、人間の開発者のミスを防ぐためのものとして紹介されています。しかし 2026 年現在、同じ原則がAIの出力を自動検証するフィルタとして機能しています。型で「不可能」を定義すると、AI が生成したコードのうち、その制約に違反するものはコンパイル時に除外されます。NonEmptyList<OrderLine> と定義すれば、AI が空の注文を返すコードを書いてもコンパイルエラーで検出されるVerifiedEmailAddress を要求すれば、AI が未検証メールへの送信を実装してもコンパイルが通らないUnvalidatedOrder → ValidatedOrder という型シグネチャがあれば、AI が検証をスキップするコードはコンパイルエラーになるこれは「AI に正しいコードを書かせる」のではなく、「AI が書いた誤ったコードを検出する」メカニズムです。AI の精度向上ではなく、フィルタリング機構として機能します。先日、Claude Code に「Order を作成する関数を書いて」と指示しました。生成されたコードは Vec<OrderLine> を返していました。しかし私のコードベースでは NonEmptyList<OrderLine> を使っています。コンパイルエラーが発生し、AI は「空の注文」を作るコードを出力しましたが、それが本番に混入することはありませんでした。一方、別のプロジェクトでは「このフィールドは必須」とコメントに書いただけでした。AI はそのコメントを無視して Option を返すコードを生成し、後から問題が発覚しました。型で定義された制約は、コンパイル時に検証されます。コメントは検証されません。この違いが重要です。「何を作るか」を決める能力本書の第 1 章で、著者は「開発者の仕事はコードを書くことではなく、ソフトウェアを通じて問題を解決すること」と述べています。2018 年に書かれたこの言葉は、2026 年の今、さらに重みを増しています。「何を作るか」という問いを分解してみます。ビジネス要件の理解: ドメインエキスパートとの対話、暗黙知の引き出し技術的制約の把握: 既存システムとの整合性、パフォーマンス要件、チームのスキルセット両者のトレードオフ判断: 「正解がない」状況での意思決定現時点で AI が得意なのは 2 番目です。ドキュメントやコードベースを読み、技術的な制約を分析できます。一方、1 番目と 3 番目は人間の仕事です。ドメインエキスパートとの対話で暗黙知を引き出すこと、そして「どちらも正しい」状況でトレードオフを判断すること。これらは AI に委譲できません。この構造を理解すれば、「人間の仕事」を「暗黙知の言語化」と「トレードオフ判断」に絞り込めます。本書で学んだドメインモデリングの技術は、まさにこの「暗黙知の言語化」を支援するものです。型で表現されたドメインモデルがあれば、AI は「どう作るか」を高い精度で実行できます。ドメイン駆動設計をはじめよう ―ソフトウェアの実装と事業戦略を結びつける実践技法作者:Vlad Khononovオーム社Amazon働き方の逆転—AIエージェント時代の開発スタイル本書を読みながら、自分の働き方が根本的に変わったことを実感しました。以前のモデルでは、人間がコードを書き、AI は相談相手でした。Stack Overflow の代わり、ドキュメント検索の高速化。補助的な存在です。現在のモデルでは、AI が運転席に座り、人間は助手席でナビゲーションをしています。AI にプランを練らせ、レビューし、実装させ、またレビューする。この流れが定着しました。AI は「分身」的な存在になりました。明確な指示とコンテキストを与えれば、疲労知らずで作業してくれる相棒です。Claude Opus 4.5 以降、この感覚は決定的になりました。プログラミングのシンタックスを書く機会は明らかに減りました。では、ソフトウェアエンジニアの役割はどう変化したのでしょうか。1. アーキテクチャの指針決定AI は「どう作るか」を実行できますが、「なぜそう作るか」は決められません。Bounded Context の境界をどこに引くか、技術選定のトレードオフ、パフォーマンスと保守性のバランス。これらは人間が判断します。2. コードベースから読み取れないコンテキストの整理・提供AI はコードに書かれていないことを知りません。なぜこの設計にしたか、本番環境でのみ発生する問題、チームの暗黙のコーディング規約、ビジネス上の制約。これらを言語化し、CLAUDE.md やコメントに落とし込む能力が求められます。3. 期待する挙動を自動・継続的に検証する枠組みの整備AI が書いたコードは「動く」かもしれませんが、「正しい」とは限りません。型による制約、プロパティベーステスト、E2E テスト、本番監視。これらの枠組みを整備し、AI の出力を検証し続けるのは人間の仕事です。本書の「Make Illegal States Unrepresentable」は、まさにこの 3 番目の観点で価値を発揮します。型で制約を定義すれば、AI の出力を自動的に検証できます。コンパイルが通れば、少なくとも型レベルの正しさは保証されます。コードを手で書くという作業は、実は思考の外在化プロセスでもありました。書きながら考えていた。この機会が減ったとき、思考の質をどう担保するか。正直、まだ答えが出ていません。本書のようなドメインモデリングの訓練はその答えの 1 つかもしれませんが、それで十分かどうかは分かりません。分からないまま、AI と協業し続けています。Architecture Modernization との接続本書を読みながら、Nick Tune 著『Architecture Modernization』の内容が何度も頭をよぎりました。現在、この本の翻訳に携わっています。Architecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazon『Domain Modeling Made Functional』は「新規開発」の文脈で DDD を説明しています。しかし現実の多くのプロジェクトは「既存システムの改善」です。レガシーシステムをどう分析し、背景情報からBounded Context をどう切り出し、段階的にモダナイズしていくか。『Architecture Modernization』はまさにその部分を扱っています。翻訳作業を通じて、共感できる内容が多くありました。特に「既存システムの暗黙知をどう言語化するか」という問題意識は、本書の「ドメインエキスパートとの対話」と通じるものがあります。AI エージェント時代において、この問題はさらに重要になっています。AI は「新しいコードを書く」ことは得意ですが、「既存システムの文脈を理解する」ことは苦手です。10 年前の設計判断の背景、当時の技術的制約、組織の歴史。これらを言語化し、モダナイゼーションの方針を決めるのは、依然として人間の仕事です。本書を読んで「関数型 DDD」に興味を持った方には、『Architecture Modernization』も勧めたいです。新規開発だけでなく、既存システムをどう改善するか。両方の視点を持つことで、設計の引き出しが増えます。最後に2018 年に出版された本書を、2026 年に読む価値はあったでしょうか。かなり、Yes です。ただ、正直なところ、本書の「すべて」を実践できる自信はありません。Smart Constructor を徹底すると言いながら、明日には String を直接使っているかもしれません。型で不可能を作るのは、思っているより面倒くさい作業です。締め切りに追われると、つい妥協してしまう。それでも、本書を読んだことで「何かに気づいた」感覚はあります。うまく言葉にできませんが、型を書くときの解像度が変わった気がします。Option を見たとき、「本当にこれは省略可能なのか？」と問い直すようになりました。冒頭で触れた『Architecture Modernization』の翻訳作業。本書を再読したことで、「Bounded Context」「Aggregate」といった用語を訳すとき、以前より自信を持てるようになりました。言葉の背後にある設計思想を、型という道具で理解したからです。翻訳は続いています。この感覚が正しいのかどうかは、実務で検証していくしかありません。関数型 DDD は、特定の言語やパラダイムに縛られません。F#で書かれた本書の概念は、Rust でも実践できます。そして、人間と AI が協業する時代において、「不可能を型で定義する」技術の価値はますます高まっていく—たぶん。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Chaos Meshで学ぶマイクロサービスのネットワーク障害と見えないリスク]]></title>
            <link>https://sreake.com/blog/learn-microservices-network-failure-and-risk-with-chaos-mesh/</link>
            <guid isPermaLink="false">https://sreake.com/blog/learn-microservices-network-failure-and-risk-with-chaos-mesh/</guid>
            <pubDate>Tue, 20 Jan 2026 01:05:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 「なんか遅い」「たまにエラーが出る」――マイクロサービスのシステムでこんな報告を受けたとき、皆さんはどこから調べ始めますか？ Sreake事業部インターン生の小林です。2025年11月-12月の間インターンに参 […]The post Chaos Meshで学ぶマイクロサービスのネットワーク障害と見えないリスク first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[
		Binance账户创建 より		]]></title>
            <link>https://sreake.com/blog/chatgpt-slack-integration/#comment-4673</link>
            <guid isPermaLink="false">https://sreake.com/blog/chatgpt-slack-integration/#comment-4673</guid>
            <pubDate>Mon, 19 Jan 2026 11:29:29 GMT</pubDate>
            <content:encoded><![CDATA[Your article helped me a lot, is there any more related content? Thanks! https://www.binance.com/fr-AF/register?ref=JHQQKNKN]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、頑張るなら組織と踊れ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/19/090119</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/19/090119</guid>
            <pubDate>Mon, 19 Jan 2026 00:01:19 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「おい、辞めるな」で辞めないことを選んだ。syu-m-5151.hatenablog.com「おい、辞めないなら頑張れ」で頑張り方を学んだ。syu-m-5151.hatenablog.com見せろ。対話しろ。上司を勝たせろ。スポンサーを作れ。そう書いた。で、やってみてどうだった。正直に言う。私はうまくいかなかった。見せているつもりだった。対話しているつもりだった。上司を勝たせようとしていた。でも、空回りしていた。なぜか。組織の力学を理解していなかったからだ。いや、もっと正確に言おう。理解しようとしなかった。組織の力学——いわゆる「政治」——を、私は嫌悪していた。「実力で勝負したい」「政治なんかに関わりたくない」——そう思っていた。技術的な正しさを盾に、人間関係の機微を「非論理的」と切り捨てていた。以前、「正義のエンジニアという幻想」という記事を書いた。syu-m-5151.hatenablog.comあの記事で書いたことは、今でも私の中に残っている。媚びないことと無礼であることの区別もつかないまま、技術的優位性を振りかざしていた——そんな恥ずかしい過去を、私は持っている。今回は、その続きを書く。組織の力学について。私が嫌悪していたもの。でも、理解しなければ成果を出せないもの。そして、したたかに生きるということについて。先に結論を言っておく。理解することと、加担することは違う。そして、政治をやっている人は「汚い大人」ではない。泥臭く仕事を通そうとしているだけだ。正直に告白する。この記事を書くことには抵抗があった。「政治のやり方を教える」みたいで、気が進まなかった。でも、過去の自分が知りたかったことを書く。飲み屋でそれを喋る。それがこの「おい、」シリーズの趣旨だ。おい、頑張るなら組織と踊れ。——と書いて、自分でも苦い顔をしている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。私は「正義のエンジニア」だった最初に告白しておく。私はかつて、自分の技術思想とキャリア戦略が100%正しいと信じて疑わなかった。そして、それを受け入れない企業、同僚たちが100%間違っていると本気で思っていた。今思えば、それはソフトウェアエンジニアという職業に就いた多くの若い人が陥る、ある種の思春期的な錯覚だったと思う。「なぜこんな非効率的な実装をするんですか？」「技術的にはこっちの方が正しいんですけどね」「政治的な理由で技術選定するなんて、エンジニアリングの敗北だ」そんな言葉を、私は何度思って何度口にしたことだろう。ある会議で、私は技術的に正しい提案をした。データに基づいていた。論理的だった。反論の余地がないと思っていた。却下された。理由は曖昧だった。「今はタイミングが悪い」「もう少し検討が必要」。でも、本当の理由は別にあった。私は後から知った。あの提案は、ある部門の利害と衝突していた。その部門のキーパーソンに、事前に話を通していなかった。だから、会議の場で潰された。私はその事実を伝えられた時に密かに怒った。「政治で正しい提案が潰されるなんて、おかしい」と。でも、冷静に考えると、私の方がおかしかった。技術的に正しいことと、組織で通ることは、別の問題だ。私はその区別ができていなかった。これは「誰に話を通すか」の問題だった。でも、組織の力学を理解していないことは、別の形でも現れた。あるプロジェクトで、私は黙々と成果を出していた。技術的な課題を解決し、納期を守り、品質を担保した。「これだけやれば評価されるだろう」と思っていた。評価面談で、上司はこう言った。「〇〇さんの貢献は分かっているんだけど、他のマネージャーに説明しにくいんだよね」。私は意味が分からなかった。成果を出しているのに、なぜ説明しにくいのか。後から分かった。私の仕事は「見えなかった」のだ。他のマネージャーは、私が何をしているか知らなかった。評価会議で私の名前が挙がっても、「誰？」という反応だった。私の上司は、私を推そうにも、材料がなかった。見えない仕事は、存在しないのと同じ——「おい、辞めないなら頑張れ」で書いたことだ。でも、それは「見せる」だけでは解決しない。誰に見せるか。どのタイミングで見せるか。どの文脈で見せるか。それを間違えると、見せても意味がない。私は「政治」を嫌悪していた。でも、その嫌悪が、私自身の足を引っ張っていた。媚びないと無礼を混同していたここで、痛い告白をする。「私は媚びない」——それが私のプライドだった。しかし「媚びない」と「無礼」は違う。私は単に無礼だった。コードレビューで、つい正論を優先してしまう癖があった。「このコード、正直ひどくないですか？全部書き直した方が早いです」——そんなコメントを書いていた。ある日、シニアエンジニアが個別に連絡をくれた。「君の指摘は技術的には正しい。でも、そのコメントを見た人がどう感じるか考えたことある？彼は他のタスクも抱えながら、期限に間に合わせようと必死だった。君のコメントは、その努力を全否定している」その言葉にハッとした。私は技術的な正しさばかりを見て、人の気持ちを踏みにじっていたのだ。別の機会には、マネージャーが1on1で厳しい指摘をした。「君は優秀だ。でも、チームメンバーが君を避け始めている。それでいいの？技術力があっても、一人では何も作れないよ」媚びないことと、相手を尊重することは両立する。でも当時の私にはその区別がつかなかった。率直であることと配慮がないことを混同していた。技術的な正しさを盾に、人としての礼儀を忘れていた。私は様々な言い訳を用意していた。「エンジニアは成果で評価されるべきだから人間関係は二の次」「技術的に正しいことが最優先だから言い方なんて些細な問題」「実力があれば多少の態度の悪さは許される」これらはすべて、自分の社会性の欠如を正当化するための、頭の悪い言い訳だった。まるで反抗期の中学生が「大人は汚い」と言い訳するように、私は「技術的正しさ」を盾に、自分の未熟さを隠していたのだ。転機は、年次が上がって後輩ができたときに訪れた。私の何気ない「それは違うよ」という一言で、新卒エンジニアが完全に萎縮してしまった。その後、彼は私に質問することを避けるようになり、分からないことを抱え込むように。私は、かつて自分が嫌っていた「怖い先輩」になっていたのだ。このとき、ようやく理解した。正しいことを、正しい方法で伝えられなければ、それはただの暴力だ。技術力は重要だが、それをどう使うかはもっと重要。正しいことを言っているつもりで、実際には相手の立場に立てていなかっただけだった。そういう時代もあったでよいここで、過去の自分との向き合い方について書いておく。ある時期、私は過去の失言や態度を思い出しては、布団の中で悶えていた。「あの時、なぜあんなことを言ったんだ」「もっと早く気づいていれば」——後悔の反芻は止まらなかった。コードレビューで人を傷つけた記憶。会議で空気を凍らせた記憶。「正しいことを言っているのに、なぜ分かってもらえないんだ」と憤っていた記憶。思い出すたびに、顔が熱くなった。でも、ある時気づいた。過去を責めても、過去は変わらない。変えられるのは、これからだけだ。だから、こう割り切ることにした。「過去はすべて正しかった」と。誤解しないでほしい。過去の行動が道徳的に正しかったと言いたいわけではない。あの無礼な態度は、やはり間違っていた。でも、あの経験があったから、今の自分がいる。痛い目に遭わなければ、私は変われなかった。あの失敗がなければ、この記事を書くこともなかった。過去を否定し続けると、エネルギーが過去に吸い取られる。後悔に費やす時間は、未来への投資に使えない。「あの時こうすればよかった」と100回考えるより、「これからどうするか」を1回考える方が、よほど生産的だ。過去を受け入れろ。そして、これからの人生に全力で取り組め。私は自分の未熟さを認めた。媚びないことと無礼の区別がついていなかったことを認めた。では、これからどうするか。答えは明確だった。組織の現実を、ちゃんと見ることだ。私が見ようとしなかったもの。「政治」と呼んで嫌悪していたもの。でも、理解しなければ前に進めないもの。——組織の力学について、正面から向き合う時が来た。組織には「裏の顔」があるここで、現実を直視しよう。組織には、公式なルールと非公式な力学の2つが常に存在している。公式なルールは分かりやすい。組織図、職務権限、承認フロー、評価制度。これらは明文化されていて、誰でもアクセスできる。でも、それだけで組織が動いているわけではない。非公式な力学とは、「正式な手続きには定められていないが、意思決定や資源配分に影響を与える行動」のことだ。根回し、人脈、暗黙の了解、派閥、影響力のある人物——そういうものだ。私はこれを「汚いもの」だと思っていた。でも、違った。彼らは汚いのではなく、泥臭いだけだった。非公式な力学は「善悪」ではなく「手段」だ。根回しは悪いことか。場合による。自分の私利私欲のためなら問題だ。でも、良いプロジェクトをスムーズに通すためなら、むしろ必要なことだ。関係者の懸念を事前に把握し、対処しておく。それは「政治」ではなく「配慮」とも呼べる。私が嫌悪していたのは、「非公式な力学」そのものではなかった。それを私利私欲のために使う人間だった。でも、手段と目的を混同していた。手段自体は中立だ。それをどう使うかが問題なのだ。ここで1つ、大事なことを言っておく。非公式な力学を理解することと、それに迎合することは違う。力学を理解した上で、「自分はこの手段は使わない」と決めてもいい。でも、理解せずに無視するのは、ただの怠慢だ。敵を知らずに戦っているようなものだ。私は長い間、「政治を理解する」こと自体を拒否していた。理解したら、自分も「あっち側」になる気がした。でも、それは間違いだった。理解することと、加担することは違う。そして、「あっち側」の人たちは、別に悪者ではなかった。ただ、泥臭く仕事を通そうとしていただけだった。理解した上で、どう振る舞うかは自分で決められる。組織図を信じるな次に、私が痛い目を見た話をする。組織図に描かれた権限構造と、実際に物事を動かせる力は違う。あるプロジェクトで、私は承認を得るために、組織図上の決裁者に話を持っていった。正式なルートだ。決裁者は「いいんじゃない」と言った。私は安心した。プロジェクトは頓挫した。何が起きたか。決裁者は「いいんじゃない」と言ったが、実際に動く現場のキーパーソンは別にいた。その人は私の提案に反対だった。決裁者が「いい」と言っても、現場が動かなければ、何も進まない。私は組織図を信じすぎていた。「誰が決裁権を持っているか」と「誰が実際に物事を動かせるか」は違う。そして後から気づいたことがある。同じ提案でも、事前に相談していれば通っていた可能性が高い。あのキーパーソンに、会議の前に一度話を聞きに行っていたらどうだっただろう。「こういうことを考えているんですが、懸念点はありますか？」と。相手の観点や懸念が事前に分かれば、提案に反映できる。相手も「聞いてもらった」という感覚がある。「聞かされていない」は、「間違っている」より強い反対理由になる。内容の良し悪しではない。プロセスの問題だ。これは単なる感情論ではない。組織心理学では「手続き的公正」と呼ばれる概念がある。人は、結果だけでなく、そこに至るプロセスが公正かどうかを重視する。自分の意見を聞いてもらえた、自分も関与できたという感覚があれば、たとえ結果が自分の望み通りでなくても、受け入れやすくなる。逆に、プロセスから排除されたと感じると、結果が正しくても反発する。私が会議で潰された提案は、まさにこれだった。内容は正しかった。でも、関係者は「自分は聞かれていない」と感じた。関係者に事前の相談なく、いきなり会議の場で出したことが、「あなたの意見は聞く必要がない」というメッセージになっていた。それだけで、反対する十分な理由になった。技術的に正しいかどうかと、組織で通るかどうかは、別の問題だ。そして、事前に挨拶して、相談して、懸念を聞いておく——それだけで結果が変わることが、驚くほど多い。ここで、少し視点を変えた話をする。私は下っ端として組織図に騙されてきた。でも、ある時気づいた。上に立つ人間こそ、この罠にはまりやすいのだと。下っ端の経験が少ない若いCEOやCTOが率いる組織を見てきた。彼らは往々にして、表側の組織図ばかり意識する。そして、裏側の関係性——長年かけて築かれた非公式なネットワーク——を軽視して、ドラスティックな組織変更をする。「この部署とこの部署を統合しよう」「この人をあのチームに異動させよう」——組織図の上では合理的に見える。でも、その変更が裏のネットワークをぐちゃぐちゃにすることがある。誰と誰が信頼関係を築いていたか。どのルートで情報が流れていたか。誰が実質的なキーパーソンだったか。それを無視して箱だけ動かす。若い頃の私は、そういうリーダーを「革新的だ」「スピード感がある」と思っていた。古い慣習を壊して、新しい組織を作る。カッコいいと思っていた。大人になった今は、違う見え方をする。成果を出すために、下の人間が苦労している。壊された関係性を、現場が必死で繋ぎ直している。組織図の上では「改革成功」に見えても、実際は現場の努力で何とか回っているだけ。これは「組織図を信じるな」の裏返しだ。組織図だけを見て動く危険は、下っ端だけの問題ではない。リーダーが組織図だけを見て動くと、現場が壊れる。私が組織の裏側を理解しようとするようになったのは、こういう経験も影響している。組織図の裏にあるものを無視すると、どうなるか。それを見てきたからだ。では、「組織図の裏にあるもの」とは、具体的に何か。私はそれを「影のネットワーク」と呼んでいる。かっこいい名前をつけたいわけではない。組織図には描かれないが、確実に存在するもの。それを言語化するために、この言葉を使っている。そしてその核心は、役職とは別に存在する権力だ。権力とは、役職に基づく権限だけではない。反対や抵抗を乗り越えて物事を実現する力。人を惹きつけ、巻き込む力。意思決定に実質的な影響を与える力。これらは、役職とは別に存在する。例えば、古株のベテラン社員。役職は高くないが、社内の歴史を全部知っている。誰と誰が仲が悪いか、過去にどんなプロジェクトが失敗したか、どの部署が何を嫌がるか。その人を味方につけると物事がスムーズに進む。敵に回すと、見えない抵抗にあう。例えば、経営者の信頼が厚い若手。役職は低いが、経営者に直接話ができる。その人の意見は、なぜか上まで届く。私は、この「影のネットワーク」を読めていなかった。組織図だけを見て、「この人に話を通せばOK」と思っていた。でも、組織図の裏には、別のネットワークがあった。なぜ「影のネットワーク」が存在するのか。理由は単純だ。組織図は「権限」を示すが、「実行力」を示さない。決裁権を持つ人が「やれ」と言っても、実際に手を動かす人が動かなければ、何も起きない。そして、実際に手を動かす人を動かせるのは、必ずしも決裁権を持つ人ではない。組織が大きくなるほど、この乖離は広がる。決裁者は現場から遠くなり、現場の信頼関係は決裁者の目に見えなくなる。結果として、「承認されたのに進まない」「反対されていないのに協力が得られない」という現象が起きる。これは個人の悪意ではない。権限と実行力が分離している構造の問題だ。組織図の裏にある「影のネットワーク」を読み解け。どの提案に誰が反発するか。誰を味方につければ障壁を突破できるか。情報がどのルートで流れるか。これが見えるようになると、立ち回り方が変わる。ここで、私が学んだ具体的な方法を書いておく。1. 会議での反応を観察する誰かが発言したとき、他の人の表情を見る。賛成しているのか、本音では反対なのか、無関心なのか。言葉ではなく、表情や態度に本音が出る。2. 「あの人に聞いてみたら」の連鎖を追う何か新しいことを始めようとしたとき、「あの人に聞いてみたら」と言われる人がいる。その人が、実質的なキーパーソンだ。組織図上の役職とは関係ない。3. 過去の意思決定を遡る大きな決定が下されたとき、「誰がどの段階で関わっていたか」を調べる。公式の決裁者だけでなく、その前に相談されていた人。その人が、影響力を持っている。4. ランチや雑談の相手を観察する誰と誰がよく一緒にいるか。情報は公式のルートだけでなく、非公式の人間関係を通じて流れる。ここまでが「見る」段階だ。では、見えたものをどう使うか。観察した後にどうするか観察だけでは意味がない。観察した情報を、行動に変える必要がある。キーパーソンが分かったら、提案の前に一度相談に行く。反対しそうな人が分かったら、その人の懸念を先回りして潰す。情報のルートが分かったら、そのルートに自分の情報を流す。最初は気が重い。「なぜこんな面倒なことを」と思う。でも、一度やってみると、驚くほど物事がスムーズに進む。私も最初は抵抗があった。でも、「正しい提案が政治で潰される」ことに比べれば、事前の相談なんて些細な手間だと気づいた。私が変わるまでの話ここまで読んで、「分かったけど、やっぱり嫌だ」と思う人がいるだろう。「政治なんかしたくない」「実力で評価されるべきだ」「こんなことに時間を使いたくない」。その気持ちは分かる。私もそうだった。そして正直に言えば、今でも完全には割り切れていない。私が組織の力学をどう受け止めてきたか、正直に書く。最初は、拒絶していた。長い間、ずっとそうだった。「実力で評価されるべきだ」「政治をやる奴は汚い大人だ」「自分はそういうことはしない」。そう思っていた。この時期は、現実とのギャップに苦しんだ。「なんで自分より実力のないあいつが評価されるんだ」「この会社はおかしい」。怒りや失望があった。でも、状況は変わらなかった。居酒屋で同僚と愚痴を言っていた。「あいつは政治がうまいだけだ」「実力で勝負しろよ」。言うたびに少し楽になった。でも、翌日も同じ状況が続いた。全ての原因を外部に求めていた。自分が提案した新技術が却下されれば「老害が変化を恐れている」と憤り、レガシーコードの改修を任されれば「俺の才能の無駄遣い」と不満を漏らし、ドキュメント作成を頼まれれば「エンジニアの仕事じゃない」と文句を言う。でも振り返ってみれば明らかだ。問題は私自身にあった。技術的な正しさだけを追求し、ビジネス的な制約や組織の事情を理解しようとしなかった。転機があった。尊敬していた先輩が、根回しをしているのを見た。「あの人も政治をやるのか」と最初は失望した。でも、よく見ると違った。先輩は、良いプロジェクトを通すために、関係者の懸念を事前に聞いて回っていた。それは「政治」というより「配慮」だった。「政治」と「配慮」の境界は曖昧だ。私が嫌悪していた「政治」の中には、実は「配慮」も含まれていた。それに気づいてから、少し楽になった。組織の力学を「存在するもの」として認められるようになった。好き嫌いを超えて、「まあ、そういうものだよな」と思えるようになった。過度に振り回されない心理的安定が生まれた。今はどうか。正直に言う。私はまだ、完全には割り切れていない。根回しをすることに、今でも抵抗がある。「これは本当に必要なのか」「実力で勝負すべきじゃないのか」と思う。でも、必要な場面では、やるようになった。割り切れないまま、やっている。——と書いて、立ち止まる。私と同じように変われ、と言いたいわけではない。どこまで受け入れるかは、自分で決めていい。「存在は認めるけど、自分はやらない」でもいい。「存在を認めることすら嫌だ」なら、別の環境を探してもいい。ただ、組織の力学を拒絶し続けていると苦しい。現実と理想のギャップに消耗し続ける。だから、少なくとも「存在を認める」ところまでは進んだ方が、楽になる。その先は、自分で決めればいい。譲れないもののために、譲るものを決める「存在を認める」ところまで進んだとする。でも、それだけでは足りない。認めた上で、どう振る舞うか。全部受け入れるのか。全部拒否するのか。——どちらも違う。私が辿り着いた答えは、もっと戦略的なものだった。ここで、私が学んだ重要なことを書く。本質を守るために、形式では妥協する。やがて私は真剣に考えるようになった。自分が本当に譲れないものは何か？見極める基準は1つ。「あったらいいな」は捨てろ。「なくなったら壊れる」だけを守れ。私にとって譲れないのは3つだった。1つ目は技術的な誠実さ。嘘はつかない、質の低いコードは書かない。これを失ったら、自分を信頼できなくなる。2つ目はユーザーファースト。エンドユーザーの利益を最優先する。これを失ったら、仕事の意味を感じられなくなる。3つ目は継続的な学習。常に新しいことを学び続ける。これを失ったら、市場価値が消える。これ以外は、状況に応じて柔軟に対応することにした。表現方法やタイミングを妥協しても、私は壊れない。だから手放せる。表現方法では本音を建前でオブラートに包むようになった。タイミングも最適な時期を待つように。プロセスでは目的のためなら遠回りも受け入れ、形式的には無駄に見える会議や書類も必要なら対応するようになった。全てを守ろうとすると、全てを失う。なぜか。理由は単純だ。妥協できない領域が増えるほど、交渉の余地は減る。交渉の余地が減るほど、衝突は増える。衝突が増えるほど、消耗する。消耗すると、本当に守りたかったものまで守るエネルギーがなくなる。私は以前、表現方法でも、タイミングでも、プロセスでも、一切妥協しなかった。「正しいことを、正しいタイミングで、正しい方法で言う」——それが自分の信念だと思っていた。結果、毎回衝突し、毎回消耗し、最終的には技術的な誠実さすら保てなくなった。疲れ果てて、どうでもよくなったのだ。だから、何を守り、何を手放すかを決める。これが大人の戦略だ。以前は、「妥協＝敗北」だと思っていた。でも違った。戦略的な妥協は、本質を守るための手段だ。形式で妥協し、本質を守る。それは負けではない。むしろ、本当に大事なもののために、大事でないものを手放す勇気だ。したたかに生きる戦略「譲れないものを守り、それ以外では妥協する」——それは分かった。でも、正直に言えば、それだけでは物足りない。守りに入っているだけだ。もっと攻めの姿勢で、組織を「利用」することはできないのか。——そう考えるようになった。ここで、もう一歩踏み込んだ話をする。技術は手段であって目的ではない——組織から見れば、そうだ。でも正直に言えば、私自身は技術的な興味に駆動されている。新しい技術を学ぶことが楽しいし、エレガントなコードを書くことに喜びを感じる。ビジネス価値なんてどうでもよくて、ただ面白い技術を触っていたいだけ、というのが本音だ。でも、お金をもらって仕事をする以上、建前上それが主目的とは言いづらい。だからこそ「したたかにやろうぜ」という考え方が大切なのだ。つまり、組織が求める「成果」という枠組みを利用して、自分の技術的好奇心を満たすということ。表向きは「ビジネス価値の創出」を掲げながら、実際には「面白い技術で遊ぶ」ための正当性を確保する。例えば、「パフォーマンス改善」という大義名分のもとで、最新のフレームワークを導入する。「開発効率の向上」という建前で、面白そうなツールチェーンを構築する。「技術的負債の解消」という錦の御旗を掲げて、自分が書きたいようにコードを書き直す。重要なのは、これらの建前が単なる口実ではなく、実際に価値を生み出すことだ。新技術で遊びながら、本当にパフォーマンスを改善する。好きなツールを使いながら、実際に開発効率を上げる。コードを書き直しながら、本当に保守性を向上させる。ここで正直に告白しておく。私はこの戦略で失敗したことがある。「開発効率の向上」を名目に、面白そうなビルドツールを導入した。確かに面白かった。でも、チームの学習コストを甘く見積もっていた。結果として、効率は上がるどころか下がった。建前が嘘になった瞬間、「あいつは自分のことしか考えていない」という評価が下された。信頼を取り戻すのに、かなりの時間がかかった。したたかさの前提は、建前が本当に価値を生み出すことだ。建前が嘘になった瞬間、したたかさは不誠実に変わる。自分が楽しいかどうかではなく、本当に成果が出るかどうか。その見極めを間違えると、戦略は破綻する。「プロフェッショナルとして責任を果たします」と胸を張りながら、心の中では「やった！これで堂々とRustが書ける！」と小躍りする。この二重構造こそが、エンジニアとしてのしたたかさだ。ただし、小躍りする前に、本当に成果が出るかを冷静に見極めること。それを怠ると、私のように痛い目を見る。組織は成果を得て満足し、私たちは技術的満足を得る。Win-Winの関係を作り出すこと。それは決して不誠実ではなく、むしろ異なる価値観を持つ者同士が、お互いの利益を最大化する賢明な戦略なのだ。組織をハックしろ。建前で成果を出し、本音で技術を楽しめ。影響力は才能ではなくスキルだここまで「したたかにやれ」と書いてきた。「でも、自分は政治が苦手だ」という人がいるだろう。分かる。私もそうだった。というか、今でもそうだ。人の顔色を読むのが苦手だし、根回しは面倒くさいと思っている。でも、安心してほしい。影響力は先天的な才能ではなく、後天的に磨けるスキルだ。私も苦手だった。今でも得意とは言えない。でも、意識して練習することで、少しずつマシになった。組織における対人影響力は、5つの能力で構成されている。これらは「観察→洞察→共感→表現→一貫性」というプロセスで連鎖する。1. 観察——表面を見る最初の能力は観察だ。目の前で起きていることを正確に捉える。何を観察するか。言葉——誰が何を言ったか。態度——表情、姿勢、声のトーン。関係——誰と誰が近いか、誰が誰を避けているか。反応——ある発言に対して、他の人がどう反応したか。観察は受動的な行為に見えるが、意識しないとできない。会議で自分の発言に集中していると、他の人の反応を見落とす。発言を減らし、観察を増やす——これだけで得られる情報量は変わる。2. 洞察——本質を見抜く観察の次は洞察だ。表面の情報から、見えないものを推測する。洞察とは何か。動機を読む——この人は何を求めているのか、何を恐れているのか。構造を読む——この組織で、誰が実質的な力を持っているのか。文脈を読む——この議論は、どんな歴史の上に成り立っているのか。観察が「何が起きているか」を捉えるなら、洞察は「なぜ起きているか」を捉える。同じ事象を見ても、洞察の深さで解釈は変わる。表面的な反対意見の裏に、本当の懸念が隠れていることがある。3. 共感——相手の立場に立つ洞察の次は共感だ。相手の世界を、相手の視点から理解する。共感は「同意」ではない。相手の意見に賛成しなくても、相手がなぜそう考えるかを理解することはできる。「この人の立場なら、確かにそう思うだろう」——その理解があれば、対立は減る。エンジニアは共感を軽視しがちだ。論理が正しければ、相手の感情は関係ないと思っている。しかし、人は論理だけでは動かない。自分の立場を理解してくれていると感じたとき、初めて耳を傾ける。4. 表現——相手に響かせる共感の次は表現だ。自分の考えを、相手に届く形で伝える。表現の本質は「相手に合わせる」ことだ。論理で動く人には論理を。感情で動く人には感情を。利害で動く人には利害を。同じ提案でも、切り口を変えれば響き方が変わる。「伝える」と「伝わる」は違う。自分が言いたいことを言うのは「伝える」。相手が受け取れる形で届けるのが「伝わる」。影響力とは「伝わる」力だ。5. 一貫性——信頼を積む最後は一貫性だ。これが他の4つを支える土台になる。一貫性とは何か。言ったことを実行する。約束を守る。嘘をつかない。単純だが、最も難しい。なぜ難しいか。一貫性を保つには、「できない約束をしない」という自制が必要だからだ。期待に応えたくて、つい「やります」と言ってしまう。しかし、守れない約束は信頼を削る。「できません」と言える人の方が、長期的には信頼される。一貫性がなければ、観察も洞察も共感も表現も、すべて無駄になる。「あの人の言うことは当てにならない」——そう思われた瞬間、影響力は消える。これら5つは、すべて後天的に磨けるスキルだ。生まれつきの才能ではない。ただし、順番がある。土台となる「一貫性」がなければ、他の4つは機能しない。まず信頼を築き、その上に観察・洞察・共感・表現を乗せる。「専門性」と「人望」が最強のカードだここまで「組織の力学を理解しろ」「影響力を磨け」と書いてきた。でも、ここで安心してほしいことがある。最も持続する影響力は「専門性」と「人望」から生まれる。なぜそう言えるのか。少し整理してみる。人が他人を動かす力——影響力には、いくつかの種類がある。ソフトウェアエンジニアの現場で見かける例で説明する。報酬で動かす場合がある。「このリファクタリングを完了させたら、次のスプリントで好きな技術調査の時間をあげる」。評価で動かすこともある。「このタスクを断ったら、次の評価に響くよ」。役職で動かすパターンもある。「テックリードの判断だから、この設計で行く」。データで動かすこともできる。「ベンチマークの結果、この実装の方が30%速い」。そして、専門性で動かす場合がある。「Kubernetesのことなら〇〇さんに聞けば間違いない」。人望で動かす場合もある。「あの人が言うなら、きっと理由があるはず」。このうち、専門性と人望が最も強い。なぜか。この2つは、相手が「自分から納得して動く」ときに生じるからだ。報酬・評価・役職で動かす場合、相手は「仕方なく」動いている。上司が変わったり、評価制度が変わったりすれば、その影響力は消える。「テックリードが言うから従う」で動いていたチームは、テックリードがいなくなれば元に戻る。専門性と人望で動かす場合、相手は「この人の言うことだから」と自分から動いている。その人がいなくなっても、「あの人ならどう判断するだろう」と考え続ける。影響が内面化されている。外からの圧力で動いた行動は、圧力がなくなれば止まる。内側から納得して動いた行動は、続く。ただし、注意点がある。どのカードが強いかは、組織や部署によって違う。エンジニアだけの組織では、データが圧倒的に強い。「ベンチマークの結果」「障害の根本原因分析」「パフォーマンス計測」——数字で示せば、それだけで説得力がある。論理と数字を重視する文化があるからだ。でも、営業部門やマーケティング部門では違う。データより「この人が言うなら」という人望が効くことがある。経営層との会議では、役職や過去の実績が重みを持つ。同じ会社でも、部署が変われば有効なカードは変わる。私はエンジニア組織にいることが多いので、データと専門性に頼りがちだ。でも、他部署との調整では、それだけでは通用しないことを何度も経験した。相手が何を重視するかを見極めて、カードを使い分ける必要がある。だから、長期的な影響力を構築するなら、専門性を磨き、人として尊敬される存在になることが最も確実な方法だ。専門性と人望は、どの組織でも比較的通用しやすい。「政治力を磨け」と言われると抵抗がある人も、「専門性を磨け」なら抵抗がないだろう。実は、専門性を磨くことは、組織における影響力を高める最も正攻法なアプローチなのだ。ここで、私の経験を1つ書いておく。ある領域で、私はチームの中で一番詳しくなった。別に政治をしたわけではない。ただ、その領域を深掘りし続けた。ドキュメントを読み、実験し、知見を共有した。すると、向こうから相談が来るようになった。「〇〇のことは△△さんに聞けばいい」という評判が立った。会議で発言すると、その領域については私の意見が尊重されるようになった。これは「政治」ではない。専門性による影響力だ。ただし、専門性を万能視するのは危険だ。限界もある。具体的に言おう。専門性が効くのは「その領域の意思決定」に限られる。組織全体の方向性、予算配分、人事——こういった領域横断的な意思決定では、専門性だけでは戦えない。私も経験がある。技術的な判断では尊重されるようになったが、プロジェクトの優先順位を決める会議では、相変わらず発言力がなかった。専門性は「深さ」を与えるが、「広さ」は別の力学で決まる。それでも、専門性があれば、政治力が弱くても、ある程度は戦える。少なくとも、自分の専門領域では発言権が得られる。そこを足がかりにして、徐々に影響力を広げていくことができる。だから、「政治が苦手だ」という人に言いたい。まず専門性を磨け。それが最も確実な道だ。政治力は、専門性という土台の上に乗せるオプションとして考えればいい。土台がないまま政治力だけ磨いても、長続きしない。組織と踊るための心構え最後に、心構えの話をする。おい、頑張るなら組織と踊れ。これは「組織に従属しろ」という意味ではない。ダンスは、相手の動きを感じながら、自分も動く。一方的にリードするわけでも、一方的にフォローするわけでもない。相手と自分の動きが調和して、初めてダンスになる。組織も同じだ。組織の力学を無視して突っ走ると、壁にぶつかる。かといって、組織に完全に従属すると、自分の意志がなくなる。組織の力学を理解し、その中で自分の目標を追求する。組織を動かしながら、自分も動く。これが「組織と踊る」ということだ。組織を敵視するな。かといって、盲従するな。組織は、自分の目標を達成するためのプラットフォームだ。うまく使えば、一人ではできないことができる。敵視していたら、使いこなせない。短期の勝ち負けにこだわるな。組織での影響力は、長期的に築くものだ。一回の会議で勝った負けたは、大した問題ではない。信頼の蓄積、専門性の蓄積、関係性の蓄積。これらが時間をかけて積み上がったとき、本当の影響力が生まれる。自分の価値観を失うな。組織の力学を理解し、活用することと、自分の価値観を捨てることは違う。「この方法は使えるけど、自分はやりたくない」と思うなら、やらなくていい。別の方法を探せばいい。「媚びない」ことと「無礼」であることは全く違う。前者は信念を持つことであり、後者は単なる社会性の欠如だ。同様に、「したたか」であることと「ずる賢い」ことも違う。前者は双方の利益を最大化する戦略的思考であり、後者は単なる利己主義だ。私は今でも、根回しに抵抗がある。でも、必要な場面ではやる。やりながら、「これでいいのか」と自問する。割り切れないまま、やっている。組織と踊るというのは、自分を殺すことではない。自分を活かしながら、組織の中で成果を出す方法を見つけることだ。その方法は、人によって違う。自分なりの踊り方を見つければいい。届かない人へここまで書いてきて、立ち止まる。「組織の力学を理解しろ」「影響力を磨け」「組織と踊れ」——私はそう書いた。でも、この記事には前提条件がある。この記事が有効なのは、以下の条件が揃っている場合だ。組織がまともである——努力が報われる余地がある自分にエネルギーがある——行動を起こす余力がある組織で働くことを選んでいる——別の選択肢を選んでいないこの前提が成り立たない場合、この記事は役に立たない。それぞれ見ていく。組織が合わない人がいるそもそも、組織で働くことが向いていない人がいる。組織の力学を理解しろと言われても、理解する気力がない。人間関係を築けと言われても、それ自体がストレスだ。会議で発言しろと言われても、声が出ない。彼らは「能力がない」のではない。組織という形態が合わないのだ。フリーランス、起業、小規模チーム、リモートワーク——組織以外の働き方もある。そちらが合う人もいる。「おい、頑張るなら組織と踊れ」は、組織で働くことを前提としている。その前提自体が合わない人には、この記事は届かない。力学を理解しても動けない人がいる組織の力学を理解した。影響力を磨く方法も分かった。でも、動けない。すでに消耗している人。根回しをする気力がない人。人間関係を築くエネルギーがない人。彼らに「影響力を磨け」と言っても、無理だ。まず休む必要がある。構造的に無理な組織もあるどんなに力学を理解しても、どんなに影響力を磨いても、無理な組織もある。腐敗した評価制度。声の大きい人だけが勝つ文化。変える気のない経営層。そういう組織では、個人の努力で変えられることに限界がある。「組織と踊れ」と言っても、相手がダンスをする気がないなら、成立しない。この記事は、「組織がまともで、自分にエネルギーがある」ことを前提にしている。その前提が成り立たないなら、この記事は役に立たない。「踊らない」という選択肢もある「組織と踊る」ことを選ばない、という選択肢もある。専門性だけで勝負する。政治には一切関わらない。評価されなくても気にしない。自分のペースで、自分のやり方で働く。それは「負け」ではない。評価ゲームから意識的に降りるという戦略だ。「おい、辞めないなら頑張れ」で書いたことを繰り返す。頑張れないなら、頑張らなくていい。降りてもいい。休んでもいい。それも、1つの選択だ。おわりに「おい、辞めるな」で辞めないことを選んだ。「おい、辞めないなら頑張れ」で頑張り方を学んだ。そして今回、「おい、頑張るなら組織と踊れ」で組織の力学を学んだ。正直に言う。この記事を書くことには抵抗があった。「政治のやり方を教える」みたいで、気が進まなかった。でも、過去の自分は、これを知りたかった。組織の力学を理解せず、「政治は汚い」と嫌悪しながら、壁にぶつかり続けていた。正義のエンジニアという幻想に囚われて、媚びないことと無礼を混同していた。その時間は、もったいなかった。組織の力学を理解しろ。でも、専門性と人望が最強のカードだ。政治に長けていても、実力がなければ長続きしない。実力があっても、組織の力学を無視していたら成果につながらない。両方必要だ。でも、長期的に見れば、専門性と人望が最も確実な道だ。譲れないもののために、譲るものを決めろ。したたかに生きろ。組織を敵視するな。盲従するな。組織と踊れ。——と書いて、自分でも苦い顔をしている。「お前も結局、体制に飲み込まれたのか」——かつての私なら、今の私をそう批判しただろう。しかし、それでいいのだ。技術的な純粋さを追求することと、社会的な成熟を遂げることは矛盾しない。むしろ、両方を兼ね備えてこそ、プロの仕事と言えるのではないだろうか。媚びないことと無礼の区別がつかなかった、頭の悪い反抗期は終わった。正直に言えば、私はまだ上手に踊れていない。根回しに抵抗がある。状況認識力が弱い。会議で空気を読めない。それでも、以前よりはマシになった。壁にぶつかる回数は減った。この記事が、かつての私のような人に届けばいいと思う。「政治は汚い」と思いながら、壁にぶつかり続けている人。組織の力学を理解することに抵抗がある人。「正義のエンジニア」という幻想に囚われている人。理解することと、加担することは違う。理解した上で、どう振る舞うかは自分で決められる。おい、頑張るなら組織と踊れ。踊れないなら、休め。踊り方は、自分で決めろ。——と、ここまで書いてきた。でも、最後に付け加えておく。組織が合わないなら、別の場所を探せばいい。それも、1つの選択だ。私も、まだ上手に踊れていない。それでも、やっている。それでいいのだと思う。かつての私のような若いエンジニアを見かけたら、優しく、でもはっきりと伝えたいと思う。「君の気持ちはよく分かる。でも、もっといい方法があるよ。一緒にしたたかにやっていこうぜ」と。多分昔の私だったら「は？日和って迎合した負け犬が何言ってんの？」とか思って、心の中で見下しながら表面上は「はい、参考にします」って適当に流すんでしょうね。まあ、それでいいんです。私も通った道だから。痛い目に遭うまで、人は変われない。私もそうだった。その時になって初めて、この言葉の意味が分かるはずです。けど大人として言う義務があるので言っておきました。参考書籍人を動かす　改訂文庫版作者:Ｄ・カーネギー創元社AmazonDD(どっちもどっち)論 「解決できない問題」には理由がある (WPB eBooks)作者:橘玲集英社Amazonその仕事、全部やめてみよう――１％の本質をつかむ「シンプルな考え方」作者:小野 和俊ダイヤモンド社Amazonアーキテクチャモダナイゼーション【リフロー型】 組織とビジネスの未来を設計する作者:Nick Tune,Jean-Georges Perrin翔泳社Amazonこれからの「正義」の話をしよう ──いまを生き延びるための哲学 (ハヤカワ・ノンフィクション文庫)作者:マイケル・サンデル早川書房AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonモンク思考―自分に集中する技術作者:ジェイ・シェティ東洋経済新報社AmazonSOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazon多様性の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon［新版］組織行動の考え方―個人と組織と社会に元気を届ける実践知作者:金井 壽宏,高橋 潔,服部 泰宏東洋経済新報社Amazonソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社AmazonTHE CULTURE CODE 最強チームをつくる方法作者:ダニエル・コイル,楠木建かんき出版Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[プログラミングが好きな人こそ今の時代、プログラマーになる方がいいと思う。- 「プログラミングが好きな人は、もうIT業界に来るな。」を読んで]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/18/123151</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/18/123151</guid>
            <pubDate>Sun, 18 Jan 2026 03:31:51 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIにリサーチをさせていた。結果が返ってくるまで数分かかる。待っている間、Xを開いた。流れてきたタイトルに、手が止まった。「プログラミングが好きな人は、もうIT業界に来るな。」note.comリサーチは終わっていた。結果を確認しないまま、記事を読んでいた。小学生の頃から黒い画面に向かい続けてきたエンジニアが、生成AIの登場によって「自分の手で作る喜び」を奪われつつあると語っていた。「心の中で何かが音を立てて崩れる」という表現があった。共感したのか、と聞かれると困る。共感しなかったのか、と聞かれても困る。たぶん、どちらでもある。読み終えて、エディタに戻った。さっきまで何をしていたか、思い出せなかった。反論したいわけではなかった。ただ、何かが引っかかっていた。「プログラミングが好き」という言葉だ。この人の「好き」と、私の「好き」は、同じものを指しているのだろうか。コーヒーを淹れた。飲みながら、書くことにした。「好き」の中身を分解する元記事の筆者と私の違いは、能力でも経験でもない。「プログラミングが好き」という言葉が指す範囲が違うのだ。言葉は同じでも、中身が違う。「好き」と言ったとき、何を思い浮かべているか。キーボードを叩く指先か、頭の中で組み上がる構造か、動いた瞬間の達成感か。同じ「好き」でも、その中身は人によって違う。中身が違えば、奪われるものも違う。プログラミングという行為には、少なくとも3つのレイヤーがある。——もちろん、これは私の視点からの便宜的な分類だ。元記事の筆者にとっては、まったく別の分け方があるかもしれない。「書くこと」と「考えること」は分離できない、という人もいるだろう。書きながら考える。考えながら書く。その不可分さこそがプログラミングだ、と。それでも、ここでは一旦この枠組みで話を進める。身体感覚：キーボードを叩く感触、コードを書く行為そのもの、画面に流れる快感知的作業：問題を分解し、設計し、実装する思考プロセス創造行為：何かを作り、動かし、世に出す達成感元記事の筆者が愛していたのは、単なる身体感覚ではないように思う。「自分の指先から生まれるロジックが、動かなかったものを動かす」——その創造の主体性だ。自分の手で書いたコードが動く。その実感が奪われたから「楽園が消えた」と感じている。AIが書いたコードをチェックする「検品係」では、創造の主体は自分ではない。これは「間違った好き」ではない。彼の文脈では、それが正解だった。小学生の頃から黒い画面に向かい続け、自分の手でコードを書くことで世界を動かしてきた。その積み重ねの上に立っている。私が「設計が好き」と言えるのも、私の文脈があるからだ。どちらが正しいという話ではない。私が好きだったのは、2だった。課題があったら適切なサイズに分割して、「この問題はこう実装すれば解決するな」と構造が頭の中で閃く。そこからコードを書き続けていく。その一連のプロセスが好きだった。AIがコードを出力するようになって初めて、自分の「好き」が何だったのか見えた。コードを書けなくなったとき、喪失感を感じたか？ 感じなかった。むしろ「これで設計に集中できる」と思った。そのとき気づいた。自分が好きだったのは、タイピングではなく、考えて、作って、また考える、その繰り返しだった。では、何が奪われ、何が残ったのか整理しよう。奪われたもの：タイピングの時間、実装の試行錯誤、ググって解決策を探す時間。残ったもの：設計を考える時間、AIの出力を評価する時間、「もっと良い方法はないか」と考える時間。私にとって、後者こそがプログラミングの核心だった。もっと言えば、コードを書く時間に追われて後回しにしていた「設計」や「トレードオフの検討」——いわゆるソフトウェアエンジニアリングの領域に、ようやく時間を使える。だから、「奪われていない」と言い切れる。実践ソフトウェアエンジニアリング (第9版)作者:ロジャー・プレスマン,ブルース・マキシムオーム社AmazonGoogleのソフトウェアエンジニアリング ―持続可能なプログラミングを支える技術、文化、プロセス作者:Titus Winters,Tom Manshreck,Hyrum WrightオライリージャパンAmazon正直に言う、めちゃくちゃ楽しい今、めちゃくちゃ楽しい。作りたいものがある。指示を出す。コードが出てくる。レビューする。直す。動く。——以前なら「面倒だな」と後回しにしていたアイデアや知識が、数分で形になる。さっき書いた「ソフトウェアエンジニアリングの領域」——設計、トレードオフ、アーキテクチャ。そこにやっと向き合えている感覚がある。楽しい。素直に、楽しい。これを「検品係」と呼ぶなら、私は世界一楽しい検品係だ。コードレビューが好きで良かった思えば、私はコードレビューが比較的好きだった。他人のコードを読んで、「この人はこう考えてるんだろうな」というのが見えると嬉しい。なぜこの設計にしたのか、どこで迷ったのか。コードの向こうに思考が透けて見える瞬間が好きだった。知らない言語機能や、思いつきもしなかった構造で課題を解決しているのを見ると、良し悪しにかかわらず楽しい。正解かどうかより、発見の方が全然面白い。正解とは常に文脈の中にしかない。チームの習熟度、プロダクトのフェーズ、パフォーマンス要件、保守する人間の数。同じ課題でも、文脈が変われば最適解は変わる。だから「このコードは正しいか」という問いより、「この文脈でなぜこう書いたのか」という問いの方が面白い。そして、その問いに答えようとする過程で、自分の中の「正解」も揺らぐ。揺らぐことが学びだ。AIが出力したコードをレビューしていると、これが想像以上に勉強になる。先日、AIに「CSVパーサーを書いて」と頼んだ。返ってきたコードを見て驚いた。私なら正規表現でゴリ押しするところを、状態機械で書いている。エスケープ処理も完璧だ。「なるほど、このアプローチがあったか」と笑った。逆に、「いや、これは現場では使えない」と思う瞬間もある。過剰に抽象化されていたり、エラーハンドリングが甘かったり。その判断力こそ、レビューを通じて研ぎ澄まされる。——もっとも、私の判断が正しいとは限らない。AIの提案を「使えない」と却下した翌週、まったく同じアプローチを別の記事で「ベストプラクティス」として紹介されているのを見たこともある。ただ、これは15年やってきた人間だから言えることだ。状態機械の良さが分かるのは、正規表現ゴリ押しで痛い目を見たことがあるからだ。「なるほど、このアプローチがあったか」と唸れるのは、比較対象を持っているからだ。経験ゼロの人がAIの出力から体系的に学べるかは、正直分からない。むしろ、学べない可能性の方が高い気がする。コードレビューが苦手な人には、AIとの協働は苦行かもしれない。でも、レビューが好きな人間にとっては、無限に相手がいるジムのようなものだ。疲れない、休まない、いつでも付き合ってくれる相手。しかも、毎回違うアプローチを見せてくれる。「検品」と「協働」の違い元記事は「検品係になった」と嘆いている。創造の主体でありたかった人にとって、この表現は正確だと思う。自分が書きたかったコードを他者（AI）が書き、自分はそれをチェックするだけ。主体と客体が入れ替わっている。ただ、私の場合は少し違った。携帯電話は私のことをめちゃくちゃ記憶している。連絡先、スケジュール、位置情報、検索履歴。私より私のことを知っているかもしれない。でも、携帯電話を使っているとき、「主体を奪われた」とは感じない。道具として使っている感覚がある。生成AIは違う。コードを書く、文章を書く、設計を考える——これまで「私がやること」だった領域に、AIが入り込んでくる。携帯電話が記憶を代替しても主体性は揺らがなかったが、生成AIは創造を代替しようとする。だから主体性が脅かされる感覚が生まれる。それでも、私は自分が主体だと思っている。なぜか。www.youtube.com答えは、関わり方にある。「検品」と「協働」の違いは何か。検品は受動的だ。ラインを流れてくる製品をチェックし、不良品を弾く。渡されたものをチェックするだけ。協働は能動的だ。方向性を示し、フィードバックを与え、成果物を一緒に作り上げる。私がAIとやっているのは後者だ。具体的に言うと——「こういう設計で書いて」と指示を出す（方向性）出てきたコードを見て「ここはこう直して」とフィードバックする「いや、アプローチ自体を変えよう」と軌道修正する最終的な成果物が完成するこのやりとりは、人間同士のペアプログラミングと構造的に同じだ。相手が人間かAIかの違いしかない。検品係は受け身だが、私は能動的にAIを導いている。方向を決め、判断を下し、軌道修正をかける。この能動性が、主体性を保つ鍵だ。AIとの関係を一言で表すなら、「相棒」ではなく「優秀だが判断できない後輩」が近い。指示を明確にすれば良い仕事をする。曖昧にすると、意図しないものが返ってくる。筆者が言うように、書く時間は減った。でも、考える時間は増えた。どう分割するか。どう設計するか。AIが出してきたコードのどこを採用し、どこを直すか。そして、仮にこれが「検品」だったとしても、私はその過程でかなり学んでいる。「こんな書き方があるのか」と何度も唸った。特に経験の浅い言語では顕著だ。自分で書いていたら絶対に思いつかないイディオムを、AIは平気で出してくる。検品のつもりが、いつの間にか授業を受けている。ただし、ここには落とし穴がある。AIが出したコードをそのまま使って「動いた、終わり」で済ませると、何も残らない。効率は上がる。成果も出る。でも、1週間後に「なぜこう書いたの？」と聞かれても、答えられない。因果を辿れない。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。以前、「AIエージェントと協働しながら学習する方法」という記事で詳しく書いたが、学びには「摩擦」が必要だ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わる。学習とは、経験を意味に変換する行為だ。AIが摩擦を消してくれると、経験が意味に変わる機会も消える。syu-m-5151.hatenablog.comだから私は、AIが出したコードを「なぜこう書いたのか」と考える時間を意図的に作っている。効率だけを求めるなら不要な時間だ。でも、この「不効率な時間」が学びを生む。摩擦は削減対象ではない。設計対象だ。何を学び、何を省略するか。その選択を自分でしている限り、主体は私だ。これを「検品」と呼ぶか「協働」と呼ぶかは、本人の姿勢次第なのかもしれない。——と書いて、自分で読み返して思った。「姿勢次第」では何も言っていないのと同じだ。具体的に、検品を協働に変えるための3つのポイントを挙げてみる。意図を言語化する: 「こう書いて」ではなく「この問題を解決したい。制約はこれ」と伝える。AIに考えさせる余地を残す。出力から学ぶ: AIが出したコードを「動くかどうか」だけでなく、「なぜこう書いたか」を考える。知らないパターンがあれば調べる。フィードバックを重ねる: 一発で完璧を求めない。「ここを直して」「いや、やっぱりこっち」のやりとりを楽しむ。この3つができれば、検品は協働になる。逆に言えば、「動くか確認するだけ」なら、それは検品だ。この3つを実践するかどうか。それが検品と協働を分け、主体性を保てるかどうかを分ける。——と偉そうに書いたが、これが「正解」かどうかは分からない。私の文脈ではうまくいっている。でも、別の文脈では別の答えがあるはずだ。締め切りに追われているときは「動けばいい」になるし、疲れているときは「なぜこう書いたか」なんて考えない。理想と現実は違う。ただ、「こうありたい」という指針があるのとないのとでは、違うと思っている。それすらも、私の文脈での話だ。ただし、これは私のケースだここまで書いてきて、一つ断っておきたいことがある。これは私の話だ。コードレビューが好きで、設計を考えるのが好きで、タイピング速度に自信がなかった人間の話だ。もし元記事の筆者のように、「自分の手で書いたコードが動く」その実感こそが喜びだったなら——この記事は何の慰めにもならないだろう。創造の主体でありたかった人に、「検品も楽しいよ」とは言えない。その人たちに「考え方を変えろ」と言うつもりはない。「自分が書きたかった小説をAIに書かせ、誤字脱字を直す校正者のような気分」——元記事のこの表現は、痛いほど分かる。創造の主体性を奪われた感覚は、姿勢や考え方でどうにかなるものではない。彼の文脈では、それが真実だ。私が「楽しい」と言えるのは、私の文脈がたまたまそうだったからに過ぎない。「でも、結局プログラマーの仕事は減るのでは？」という反論もあるだろう。正直、分からない。AIの進化は私の想像を超えている。5年後にどうなっているか、予測する自信がない。そして、ここは誤魔化さずに言っておくべきだと思う。「楽しい人がいること」と「職業として持続可能かどうか」は、まったく別の話だ。ドライバーが100人必要だった時代から、10人で済む時代へ。私が楽しくても、市場が縮小すれば、その楽しさを職業にできる人は減る。元記事の筆者が問うているのは、たぶんそっちの話でもある。この問いについて、エンジニアに許された特別な時間の終わりというスライドがある。エンジニアがドライバー席から助手席へ移る時代が来ている、という話だ。AIが「副操縦士（Copilot）」から「操縦士（Pilot）」へ進化しつつある。続編のたかが特別な時間の終わりでは、9ヶ月後にその予測が現実化しつつあると報告されている。私がこの記事で書いてきた「協働」も、結局は助手席からの関わり方なのかもしれない。ドライバー席に座っていた時代は終わりつつある。それでも、助手席には助手席の仕事がある。呑気なドライブデートを思い浮かべたかもしれないが、全然様相は違う。ラリーのコ・ドライバーは、ただ座っているだけではない。本番前にコースを試走し、コーナーの角度、直線の距離、路面の状態、危険なポイントをすべてペースノートに書き込む。本番では猛スピードで揺さぶられる車内で、そのノートを絶妙なタイミングで読み上げる。「左3、50m、右2、クレスト注意」。ドライバーは全コースを暗記できない。コ・ドライバーなしでは走れない。AIとの協働も似ている。事前にコードベースを把握し、設計を考え、制約を整理する——これがペースノートの作成だ。本番では、AIが猛スピードでコードを生成する中、「次は右だ」「ここは危険だ」と指示を出し続ける。曖昧な指示を出せば、車は崖から落ちる。ただし、その車は時速200kmで走っている。のんびり景色を眺める余裕はない。コ・ドライバーとして生きる。それがこの時代の選択だ。——と書いたが、この比喩にも限界がある。ラリーではコ・ドライバーの仕事がなくなることはない。しかし、AIとの協働では、その保証がない。今は「設計」「評価」「判断」が人間の仕事として残っている。だが、AIが設計し、AIが実装し、AIがレビューする世界が来たら？ コ・ドライバーの席さえ、自動運転に置き換わるかもしれない。この記事は「設計や評価は人間に残る」という前提で書いている。その前提が崩れたら、私の話は無効になる。ただ、「だから今やっても意味がない」とは思わない。今この瞬間、プログラミングが楽しいなら、それでいい。未来のことは、未来の自分が考える。——もっとも、この「楽しい」を大声で言うのは少し気が引ける。誰かが失った「楽しさ」の上に、私の「楽しさ」が成り立っているかもしれないからだ。元記事の筆者が読んだら、どう思うだろう。「お前はたまたま運が良かっただけだ」と言われたら、反論できない。おわりに書き終えて、コーヒーを淹れ直した。冷めていた。あの日から何日か経った。書いている間、ずっと考えていた。私は本当に「楽しい」のか。それとも、楽しいと思いたいだけなのか。正直、分からない。分からないまま書いた。元記事の筆者が読んだら、どう思うだろう。「お前はたまたま運が良かっただけだ」と言われるかもしれない。反論できる気がしない。私の「好き」と、あの人の「好き」は、たまたま違った。彼の文脈では彼が正しく、私の文脈では私が正しい。それだけのことだ。どちらかが間違っているわけではない。明日もたぶん、AIにコードを書かせる。レビューする。直す。動かす。それを「楽しい」と感じるかどうかは、そのときになってみないと分からない。ただ、少しだけ違うことがある。「プログラミングが好き」という言葉を使うとき、自分が何を指しているのか、前より意識するようになった。摩擦は削減対象ではない。設計対象だ。——この言葉を、自分に言い聞かせるようになった。そして、自分の「正解」も揺らぐことを知った。書く前と書いた後で、考えが変わっている。元記事の筆者の気持ちが、前より分かる気がする。揺らぐことが学びだと書いた。この記事を書くこと自体が、そうだった。「IT業界に来るな」と言われた君へ。私は「来い」とは言わない。言えない。生成AIがいつか道具になる日までは。ただ、私は来てよかった。少なくとも、今日は。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。技術が人類を幸せにするかみたいな問いは常に面白いです。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【Vul】CodeBuildの設定ミスによるフィルタバイパス]]></title>
            <link>https://www.rowicy.com/blog/vulmemo-aws-codebuild-misconfig/</link>
            <guid isPermaLink="false">https://www.rowicy.com/blog/vulmemo-aws-codebuild-misconfig/</guid>
            <pubDate>Fri, 16 Jan 2026 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[AWS CodeBuildにおける設定ミスにより、AWS提供のGitHubリポジトリがサプライチェーン攻撃のリスクにあった件]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[不動点コンビネータと無名再帰]]></title>
            <link>https://silasol.la/posts/2026-01-16-01_least_fixed_point/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2026-01-16-01_least_fixed_point/</guid>
            <pubDate>Fri, 16 Jan 2026 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[不動点コンビネータと実践的な示唆について紹介します．]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Agent Development Kit (ADK)における評価駆動型開発（EDD）]]></title>
            <link>https://sreake.com/blog/evaluation-driven-development-with-adk/</link>
            <guid isPermaLink="false">https://sreake.com/blog/evaluation-driven-development-with-adk/</guid>
            <pubDate>Thu, 15 Jan 2026 04:42:40 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。 Agent Developmen […]The post Agent Development Kit (ADK)における評価駆動型開発（EDD） first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ory Kratosで認証を委譲する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/14/140248</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/14/140248</guid>
            <pubDate>Wed, 14 Jan 2026 05:02:48 GMT</pubDate>
            <content:encoded><![CDATA[前回からの続き前回の記事では、Playwright MCPを使ったE2Eテストで5つのバグを発見した。CORS設定の欠如、JWTトークンの切り詰め、Hydraトークンとの不一致、ミドルウェアの適用漏れ、X-Tenant-Slugヘッダーの欠如。RBACの検証とOWASP Top 10との比較まで行い、マルチテナント認証システムが一通り動くようになった。前提知識: この記事はOry Hydraシリーズの続編です。OAuth2認可コードフローの基礎知識と、Login/Consent Providerの役割を理解している前提で進めます。前回記事はこちら。動く。ちゃんと動く。でも、レビューコメントが気になった。「パスワードリセット機能は？」「MFA対応の予定は？」「メール確認フローは？」全部、自分で実装しなければならない。Argon2idでパスワードをハッシュ化するコードは書いた。ログイン認証は動く。でも、パスワードを忘れたユーザーへのリセットメール送信、そのトークン管理、有効期限の検証。TOTPによる二要素認証。メールアドレス確認のフロー。これ全部、自分で実装するのか？RFCを読んでいたあの3日間を思い出した。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。同じ結論に至った。今度は認証機能についてだ。Ory Kratosという選択肢www.ory.shgithub.comOry Kratosは「ヘッドレスID管理システム」だ。Hydraが「認証をしない認可サーバー」だったことを思い出してほしい。Hydraはプロトコル層（OAuth2/OIDC）に特化し、認証は私たちに任せた。Kratosはその「任された認証」を担当する。┌─────────────────────────────────────────────────────────────┐│                     Ory Stack                               │├────────────────────────┬────────────────────────────────────┤│      Ory Kratos        │           Ory Hydra                ││   (Identity Provider)  │      (Authorization Server)        │├────────────────────────┼────────────────────────────────────┤│ - ユーザー登録         │ - OAuth2/OIDC                      ││ - ログイン認証         │ - トークン発行                     ││ - MFA (TOTP, WebAuthn) │ - クライアント管理                 ││ - パスワードリセット   │ - Consent管理                      ││ - プロフィール管理     │ - セッション管理                   ││ - メール確認           │                                    │└────────────────────────┴────────────────────────────────────┘つまり、これまでに私がRustで書いたAuthService——パスワード検証、ユーザー登録、セッション管理——これらをKratosに任せられる。アーキテクチャの変化これまでの構成を振り返る。【01-03の構成】┌─────────────┐     ┌─────────────────────┐     ┌─────────────┐│   Browser   │────▶│ Rust Login Provider │────▶│  Ory Hydra  ││             │     │ (自前実装)           │     │             │└─────────────┘     └─────────────────────┘     └─────────────┘                              │                              ▼                    ┌─────────────────────┐                    │ PostgreSQL (users)  │                    └─────────────────────┘私が書いたRust Login Providerは認証を担当していた。ユーザーテーブルも自前で管理していた。Kratosを導入すると、こうなる。【Kratos導入後の構成】┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Browser   │────▶│  Kratos UI  │────▶│  Ory Kratos │────▶│  Ory Hydra  ││             │     │  (Node.js)  │     │             │     │             │└─────────────┘     └─────────────┘     └──────┬──────┘     └─────────────┘                                               │                                               ▼                                      ┌─────────────────────┐                                      │ PostgreSQL          │                                      │ (identities)        │                                      └─────────────────────┘私が書くコードは、ほぼゼロになる。パスワード検証、ユーザー登録、セッション管理——これまでに私がRustで実装した機能は、全てKratosが提供する。私が書くのはKratosの設定ファイルと、必要に応じたUIのカスタマイズだけだ。「それって、学習した意味がないのでは？」いや、逆だ。認証システムを自前で実装した経験は、Kratosの設定を理解する上で役立った。例えば、Kratosの設定にhashers.argon2.memory: 128MBという項目がある。自前実装の経験がなければ、その意味を理解できなかっただろう。メモリコストを上げればセキュリティは向上する。しかし同時接続数の増加でOOMのリスクも上がる——この判断ができるのは、OWASPのドキュメントを読み、自分でパラメータを選んだ経験があるからだ。「ドキュメントを読めば同じでは？」——そう思うかもしれない。確かに、ドキュメントを読めば設定はできる。しかし、障害時に「この設定が原因かもしれない」と仮説を立てられるのは、自分で同じ問題に苦しんだ経験があるからだ。ログを見て「これはセッション固定化攻撃への対策が発動した」と判断できるか。エラーメッセージから「Identity Schemaの定義が間違っている」と気づけるか。これは学習効率の問題ではなく、デバッグ能力の問題だ。これまでの実装で、認証システムの複雑さを体験した。Argon2idのパラメータ設定、ユーザー列挙攻撃への対策、セッション管理の罠。58個のテストを書いて「できないこと」を確認した。だからこそ、Kratosのありがたみが分かる。そして、Kratosで問題が起きたときに対処できる。全員が自前実装を経験すべきとは言わない。しかし、チームに1人は「中身を理解している人」がいた方がいい。Docker Composeで動かすwww.ory.com実際に動かしてみよう。services:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: postgres      POSTGRES_PASSWORD: secret      POSTGRES_DB: postgres    volumes:      - postgres_data:/var/lib/postgresql/data      - ./init.sql:/docker-entrypoint-initdb.d/init.sql:ro  # 後述の初期化スクリプト    healthcheck:      test: ["CMD-SHELL", "pg_isready -U postgres -d postgres"]      interval: 5s      timeout: 5s      retries: 5    networks:      - ory  kratos-migrate:    image: oryd/kratos:v1.3.1    environment:      DSN: postgres://postgres:secret@postgres:5432/kratos?sslmode=disable    volumes:      - ./kratos:/etc/config/kratos:ro    command: migrate sql -e --yes --config /etc/config/kratos/kratos.yml    depends_on:      postgres:        condition: service_healthy    networks:      - ory  kratos:    image: oryd/kratos:v1.3.1    environment:      DSN: postgres://postgres:secret@postgres:5432/kratos?sslmode=disable      LOG_LEVEL: debug      SERVE_PUBLIC_BASE_URL: http://localhost:4433      SERVE_ADMIN_BASE_URL: http://localhost:4434    volumes:      - ./kratos:/etc/config/kratos:ro    command: serve all --dev --config /etc/config/kratos/kratos.yml    ports:      - "4433:4433"  # Public API      - "4434:4434"  # Admin API    depends_on:      kratos-migrate:        condition: service_completed_successfully    healthcheck:      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4433/health/ready"]      interval: 10s      timeout: 5s      retries: 5    networks:      - ory  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://postgres:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy    networks:      - ory  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://postgres:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:4455/consent      URLS_LOGIN: http://localhost:4455/login      URLS_LOGOUT: http://localhost:4455/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - "4444:4444"  # Public API      - "4445:4445"  # Admin API    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4444/health/ready"]      interval: 10s      timeout: 5s      retries: 5    networks:      - ory  kratos-ui:    image: oryd/kratos-selfservice-ui-node:v1.3.1    environment:      PORT: 4455      KRATOS_PUBLIC_URL: http://kratos:4433      KRATOS_BROWSER_URL: http://localhost:4433      HYDRA_ADMIN_URL: http://hydra:4445      COOKIE_SECRET: super-secret-cookie-secret-32chars      CSRF_COOKIE_NAME: ory_csrf_ui      CSRF_COOKIE_SECRET: super-secret-csrf-secret-32-chars    ports:      - "4455:4455"    depends_on:      kratos:        condition: service_healthy      hydra:        condition: service_healthy    networks:      - oryvolumes:  postgres_data:networks:  ory:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMやCOOKIE_SECRETに32文字以上の暗号学的に安全な値を設定してください。サービスが6つある。PostgreSQL、KratosとHydraそれぞれのmigrate/serveサービス、そしてKratos UI。以前の自前実装（auth-provider）はKratosに置き換わった。ポイントはkratos-uiだ。これはOry公式が提供するセルフサービスUI。ログイン画面、登録画面、パスワードリセット画面などが含まれている。「自分でUI書かなくていいの？」開発環境ではこれで十分だ。本番環境では、このUIを参考に自前のUIを実装できる。Kratosの「ヘッドレス」設計により、UIは完全に切り離されている。github.comKratos設定ファイルの解説Kratosの設定ファイルkratos.ymlを見てみよう。version: v1.3.1dsn: memoryserve:  public:    base_url: http://localhost:4433/    cors:      enabled: true      allowed_origins:        - http://localhost:4455  admin:    base_url: http://localhost:4434/selfservice:  default_browser_return_url: http://localhost:4455/  allowed_return_urls:    - http://localhost:4455    - http://localhost:4444  methods:    password:      enabled: true    totp:      enabled: true      config:        issuer: OryKratosVerification    lookup_secret:      enabled: true    link:      enabled: true    code:      enabled: true  flows:    error:      ui_url: http://localhost:4455/error    settings:      ui_url: http://localhost:4455/settings      privileged_session_max_age: 15m    recovery:      enabled: true      ui_url: http://localhost:4455/recovery      use: code    verification:      enabled: true      ui_url: http://localhost:4455/verification      use: code      after:        default_browser_return_url: http://localhost:4455/    logout:      after:        default_browser_return_url: http://localhost:4455/login    login:      ui_url: http://localhost:4455/login      lifespan: 10m    registration:      lifespan: 10m      ui_url: http://localhost:4455/registration      after:        password:          hooks:            - hook: sessionlog:  level: debug  format: text  leak_sensitive_values: truesecrets:  cookie:    - super-secret-cookie-secret-32chars  cipher:    - super-secret-cipher-key-32-charsciphers:  algorithm: xchacha20-poly1305hashers:  algorithm: argon2  argon2:    parallelism: 1    memory: 128MB    iterations: 2    salt_length: 16    key_length: 16identity:  default_schema_id: default  schemas:    - id: default      url: file:///etc/config/kratos/identity.schema.jsoncourier:  smtp:    connection_uri: smtps://test:test@mailslurper:1025/?skip_ssl_verify=trueoauth2_provider:  url: http://hydra:4445セルフサービスフローselfservice:  methods:    password:      enabled: true    totp:      enabled: true以前、私がRustで実装したパスワード認証。Kratosではpassword: enabled: trueの一行で有効になる。TOTPも同様だ。以前は「MFA対応の予定は？」という質問に答えられなかった。Kratosなら設定1つで有効化できる。パスワードハッシュhashers:  algorithm: argon2  argon2:    parallelism: 1    memory: 128MB    iterations: 2    salt_length: 16    key_length: 16以前、私はArgon2::default()を使った。Kratosも同じArgon2を使っている。設定値を明示的に指定することで、チーム内で「なぜこのパラメータか」を共有できる。cheatsheetseries.owasp.orgHydra連携oauth2_provider:  url: http://hydra:4445これが最も重要な設定だ。KratosがHydraのAdmin APIに接続し、login_challengeを処理する。以前は私がRustでHydraClientを実装し、accept_loginを呼び出していた。Kratosはこれを自動で行う。https://www.ory.com/docs/kratos/self-hosted/hydra-integrationwww.ory.comIdentity Schemaの設計Kratosはユーザー情報を「Identity」として管理する。その構造はJSON Schemaで定義する。{  "$id": "https://schemas.ory.sh/presets/kratos/identity.email.schema.json",  "$schema": "http://json-schema.org/draft-07/schema#",  "title": "Person",  "type": "object",  "properties": {    "traits": {      "type": "object",      "properties": {        "email": {          "type": "string",          "format": "email",          "title": "E-Mail",          "ory.sh/kratos": {            "credentials": {              "password": {                "identifier": true              },              "totp": {                "account_name": true              }            },            "recovery": {              "via": "email"            },            "verification": {              "via": "email"            }          }        },        "name": {          "type": "object",          "properties": {            "first": {              "title": "First Name",              "type": "string"            },            "last": {              "title": "Last Name",              "type": "string"            }          }        }      },      "required": ["email"],      "additionalProperties": false    }  }}ory.sh/kratosという拡張プロパティが特徴的だ。credentials.password.identifier: true — このフィールドがログインIDになるrecovery.via: email — パスワードリセットはこのメールアドレスに送信されるverification.via: email — メール確認もこのアドレスに送信される以前、私はユーザーテーブルを自前で設計した。Kratosではスキーマを宣言的に定義するだけでいい。www.ory.com実際にハマったことでも、最初のdocker compose upは失敗した。データベースが存在しないFATAL: database "kratos" does not exist (SQLSTATE 3D000)KratosとHydraはそれぞれkratosとhydraという名前のデータベースを期待する。でも、PostgreSQLコンテナはpostgresデータベースしか作らない。解決策は初期化スクリプトだ。-- init.sqlCREATE DATABASE kratos;CREATE DATABASE hydra;# docker-compose.ymlpostgres:  volumes:    - ./init.sql:/docker-entrypoint-initdb.d/init.sql:roPostgreSQLは/docker-entrypoint-initdb.d/にあるSQLファイルを起動時に実行する。これで両方のデータベースが作成される。最初は「なぜ自動で作ってくれないんだ」と思った。おそらく、本番環境では既存のデータベースサーバーに接続することが多いからだろう。いずれにせよ、初期化スクリプトで解決できる。ポート競合Bind for 0.0.0.0:4444 failed: port is already allocated以前の記事で作ったory-hydra-rust環境がまだ動いていた。同じポート4444を使おうとして衝突。# 他の環境を停止cd ../ory-hydra-rust && docker compose down複数のOry環境を並行して動かす時は、ポートを変える必要がある。開発環境では素直に片方を停止した方がいい。Kratosが教えてくれた盲点E2EテストでTestPassword123!というパスワードを使おうとした。{  "id": 4000034,  "text": "The password has been found in data breaches and must no longer be used.",  "context": {    "breaches": 3330  }}KratosはデフォルトでHave I Been PwnedのAPIを使い、パスワードが過去のデータ漏洩に含まれていないかチェックする。TestPassword123!は3,330件の漏洩で見つかっていた。haveibeenpwned.comなぜ私は思いつかなかったのか。振り返ると、私の58個のテストは「攻撃者がシステムに対して行う操作」をテストしていた。間違ったパスワードでログインできないこと存在しないユーザーで情報が漏れないこと同時登録で競合状態が起きないことこれは全て「システムへの攻撃」に対するテストだ。攻撃者がシステムの外側から突破を試みるシナリオ。HIBPチェックは視点が異なる。「ユーザーが持ち込むリスク」に対処している。ユーザーが「password123」を使おうとするユーザーが他のサービスで使い回しているパスワードを登録するユーザーが過去に漏洩したパスワードを選ぶこれはシステムへの攻撃ではない。ユーザー自身がリスクを持ち込むシナリオだ。私はこのカテゴリを完全に見落としていた。なぜ見落としたのか。おそらく「ユーザーは正しく行動する」という暗黙の前提があった。パスワード強度のバリデーション（8文字以上、英数字混合など）を入れれば十分だと思っていた。でも、TestPassword123!は典型的な強度バリデーションを通過する。英大文字、英小文字、数字、記号、8文字以上。全ての条件を満たしている。にもかかわらず、3,330件の漏洩で見つかっている。強度バリデーションは「推測しやすいか」をチェックする。HIBPチェックは「既に漏洩しているか」をチェックする。両者は補完関係にある。Kratosを使うことで、私が想定していなかった脅威カテゴリまでカバーできる。これが「専門家が作ったツールを使う」ことの価値だ。自分の盲点を、他者の知見で補える。E2Eテストではタイムスタンプを含むランダムなパスワードを生成して回避した。TEST_PASSWORD="Kratos$(date +%s)E2E!Xk9#mN"本番環境では、この機能を有効にしたまま運用すべきだ。ユーザーに「このパスワードは漏洩しています」と伝えることで、アカウント乗っ取りのリスクを下げられる。環境の起動と動作確認初期化スクリプトを追加した状態で起動する。docker compose up -ddocker compose logs -fヘルスチェック用エンドポイントにアクセスしてみる。# Kratosのヘルスチェックcurl http://localhost:4433/health/ready# {"status":"ok"}# Hydraのヘルスチェックcurl http://localhost:4444/health/ready# {"status":"ok"}両方ともokが返ってきた。セルフサービスフローの確認ブラウザでhttp://localhost:4455/registrationにアクセスする。登録画面が表示される。メールアドレスとパスワードを入力して登録。次にhttp://localhost:4455/loginにアクセス。ログイン画面が表示される。先ほど登録した認証情報でログイン。ログイン成功。これだけだ。拍子抜けするほど簡単だった。以前、私は以下を実装した。AuthService::register() — ユーザー登録AuthService::authenticate() — パスワード検証login_page() — ログインフォームのHTMLlogin_submit() — フォーム送信処理58個のテストKratosでは、設定ファイルを書くだけでこれらが全て動く。OAuth2フローの確認OAuth2クライアントを作成する。docker compose exec hydra hydra create oauth2-client \  --endpoint http://localhost:4445 \  --grant-type authorization_code \  --response-type code \  --scope openid,profile,email \  --redirect-uri http://localhost:8080/callback \  --name "Test Client"クライアントIDとシークレットが出力される。ブラウザで認可エンドポイントにアクセスする。http://localhost:4444/oauth2/auth?client_id=<CLIENT_ID>&response_type=code&scope=openid+profile+email&redirect_uri=http://localhost:8080/callback&state=test-stateHydraがKratos UIにリダイレクトKratos UIがログイン画面を表示ログイン成功後、Kratosがlogin_challengeをHydraに送信HydraがConsent画面にリダイレクトConsent承認後、認可コードがコールバックURLに返される以前、私がRustで実装したlogin_submit()の処理を、Kratosが自動で行っている。// 前回の実装（不要になった）pub async fn login_submit(    State(state): State<AppState>,    Form(form): Form<LoginForm>,) -> Result<Redirect, AppError> {    let user = state.auth.authenticate(&form.email, &form.password).await?;    let completed = state.hydra        .accept_login(&form.login_challenge, &user.id.to_string(), false)        .await?;    Ok(Redirect::to(&completed.redirect_to))}このコードは、もう書く必要がない。E2Eテストで確認したこと実際にAPIを叩いて、フロー全体が動くことを確認した。Registration Flow# 1. フローを初期化curl -s -X GET "http://localhost:4433/self-service/registration/api"# Flow ID: 77ff9653-ccd2-4f91-aeea-8fbb4d67fce7# 2. 登録を実行curl -s -X POST "http://localhost:4433/self-service/registration?flow=$FLOW_ID" \  -H "Content-Type: application/json" \  -d '{    "method": "password",    "password": "Kratos1767517527E2E!Xk9#mN",    "traits": {      "email": "e2etest@example.com",      "name": { "first": "E2E", "last": "Test" }    }  }'Registration successful!Identity ID: 169e0834-4b45-441f-95f8-5adc45d8a3e9Email: e2etest-1767517527@example.comSession Token: ory_st_WugR5gisST7SO...Kratosのセルフサービスフローは2段階構成だ。まずフローを初期化してFlow IDを取得し、そのIDを使ってデータを送信する。これにより、CSRFトークンやフローの有効期限が管理される。Login Flow# 1. フローを初期化curl -s -X GET "http://localhost:4433/self-service/login/api"# 2. ログインを実行curl -s -X POST "http://localhost:4433/self-service/login?flow=$FLOW_ID" \  -H "Content-Type: application/json" \  -d '{    "method": "password",    "identifier": "e2etest@example.com",    "password": "Kratos1767517527E2E!Xk9#mN"  }'Login successful!Session ID: 8b97d548-8436-48ee-b4fd-8e1c643dac04Session Token: ory_st_ty15oU5JLIABh...Session Verificationcurl -s -X GET "http://localhost:4433/sessions/whoami" \  -H "Authorization: Bearer $SESSION_TOKEN"Session valid!Identity: e2etest-1767517527@example.comActive: trueセッショントークンを使って/sessions/whoamiを呼ぶと、現在のセッション情報が返ってくる。これは以前私がRustで実装したJwtService::verify()に相当する機能だ。OAuth2 Authorization Flow# OAuth2クライアントを作成curl -s -X POST "http://localhost:4445/admin/clients" \  -H "Content-Type: application/json" \  -d '{    "client_id": "e2e-test-client",    "client_secret": "e2e-test-secret",    "grant_types": ["authorization_code"],    "response_types": ["code"],    "scope": "openid profile email",    "redirect_uris": ["http://localhost:8080/callback"]  }'認可エンドポイントにアクセスすると、HydraがKratos UIにリダイレクトする。http://localhost:4444/oauth2/auth?client_id=e2e-test-client&...  ↓http://localhost:4455/login?login_challenge=Xv84rhGlXQQrVNL7SlICdNobNbYvcK7z8il...login_challengeパラメータが付与されている。Kratos UIはこのチャレンジを使ってHydraと連携し、認証完了後に適切なリダイレクトを行う。E2Eテスト結果サマリー テスト項目  結果  Registration Flow  成功  Login Flow  成功  Session Verification  成功  OAuth2 Client Setup  成功  OAuth2 Authorization Flow  成功（login_challenge生成確認） 全てのフローが期待通りに動作した。以前の自前実装と比較して、コード量はゼロになり、機能は増えた。自前実装との比較 観点  自前実装（02）  Kratos  パスワード認証  Argon2id実装  組み込み  MFA  未実装  TOTP, WebAuthn対応  パスワードリセット  未実装  フロー組み込み  メール確認  未実装  フロー組み込み  ソーシャルログイン  未実装  OIDC対応  漏洩パスワードチェック  未実装  HIBP連携  ログイン画面  HTML手書き  公式UI or 自前  セキュリティテスト  58個書いた  Oryが検証済み  学習コスト  Rust知識  Kratos設定  カスタマイズ性  完全自由  スキーマ/フック 特筆すべきは漏洩パスワードチェックだ。Have I Been Pwnedとの連携により、過去のデータ漏洩で流出したパスワードを拒否できる。これは以前書いた58個のテストでも考慮していなかった観点だ。Kratosを使うことで、私が思いつかなかったセキュリティ対策まで自動的に適用される。自前実装は無駄だったのか？いや、違う。以前の実装で学んだこと——Argon2idのパラメータ、ユーザー列挙攻撃への対策、タイミング攻撃の考慮——これらはKratosの設定を理解する上で役立った。「なぜこの設定があるのか」が分かるのは、自分で実装した経験があるからだ。いつKratosを使うべきかKratosを選ぶかどうかは、3つの軸で判断する。技術的要件: カスタマイズの複雑さはどの程度か。Kratosはフック機構やIdentity Schemaで柔軟性を提供するが、「3回目のログインでは必ずCAPTCHAを表示」のような独自フローは難しい。標準的な認証フローなら、Kratosで十分だ。組織的要件: チームにセキュリティ専門家がいるか。いないなら、Kratosに任せた方がいい。脆弱性対応、ベストプラクティスの追従——これらを自前でやるには専門性が必要だ。SOC2やISO27001の監査でも「専門企業の製品を使っています」と答えられる。ビジネス要件: 認証がコア価値か否か。パスワードマネージャーや認証SaaSなら、自前実装に意味がある。ECサイトや社内ツールなら、認証に時間をかけるより本業に集中すべきだ。私がこれまで関わってきたプロジェクトの8割は、最初からKratosで良かった。残り2割は、レガシーシステムとの統合が複雑すぎるか、認証自体がプロダクトの価値だった。今回のケースでは、学習目的で自前実装から始めたが、本番プロジェクトなら最初からKratosを選ぶ。認証に独自性は不要で、チームにセキュリティ専門家もいない——判断は明確だ。次回予告Kratosを導入したことで、認証（Authentication）は解決した。ユーザーはログインできる。セッションも管理される。でも、ログインしたユーザーが「何をできるか」は、まだ決まっていない。認証と認可は別物だ。認証は「誰であるか」を確認する。認可は「何ができるか」を判断する。次回は、Ory Ketoを使ってZanzibarモデルによる認可システムを構築する。おわりに正直に言うと、Kratosの設定を書いている時、何度か「自分で実装した方が分かりやすいのでは」と思った。YAMLの設定項目が多い。ドキュメントを何度も読み返した。でも、動いた時の感覚が違う。これまでに私が書いた数百行のRustコード。それがYAML数十行で置き換わった。しかも、MFAやパスワードリセットなど、私が「次回以降に実装する」と書いていた機能が、既に含まれている。「自前で作ることの非合理性」第1回で書いた言葉を思い出した。認可サーバーだけでなく、認証システムも同じだった。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Kratosに移行しても、設定の検証やアップグレード対応、障害時の判断は残る。責任が消えるのではなく、「実装の責任」から「選定と運用の責任」に形を変える。その上で、認証の基本的な部分——パスワード認証、MFA、セッション管理——は、毎回ゼロから考える問題ではなくなった。そして、もう1つ学んだことがある。Have I Been Pwnedの件だ。私は58個のテストを書いて「完璧だ」と思っていた。でも、「ユーザーが持ち込むリスク」という視点が完全に抜けていた。専門家が作ったツールを使う価値は、自分の盲点を補えることにある。レビューコメントに返信しよう。「パスワードリセット機能は？」——Kratosで対応します。この記事が参考になれば、読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料Ory KratosOry Kratos GitHubOry Kratos DocumentationKratos QuickstartIdentity SchemaHydra IntegrationOry HydraOry Hydra DocumentationLogin and Consent FlowセキュリティガイドラインOWASP Password Storage Cheat SheetOWASP Authentication Cheat Sheet検証環境ory-kratos-verification（GitHub）]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Error ReportingとCloud Runでアプリエラーをいい感じにグループ化してGitHubイシューにする]]></title>
            <link>https://zenn.dev/kimitsu/articles/report-error-to-github</link>
            <guid isPermaLink="false">https://zenn.dev/kimitsu/articles/report-error-to-github</guid>
            <pubDate>Mon, 12 Jan 2026 02:52:23 GMT</pubDate>
            <content:encoded><![CDATA[Error Reporting とは皆さん、Google Cloud の Error Reporting はご存知でしょうか。あまり知られていないのではないかなと思っています。アプリからは日々エラーが出ておりエンジニアはそれに対応する必要がありますが、エラーというものは同じ原因で複数回出るものです。ログを眺めていて同じようなエラーがたくさん並んでいてもあまり情報は増えません。Error Reporting はアプリケーションのエラーログを収集し、同じ原因のエラーをグループ化してくれるサービスです。[1]例えば以下の例では同じエラーが 3 回出ていますが、Error Rep...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、辞めないなら頑張れ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/12/003013</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/12/003013</guid>
            <pubDate>Sun, 11 Jan 2026 15:30:13 GMT</pubDate>
            <content:encoded><![CDATA[はじめに先週、「おい、辞めるな」という記事を書きました。syu-m-5151.hatenablog.com思った以上に反響がありました。何人かから連絡をもらいました。辞めないことにしました、考えるきっかけになりました、と。ありがたかったです。嬉しかった、と言っていいです。たぶん。ただ、何か落ち着きませんでした。辞めないと決めた。それは分かった。で、その次は。辞めないと決めただけで、何かが変わるわけではありません。私がそうだったからです。辞めないと決めた後も、何も変わりませんでした。評価は上がらない。漠然としたモヤモヤは消えない。夜遅くまでコードを書いた。勉強会に参加した。資格を取った。ブログを書いた。技術力を上げれば認められる。そう信じていました。評価は上がりませんでした。振り返ると、私は頑張り方を間違えていたのです。もっと正確に言えば、評価の構造を理解していませんでした。良い仕事をすれば評価される。そう思っていました。でも、評価者には評価者の論理があります。組織には組織の論理があります。その構造を理解せずに、がむしゃらに頑張っても、報われません。「おい、辞めるな」の最後に、「選んだ道を、正解にしていく過程があるだけだ」と書きました。辞めないと決めた。その選択を正解にするために、何をすればいいのか。この文章は、それを書くために開きました。ただ、書きながらも思います。これが誰かの役に立つのかは、分かりません。分からないまま、書いています。先に断っておきます。この記事は、まだ頑張れる余力がある人に向けて書いています。すでに消耗している人、頑張る気力すらない人には、この記事は届かないだろう。それについては、最後に書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。見えない努力まず、頑張り方を間違えている人が多いです。私もそうでした。インフラのトラブルを未然に防いだことがあります。監視アラートの傾向を見て、「これ、来週やばいことになる」と気づきました。週末に対応して、障害を防ぎました。本番で落ちていたら大騒ぎでした。サービスが止まれば、ビジネスに直接影響が出ます。ユーザーからのクレームが殺到します。深夜に全員が叩き起こされます。そういう未来を、私は未然に防ぎました。でも、月曜日、何事もなかったように仕事が始まりました。誰も何も言いませんでした。障害が起きなかったという「非イベント」は、誰の記憶にも残りません。チームの技術的負債を黙々と返済したことがあります。3ヶ月かけて、複雑なモジュールをリファクタリングしました。スパゲッティコードを解きほぐし、テストカバレッジを上げ、ドキュメントを整備しました。誰かがこの負債を返さなければ、いずれチーム全体が身動きを取れなくなります。そう思って、地道に片付けました。でも、リリース直前に「いつの間にかキレイになってた」と言われただけでした。3ヶ月の努力が、「いつの間にか」で片付けられました。いつの間にか、俺も消えていました。私は「良い仕事をしていれば、いつか評価される」と思っていました。黙々と価値を出していれば、誰かが見ている。実力で認められる。そう信じていました。甘かったです。現実はこうです。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知りません。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われます。障害を未然に防いでも、障害が起きなかったという「非イベント」は記憶に残りません。これは不公平だと思うだろう。私もそう思いました。私は2年間嘆いていました。居酒屋で同僚と「この会社の評価制度はおかしい」と言い合ったこともあります。「なんで俺の仕事が評価されないんだ」と愚痴りました。言うたびに少し楽になりました。だけど、翌日も同じ状況が続きました。嘆きは鎮痛剤です。痛みを一時的に和らげますが、原因は治りません。この構造を理解した上で、どう振る舞うか。 それが「頑張り方」です。構造を知れここで公平を期しておきます。仕組みの問題は確かにあります。OKRの目標設定が形骸化している。評価者によって評価がブレる。数値化できない仕事が過小評価される。これは仕組みを運営する上で抱える問題です。「人は他人を正しく評価できる」——これは幻想です。同じ人の同じ仕事を見ても、評価者が違えば評価は違います。同じアウトプットで、上司が変わっただけで評価が2段階変わることもあります。私です。絶対的に客観的な評価など存在しません。そもそも、数値で測ろうとした瞬間、測定対象は変質します。コミット数を測り始めたチームを見たことがあります。結果、コミットが細切れになりました。バグ修正件数を測れば、バグを作った人が有利になります。プルリクエストの数を測れば、小さなPRを乱発する人が評価されます。グッドハートの法則と呼ばれる現象です。「指標が目標になると、その指標は機能しなくなる」。OKRを導入したとき、私はこの法則を知りませんでした。知っていたら何か変わったかと言われると、たぶん変わりませんでした。人間だから。エンジニアリングの現場では、これが顕著に現れます。これは事実です。認めましょう。その上で、自分に何ができるかを考えます。仕組みの問題を批判するのは簡単です。でも、評価制度を変えるのは難しい。上司を変えることはできません。待っていても変わりません。冒頭で書いた通り、私はこれをやっていました。仕組みの問題を指摘して溜飲を下げる。鎮痛剤を飲み続けて、原因を放置していました。仕組みがおかしいのは事実です。でも、仕組みは変えられない。自分は変えられる。 それが「頑張る」ということです。変えられないものに時間を使うほど、あなたの人生は長くありません。——と書いて、立ち止まります。「結局、自己責任論じゃないか」と言われるだろう。構造の問題を認識しながら、最後に「個人が変われ」と言っている。評価されないのは構造の問題なのに、「お前の頑張り方が悪い」と言っている。それは自己責任論の強化じゃないか、と。正直に言えば、その批判は当たっています。私は構造の問題を認識しながら、「構造を変えろ」とは言いませんでした。「構造の中でうまくやれ」と言いました。それは、構造を温存することに加担しています。これは私の限界です。私が書けるのは、私が経験したことだけです。構造を変えることに成功した人が、その方法を書いてくれることを願います。ただ、1つだけ言い訳させてください。私は「評価されないのはお前のせいだ」とは言っていません。「評価制度には限界がある」「客観的評価は存在しない」と、繰り返し書きます。その上で、「構造が変わらない中で、個人に何ができるか」を書いています。自己責任論と言われれば、そうだろう。でも、構造が変わるのを待っていても、あなたの評価は上がりません。変わらない構造の中で、今日をどう生きるか。それを考えるしかありませんでした。しかし、重要な注意点があります。仕組みの問題が大きすぎる時は、「辞める」が正解のことがあります。 個人の努力で覆せない構造もあります。それを見極める目も必要です。評価制度が必ず歪む理由評価制度が歪むのは、設計者の能力不足ではありません。測定されるものは、測定によって変質するからです。どの制度も、導入した瞬間に歪み始めます。完璧な評価制度は原理的に存在しません。この事実は、あなたを責めるためにあるのではありません。あなたを解放するためにあります。「自分が無能だから評価されない」という思い込みから解放され、「制度の限界を前提に、どう動くか」という問いに切り替わります。評価の幻想上司は、神でもエスパーでも上位存在でもありません。人間です。君よりも少しだけ観点の多い人間です。人外だと思っている上司も、人間であり、認知には限界があります。これは「上司が無能だ」という話ではありません。人間である限り、客観的評価は原理的に不可能だという話です。なぜ「客観的評価」は不可能なのか「客観的評価」という言葉には、2つの前提があります。「評価すべき対象を正確に観察できる」という前提と、「観察したものを正確に評価できる」という前提です。どちらも成り立ちません。観察の問題から見てみましょう。上司があなたの仕事のうち、何%を直接観察しているでしょうか。会議での発言。Slackでのやり取り。プルリクエスト。これは観察できます。でも、設計を考えている時間。問題を切り分けている時間。ドキュメントを読んでいる時間。これは見えません。上司が見ているのは、あなたの仕事の氷山の一角に過ぎません。観察できるものだけを見て、全体を評価している。これは観察者の怠慢ではありません。構造的に避けられない限界です。比較の問題もあります。評価とは、本質的に比較です。Aさんは「期待以上」、Bさんは「期待通り」。この判断をするには、AさんとBさんを比較する必要があります。でも、2人の仕事が違えば、比較は困難になります。バックエンドで高負荷対策をしたAさんと、フロントエンドで複雑なUIを実装したBさん。どちらが「より価値がある」か。答えはありません。比較不可能なものを比較しています。上司は無理やり比較し、順位をつけます。その順位に「客観性」などありません。観察者効果という問題もあります。観察すること自体が観察対象に影響を与えるというものです。「評価される」と意識した瞬間、行動が変わります。評価されやすい仕事を選ぶ。見える形で成果を出そうとする。「本当の仕事ぶり」を観察しているわけではありません。「評価を意識した仕事ぶり」を観察しています。上司の認知バイアス観察の限界に加えて、観察したものを処理する段階でもバイアスがかかります。直近バイアス: 1年間を均等に覚えていません。評価直前の出来事が記憶に残ります。4月に素晴らしい仕事をしても、12月の評価面談では薄れています。11月に目立つ失敗をすると、それが印象を決めます。ハロー効果: 1つの良い印象が全体評価を引き上げます。1つの失敗が全体を引き下げます。障害対応で活躍すると、「この人は優秀だ」と思われます。その印象が、関係のない能力の評価にも影響します。確証バイアス: 一度「優秀」と思うと優秀な証拠ばかり目に入ります。「ダメ」も同様です。最初の印象が固定され、それを覆す情報は無視されます。これは上司の能力不足ではありません。人間の認知システムに組み込まれた特性です。どんなに優秀な上司でも、これらのバイアスから完全に逃れることはできません。ここで、1つ確認しておきたいです。「自分は正しく評価されていない」と感じたことがあるでしょうか。もしあるなら、それは被害妄想ではありません。構造的に、完全に正しい評価など存在しません。上司がどんなに優秀でも、認知バイアスからは逃れられません。あなたの感覚は、間違っていません。評価基準自体が「客観的」ではないより根本的な問題があります。評価基準自体が客観的ではないのです。「技術力」「コミュニケーション力」「リーダーシップ」——評価シートに並ぶこれらの言葉は、一見客観的に見えます。でも、その定義は人によって違います。「技術力が高い」とは何か。コードの品質が高いこと？難しい問題を解決できること？新しい技術をキャッチアップするのが速いこと？幅広い技術に詳しいこと？上司によって、重視する側面が違います。つまり、評価基準そのものが社会的に構成されたものです。「何を価値とするか」は、文化、組織、時代によって変わります。普遍的な基準などありません。私は異動で気づきました。前のチームでは「期待以上」と評価されていました。技術的な深さを評価してくれる上司でした。異動した先では「成長途上」と評価されました。新しい上司はチームへの影響力を重視していました。スキルは変わっていません。変わったのは上司です。「客観的評価」を求めるより、やるべきこと評価とは「私が何をしたか」ではなく「上司が私をどう見るか」です。この事実を受け入れると、行動が変わります。「客観的に見れば、私は評価されるべきだ」という主張は意味がありません。客観的な視点など存在しないからです。存在するのは、上司の視点だけです。だから、「客観的評価」を求めるのはやめました。代わりに、上司が何を見ているかを理解することに注力しました。上司は何を重視するか。何に反応するか。何を見落としているか。それを理解した上で、上司に伝わる形で成果を見せます。これは媚びを売ることとは違います。上司の視界に入る努力をしているだけです。上司の視点を理解するには、いくつかの問いを考えるといいです。「この上司は何を『良い仕事』だと思っているか」「この上司は何にストレスを感じているか」「この上司は、上からどんなプレッシャーを受けているか」。これらを理解すると、上司が何を見て、何を見落としているかが見えてきます。組織の論理評価制度と評価者の心理を理解したら、次は組織の論理を理解しましょう。組織には、個人の論理とは異なる、独自の論理があります。この論理を理解しないと、「なぜ評価されないのか」が分からないままになります。組織は「最適化」で動く組織は、個人の幸福を最大化するために存在しているわけではありません。組織の存続と成長を最適化するために存在しています。この当たり前の事実を、意外と多くの人が忘れています。評価制度も、昇進制度も、給与制度も、すべて「組織の最適化」のために設計されています。「個人が納得するか」は、二次的な目標に過ぎません。もちろん、個人が納得しなければ離職が増えるから、ある程度は配慮されます。でも、最優先ではありません。だから、「公平な評価」を期待すると、裏切られます。組織が目指しているのは公平な評価ではなく、組織にとって都合の良い行動を引き出す評価だからです。昇進はゼロサムゲームである昇進枠は有限です。誰かが昇進すれば、誰かは昇進しません。「今期は枠がなかった」と言われたことがある人もいるでしょう。それは、あなたの実力の問題ではなく、構造の問題です。予算も同じです。パイの大きさは決まっています。問題は、パイをどう切り分けるかです。だから、昇給交渉は「自分の価値を証明する」だけでは不十分です。「なぜ自分に配分を増やすべきか」を説明する必要があります。自分に正直に向き合ってください。あなたが昇進することで、上司やチームにはどんな具体的なメリットがあるか。「この人を昇進させると、〇〇という効果があります」と言える材料を、あなた自身が上司に渡してください。政治は「資源配分の闘争」である「誰を昇進させるか」は、技術力だけで決まりません。上司と上司の上司の関係。部門間の力学。人事部の意向。様々な要素が絡み合います。「政治なんて関係ない」と思いたい気持ちは分かります。技術力で勝負したい。でも、組織で働く以上、政治は存在します。政治とは何か。限られた資源を巡る配分の闘争です。資源とは、予算、人員、プロジェクト、昇進枠、注目、発言力。これは有限です。誰かが得れば、誰かが失います。この配分を決めるプロセスが、政治です。政治を「汚いもの」と見なすのは、的外れです。資源が有限である限り、配分のプロセスは必ず存在します。それを「政治」と呼ぼうが呼ぶまいが、現象は消えません。政治を無視しても、政治はあなたに影響します。あなたが政治を無視しても、他の誰かが政治を使って資源を獲得すれば、あなたに回る資源は減ります。だから、政治を理解した上で動いた方がいいです。しかし、誤解しないでください。「政治を理解してください」は「政治に加担してください」という意味ではありません。「政治ゲームの名プレイヤーになってください」とも言っていません。政治の存在を認識し、その中で自分がどう動くかを考えるということです。組織の論理と個人の論理は違うここまでの話をまとめると、こうなります。組織は「組織の最適化」で動きます。個人の最適化ではありません昇進枠は有限です。ゼロサムゲームです予算は配分の問題です。パイの切り分けです政治は資源配分の闘争です。避けられませんこれらを理解すると、「なぜ評価されないのか」の見え方が変わります。「自分は良い仕事をしている」は、個人の論理です。組織の論理から見ると、「良い仕事をしている人」は他にもいます。問題は、有限の資源を誰に配分するかです。だから、「良い仕事をすれば評価される」は半分しか正しくありません。正確には、「良い仕事をした上で、資源を配分すべき理由を説明できれば評価される」です。ここまで読んで、息苦しくなっただろう。評価制度には限界があります。客観的評価は存在しません。組織は個人の幸福を最大化しません。昇進はゼロサムゲームです。政治は避けられません。厳しい現実です。でも、現実を知ることは、現実に絶望することではありません。構造を知らなければ、暗闘の中で闘っているようなものです。構造を知れば、どこに光があるか見えます。ここからは、その光に向かって動く方法を書きます。やるべきことは、大きく3つあります。「どこを見るか」を変えること、「対話」を通じて認識を揃えること、「見せる」ことで存在を証明することです。チームを見ろ組織の論理を理解したら、次は「どこを見るか」を変えることです。「どの会社で働くか」が大事だと思われています。でも、本当に大事なのは「どのチームで働くか」です。従業員が「ここで働くのをやめよう」と決める時、この「ここ」は会社ではありません。チームです。会社は好きだがチームが合わなくて異動する人がいます。逆に、会社の方針には疑問があるがチームが良くて残る人もいます。これは新卒就職活動をされている方や、転職を考えている方に特に知っておいてもらいたいことです。企業文化が良い会社でも、自分が配属されるチームの雰囲気が良いとは限りません。評価も同じです。「この会社の評価制度」より、「直属の上司の評価パターン」の方が、あなたの評価に直接影響します。会社の評価制度がどれだけ整っていても、その制度を運用するのは上司です。上司が制度を正しく運用しなければ、制度の意味はありません。逆も同じです。評価制度が多少おかしくても、上司が良ければ、適切に評価される可能性があります。だから、転職先を選ぶときも、残るか辞めるかを判断するときも、「会社」という抽象的な単位で考えないでください。どのチームに入るか。誰が上司になるか。 その具体的な単位で考えてください。対話しろ嘆きは鎮痛剤だと書きました。では、対話は何か。対話は手術です。痛いし、面倒だし、時間がかかります。でも、原因を取り除ける可能性があります。対話が必要な理由は単純です。あなたと上司は、別の人間だからです。別の経験を持ち、別の価値観を持ち、別の情報を持っています。この情報の非対称性を埋める方法は、対話しかありません。見えている世界の違いを理解する上司と話が通じないとき、「上司が悪い」と思いがちです。でも違います。部下と上司では見えている世界が違います。自分から見ると理不尽な判断でも、上司の立場から見ると合理的なことがあります。上司には上司のプレッシャーがあります。部門の目標があります。上からの期待があります。その世界の中で、上司は合理的に動いています。その上で話せないことがあります。これは「上司の判断を正当化してください」という話ではありません。上司の判断が間違っていることもあります。でも、その判断がどこから来ているかを理解しなければ、対話はできません。対話とは、この世界の違いを認識した上で、共通の理解を構築する作業です。自分の世界だけで考えると「なんで分かってくれないんだ」となります。でも、上司の世界に立ってみると「なるほど、だからそう判断するのか」と見えてきます。見えてくれば、「では、この点はどうですか」と別の角度から提案できます。上からの視点と現場の視点上司と部下では、見ている方向が違います。上司は上から降りてくる方針を見ています。目標、KPI、ロードマップ。経営が何を求めているか。一方、現場は下を見ています。実際に何が起きているか。どこに問題があるか。この2つが噛み合っていないと、話が通じません。「上が何を考えているか分からない」「現場の声が届かない」——どちらも、この断絶の症状です。対話は、この2つをつなぐ作業です。上司と話すとき、上司が見ている方向を理解しようとします。同時に、現場のリアリティを言語化して伝えます。その接点を見つけることが、対話の目的です。ここで具体的なアクションがあります。上司が今、上の階層から課されている「最も頭の痛い課題」を把握してください。上司も誰かの部下です。上司にも上司がいます。その上司から何を求められているか。何に頭を抱えているか。それを知れば、あなたの仕事をどう位置づければいいか見えてきます。上司が「コスト削減」に追い詰められているなら、あなたの技術改善は「効率化」として語ってください。上司が「新規プロジェクトの立ち上げ」に追われているなら、あなたの貢献は「立ち上げを支える基盤整備」として語ってください。上司の頭痛の種を知れば、あなたの仕事の見せ方が変わります。対話を自分から始める「次の昇進に必要なことは何ですか」と1on1で聞きます。怖いです。否定されるでしょう。「まだ早い」と言われるでしょう。でも、聞かないと何も始まりません。自己評価と組織からの評価が食い違うとき、上司を敵だと思ってしまいがちです。「この人とは話しても仕方ない」と見限って、対話をやめます。これが最悪のパターンです。一度「敵」だと思うと、何を見ても敵の証拠に見えます。中立的な発言も「やっぱり敵だ」と解釈します。相手もそれを感じ取り、本当に敵対してきます。悪循環にハマります。これは認知バイアスの一種で、一度形成された敵対的な認知は、自己強化していきます。対話を自分から始めてください。待っていても始まりません。対話は「同意」ではない対話の目的は、合意することではありません。理解を共有することです。対話した結果、意見が一致しないこともあります。それでいいです。重要なのは、「なぜ相手がそう考えるか」を理解することです。理解した上で、なお意見が違うなら、それは対話の失敗ではありません。「上司と対話したが、評価は変わらなかった」という結果があり得ます。それでも、対話には意味があります。「なぜ評価が変わらないのか」の理由を理解できたはずです。理由を理解すれば、次の行動を決められます。理由が「あなたのスキルが足りない」なら、スキルを伸ばす努力をします。理由が「今期は枠がない」なら、来期に向けて準備します。理由が「この上司とは価値観が合わない」なら、異動や転職を検討します。対話の目的は、情報を得ることです。同意を得ることではありません。制度が機能していないなら、自分で対話を作れ本当は、目標設定や評価制度というのは、この対話を縮減化して仕組み化したものです。「何を目指すか」「どこまでやるか」「何ができたか」を定期的にすり合わせる機会です。でも、多くの組織で、この仕組みは形骸化しています。目標設定は形だけです。評価面談は結果の通知だけです。対話が発生していません。仕組みがうまく機能していないなら、仕組みが本来やろうとしていたことを、自分で意識的にやればいいです。1on1で自分から聞きます。週次報告で自分から伝えます。仕組みに頼らず、対話を自分で作ります。基準を握れ構造を理解し、対話の重要性を理解したら、次は具体的に動きます。まず、評価基準を言語化してください。多くの人は、上司が何を基準に評価しているか、明確に理解していません。なんとなく「良い仕事をすれば評価される」と思っています。でも、上司の頭の中にある評価基準と、自分が想像している評価基準は、往々にしてズレています。1on1で聞くべき具体的な質問「昇進に必要なことは何ですか」「今の自分に足りないものは何ですか」「次の評価期間で何を達成すれば、評価が上がりますか」「あなたが重視していることは何ですか」「なぜその目標が重要なんですか」「この目標が達成されないと、何が困りますか」これらの質問を、恐れずに聞いてください。「そんなこと聞いていいの？」と思うでしょう。私もそう思っていました。こういう質問をすることに、強い抵抗がありました。正直に言えば、私を含めてエンジニアは、こういう「合意形成」をバカにしている節があります。技術力で勝負したい。政治的なことはやりたくない。上司にゴマをするみたいで嫌だ。そういう感覚があります。もう1つ、ネガティブなフィードバックを受け取りたくない、という心理もあります。「今の自分に足りないものは何ですか」と聞いて、厳しいことを言われたらどうしよう。自分が思っているより評価が低かったらどうしよう。聞かなければ、知らずに済みます。でも、聞かなければ分かりません。上司はエスパーではないし、あなたもエスパーではありません。期待値をすり合わせるには、対話するしかありません。「昇進したいです」と直接言うのは恥ずかしいです。自分の欲を見せることに抵抗があります。私は3年間言えませんでした。言い出せないまま、居酒屋で愚痴を言い、鎮痛剤を飲み続けていました。鎮痛剤の効き目が切れてきた4年目に、ようやく口を開きました。でも、上司からすれば、部下が何を求めているか分からなければ、サポートのしようがありません。期待値のすり合わせ上司が求めるものと、自分がやりたいことは、必ずしも一致しません。上司が重視するのはAだが、自分が得意なのはB。この場合、どう動くか。まず、そのギャップを言語化してください。「自分はBが得意だが、Aに注力すべきですか」と聞いてください。上司は「Aをやってほしい」と言うでしょうし、「Bで成果を出してくれればいい」と言うでしょう。どちらにせよ、ギャップを認識した上で動けます。ギャップを認識しないまま、自分の得意なBに注力して、評価面談で「Aをやってほしかったのに」と言われるのが最悪のパターンです。見せろ評価基準を理解しました。上司との期待値もすり合わせました。次は、実際に動く番です。対話は手術だと書きました。では、見せることは何か。見せることはリハビリです。地味で、継続が必要で、効果が見えるまで時間がかかります。でも、これをやらなければ、手術しても回復しません。冒頭で書きました。見えない仕事は、存在しないのと同じだと。障害を未然に防いでも、誰も気づきません。技術的負債を返済しても、「いつの間にかキレイになってた」で終わります。これは不公平です。でも、嘆いても変わりません。変えられるのは、自分の行動だけです。だから、見せてください。何をやっているか、どんな価値を生んでいるか、言葉にして伝えてください。なぜ「見せる」ことが必要なのか「良い仕事をしていれば、見てもらえるはずだ」——これは幻想です。上司の注意は有限です。注意は希少資源です。上司は複数の部下を持っています。自分の仕事もあります。上からのプレッシャーもあります。その中で、あなたの仕事に割ける注意は、ごくわずかです。あなたが黙って良い仕事をしていても、上司の注意はあなたに向きません。問題を起こす部下、声の大きい部下、頻繁に報告してくる部下に注意が向きます。注意を向けてもらえなければ、あなたの仕事は認識されません。認識されなければ、評価されません。これは「目立ったもの勝ち」という話ではありません。情報の非対称性の話です。あなたは自分の仕事を100%知っています。上司は、あなたの仕事の10%も見ていません。この情報ギャップを埋めるのは、あなたの責任です。上司が勝手に気づいてくれることを期待するのは、非現実的です。人が本当に求めているのは、実はフィードバックではありません。「注目」です。自分の仕事を見てもらっている。気にかけてもらっている。存在を認識されている。そういう感覚です。私自身、厳しいフィードバックより、上司が自分の仕事を把握していないことの方が堪えました。評価されないと感じるとき、本当の問題は「評価が低い」ことではなく「注目されていない」ことでしょう。上司は、あなたが何をしているか知りません。知らなければ、評価以前の問題です。「見せる」ことへの抵抗多くのエンジニアは、「見せる」ことに抵抗がある。「アピールは卑しい」という感覚がある。日本の文化では、自己主張は美徳ではない。「黙って結果を出す」が美しいとされる。自分の成果を語ることは、自慢に見える。謙虚さが失われる。そういう感覚がある。でも、この感覚は、情報の非対称性を無視している。あなたが黙っていれば、上司はあなたの仕事を知らない。知らなければ、評価できない。「黙って結果を出す」は、「結果を出しても評価されない」と同義だ。「仕事の質で勝負したい」という信念もある。アピールの上手さではなく、仕事の質で評価されたい。それは正しい感覚だ。でも、仕事の質を上司に伝えるのは、アピールではない。情報提供だ。上司は、あなたの仕事の質を判断する材料を持っていない。その材料を提供するのは、あなたの役目だ。具体的な言い方週次報告での言い方ダメな例:「今週はAの修正をしました。」良い例:「今週はAの修正をしました。このバグは再現条件が複雑で、ログから特定するのに2日かかりました。原因は○○で、同様の問題が他に3箇所あったので併せて修正しています。」違いは、「何が難しかったか」「どう判断したか」「影響範囲をどう考えたか」を言語化していること。Slack、1on1、どの場面でも同じ原則です。言語化はスキルだアピールが苦手？ なら、存在しないのと同じだ。「自慢みたいで嫌だ」と思うだろう。私もそうだった。でも、これは自慢ではない。自分の仕事の価値を言語化しているだけだ。言語化しなければ、他人には見えない。見えなければ、評価されない。言語化は、スキルだ。最初は苦手でも、練習すれば上達する。週次報告を書くたびに、「何が難しかったか」を1文追加する。それだけで、見え方が変わる。タイミングを狙え「見せる」にも戦略がある。上司の認知の限界を理解することが重要だ。なぜタイミングが重要なのか評価面談の席で、上司は1年間を振り返る。でも、1年間を均等に思い出すことは、人間には無理だ。上司も人間だ。人間の記憶には癖がある。最初の方と最後の方は覚えているが、中間は忘れやすい。期初に立てた目標は覚えている。期末の追い込みも覚えている。でも、中間の地道な仕事は埋もれる。より厄介なのが、最近の出来事ほど重要に感じられる傾向だ。4月に素晴らしい仕事をしても、12月の評価面談では遠い記憶だ。「そういえば、何かやってくれた気がするな」程度の印象しか残らない。一方、11月に目立つ成果を出せば、12月の評価面談では鮮明に覚えている。もう1つ、人間は経験全体を平均的に評価しない。最も印象的だった瞬間と、終わりの印象で全体を判断する。1年間コツコツ働いても、期末に目立つ成果がなければ、「今期は普通だったな」という印象になりやすい。逆に、期末に大きな成果を出せば、「今期は頑張っていたな」という印象が残る。これは上司の能力不足ではない。人間の脳の仕組みだ。批判しても変わらない。構造を理解した上での3つの戦略この認知の限界を理解した上で、どう動くか。1. 評価の2ヶ月前に目立つ成果を出す大きなリリースのタイミングを調整可能なら、評価期間の後半に持ってくる。調整できなくても、過去の成果の効果を後半に言語化し直すことはできる。「4月にリリースした機能が、この半年でこれだけの効果を出しました」と。成果を「過去のイベント」ではなく「現在も続いている効果」として再提示する。2. 月次で「今月やったこと」を共有する上司の記憶を定期的に上書きする。年末に慌てて振り返るのではなく、毎月、記録を残しておく。これは上司のためだけではない。自分のためでもある。1年前に何をやったか、自分でも忘れる。月次の記録があれば、評価面談の準備が楽になる。もう1つ重要なことがある。「ピーク」がない期間の地味な貢献を、上司が「思い出しやすいエピソード」として毎月ストックしているか。「今月は特に目立った成果はありませんでした」で終わらせるな。地味な仕事でも、言語化すれば印象に残る。「依存ライブラリのアップデートで、セキュリティリスクを2件潰しました」。これだけで、「あの人は地道にやってくれている」という印象が積み上がる。3. 印象に残る瞬間を意識的に作る人間は、最も印象的だった瞬間で全体を判断する。これを逆手に取る。難しい問題を解決した。障害対応で活躍した。これらの「ピーク」は記憶に残りやすい。ピークがあれば、平凡な日々も「あの人は活躍していた」という印象に変換される。「ズルい」という感覚について「タイミングを調整するなんてズルい」と思うでしょう。仕事の質で評価されるべきです。タイミングを操作するのは、本質的ではありません。でも、考えてみてほしい。あなたがタイミングを意識しなくても、他の誰かは意識しています。評価期間の後半に目立つ成果を出す人。月次報告を欠かさない人。彼らは「ズルい」のではなく、「構造を理解している」だけです。タイミングを調整することは、媚びを売ることではありません。上司の認知の限界を理解した上で、情報を届けているだけです。上司が全てを均等に覚えていてくれるなら、タイミングは関係ありません。でも、上司は人間です。人間の記憶には限界があります。その限界を前提として動く方が、合理的です。この癖は、知っていれば対処できます。知らなければ、無意識のうちに損をします。評価する側もされる側も、同じ脳を持っています。上司もまた、自分の記憶の癖に気づいていないことが多いです。4. 失敗したときのリカバリーを設計しておく失敗は起きます。問題は、その失敗がハロー効果で全体評価を引きずり下ろすことです。「あの人は失敗した」という印象が、関係のない能力の評価まで下げます。これを防ぐには、失敗の直後に2つのことをやってください。まず、迅速に報告してください。隠そうとして発覚すると、「失敗した」にまた「隠そうとした」が上乗せされます。次に、原因と対策を透明に説明してください。「なぜ起きたか」「何を学んだか」「次にどう防ぐか」を言語化します。これができると、「失敗した人」ではなく「失敗から学べる人」という印象に変換されます。失敗を完全に消すことはできません。ですが、失敗の印象を上書きすることはできます。スポンサーを作れ昇進には「スポンサー」と「可視化」が必要だ。なぜスポンサーが必要なのか昇進は、だいたいあなたの知らないところで決まる。評価会議というものがある。マネージャーが集まって、誰を昇進させるか、誰に良い評価をつけるかを議論する。あなたは、その会議に出席できない。出席できないのに、そこであなたの運命が決まる。あなたの仕事ぶりを知っている人が、その会議にいなければ、あなたの名前は挙がらない。名前が挙がらなければ、昇進しない。どんなに良い仕事をしていても、その会議で誰かがあなたの名前を出さなければ、無意味だ。その「誰か」が、スポンサーだ。スポンサーとメンターの違いメンターは、アドバイスをくれる人だ。キャリアの相談に乗ってくれる。「こうした方がいいよ」「あの人に話を聞いてみたら」と教えてくれる。スポンサーは、あなたの成果を上に伝えてくれる人だ。人事評価の場で、あなたの名前を出してくれる。「あいつは良い仕事をしている」と会議で言ってくれる。この違いは決定的だ。メンターは「あなたのために」アドバイスをくれる。でも、スポンサーは「あなたのために」リスクを取る。評価会議であなたの名前を出すということは、スポンサー自身の信用を賭けることだ。「私が推薦した人」が期待外れだったら、スポンサーの評価が下がる。だから、スポンサーになってもらうのは、メンターになってもらうより難しい。メンターがいても、スポンサーがいなければ、昇進の話にはならない。あなたの良い仕事を知っている人がいても、その人が上に伝えてくれなければ、上層部はあなたを知らない。上司だけがスポンサーではない多くの場合、直属の上司が最初のスポンサー候補になる。でも、上司だけに依存するのはリスクがある。上司が異動することがある。上司が退職することがある。上司との相性が悪いこともある。上司が評価会議で発言力を持っていないこともある。上司一人に依存していると、その上司がいなくなった瞬間、あなたを推してくれる人がゼロになる。だから、上司以外のスポンサーも獲得しろ。評価会議には、複数のマネージャーが参加する。あなたの上司だけでなく、他のチームのマネージャーも発言権を持っている。もし、あなたの名前が複数の人から挙がったらどうなるか。「〇〇さん、評判いいね」となる。一人が推すより、複数が推す方が説得力がある。上司以外のスポンサー候補は、意外と身近にいます。他チームのマネージャー: 横断プロジェクトで一緒に働いた人技術リード: マネージャーに意見を求められる立場の人越境した仕事を意図的に作ってください。横断プロジェクトに手を挙げます。他チームのコードレビューを引き受けます。上司を勝たせることの意味上司が成果を出せば、チーム全体の評価が上がります。リソースが配分されます。自分の評価も上がりやすくなります。「媚びる」と「伝える」は違います。情報の非対称性を埋めているだけです。条件が揃わない場合しかし、これには条件がある。条件1: 上司が「勝とうとしている」こと上司が何を達成しようとしているかを理解できないなら、この戦略は機能しない。目標が不明確な上司、日々の消化試合に終始している上司には、「勝たせる」も何もない。判断方法：1on1で「今期の最優先目標は何ですか」と聞く。具体的な目標を即答できるなら、勝とうとしている。「色々ある」「維持が目標」と言うなら、勝とうとしていない可能性が高い。条件2: 上司が「部下の貢献を認識できる」こと上司を勝たせても、「これは俺の成果だ」と言い張る上司がいる。この場合、どれだけ貢献しても報われない。判断方法：過去の昇進者を観察する。上司が「〇〇さんのおかげで成功した」と言っていたか。チームの成果発表で、メンバーの名前を出していたか。自分の手柄にする上司は、パターンがある。条件3: 組織が「チームの成功を個人にも還元する」構造であることチームが勝っても、個人の評価に反映されない組織がある。年功序列が強すぎる、政治が評価を決める。この場合、上司を勝たせても自分には返ってこない。判断方法：先輩に聞く。「チームが成果を出したとき、個人の評価に反映されましたか」と。曖昧な答えが返ってきたら、還元されていない証拠だ。これらの条件が揃わない場合、「上司を勝たせる」戦略は機能しない。別の手を考える必要がある。例えば、「異動する」「別のスポンサーを見つける」「辞める」だ。上司以外のスポンサーを持っていれば、この「別のスポンサーを見つける」がすでに準備できている。上司に依存しすぎないためにも、日頃から複数のスポンサー候補との関係を築いておくことが重要だ。下振れで測られる対話しても評価が変わらないことがある。そのとき、もう1つ確認すべきことがある。自己認識と他者認識のギャップだ。「最高の自分」は実力ではない多くの人は、「最高の自分」を自分の実力だと思っている。ゾーンに入って神がかった速度でコードを書く自分。難解なバグを一瞬で特定する自分。そういう「最高の瞬間」を「自分の実力」だと信じる。でも、上司が見ているのは別のものだ。上司は、あなたに仕事を任せるとき、こう考える。「この人に任せて、最悪どうなるか」と。最高のケースではない。最悪のケースだ。なぜなら、任せた仕事が期待以下だったとき、責任を取るのは上司だからだ。上司は自分の評価を賭けている。だから、リスクを最小化したい。つまり、あなたは「上振れ」ではなく「下振れ」で判断されている。調子が良い日に出した成果は、「たまたま」でしょう。調子が悪い日に出した成果こそ、「確実に期待できるライン」です。上司が知りたいのは、後者です。だから、自分の実力を測るなら、最高の日ではなく、最悪の日を見てください。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その日に絞り出したアウトプット。それが、他人から見た「あなたの実力」に近いです。安定性という信頼信頼は、瞬間最大風速では測られない。安定性で測られる。毎週コンスタントに成果を出す人と、たまに爆発的な成果を出すが波がある人。どちらが信頼されるか。前者だ。爆発的な成果は印象に残る。でも、任せる側からすれば、「今回はどっちだろう」と毎回賭けをすることになる。安定している人には、安心して任せられる。ここで、あまり語られない現実を書く。体調管理は、評価に直結する。「体調不良は仕方ない」と、口では誰もがそう言う。風邪をひいた、熱が出た、それは本人のせいではない。責めるべきではない。正論だ。でも、現実はそんなに甘くない。風邪で3日寝込めば、1週間分の生産性が消える。体調不良の翌週もパフォーマンスは戻りきらない。締め切り直前に体調を崩せば、チーム全体に影響が出る。上司は、それを見ている。口では「お大事に」と言う。でも、心の中では「また休みか」と思っている。重要なプロジェクトを任せるとき、「この人、大丈夫かな」と不安がよぎる。結果、重要な仕事は「安定して稼働できる人」に回る。これは不公平だと思うだろう。体質の問題もある。本人の努力だけではどうにもならないこともある。それは事実だ。でも、コントロールできる部分は、コントロールしてください。もう1つ重要なことがあります。自分のパフォーマンスが落ちる兆候を自己認識していますか。睡眠不足が続くとどうなるか。ストレスが溜まるとどうなるか。これらを把握しておけば、周囲に「予測可能性」を提供できます。「来週は締め切りが重なっているので、レスポンスが遅くなるだろう」と先に言っておきます。これは弱みを見せることではありません。プロとして自分の状態を管理していることを示しています。上司があなたに仕事を任せるとき、「リスク」として感じている要素は何か。「この人は締め切りを守らない」と思われているなら、小さな約束から確実に守ってください。上司の中にある「リスク認知」を、1つずつ消していってください。他人はあなたの「見えた成果の平均」を見ている自分で認識している自分と、他人が見ている自分は違います。あなたは自分の内面を知っています。「今日は調子が悪い」「昨日は睡眠不足だった」「あのときは本気を出していなかった」。そういう文脈を全て知っています。だから、最高のパフォーマンスを出した日を「本当の自分」だと思います。それ以外の日は、何か理由があってパフォーマンスが落ちた「例外」だと思います。他人は、あなたの内面を知りません。見えるのは、あなたのアウトプットだけです。見えたアウトプットの平均が、「あなた」として認識されます。見せなかった仕事は、平均にすら入りません。最高の日も、最悪の日も、見えた範囲で平均化されます。だから、あなたが「本気を出せばもっとできる」と思っていても、他人から見れば「見えた範囲のあなた」がそのままあなたの実力です。見せていない実力は、存在しないのと同じです。ギャップを埋める方法自己認識と他者認識のギャップを埋めるには、フィードバックを求めるしかない。「私の強みと弱みは何ですか」と上司に聞く。怖い。自分が思っている自分と違う答えが返ってくるだろう。でも、聞かなければギャップは分からない。もう1つの方法は、360度評価の結果を真剣に受け止めることだ。多くの人は、360度評価の結果を「まあ、そういう見方もあるよね」程度で流す。でも、複数の人が同じことを指摘しているなら、それはおそらく事実だ。「本当はもっとできる」は通用しない新しい環境で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。それは言い訳だ。今、目の前で出しているアウトプットが、あなたの実力として認識される。「体調が悪かったので」も通用しない。体調が悪い日も含めた平均が、あなたの実力だ。だから、自分の「下限」を正しく認識することが重要だ。自分が思っているよりも、自分の下限は低いだろう。他人から見えている自分は、自分が思っている自分とは違うだろう。このギャップを認識した上で、どう動くか。それが「構造を理解した上で頑張る」ということだ。チームを勝たせろここまで「やるべきこと」を書いてきた。ここで1つ、やらなくていいことを書く。「最高の人材はオールラウンダーである」——そう信じられている。でも、そもそもオールラウンダーは、組織が作り出した便利な幻想だ。能力は文脈の中にしか存在しない。「オールラウンダー」とは、会社が定義した評価項目の範囲内でバランスが良い、というだけの話だ。それは普遍的な能力ではなく、ある限定された文脈の中で複数の能力がそこそこ高いだけだ。オールラウンダーの罠でも、オールラウンダーを目指すと何が起きるか。どの分野でも「そこそこ」になります。よくある罠があります。評価面談で「コミュニケーション力が弱い」と言われて、無理に改善しようとします。勉強会で発表する練習をします。ファシリテーションの本を読みます。その結果、強みだった技術力を伸ばす時間が減ります。コミュニケーション力は「平均以下」から「平均」になっただけです。技術力は「突出」から「やや上」に落ちました。本末転倒です。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪いです。100時間かけて弱みを「平均以下」から「平均」にするより、100時間かけて強みを「上位10%」から「上位1%」にする方が、価値が出ます。「チームを勝たせる」という発想ここで視点を変えてほしい。ここまで「上司を勝たせてください」と書いてきました。上司の目標に貢献してください。上司の労力を最小化してください。それがスポンサーを獲得し、評価につながる、と。でも、上司を勝たせることは、手段に過ぎません。本質は「チームを勝たせること」です。チームが勝てば、全員が恩恵を受けます。リソースが配分されます。良いプロジェクトが回ってきます。評価の枠が増えます。逆に、チームが負ければ、個人がどれだけ頑張っても報われません。沈む船の上でいくら走っても、沈むことに変わりはありません。だから、「自分がどう評価されるか」ではなく「チームがどう勝つか」を考えてください。強みで貢献するチームを勝たせるために、あなたは何ができるか。答えは単純です。強みで貢献してください。チームには様々な仕事があります。設計、実装、テスト、ドキュメント、調整、発表。全部を一人でやる必要はありません。チームとして、全部ができていればいいです。あなたがコードを書くのが得意なら、コードで貢献してください。ドキュメントが得意な人に、ドキュメントは任せてください。あなたが調整が得意なら、調整で貢献してください。実装が得意な人に、実装は任せてください。これが「補完」です。全員がオールラウンダーを目指すより、それぞれが強みを発揮して補完し合う方が、チームとしての出力は高くなります。優秀な人に共通パターンはありません。コードは神がかっているがドキュメントは壊滅的な人。設計は天才的だが実装は遅い人。トラブルシューティングは超人的だが新規開発には興味がない人。万能な人はいません。でも、チームとして万能であればいいです。弱みはチームでカバーする弱みを克服する必要がないと言っているわけではありません。弱みを自分で克服するか、チームでカバーするかを選んでください、と言っています。弱みを無視していいかどうかは、3つの質問で判断できます。その弱みがないと仕事ができないか？ コミュニケーションが苦手でも、コードで結果を出せるなら問題ありません。ですが、リーダーを目指すなら、コミュニケーションは避けられません。その弱みをカバーする人がチームにいるか？ ドキュメントが苦手でも、得意な人がチームにいれば補完できます。その弱みを平均にする努力で、強みを伸ばす時間が失われないか？ 弱みを平均にするのに100時間かかるなら、その100時間で強みを突き抜けさせた方がいいです。3つとも「いいえ」なら、弱みの克服は後回しでいいです。チームでカバーできる弱みは、チームに任せてください。しかし、役割によって「致命的な弱み」は変わります。今の役割では問題なくても、次の役割では致命的になることがあります。上司と話し合ってください。「私はAが強みで、Bが弱みです。今の役割でBは致命的ですか。次の役割ではどうですか」と。「この人がいないと困る」状態を作るチームを勝たせる中で、「この人がいないと困る」という状態を作ってください。みんなが平均を目指すなら、平均的な人材は溢れます。「そこそこ何でもできる人」は大量にいます。だから、差別化できません。代わりはいくらでもいます。一方、「この分野なら誰にも負けない」と言える人は少ないです。少ないから、価値があります。「この人じゃないと困る」という状況を作れます。それが交渉力になります。「パフォーマンスチューニングなら〇〇さん」「あの複雑な仕様を理解しているのは〇〇さんだけ」「障害対応で真っ先に呼ばれるのは〇〇さん」——こういうポジションを取ってください。チームの中で、代替不可能な存在になってください。「何でもできる人」という便利なラベルを捨ててください。代わりに、「〇〇の問題ならあいつに聞け」という、組織内の検索ワードを確立してください。検索ワードがあれば、困っている人が自分を見つけてくれます。仕事が向こうからやってきます。その仕事で成果を出せば、また検索ワードが強化されます。この循環を作ってください。そして、自分に問うてみてください。あなたの強みをより伸ばすことが、どのように「チーム全体の勝率」に直結するか。個人の成長と、チームの勝利を結びつけて説明できるか。「私が〇〇を極めれば、チームは△△で勝てるようになります」と。この論理が説明できれば、強みを伸ばす時間を堂々と確保できます。これは「自分だけが得をする」話ではありません。チームが勝つために、自分の強みを最大限に活かすという話です。チームが勝ち、その中で自分が不可欠な貢献をしている。この状態が、評価につながります。上司は言えます。「あのプロジェクトが成功したのは、〇〇さんの△△があったからです」と。具体的な貢献があれば、評価会議で名前を出しやすいです。組織の論理と個人の論理を重ねる組織は「オールラウンダーになれ」と言います。でも、その言葉を額面通りに受け取らないでください。組織が本当に求めているのは、「チームが勝つこと」です。オールラウンダーを求めるのは、そのための手段に過ぎません。誰が抜けてもチームが回るように、リスクヘッジしたいだけです。だから、「チームを勝たせる」という目的を共有した上で、手段は自分で選んでください。オールラウンダーになることでチームに貢献できるなら、それでいいです。でも、強みを尖らせることでチームに貢献できるなら、それでもいいです。目的が達成されていれば、手段は問われません。「私はオールラウンダーではありません。でも、この分野では誰にも負けません。チームの勝利に、この強みで貢献します」と言える状態を作ってください。組織の論理と、個人の論理を、「チームを勝たせる」という一点で重ねてください。これが、構造を理解した上で頑張る、ということです。それでもダメならここまでやっても評価されないことがあります。そのときの判断基準を明確にしておきます。「正しく頑張った」の定義成果を言語化し、見せた1on1で評価基準と昇進に必要なことを確認した上司の目標、チームの目標に貢献した評価のタイムラインを意識して動いたフィードバックを受け入れ、行動を変えた上司以外のスポンサーも獲得しようとした強みで貢献し、弱みはチームでカバーしたこの7つを1年間やった上で、評価が変わらなければ、構造の問題です。2年以上待っても変わらないなら、個人の努力では覆りません。しかし、正直に書いておきます。運の要素は大きいです。この記事は、努力すれば報われるかのように書いてきました。でも、現実はそうじゃありません。良い上司に当たるかどうかは、運です。自分の強みを評価してくれる上司、対話に応じてくれる上司、スポンサーになってくれる上司。そういう上司に当たるかどうかは、自分ではコントロールできません。良いプロジェクトに配属されるかも、運です。成果が見えやすいプロジェクト、評価につながりやすい仕事。それに関われるかどうかは、タイミングと巡り合わせです。会社の業績も、運です。会社が成長していれば昇進枠は増えます。会社が停滞していれば枠は減ります。個人の努力とは関係ありません。この記事に書いたことを全部やっても、運が悪ければ評価されません。逆に、何もしなくても、運が良ければ評価されます。そういうことは、あります。私が評価されるようになったのも、運の要素が大きいです。良い上司に当たりました。良いプロジェクトに関われました。会社の業績が良かった時期に、たまたま成果を出せました。努力したのは事実ですが、運が良かったのも事実です。この記事は、「努力でコントロールできる部分」にフォーカスしています。でも、コントロールできない部分の方が大きいでしょう。運が悪いときに、「頑張り方が間違っている」と言われても、救いになりません。運が悪かった人に、私は何も言えません。「次は運が良いといいね」としか言えません。それは無責任でしょうが、本当のことです。見切るべき3つのパターン パターン  状況  対処  上司とのズレ  上司が重視するAと、自分が得意なBがズレている。対話しても埋まらない  異動するか、別のスポンサーを見つける  制度の破綻  年功序列、政治、声の大きい人が勝つ。チームが勝っても個人に還元されない  組織を変えるか、出るか  市場価値との乖離  外では高く評価されるスキルが、今の組織では価値がない  辞める 見切りの解像度を上げろ「組織を辞める」というより、「この人たちと働くことを辞める」と考えた方が正確だ。冒頭で書いた。「どの会社で働くか」より「どのチームで働くか」が大事だと。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要だ。この上司との関係は修復可能か？別のチームに移れば解決するか？この会社の「誰か」に働きかければ変わるか？上司以外にスポンサーになってくれる人はいるか？全部試して、全部無理だった。そのとき初めて「構造の問題」と言える。あなたが直面している「評価への不満」は、個人の努力で突破可能な「運用上の課題」か。それとも、組織のDNAに刻まれた「構造的な腐敗」か。この見極めが重要です。1つの判断材料があります。過去3年間で、あなたと同じような「正論を吐く優秀な人」がどのように去っていったか、そのパターンを分析してください。同じパターンが繰り返されているなら、構造の問題です。もう1つの判断材料があります。今の会社で「最も高く評価されている人」の振る舞いは、あなたが5年後に「なりたい姿」と重なるか。重ならないなら、この組織で評価されることに意味があるのか。経営陣が「評価制度の不備」を認識していながら変えないなら、それは彼らにとって「都合が良い」からでしょう。仕組みの問題か、人の問題か「評価制度を変えればいい」——そう思いがちです。でも、制度を変えても、運用する人が変わらなければ、結果は変わりません。本当の問題は、制度ではなく、人と人の関係性にあることが多いです。逆もあります。「この上司が悪い」と思っていても、制度が上司にそう振る舞わせている場合があります。上司も構造の中で動いています。上司を責めても、構造は変わりません。撤退は戦略だ構造的な問題がある場合、とっとと辞めてください。「変われない組織」には共通パターンがあります。正しく頑張っても報われない構造ができあがっています。仕事が見えなくなり、提案が通らなくなり、評価基準が不透明になり、変えようとする人が去っていきます。こうなった組織は、個人の努力では変えられません。見極めのサインあなたの組織がこの状態に陥っているかどうか、いくつかのサインがあります。「これ、誰の仕事？」という会話が週に何度もある障害を未然に防いでも誰も気づかない提案しても「今は優先度が低い」と言われ続ける「なぜこのプロセス？」に「昔からこう」と返ってくる「変えようとして辞めた人」の話をよく聞くチームが勝っても、個人の評価に反映されないこれらのサインが複数当てはまるなら、個人の努力で変えるのは難しいです。異動か転職を視野に入れてください。成功した組織ほど変われなくなる皮肉なことに、成功した組織ほど変われなくなります。「過去にこうやってうまくいった」という経験が、新しいやり方を排除します。成功体験が足かせになります。あなたが「この組織はおかしい」と感じるとき、それは正しいでしょう。組織は過去の成功に縛られて、新しい環境に適応できなくなっているのでしょう。その場合、あなた個人が変えられることは限られています。構造を変えるには、経営層が本気で取り組む必要があります。それがないなら、辞めてください。撤退は戦略である「おい、辞めるな」で書きました。短期ではなく長期で考えてください。信頼の貯金を積み上げてください。転職はリセットコストがかかります。でも、「長期で考えた結果、辞める」という判断もあります。1年間正しく頑張りました。構造を理解した上で動きました。対話を試みました。スポンサーを探しました。チームを勝たせようとしました。それでも変わりませんでした。組織が考える力を失っていて、経営層も本気で取り組む気配がありません。そういう状況なら、辞めることが長期的に正しい判断です。それは逃げではありません。戦略的撤退です。交渉してダメなら去るしかし、順番を間違えないでください。まず交渉してください。評価に納得がいかないなら、上司に聞いてください。「何をすれば評価されるのか」を明確にしてください。構造に問題があると思うなら、提案してください。改善案を出してください。異動を申し出てください。別のスポンサーを探してください。やれることをやってください。交渉するとき、あなたの言葉に「重み」はありますか。社外の市場価値を把握していますか。「いつでも外に出られる」という自信が、言葉に重みを与えます。交渉するなら、「何を、いつまでに、どう変えてほしいか」を具体的に伝えてください。そして、交渉が決裂した際の「プランB」は準備していますか。プランBがないまま交渉しても、本気度が伝わりません。それでダメなら、去ってください。この順番が大事です。交渉せずに辞めるのは、ただの逃げです。でも、交渉した上で辞めるのは、戦略です。「やることはやった。それでも変わらなかった」という事実が、あなたの判断を正当化します。次の面接で「なぜ辞めたのか」と聞かれたとき、「改善を試みたが、構造的に無理だった」と言えます。というか、交渉するというのは、それぐらいデカいことです。「評価に納得いきません」「異動させてください」「この構造を変えてください」——これを口にした時点で、あなたは覚悟を示しています。ダメだったら去る覚悟を。交渉とは、そういう重さを持つ行為です。軽い気持ちで切り出すものではありません。だからこそ、ダメだったときに居座るのは筋が通りません。覚悟を示しておいて、結果が出たら何もしない。それは自分の言葉を裏切ることです。全てはトレードオフです。残るコストと、去るコストがあります。残れば、信頼の貯金を積み上げられます。人間関係もリセットされません。でも、構造が変わらないなら、消耗し続けます。3年後も5年後も同じ愚痴を言っている自分が見えます。去れば、リセットコストがかかります。また一から信頼を築く必要があります。新しい環境に適応するストレスもあります。でも、正しく評価される構造の中で働ける可能性があります。どちらが正解か、一般論では言えません。あなたの状況によります。あなたの価値観によります。あなたのキャリアのフェーズによります。ただ、1つだけ言えます。交渉してダメだったのに居座り続けるのは、最悪の選択です。構造が変わらないと分かりました。自分の力では変えられないと確認しました。それでも残る。それは「判断を放棄している」だけです。答えは出ているのに、行動しません。時間だけが過ぎていきます。交渉してください。ダメなら去ってください。それがトレードオフを引き受けるということです。辞める前に確認することしかし、辞める前に確認すべきことがあります。1. 本当に構造の問題か「評価されない」と感じるとき、構造のせいにしたくなります。自分のせいではない。組織が悪い。そう思いたいです。でも、まず自分を疑ってください。ちゃんと見せていたか。対話していたか。チームを勝たせようとしていたか。強みで貢献していたか。これらを本当にやった上で、評価されなかったのか。構造のせいにするのは、自分の責任を回避できて楽です。でも、構造のせいにして辞めても、次の組織で同じことが起きるでしょう。2. 異動で解決できないか「組織を辞める」前に、「チームを辞める」を検討してください。別のチームに移れば解決することがあります。上司が変われば、評価が変わることがあります。別のスポンサーがいれば、状況が変わることがあります。会社全体がダメなのか、今いるチームがダメなのか。この見極めは重要です。3. 辞めた後に何があるか辞めることを決める前に、辞めた後の絵を描いてください。「ここから出たい」だけでは、どこに行っても同じ問題にぶつかります。次の組織で何をしたいのか。どんな環境なら自分の強みを活かせるのか。どんなチームなら自分が貢献できるのか。それが見えてから、辞めてください。大企業にいるなら、よく考えろあなたは自分が持っているものを過小評価しています。 安定した給与、福利厚生、開発環境、ネームバリュー。これらが「普通」に感じられています。不満ばかりが目につきます。でも、構造的な問題——評価制度の限界、政治、見えない仕事の軽視——は、大企業だから存在するのではありません。組織という形態が持つ宿命です。スタートアップでも20人を超えれば政治が生まれます。50人を超えれば部門間の壁ができます。環境を変えても、構造は変わりません。大企業を辞める前に、まず異動を検討してください。辞めなくても環境を変えられます。サバンナで戦う覚悟があるなら飛び出せばいいです。覚悟がないなら、城壁の中で戦略を練ってください。辞めると決めたら辞めると決めたら、長居しないでください。「あと半年頑張ってみよう」「プロジェクトが終わるまで」と思いがちです。でも、辞めると決めた組織で頑張り続けるのは、消耗します。モチベーションが上がりません。パフォーマンスが落ちます。評価が下がります。悪循環にハマります。辞めると決めたら、次を探し始めてください。時間をかけすぎないでください。辞めても何も変わらないだろう正直に言えば、辞めても何も変わらないでしょう。次の組織も、同じような問題を抱えているでしょう。評価制度に限界があります。上司との相性があります。政治があります。これは、どの組織にもあります。というかそれはあなたの問題でもあります。そこに向き合ったほうが良いです。転職は、問題を解決する魔法ではありません。環境を変えるだけです。新しい環境で、同じ問題に別の形でぶつかることもあります。だから、辞める前に、「この問題は環境を変えれば解決するのか、自分が変わらないと解決しないのか」を考えてください。環境の問題なら、辞めてください。自分の問題なら、自分を変えてください。両方なら、両方やってください。届かない人へここまで書いてきて、立ち止まります。「見せてください」「対話してください」「チームを勝たせてください」——私はそう書きました。構造を理解した上で、その中でうまくやってください、と。でも、この記事が届かない人がいます。頑張れない人がいる「頑張り方を変えてください」と言いました。ですが、もう頑張る余力がない人はどうするのか。すでに消耗している人。毎日出社するだけで精一杯の人。週次報告に「何が難しかったか」を1文追加する気力すらない人。1on1で交渉する心理的余裕がない人。彼らに「見せてください」「対話してください」と言っても、届きません。むしろ、「お前の頑張りは間違っている」と告げることになります。追い詰めることになります。「体調管理は評価に直結する」と書きました。事実です。でも、体調を管理できない人がいます。慢性疾患を抱えている人。精神疾患と付き合っている人。家庭の事情で睡眠時間を削らざるを得ない人。介護や育児で「安定して稼働」できない人。彼らは、努力が足りないのではありません。構造が彼らを排除しているのです。「アピールが苦手なら、存在しないのと同じだ」と書きました。ですが、アピールが苦手な人は、苦手だから苦労しています。「苦手を克服してください」と言うのは簡単です。でも、克服できないから苦手なのです。内向的な人、言語化が苦手な人、自己主張に強い抵抗がある人。彼らに「見せてください」と言っても、できないものはできません。この記事に書いた「正しい頑張り方」ができる人は、すでに恵まれています。対話する余力があります。アピールする能力があります。安定して稼働できる体があります。それらを持っている時点で、スタートラインが違います。私は、持っている側でした。だから、この記事を書けました。持っていない人に、同じことを求めるのは、傲慢でしょう。「頑張らない」という選択肢「辞めないなら頑張ってください」と書きました。ですが、「辞めないけど頑張らない」という選択肢もあります。昇進を追わない。評価を気にしない。自分のペースで働く。それは「諦め」ではありません。評価ゲームから意識的に降りるという戦略です。評価制度は、組織が作ったゲームに過ぎません。そのゲームに参加するかどうかは、自分で選べます。「昇進しなければ給料が上がらない」と言うでしょう。ですが、昇進のために消耗して、心身を壊したら、給料どころではありません。評価を追いかけて、本来の仕事の楽しさを失ったら、何のために働いているのか分からなくなります。評価されなくても、良い仕事はできます。障害を未然に防いだ本人は、その価値を知っています。上司が知らなくても、自分は知っています。それで十分だと思える人もいます。もし今の評価ゲームが「勝てない設定」であるなら、「頑張らない」ことで確保したエネルギーを、どこに投資するか考えてみてください。社内の評価を「食い扶持を維持する程度」にコントロールし、余ったリソースで社外での市場価値を育てることは可能か。今の場所を「人生のゴール」ではなく「ベースキャンプ」と定義し直してください。もちろん、評価されないと生活に困ることもあります。だから、全員にこの選択肢を勧めているわけではありません。ただ、「頑張らない」という選択肢もあることを、知っておいてほしいです。評価ゲームに全てを賭ける必要はありません。降りてもいいです。構造を変えるという選択肢「仕組みは変えられない。自分は変えられる」と書きました。ですが、本当に変えられないのか。「見えない仕事」を評価する仕組みを作った組織はあります。障害を未然に防いだことを、きちんと評価する制度を設計した会社はあります。短期成果だけでなく、長期的な貢献を測る仕組みを導入したチームはあります。変えられないのではありません。変えようとする人がいなかっただけでしょう。変えようとした人が、諦めて辞めていっただけでしょう。この記事では、構造を変える方法は書きませんでした。正直、私にはその経験がないからです。私は構造の中で適応する方を選んできました。変えようとしたこともありますが、うまくいきませんでした。だから、「変えてください」とは言えませんでした。でも、適応することが唯一の選択肢ではありません。もしあなたに発言力があるなら、提案してみてもいいです。評価制度を変える提案。見えない仕事を可視化する仕組み。非機能要件を評価する基準。障害を未然に防いだことを記録するプロセス。変わらないでしょう。でも、変わるでしょう。少なくとも、試さなければ分かりません。「構造を理解した上で適応する」は、1つの戦略です。でも、「構造を理解した上で変えようとする」も、1つの戦略です。どちらを選ぶかは、あなた次第です。多様な「正解」があるこの記事は、「評価される頑張り方」を書きました。ですが、それが唯一の正解ではありません。評価を追いかけて、昇進して、影響力を持つ。それも正解です。評価を諦めて、自分のペースで働く。それも正解です。構造を変えようとして、組織を動かす。それも正解です。評価ゲームから降りて、別の働き方を選ぶ。それも正解です。どれが正しいかは、あなたの状況によります。あなたの価値観によります。あなたの人生のフェーズによります。「辞めないなら頑張ってください」と私は書きました。でも、「辞めないけど頑張らない」でもいいです。「辞めないで、構造を変えようとする」でもいいです。この記事が、あなたを追い詰めるためにあるのではありません。選択肢を増やすためにあります。そう思いたいです。おわりに先週の記事に、思った以上の反響がありました。「辞めないことにしました」という連絡をくれた人たちが、どんな人で今どうしているのか、私は知りません。うまくいっているといいです。うまくいっていなくても、間違えながら何とかやっているといいです。この文章を書き終えました。書いている間、何度か手が止まりました。こんなことを書いて、誰かの役に立つのだろうか。自分が経験したことを、他人に押し付けているだけではないか。答えは出ませんでした。出ないまま、最後まで書きました。明日からできることはあります。週次報告に「何が難しかったか」を1文足す。1on1で「昇進に必要なこと」を聞く。カレンダーに「評価2ヶ月前」をマークする。見えない仕事を、見える形にする。それだけで、何かが変わるでしょう。たぶん、私は来週の週次報告で「何が難しかったか」を書くのを忘れます。上司を敵認定しそうになります。また同じ愚痴を居酒屋で言います。間違えたら直せばいいです。間違えていることに気づいているなら、まだやれます。たぶん。「評価が上がりました」でも、「やっぱり辞めました」でも、「まだ間違え続けています」でも、「頑張るのをやめました」でも。どれでもいいです。どれも、選んだ道を歩いている証拠だと思うから。正解かどうかは、分かりません。私がやってきたことが正しかったかどうかも、分かりません。分かるのは、ずっと後になってからです。おい、辞めないなら頑張ってください。頑張り方を間違えないでください。——と、ここまで書いてきました。でも、最後に付け加えておきます。頑張れないなら、頑張らなくていいです。降りてもいいです。休んでもいいです。それも、1つの選択です。私も、まだ間違え続けています。それでいいのだと思います。続編も書きました。syu-m-5151.hatenablog.com参考書籍外資系コンサルの仕事の進め方: 実践の場で使える問題解決の基盤スキル作者:金地 毅,田辺 元,柳田 拓未東洋経済新報社Amazon私文ホワイトカラーが AI・コンサルに仕事を奪われない働き方戦略作者:株式会社板橋　東京中央支店かんき出版AmazonSOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社AmazonHigh Conflict よい対立 悪い対立 世界を二極化させないために作者:アマンダ・リプリーディスカヴァー・トゥエンティワンAmazonソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社AmazonTHE CULTURE CODE 最強チームをつくる方法作者:ダニエル・コイル,楠木建かんき出版Amazonセンスメイキング――本当に重要なものを見極める力作者:クリスチャン・マスビアウプレジデント社Amazon心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon組織と働き方の本質　迫る社会的要請に振り回されない視座 (日本経済新聞出版)作者:小笹芳央日経BPAmazon［新版］組織行動の考え方―個人と組織と社会に元気を届ける実践知作者:金井 壽宏,高橋 潔,服部 泰宏東洋経済新報社Amazon「組織と人数」の絶対法則―人間関係を支配する「ダンバー数」のすごい力作者:トレイシー・カミレッリ,サマンサ・ロッキー,ロビン・ダンバー東洋経済新報社Amazonチームの力で組織を動かす 〜ソフトウェア開発を加速するチーム指向の組織設計作者:松本 成幸技術評論社Amazon恐れのない組織――「心理的安全性」が学習・イノベーション・成長をもたらす作者:エイミー・C・エドモンドソン,村瀬俊朗英治出版Amazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazon多様性の科学作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新　失敗学　正解をつくる技術作者:畑村洋太郎講談社Amazon企業変革のジレンマ　「構造的無能化」はなぜ起きるのか (日本経済新聞出版)作者:宇田川元一日経BPAmazon「わかりあえない」を越える――目の前のつながりから、共に未来をつくるコミュニケーション・NVC作者:マーシャル・B・ローゼンバーグ海士の風Amazonみんな違う。それでも、チームで仕事を進めるために大切なこと。作者:岩井俊憲ディスカヴァー・トゥエンティワンAmazonなぜ働く？　誰と働く？　いつまで働く？　限られた人生で後悔ない仕事をするための20の心得作者:有山 徹アスコムAmazon問いかける技術――確かな人間関係と優れた組織をつくる作者:エドガー・H・シャイン英治出版Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OAuth2認証をE2Eテストしたら、5つのバグが出てきた話]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/11/064311</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/11/064311</guid>
            <pubDate>Sat, 10 Jan 2026 21:43:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめに認証が動いた。だがそれは始まりに過ぎなかった。前回の記事では、Next.jsでOry Hydra認証を実装した。OAuth2認可コードフロー、Cookie管理、ID Token署名検証、マルチテナント認証について解説した。前提知識: この記事は前回の記事の続編です。Next.jsでのOAuth2認証フロー実装を理解している前提で進めます。Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践 - じゃあ、おうちで学べる今回は、実装した認証フローを検証する。Playwright MCPを使ったE2Eテスト、発見した5つのバグ、RBACの検証、そしてベストプラクティスとの比較までを一気に解説する。Playwright MCPによるE2Eテストもう本当に10年くらい前は「E2Eテストなんて、デモ前に手動で確認すれば十分でしょ」と思っていた。仕事でフロントエンド書いたことなかったので…。今の自分から言わせてもらえば、それは個人の能力を過信している。あとはフロントエンドのテストの大変さを軽く見ている。OAuth2フローのE2Eテストは手動では破綻する。複数のリダイレクト、Cookie管理、セッション状態の確認——これらを毎回手動で確認するのは、人間の注意力の限界を超えている。「今日は疲れていたから見落とした」で本番障害が起きるのは、個人の問題ではなく構造的な失敗だ。人間に頼らない仕組みを作る必要がある。Claude CodeとPlaywright MCPの組み合わせPlaywright MCPは、LLMがブラウザを直接操作できるModel Context Protocol（MCP）サーバーだ。Claude Codeと組み合わせることで、自然言語でE2Eテストを実行できる。従来のPlaywrightとの違いは、スクリプトを書かずにテストできる点だ。# セットアップ（プロジェクトごとに一度だけ）claude mcp add --transport stdio playwright --scope project -- npx -y @playwright/mcp@latest.mcp.jsonが生成される：{  "mcpServers": {    "playwright": {      "type": "stdio",      "command": "npx",      "args": ["-y", "@playwright/mcp@latest"]    }  }}実際のテスト実行例Claude Codeで以下のように指示する：Playwright MCPでOAuth2フローをE2Eテストしてください：1. http://localhost:3001/ にアクセス2. Sign Inをクリック3. demo@example.com / password123 でログイン4. Consentで Allow をクリック5. ダッシュボードが表示されることを確認6. スクリーンショットを取得Claude Codeは以下のツールを順次実行する： ステップ  MCPツール  結果  1  browser_navigate  ホームページ表示  2  browser_click (ref=e10)  Hydra認可エンドポイントへリダイレクト  3  browser_fill_form  ログインフォーム入力完了  4  browser_click (Sign In)  Consent画面へリダイレクト  5  browser_click (Allow)  トークン交換・フロントエンドへリダイレクト  6  browser_take_screenshot  エビデンス取得 ARIA Snapshotの活用Playwright MCPの特徴は、DOMではなくアクセシビリティツリーでページ構造を表現する点だ。各要素にはref=eXX形式の参照IDが付与される：- banner:  - navigation:    - link "Sign In" [ref=e10] [cursor=pointer]:      - /url: /api/auth/loginこのref=e10を使ってクリック対象を指定する。セレクタの管理が不要になり、UIの変更に強いテストが書ける。従来のE2Eテストとの比較 項目  従来のPlaywright  Playwright MCP  テスト作成  スクリプト記述が必要  自然言語で指示  セレクタ管理  CSSセレクタ/XPath  ARIA参照ID  リダイレクト追跡  手動でwait設定  自動追跡  デバッグ  ログ/スクリーンショット  対話的に確認可能  再現性  高（スクリプト化）  中（LLMに依存） Playwright MCPは「探索的テスト」に向いている。本番のCIには従来のPlaywrightスクリプトを使い、開発中の手動確認をPlaywright MCPで効率化する、という使い分けがよさそうだ。E2Eテストで発見した5つのバグPlaywright MCPとシェルスクリプトによるE2Eテストを実行した結果、5つの重要なバグを発見・修正した。OAuth2+マルチテナント構成の複雑さを示す良い事例だ。バグ1：CORS設定の欠如症状：フロントエンド（localhost:3001）からバックエンド（localhost:3000）へのAPIリクエストがブロックされる原因：Axumルーターにtower-httpのCorsLayerが設定されていなかった修正（src/main.rs）：use tower_http::cors::{Any, CorsLayer};let app = Router::new()    // ... routes ...    .layer(        CorsLayer::new()            .allow_origin(Any)            .allow_methods(Any)            .allow_headers(Any),    )教訓：これは個人の注意力の問題ではない。フロントエンド・バックエンド分離構成では、CORSは「設定を忘れると動かない」構造になっている。チェックリストに入れる。プロジェクトテンプレートに含める。人間の記憶に頼らない仕組みを作る。「動かない」の原因がCORSだと気づくまでに時間がかかることがある。エラーメッセージが分かりにくいからだ。ブラウザのコンソールを見る習慣をつけるしかない。詳細はMDN: CORSを参照。バグ2：Cookieパース時のJWTトークン切り詰め症状：認証後のAPIリクエストで401エラーが発生原因：.split("=")[1]でCookieを取得すると、base64エンコードされたJWTの=パディング文字で切れてしまう// ❌ 危険：JWTが途中で切れるconst token = document.cookie  .split("; ")  .find((row) => row.startsWith("auth_token="))  ?.split("=")[1];  // "ory_at_abc...def=" → "ory_at_abc...def" で切れる// ✅ 正しい：トークン全体を取得const cookieRow = document.cookie  .split("; ")  .find((row) => row.startsWith("auth_token="));const token = cookieRow ? cookieRow.substring("auth_token=".length) : null;教訓：JWTは必ずbase64パディング（=）を含む可能性がある。文字列操作でトークンを扱う時は要注意。バグ3：HydraトークンとJWTの不一致症状：フロントエンドからのAPIリクエストで401エラー。curlでJWTを直接送ると成功する。原因：- フロントエンドはHydra発行のアクセストークン（ory_at_...形式）を使用- バックエンドは自前のJWTのみ対応していた修正（src/middleware/auth.rs）：// JWT検証を試み、失敗したらHydraイントロスペクションにフォールバックlet claims = match state.jwt.verify_access_token(token) {    Ok(claims) => claims,    Err(_) => {        // Hydra Admin APIでトークンを検証        let introspection = state.hydra.introspect_token(token).await?;        // IntrospectionResponseからClaimsに変換        Claims::from(introspection)    }};教訓：OAuth2プロバイダー（Hydra）のトークンと自前JWTの両方をサポートするか、どちらか一方に統一するか、設計段階で決めておくべきだった。バグ4：テナント抽出ミドルウェアの欠如症状：テナントAPI（/api/v1/tenant/*）で「No tenant context」エラー原因：tenant_apiルーターにextract_tenantミドルウェアが適用されていなかった修正（src/main.rs）：let tenant_api = Router::new()    // ... routes ...    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::require_auth,    ))    .layer(axum_middleware::from_fn_with_state(        state.clone(),        middleware::extract_tenant,  // 追加    ));教訓：ミドルウェアの適用漏れは見つけにくい。各ルートグループに必要なミドルウェアをリスト化しておくとよい。バグ5：X-Tenant-Slugヘッダーの欠如症状：ローカル開発環境でテナントが識別できない原因：- 本番環境ではサブドメイン（tenant-a.example.com）でテナント識別- ローカル開発ではlocalhost:3001のためサブドメインが使えない- フロントエンドがX-Tenant-Slugヘッダーを送信していなかった修正（frontend/src/lib/api.ts）：class ApiClient {  private tenantSlug: string = "test-shop"; // デフォルトテナント  private async fetch<T>(endpoint: string, options: RequestInit = {}): Promise<T> {    const headers: HeadersInit = {      "Content-Type": "application/json",      "X-Tenant-Slug": this.tenantSlug,  // 追加      ...options.headers,    };    // ...  }}教訓：マルチテナントのテナント識別は、サブドメイン方式とヘッダー方式の両方をサポートしておくとローカル開発が楽になる。E2Eテスト実行結果修正後のOAuth2フロー完全テスト：=== DONADONA E2E Test v4 ===1. Starting OAuth2 Flow...   Login Challenge: LuAyzZfWTX03DnVcFC1xu0A-rntZcx...2. Submitting Login (demo@example.com)...   Consent Challenge obtained3. Approving Consent...   Final: http://localhost:3001/callback?code=ory_ac_d9jRSkWUb1YXm...4. Token Exchange...   Access Token: ory_at_dxBjsXjmRvMuTcSJercIxT_Kq2nUIR6OrUhdBEcEZIg...5. Testing API Endpoints...   Engineers Count: 36. Backend Verification:   slug_from_header=Some("test-shop")   Hydra token introspection successful: sub=Some("3767fa6a-...")============================================   E2E Test PASSED - All fixes verified!============================================複数アカウントでのRBAC検証E2Eテストの最後に、異なるロールのアカウントでログインして、役割ベースアクセス制御（RBAC）が正しく機能しているかを検証した。テスト結果のサマリー以下は修正前のテスト結果だ。platform_adminがDashboardで403を返すなど、明らかな異常がある。詳細は後述する。 アカウント  ロール  ナビゲーションメニュー  アクセス可能ページ  demo@example.com  platform_admin  全メニュー  Dashboard(403)、その他未テスト  manager@example.com  manager  全メニュー  Dashboard, Incidents, Projects, Engineers, Recruitment, Leaderboard  sato@example.com  engineer  制限メニュー  Dashboard, Incidents, Projects, Leaderboard  reporter@example.com  reporter  制限メニュー  すべてAccess Denied 発見1：フロントエンドとバックエンドのデータ不一致テストアカウント一覧を表示するフロントエンドのホームページには、こう書いてあった：Reporter | customer@example.com | Report incidents onlyしかし実際にcustomer@example.comでログインすると、ヘッダーにはengineerと表示された。データベースとフロントエンドの表示が不一致だった。正しいReporterアカウントはreporter@example.comだった。発見2：ロールごとのメニュー制御Playwright MCPのARIAスナップショットで、ロールごとのナビゲーションメニューの違いを確認できた。Manager（manager@example.com）のメニュー：- link "Dashboard" [ref=e10]- link "Incidents" [ref=e11]- link "Projects" [ref=e12]- link "Engineers" [ref=e13]- link "Recruitment" [ref=e14]- link "Leaderboard" [ref=e15]Engineer（sato@example.com）のメニュー：- link "Dashboard" [ref=e10]- link "Incidents" [ref=e11]- link "Projects" [ref=e12]- link "Leaderboard" [ref=e13]# Engineers, Recruitmentが表示されない発見3：Reporterの「何もできない」状態reporter@example.comでログインして各ページにアクセスすると、すべて「Access Denied」が表示された。CLAUDE.mdによると、Reporterは「Report incidents only」という説明だったが、実際にはインシデントページすら見られない。これは設計ミスだった。修正が必要だ。フロントエンドとバックエンドの権限制御問題の根本原因Reporterロールがすべてのページでアクセス拒否されていた原因は、Next.jsのmiddleware.tsにあった：// 修正前：ReporterはADMIN_PATHSに含まれていないconst ADMIN_PATHS = ["/dashboard", "/incidents", "/projects", "/engineers", "/recruitment", "/leaderboard"];// ロールチェック：platform_admin, manager, engineerのみ許可if (isAdminPath && !["platform_admin", "manager", "engineer"].includes(role)) {  return NextResponse.redirect(new URL("/?error=unauthorized", request.url));}修正内容// 修正後：ADMIN_PATHSから/incidentsを分離し、REPORTER_PATHSを新設const ADMIN_PATHS = ["/dashboard", "/projects", "/engineers", "/recruitment", "/leaderboard"];const REPORTER_PATHS = ["/incidents"];  // Reporter専用パス// Reporter paths - reporter, engineer, manager, platform_admin can accessconst isReporterPath = REPORTER_PATHS.some((p) => pathname.startsWith(p));if (isReporterPath && !["platform_admin", "manager", "engineer", "reporter"].includes(role)) {  return NextResponse.redirect(new URL("/?error=unauthorized", request.url));}// Admin paths - platform_admin, manager, engineer can access (not reporter)const isAdminPath = ADMIN_PATHS.some((p) => pathname.startsWith(p));if (isAdminPath && !["platform_admin", "manager", "engineer"].includes(role)) {  return NextResponse.redirect(new URL("/?error=unauthorized", request.url));}これで権限階層が明確になった： パス  platform_admin  manager  engineer  reporter  /tenants  ✅  ❌  ❌  ❌  /dashboard  ✅  ✅  ✅  ❌  /incidents  ✅  ✅  ✅  ✅  /projects  ✅  ✅  ✅  ❌ 多層防御の実装「フロントエンドで権限チェックすればいい」という意見と、「バックエンドだけでやるべき」という意見がある。どちらも正しく、どちらも不十分だ。フロントエンドだけでは、攻撃者がcurlで直接APIを叩けば突破される。バックエンドだけでは、権限のないユーザーが画面を見てから「アクセス拒否」されるUXになる。答えは「両方やる」——多層防御と呼ばれる考え方だ。城の防壁が一重ではなく多重であるように、セキュリティも複数のレイヤーで守る。フロントエンドのmiddleware.tsだけでは不十分だ。攻撃者はフロントエンドを完全にバイパスできる：# フロントエンドを経由せずにAPIを直接叩けるcurl -s http://localhost:3000/api/v1/tenant/incidents \  -H "Authorization: Bearer $TOKEN" \  -H "X-Tenant-Slug: test-shop"Rustバックエンド（Axum）では、権限制御が複数のレイヤーで行われている：レイヤー1：require_auth（認証） - トークンが有効かどうかをチェックレイヤー2：extract_tenant（テナント抽出） - X-Tenant-Slugヘッダーからテナントを特定レイヤー3：ハンドラー内のロールチェック - 特定の操作でロールをチェックpub async fn assign_incident(/* ... */) -> Result<Json<IncidentWithStatus>, AppError> {    let role = claims.get_role();    if !role.can_manage_team() {        return Err(AppError::Forbidden(            "Only managers can assign incidents".to_string(),        ));    }    // ...}多層防御が正解だ： レイヤー  役割  目的  フロントエンド middleware  早期リダイレクト  UX向上、不要なリクエスト削減  バックエンド require_auth  認証チェック  不正アクセス防止  バックエンド ハンドラー  操作ごとの認可  きめ細かい権限制御 ベストプラクティスとの比較この実装が業界のベストプラクティスにどれだけ準拠しているかを評価する。OWASP Top 10 2025との比較OWASP Top 10 2025でBroken Access Controlが1位を維持している。 OWASP推奨事項  準拠状況  実装詳細  サーバーサイドでのアクセス制御  ✅ 準拠  Axumミドルウェアで全APIを保護  デフォルト拒否  ✅ 準拠  未認証リクエストは全て拒否  アクセス制御の再利用  ✅ 準拠  require_authを全ルートで共有  レコード所有権の検証  ⚠️ 部分的  テナント分離は実装、リソース単位は未実装  アクセス制御失敗のログ  ⚠️ 部分的  tracingでログ出力、アラートは未実装  レート制限  ❌ 未実装  APIにレート制限なし  JWTの不正利用防止  ✅ 準拠  Hydraによるトークン検証  セキュリティヘッダ  ⚠️ 部分的  HSTS, X-Frame-Options, X-Content-Type-Optionsの設定が必要  入力値バリデーション  ✅ 準拠  サーバーサイドでバリデーション実施 Next.jsセキュリティガイドラインとの比較Next.js Authentication Guideは、認証に関する重要な警告を含んでいる。 Next.js推奨事項  準拠状況  実装詳細  Middlewareだけに依存しない  ✅ 準拠  バックエンドでも認証チェック  Data Access Layer (DAL)の使用  ⚠️ 部分的  サービス層で分離、専用DALなし  HttpOnly Cookieの使用  ⚠️ 部分的  auth_tokenは非HttpOnly Next.jsチームは「middlewareは認証に安全ではない」と警告している。この多層防御は、CVE-2025-29927のようなmiddlewareバイパス脆弱性への対策にもなる。RBACパターンとの比較 RBACベストプラクティス  準拠状況  実装詳細  バックエンドでのポリシー強制  ✅ 準拠  ハンドラー内でロールチェック  フロントエンドはUI適応のみ  ✅ 準拠  メニュー表示/非表示で対応  権限キャッシュ  ❌ 未実装  毎リクエストでHydra呼び出し  中央集権的ポリシー管理  ⚠️ 部分的  定義は分散している  ロール階層の明確化  ✅ 準拠  4段階のロール階層を定義 総合評価 評価軸  スコア  コメント  OWASP Top 10 2025  7/10  基本的なアクセス制御は準拠、レート制限が不足  Next.js Security  8/10  多層防御を実装、HttpOnly Cookieが部分的  RBAC Patterns  7/10  フロントエンド/バックエンド分離は適切、権限定義が分散 強み：多層防御の実装：フロントエンド + バックエンド + ハンドラーの3層テナント分離：PostgreSQLスキーマレベルでのデータ分離OAuth2標準準拠：Ory Hydraによる標準的なOAuth2/OIDC実装トークン検証の二重化：自前JWT + Hydraイントロスペクションのフォールバック弱み：正直に言えば、見落としがあるかもしれない。セキュリティの評価は、「問題がない」ことを証明できない。見つかっていないだけかもしれない。だから、この記事を読んで「これで完璧だ」と思わないでほしい。OWASP Top 10のチェックリストを自分で回して、この記事で触れていない項目を確認してほしい。それを前提に、現時点で認識している弱みを列挙する。レート制限なし：DoS攻撃への脆弱性権限定義の分散：フロントエンドとバックエンドで定義が重複権限キャッシュなし：毎リクエストでHydraに問い合わせ監査ログの不足：アクセス制御失敗のアラート機能なし改善ロードマップ優先度順に改善すべき項目： 優先度  項目  工数  効果  高  レート制限の追加  小  DoS防止、OWASP準拠  高  監査ログとアラート  中  インシデント検出  高  セキュリティヘッダの追加  小  HSTS, X-Frame-Options, X-Content-Type-Options  中  権限定義の一元化  中  保守性向上  中  権限キャッシュ（Redis）  中  パフォーマンス向上  中  Cookie Prefix（__Host-）の導入  小  Cookie属性の強制  低  PKCE導入  小  認可コード横取り防止  低  HttpOnly Cookie化  中  XSS対策強化 // 改善案：tower-governor等でレート制限を追加use tower_governor::{governor::GovernorConfigBuilder, GovernorLayer};let governor_conf = GovernorConfigBuilder::default()    .per_second(10)    .burst_size(50)    .finish()?;let app = Router::new()    // ...    .layer(GovernorLayer { config: governor_conf });まとめOAuth2 + マルチテナントの認証システム実装を通じて学んだこと「動く」と「正しく動く」は違う：ログインできても、APIが動くとは限らない。APIが動いても、全ロールで正しく動くとは限らない。全ロールで動いても、攻撃に耐えるとは限らない。5つのバグすべてが、「ログインできた」の後に発見されたE2Eテストは必須：すべてユニットテストでは発見できなかった多層防御が重要：フロントエンドだけ、バックエンドだけでは不十分全ロールで検証する：「ログインできた」だけでは不十分ベストプラクティスとのギャップを把握する：何ができていて、何が不足しているかを明確にする認証は地味だが重要だ。インシデント対応のように緊張感もないし、新機能開発のような達成感もない。でも、認証が崩れたときの被害は、他のどの機能障害よりも大きい。過去に見た事例では、セッション管理の不備で全ユーザーのデータが漏洩した。復旧に数ヶ月、信頼回復に1年以上かかった。地味なものほど、丁寧にやる。例えば、この記事で示したE2Eテスト、全ロールでの検証、ベストプラクティスとの比較を、リリース前に必ず行う。それがインフラを支える人間の流儀だ。派手な仕事は誰でも丁寧にやる。地味な仕事を丁寧にやれるかどうかが、プロとアマチュアの違いだと思っている。「ログインできる」は最低条件であり、「安全にログインできる」「快適にログインできる」「問題が起きたときに追跡できる」まで含めて、初めて「認証が実装できた」と言える。この認証実装は完成ではなく、継続的に改善していく起点だ。半年後、1年後に見直したとき、「あの時の判断は正しかったか」を検証できるように、今回の記事を残しておく。次回予告ここまでの4記事で、OAuth2認可サーバー（Hydra）+ 自前認証プロバイダー（Rust）+ フロントエンド（Next.js）の構成が完成した。E2Eテストも通り、RBACも検証できた。しかし、レビューコメントが届いた。「パスワードリセット機能は？」「MFA対応の予定は？」全部、自分で実装するのか？——次回は、Ory Kratosを導入して認証機能を委譲する方法を解説する。syu-m-5151.hatenablog.com参考資料E2EテストPlaywright MCP - LLMがブラウザを操作するためのMCPサーバーModel Context Protocol (MCP) - LLMと外部ツールを接続するプロトコルOry HydraOry Hydra Documentation - Ory Hydra公式ドキュメントToken Introspection - トークンイントロスペクションAPILogin Flow - ログインフローの概念Consent Flow - 同意フローの概念OAuth2 Token Endpoint - トークンエンドポイントAPIリファレンスOAuth2 Revoke Token - トークン失効APIJWKS Endpoint - 公開鍵配信エンドポイントセキュリティガイドラインOWASP Top 10 2025 - Broken Access Control - アクセス制御の脆弱性OWASP Authorization Cheat Sheet - 認可チートシートOWASP Access Control Cheat Sheet - アクセス制御チートシートOWASP OAuth2 Cheat Sheet - OAuth2セキュリティチートシートAuth0 Token Storage - トークンストレージのベストプラクティスRFC 9700 - OAuth 2.0 Security Best Current Practice - OAuth2セキュリティBCPRBACOso: RBAC Role Based Access ControlLogRocket: Choosing the best access control model for frontendLeapcell: Implementing Robust RBAC Across Backend FrameworksNext.jsNext.js Authentication GuideNext.js MiddlewareCORSMDN: Cross-Origin Resource Sharing (CORS)tower-http CorsLayer]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Next.jsでOry Hydra認証を実装する ― マルチテナントSaaSでの実践]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/09/104616</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/09/104616</guid>
            <pubDate>Fri, 09 Jan 2026 01:46:16 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の記事では、RustでOry HydraのLogin/Consent Providerを実装した。5つのエンドポイント（GET/POST /login、GET/POST /consent、GET /logout）とHydra Admin APIの連携。Argon2idによるパスワードハッシュ、ユーザー列挙攻撃を防ぐテスト設計の話をした。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory HydraのLogin/Consent Providerの役割を理解している前提で進めます。syu-m-5151.hatenablog.com今回は、そのバックエンドと連携するフロントエンドをNext.js 15で実装する。なぜフロントエンドも自分で書くのか。認証フローを端から端まで把握しておきたいからだ。ちなみにフロントエンドは専門外なのである程度は許してほしいです。NextAuth.jsやAuth0のSDKを使えば楽だが、ブラックボックスのまま本番に出すのは怖い。何かが壊れたとき、「ライブラリの中で何が起きているかわからない」では障害対応で詰むことがある。もちろん、最終的なゴールは「理解した上でライブラリを使う」ことだ。車輪の再発明を推奨しているわけではない。OAuth2/OIDCフローをブラウザ側でどう扱うか。Cookie管理の罠。マルチテナント環境での認証の複雑さ。実際に動かして気づいたことを記録する。OAuth2認可コードフロー：フロントエンドから見た流れまず全体像を把握しておく。┌─────────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Browser   │     │   Next.js   │     │ Rust Backend│     │  Ory Hydra  ││  (User)     │     │  Frontend   │     │ (Provider)  │     │  (OAuth2)   │└──────┬──────┘     └──────┬──────┘     └──────┬──────┘     └──────┬──────┘       │                   │                   │                   │       │ 1. Login Click    │                   │                   │       │──────────────────>│                   │                   │       │                   │                   │                   │       │ 2. Redirect to    │                   │                   │       │    /oauth2/auth   │                   │                   │       │<──────────────────│                   │                   │       │                   │                   │                   │       │ 3. GET /oauth2/auth?client_id=...    │                   │       │──────────────────────────────────────────────────────────>│       │                   │                   │                   │       │ 4. Redirect to /login?login_challenge=xxx                 │       │<──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 5. GET /login                         │                   │       │──────────────────────────────────────>│                   │       │                   │                   │                   │       │ 6. Login Form     │                   │                   │       │<──────────────────────────────────────│                   │       │                   │                   │                   │       │ 7. POST /login (credentials)          │                   │       │──────────────────────────────────────>│                   │       │                   │                   │                   │       │                   │                   │ 8. Accept Login   │       │                   │                   │──────────────────>│       │                   │                   │                   │       │ 9. Redirect to /consent               │                   │       │<──────────────────────────────────────│                   │       │                   │                   │                   │       │ ... Consent Flow ...                  │                   │       │                   │                   │                   │       │ 10. Redirect to /callback?code=xxx    │                   │       │<──────────────────────────────────────────────────────────│       │                   │                   │                   │       │ 11. GET /callback │                   │                   │       │──────────────────>│                   │                   │       │                   │                   │                   │       │                   │ 12. Exchange code for tokens          │       │                   │──────────────────────────────────────>│       │                   │                   │                   │       │                   │ 13. Tokens (access, id, refresh)      │       │                   │<──────────────────────────────────────│       │                   │                   │                   │       │ 14. Set Cookie &  │                   │                   │       │     Redirect      │                   │                   │       │<──────────────────│                   │                   │このフローで重要なのは、フロントエンドは認証ロジックを持たないということだ。なぜか。フロントエンドのコードはユーザーのブラウザで動く。攻撃者は自由に改変できる。DevToolsを開けばJavaScriptは丸見えだし、リクエストも書き換えられる。認証ロジックをそこに置くということは、攻撃者に「好きに改ざんしていいですよ」と言っているようなものだ。認証情報の検証はすべてRustバックエンド（Login Provider）で行う。フロントエンドの役割は：認可エンドポイントへのリダイレクト開始コールバックで認可コードを受け取る認可コードをトークンに交換トークンをCookieに保存以降のAPI呼び出しでトークンを使用Next.js App Routerでの実装ディレクトリ構成frontend/src/├── app/│   ├── layout.tsx│   ├── page.tsx                    # ランディング│   ├── dashboard/page.tsx          # 認証後のダッシュボード│   ├── callback/page.tsx           # OAuth2コールバック│   └── api/auth/│       ├── login/route.ts          # ログイン開始│       ├── callback/route.ts       # コールバック処理│       └── logout/route.ts         # ログアウト├── components/│   └── shared/│       └── Header.tsx├── lib/│   └── api.ts                      # APIクライアント└── middleware.ts                   # 認証チェックログイン開始：認可エンドポイントへのリダイレクト// app/api/auth/login/route.tsimport { NextResponse } from "next/server";import crypto from "crypto";export async function GET(request: Request) {  const { searchParams } = new URL(request.url);  const returnTo = searchParams.get("returnTo") || "/dashboard";  // CSRF対策用のstate生成  const state = crypto.randomBytes(16).toString("hex");  // stateにリダイレクト先を含める（Base64エンコード）  const stateWithReturn = `${state}:${Buffer.from(returnTo).toString("base64")}`;  // Hydra認可エンドポイントへのURL構築  const params = new URLSearchParams({    client_id: process.env.OAUTH_CLIENT_ID!,    response_type: "code",    scope: "openid profile email",    redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,    state: stateWithReturn,  });  const authUrl = `${process.env.HYDRA_PUBLIC_URL}/oauth2/auth?${params}`;  return NextResponse.redirect(authUrl);}stateパラメータは2つの役割を持つ：CSRF対策：ランダムな値を含めることで、攻撃者が生成したURLでのコールバックを防ぐリダイレクト先の保持：認証後、元のページへ戻るためにreturnToをエンコードして含めるRFC 9700 (OAuth 2.0 Security Best Current Practice)では、stateパラメータによるCSRF対策が明記されている。認可サーバーがPKCEをサポートしていることを確認できるなら、PKCEでCSRF対策を兼ねることも可能だが、stateを使う方法が最も広くサポートされている。cheatsheetseries.owasp.orgコールバック処理：トークン取得とCookie設定ここが最も複雑な部分だ。// app/api/auth/callback/route.tsimport { NextResponse } from "next/server";export async function POST(request: Request) {  const body = await request.json();  const { code, state } = body;  // stateからリダイレクト先を取り出す  const [, returnToBase64] = state.split(":");  const returnTo = Buffer.from(returnToBase64, "base64").toString();  // 認可コードをトークンに交換  const tokenResponse = await fetch(    `${process.env.HYDRA_PUBLIC_URL}/oauth2/token`,    {      method: "POST",      headers: {        "Content-Type": "application/x-www-form-urlencoded",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString("base64")}`,      },      body: new URLSearchParams({        grant_type: "authorization_code",        code,        redirect_uri: `${process.env.NEXT_PUBLIC_URL}/callback`,      }),    }  );  if (!tokenResponse.ok) {    const error = await tokenResponse.text();    console.error("Token exchange failed:", error);    return NextResponse.json(      { error: "Token exchange failed" },      { status: 401 }    );  }  const tokens = await tokenResponse.json();  // IDトークンをデコードしてユーザー情報を取得  const idTokenPayload = JSON.parse(    Buffer.from(tokens.id_token.split(".")[1], "base64").toString()  );  console.log("ID token decoded:", idTokenPayload);  // レスポンスにCookieを設定  const response = NextResponse.json({ success: true, returnTo });  response.cookies.set("auth_token", tokens.access_token, {    httpOnly: false,  // クライアントJSからアクセス可能に    secure: process.env.NODE_ENV === "production",    sameSite: "lax",    maxAge: tokens.expires_in,    path: "/",  });  if (tokens.refresh_token) {    response.cookies.set("refresh_token", tokens.refresh_token, {      httpOnly: true,  // リフレッシュトークンはhttpOnlyで保護      secure: process.env.NODE_ENV === "production",      sameSite: "lax",      maxAge: 30 * 24 * 60 * 60, // 30日      path: "/",    });  }  return response;}Cookie設定で学んだこと最初、httpOnly: trueでアクセストークンを設定していた。OWASPのセッション管理チートシートによれば、これがセキュリティのベストプラクティスだ。しかし、クライアントサイドでAPIを呼び出す必要があった。owasp.org// クライアントコンポーネントでAPIを呼び出すuseEffect(() => {  const token = document.cookie    .split("; ")    .find((row) => row.startsWith("auth_token="))    ?.split("=")[1];  if (token) {    api.setToken(token);  }}, []);httpOnly: trueだとdocument.cookieからアクセスできない。選択肢は2つ：アクセストークンをhttpOnly: falseにする - クライアントJSからアクセス可能Server Componentからのみ API を呼ぶ - httpOnlyのまま、サーバーサイドで処理今回は1を選んだ。「httpOnlyをfalseにするなんて、セキュリティの教科書に反している」——そう思う人がいるかもしれない。私もそう思った。OWASPのチートシートにも「httpOnly: trueにしろ」と書いてある。でも、教科書に書いてあることと、目の前のシステムで最善の選択は、必ずしも一致しない。この判断には明確な理由がある。まず、脅威モデルを整理する。httpOnlyの目的は「XSSでトークンを盗まれること」を防ぐことだ。では、XSSが成功した場合に何が起きるか。攻撃者はユーザーのブラウザ上で任意のJavaScriptを実行できる。httpOnlyでトークンを保護しても、攻撃者はfetch('/api/user/delete', {credentials: 'include'})を実行できる。トークンを「盗む」ことはできなくても、「使う」ことはできる。しかし、httpOnly: falseにすることで追加のリスクが生じる。トークンを読み取って攻撃者のサーバーに送信できるため、攻撃者は別のマシンからトークンを使用できる。httpOnly: trueなら被害はそのブラウザセッション内に限定されるが、falseなら攻撃者が任意の場所からAPIを叩ける。つまり、httpOnlyは「トークンの窃取」を防ぐことで、XSS被害の範囲を限定する。しかし、XSS対策の本質は、そもそもXSSを発生させないことだ。CSP（Content Security Policy）、入力のサニタイズ、Reactの自動エスケープ——これらがXSS対策の本丸であり、httpOnlyは最後の砦にすぎない。その上で、今回の判断基準は以下だ。アクセストークンは短命（15分）: 仮に窃取されても、15分で無効化されるリフレッシュトークンはhttpOnly: trueで保護: 長期間有効なトークンは絶対に保護するクライアントサイドでのAPI呼び出しが必須: Server Componentだけでは実現できないリアルタイム機能があるしかし、これはトレードオフだ。Auth0のToken Storageガイドでは、SPAの場合、インメモリストレージが最も安全とされている。将来的にはBFF（Backend for Frontend）パターンに移行し、トークンをサーバーサイドで完全に管理する構成を検討している。Curity社のベストプラクティス記事では、JWTの安全な取り扱いについて詳しく解説されている。owasp.orgID Tokenの署名検証なぜ署名検証が必要か最初の実装では、ID Tokenを単純にBase64デコードしていた：// ❌ 危険：署名検証なしのデコードconst payload = JSON.parse(  Buffer.from(tokens.id_token.split(".")[1], "base64").toString());これは動く。中身も読める。でも、これでは改ざんを検出できない。「tokenエンドポイントから直接取得しているから、改ざんされることはないのでは？」と思うかもしれない。確かに、バックエンドでtokenエンドポイントを呼び出し、その結果をそのまま使うなら、経路上で改ざんされるリスクは低い。しかし、問題は別のところにある。フロントエンドにトークンを渡す設計だと、ブラウザ側で別のトークンに差し替えられる可能性がある。また、マイクロサービス間でトークンを渡す際、悪意あるサービスが偽トークンを送る可能性もある。署名検証は「このトークンは本当にHydraが発行したものか」を確認する仕組みだ。具体的に何が起きるか。攻撃者は以下のようなトークンを作成できる。// 攻撃者が作成した偽のトークンconst fakePayload = {  sub: "admin-user-id",  // 管理者のユーザーID  email: "admin@example.com",  role: "platform_admin",  // 権限昇格  tenant_id: "target-tenant",  // 他テナントへのアクセス  exp: 9999999999  // 無期限};const fakeToken = `eyJhbGciOiJub25lIn0.${btoa(JSON.stringify(fakePayload))}.`;署名検証をしていなければ、このトークンは「有効」として受け入れられる。攻撃者は任意のユーザーになりすまし、任意の権限を持ち、任意のテナントにアクセスできる。認証システムが完全に無意味になる。JWTは3つのパートで構成される：ヘッダー.ペイロード.署名。署名を検証しないということは、攻撃者が作った偽のトークンも受け入れてしまうということだ。これは「鍵のかかっていない金庫」と同じだ。中身は入っているが、誰でも開けられる。OpenID Connect Core 1.0のID Token検証仕様では、以下の検証が必須とされている：署名アルゴリズムの確認（alg）発行者の検証（iss = Hydra URL）対象者の検証（aud = クライアントID）有効期限の確認（exp）署名の検証（公開鍵で）joseライブラリによる実装joseライブラリを使うと、これらの検証を簡潔に実装できる。npm install jose// lib/auth.tsimport * as jose from "jose";export interface IdTokenClaims {  sub: string;  aud: string | string[];  iss: string;  exp: number;  iat: number;  email?: string;  role?: string;  tenant_id?: string;}/** * ID Tokenの署名を検証し、クレームを返す * @see https://openid.net/specs/openid-connect-core-1_0.html#IDTokenValidation */export async function verifyIdToken(idToken: string): Promise<IdTokenClaims> {  const hydraUrl = process.env.HYDRA_PUBLIC_URL || "http://localhost:4444";  const clientId = process.env.NEXT_PUBLIC_CLIENT_ID || "demo-client";  // JWKSエンドポイントから公開鍵を取得  // @see https://www.ory.sh/docs/hydra/reference/api#tag/jwk/operation/discoverJsonWebKeys  const JWKS = jose.createRemoteJWKSet(    new URL(`${hydraUrl}/.well-known/jwks.json`)  );  // 署名検証 + issuer/audience検証  const { payload } = await jose.jwtVerify(idToken, JWKS, {    issuer: hydraUrl,    audience: clientId,  });  return payload as IdTokenClaims;}コールバックでの使用// app/api/auth/callback/route.tsimport { verifyIdToken } from "@/lib/auth";export async function POST(request: Request) {  const { code } = await request.json();  // トークン交換...  const tokens = await exchangeCodeForTokens(code);  // ✅ 署名検証付きでID Tokenをデコード  try {    const claims = await verifyIdToken(tokens.id_token);    console.log("ID token verified:", {      sub: claims.sub,      email: claims.email,      role: claims.role,      iss: claims.iss,    });    // ユーザー情報をセッションに保存    const user = {      id: claims.sub,      email: claims.email || "unknown",      role: claims.role || "customer",      tenant_id: claims.tenant_id,    };    // Cookie設定...  } catch (error) {    console.error("ID token verification failed:", error);    return NextResponse.json(      { error: "Token verification failed" },      { status: 401 }    );  }}E2Eテストでの確認実際にログインフローを実行して、署名検証が機能していることを確認した。verifyIdToken()の内部ログと、コールバックハンドラーのログが出力される：ID token verified successfully: {  sub: 'c128f3e7-5013-46b8-add2-fbe0e78bfec7',  email: 'demo@example.com',  role: 'platform_admin',  iss: 'http://localhost:4444'}ID token verified and decoded: {  sub: 'c128f3e7-5013-46b8-add2-fbe0e78bfec7',  email: 'demo@example.com',  role: 'platform_admin',  tenant_id: undefined,  iss: 'http://localhost:4444',  aud: [ 'demo-client' ]}POST /api/auth/callback 200 in 609msverified successfullyと出力されれば、以下が確認できている：JWKSエンドポイント（/.well-known/jwks.json）から公開鍵を取得できた署名が正しく検証された（RS256）issがHydra URL（http://localhost:4444）と一致したaudにクライアントID（demo-client）が含まれていたトークンが有効期限内だったtenant_id: undefinedは、Platform Adminユーザーがテナントに所属していないため。通常のテナントユーザーでログインすると、ここにテナントIDが表示される。開発環境でのフォールバック開発環境ではJWKSエンドポイントにアクセスできない場合がある。その時は警告を出しつつ、署名なしデコードにフォールバックする：try {  const claims = await verifyIdToken(tokens.id_token);  // 検証成功} catch (verifyError) {  console.warn("ID token verification failed, falling back to unsafe decode");  console.warn("WARNING: Using unverified ID token claims. This is insecure!");  // 開発環境のみ許容  const unsafeClaims = decodeIdTokenUnsafe(tokens.id_token);  // ...}本番環境では、このフォールバックを無効化すべきだ。github.comマルチテナント認証JWTにテナント情報を含めるOry HydraのConsent画面で、ユーザーのテナント情報をIDトークンに含める。ベストプラクティスとして、Login時にcontextに保存したユーザー情報をConsent時に取得する（DBルックアップを回避）：// Rustバックエンド側（Consent Provider）// Best Practice: contextからユーザー情報を取得（DBルックアップ不要）// Login時にUserContextとして保存した情報をここで復元let user_context: Option<UserContext> = consent_request    .context    .as_ref()    .and_then(|ctx| serde_json::from_value(ctx.clone()).ok());let (user_email, user_role, user_tenant_id) = user_context    .map(|ctx| (ctx.email, ctx.role, ctx.tenant_id))    .unwrap_or_default();// IDトークンにカスタムクレームを追加let session = ConsentSession {    id_token: serde_json::json!({        "email": user_email,        "role": user_role,        "tenant_id": user_tenant_id,  // テナントIDを含める    }),};hydra.accept_consent(&challenge, grant_scope, grant_audience, Some(session)).await?;ここで重要なのは、user_emailやuser_roleをDBから取得するのではなく、Login時にHydraのcontextに保存したUserContextから取得している点だ。これにより：Consent時のDBアクセスが不要になるLogin時点のユーザー状態が保持される（整合性）パフォーマンスが向上するフロントエンドでトークンをデコードすると、テナント情報が取得できる：// IDトークンのペイロード例{  "aud": ["demo-client"],  "email": "manager@example.com",  "role": "manager",  "tenant_id": "aa8d56f1-a083-439b-996a-4a7b73698dfb",  "sub": "e5555555-5555-5555-5555-555555555555"}APIリクエストでのテナント分離バックエンドAPIは/api/v1/tenant/というプレフィックスでテナント固有のエンドポイントを提供：/api/v1/tenant/incidents    # テナント内のインシデント/api/v1/tenant/projects     # テナント内のプロジェクト/api/v1/tenant/engineers    # テナント内のエンジニアテナントIDはJWTから取得するため、URLにテナントIDを含める必要はない。これにより：URLの推測による他テナントへのアクセス試行を防ぐテナントIDの改ざんを防ぐ（JWTは署名で保護されている）なぜURLパスにテナントIDを含める方式が危険なのか、具体例で説明する。# URLパス方式（危険）GET /api/v1/tenants/tenant-123/incidentsGET /api/v1/tenants/tenant-456/incidents  ← tenant-123のユーザーがアクセスを試みるこの方式では、バックエンドで「リクエストしたユーザーがtenant-456に所属しているか」を毎回検証する必要がある。検証を忘れると、他テナントのデータが漏洩する。実際、この種のバグは「IDOR（Insecure Direct Object Reference）」として知られ、OWASPのトップ10に常に入る脆弱性だ。# JWTクレーム方式（安全）GET /api/v1/tenant/incidents# JWTの中身: {"tenant_id": "tenant-123", ...}この方式では、バックエンドはJWTからテナントIDを取得する。JWTは署名で保護されているため、ユーザーが改ざんできない。「どのテナントのデータを返すか」はJWTが決定し、URLは関与しない。URLパラメータとユーザー権限を照合する追加の検証が不要になるため、バグの入り込む余地が減る。このアプローチはMicrosoft Azure Architecture Centerでも推奨されている。ログアウト処理OAuth2のログアウトは複雑だ。以下を考慮する必要がある：フロントエンドのCookie削除HydraのOAuth2セッション無効化バックエンドのセッション無効化（該当する場合）// app/api/auth/logout/route.tsexport async function GET(request: Request) {  const accessToken = request.cookies.get("auth_token")?.value;  if (accessToken) {    // 1. Hydraでトークンを無効化    await fetch(`${process.env.HYDRA_PUBLIC_URL}/oauth2/revoke`, {      method: "POST",      headers: {        "Content-Type": "application/x-www-form-urlencoded",        Authorization: `Basic ${Buffer.from(          `${process.env.OAUTH_CLIENT_ID}:${process.env.OAUTH_CLIENT_SECRET}`        ).toString("base64")}`,      },      body: new URLSearchParams({        token: accessToken,      }),    });    // 2. Hydraのログインセッションも削除    // （IDトークンからsubjectを取得して削除）  }  // 3. Cookieを削除してリダイレクト  const response = NextResponse.redirect(new URL("/", request.url));  response.cookies.delete("auth_token");  response.cookies.delete("refresh_token");  return response;}RP-Initiated LogoutOpenID ConnectにはRP-Initiated Logout 1.0という仕様がある。この仕様では、Relying Party（クライアントアプリケーション）からOpenID Providerに対してログアウトを要求する方法が定義されている。Hydraはこれをサポートしている。www.ory.sh// Hydraのログアウトエンドポイントを使う方法const logoutUrl = new URL(`${process.env.HYDRA_PUBLIC_URL}/oauth2/sessions/logout`);logoutUrl.searchParams.set("id_token_hint", idToken);logoutUrl.searchParams.set("post_logout_redirect_uri", `${process.env.NEXT_PUBLIC_URL}/`);return NextResponse.redirect(logoutUrl);この方法だと、Hydraがログアウト処理を統括し、Login Providerの/logoutエンドポイントにリダイレクトしてくれる。トラブルシューティング：実際に遭遇した問題問題1：Cookie名の不一致症状：ログイン後、ダッシュボードでAPIデータが取得できない原因：コールバックで設定するCookie名と、各ページで読み取るCookie名が異なっていた// コールバックresponse.cookies.set("auth_token", ...);// ダッシュボード（間違い）.find((row) => row.startsWith("access_token="))// 正しくは.find((row) => row.startsWith("auth_token="))教訓：Cookie名は定数として一箇所で定義し、全体で共有する。なぜこのミスが起きるのか。認証コードはコールバック処理から書き始め、ダッシュボードは後から書く。時間が空くと、最初に使った名前を忘れる。「書いた順番」と「読まれる順番」が異なるコードでは、定数化を最初に行うべきだ。// lib/constants.tsexport const AUTH_COOKIE_NAME = "auth_token";export const REFRESH_COOKIE_NAME = "refresh_token";問題2：APIパスの構造症状：APIリクエストが404を返す原因：テナントAPIのパスプレフィックスを間違えていた// 間違いfetch("/api/v1/incidents")  // 404// 正しいfetch("/api/v1/tenant/incidents")  // 200教訓：APIのベースパスはAPIクライアントクラスで管理するclass ApiClient {  private baseUrl = process.env.NEXT_PUBLIC_API_URL;  private tenantPath = "/api/v1/tenant";  async getIncidents() {    return this.request(`${this.tenantPath}/incidents`);  }}問題3：トークン期限切れ症状：しばらく操作しないとAPI呼び出しが失敗する原因：アクセストークンの有効期限（15分）が切れていた対策：リフレッシュトークンを使った自動更新async request<T>(path: string, options?: RequestInit): Promise<T> {  const response = await fetch(`${this.baseUrl}${path}`, {    ...options,    headers: {      ...options?.headers,      Authorization: `Bearer ${this.token}`,    },  });  if (response.status === 401) {    // トークンをリフレッシュして再試行    await this.refreshToken();    return this.request(path, options);  }  return response.json();}問題4：HydraのセッションとProviderのセッション症状：ログアウト後、再度ログインしようとすると認証画面をスキップしてしまう原因：Hydraのログインセッションが残っていたOry Hydraのドキュメントによると、HydraはLogin Providerでの認証成功を記憶している。skipフラグが立っている場合、ログイン画面をスキップする。これはSSO（シングルサインオン）の正しい動作だが、完全なログアウトを実装する際には注意が必要だ。// Login Provider側if login_request.skip {    // 既にセッションがあるのでスキップ    // Note: skip時はcontextが既に設定されているためNoneで良い    let completed = hydra.accept_login(&challenge, &login_request.subject, false, None).await?;    return Ok(Redirect::to(&completed.redirect_to));}完全なログアウトには、Hydraのセッションも削除する必要がある：// ログアウト時にHydraのセッションも削除await fetch(  `${process.env.HYDRA_ADMIN_URL}/admin/oauth2/auth/sessions/login?subject=${userId}`,  { method: "DELETE" });エラーハンドリングのパターンバックエンドから返されるエラーは統一された形式になっている：{  "error": "invalid_credentials",  "error_description": "The provided credentials are invalid",  "error_code": "AUTH_002"}フロントエンドではこれを適切に処理する：async request<T>(path: string, options?: RequestInit): Promise<T> {  const response = await fetch(`${this.baseUrl}${path}`, options);  if (!response.ok) {    const error = await response.json().catch(() => ({      error: "unknown_error",      error_description: "An unexpected error occurred",    }));    throw new ApiError(response.status, error);  }  return response.json();}class ApiError extends Error {  constructor(    public status: number,    public body: { error: string; error_description: string; error_code?: string }  ) {    super(body.error_description);  }}セキュリティチェックリスト実装後に確認すべき項目。これは完璧なリストではない——セキュリティに完璧はない——が、最低限チェックすべきポイントをまとめた。認証に関わるCookieの属性[ ] HttpOnly属性: XSSの緩和策。クライアントJSからアクセス不要なCookieには必ず設定[ ] SameSite属性: LaxもしくはStrictに設定。CSRF対策の基本。Laxの場合、GETリクエストで更新処理を行っていないか確認[ ] Secure属性: HTTPS通信でのみCookieが送られるように。本番環境では必須[ ] Domain属性: サブドメインへのCookie送信範囲を理解しているか。example.comのCookieがjobs.example.comにも送られる設定だと、他サブドメインの脆弱性がリスクになる[ ] Cookie Prefix: Cookie名を__Host-で始めると、Domain属性が空でないCookieの指定を無視してくれる（参考: Cookie Prefixのバイパス）blog.tokumaru.orgレスポンスヘッダ[ ] Strict-Transport-Security（HSTS）: ブラウザにHTTPS接続を強制。max-age=31536000; includeSubDomains; preload[ ] X-Frame-Options: DENYもしくはSAMEORIGINでクリックジャッキング対策。CSPのframe-ancestorsも検討[ ] X-Content-Type-Options: nosniffを指定。MIMEタイプスニッフィング攻撃を防ぐ認証フロー[ ] stateパラメータでCSRF対策している[ ] リフレッシュトークンはhttpOnlyで保護している[ ] アクセストークンの有効期限は短く設定している（15分推奨）[ ] ログアウト時にトークンを無効化している[ ] メールアドレスの列挙ができないこと: ログイン画面やパスワード再設定画面で「このメールアドレスは登録されていません」のようなエラーを出さない[ ] JWTの署名を検証している（バックエンド側）[ ] テナント分離がJWTベースで行われている[ ] 退会/メールアドレス変更などの重要操作で直前のログインを必須にしている: XSSやセッションハイジャック発生時の緩和策その他[ ] サードパーティCookieに依存していないこと（Chrome廃止予定）[ ] iOS SafariのITPによりローカルストレージやJSから保存したCookieは7日で消える可能性がある（未使用時）まとめNext.jsでOry Hydra認証を実装する際の要点：OAuth2フローの理解：認可コードフローの各ステップでフロントエンドが何をすべきか把握するID Token署名検証：JWKSを使って署名を検証し、issuer/audienceを確認するCookie管理：httpOnly, Secure, SameSiteの設定を用途に応じて選択するマルチテナント：JWTにテナント情報を含め、APIはトークンからテナントを識別するエラーハンドリング：OAuth2仕様に沿ったエラー形式を統一的に処理するログアウト：Hydraのセッションとフロントエンドのセッション両方を考慮する認証は「動いた」で終わりではない。Cookie名の不一致のような単純なミスから、セッション管理の複雑さまで、実際に動かして初めて見つかる問題が多い。結局のところ、OAuth2は「誰かが決めた仕様に従う」ゲームだ。RFCを読み、OWASPを読み、Hydraのドキュメントを読む。自分で発明する余地は少ない。でも、それでいい。認証のような重要な仕組みを自己流で作るのは、傲慢だと思う。セキュリティの歴史は「賢い人が作ったものを、もっと賢い攻撃者が破る」の繰り返しだ。OAuth 1.0のセッション固定攻撃、JWTのalg=none脆弱性——仕様を作った人たちでさえ、穴を見落とす。自分がその歴史に新たな失敗を加える必要はない。先人の知恵に乗っかり、その上で自分のシステムに合った判断をする。それが現実的なアプローチだ。前回のバックエンド実装でユーザー列挙攻撃を防ぐテストを書いたように、フロントエンドでも手動でのE2Eテストが重要だ。ログイン→操作→ログアウト→再ログイン。このサイクルを何度も試して、エッジケースを潰していく。次回は、Playwright MCPを使ったE2Eテストの自動化と、テストで発見したバグについて解説する。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。おわりに今日は社内で学生向けワークショップを担当した。終わった後、若い参加者が話しかけてきた。「ブログ読んでます」と言われた。嬉しかった。嬉しかったが、すぐに釘を刺した。「あまり憧れないでくださいね」と。憧れられるのがあまり得意ではない。偶像として崇拝されるのが苦手だし、偶像として振る舞って相手に応えるのも苦手だ。それに、ブログで良いこと言っている人に若いうちから憧れすぎるのは良くない。自分がそうだったのでよく分かる。10代の頃、文章が上手くて考え方が明快な技術ブロガーを見つけて、「この人みたいになりたい」と思った。記事を読み漁った。でも、その人が実際にどんなコードを書いているかは知らなかった。ブログは編集された「ハイライト」にすぎない。裏側の泥臭い試行錯誤、失敗、妥協は見えない。数年後にそれを知ったとき、ちょっとがっかりした。がっかりした自分にもがっかりした。若い技術者なら、現場に居る良い技術者に憧れてほしい。ブログを書く人ではなく。GitHubのコミット履歴を見てほしい。PRのレビューコメントを見てほしい。本番障害のポストモーテムを読んでほしい。そこに本当の技術者がいる。ブログの「正解」ではなく、コードの「試行錯誤」に学んでほしい。正直に言えば、フロントエンドでの認証実装は想像以上に複雑だった。3年前の自分に言いたい。「Next.jsで認証？OAuth2知ってるし、すぐできるでしょ」と思っていた過去の自分に。そうじゃない。Cookieの属性一つでセキュリティモデルが変わる。ID Tokenの署名検証を省略した瞬間、認証システムの意味がなくなる。OAuth2のフローは理解していたつもりだった。RFCも読んだ。でも、実際にNext.jsでCookieを扱い、ID Tokenの署名を検証し、マルチテナントのテナント分離を実装すると、「知っている」と「動かせる」の間には大きな溝があることを思い知らされた。RFCには「stateパラメータでCSRF対策」と書いてある。でも、実際にコードを書くと「stateはどこに保存する？」「検証はいつやる？」「不一致の場合のエラーメッセージは？」という判断が次々と必要になる。仕様書は「何をすべきか」は教えてくれるが、「どう実装すべきか」は教えてくれない。その溝を埋めるのは、結局、自分で書いて動かす経験しかない。特にhttpOnlyの判断には時間を使った。OWASPのベストプラクティスを読み、Auth0のガイドを読み、それでも「これで正しいのか」という不安は消えない。セキュリティに100%の正解はない。トレードオフを理解し、判断し、記録する。それしかできることはない。この記事を書いている人間も、悩みながら書いている。ブログに書かれている「正解」は、試行錯誤の結果を事後的に整理したものにすぎない。過程で何度も間違えている。それを知った上で、参考にしてもらえれば。なんか総じてとても疲れた。でも、まあ、悪くない一日だった。参考資料Ory HydraOry Hydra DocumentationOAuth2 Token EndpointLogin FlowLogout FlowOAuth2/OIDC仕様RFC 6749 - OAuth 2.0RFC 9700 - OAuth 2.0 Security Best Current PracticeOpenID Connect Core 1.0RP-Initiated Logout 1.0セキュリティガイドラインOWASP OAuth2 Cheat SheetOWASP Session Management Cheat SheetAuth0 Token StorageCurity JWT Best PracticesCookie属性CookieのDomain属性は指定しないが一番安全 - 徳丸氏によるCookie Domain属性の解説Cookie Prefixのバイパス - __Host-プレフィックスの重要性MDN: Set-Cookie - Cookie属性の公式リファレンスサードパーティCookieの廃止に向けた準備 - Chrome対応ガイドライブラリjose - JavaScript Object Signing and EncryptionNext.jsNext.js App RouterRoute HandlersMiddleware]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fear of the Unknown：Rust/sqlxでNULLを制する6つのパターン]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/08/092409</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/08/092409</guid>
            <pubDate>Thu, 08 Jan 2026 00:24:09 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあるプロジェクトで、電話番号が未登録のユーザーを検索するコードをレビューしていた。WHERE phone = NULL——一見正しく見えるこのクエリは、常に0件を返していた。データは確実に存在する。クエリもシンプル。では何が問題なのか。答えはSQLの3値論理にあった。通常の比較演算はTRUEかFALSEを返すが、SQLにはUNKNOWN（不明）という第3の真偽値がある。NULLは「値が不明」を意味するため、NULL = NULLは「不明 = 不明」となり、結果もUNKNOWNになる。WHERE句はTRUEの行しか返さないから、UNKNOWNは暗黙にFALSE扱いされ、結果は常に0件になる。この問題は『SQLアンチパターン』で「Fear of the Unknown」として解説されている。本記事ではRust + sqlxでの実装パターンに焦点を当てる。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonこういう妄想の仕様と実際の仕様には違いがある。「おい、類推するな」というブログで書いたので時間がある時に読んでほしい。syu-m-5151.hatenablog.comsqlxの型マッピングRustにはOption<T>という型がある。これは「値があるかもしれないし、ないかもしれない」を表現する型だ。Some(値)が「値あり」、Noneが「値なし」を意味する。SQLのNULLに相当するのがこのNoneだ。let phone: Option<String> = Some("090-1234-5678".to_string());  // 値ありlet phone: Option<String> = None;                                // 値なし（NULL相当）sqlxはPostgreSQLのNULLをこのOption<T>に自動マッピングする。 PostgreSQL  Rust (NULLable)  Rust (NOT NULL)  VARCHAR, TEXT  Option\<String>  String  INTEGER  Option\<i32>  i32  BIGINT  Option\<i64>  i64  UUID  Option\<Uuid>  Uuid  DECIMAL  Option\<Decimal>  Decimal  TIMESTAMPTZ  Option\<DateTime\<Utc>>  DateTime\<Utc> NULLableカラムをOption<T>以外にマッピングすると、NULLが返された時点で実行時エラーになる。私も一度やった。「NULLなんて来ないだろう」と思っていたカラムが、特定の条件でNULLを返し、深夜にSlackが鳴った。#[derive(Debug, sqlx::FromRow)]struct User {    id: Uuid,    email: String,              // NOT NULL → 必ず値がある    name: String,               // NOT NULL → 必ず値がある    phone: Option<String>,      // NULLable → Option型で「値があるかもしれないし、ないかもしれない」を表現    bio: Option<String>,        // NULLable → Noneが「値なし」、Some("値")が「値あり」    created_at: DateTime<Utc>,  // NOT NULL → 必ず値がある}パターン1：検索フィルターでのNULL// NG: NoneがNULLにバインドされ、phone = NULLは常にUNKNOWN// query_as::<_, User>の説明://   ::<_, User> は戻り値の型を指定するRustの記法（turbofish構文）//   _ はデータベースの種類をコンパイラに推論させる部分//   User は「検索結果をUser構造体に変換して」という指定let users = sqlx::query_as::<_, User>(    "SELECT * FROM users WHERE phone = $1"  // $1はプレースホルダ（SQLインジェクション対策）).bind(&params.phone)  // bind()で$1に値を埋め込む。NoneはNULLになる.fetch_all(&pool)     // 全件取得.await?;              // 非同期処理の完了を待つ。?はエラー時に早期リターン// OK: 条件分岐でクエリを切り替える// match式: Option型の中身に応じて処理を分岐（switch文のようなもの）let users = match &params.phone {    Some(phone) => {  // Some(値): 値がある場合        sqlx::query_as::<_, User>("SELECT * FROM users WHERE phone = $1")            .bind(phone)            .fetch_all(&pool)            .await?    }    None => {  // None: 値がない場合 → IS NULLを使う        sqlx::query_as::<_, User>("SELECT * FROM users WHERE phone IS NULL")            .fetch_all(&pool)            .await?    }};// OK: IS NOT DISTINCT FROMで1クエリにまとめる（PostgreSQL固有）// NULLを普通の値として比較できる（NULL同士も「等しい」と判定）let users = sqlx::query_as::<_, User>(    "SELECT * FROM users WHERE phone IS NOT DISTINCT FROM $1").bind(&params.phone).fetch_all(&pool).await?;パターン2：COUNTの挙動// r#"..."# は生文字列リテラル（raw string literal）// 複数行のSQLを書きやすく、エスケープも不要な記法sqlx::query_as(    r#"    SELECT        COUNT(*) as total_users,                           -- 全行数（NULLを含む）        COUNT(coupon_code) as users_with_coupon,           -- NULLでない行数        COUNT(*) - COUNT(coupon_code) as users_without_coupon    FROM users    "#)空文字列とNULLが混在している場合は注意が必要。// NG: 空文字列のみマッチ、NULLはマッチしない"SELECT * FROM users WHERE coupon_code = ''"// OK: 両方を考慮"SELECT * FROM users WHERE coupon_code IS NULL OR coupon_code = ''"// OK: NULLIFで正規化"SELECT * FROM users WHERE NULLIF(coupon_code, '') IS NULL"パターン3：フォーム送信での空文字列フロントエンドから{ "phone": "" }が送られると、Option<String>ではSome("")になる。データベースには空文字列が保存され、NULLにはならない。// Rustレイヤーで正規化// filter(): 条件を満たさない場合はNoneに変換するメソッド// |s| !s.is_empty() はクロージャ（無名関数）: sが空でなければtruelet phone = req.phone.filter(|s| !s.is_empty());  // Some("") → None, Some("090") → Some("090")let bio = req.bio.filter(|s| !s.is_empty());sqlx::query("UPDATE users SET phone = $1, bio = $2 WHERE id = $3")    .bind(&phone)  // NoneはNULLとしてバインドされる    .bind(&bio)    .bind(user_id)    .execute(&pool)  // execute(): SELECT以外のクエリ実行    .await?;// SQLレイヤーで正規化sqlx::query(    r#"    UPDATE users    SET phone = NULLIF(TRIM($1), ''),  -- TRIM: 空白除去, NULLIF: ''ならNULLに        bio = NULLIF(TRIM($2), '')    WHERE id = $3    "#)パターン4：LEFT JOINでのOption必須LEFT JOINは左側のテーブル（例: users）の全行を返す。右側のテーブル（例: orders）に一致する行がない場合、右側のカラムはすべてNULLで埋められる。だから注文がないユーザーの場合、o.created_atはNULLになり、MAX(o.created_at)の結果もNULLになる。// NG: 注文がないユーザーでMAX(o.created_at)がNULLになり、実行時エラーstruct UserWithLastOrder {    last_order_date: DateTime<Utc>,  // NULLを受け付けない型}// OK: Option<T>でNULLを許容するstruct UserWithLastOrder {    last_order_date: Option<DateTime<Utc>>,  // NULLならNone、値があればSome(値)}LEFT JOINや集約関数（MAX, AVG, SUM等）の結果は常にNULLになりうる。迷ったらOption<T>を使う。パターン5：NOT INの罠// NG: category_idがNULLの行は削除されないsqlx::query(    r#"    DELETE FROM products    WHERE category_id NOT IN (        SELECT id FROM categories WHERE active = true    )    "#)なぜNULLの行が削除されないのか。NOT INは内部でx <> 1 AND x <> 2 AND ...に展開される。ここでcategory_idがNULLだとどうなるか。NULL <> 1はUNKNOWNを返す。NULL <> 2もUNKNOWN。ANDの3値論理ではTRUE AND UNKNOWN = UNKNOWNだから、条件全体がUNKNOWNになる。WHERE句はTRUEの行しか処理しないため、NULLを含む行は削除対象から外れてしまう。// OK: NOT EXISTSを使う// NULLの行も正しく処理される（サブクエリが0行ならTRUE）sqlx::query(    r#"    DELETE FROM products p    WHERE NOT EXISTS (        SELECT 1 FROM categories c        WHERE c.id = p.category_id AND c.active = true    )    "#)パターン6：query_as!マクロこれまでのパターンで使っていたquery_as()は実行時に型チェックを行う。一方query_as!()はマクロで、コンパイル時にデータベースへ接続してスキーマを確認し、型の不整合をビルドエラーとして検出する。NULLになりうるカラムをOption<T>以外でマッピングしようとすると、実行前にエラーを発見できる。// NG: AVG(rating)はNULLを返す可能性があり、コンパイルエラーstruct ProductSummary {    average_rating: f64,  // f64はNULLを受け付けない}sqlx::query_as!(    ProductSummary,    "SELECT name, AVG(rating) as average_rating FROM products GROUP BY name")// コンパイルエラー: AVGの結果がNULLになりうるのにOption<f64>ではない// OK: Option<T>を使うstruct ProductSummary {    average_rating: Option<f64>,}// OK: COALESCEと"!"サフィックスでNOT NULLを保証sqlx::query_as!(    ProductSummary,    r#"    SELECT name,           COALESCE(AVG(rating), 0)::FLOAT8  -- NULLなら0、FLOAT8にキャスト           as "average_rating!"              -- "!"でNOT NULLを宣言    FROM products GROUP BY name    "#) サフィックス  意味  !  NOT NULLを強制（Option\<T>ではなくT）  ?  NULLを許容（TではなくOption\<T>） まとめ冒頭のWHERE phone = NULLは、WHERE phone IS NULLに書き換えて5分で解決した。3値論理を知っているかどうか——それだけの差だった。NULLの問題はバグではなく、SQLの仕様だ。Rust/sqlxでは以下を守れば大半の問題は防げる。NULLableカラムはOption<T>にマッピング= NULLではなくIS NULLを使うNOT INではなくNOT EXISTSを使う空文字列とNULLを混在させない迷ったらOption<T>を使う。後からOptionを外すのは簡単だが、NULLが返ってきたときのパニックを本番で見るのは心臓に悪い。そもそもNULLableカラムを減らす設計（NOT NULL制約のデフォルト化、別テーブルへの分離）も検討に値する。3値論理の詳細は『SQLアンチパターン』の「Fear of the Unknown」章を参照してほしいです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料SQL Antipatterns - Fear of the UnknownPostgreSQL - Comparison Functionssqlx - Compile-time checked queries]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代に今からITエンジニアを目指す若者にオススメする10冊の本  2026年版]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/07/103853</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/07/103853</guid>
            <pubDate>Wed, 07 Jan 2026 01:38:53 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIは、あなたが聞いたことにしか答えない。聞かなかったことは、永遠に教えてくれない。あなたが何を知らないのか、AIは知らない。2026年だ。AIに聞けば何でも教えてくれる。コードを書いてもらい、設計を相談し、ドキュメントを要約させる。便利だ。では、なぜ本を読むのか。300ページもある本を、最初から最後まで読む必要があるのか。本は違う。本は、聞いていないことを語りかけてくる。知らなかった世界を見せてくる。持っていなかった問いを、手渡してくる。「そんなこと、考えたこともなかった」。そういう瞬間が、本にはある。AIとの対話では、たぶん起きない。AIは効率的だ。知りたいことに、最短距離でたどり着ける。でも、最短距離で歩いていると、道の脇にあるものが見えない。著者が失敗した話、遠回りした話、「今思えば間違いだった」という告白。そういう「寄り道」が、不思議と頭に残る。正解は忘れる。でも、誰かの失敗談は覚えている。たぶん、人間の脳は感情を伴う記憶を優先的に保持するからだ。著者の後悔や苦労を読むとき、読者は追体験している。その感情が、記憶を定着させる。AIに「失敗談を教えて」と聞けば、一般化された失敗談が返ってくる。でも、それは「誰かの」失敗ではない。固有名詞のない失敗談には、感情が宿らない。もう1つ。若者や学生は、そもそも問いを持っていない。何を聞けばいいか分からない。だから、AIに質問もできない。何が分からないのかも分からない。本を読めと言われても、何を読めばいいか分からない。本屋の技術書コーナーに行けば、棚一面に並ぶ背表紙の圧に押しつぶされそうになる。結局、何も買わずに帰る。本は、そういう人に問いをくれる。「あ、これが分からなかったのか」。読み終わって初めて、自分が何を知らなかったのかが分かる。問いを持たない人間に、問いを渡す。それが、本にしかできないことなのだと思う。そういう人のために、10冊を選んだ。「若者にオススメ」と書いておきながら、自分もまだ若い方なのだと思う。少なくとも、将来の自分から見れば若い。ただ、激動の時代だ。技術だけ磨いていればいい時代は、終わりかけているのかもしれない。あるいは、もう終わっているのかもしれない。だから、技術以外の本も混ぜて紹介することにした。先に断っておく。私はバックエンドエンジニアやインフラエンジニアからキャリアをスタートさせた人間だ。だから、フロントエンドやネイティブアプリに関しては、ほぼ紹介しない。偏っている。偏っているが、自分が読んでいない領域の本を勧めることはできない。プログラミング言語個別の書籍も紹介しない。どの言語を学ぶかは人によって違う。だから、言語に依存しない本を中心に選んだ。この10冊が良い10冊かどうかは、分からない。私が良いと思った本が、誰にとっても良いとは限らない。だから、この記事を「正解」として読まなくていい。「こういう本があるんだな」という参考程度に。それでいいのだと思う。それから、もう1つ。本を買うお金がないなら、図書館で借りればいい。技術書は高い。1冊3000円、4000円は当たり前だ。まず読む。金は後でいい。読んで、良かったら、いつか買えばいい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、本題に入る。技術の土台を作るまずは土台だ。プログラミングを始める前に、あるいは始めたばかりの頃に、IT業界で使われる言葉を知っておく必要がある。語彙がなければ、技術書も読めない。先輩の話も分からない。AIに質問もできない。1冊目：情報処理技術者試験の参考書（どれでもいい）1冊目から、いきなり「どれでもいい」と言うのは無責任に聞こえるかもしれない。でも、本当にそうなのだ。ITパスポートでも、基本情報技術者試験でも、応用情報技術者試験でも、高度試験でも。自分のレベルに合ったものを選べ。本屋で立ち読みして、7割くらい分かるやつを買え。分からなすぎると挫折する。簡単すぎると意味がない。誤解しないでほしい。資格を取れと言っているわけではない。「資格なんて意味ない」「資格より実務経験だ」——そういう声があるのは知っている。半分は正しい。資格を持っているだけでは、コードは1行も書けない。試験に受かっても、現場で即戦力にはなれない。それは分かっている。もっと言えば、試験に受からなくてもいい。俺は全然受からないのに優秀なソフトウェアエンジニアを死ぬほど知っている。資格の有無と実力は、必ずしも一致しない。でも、勉強するなら、頭に入った方がいいだろう。頭に入れるなら、試験を受けた方がいい。締め切りがあると、人は勉強する。試験日という締め切りがなければ、参考書は積読になる。金を払って申し込んで、日程を押さえて、会場に行く。その「仕組み」を使え。なぜ資格試験を勧めるのか。語彙が手に入るからだ。現場に出ると、専門用語が飛び交う。「スループットが落ちてる」「レイテンシがネックになってる」「冗長構成にしないと」「SLAどうする？」——こういう会話が、当たり前のように行われる。プログラミングはできるのに、この語彙がなくて会話に入れない。コードは書ける。でも、技術的な議論ができない。語彙がないと、会話にすら入れない。これは、よくある話だ。試験勉強を通じて、開発特有の語彙が頭に入る。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント。知識として知っているだけで、会話の輪に入れる。「あ、それ試験で出たな」という感覚で、先輩の話が理解できる。試験の内容を全部覚えている必要はない。語彙が残ればいい。それだけで、現場での学習速度が全然違う。ここで正直に言う。実務経験の方が大事だというのは、その通りだと思う。本を読むより、コードを書いた方がいい。知識を詰め込むより、実際にシステムを動かした方がいい。2026年の今なら、分からないことはAIに聞けばいい。AIに疑問をぶつければ、理解も早く進む。でも、経験がなければ、疑問も生まれない。これは「経験を積め」という精神論ではない。構造の問題だ。語彙がなければ問いが立たず、問いがなければ経験を言語化できず、言語化できなければ次の学習に繋がらない。この悪循環を断ち切るには、どこかで語彙を入れるしかない。何を聞けばいいか分からなければ、AIも使いこなせない。「スループット」という言葉を知らなければ、「スループットが落ちている原因は何ですか」とは聞けない。「処理が遅い」と「スループットが低い」は、同じ現象を指しているように見えるが、後者の方が解決策にたどり着きやすい。なぜなら、「スループット」という言葉には、それを改善するための知識体系が紐づいているからだ。語彙は、学習の入り口だ。入り口がなければ、どんなに優秀なAIがあっても、中に入れない。IPA（情報処理推進機構）の試験は、日本のIT業界における共通言語を学ぶのに最も効率がいい。ネットワーク、データベース、セキュリティ、プロジェクトマネジメント、システム設計。全部、体系的にまとまっている。しかも、過去問が無料で公開されている。金がないなら、参考書すら買わなくていい。過去問だけで受かる人もいる。2026年度から、応用情報技術者試験や高度試験がCBT（Computer Based Testing）方式に移行する。これまで年2回、決まった日に会場に足を運ばなければならなかったのが、自分の都合に合わせて受験できるようになる。受験のハードルは確実に下がった。どの参考書がいいかは、正直、好みだ。キタミ式が好きな人もいれば、技術評論社の「合格教本」シリーズが好きな人もいる。Amazonのレビューを見て、自分に合いそうなのを選べばいい。図書館にあることも多い。もう1つ言っておく。ITに興味があるけど、プログラミングには興味がない。そういう若者は多いと思う。「エンジニアになりたいけど、コードを書くのはちょっと……」という人。そういう人こそ、まず資格を取れ。プログラミングができなくても、ITの世界で活躍する道はいくらでもある。インフラ、セキュリティ、プロジェクトマネジメント、ITコンサル。そのすべてにおいて、資格で得た知識と語彙は武器になる。繰り返す。資格を取ることが目的ではない。語彙を入れることが目的だ。語彙があれば、AIにも質問できる。語彙があれば、技術書も読める。語彙があれば、先輩の話も分かる。入り口を作れ。話はそれからだ。www.meti.go.jpシステムの基盤を理解するコードを書けるようになっても、それだけではシステムは動かない。サーバー、ネットワーク、データベース、OS。アプリケーションの下にあるレイヤーを理解しなければ、本番環境で動くものは作れない。ここでは、システムを支える基盤技術について学ぶ本を4冊紹介する。2冊目：バックエンドエンジニアのためのインフラ・クラウド大全コードを書けるようになった。アプリケーションが動くようになった。でも、本番環境にデプロイしようとすると、急に分からないことだらけになる。サーバーって何？ネットワークって何？クラウドって何？アプリだけ書けても、本番では動かせない。この本は、そのギャップを埋めてくれる。バックエンドエンジニアに求められるインフラ・クラウド領域の基礎知識が、1冊にまとまっている。情報システムの基礎から、可用性、キャパシティ、パフォーマンス、監視、セキュリティ、DevOps、SRE。現場で必要になる知識が、体系的に整理されている。全23章、544ページ。分厚いが、それだけの価値がある。「基礎知識」と聞くと、簡単そうに思えるかもしれない。でも、違う。基礎とは、簡単という意味ではない。基礎とは、すべての土台になるという意味だ。なぜこの混同が起きるのか。学校教育のせいだろう。教科書は「基礎→応用」の順に並んでいて、基礎は最初に習う、つまり簡単なものだと刷り込まれる。でも、実際には逆だ。基礎は最後に理解できる。応用を経験して初めて、基礎の意味が分かる。この本に書かれていることは、10年後も20年後も変わらない原則ばかりだ。最初は分からなくていい。分からないまま読み進めて、5年後に読み返したとき、「ああ、これはこういう意味だったのか」と分かる。それが基礎だ。構成も良い。分野ごとに解説がまとまっているが、章末で「あわせて読みたい」範囲が紹介されている。1つの章を読み終わると、「次はこっちも読んでみるか」となる。ちょっとだけ調べるつもりが1時間経っている。そういう本だ。クラウドネイティブな環境では、アプリケーションとインフラの境界が曖昧になっている。コンテナ、Kubernetes、オブザーバビリティ。これらを理解せずに、本番環境で動くシステムは作れない。「俺はアプリ側だから」では通用しない時代だ。この本は、その橋渡しをしてくれる。以前、自分が書いたアプリケーションを本番環境にデプロイしたとき、ローカルでは動いていたのに、本番では動かなかった。原因を調べるのに丸1日かかった。ネットワークの設定だった。そのとき、「アプリを書けるだけでは、本番では戦えない」と痛感した。この本があの頃の自分にあったら、もう少し早く原因にたどり着けたかもしれない。バックエンドエンジニアのためのインフラ・クラウド大全【リフロー型】作者:馬場 俊彰,株式会社X-Tech5翔泳社Amazon3冊目：SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策データベースは、難しい。でも、難しいのに、簡単にできてしまう。ORMを使えば、SQLを書かなくてもデータを取得できる。CREATE TABLE文を書けば、テーブルが作れる。動く。動いてしまう。だから、問題に気づくのが遅れる。テーブル設計の失敗は、ソースコードの失敗よりもリファクタリングが難しい。データが入ってしまってからでは、修正のコストが跳ね上がる。だから、最初から正しい設計を知っておく必要がある。この本は、データベースプログラミングで陥りがちな失敗（アンチパターン）を体系的にまとめた本だ。カンマ区切りで値を格納する「ジェイウォーク」。外部キーを張らない「キーレスエントリ」。1つのカラムに複数の意味を持たせる「マルチカラムアトリビュート」。NULLの扱いを間違える「アンビギュアスグループ」。名前を聞いただけで「あ、やったことある」と思う人は多いはずだ。第2版では、新規書き下ろしの章と15のミニ・アンチパターンが加わった。特にミニ・アンチパターンは実務的な内容が多く、「自分もこの問題にハマった」「こうやって解決した」と思える内容が詰まっている。それなりにエンジニアをやっていると、多くのアンチパターンは踏んだことがある。でも、それを他者に体系的に伝えるのは難しい。自分の設計がシステムにどのような影響を与えていくかを経験として学習する機会は、意外と少ない。だからこそ、この本で先人の失敗を学んでおく価値がある。不思議なことがある。ベストプラクティスを調べて実装しても、想定通りにならないことが多い。環境が違う、前提が違う、規模が違う。でも、アンチパターンは違う。アンチパターンを実装すると、想定通りに困る。なぜか。アンチパターンは「制約違反」だからだ。リレーショナルデータベースには設計原則がある。その原則を破れば、必ず不整合やパフォーマンス問題が起きる。ベストプラクティスは「この文脈では有効」という条件付きだが、アンチパターンは「どの文脈でも有害」という普遍性を持つ。だから、何をすべきかより、何をすべきでないかを学ぶ方が、確実に役に立つ。SQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazon4冊目：モダンオペレーティングシステム 第5版（上・下）データベースの次は、さらに下のレイヤーだ。OSの話をする。OSの中身を知りたければ、この本を読め。プロセスとスレッド、メモリ管理、ファイルシステム、入出力、デッドロック、仮想化とクラウド、マルチプロセッサシステム、セキュリティ。OSを構成する要素が、網羅的に解説されている。上下巻合わせて1000ページ超。分厚いが、それだけの価値がある。コンピュータ・サイエンスの分野で世界的な定番となっている教科書だ。21年ぶりに日本語版が復活した。第5版では、Windows 11やSSDなど、最新のトピックまで詳しく解説されている。セキュリティの章は大部分が書き直された。各章末には585題もの演習問題がある。基礎知識の確認から、プログラミングや計算、さまざまな状況への対応まで。問題に取り組むことで、その章で学んだことの理解が深まる。上下巻で1万円を超える。学生には厳しい価格だ。だから言う。図書館で借りろ。大学の図書館には、たいてい置いてある。この本自体がなくても、類書は置いてある。以前、というかかなり昔にマルチスレッドのバグで丸2日を溶かしたことがある。ログを見ても再現しない。デバッガをつけると動く。原因はスレッド間のレースコンディションだった。そのとき、「なぜプロセスとスレッドが分かれているのか」「なぜロックが必要なのか」を、初めて本当に理解した。この本を先に読んでいたら、もう少し早く気づけたかもしれない。この辺はパタヘネ本など他にも良書があるのでそれらでもよい。モダンオペレーティングシステム 第5版 上作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazonモダンオペレーティングシステム 第5版 下作者:アンドリュー・S・タネンバウム,ハーバート・ボス日経BPAmazon5冊目：データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理OSの次は、分散システムだ。現代のアプリケーションは、1台のサーバーでは動かない。分散システム設計のあらゆるトピックを660ページに渡って網羅する、百科事典のような書籍。バックエンドエンジニアなら、いつかは読むべき本。データベース、レプリケーション、パーティショニング、トランザクション、分散システムの課題、バッチ処理、ストリーム処理。データを扱うシステムを設計する上で知っておくべき知識が、体系的に整理されている。この本の特徴は、何ができるか（WHAT）だけでなく、なぜそうなっているか（WHY）まで説明されていることだ。「なぜレプリケーションが難しいのか」「なぜ書き込み性能が高いマルチリーダーではなくシングルリーダーが広く使われているのか」。そういった「なぜ」を知ることができる。正直、難しい。分散システムに関わっていないと、なかなかピンとこない部分もある。入門として読む本ではない。でも、大規模でデータ量が多いアプリケーションを設計するときには、必ず役に立つ。2026年2月に原著の第2版が出版される予定だ。翻訳版も出てほしい。というか、出てくれ。頼む。この記事を定期的に更新するつもりなので、第2版が出たら差し替える。データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理作者:Martin Kleppmann,斉藤太郎,玉川竜司オライリージャパンAmazonプログラマーとしての姿勢を学ぶここまで、技術の土台とシステムの基盤について紹介してきた。ここからは、少し違う話をする。何を学ぶかではなく、どう向き合うかの話だ。技術は日々変わる。でも、変わらないものもある。良いコードを書くための考え方、問題に向き合う姿勢、キャリアを築くためのマインドセット。ここでは、プログラマーとしての「あり方」を教えてくれる本を紹介する。6冊目：達人プログラマー（第2版）熟達に向けたあなたの旅1999年に出版されて以来、世界中のプログラマーに読まれ続けている名著。2019年に20周年記念版として大幅に改訂され、第2版が出た。原題は「The Pragmatic Programmer」。Pragmaticとは、実用本位、実践的という意味だ。理論だけではなく、現場で使える知恵が詰まっている。この本の特徴は、コーディング技法だけでなく、エンジニアとしてのものの見方を教えてくれることだ。DRY原則、ETC原則（Easier To Change）、凝集度と疎結合。そういった技術的な話もあるが、それだけではない。開発の進め方、コミュニケーションの取り方、キャリアの考え方。プログラマーとして生きていくための姿勢が書かれている。「割れた窓」の話は有名だ。悪い設計、誤った意思決定、質の悪いコード。それを放置すると、ネガティブな考えが伝染する。だから、最初の「割れた窓」を見つけたら、すぐに直せ。自分もつい、割れた窓のようなコードを書いてしまったことがある。その後に若いプログラマに保守を任せたとき、いい書き方になっていなかった。元がよくない書き方だから、指摘するのも躊躇してしまう。「石のスープ」の話も印象的だ。大きな変化を一度に起こそうとすると、周囲は萎縮する。だから、小さく始めて、少しずつ巻き込んでいく。未来を少し垣間見せるだけで、みんな集まってくる。読み直すたびに、新しい発見がある。入門者には手引きとなり、ベテランでも読み返すたびに得るものがある。年に1回は読み返し、達人プログラマーを志していきたい。そういう本だ。20年以上読み継がれてきたからこそ、普遍的な価値がある。古い本だから読まなくていい、ということはない。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon7冊目：プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則KISS、DRY、YAGNI、SOLID。プログラミングの世界には、先人たちが積み上げてきた原理原則がある。でも、それらを体系的に学ぶ機会は意外と少ない。現場で「DRYって何？」と聞かれて、ちゃんと説明できるだろうか。この本は、そういった原理原則を101個集めて、1冊にまとめたものだ。「3年目までに身につけたい」という副題がついているが、3年目以降の人が読んでも学びがある。むしろ、色々な現場を経験した人の方が、それぞれの原理原則の含蓄を感じられる。「あのとき、これを知っていれば……」と思うことが、きっとある。この本の特徴は、各項目に「なぜそれが必要か」が明確に説明されていることだ。Howだけでなく、Whyが書かれている。だから、抽象的な情報でありながら、実際に使える知識になる。「How to本」ならぬ「Why本」だ。もう1つの特徴は、各項目に出典書籍と関連書籍が記載されていることだ。「達人プログラマー」「アジャイルソフトウェア開発の奥義」「プログラマが知るべき97のこと」など、名著への参照がちりばめられている。次に読む本を選ぶときの索引としても使える。具体的なコード例がないことを不満に思う人もいるかもしれない。でも、それは意図的だ。言語に依存しないからこそ、どんな言語でプログラミングしていても適用できる。抽象度が高い分、適用範囲は果てしなく広い。本書で「抽象」を押さえたら、「具象」も押さえたい。コードの書き方を扱った本では、『リーダブルコード』（Dustin Boswell、Trevor Foucher著、2012年）が定番として挙げられることが多い。変数名の付け方、コメントの書き方、制御フローの整理。確かに実践的な内容だ。でも、私のおすすめは『ルールズ・オブ・プログラミング』（Chris Zimmerman著、2023年）の方だ。『ルールズ・オブ・プログラミング』は、『Ghost of Tsushima』を開発したSucker Punch Productionsで実際に使われている21のルールをまとめた本だ。「最適化の前に単純化せよ」「コードを制約で囲め」「プログラマーの時間はCPUの時間より貴重」。ゲーム開発という、パフォーマンスと保守性の両方が求められる過酷な現場で磨かれたルールには、説得力がある。syu-m-5151.hatenablog.comもし「リーダブルコードを読め」と勧めてくる人がいたら、「ルールズ・オブ・プログラミングは読みましたか？」と聞いてみてほしい。読んだ上でリーダブルコードを勧めているなら、それは信頼できる。読んでいないなら、まず読んでもらってから、改めて話を聞けばいい。プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システム新社Amazon技術以外のスキルを身につけるプログラミングができればエンジニアとして成功できる。そう思っていた時期が、私にもあった。でも、現実は違う。あるプロジェクトで、技術的には正しい提案をしたことがある。でも、通らなかった。別のエンジニアの、技術的にはやや劣る提案が採用された。理由は「あいつの方が話しやすい」「あいつの言うことなら安心できる」だった。悔しかった。でも、それが現実だった。技術力だけでは、キャリアは伸びない。なぜか。2つの構造的理由がある。1つは、評価の非対称性だ。あなたの技術力を正しく評価できる人は、組織の中に何人いるか。CTOと数人の先輩エンジニアくらいだろう。でも、あなたのコミュニケーション力は、同僚全員が評価できる。評価が多数決に近い以上、「多くの人に見えるスキル」を持つ人が有利になる。もう1つは、レバレッジの問題だ。自分一人の技術力には限界がある。でも、他者を巻き込む力は、レバレッジが効く。10人を動かせる人は、自分1人で10倍の成果を出す人より、組織では重宝される。これが良いことかどうかは別として、構造としてそうなっている。だから、技術以外のスキルも身につける必要がある。8冊目：SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版技術書ではない。でも、エンジニアにとって必読の1冊だ。この本のサブタイトルは「ソフトウェア開発者の人生マニュアル」。技術習得法やキャリア構築法だけでなく、セルフマーケティング、生産性、資産形成、フィットネス、マインドセット。人生全般をより良く生きる方法が書かれている。「技術者の地位は技術力の高さではなく、他者の評価で決まってしまう」。これは厳しい現実だ。でも、現実を直視した上で、どうすればいいかを教えてくれる。キャリアをビジネスとして捉え、自分自身をマーケティングする。そういう視点を持つことの重要性が説かれている。正直に言うと、後半の資産形成やフィットネスの章は、ソフトウェア開発者に特化した話題ではない。不動産投資や筋トレの話がかなり詳しく書かれていて、「それ、この本でそこまで書く必要がある？」と思う人もいるだろう。私もそう思った。読む人を選ぶ本、という感想もある。でも、前半のキャリア、セルフマーケティング、学習、生産性の章は、間違いなく読む価値がある。技術力だけでは生き残れない時代に、何を身につけるべきか。その指針を与えてくれる。既に読者が若手ソフトウェアエンジニアの場合にはソフトウェアエンジニアガイドブック―世界基準エンジニアの成功戦略ロードマップも合わせておすすめしたい。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon設計とアーキテクチャを深める技術以外のスキルも大事だ。でも、技術を疎かにしていいわけではない。むしろ、技術力があってこそ、それ以外のスキルが活きる。コードが書けるようになったら、次は設計だ。どうやってモジュールを分けるか。どうやってシステム全体を構成するか。設計の良し悪しが、システムの保守性を決める。ここでは、設計とアーキテクチャについて学ぶ本を2冊紹介する。9冊目：アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築「アーキテクトになりたい」「アーキテクトとして成長したい」。そう思ったとき、何から始めればいいのか分からない人は多い。相談できる先輩や上司が身近にいないこともある。この本は、アーキテクティングという世界を探検するにあたっての「地図」となる本だ。アーキテクトの「最初の1冊」として、これ以上のものはない。第2章「ソフトウェア設計」では、V字モデル、4つの抽象（アーキテクチャ設計、モジュール設計、コンポーネント設計、クラス設計）、SOLID原則、設計パターンと、設計を語っていく上での基本概念が密度高く語られる。この章だけでも読んでおけば、設計の話をするときに「何を言っているのか分からない」という状態にはならない。オライリーの『ソフトウェアアーキテクチャの基礎』も良書だが、どこかアカデミックさがあり、ある程度の前提知識が要求される。それに比べて本書は、初学者にも分かりやすく書かれている。ユースケースに沿った解説があるのでおすすめである。第6章「アーキテクトとしての学習と成長」も見逃せない。普段のプロジェクトの中で表立って取り上げられることの少ないテーマだ。「自分がアーキテクトになっていくためにどんな心構えが必要なのか」と悩んでいる人には、とても学びの多い内容になっている。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon10冊目：ソフトウェア設計の結合バランス 持続可能な成長を支えるモジュール化の原則「疎結合にしろ」「密結合は悪だ」。そういうスローガンは、現場でよく聞く。でも、疎結合とは、具体的にどの程度が「疎」なのか。それを説明できる人は、意外と少ない。この本は、「結合」という概念を徹底的に掘り下げた本だ。本書の主張は明快だ。結合をゼロにすることは不可能であり、むしろ適切な結合を選択することが重要。「疎結合至上主義」ではなく、「結合の均衡化（Balancing Coupling）」という視点を提示している。構造化設計におけるモジュール結合、オブジェクト指向におけるコナーセンス。それらを一通り説明した後、独自の「統合強度」モデルが導入される。強度・距離・変動性の関係性を解き明かし、実際の設計においてそれらをどう均衡化するのかが、具体例を用いて示される。印象的だったのは、結合の「距離」という概念だ。同じ強度の結合でも、それが文レベル、メソッドレベル、オブジェクトレベル、サービスレベルのどこに存在するかによって、変更のコストが大きく異なる。マイクロサービスアーキテクチャの設計において、この視点は特に重要だ。この本は手順書でもルールブックでもない。この本に書かれている通りにモジュール設計をすれば自然とバランスの良い設計になる、という話ではない。でも、方針決定やレビュー時に迷ったとき、この本に書かれているような発想をインプットに意思決定すると、判断の精度が上がる。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonおわりに10冊を紹介した。この記事を読んだからといって、明日から何かが変わるわけではない。たぶん来週も、再来週も、同じような日々が続く。10冊すべてを読む必要もない。というか、いきなり10冊読み終わることなんてない。自分も、速読で済ませようとしたことがある。でも、身につかなかった。1冊読んで、合わなければ閉じればいい。それでいい。派手な近道はない。地味な積み重ねだけがある。常に今の自分で戦うしかない。1つだけ、注意しておきたいことがある。誰かを冷笑したり、バカにしたりするのは楽だ。でも、その道に未来はない。他人をバカにしない唯一の方法は、自分が自分の枠の中で精一杯頑張ることだ。精一杯やっている人間は、他人を笑っている暇がない。syu-m-5151.hatenablog.com私も、達人と呼ばれたい者の1人だ。まだ諦めているわけではない。諦めているわけではないが、達人になれるかどうかは分からない。分からないまま、コードを書いている。本を読んでいる。冒頭で、本は問いをくれると書いた。知らなかった世界を見せてくれると書いた。10冊のうち、どれか1冊でも手に取ってもらえたら、と思う。読み終わったとき、新しい問いが生まれているかもしれない。「あ、これが分からなかったのか」。そう思えたら、その本は、あなたにとって正解だったのだと思う。本との出会いは、計画だけでは起きない。本屋に行くと、紹介した本の隣に、もっと自分に合った本が置いてあるかもしれない。図書館で棚を眺めていると、別の本が目に入るかもしれない。そういう出会いは、検索では起きない。AIにも、たぶん見つけられない。だから、本屋に行ってみてもいいかもしれない。図書館に寄ってみてもいいかもしれない。棚の前に立ってみる。それだけでいい。何かが始まるかどうかは、分からない。分からないが、始まるとしたら、たぶんそこからだ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustでOry Hydra用認証プロバイダーを実装する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/06/004244</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/06/004244</guid>
            <pubDate>Mon, 05 Jan 2026 15:42:44 GMT</pubDate>
            <content:encoded><![CDATA[はじめに年が明けた。月曜日。エディタを開いている。認証プロバイダーを自分で実装できるか、と聞かれたら、たぶん「できる」と答える。OAuth2のRFCは読んだ。フローも理解している、と思う。ただ、「じゃあ書いて」と言われたとき、キーボードに手を置いたまま止まってしまうことがある。頭では分かっている。手が動かない。10年近くインフラやプラットフォームを触ってきた。認可の仕組みは何度も設計した。Kubernetesの認証、サービスメッシュの認可、アクセストークンの検証。それでも「Login Providerをゼロから書け」と言われると、急に自信がなくなる。分かっているはずなのに、分かっていない気がする。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon知ってるつもり～「問題発見力」を高める「知識システム」の作り方～ (光文社新書)作者:西林 克彦光文社AmazonOry Hydraのドキュメントを開く。Login ProviderとConsent Providerを自分で実装しろ、と書いてある。Node.jsのサンプルがある。Goのサンプルもある。どちらも動く。でも私はRustで書きたかった。年末年始、ぼんやり考えていて気づいたことがある。止まっているのは、技術的に難しいからではない気がする。「何をどの順番で実装すればいいのか」が見えていないのだ。全体像が掴めないまま、最初の一歩が踏み出せずにいる。だからこの記事を書くことにした。過去の自分に向けて。最初の一歩を、順番に。前提知識: この記事は前回の記事の続編です。OAuth2認可コードフローの基礎知識と、Ory Hydraのアーキテクチャ（Login/Consent Providerの役割）を理解している前提で進めます。syu-m-5151.hatenablog.com作るものLogin/Consent Providerとは、Ory Hydraと連携してOAuth2認証フローを処理するWebアプリケーションだ。以下の5つのエンドポイントを実装する。 エンドポイント  役割  GET /login  ログインフォームを表示する  POST /login  認証処理を行い、Hydraに結果を通知する  GET /consent  スコープ承認画面を表示する  POST /consent  承認結果をHydraに通知し、トークン発行へ進む  GET /logout  ログアウト処理を行い、セッションを破棄する 全体の流れOAuth2認可コードフローの中で、Login/Consent Providerがどう動くかを示す。1. ユーザーがクライアントアプリで「ログイン」をクリック2. クライアントがHydraの /oauth2/auth にリダイレクト3. Hydra が Login Provider の GET /login にリダイレクト（login_challenge付き）4. Login Provider がログインフォームを表示5. ユーザーがメール・パスワードを入力して送信6. Login Provider が認証し、Hydra に accept_login を送信7. Hydra が Consent Provider の GET /consent にリダイレクト（consent_challenge付き）8. Consent Provider がスコープ承認画面を表示9. ユーザーが承認10. Consent Provider が Hydra に accept_consent を送信11. Hydra がクライアントにリダイレクト（認可コード付き）12. クライアントが認可コードをトークンに交換Login/Consent Providerが担当するのは3〜10だ。Hydraとの通信には6つのAPIを使う。 API  役割  GET /admin/oauth2/auth/requests/login  login_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/login/accept  認証成功をHydraに通知  GET /admin/oauth2/auth/requests/consent  consent_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/consent/accept  承認結果をHydraに通知  GET /admin/oauth2/auth/requests/logout  logout_challengeからリクエスト情報を取得  PUT /admin/oauth2/auth/requests/logout/accept  ログアウトをHydraに通知 www.ory.comLogin HandlerLogin Handlerは2つのエンドポイントで構成される。GET /loginクエリパラメータからlogin_challengeを取得するHydra APIでlogin_challengeを検証し、リクエスト情報を取得するskipフラグが立っていれば（既にセッションがあれば）、フォームを表示せず即座にaccept_loginそうでなければログインフォームを表示するPOST /loginフォームからemail、password、login_challengeを受け取る認証サービスでパスワードを検証する認証成功なら、ユーザー情報をcontextに詰めてaccept_loginを呼ぶHydraが返すリダイレクトURLへ転送するpub async fn login_submit(    State(state): State<AppState>,    Form(form): Form<LoginForm>,) -> Result<Redirect, AppError> {    // 1. 認証処理    let user = state.auth.authenticate(&form.email, &form.password).await?;    // 2. ユーザー情報をcontextに保存（Consent時にDBルックアップ不要）    let user_context = UserContext {        email: user.email.clone(),        role: "customer".to_string(),        tenant_id: None,    };    // 3. Hydraに認証成功を通知    let completed = state        .hydra        .accept_login(            &form.login_challenge,            &user.id.to_string(),            false,            Some(serde_json::to_value(&user_context)?),        )        .await?;    // 4. Consent画面へリダイレクト    Ok(Redirect::to(&completed.redirect_to))}ポイントはcontextだ。Login時に認証したユーザー情報（email、role、tenant_id）をJSON形式で保存し、Consent Providerへ受け渡す。これにより、Consent処理でDBルックアップが不要になる。Consent HandlerConsent Handlerも2つのエンドポイントで構成される。GET /consentクエリパラメータからconsent_challengeを取得するHydra APIでリクエスト情報（要求されたスコープ、クライアント情報）を取得するskipフラグが立っていれば（既に承認済みなら）、即座にaccept_consentそうでなければスコープ承認画面を表示するPOST /consentフォームからconsent_challengeと承認するスコープを受け取るLogin時に保存したcontextからユーザー情報を取得するIDトークンにカスタムクレーム（email、role、tenant_id）を追加するaccept_consentを呼び、Hydraが返すリダイレクトURLへ転送するIDトークンにクレームを追加することで、クライアントアプリケーションはトークンをデコードするだけでユーザー情報を取得できる。Logout HandlerLogout Handlerは1つのエンドポイントで構成される。Login/Consentと比べてシンプルだ。GET /logoutクエリパラメータからlogout_challengeを取得するHydra APIでaccept_logoutを呼び出すHydraが返すリダイレクトURLへ転送するpub async fn logout_handler(    State(state): State<AppState>,    Query(query): Query<LogoutQuery>,) -> Result<Redirect, AppError> {    let completed = state.hydra.accept_logout(&query.logout_challenge).await?;    Ok(Redirect::to(&completed.redirect_to))}ログアウトフローはLogin/Consentと異なり、確認画面を表示せずに即座にaccept_logoutを呼んでいる。本番環境では「本当にログアウトしますか？」という確認画面を挟むことを検討してもよい。動作確認docker compose up -d./scripts/e2e-test.shIDトークンにemail、role、subが含まれていれば成功だ。ここまでが「何を作るか」「どう動くか」の説明だ。以降は実装の詳細に入る。認証サービスの実装Login Handlerから呼び出される認証サービスの実装に入る。パスワード認証にはOWASPのガイドラインに従い、Argon2idを採用した。cheatsheetseries.owasp.orgArgon2::default()を使っているが、これは意図的だ。argon2クレートのデフォルト値はOWASP推奨設定に準拠している。「専門家が作ったものを信頼する方が合理的」という前回の記事と同じ論理だ。認証部分で見落としがちなのが次の点だ。pub async fn authenticate(&self, email: &str, password: &str) -> Result<User, AppError> {    let users = self.users.read().await;    let user = users.get(email).ok_or(AppError::InvalidCredentials)?;    Argon2::default()        .verify_password(password.as_bytes(), &parsed_hash)        .map_err(|_| AppError::InvalidCredentials)?;    Ok(user.clone())}ユーザーが存在しない場合も、パスワードが間違っている場合も、返すエラーは同じInvalidCredentialsだ。「ユーザーが見つかりません」というエラーを返したくなるが、それは攻撃者に情報を与えてしまう。これはユーザー列挙攻撃（User Enumeration Attack）への対策だ。攻撃者はまず有効なメールアドレスを特定しようとする。エラーメッセージが違えば、登録済みかどうかが分かってしまう。なお、完全な対策にはタイミング攻撃への考慮も必要だ。ユーザーが存在しない場合はArgon2の検証が走らないため、レスポンス時間の差で存在を推測される可能性がある。本番環境では、ユーザー不在時もダミーハッシュを検証することを検討してほしい。owasp.orgテスト設計認証システムのバグは「静かに」起きる。だからテストの考え方も変わる。普通の機能開発では「この操作をしたらこうなる」というテストを書く。でも認証システムでは「この操作をしてもこうならない」というテストの方に価値がある。#[tokio::test]async fn test_login_does_not_reveal_user_existence() {    let service = AuthService::new();    service.register("exists@example.com", "password").await.unwrap();    let err1 = service.authenticate("exists@example.com", "wrong").await.unwrap_err();    let err2 = service.authenticate("nobody@example.com", "password").await.unwrap_err();    assert_eq!(err1.to_string(), err2.to_string());}このテストは「エラーメッセージが同じ」という実装の意図を明示化している。将来誰かが「親切なエラーメッセージにしよう」と思って変更しても、このテストが警告を出す。責任分界点全ての攻撃をアプリケーション層で防ぐ必要はない。何を守り、何をインフラに任せるかを明確にする。ブルートフォース対策: Nginxのrate limitで弾くセッション固定化攻撃: フレームワーク（Axum + tower-sessions）に委譲HTTPS強制: インフラ設定の問題プロジェクト構成今回はAxumを使った。github.comsrc/├── main.rs          # サーバーエントリーポイント├── auth.rs          # 認証サービス├── handlers.rs      # Login/Consent/Logoutハンドラー├── hydra.rs         # Hydra Admin APIクライアント├── models.rs        # Hydra API型定義└── error.rs         # エラー型定義ハンドラー層とサービス層を分離している。認証ロジックはauth.rsに置き、ハンドラーはHTTPリクエストの受け取りとレスポンスの返却だけを担う。フルコードはGitHubリポジトリを参照してほしい。github.com実装チェックリスト必須の実装[ ] Hydra APIクライアント - 6つのAPI呼び出し[ ] GET /login - login_challenge検証、skipフラグ確認、フォーム表示[ ] POST /login - 認証、contextにユーザー情報、accept_login[ ] GET /consent - consent_challenge検証、skipフラグ確認、承認画面表示[ ] POST /consent - context取得、IDトークンにクレーム追加、accept_consent[ ] GET /logout - logout_challenge取得、accept_logout[ ] 認証サービス - Argon2id、ユーザー列挙攻撃対策忘れがちなポイントlogin_challengeとconsent_challengeはhiddenフィールドでフォームに埋め込むskipフラグが立っている場合は画面を表示せず即座にacceptするcontextでLogin→Consent間のユーザー情報受け渡しエラーメッセージはユーザーの存在を漏らさないおわりにこの文章を書き終えて、ターミナルに戻った。docker compose up -dを叩く。コンテナが立ち上がる。E2Eテストを走らせる。グリーン。IDトークンにemailとroleが入っている。動いた。正直に言うと、書いている途中で何度か不安になった。これで説明になっているのか。Login HandlerとConsent Handlerの違いが曖昧になっていないか。contextの使い方は2回書き直した。それでも、動いた。冒頭で書いた「キーボードに手を置いたまま止まってしまう」感覚は、たぶん、また来る。次に認証システムを書くときも、OAuth2のフローを思い出すところから始めるだろう。login_challengeって何だっけ、と調べ直すかもしれない。それでいいのだと思う。認証は「一度理解したら終わり」という領域ではない気がする。毎回、RFCを確認しながら、慎重に実装する。ユーザー列挙攻撃のテストを書いたのも、将来の自分が「親切なエラーメッセージ」を入れようとしたときに止めるためだ。年が明けて、また仕事が始まる。本番の認証システムはOry Hydraに任せる。Login Providerは自分で書く。その境界線が、今の私には見えている気がする。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、辞めるな]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/05/090020</guid>
            <pubDate>Mon, 05 Jan 2026 00:00:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめにかつての私は、深夜2時にベッドの中で転職サイトを開いていた。開いて、求人を眺めて、閉じて、また開く。そういうことを繰り返していた。辞めたいのか、と聞かれると困った。会社の限界が見えたのか。自分の天井が見えたのか。それとも、隣の芝生の青さに目が眩んでいただけなのか。たぶん、全部だった。たぶん、どれでもなかった。今は、転職を考えていない。これは「今の会社が最高だから」という話ではない。どんな会社にも良い面と悪い面がある。不満がゼロになることはない。ただ、深夜に転職サイトを開く衝動は、いつの間にか消えた。何が変わったのか。環境が変わったのか、自分が変わったのか。たぶん、両方だ。「エンジニアは転職で年収が上がる」「成長できる環境に身を置け」——そんな言葉がタイムラインに流れてくる。転職エージェントからのスカウトメールは週に何通も届く。カジュアル面談のお誘い。年収アップの可能性。もっと刺激的な環境。全部、本当のことだと思う。全部、嘘だとも思う。若いエンジニアが短期的にモノを考えてしまうのは、仕方がない。私もそうだった。目の前の不満が大きく見える。3年後、5年後のことなんて、想像できない。「今すぐ環境を変えたい」という衝動は、若さゆえの特権でもある。その衝動を否定するつもりはない。ただ、かつての自分に言いたいことがある。「おい、ちょっと待て」と。私自身、何度も転職を考えた。「もう限界だ」「ここにいても意味がない」「他の会社ならもっとできるはずだ」——そう思って、転職サイトを眺めた夜は数えきれない。そして、実際に転職したこともある。転職して正解だったケースもあった。「あのタイミングで辞めなくてよかった」と思うケースもあった。だから、この記事で「辞めるな」と書くのは、上から目線のアドバイスではない。かつての自分への手紙だ。あのとき、もう少し踏みとどまっていたらどうなっていたか。もう少し早く辞めていたらどうなっていたか。そういう問いを、今も抱えている。——もし読んでいて上から目線に感じたなら、それは私の力量不足だ。申し訳ない。ある日、気づいたことがある。深夜に転職サイトを開く自分と、翌朝それを後悔する自分は、同じ人間なのに、まったく違うことを考えている。どちらが本当の自分なのか。たぶん、どちらも本当だ。だから困る。この記事は、深夜の衝動と、翌朝の冷静さの、両方に向けて書いている。この記事が、辞めそうな若手に上司から共有されないことを祈っている。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しい。「転職しやすい」という罠ITエンジニアは「転職しやすい職業」だと言われる。確かにそうだ。求人は多い。売り手市場だ。スキルがあれば、転職先を見つけることは比較的容易だろう。だが、「転職しやすい」ことと「キャリアを作れる」ことは、全く別の話だ。私自身、この罠にはまった。転職市場で「引く手あまた」だった時期がある。スカウトメールは毎週届いた。カジュアル面談をすれば、たいてい次のステップに進めた。「自分は市場価値が高い」と思っていた。でも、それは錯覚だった。振り返ると、私は「転職できる」ことと「キャリアを積み上げている」ことを混同していた。転職市場で需要があるのは、単に「エンジニアが足りない」からだ。私個人の価値が高いわけではない。需要と供給のバランスが崩れているだけ。その状況に甘えて、「いつでも転職できる」という安心感に浸っていた。「3年で転職すれば年収が上がる」という話もある。だが、これは単純化しすぎた話だ。実際には、年収が上がる転職もあれば、上がらない転職もある。そして、年収が上がらない転職の方が、実は多い。なぜか。転職には必ずロスが発生するからだ。私が転職したとき、最初の3ヶ月は本当に苦しかった。前職では「あいつに聞けば分かる」と言われていた領域があった。コードベースを熟知していた。誰に何を聞けばいいか知っていた。暗黙のルールも把握していた。転職した瞬間、それが全部ゼロになった。会議で発言しても、「この人、誰？」という空気が流れる。提案しても、文脈を知らないから的外れになる。前職では30分で終わる作業が、3時間かかる。「俺はもっとできるはずなのに」——そう思いながら、毎日を過ごしていた。これが「転職のロス」だ。どんなに経験者であっても、新しい会社のコンテキストをつかむには時間がかかる。前職で積み上げた信頼貯金は、転職した瞬間にリセットされる。私がこの記事で伝えたいのは、現場で働いてきた人間としての実感だ。机上の空論ではなく、実際に転職を経験し、成功も失敗もしてきた中で気づいたことを書く。一見「転職しやすい」ように見えるITエンジニアほど、実は「キャリアを作ること」が難しい——これが私の結論だ。転職のハードルが低いからこそ、安易に転職してしまう。そして、キャリアが積み上がらないまま、年齢だけが積み上がっていく。ただ、ここまで書いてきて、誤解されたくないことがある。「辞めたい」と思うのは、悪いことではない「転職には罠がある」と書いた。でも、それは「辞めたいと思うこと自体が悪い」という意味ではない。ここで1つ、大事なことを言っておきたい。「辞めたい」と思うこと自体は、悪いことではない。むしろ、自然なことだ。どんな会社にも、良い面と悪い面がある。仕事には波がある。うまくいく時期もあれば、何をやってもダメな時期もある。人間関係でストレスを感じることもある。深夜2時に転職サイトを眺める。上司との関係がうまくいかなくて、帰りの電車で「もう嫌だ」と思う。日曜の夜、明日会社に行きたくないと感じる。そういう瞬間は、誰にでもある。私にもあった。今でもある。だから、この記事を読んで「辞めたいと思っている自分はダメだ」とは思わないでほしい。辞めたいと思うことと、実際に辞めることは、別の問題だ。ただ、この分離は言うほど簡単ではない。深夜2時に転職サイトを見ているとき、「これは感情だ、今は判断するな」と冷静に思える人がどれだけいるだろうか。私自身、何度も感情に流されて判断しそうになった。だから、私は自分にルールを課している。1回目で決めるな。深夜のベッドで「辞めたい」と思った。それは1回目だ。まだ決めるな。翌週、上司に理不尽なことを言われて「辞めたい」と思った。まだ決めるな。1ヶ月後、半年後、同じ状況で同じことを思うか。時間をかけて、何度も問い直せ。衝動ではなく、熟慮の末に出した答えなら、それが「辞める」でも「残る」でも、後悔は少ない。要するに、短期ではなく長期で考えろ、ということだ。目の前の感情に振り回されるな。5年後、10年後の自分がどうなっていたいか。そこから逆算して、今の決断を考えろ。正直に言えば、3年程度では何も身についていない。「3年経験があります」と言っても、それは今の環境が整っている状況で、その能力が発揮できる程度だ。上司が調整してくれて、先輩がフォローしてくれて、チームが支えてくれて、ようやく成果が出せている。その支えがなくなった瞬間、同じパフォーマンスが出せるか。出せないなら、それは本当に「能力」と呼べるのか。感情は感情として受け止めていい。ただ、その感情だけで大きな決断をしないでほしい。この記事は、そのための材料を提供したいと思っている。では、冷静に考えるとは、具体的に何を考えればいいのか。次に目指す役割を明確にするまず最初に考えるべきは、「次にどこへ向かいたいのか」だ。エンジニアのキャリアには、いくつかの方向性がある。技術を深める方向——テックリードやスペシャリストだ。特定の領域で「この人に聞けば分かる」と言われる存在になる。アーキテクチャの意思決定を任される。難しい技術的課題を解決する。人を率いる方向——エンジニアリングマネージャー（EM）だ。チームの生産性を最大化する。メンバーの成長を支援する。採用や評価といった組織課題に向き合う。事業に近づく方向——プロダクトマネージャーや、ビジネスサイドとの橋渡し役だ。「何を作るか」を決める側に回る。技術とビジネスの両方を理解し、最適な解を見つける。ここで強調しておきたいのは、IC（Individual Contributor）トラック——部下を持たずに技術で貢献し続けるキャリアパス——という選択肢の存在だ。スタッフエンジニア、プリンシパルエンジニアといった役職は、マネージャーにならずとも、より大きなインパクトを生み出す道だ。マネジメントだけが「上」ではない。シニアの先には4つの方向性がある。テックリード（チームの技術方針を導く）、アーキテクト（システム設計の意思決定を担う）、ソルバー（組織横断の難問を解決する）、ライトハンド（経営層の右腕として動く）。どれを目指すかで、求められるスキルセットも変わる。全部できる必要はない。どれを選ぶかは、あなた次第だ。重要なのは、スタッフエンジニアは「シニアのシニア」ではないということだ。役割そのものが変わる。コードを書く時間は減り、リーダーシップ、ファシリテーション、組織の接着剤としての仕事が増える。「もっとコードを書きたい」という人には向かない道だ。だから、「シニアになったら自動的にスタッフを目指す」という発想は危険だと私は思っている。多くのエンジニアは、最初は「一人前の開発者」からスタートする。そこから、どの方向に進むか。それを決めるのは、あなた自身だ。ここで自分に問いかけてほしい。あなたは次にどの方向に進みたいのか。それが言語化できていないなら、転職を考えるのはまだ早い。なぜなら、方向が定まっていない転職は、ただの「移動」に過ぎないからだ。移動しても、キャリアは積み上がらない。方向性を考えることと同じくらい大事なことがある。「自分は今、どこにいるのか」を知ることだ。自分の能力を棚卸しする目指す方向が見えてきたとしよう。でも、その方向に進むためには、今の自分の立ち位置を正確に把握する必要がある。転職を考えるとき、多くの人は外側に目を向ける。「あの会社は良さそうだ」「この技術を使ってみたい」「あの人みたいになりたい」。でも、本当に大事なのは、自分という器がどうなっているかを知ることだ。どんなに良い環境に移っても、器が変わらなければ、入ってくるものは同じだ。逆に、自分の器をちゃんと理解していれば、今の環境でも次の環境でも、適切な選択ができる。ここで、転職を考える前に確認してほしいことがある。自分の「実力」を正しく評価できているか、ということだ。私は長い間、この評価を間違えていた。ゾーンに入って神がかった速度でコードを書く自分、難解なバグを一瞬で特定する自分——そういう「最高の瞬間」を「自分の実力」だと信じていた。だから、転職先でも同じパフォーマンスが出せると思っていた。逆だった。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」だ。絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎない。転職先で、その「上振れ」を再現できる保証はどこにもない。なぜこれが転職を考えるときに重要なのか。信頼は「下限」に支払われるからだ。新しい職場で、あなたは「最高の自分」ではなく「最悪の自分」で評価される。慣れない環境、知らないコードベース、初対面のチームメンバー。その状況で出せるアウトプットが、あなたの「実力」として記録される。「本当はもっとできるんです」は通用しない。だから、転職先を選ぶときに問うべきは、「最高の自分が活躍できる場所か」ではない。「最悪の自分でも、最低限のパフォーマンスを出せる場所か」だ。もう1つ、能力について知っておくべきことがある。能力は文脈の中にしかない。今の環境で「できる人」だとしても、それは文脈に依存している。私自身、痛い目を見た。あるプロジェクトで成果を出せたとき、私はそれを自分の実力だと思っていた。でも振り返ると、違った。上司が事前に関係者と調整してくれていた。マネージャーがスコープを適切に切ってくれていた。先輩が技術的な地雷を踏む前に教えてくれていた。私は、応援してくれて、調整してくれていたマネージャーや上司の能力まで、自分の能力だと勘違いしていた。その支えが消えた環境で、同じパフォーマンスを出せるか。出せるわけがない。正しい認識はこうだ。「この文脈において、これまでの経験と周囲のサポートが噛み合って、たまたま価値が出せている」。では、その「器」——能力——は、どう捉えればいいのか。大きく分けて3つの軸がある。技術力——コードを書く力だ。設計力、実装力、レビュー力。特定の領域を深掘りする「スペシャリスト」か、複数の領域をカバーする「ジェネラリスト」か。どちらを目指すにせよ、ここが基盤になる。推進力——プロジェクトを前に進める力だ。タスクを完遂できるか。障害にぶつかっても解決策を見つけられるか。チームのボトルネックを解消できるか。「なぜこの機能が必要か」というビジネス課題を理解し、技術的な意思決定をビジネスインパクトで説明できるか。影響力——自分の外側に価値を生み出す力だ。チームへの影響力は、採用、オンボーディング、ドキュメント整備、勉強会の開催など。社外への影響力は、技術ブログ、カンファレンス登壇、OSS貢献など。どの軸を伸ばすかは、目指す役割によって変わる。テックリードを目指すなら技術力と推進力。EMを目指すなら推進力と影響力。スペシャリストを目指すなら技術力を極める。重要なのは、全部を上げようとしないことだ。自分が目指す役割に必要な能力を見極めて、そこに集中する。ここで、私自身の失敗を話したい。かつての私は「良いコードを書いていれば、いつか評価される」と思っていた。技術力さえあれば、周りが認めてくれる。黙々と良い仕事をしていれば、誰かが見ている。——甘かった。現実はこうだ。見えない仕事は、存在しないのと同じ。どんなに素晴らしい設計をしても、それを言語化して共有しなければ、誰も知らない。どんなに難しいバグを直しても、「大変だった」と伝えなければ、簡単な修正だと思われる。「仕事をやり遂げる人」として認められるには、技術的な能力だけでなく「何が重要かを見極める力」と「自分の仕事を周囲に伝える力」が必要だ。この2つを、私は長い間、軽視していた。「アピールするのは恥ずかしい」「実力で示せばいい」——そう思っていた。でも、それは傲慢だった。相手の時間を奪わずに、自分の仕事の価値を簡潔に伝えること。それはコミュニケーションスキルであり、チームで働く上での基本的な作法なのだ。つまり、私は「技術力」に過剰投資し、「推進力」と「影響力」に過少投資していた。多くのエンジニアは、同じ罠にはまる。新しいフレームワークを学ぶ。新しい言語を触る。それは楽しいし、成長した気になる。だが、「推進力」——泥臭い調整や、やり切る力——の不足から目を背けていないか。技術力があっても、プロジェクトを完遂できなければ、市場価値は上がらない。今の会社を辞めようとしているあなた。この3つの軸で自分を評価してみてほしい。次に目指す役割に対して、どの軸が足りていないのか。それが明確になっていないなら、転職しても同じ困難にぶつかる。環境を変えても、足りない能力は足りないままだ。ただ、ここで1つ付け加えたいことがある。能力を棚卸しするとき、多くの人は「足りないもの」ばかりを見る。私もそうだった。「技術力が足りない」「推進力が弱い」「影響力がない」——チェックリストを見て、できないことを数え上げる。そして、転職先を探すときも「ここに行けば○○が身につく」「あの会社なら△△を学べる」と、ないものを補う発想で動いてしまう。ないものを探し続けていたら、悩みは一生消えない。考えてみてほしい。どんな環境に行っても、足りないものは必ずある。新しい技術が次々に出てくる。上には上がいる。「あれもできない、これもできない」と数え上げれば、キリがない。そうやって「ないもの」を埋めようとしている限り、永遠に充足感は得られない。私自身、この罠に長い間はまっていた。「もっとコードが書けるようになりたい」「もっとコミュニケーション力をつけたい」「もっとビジネス視点を持ちたい」——足りないものリストは常に更新され続けた。そして気づいた。そのリストは、一生埋まらない。発想を変えよう。「ないものを探す」のではなく、「あるものを伸ばす」。あなたには、すでに強みがある。周囲より得意なことがある。それが何かを見極めて、そこに集中する。弱みを平均まで引き上げる努力は、強みを突き抜けさせる努力より、はるかに効率が悪い。私の場合、「調べること」「言語化すること」「ソフトウェアを実装すること」が比較的得意だった。コミュニケーション力が高いわけではない。政治的な立ち回りも苦手だ。でも、RFCやドキュメントを読み込んで理解し、それを実際に動くコードに落とし込み、さらに文章としてまとめることなら、周囲より少しだけ速かった。その「少しだけ」を、徹底的に伸ばすことにした。結果として、「あいつに任せれば、調べて、作って、ドキュメントにしてくれる」という評価が生まれた。これは戦略的な選択だ。何をやるかではなく、何をやらないか。弱みを気にして、あれもこれもと手を広げるのではなく、強みに絞って、そこで突き抜ける。だから、能力を棚卸しするとき、「足りないもの」だけでなく「すでにあるもの」にも目を向けてほしい。転職を考えるとき、「ここに行けば足りないものが補える」ではなく、「ここに行けば今の強みがさらに活きる」という視点で選んでほしい。足りないものは、一生足りない。だから、足りないものを数えるのをやめろ。今あるものを、もっと伸ばせ。正直に告白しよう。私には、仕事を選ぶときの悪い癖がある。小さなバグを直す。ドキュメントの誤字を修正する。チェックリストを埋めていく。1日の終わりに「今日も色々やった」と思える。でも、週末に振り返ると、本当にインパクトのある仕事をしたのか、分からなくなる。——これが、私の悪い癖だ。簡単で達成感はあるが、インパクトの低い仕事に逃げてしまう。お菓子をつまむように、小さなタスクをつまんでしまう。これが「スナッキング」だ。チェックリストを埋める快感は、脳にとって報酬だ。でも、その報酬に溺れて、本当に重要な仕事——曖昧で、難しくて、すぐに結果が出ない仕事——から逃げていないか。もう1つ、自分を戒めている罠がある。目立つが価値の低い仕事だ。社内の勉強会を頻繁に開く。Slackで積極的に発言する。目立つ。注目を集める。でも、ビジネスへの貢献は薄い。この罠にはまると、「忙しかった」と「成果を出した」を混同するようになる。振り返ってほしい。直近1ヶ月で、最もインパクトのあった仕事は何だったか。それに費やした時間は、全体の何割だったか。もし1割以下なら、残りの9割は「スナッキング」だった可能性がある。ここまで、「どこを目指すか」と「何を伸ばすか」について話してきた。では、実際に転職するとなったとき、何を失い、何を得るのか。その前に、転職を考えるときの大前提を確認しておきたい。「自分は会社にとって必要な存在だ」と思っているかもしれない。でも、それは本当だろうか。「替えが効く」という前提を認める別に会社なんていつ辞めても良い。文字通りの意味で替えの効かない人間なんて資本主義においては存在しない。これは冷徹な事実だ。どんなに優秀なエンジニアでも、会社は回る。あなたが辞めても、誰かが引き継ぐ。プロジェクトは続く。組織は適応する。「私がいないと回らない」——そう思いたい気持ちは分かる。でも、それは幻想だ。私自身、これを認めるのに時間がかかった。ある会社を辞めるとき、「自分がいなくなったら、あのシステムは誰がメンテするんだろう」と心配していた。3ヶ月後、元同僚に聞いた。「全然大丈夫だよ。○○さんが引き継いで、むしろ前より整理されてる」。——少し寂しかったが、同時にホッとした。そして気づいた。私は「替えが効かない」と思いたかっただけだ。この事実を認めることは、絶望ではない。むしろ、解放だ。「替えが効かない」と思い込んでいると、会社に縛られる。「私がいないと困る」「今辞めたら迷惑をかける」——そういう責任感は美しいが、それが「辞められない」という足枷になることがある。ブラックな環境でも我慢してしまう。メンタルを壊しても「今は辞められない」と言い聞かせる。替えが効くと認めることで、初めて「辞める」という選択肢が本当の意味で手に入る。ただし、ここで短絡的な結論に飛ばないでほしい。「替えが効く」→「だから辞めてもいい」——これは論理の飛躍だ。「替えが効く」から導ける結論は、もう1つある。「だから、どこに行っても価値を出せる能力を磨け」だ。会社にとって、あなたは替えが効く。だが、あなたにとって、積み上げた実績は替えが効かない。ここが重要だ。会社はあなたを手放せる。次の人を雇えばいい。でも、あなたが2年間かけて積み上げた信頼、ドメイン知識、人間関係——これは、転職した瞬間にリセットされる。会社にとっては「替えが効く」リソースでも、あなたにとっては「替えが効かない」資産なのだ。だから、問いはこうなる。「会社にとって替えが効く」という事実を認めた上で、「自分にとって替えが効かない資産」をどれだけ積み上げたか。信頼の複利、実績の蓄積、ドメイン知識——これらは「会社のため」に積み上げるのではない。「自分のため」に積み上げる。たまたま、その資産が今の会社で活きているだけだ。転職すれば、その一部はリセットされる。リセットされてでも得たいものがあるなら、辞めればいい。リセットするには惜しい資産があるなら、もう少し留まって、その資産を使い切ってから辞めればいい。「替えが効く」という事実は、転職を正当化する理由にも、現職に留まる理由にもなる。どちらの結論を導くかは、あなた次第だ。大事なのは、この事実を、感情的な決断の言い訳に使わないことだ。「どうせ替えが効くんだから、辞めてもいいでしょ」——それは、考えることを放棄している。「替えが効くからこそ、自分の資産を最大化する選択をする」——それが、戦略的な判断だ。この前提を踏まえた上で、いよいよ転職のコストについて考えよう。「替えが効く」からこそ、転職は自由にできる。だが、自由にできるからといって、コストがゼロなわけではない。転職は「投資」であり「リセット」である若さという資源は有限だ。私たちはキャリアを積む中で何かを投資し、その結果として何かを得ている。この構造を理解しないまま転職を繰り返すのは危険だ。20代の私は、この構造を理解していなかった。「若いうちは色々経験した方がいい」「転職で視野が広がる」——そういう言葉を真に受けて、2〜3年ごとに環境を変えていた。確かに視野は広がった。でも、振り返ると、広く浅くなっただけだった。新卒で未経験のうちは何もない。あるのはポテンシャルであり、若さであり、可能性だ。その資源を使い、何かしらの資産を得る必要がある。何を得るのか。それはスキルであり、それを活用した先の実績だ。実績は資産だ。そして資産には複利が効く。ある領域で実績を出すと、次はもう少し大きな仕事が回ってくる。それをこなすと、さらに大きな仕事が来る。「あの人はこの領域で結果を出した」という評判が、次の機会を連れてくる。これが複利だ。私が見てきた「キャリアがうまくいっている人」は、例外なくこの複利を回していた。1つの実績が次の実績を呼び、雪だるま式に大きくなっていく。逆に言えば、転職するたびにこの複利がリセットされる。転職するたびに、一定のロスが発生する。ビジネスドメインの理解、社内の人間関係、意思決定のプロセス、暗黙知として共有されている文化。これは、転職した瞬間にリセットされる。信頼貯金も同様だ。前職で積み上げた「あいつなら任せられる」という信頼は、新しい会社では通用しない。ゼロから積み上げ直す必要がある。この「リセットコスト」を、転職を考えるときに計算しているだろうか。私は、転職のリセットコストを「半年〜1年」と見積もっている。新しい環境でコンテキストをつかみ、信頼を積み上げ、本来のパフォーマンスを発揮できるようになるまでの時間だ。転職した直後の、あの居心地の悪さを覚えているだろうか。私が転職して最初の1週間、Slackの雑談チャンネルを眺めていた。前職では、私も会話の輪に入っていた。誰かが投稿すれば、すぐにリアクションをつけた。冗談を言えば、笑ってくれる人がいた。でも新しい会社では、誰も私のことを知らない。雑談チャンネルに何か書こうとして、やめた。「この人、誰？」と思われるのが怖かった。些細なことだ。でも、あの孤独感は今でも覚えている。前職では「あいつに聞けば分かる」と頼られていたのに、新しい会社では誰も自分を知らない。会議で発言しても、反応が薄い。提案しても、「この人は何者だ？」という目で見られる。チャットで質問しても、返事が遅い。——あの感覚は、信頼貯金がゼロになった瞬間だ。これが「信頼の貯金」だ。具体的に言おう。「あの件、○○さんに頼んでおけば大丈夫」——そう思われるまでに、どれだけの時間がかかっただろうか。最初は小さな仕事を任される。それを期限通りに、期待以上の品質で納める。次は少し大きな仕事を任される。また納める。この繰り返しで、「この人なら任せられる」という信頼が積み上がっていく。信頼があると、仕事が回りやすくなる。他のチームに協力を頼むとき、「あの人の頼みなら」と動いてもらえる。提案するとき、「あの人が言うなら、一度聞いてみよう」と耳を傾けてもらえる。逆に信頼がないと、どんなに正しいことを言っても、「あの人、誰？」で終わる。周囲があなたと一緒に働きたいと思う度合いが、あなたの成功を直接左右する。そして、この信頼の貯金は、転職した瞬間にゼロにリセットされる。前職で「あの人は信頼できる」と思われていても、新しい会社では関係ない。ゼロから積み上げ直すしかない。今の会社で、信頼貯金はどれくらい貯まっているか。その信頼貯金を使ってできる挑戦は、まだ残っていないか。せっかく貯めた信頼貯金を、使わずに捨てるのは、もったいなくないか。ここで、信頼貯金のROI（投資対効果）を考えてみてほしい。今の会社で積み上げた信頼があるからこそ挑戦できる「高難易度・高リターン」の仕事はないか。新規プロジェクトの立ち上げ。技術的負債の解消。チームの構造改革。こういう挑戦は、信頼がなければ任されない。信頼があるからこそ、「あいつに任せてみよう」となる。転職先で得られる期待値は、このリセットコストを支払ってでも余りあるほど高いか。その根拠は何か。「なんとなく成長できそう」ではなく、具体的に何を得られるのか。それを言語化できなければ、転職は「期待値の高い投資」ではなく、「よく分からないギャンブル」になる。ここまで、転職のコストについて話してきた。では、そのコストを支払う価値があるかどうかを判断するために、何を見ればいいのか。それは、今の場所で何を積み上げたか、だ。現職で何を成し遂げたか転職を考えるとき、多くの人は「次に何をしたいか」を考える。でも、その前に考えるべきことがある。現職で何を成し遂げたかだ。きつい言い方をする——これは私自身への言葉でもあるのだが——。転職する時に現職で主体的に動いて成し遂げた実績が語れなければ、現職の経験はエンジニアキッザニアに近い。シニアエンジニアやCTOが用意してくれた環境で、お膳立てされた仕事をこなしていただけ。新しいスキルが身についたとする。それは素晴らしい。でも、それだけでは足りない。そのスキルを使って、どのようなビジネス価値を出したのか。その過程でどう主体的に関わったのか。これが語れなければ、あなたは「お客さん」のままだ。もちろん、「キッザニア」も大事だ。お膳立てされた環境で体感したことは血肉になる。でも、それでいいのはある段階までだ。年収700万円、800万円、その先を目指すなら、「遊ばせてもらう側」から「遊び場を作る側」に回る必要がある。技術力だけでは昇進できない——これは誰でも言える。問題は、なぜ、分かっていても実践できないのかだ。「コードで問題を解決する」。それが私たちのアイデンティティだ。だから、可視化やスポンサー獲得を「政治的で汚い」と感じてしまう。「実力で認められたい」。その気持ちは痛いほど分かる。私もそうだった。でも現実は違う。技術的に正しい提案をしても、周囲を巻き込めなければ、提案は提案のまま終わる。「技術で解決できる」ことと「解決を任される」ことは、別の能力だ。私自身、昇進を見送られた経験がある。なぜ評価されないのか分からなかった。振り返って気づいた。上司が私のキャリア目標を察してくれることを、勝手に期待していた。「昇進したいです」と言ったことがあっただろうか。なかった。上司はエスパーではない。言わなければ、伝わらない。そしてもう1つ。技術的な正しさを組織に浸透させるのも、「技術」だ。相手の立場を理解し、伝わる言葉で説明し、合意を形成する。これを「政治」と呼ぶなら、政治もまた技術なのだ。そして、成果を出すだけで終わりではない。私は日報をつける習慣を大事にしている。Claude Codeを使って、日々の作業を記録している。何をやったか、何を学んだか、何に詰まったか。こうして記録しておけば、パフォーマンスレビューの自己評価で圧倒的に有利になる。半年前、1年前に何を達成したか、正確に思い出せるだろうか。記録がなければ、自分の成果を過小評価してしまう。成果を出すことと、成果を可視化することは、別のスキルだ。昇進には「スポンサー」と「可視化」が必要だ。スポンサーとは何か。あなたの成果を経営層に伝えてくれる人だ。上司や先輩の中に、「あいつは良い仕事をしている」と会議で言ってくれる人はいるか。人事評価の場で、あなたの名前を出してくれる人はいるか。いくら良い仕事をしても、上層部に伝わらなければ、昇進の話にはならない。スポンサーは単なる応援者ではなく、あなたのキャリアに実際に投資してくれる存在だ。可視化とは何か。自分の仕事の価値を、他人が理解できる形で残すことだ。「何を達成したか」「なぜそれが重要だったか」「組織にどう貢献したか」——これをドキュメントやSlackで発信しているか。戦略的に重要なプロジェクトに参加して、名前を売っているか。これが揃って初めて、「この人を昇進させよう」という話になる。ネットワークも重要だ。社内の同僚、社外のプロフェッショナル、経営層——この3方向の人脈を意識的に育てることで、キャリアの選択肢が広がる。転職を考えるなら、この3つのネットワークがどれだけ育っているか、自問してみてほしい。今、辞めようとしているあなたに問いたい。現職で、あなたは何を成し遂げたか。主体的に動いた結果として、何が変わったか。もし自分がその場にいなかったとしたら、結果はどう変わっていたか。「自分がいたからこそ生まれた差分」を言語化できるか。それが語れないなら、まだ辞めるタイミングではないかもしれない。少なくとも、もう一度自分に問いかける価値はある。ここで、よく聞く反論がある。「現職で成し遂げたいけど、もう成長の機会がないんです」——本当だろうか。この「成長できない」という感覚を、もう少し掘り下げてみたい。「成長できない」は本当か「もうこの場所では成長できない」これは、転職理由としてよく聞く言葉だ。刺激がなくなった。慣れてしまった。自分よりできる人がいない。だから、成長するために環境を変えたい。でも、本当にそうだろうか。それは本当に環境のせいなのか。厳しいことを言う。「成長できない環境」なんて、ほとんど存在しない。あるのは、今の自分の能力では打破できない環境だ。それは環境の問題ではなく、能力の問題だ。能力があれば、たいていの環境は打破できる。「この環境では無理だ」と言っているのは、「今の自分には無理だ」と言っているのと同じだ。だからこそ、転職には意味がある。——逆説的に聞こえるかもしれないが、聞いてほしい。能力を上げてから転職すれば、次の環境も打破できる。能力を上げずに転職しても、また同じ壁にぶつかる。「この環境では成長できない」と言って転職した人が、次の会社でも同じことを言っているのを、何度も見てきた。環境を変えても、能力が変わらなければ、結果は同じだ。逆に、今の環境で壁を打破する力をつけた人は、どこに行っても通用する。転職は「逃げ場」ではなく「能力を活かす場」として選ぶべきだ。今の環境で能力を証明してから、その能力をより活かせる場所に移る。それが、転職を「飛躍」にする唯一の方法だ。では、ここで言う「能力を上げる」とは、具体的に何を指すのか。そもそも「成長」とは何なのか。成長とは何か。新しい技術を触ることか。新しいフレームワークを学ぶことか。それらは成長の一部ではあるが、本質ではない。成長とは、「解ける問題の範囲が広がること」であり、「より大きな責任を担えるようになること」だ。シニアエンジニアへの成長で最も重要なのは、「どの問題を解くべきかを見極める力」だ。コードで問題を解くことと、そもそも「どの問題を解くべきか」を判断することは、まったく別のスキルだ。私自身、この違いを理解するのに時間がかかった。ある時期、私は「新しい技術を触れていないと成長が止まる」と焦っていた。業務ではレガシーなコードをメンテしている。新しいことを学べていない。だから成長していない。そう思い込んでいた。でも振り返ると、あのレガシーコードのメンテナンス期間こそ、私が最も成長した時期だった。複雑に絡み合った依存関係を解きほぐす力。ドキュメントがない状況で調査する力。リスクを見積もって段階的にリファクタリングする判断力。これらは、最新技術を追いかけていたら身につかなかった。その定義で考えたとき、今の環境で成長の余地は本当にないのか。もしかしたら、自分が「成長」と呼んでいるものが、単なる「刺激」ではないだろうか。新しい技術を触る刺激。新しいチームに入る刺激。新しいプロダクトに関わる刺激。刺激と成長は違う。刺激は消費されるが、成長は蓄積される。私が「成長できない」と感じていたとき、本当は「刺激がない」だけだった。成長の機会は目の前にあった。ただ、それが「地味でつまらない仕事」に見えていたから、気づかなかった。ここで、よく言われる教えについて考えてみたい。「一番の下手くそでいよう（Be the Worst）」——プログラマーの世界でよく引用される教えだ。自分より優れた人たちの中に身を置くことで、自分も成長できる。だから、自分が一番下手くそになれる環境を探せ、と。この教えは正しい。でも、これを全員が実践したら、組織は成り立たない。全員が「学ぶ側」を求めて、誰も「教える側」に回らなかったら、どうなるか。優秀な人が集まる環境は、誰かが「教える側」を引き受けてくれているから成立している。「一番の下手くそでいよう」という教えは、その前提を無視している。——というのは、批判としては正しい。ただ、この教えの本質は、「常に学び続けろ」ということだ。「教える側」に回っても、学びは止まらない。むしろ、教えることで自分の理解の穴が見つかる。成長の形が変わるだけで、成長自体は続く。「もうこの場所では成長できない」と感じたとき、立ち止まって考えてほしい。自分は「学ぶ側」でいることしか考えていないのではないか。新しい技術を教わりたい。優秀な先輩からコードレビューを受けたい。それは大事だ。だが、いつまでも「教わる側」にいるわけにはいかない。「教える側」に回ったとき、別の成長が始まる。後輩のコードをレビューすることで、自分の理解の穴が見つかる。ドキュメントを整備することで、暗黙知が言語化される。勉強会を開くことで、チーム全体の底上げができる。そして何より、「自分がいないと回らない」から「自分がいなくても回る」状態を作ることが、次のステージへの準備になる。「接着剤の仕事」というものがある。チーム間の調整、ドキュメント整備、後輩の面倒を見る——コードを書かないが、チームを機能させるために不可欠な仕事だ。日本企業では、この仕事は評価されにくい。「○○さんはコード書いてないよね」と言われがちだ。でも、シニアレベルでこれをやると「リーダーシップを発揮している」と見なされることもある。上司とすり合わせて、この仕事がキャリアにどう評価されるか確認しておいた方がいい。評価されないなら、やりすぎは損だ。効果的なメンタリングとは何か。良いメンターはすぐに答えを与えない。複数の選択肢を提示し、メンティー自身に考えさせる。そして、自立を促す。メンタリングを受ける側も、答えを教えてもらうことを期待するのではなく、自分で考える姿勢が求められる。もし今の環境で良いメンターがいるなら、それは転職で失う大きな資産の1つだ。今の環境で、より大きな責任を担う機会はないか。より難しい問題に挑戦する機会はないか。それを探さずに「成長できない」と言っているなら、次の環境でも同じことが起きるだろう。ここまで、「成長できない」という感覚について掘り下げてきた。成長の機会は、案外、目の前にあるかもしれない。ただ、それでも「辞めたい」という気持ちが消えない人もいるだろう。次の問いは、より厳しいものになる。転職は「逃げ」になっていないか転職を繰り返す人の中に、あるパターンがある。新しい会社に入る。最初の半年は必死でキャッチアップする。コードベースを読み、ドメイン知識を吸収し、チームの信頼を獲得する。1年が経つ頃には「だいたい分かった」という感覚が出てくる。そして、ふと気づく。「あれ、最近あまり成長していない気がする」。ここで選択肢が2つある。今の環境で次のステージに挑戦するか、また新しい環境に移るか。後者を選び続けると、こうなる。キャッチアップが終わるたびに「成長が止まった」と感じ、また次の会社に行く。新しい環境でのキャッチアップを「成長」だと錯覚する。でも、それは成長ではない。ただの適応だ。本当の成長は、適応が終わった後にある。その環境で自分なりの仮説を持ち、試行錯誤し、失敗し、そこから学ぶ。大きなプロジェクトをやり遂げる。チームを任される。技術的な意思決定を下す。そういう経験を積んで初めて、次のステージに進める。転職を繰り返すたび、この「本当の成長」への到達前にリセットがかかる。結果、いつまでも「一人前の開発者」のまま、年齢だけが進んでいく。私自身、このリセットの苦しさを身をもって経験した。自社開発からSRE支援の会社に転職したとき、リセットが1回では済まないことを思い知った。支援先が変わるたびに、文脈がリセットされる。コードベース、チームメンバー、組織文化——全部ゼロから。しかも「支援」として来ている以上、キャッチアップ期間なんてない。初日から「で、何ができますか？」と問われる。最初は本当に苦しんだ。広い視野は得られたが、深さが積み上がらない。ある現場で得た知見を次の現場で活かそうとしても、文脈が違いすぎて通用しない。そして何より、信頼の蓄積がリセットされ続ける。ある支援先で信頼を獲得しても、次の案件ではまたゼロからだ。この経験から学んだことがある。転職のリセットコストは、転職先の業態によって大きく変わる。自社開発から自社開発への転職なら、リセットは1回で済む。でも、支援会社やコンサル、技術顧問に転職すると、リセットが繰り返し発生する。その覚悟があるかどうか、転職前に考えておくべきだ。この経験を通じて、私が学んだ原則がある。「自分の決定の結果を見届けられるだけの期間、同じ場所に留まれ」。成長のフィードバックループを回すためだ。設計した仕組みが半年後にどう使われているか。提案した施策が1年後にどんな結果を生んだか。それを見届けずに次の環境に移ったら、学びは半分で終わる。もう1つ、「許可を求めるな、宣言しろ」という原則がある。「○○してもいいですか？」ではなく、「○○します。問題があれば教えてください」と発信する。異論があれば誰かが止めてくれる。このスタイルで動けるようになると、権限がなくても物事を前に進められる。日本企業では「根回し」が重要だと言われる。それは間違いではない。でも、根回しにも2種類ある。「許可を得るための根回し」と「宣言を通すための根回し」だ。後者の方が、物事が前に進む。逆に、常に許可を求めないと動けない状態なら、まだその環境で信頼貯金が足りていない。その信頼を積み上げる前に辞めるのは、もったいない。ここで、このセクションの問いに戻ろう。「転職は『逃げ』になっていないか」。「今の環境では成長できない」と感じたとき、一度立ち止まって考えてほしい。それは本当に環境の限界なのか。それとも、環境には問題がないのに、難しいことから逃げているだけではないか。——私自身も、この問いに何度も向き合ってきた。そして正直に言えば、「逃げ」だったこともある。「退屈だが重要な課題」を解決することから目を背けて、「新しくて刺激的な環境」に逃げたくなる気持ちは、痛いほど分かる。ここまで、「今の環境で成長できるか」について話してきた。では、環境を変えるにせよ、留まるにせよ、これからのエンジニアは何を磨くべきなのか。AIと共存する時代に何を磨くかこの問いを考えるとき、避けて通れないのがAIの存在だ。AIは、定型的な作業を得意とする。コードの自動生成、バグの検出、ドキュメントの作成。これらの領域では、すでにAIが人間を補助し、場合によっては代替し始めている。つまり、「言われたことをそのまま実装する」だけのエンジニアは、価値が下がっていく。一方で、AIに代替されにくい領域もある。技術的な意思決定を下すこと。チームを率いること。ビジネス課題を理解し、技術で解決策を提案すること。曖昧な要件を整理し、実装可能な形に落とし込むこと。これは、当面の間、人間の仕事だ。私が優れた組織で見てきた共通点がある。エンジニアがビジネスに直接触れていることだ。「ITとビジネスの橋渡し役」を介さず、エンジニア自身がビジネス指標を理解し、顧客と対話する。その直接的な接点が、AIには代替できない価値を生む。逆に言えば、「要件を受け取って実装するだけ」のエンジニアは、AIに代替されやすい。これは他人事ではなく、私自身も常に意識していることだ。だが、ここで短絡的な結論に飛ばないでほしい。「じゃあ、転職してシニアなポジションを取りに行こう」というのは間違いだ。なぜなら、シニアになるためには、ジュニアとしての経験が必要だからだ。問題は、「ジュニアのまま留まり続けること」だ。今の環境で、次のステージに進むための挑戦ができるなら、そうすべきだ。転職は、その挑戦ができない場合の、最後の手段であるべきだ。ここで自分に問いかけてほしい。直近1ヶ月で、「人間が介入しなければ解決しなかった意思決定」を何回行ったか。AIがコードを書ける今、「実装する」だけでは価値が出にくい。曖昧な要件を整理する。ステークホルダー間の調整をする。技術的な選択肢の中から、ビジネスインパクトを考慮して決断する。そういう「人間にしかできない仕事」をどれだけやっているか。それがシニアへの階段を登る経験だ。ここまで、「どの方向に進むか」「何を磨くか」「今の環境で成長できるか」について話してきた。キャリアを考えるとき、避けて通れない話がもう1つある。転職を考える動機として、最も頻繁に挙がるテーマだ。「年収を上げたい」は目的ではなく結果である転職理由として「年収を上げたい」はよく聞く。分かる。私だって年収は高い方がいい。だが、年収は目的ではなく、結果だ。「年収は結果」と言うのは簡単だ。でも、転職サイトを開くと、年収で検索してしまう。なぜか。年収は分かりやすい指標だからだ。「能力が上がった」は測りにくい。「年収が上がった」は明確だ。この分かりやすさの罠が、私たちを「能力より年収」に引き寄せる。対策は1つ。年収以外の「分かりやすい指標」を自分で設定することだ。「○○の技術を導入した」「△△人のチームをリードした」「□□の問題を解決した」——そういう指標を先に決めておけば、年収の誘惑に負けにくい。転職サイトを開く前に、「この転職で得たいもの」を3つ書き出してみてほしい。そのうち「年収」が1番目に来るなら、一度立ち止まる必要がある。年収は、あなたが提供できる価値の対価だ。技術力が高ければ、難しい問題を解ける。推進力があれば、プロジェクトを成功に導ける。影響力があれば、チームや組織を良い方向に動かせる。これらの価値を提供できるから、高い年収が払われる。年収600万円から800万円、800万円から1000万円。それぞれのステージを超えるには、提供できる価値のレベルを上げる必要がある。「一人で開発できる」から「チームをリードできる」へ。「技術的な問題を解ける」から「ビジネス課題を技術で解決できる」へ。企業によって「シニアエンジニア」の意味は違う。大手IT企業とスタートアップでは、同じ肩書きでも求められる水準が全く異なる。1000人規模の会社のシニアと、10人のスタートアップのシニアでは、経験してきた課題の複雑さも、責任の範囲も違う。同じ「シニア」でも、会社によって期待値が違う。ここで正直に振り返りたい。キャリアの進め方について、私は無自覚だった。一生懸命働けば、報酬は自然についてくるものだと思っていた。「会社が見ていてくれる」「評価されるべき人は評価される」——そう信じていた。でも、それは間違いだった。努力だけでは、次のレベルに到達できない。技術を磨くことと、キャリアを戦略的に構築することは、別のスキルなのだ。日本企業では「出る杭は打たれる」と言われるが、「出なさすぎる杭」は存在すら認識されない。逆に言えば、能力を上げずに年収だけ上げようとしても、無理がある。高年収の会社に転職できたとしても、その期待値に応えられなければ、いずれ居場所を失う。私自身、この罠に片足を突っ込んだことがある。ある時期、市場が過熱していた。エンジニアの採用難で、年収相場が跳ね上がっていた。転職サイトを見ると、今の年収より明らかに高いオファーがゴロゴロしている。「自分の市場価値はこんなに高いのか」と浮かれていた。でも、冷静に考えれば分かる話だった。それは「私の価値」ではなく、「市場のバブル」だった。実際に転職した人の話を聞くと、入社後に苦しんでいるケースが少なくなかった。「この年収なら、これくらいできるだろう」という期待に応えられない。前職では周囲のサポートがあったから成果が出せていたのに、新しい環境では1人で同じ成果を求められる。結果、評価が下がり、居心地が悪くなる。中には、年収ダウンで再び転職した人もいた。年収アップの転職で失敗する人には、共通点があった。「年収が上がる＝自分の価値が認められた」と解釈していたことだ。でも、採用側の論理は違う。「この年収を払えば、このくらいの成果が出るはずだ」という投資判断をしている。年収は「認定」ではなく「期待値」なのだ。その期待値に応えられなければ、厳しい現実が待っている。ここで、提示された年収アップのオファーについて冷静に考えてほしい。その年収は、あなたの「現在の実力」に対する評価なのか。それとも、市場のバブルや採用の緊急度による「プレミアム（下駄）」なのか。下駄を履いた状態で入社すると、期待値の調整で苦しむ。「このくらいできるだろう」という期待に応えられず、評価が下がり、居心地が悪くなる。そのリスクをどう管理するか。年収だけを見て決めると、この罠にはまりやすい。だから、「年収を上げるために転職する」のではなく、「能力を上げた結果として年収が上がる」という順序を間違えてはいけない。そして、能力を上げるためには、今の環境で何ができるかをまず考えるべきだ。ここで、転職を考えるときに気をつけてほしいことがある。「年収アップ」という言葉に惹かれて、転職エージェントの話を聞き始める人は多い。だが、エージェントの言葉を聞く前に、知っておくべきことがある。転職エージェントのビジネスモデルを理解する転職エージェントは、あなたの味方ではない。これは悪口ではなく、ビジネスモデルの話だ。転職エージェントにお金を払っているのは、あなたではない。採用企業だ。エージェントは、あなたを企業に紹介し、採用が決まったときに、企業から報酬を受け取る。その報酬は、あなたの年収の一定割合だ。つまり、エージェントにとって、あなたが「転職すること」が利益になる。あなたが「現職に残ること」は、彼らには何のメリットもない。むしろ、売上ゼロだ。だから、エージェントは転職を勧める。「今の会社に残った方がいい」とは、なかなか言ってくれない。彼らの言葉をそのまま鵜呑みにするのは危険だ。エージェントを使うなとは言わない。彼らは市場の情報を持っているし、面接対策のアドバイスもくれる。ただ、彼らのインセンティブ構造を理解した上で、話を聞くべきだ。本当に転職すべきかどうかは、エージェントではなく、あなた自身が決めることだ。できれば、利害関係のない第三者——信頼できる先輩、友人、メンター——に相談してほしい。ここで厳しいことを言う。自分のキャリアの最終責任者になれ。日本企業では、「会社がキャリアパスを用意してくれる」という期待がある。年功序列で昇進できる。上司が適切なアサインメントを考えてくれる。人事部がキャリア相談に乗ってくれる。——しかし、それは幻想だ。あなたのキャリアの最終責任者は、上司やエージェントや人事部ではなく、あなた自身だ。誰かが導いてくれるのを待つのではなく、自分で方向を決めて、自分で動く。その覚悟があるかどうかが、キャリアを作れるかどうかの分かれ目になる。自分でキャリアを管理するために、私が大事にしている習慣が2つある。1つは、時間管理より体力管理だ。同じ1時間でも、元気なときと疲れているときでは、アウトプットが全く違う。燃え尽きそうな状態で長時間働いても、成果は出ない。自分の体力がどこで回復し、どこで消耗するかを把握することが、長く働き続けるための鍵だ。もう1つは、フィードバックを受け入れる力だ。「それは違うと思います」と言われたとき、どう反応するか。防御的にならず、「なるほど、そういう見方もあるのか」と学びに変えられる人が、成長し続けられる。「自分は正しい」と固まった人は、どんなに優秀でも、そこで成長が止まる。ここまで、「辞めるな」「考えろ」と書き続けてきた。読んでいて息苦しくなった人もいるかもしれない。だから、バランスを取っておきたい。転職が正解だったケースも、確かにあるからだ。転職して正解だった人たちここまで「辞めるな」と書いてきたが、一方的になりすぎただろう。転職して正解だった人も、たくさんいる。私の知り合いにも、転職がキャリアの転機になった人がいる。大企業からスタートアップに移って、2年で技術力が飛躍的に伸びた人。逆に、スタートアップから大企業に移って、大規模開発の経験を積んだ人。マネジメント志向だったのに、転職先でスペシャリストとして開花した人もいる。1人の話をしよう。彼は大企業で5年間、安定したキャリアを積んでいた。評価も悪くなかった。でも、「このまま10年後も同じことをしているのか」という問いが、ずっと頭の片隅にあったという。彼が転職を決めたのは、「逃げたい」からではなかった。「自分の手でプロダクトを作りたい」という明確な欲求があった。大企業では、どうしても歯車の一部になる。意思決定に関われるのは、ずっと先の話だ。彼は、その「ずっと先」を待てなかった。転職先は、20人規模のスタートアップだった。最初の3ヶ月は地獄だったと言っていた。前職では当たり前だったインフラが何もない。ドキュメントもない。聞ける人もいない。「俺、何やってるんだろう」と思った夜もあったらしい。でも、半年後に変化が起きた。自分が設計したアーキテクチャが、本番環境で動き始めた。ユーザーからのフィードバックが、直接Slackに届くようになった。「自分の仕事が、誰かの役に立っている」——その実感が、すべてを変えたと言っていた。彼が転職で成功したのは、運が良かったからではない。辞める前に、「次に何を得たいか」が明確だったからだ。「今の環境が嫌だから」ではなく、「次の環境でこのスキルを得たい」「この経験を積みたい」という具体的な理由で動いていた。これは、私が見てきた「転職で成功した人たち」に共通する特徴だ。ここで視点を切り替えてみたい。「今の仕事への期待値は下げ、キャリアにはもっと期待しよう」。今の仕事で完璧を求めすぎない。すべての仕事が理想的であるはずがない。でも、キャリア全体では高い目標を持つ。3年後、5年後にどうなっていたいか。この視点の切り替えが、良い転職をした人たちの特徴だった。そして、もう1つ。彼らは辞める前に、現職でやれることをやり切っていた。「ここでやれることはやった」という実感があった。だからこそ、次の環境で活かせる実績と経験を持って移れた。転職が正解になるかどうかは、転職先の問題ではない。辞める前に何を積み上げたかの問題だ。だから、この記事で伝えたいのは「絶対に辞めるな」ではない。「辞める準備はできているか」を問え、ということだ。ただし、ここで1つ付け加えておきたい。準備とは関係なく、すぐに辞めるべきときがある。そのタイミングを見誤ると、取り返しのつかないことになる。それでも辞めるべきタイミングここまで「辞めるな」と書いてきた。でも、辞めるべきタイミングは確かにある。そして、それは「自分の問題」ではなく、「環境の問題」であることも多い。メンタルや身体が壊れそうなときは、今すぐ辞めろ。これだけは絶対だ。キャリアよりも健康が大事だ。あなた個人に対するリスペクトを感じない会社や現場からは、即刻立ち去るべきだ。そこで無理をする必要はない。一方的に消耗させられる必要もない。我慢して壊れてからでは遅い。組織の構造的問題があるときも、辞めていい。これは重要なポイントだ。個人の努力では変えられない問題が、組織には存在する。いくつか例を挙げる。評価制度が機能していない——成果を出しても正当に評価されない。声が大きい人だけが昇進する。透明性がない。技術的負債が放置されている——経営層が技術投資を理解せず、ひたすら機能追加だけを求める。改善の余地がない。権限と責任が一致しない——責任だけ押し付けられて、決定権がない。何を提案しても却下される。人間関係の構造が壊れている——特定の人物によるハラスメント。派閥争い。コミュニケーションの断絶。会社の方向性に共感できない——ビジョンが見えない。または、見えたビジョンが自分の価値観と合わない。これは、あなたの責任ではない。どんなに努力しても、個人で変えられない問題はある。「もっと頑張れば変えられるはず」と思って消耗し続ける必要はない。構造的問題を個人の努力で乗り越えようとするのは、無理ゲーだ。今の環境で目指す役割に挑戦する機会がどうしても得られないときも、辞め時だ。組織の構造上、テックリードのポジションがない。マネジメントのポジションがない。専門性を深める機会がない。そういう時は、環境を変える必要がある。私が辞め時だと思う明確なサインがある。「学びたい意欲はあるのに、実際には学べていない」状態だ。技術を深めたい、新しいことに挑戦したい——その気持ちはある。でも、日々の仕事は同じことの繰り返し。成長の機会がない。もう1つのサインは、「スキルではなく、対処法を学んでいる」状態だ。技術力が上がっているのではなく、「この上司にはこう報告すればいい」「この会議はこうやり過ごせばいい」という政治的なサバイバルスキルばかりが磨かれている。これは危険信号だ。その環境で得られるものは、もう得尽くした可能性が高い。しかし、一点だけ確認してほしい。本当に機会がないのか、自分が機会を見逃していないか。機会は待っていても来ない。自分で作り出すものだ。作り出そうとしたけど本当に無理だった——そう言えるなら、転職は正しい選択だ。一方で、こういう時は立ち止まってほしい。「なんとなく飽きた」「刺激がない」「成長できない気がする」——こういう漠然とした不満だけで辞めようとしているなら、一度考えてみてほしい。それは本当に環境の問題なのか。自分の姿勢の問題ではないのか。辞める理由が「環境の構造的問題」なら、辞めていい。辞める理由が「自分の漠然とした不満」なら、もう少し掘り下げてみてほしい。その違いを見極めることが大事だ。ここで1つ、厳しい問いを投げかけたい。「この会社では無理だ」という結論に至るまでに、組織のボトルネックに対して具体的な改善提案や行動を何回試みたか。「評価制度がおかしい」と感じたなら、上司やHRに具体的な改善案を提案したか。「技術的負債が放置されている」と感じたなら、解消のためのロードマップを作って経営層に説明したか。試行回数がゼロなら、それは「構造の問題」ではなく「食わず嫌い」かもしれない。失敗してもいいから、一度は試みてほしい。試みた上で無理だったなら、辞める判断は正しい。ここまで、様々な角度から転職について考えてきた。辞めるべきとき、辞めるべきでないとき、その判断基準を見てきた。最後に、これまでの内容を整理して、問いかけの形にまとめておきたい。転職を決断する前に転職を考えているあなたに、最後に問いかけたい。まず、方向性は明確か。テックリードを目指すのか、EMを目指すのか、スペシャリストとして深掘りするのか。次に進みたい方向が言語化できていなければ、転職は単なる「移動」に終わる。技術力、推進力、影響力のうち、今の自分に足りないものは何か。それを伸ばす機会が、本当に今の環境にはないのか。転職すれば自動的に成長できるわけではない。次に、積み上げたものを使い切ったか。転職には必ずリセットコストがかかる。信頼の貯金はゼロに戻る。ドメイン知識も、人間関係も、リセットされる。その代償を払ってでも得たいものは何か。今の会社で、信頼の貯金を活用してできる挑戦はもうないのか。信頼があるからこそ任される大きな仕事を、やり残していないか。現職で主体的に動いて成し遂げた実績を語れるか。「自分がいたからこそ生まれた差分」を説明できるか。そして、冷静に判断できているか。「成長できない」のは本当に環境のせいか。それとも、難しい課題から逃げているだけではないか。転職理由が「年収を上げたい」だけになっていないか。年収は結果であって、目的ではない。転職エージェントのアドバイスを鵜呑みにしていないか。彼らは転職させることでお金をもらっている。利害関係のない第三者——信頼できる先輩、友人、メンター——に相談したか。「一人前の開発者」から次のステージに進めているか。それとも、キャッチアップを繰り返しているだけではないか。すべてに明確な答えを持っている必要はない。だが、1つも考えたことがないなら、まだ転職を決断する段階ではない。おわりにこの記事で言いたかったことは、結局、1つだけだ。短期的にモノを考えるな。目の前の不満。今月の年収。来週の上司との関係。そういうものに振り回されて、衝動的に決断するな。3年後、5年後、10年後の自分がどうなっていたいか。そこから逆算して考えろ。若いエンジニアが短期的に考えてしまうのは、仕方がない。私もそうだった。目の前の不満が世界のすべてに見える。「今すぐ環境を変えたい」という衝動を抑えられない。それは、若さゆえの特権でもある。でも、その特権には代償がある。転職を繰り返すたびに、信頼の貯金はリセットされる。キャリアの複利は止まる。「いろんな経験を積んだ」と言えば聞こえはいいが、どこにも根を張れないまま、年齢だけが積み上がっていく。私は、そういう未来を避けたかった。転職は、逃げにもなるし、飛躍にもなる。同じ「辞める」という行動でも、その意味は正反対になりうる。違いを決めるのは、辞める前に何を考えたか。それだけだ。1つだけ、問いを残しておく。もし今の会社の嫌な部分——人間関係や評価制度——がすべて解消されたとしたら、それでもなお、その新しい会社に行きたいと心から思えるか。YESなら、それは「攻め」の転職だ。NOなら、それは高度に正当化された「逃げ」かもしれない。逃げが悪いとは言わない。ただ、逃げを「攻め」の物語ですり替えていないか、正直な気持ちで自分に問いかけてほしい。深夜2時、ベッドの中で転職サイトを開いたとき。その衝動を否定はしない。ただ、その衝動のまま動くな。翌朝、もう一度考えろ。1週間後、もう一度考えろ。それでもなお、辞めたいと思うなら、そのときは辞めればいい。正直に言えば、「正解」なんてない。辞めても、残っても、どちらが正しかったかは、誰にも分からない。分かるのは、ずっと後になってからだ。そして、その「正しさ」は、最初から存在していたわけではない。選んだ道を、正解にしていく過程があるだけだ。おい、考えろ。短期ではなく、長期で考えろ。そして、選んだら、それを正解にしろ。続編を書きました。syu-m-5151.hatenablog.com参考書籍ＩＴエンジニアの転職学　２万人の選択から見えた、後悔しないキャリア戦略 (ＫＳ科学一般書)作者:赤川朗講談社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社AmazonNINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon世界標準のフィードバック　部下の「本気」を引き出す外資流マネジメントの教科書作者:安田 雅彦SBクリエイティブAmazonみんなのフィードバック大全作者:三村 真宗光文社Amazonネガティブフィードバック　「言いにくいこと」を相手にきちんと伝える技術作者:難波 猛アスコムAmazonロバート・キーガンの成人発達理論――なぜ私たちは現代社会で「生きづらさ」を抱えているのか作者:ロバート・キーガン,中土井僚,鈴木規夫英治出版Amazon「人の器」の磨き方　リーダーシップ・コーチングと成人発達理論による人間力の変容プロセス作者:加藤洋平,中竹竜二日本能率協会マネジメントセンターAmazon「人の器」を測るとはどういうことか　成人発達理論における実践的測定手法作者:オットー・ラスキー,中土井僚日本能率協会マネジメントセンターAmazon組織も人も変わることができる！　なぜ部下とうまくいかないのか　「自他変革」の発達心理学作者:加藤洋平日本能率協会マネジメントセンターAmazon人が成長するとは、どういうことか作者:鈴木規夫日本能率協会マネジメントセンターAmazonあなたはなぜ雑談が苦手なのか（新潮新書）作者:桜林直子新潮社Amazon世界の一流は「雑談」で何を話しているのか作者:ピョートル・フェリクス・グジバチクロスメディア・パブリッシング（インプレス）Amazon「何を話していいかわからない」がなくなる　雑談のコツ作者:ひきた よしあきアスコムAmazon雑談の一流、二流、三流作者:桐生 稔明日香出版社Amazon雑用は上司の隣でやりなさい――あなたの評価を最大限に高める「コスパ最強」仕事術作者:たこすダイヤモンド社Amazon資本主義が人類最高の発明である：グローバル化と自由市場が私たちを救う理由作者:ヨハン・ノルベリニューズピックスAmazon資本主義は私たちをなぜ幸せにしないのか (ちくま新書)作者:ナンシー・フレイザー,江口泰子筑摩書房Amazon資本主義はなぜ限界なのか　――脱成長の経済学 (ちくま新書)作者:江原慶筑摩書房Amazon資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Hacker NewsのShow HN に自作ツールを投稿する方法 ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/04/141622</guid>
            <pubDate>Sun, 04 Jan 2026 05:16:22 GMT</pubDate>
            <content:encoded><![CDATA[はじめにHacker News の「Show HN」は、自分が作ったものを開発者コミュニティに紹介できる場だ。しかし、ただ URL を貼れば良いわけではない。明確なルールがあり、それを守らないと投稿が埋もれたり、他のユーザーから通報されて非表示になることもある。この記事では、Show HN のルールを読み解き、効果的な投稿を作成するまでのプロセスを解説する。Show HN とは何かShow HN は Hacker News 内の特別なカテゴリで、自分が作ったものを他の人が試せる形で共有する場所だ。通常の HN 投稿がニュースや記事のシェアであるのに対し、Show HN は「触れるもの」を紹介する。投稿が一定のポイントを獲得すると、トップバーの "show" ページに表示され、より多くの人の目に触れる。ルールを正確に理解するShow HN には明確なルールがある。公式ガイドラインから重要なポイントを抜粋する。news.ycombinator.com投稿できるものユーザーが実際に試せるもの（run on their computers or hold in their hands）ハードウェアの場合は動画や詳細な記事でも可書籍の場合はサンプルチャプターでも可投稿できないものブログ記事サインアップページニュースレターリスト記事その他「読むだけ」のコンテンツこれらは「試せない」ため Show HN の対象外だ。通常の投稿として submit すべき。その他の重要なルール自分が関わったプロジェクトであること議論に参加できる状態であることサインアップやメール登録なしで試せるのが理想準備ができていないなら投稿しない（ready になってから来い）ランディングページや資金調達ページは NG友人に upvote や comment を頼むのは禁止（組織的な票操作とみなされる）マイナーアップデート（Foo 1.3.1 is out）は NG、メジャーオーバーホールなら可投稿フォームの構成Show HN の投稿は3つの要素で構成される。1. Title（タイトル）Show HN: で始める必要がある80文字制限がある（超過するとエラー）プロジェクト名と一言説明を入れる2. URLプロジェクトのリポジトリ、デモサイト、またはドキュメントページユーザーがすぐに試せる URL が理想3. Text（オプション）URL を補足する説明文何を作ったか、なぜ作ったか、どう使うかフィードバックを求めるポイントを明示すると反応が得やすい効果的なタイトルの作り方80文字という制限の中で、以下を伝える必要がある。プロジェクト名 — 何と呼ばれているか何をするものか — 一言で説明差別化ポイント（余裕があれば） — なぜこれが面白いかタイトルのパターンShow HN: [プロジェクト名] – [一言説明]文字数を削るテクニック：- 冠詞（a, an, the）を省略- "for" を "–" に置き換え- 形容詞を削る- 技術用語は略称を使う（もし一般的なら）良いタイトルの例Show HN: Helix – A post-modern text editor written in RustShow HN: Zed – A high-performance code editor from the creators of AtomShow HN: DuckDB – An embeddable SQL OLAP database management system避けるべきタイトルShow HN: My new project that I've been working on for 6 months  ← 情報がないShow HN: Check this out!  ← 何かわからないShow HN: Tool v1.3.2 released  ← マイナーアップデートは NGText（説明文）の書き方Text は任意だが、書いた方が反応は良くなる。以下の構成が効果的：1. 何を作ったか（1-2文）I built a [種類] that [主要機能].2. なぜ作ったか / 何が新しいか（2-3文）既存ツールとの違い、解決した課題、採用した理論やアプローチ。3. 使い方（1-3行）Quick start:  npm install -g mytool  mytool initワンライナーで試せると理想的。4. 主要機能（箇条書き、3-5個）Features:- Feature A- Feature B- Feature C5. フィードバックの呼びかけ（1文）Would love feedback on [具体的なポイント].「フィードバックください」だけでなく、何について聞きたいかを明示すると、具体的なコメントが得やすい。実際の投稿準備プロセスStep 1: ルールの確認まず公式ガイドラインを読む。ルールは時々更新されるため、投稿前に毎回確認するのが安全。news.ycombinator.comStep 2: 素材の整理プロジェクトの URLREADME や説明文主要機能のリストインストール方法Step 3: タイトルの作成80文字制限を意識しながら複数案を作成。文字数カウンターを使って確認する。Step 4: Text の作成上記の構成に沿って簡潔に。長すぎると読まれない。Step 5: 投稿タイミングHN のトラフィックは米国時間の午前中（太平洋時間 6-10 AM）がピーク。日本時間だと夜〜深夜にあたる。AI を活用した投稿準備Show HN の投稿準備は、AI アシスタントとの相性が良い。依頼の例https://news.ycombinator.com/showhn.html のルールに沿って、https://github.com/username/project を Show HN に投稿したい。タイトル、URL、テキストを作成してほしい。AI に依頼する際のポイント：ルールの URL を渡す — AI が最新のルールを参照できるプロジェクトの URL を渡す — README から情報を抽出してもらえる文字数制限を伝える — 80文字制限など、具体的な制約を共有AI が生成した案をそのまま使うのではなく、自分の言葉で調整することで、より自然な投稿になる。投稿後の対応Show HN では投稿者がコメントに返信することが期待されている。質問には丁寧に回答批判的なコメントにも建設的に対応バグ報告には感謝を伝え、対応する姿勢を見せる投稿して放置するのは印象が悪い。数時間はコメントを監視できるタイミングで投稿しよう。まとめShow HN への投稿は、単なる宣伝ではなく、開発者コミュニティとの対話の始まりだと思います。ルールを守る — 「試せるもの」を投稿するタイトルは80文字以内 — プロジェクト名 + 一言説明Text で文脈を与える — 何を、なぜ、どう使うかフィードバックポイントを明示 — 具体的な質問を投げかける投稿後は対話する — コメントに返信する]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Ory HydraでOAuth2認可サーバーを構築する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/04/133007</guid>
            <pubDate>Sun, 04 Jan 2026 04:30:07 GMT</pubDate>
            <content:encoded><![CDATA[はじめに認可サーバーを構築するタスクがアサインされた。技術選定の裁量はある。仕事の合間にRFC 6749や技術書をいくつか読み始めた。datatracker.ietf.org帰宅後の深夜、週末の空き時間。3日目の深夜2時、私は確信した。これは自前で作るべきではない。認可コードフロー、インプリシットフロー、リソースオーナーパスワードクレデンシャル、クライアントクレデンシャル。4つのグラントタイプ。それぞれにセキュリティ要件がある。PKCEも必要だ。OpenID Connectも。IDトークンのクレーム設計。JWKSエンドポイント。セッション管理。トークン失効。リフレッシュトークンのローテーション。仕様を読めば理解できる。実装もできる。でも、これをプロダクション品質で検証し続けるのは、私たちの仕事ではない。3日間RFCを読んで分かったのは、「自前で作ることの非合理性」だった。調べていく中で、OpenAIがOryを採用していることを知った。www.ory.com彼らは認可サーバーの実装に時間を使わないことを選んだ。彼らの本業はAIモデルの開発だ。認証認可は重要だが、「解くべき問題」ではなく「解決済みの問題を使う」領域として扱っている。妥当な判断だと思う。Ory Hydraを採用することにした。www.ory.shgithub.comこの記事では、Hydraのアーキテクチャを解説し、Docker Composeで実際に動かすところまでやる。OAuth2/OIDCの基本概念は知っている前提で進める。OAuth徹底入門 セキュアな認可システムを適用するための原則と実践作者:Justin Riche,Antonio Sanso翔泳社AmazonOAuth 2 in Action (English Edition)作者:Richer, Justin,Sanso, AntonioManningAmazonこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。「認証をしない認可サーバー」という話www.ory.comHydraのドキュメントを読んでいて、ある一文で手が止まった。「Hydraは認証をしません」認可サーバーなのに認証しない。最初は設計の欠落かと思った。Auth0やKeycloakは全部やってくれるのに。だが、ドキュメントを読み進めるうちに意図が見えてきた。これは欠陥ではない。これこそが設計の核心だ。考えてみてください。あなたの会社には、おそらく既にユーザーデータベースがある。10年使ってきた認証システムがある。LDAPで認証している。多要素認証は自前のものを使っている。パスキー対応も進めている。一般的なIdP——Auth0やKeycloak——を導入すると、これらを全部IdP側に合わせなければなりません。データ移行。認証フローの再設計。既存システムとの複雑な連携。Hydraは違うアプローチを取ります。「認証はあなたたちでやってください。終わったら教えてくれれば、あとはこちらでOAuth2/OIDCの面倒なことは全部やります」この瞬間、私の中で何かがカチッとはまりました。既存の認証システムはそのまま。ユーザーDBもいじらない。ただ、OAuth2/OIDCのプロトコル層だけをHydraに任せる。認証と認可の責務が完全に分離される。これが「ヘッドレス」な認可サーバーというコンセプトです。具体的には以下のメリットがあります。既存システムはそのまま使える: ユーザーDB・認証ロジックをいじらなくていい認証方法は完全に自由: パスワード、パスキー、生体認証、なんでもHydraが担保するのはプロトコル準拠: OpenID Connect Certificationを取得済みhttps://openid.net/certification/openid.netアーキテクチャの全体像www.ory.comHydraを使ったシステムは、3つのコンポーネントで構成されます。Hydra Public API（ポート4444）はOAuth2/OIDCの「顔」です。クライアントアプリケーションが/oauth2/authに認可リクエストを投げ、/oauth2/tokenでトークンを受け取る。ここはHydraが全部やってくれます。Login/Consent Provider（ポート3000）が私たちの実装領域です。Hydraからリダイレクトされてきたユーザーに対して、/loginで認証画面を、/consentで同意画面を表示します。「このユーザーは本人か？」「このスコープを許可するか？」という判断を担う。ここに既存の認証ロジックを組み込みます。Hydra Admin API（ポート4445）は裏方です。Login/Consent Providerが認証・同意の結果をHydraに通知するために使います。チャレンジの検証、承認の通知、セッション管理を担当します。外部には公開せず、内部ネットワークからのみアクセスさせます。この構成を理解したとき、肩の荷が下りた気がしました。OAuth2/OIDCの複雑な部分はHydraに任せて、自分たちは「認証」という本質的な部分だけに集中できる。これなら、やれそうだ。チャレンジベースのフローwww.ory.comHydraとProviderの連携には「チャレンジ」という仕組みが使われます。最初は「なんで直接やり取りしないんだろう」と思いました。でも、この設計にはちゃんと理由があります。クライアントがHydraの/oauth2/authにリダイレクトHydraがlogin_challengeを生成し、Login ProviderにリダイレクトLogin Providerはlogin_challengeを検証し、ユーザーを認証認証成功後、Admin APIで承認を通知し、Hydraに戻るHydraがconsent_challengeを生成し、Consent ProviderにリダイレクトConsent Providerはスコープを確認し、Admin APIで承認クライアントに認可コードが返されるチャレンジは一度きりの使い捨てトークンです。傍受されても再利用できない。リプレイ攻撃やセッションハイジャックを構造的に防ぎます。この手のセキュリティ上の細かい配慮——正直、自前実装だと見落としがちだ。PKCEのcode_verifierの長さ制限（43-128文字）。stateパラメータに暗号学的に安全な乱数を使うべきこと。RFCを読んでいたあの3日間で、攻撃ベクトルをどれだけ考慮できていたか。Hydraはこれらをすべて内包しています。OpenID Connect Certificationを取得しているということは、私が見落としていたであろう細部まで検証されているということです。Docker Compose環境の構築www.ory.com理論は十分。実際に動かしてみましょう。OAuth2/OIDCの仕様は複雑です。RFC 6749を読んでも、認可コードフローの全体像が頭に入らなかった。実際にcurlでリクエストを投げ、リダイレクトを追いかけることで、初めて仕様書の抽象的な記述が腑に落ちました。開発環境は4つのサービスで構成されます。HydraのDockerイメージは公式で提供されています。hub.docker.comservices:  postgres:    image: postgres:16-alpine    environment:      POSTGRES_USER: hydra      POSTGRES_PASSWORD: secret      POSTGRES_DB: hydra    volumes:      - postgres_data:/var/lib/postgresql/data    healthcheck:      test: ["CMD-SHELL", "pg_isready -U hydra -d hydra"]      interval: 5s      timeout: 5s      retries: 5  hydra-migrate:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable    command: migrate sql -e --yes    depends_on:      postgres:        condition: service_healthy  hydra:    image: oryd/hydra:v2.2    environment:      DSN: postgres://hydra:secret@postgres:5432/hydra?sslmode=disable      SECRETS_SYSTEM: super-secret-system-secret-at-least-32-chars      URLS_SELF_ISSUER: http://localhost:4444      URLS_CONSENT: http://localhost:3000/consent      URLS_LOGIN: http://localhost:3000/login      URLS_LOGOUT: http://localhost:3000/logout      LOG_LEVEL: debug    command: serve all --dev    ports:      - "4444:4444"      - "4445:4445"    depends_on:      hydra-migrate:        condition: service_completed_successfully    healthcheck:      test: ["CMD", "wget", "-q", "--spider", "http://localhost:4444/health/ready"]      interval: 10s      timeout: 5s      retries: 5  auth-provider:    build: .    environment:      HOST: 0.0.0.0      PORT: 3000      HYDRA_ADMIN_URL: http://hydra:4445      RUST_LOG: ory_hydra_rust=debug,tower_http=debug    ports:      - "3000:3000"    depends_on:      hydra:        condition: service_healthyvolumes:  postgres_data:注意: 上記の設定は開発環境用です。本番環境ではSECRETS_SYSTEMに32文字以上の暗号学的に安全な値を設定し、sslmode=disableはrequireに変更してください。docs.docker.comauth-providerサービスのbuild: .は、Login/Consent ProviderのDockerfileを参照しています。このDockerfileとRust実装は次回の記事で解説します。今回はHydraのアーキテクチャ理解に集中しましょう。サンプルコードは以下のリポジトリで公開しています。https://github.com/nwiizo/workspace_2026/tree/main/samples/ory-hydra-rustgithub.comdepends_onとhealthcheckの組み合わせがポイントです。PostgreSQL → マイグレーション → Hydra → auth-providerという起動順序が保証されます。私は最初これを書かずに「DBがない」エラーで30分悩みました。環境の起動と動作確認docker compose up -d --builddocker compose logs -f auth-providerヘルスチェック用エンドポイントにアクセスしてみます。curl http://localhost:3000/health# {"status":"healthy"}{"status":"healthy"}が返ってきた。たった数十行のdocker-compose.ymlで、OAuth2認可サーバーの基盤が動いている。RFCを読んでいたあの3日間で見えた複雑さが、Hydraの中に隠蔽されている。OAuth2クライアントの登録OAuth2フローをテストするには、まずクライアントを登録します。www.ory.shdocker compose exec hydra hydra create oauth2-client \  --endpoint http://localhost:4445 \  --grant-type authorization_code \  --response-type code \  --scope openid,offline_access,profile,email \  --redirect-uri http://localhost:8080/callback \  --name "Test Client"クライアントIDとシークレットが出力されるので控えておきます。OAuth2フローのテストテストユーザーを作成します。curl -X POST http://localhost:3000/api/auth/register \  -H "Content-Type: application/json" \  -d '{"email": "test@example.com", "password": "password123"}'ブラウザで認可エンドポイントにアクセスします（<CLIENT_ID>は先ほど取得したもの）。http://localhost:4444/oauth2/auth?client_id=<CLIENT_ID>&response_type=code&scope=openid+profile+email&redirect_uri=http://localhost:8080/callback&state=random_stateフローは以下のように進みます。Hydraがログイン画面にリダイレクトメールアドレスとパスワードを入力してログインHydraが同意画面にリダイレクトスコープを確認して同意http://localhost:8080/callback?code=...にリダイレクトリダイレクト先（8080）は存在しなくても構いません。URLから認可コードを取得できれば成功です。おわりにこの記事を書き終えて、時計を見た。深夜1時だ。正直に言うと、書いている途中で何度かRFCのタブを開いてしまった。「この説明で合ってるかな」と不安になって。私はこの記事を書いたからといって、OAuth2/OIDCを完全に理解したわけではない。たぶん来週も、仕様書の細部で「あれ？」となる瞬間がある。でも、少しだけ違うことがある。3日目の深夜2時、RFCのタブを20個開いて、私は判断した。これは自前で作るべきではない、と。仕様は理解できる。実装もできる。でも、プロダクション品質で検証し続けることは、私たちの仕事ではない。Hydraのアーキテクチャを理解して、Docker Composeで動かしてみて、その判断が正しかったと確信した。認証と認可は分離できる。複雑なプロトコル層は、検証済みの実装に任せていい。私が書くべきコードは、真ん中の「Login/Consent Provider」だけだ。「認可サーバーを自前で作ってくれ」もしあなたが今、この言葉を受けてRFCを読んでいるなら。3日読めば分かる。作れるかどうかではない。作るべきかどうかだ。RFCを読むことには意味がある。私もあの3日間があったから、Hydraの設計思想が腑に落ちた。でも、プロダクション品質の認可サーバーを一人で検証し続ける必要はない。検証済みの実装がある。明日の朝、目覚ましが鳴る。また仕事が始まる。おい、RFCのタブを閉じろ。Hydraのドキュメントを開け。何度でも思い出せることの方が大事だ。次の記事では、RustでLogin/Consent Providerを実装する。一緒に認証画面を作ろう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[私の為のNvChadのキーマッピングガイド 2026年版]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/03/002621</guid>
            <pubDate>Fri, 02 Jan 2026 15:26:21 GMT</pubDate>
            <content:encoded><![CDATA[はじめに一月三日である。私は今、ソファの深淵に身を沈め、己の怠惰と対峙しているところである。年末にやろうと固く心に誓った開発環境の整理は、見事なまでに手つかずのまま新年を迎えてしまった。大掃除もしていない。年賀状も書いていない。結婚もしていないし、友人と過ごす予定もなかった。やらなかったことを指折り数えていると、正月休みの大半が、まるで人生の棚卸しのような様相を呈し、胸中は罪悪感で満たされていくのである。「年末年始は何をしていたのか」と問われれば、私は途方に暮れるほかない。身体は動かしていない。コードは書いた。本を読み、近所を散歩した。であるから、休んだと言えば休んだのであろう。しかしながら、休んだという実感が皆無なのである。なぜか。「あのキーバインド、なんだったか」という問いが、四六時中、頭蓋骨の内側をぐるぐると巡り続けていたからに相違ない。私はNvChadを使っている。かれこれ四年ほど使い続けている。それにもかかわらず、半年ぶりに設定を見直すたびに「これ、なんのキーだったか」と首を傾げてしまうのである。設定ファイルには丁寧にコメントを書いてある。過去の自分が、未来の自分のために残してくれた親切なメモである。しかし、読んでも思い出せない。覚えた数だけ忘れている。どうやら人間の脳というものは容量が有限であり、Vimのキーバインドよりも優先して記憶すべき事柄があるらしいのだ。たとえば、それが何であるかは私にもわからないのだが。毎年、年始になると私は同じことを繰り返している。設定を見直す。新しいプラグインを試す。キーマッピングを整理する。そしてまた忘れる。「今年こそ覚える」という新年の誓いは、結局のところ、翌年の自分に対する壮大な裏切り行為でしかないのである。このガイドは、そんな救いようのない私のための備忘録である。来年の今頃、またしても全てを忘れ去った自分のために書いている。もしかすると、同じように忘れっぽい誰かの役に立つかもしれない。立たないかもしれない。たぶん、立たない。ちなみに、一昨年にも同じようなことを書いている。進歩がない。ただし、構成はだいぶ変わった。ステータスラインを廃止し、ファイルエクスプローラーをoil.nvimに変え、Snacks.nvimを導入した。変わっていないのは、私が相変わらずキーマッピングを忘れ続けているという事実だけである。syu-m-5151.hatenablog.com開発環境全体についてはこちらに記した。興味のある方は参照されたい。syu-m-5151.hatenablog.comさて、前置きが長くなった。よく忘れるキーマッピングをまとめていくこととする。設定ファイルは以下に置いてある。github.com基本的なショートカット表記<C> = Ctrlキー<leader> = スペースキー（デフォルト）<A> = Altキー<S> = Shiftキーよく使う機能とそのキーマッピング基本操作で必須のコマンド<C-s>       - 保存（これだけは絶対覚える。:w なんてやっているとVSCodeを使っている人にバカにされる）;           - コマンドモードに入る（:を押す必要がない）jk または jj - インサートモードを抜ける（Escより断然速い）<Esc>       - 検索ハイライトをクリア<leader>y   - システムクリップボードにヤンク<leader>Y   - 行全体をシステムクリップボードにヤンク<leader>d   - ヤンクせずに削除（レジスタを汚さない）ナビゲーション（移動系）スクロールと検索が画面中央に来るようにカスタマイズしている。迷子にならない。<C-d>  - 半ページ下スクロール（画面中央維持）<C-u>  - 半ページ上スクロール（画面中央維持）n      - 次の検索結果（画面中央維持）N      - 前の検索結果（画面中央維持）検索系（2つのピッカーを使い分け）Snacks Picker（s系）- メインで使うSnacks.nvimは2024年末に登場した新しいユーティリティセット。高速で美しい。<leader><leader> - スマートピッカー（最重要：状況に応じた最適な検索）<leader>sf - ファイル検索<leader>sg - プロジェクト内テキスト検索（grep）<leader>sw - カーソル下の単語を検索<leader>sb - 開いているバッファを検索<leader>sr - 最近開いたファイルを検索<leader>sc - コマンド検索<leader>sh - ヘルプ検索<leader>sk - キーマップ検索（何かわからなくなったらこれ）<leader>sd - 診断情報を検索<leader>ss - LSPシンボル検索<leader>sR - 直前のピッカーを再開github.comTelescope（f系）- 補助的に使う長年使い慣れたTelescope。fzf-nativeで高速化済み。<C-p>       - ファイル検索（VSCodeユーザーも安心）<leader>ff  - ファイル検索<leader>fg  - ライブgrep<leader>fb  - バッファ検索<leader>fh  - ヘルプタグ検索<leader>fr  - 最近のファイル<leader>fc  - Gitコミット検索<leader>fs  - Gitステータス<leader>fd  - 診断情報github.comファイルエクスプローラー（oil.nvim）NvimTreeからoil.nvimに乗り換えた。バッファのようにディレクトリを編集できる革命的なプラグイン。ファイル名を間違えて作成しても、ddで消せる。Vimの操作で世界を編集している気分になれる。気分だけ。-           - 親ディレクトリを開く（最重要：ファイル階層を上る）<leader>e   - ファイルエクスプローラーを開く<CR>        - ファイル/ディレクトリを選択<C-v>       - 垂直分割で開く<C-s>       - 水平分割で開くg.          - 隠しファイルの表示切り替えgithub.com高速移動（flash.nvim）EasyMotion系のモダンな代替。画面内のどこにでも2-3キーで飛べる。s  - Flash（画面内の任意の位置にジャンプ）S  - Flash Treesitter（構文単位でジャンプ）r  - Remote Flash（オペレーターモード用）github.comLSP関連（コードジャンプ・リファレンス）コードリーディングする時に本当に助かる機能たち。gd          - 定義へジャンプ（最も使う）gD          - 宣言へジャンプgi          - 実装へジャンプ（インターフェースから実装を探せる）gr          - 参照を探す（変数やメソッドの使用箇所を探せる）K           - ホバー情報を表示（ドキュメント、型情報）Ctrl-^    直前に編集していたファイルに切り替え<leader>rn  - シンボルをリネーム<leader>ca  - コードアクション（自動修正候補など）<leader>fm  - フォーマット（conformで整形）<leader>cf  - フォーマット（代替キー）<leader>lk  - シグネチャヘルプ<leader>lD  - 型定義へジャンプgithub.comコードピーク（overlook.nvim）定義にジャンプせずに、フローティングウィンドウで確認できる。<leader>pd  - 定義をピーク（フローティングで定義を確認）<leader>pc  - すべてのポップアップを閉じる<leader>pu  - 最後のポップアップを復元<leader>pU  - すべてのポップアップを復元<leader>pf  - フォーカスを切り替え<leader>ps  - 分割で開く<leader>pv  - 垂直分割で開く<leader>po  - 元の場所で開くgithub.com診断・エラー確認（Trouble）診断情報を一覧で見やすく表示してくれる。[d          - 前の診断へ]d          - 次の診断へ<leader>ld  - 行の診断情報をフロートで表示<leader>lq  - 診断をloclistに送る<leader>xx  - 診断パネルをトグル（Trouble）<leader>xX  - 現在のバッファの診断のみ<leader>xs  - シンボル一覧（Trouble）<leader>xl  - LSP定義一覧<leader>xq  - Quickfixリスト<leader>xt  - TODO/FIXME一覧github.com画面分割とウィンドウ移動複数のファイルを同時に見たい時に使う。<C-h>       - 左のウィンドウへ<C-l>       - 右のウィンドウへ<C-j>       - 下のウィンドウへ<C-k>       - 上のウィンドウへ<leader>|   - 垂直分割<leader>-   - 水平分割<leader>w=  - ウィンドウサイズを均等に<leader>wm  - ウィンドウを最大化（他を閉じる）バッファ操作<S-h>       - 前のバッファへ（Shift + h）<S-l>       - 次のバッファへ（Shift + l）<leader>x   - バッファを閉じる<leader>bd  - バッファを削除（Snacks）<leader>bo  - 他のバッファをすべて削除ビジュアルモードの改善J           - 選択した行を下に移動K           - 選択した行を上に移動<leader>p   - ペースト（レジスタを上書きしない）Git操作LazyGitとの統合が最高に便利。ターミナルでgitコマンドを打つ必要がほぼなくなった。git add -pのインタラクティブモードを思い出せなくても、もう困らない。<leader>gg  - LazyGitを開く（これだけで全部できる）<leader>gl  - LazyGit ログを表示<leader>gf  - 現在のファイルのログを表示<leader>gd  - Git Diff（作業ツリー全体）<leader>gD  - 前のコミットとのDiff<leader>gh  - ファイルの履歴<leader>gH  - ブランチの履歴<leader>gs  - ステージされた変更のDiff<leader>gm  - mainブランチとのDiff<leader>gM  - masterブランチとのDiff<leader>gq  - Diffviewを閉じる<leader>gt  - ファイルパネルをトグル<leader>gp  - Hunkをプレビュー<leader>gb  - 行のBlameを表示<leader>gB  - 行Blameのトグル]c          - 次のHunkへ[c          - 前のHunkへ<leader>hr  - Hunkをリセット<leader>hs  - Hunkをステージ<leader>hu  - Hunkのステージを取り消しgithub.comgithub.comgithub.comターミナル操作<leader>tt  - ターミナルをトグル（Snacks）<C-x>       - ターミナルモードを抜けるAI統合（2026年の目玉）GitHub CopilotとClaudeの両方を使える贅沢な環境。CopilotChat（a系）<leader>ao  - チャットを開く<leader>aq  - チャットを閉じる<leader>ar  - チャットをリセット<leader>ae  - コードを説明（ビジュアルモード対応）<leader>af  - コードを修正<leader>at  - テストを生成<leader>ad  - ドキュメントを生成<leader>aR  - コードをレビューgithub.comAvante（Cursor風のAI体験）<leader>aa  - AIに質問<leader>ax  - コードを編集<leader>aS  - 回答をリフレッシュgithub.comClaudeCode（ターミナル統合）<leader>cc  - Claudeをトグル<leader>cf  - Claudeにフォーカス<leader>cr  - 会話を再開<leader>cC  - 会話を継続<leader>cm  - モデルを選択<leader>cb  - 現在のバッファを追加<leader>cs  - 選択範囲をClaudeに送信（ビジュアルモード）github.com補完操作（nvim-cmp）<C-p>       - 前の候補<C-n>       - 次の候補<C-d>       - ドキュメントを下にスクロール<C-f>       - ドキュメントを上にスクロール<C-Space>   - 補完を手動で開始<C-e>       - 補完を閉じる<CR>        - 候補を確定<Tab>       - 次の候補 / スニペット展開<S-Tab>     - 前の候補 / スニペット前へgithub.comトグル系（u系）Snacks.nvimが提供する便利なトグル機能。<leader>us  - スペルチェックのトグル<leader>uw  - ワードラップのトグル<leader>ud  - 診断のトグル<leader>uh  - インレイヒントのトグルその他の便利機能<leader>?   - 現在のバッファのキーマップを表示（which-key）<leader>rr  - カーソル下の単語を置換<leader>cx  - ファイルに実行権限を付与<leader>j   - 次のQuickfix項目へ<leader>k   - 前のQuickfix項目へ<leader>sT  - TODO/FIXME/HACKなどを検索（TodoTelescope）]t          - 次のTODOへ[t          - 前のTODOへgithub.comgithub.comDiffviewコンフリクト解決マージコンフリクトの解決が格段に楽になる。]x          - 次のコンフリクトへ[x          - 前のコンフリクトへ<leader>co  - oursを選択<leader>ct  - theirsを選択<leader>cb  - baseを選択<leader>ca  - 両方を選択dx          - コンフリクトを削除ビジュアル・UI設定2026年版の大きな特徴は、ミニマルなUIへの移行だ。ステータスラインとタブラインを完全に廃止し、編集スペースを最大化している。情報が多すぎて、結局何も見ていなかったことに気づいたからだ。テーマとカラースキームaquariumテーマを採用。落ち着いた色調で長時間の作業でも目が疲れにくい。-- chadrc.luaM.base46 = {  theme = "aquarium",  transparency = false,  hl_override = {    Comment = { italic = true },    ["@comment"] = { italic = true },    CursorLine = { bg = "#2a2a3a" },    CursorLineNr = { fg = "#fab387", bold = true },  },}ステータスライン廃止の理由従来のステータスラインは廃止し、代わりに以下のプラグインで情報を表示している:incline.nvim: ウィンドウ右下にファイル名と診断情報を表示modes.nvim: カーソルラインの色でモードを表示（Insert=水色、Visual=紫、Delete=赤、Copy=黄）noice.nvim: コマンドラインをフローティングで中央に表示-- options.luao.cmdheight = 0    -- コマンドラインを非表示（noice.nvimが担当）o.laststatus = 0   -- ステータスラインを非表示（incline.nvimが担当）o.showmode = false -- モード表示を非表示（modes.nvimが担当）行番号設定相対行番号を有効化。5jや10kのような相対移動が直感的になる。o.number = true         -- 現在行は絶対行番号o.relativenumber = true -- 他の行は相対行番号o.numberwidth = 4       -- 行番号の幅スクロール設定カーソルが画面端に到達する前にスクロールが始まる。常に周囲のコンテキストが見える。o.scrolloff = 8     -- 上下8行を常に表示o.sidescrolloff = 8 -- 左右8列を常に表示インデント設定2スペースインデントを採用。タブは使わない。o.tabstop = 2o.shiftwidth = 2o.expandtab = trueo.smartindent = trueその他のUI設定o.termguicolors = true  -- 24bitカラーo.signcolumn = "yes"    -- サインカラムを常に表示（ガター）o.cursorline = true     -- カーソル行をハイライト（modes.nvimで色が変わる）o.splitright = true     -- 垂直分割は右にo.splitbelow = true     -- 水平分割は下にo.clipboard = "unnamedplus" -- システムクリップボードと連携o.undofile = true       -- 永続的なundo履歴o.swapfile = false      -- スワップファイルを作らない使用プラグイン一覧と説明UI系プラグイン プラグイン                 説明                                                                                                                                                                                    incline.nvim           ウィンドウ右下にファイル名・アイコン・診断情報を表示するミニマルなフローティングステータスライン。init.luaやmod.rsのような一般的なファイル名の時は親ディレクトリ名も表示される。  modes.nvim             Vimのモード（Normal/Insert/Visual/Delete）に応じてカーソルラインと行番号の色を変える。モード表示がなくても今どのモードにいるか一目でわかる。                                            noice.nvim             コマンドライン、メッセージ、通知をモダンなフローティングUIで表示。画面中央にポップアップするコマンドパレット風のUIが特徴。詳細は後述。                                                  nvim-notify            通知をモダンなポップアップで表示。フェードアニメーションで視認性が高い。                                                                                                                vimade                 非アクティブなウィンドウ/バッファを薄暗く表示。どのウィンドウがアクティブかが視覚的にわかる。                                                                                           better-escape.nvim     jkやjjでインサートモードから抜ける。Escキーに手を伸ばす必要がなくなる。                                                                                                             which-key.nvim         キーを押すと次に押せるキーのヒントを表示。<leader>を押して300ms待つとメニューが出る。                                                                                                 indent-blankline.nvim  インデントレベルを縦線で可視化。ネストの深さが一目でわかる。                                                                                                                           noice.nvim の詳細noice.nvimは、Neovimの標準的なコマンドライン（画面下部の:プロンプト）を完全に置き換え、モダンなフローティングUIを提供するプラグイン。従来の「画面下に張り付いたコマンドライン」から「画面中央にポップアップするコマンドパレット」へと体験が一変する。主な機能:コマンドラインのポップアップ化:を押すと画面中央にフローティングウィンドウが出現入力中のコマンドがシンタックスハイライトされるコマンドタイプに応じたアイコン表示検索のポップアップ化/（前方検索）や?（後方検索）もポップアップで表示検索パターンが正規表現としてハイライトされるコマンドタイプ別のアイコン| 入力 | アイコン | 説明 ||------|---------|------|| : | | 通常のVimコマンド || `/` | ` ` | 前方検索 || `?` | ` ` | 後方検索 || `:!` | `$` | シェルコマンド実行 || `:lua` | | Lua実行 || :help | 󰋖 | ヘルプ |メッセージ・通知の統合エラーや警告メッセージをnvim-notify経由で右下にポップアップ長いメッセージは自動的にスプリットウィンドウに表示LSP統合LSPの処理進捗を表示ホバー情報やシグネチャヘルプもモダンなUIで表示-- 設定例（私の設定）views = {  cmdline_popup = {    position = { row = "50%", col = "50%" },  -- 画面中央    size = { width = 60, height = "auto" },    border = { style = "rounded", padding = { 0, 1 } },  },},この設定により、従来のNeovimとは全く異なる、VSCodeやCursor風のモダンな操作感が得られる。github.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comgithub.comナビゲーション系プラグイン プラグイン          説明                                                                                                                                                      snacks.nvim     folke氏による多機能ユーティリティセット。LazyGit統合、高速ピッカー、バッファ削除、ターミナル、デバッグ機能などを提供。2024年末に登場し、急速に普及した。  telescope.nvim  定番のファジーファインダー。ファイル、バッファ、grep、Git操作など何でも検索できる。fzf-nativeで高速化済み。                                               oil.nvim        ディレクトリをバッファとして編集できるファイルエクスプローラー。ファイル名の変更や移動がテキスト編集と同じ感覚でできる革命的なプラグイン。                flash.nvim      画面内の任意の位置に2-3キーでジャンプ。EasyMotionの後継。Treesitterと連携して構文単位のジャンプも可能。                                                   overlook.nvim   定義にジャンプせずにフローティングウィンドウでコードをプレビュー。元の位置を見失わずに定義を確認できる。                                                  hbac.nvim       開いているバッファが一定数を超えると、最近使っていないバッファを自動的に閉じる。バッファが溢れかえるのを防ぐ。                                           github.comGit系プラグイン プラグイン         説明                                                                                                                    gitsigns.nvim  変更行の左側にサイン（追加=緑、変更=青、削除=赤）を表示。Hunk単位でのステージ、リセット、プレビュー、Blame表示も可能。  diffview.nvim  Git Diffを視覚的に表示。2画面分割で変更前後を比較できる。コンフリクト解決UIも備え、ours/theirs/baseの選択が簡単。      診断・コード品質系プラグイン プラグイン              説明                                                                                                                          trouble.nvim        診断情報（エラー、警告）をパネルに一覧表示。プロジェクト全体の問題を俯瞰できる。シンボル一覧やQuickfixリストの表示にも対応。  todo-comments.nvim  コード内のTODO、FIXME、HACK、BUG、NOTEなどをハイライト表示し、検索可能にする。放置されたTODOを見つけやすい。       LSP・フォーマッタ系プラグイン プラグイン            説明                                                                                                                nvim-lspconfig    Neovim内蔵LSPクライアントの設定を簡単にする公式プラグイン。各言語のLanguage Serverとの接続を管理。                  mason.nvim        LSPサーバー、DAP（デバッガ）、リンター、フォーマッタを簡単にインストール・管理できる。:MasonコマンドでUIが開く。  conform.nvim      フォーマッタの統合プラグイン。保存時に自動フォーマットを実行。複数フォーマッタの連携も可能。                        nvim-treesitter   Tree-sitterによる高精度なシンタックスハイライトとインデント。正規表現ベースよりも正確な構文解析。                   schemastore.nvim  JSON/YAMLファイル用のスキーマを提供。package.jsonやtsconfig.jsonなどの補完と検証が効く。                       github.comgithub.comgithub.comgithub.comAI統合プラグイン プラグイン            説明                                                                                                                                             copilot.lua       GitHub Copilotの純粋なLua実装。インライン補完を提供するが、私の設定ではcopilot-cmp経由で補完メニューに統合。                                     copilot-cmp       Copilotの補完をnvim-cmpのソースとして使用。補完メニュー内で他のソース（LSP、バッファ等）と一緒にCopilot候補が表示される。                        CopilotChat.nvim  AIとのチャットインターフェース。コードの説明、レビュー、テスト生成、ドキュメント生成などをチャット形式で依頼できる。Claude Sonnetモデルを使用。  avante.nvim       Cursor風のAI編集体験をNeovimで実現。選択範囲に対してAIに編集を依頼し、差分をプレビューしてから適用できる。                                       claudecode.nvim   Claude Code CLIをNeovim内で直接使用。ターミナル統合でClaude Codeの全機能にアクセス可能。                                                        github.comgithub.com補完系プラグイン プラグイン        説明                                                                                      nvim-cmp      Neovimの補完エンジン。高速でカスタマイズ性が高い。複数のソースからの補完を統合して表示。  cmp-nvim-lsp  LSPからの補完をnvim-cmpに提供するソース。                                                 cmp-buffer    現在開いているバッファ内の単語を補完候補として提供。                                      cmp-path      ファイルパスを補完。ディレクトリ構造をたどりながら入力できる。                            cmp-cmdline   コマンドラインモード（:）での補完を提供。                                                 LuaSnip       スニペットエンジン。定型コードを素早く展開。                                              lspkind.nvim  補完メニューにアイコンを表示。種類（関数、変数、クラス等）が視覚的にわかる。             github.comgithub.comgithub.comgithub.comgithub.comgithub.com言語固有プラグイン プラグイン        説明                                                                                                                      rustaceanvim  Rust開発を強化するプラグイン。rust-analyzerとの統合を改善し、Rust固有の機能（expand macro、join lines等）を提供。         crates.nvim   Cargo.toml内のクレート（依存関係）のバージョン情報を表示。最新バージョンへの更新や、利用可能なバージョンの確認が簡単。 github.comgithub.comフォーマッタ・LSP設定保存時に自動フォーマットが走る。conform.nvimを使用。 言語                   フォーマッタ               TypeScript/JavaScript  prettier, deno_fmt         Lua                    stylua                     Rust                   rustfmt                    Go                     gofmt, goimports, gofumpt  Python                 black, isort               Terraform              terraform_fmt              Bash/Shell             shfmt                      YAML/JSON/Markdown     prettier                  Treesitter対応言語シンタックスハイライトとインデントはTreesitterで処理。vim, lua, vimdoc, html, css, markdown, markdown_inline, terraform, hcl, bash, python, rust, go, typescript, javascript, tsx, json, yaml, toml2024年版からの主な変更点追加されたプラグイン・機能Snacks.nvim: folke氏の新しいユーティリティセット。LazyGit統合、高速ピッカー、バッファ管理などoil.nvim: NvimTreeに代わるファイルエクスプローラー。ディレクトリをバッファとして編集flash.nvim: EasyMotion系のモダンな代替。Treesitter対応Trouble.nvim: 診断情報の一覧表示diffview.nvim: Git Diffの可視化とコンフリクト解決overlook.nvim: 定義をフローティングでピークAvante.nvim: Cursor風のAI編集体験ClaudeCode: Claude Code CLIとのNeovim統合noice.nvim: コマンドラインとメッセージのモダン化which-key.nvim: キーバインドのヒント表示incline.nvim: ミニマルなファイル名表示modes.nvim: モードに応じたカーソルライン色変更vimade: 非アクティブウィンドウの薄暗化hbac.nvim: 未使用バッファの自動クローズ変更されたキーマッピングバッファ切り替え: <Tab>/<S-Tab> → <S-h>/<S-l>（より直感的）スクロール: 画面中央維持が追加検索: SnacksとTelescopeの二刀流にUI設計の変更ステータスラインを完全廃止（incline.nvim + modes.nvim で代替）タブラインを廃止（Snacks pickerで代替）コマンドラインをフローティング化（noice.nvim）なぜこれらのキーマッピングを覚える必要があるのか私の経験上、以下の機能は開発効率を大きく向上させてくれる。ファイル検索（Snacks/Telescope）プロジェクト内のファイルを素早く見つけられるコードベースの把握が容易になる<leader><leader>のスマートピッカーが特に便利LSP機能コードの定義や参照を素早く調べられるリファクタリングが楽になるコードの理解が深まるエラー診断が即座にわかるRustを書いていると1箇所書き換えると芋づる式に修正が発生する。コンパイラに叱られ、LSPに導かれ、最終的には正しいコードにたどり着く。自分で考えているのか、ツールに考えさせられているのか、もはやわからないGit統合（LazyGit + Diffview）エディタを離れずにすべてのGit操作ができるコンフリクト解決が視覚的でわかりやすい<leader>ggでLazyGitを開けば、ステージ、コミット、プッシュ、ブランチ操作など全部できるAI統合コードの説明、レビュー、修正をエディタ内で完結CopilotChatでClaude Sonnetが使える時代Avanteでカーソル位置に応じたAI編集高速移動（flash.nvim）画面内のどこにでも2-3キーで移動できるマウスに手を伸ばす必要がなくなるなぜNvChadを選び続けているのか2024年版でも書いたが、NvChadを選んだ理由は開発体制の健全さだった。その判断は2026年になっても変わっていない。毎年のように「今年こそAstroNvimとかに移行する」と思うが、結局設定を移行する時間で正月休みが終わる。NvChad v3.0以降、設定の構造がより洗練された。lua/plugins/ディレクトリに機能ごとにプラグインをまとめる方式は、設定の見通しを良くしてくれる。私の設定では以下のように分割している:ui.lua: 見た目関連（incline, modes, noice, notify）navigation.lua: 移動・検索（snacks, telescope, oil, flash）git.lua: Git統合（gitsigns, diffview）diagnostics.lua: 診断（trouble, todo-comments）lsp.lua: LSPとフォーマッタ（conform, lspconfig, mason, treesitter）ai.lua: AI統合（copilot, copilot-chat, avante, claudecode）completion.lua: 補完（nvim-cmp）lang.lua: 言語固有（rustaceanvim, crates）この構造のおかげで、何か問題があった時にどこを見ればいいかすぐわかる。nvchad.comVimを学ぶために通常のVimを学ぶ時は、「実践Vim 思考のスピードで編集しよう！」がおすすめだ。Vimの基本から応用までを体系的に学べ、実践的な例も豊富に掲載されている。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazonまた、Vim Adventuresというゲームも面白い。ゲーム感覚でVimのキー操作を学べ、楽しみながら基本的なコマンドが身につく。初心者にも優しい学習カーブで、Vimの世界に入るきっかけとして最適だ。vim-adventures.comおわりにこの文章を書き終えて、ふと時計に目をやると、針は深夜一時を回っていた。年末にやるはずだった開発環境の整理を、結局、一月三日の深夜に敢行しているのである。休めていない。そんなことは百も承知である。正直に告白すれば、この文章を書いている最中にも、私は何度か「あれ、このキーは何だったか」と己の設定ファイルを参照せざるを得なかった。自分のための備忘録を執筆しながら、その備忘録を必要としている。なんという滑稽な光景であろうか。笑えない。いや、笑うしかないのかもしれない。来年の今頃、私は間違いなくこの記事を読み返しているであろう。「そうだ、<leader><leader>でスマートピッカーが開くのであった」と膝を打ち、束の間の安堵を覚える。そしてまた忘れる。おそらく、その繰り返しなのである。人間とは、かくも愚かな生き物なのだ。しかしながら、少しだけ異なることもある。毎年毎年、同じことを馬鹿の一つ覚えのように繰り返しているうちに、いつの間にか身体が記憶している操作というものが存在するのだ。gdで定義へ跳躍すること。<C-s>で保存すること。意識せずとも指が勝手に動く。それは、忘却と想起を幾度となく繰り返した果てに、ようやく獲得した境地なのである。エディタの設定に正解などない。完璧なキーマッピングも存在しない。ただ、自分が少しでも快適に作業できる環境を、毎年少しずつ更新していくのみである。それでよいのだ。それ以上を望むのは、人間の分際で天に唾するようなものである。さて、私はソファの深淵から這い上がることにする。正月休みはまだ幾ばくか残されている。しかし、仕事が始まれば、またすぐに「あのキーは何だったか」と途方に暮れる瞬間が訪れるに違いない。その時のために、この記事は存在するのである。来年の自分へ。また忘れたら読み返すがよい。どうせ忘れるのだから。参考リンクnvchad.comgithub.comneovim.io]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[テスト,検証してますか: cargo-mutantsによるミューテーションテスト入門]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/02/083735</guid>
            <pubDate>Thu, 01 Jan 2026 23:37:35 GMT</pubDate>
            <content:encoded><![CDATA[はじめにテストは全部通っている。コードカバレッジも90%を超えている。なのに、本番環境でバグが見つかった。私が実際に経験したことだ。原因を調べると、テストコードにassert（検証）が書かれていなかった。テストは「コードを実行しただけ」で、結果が正しいかどうかを確認していなかったのだ。正直、恥ずかしかった。テストを書いている気になっていただけで、何も守っていなかった。こういう経験はないだろうか。あるいは、レビューで「このテスト、意味ありますか」と指摘されたことは。この記事では、こうした「見せかけのテスト」を発見するミューテーションテストという手法と、Rust向けのツールcargo-mutantsを紹介します。公式ドキュメントを参照する場合は、以下のリンクからどうぞ。mutants.rsgithub.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。ミューテーションテストとはミューテーションテストは、「テストをテストする」手法です。具体的なコードで説明しましょう。例：割引価格を計算する関数以下のような、商品価格から10%割引した金額を返す関数があるとします。/// 価格から10%割引した金額を返すfn apply_discount(price: u32) -> u32 {    price - (price / 10)}この関数に対して、以下のテストを書きました。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    // 1000円の10%引きは900円のはず...    // でも、assertを書き忘れた！}このテストには問題があります。apply_discount(1000)を呼び出していますが、結果が900であることを検証していません。コードカバレッジは100%ですが、このテストは何も守っていないのです。ミュータント（突然変異体）の生成ミューテーションテストでは、コードに「わざとバグを入れた」バージョンを作ります。これをミュータント（突然変異体）と呼びます。apply_discount関数に対して、以下のようなミュータントが生成されます。// ミュータント1: 引き算を足し算に変えるfn apply_discount(price: u32) -> u32 {    price + (price / 10)  // - を + に変更}// ミュータント2: 常に0を返すfn apply_discount(price: u32) -> u32 {    0  // 関数の本体を0に置き換え}// ミュータント3: 入力をそのまま返すfn apply_discount(price: u32) -> u32 {    price  // 割引計算を削除}テストがミュータントを検出できるか各ミュータントに対してテストを実行します。 ミュータント   変更内容     テスト結果               判定           ミュータント1  - → +    ✅ 成功（テストが通る）  ❌ missed  ミュータント2  常に0を返す  ✅ 成功（テストが通る）  ❌ missed  ミュータント3  割引なし     ✅ 成功（テストが通る）  ❌ missed すべてのミュータントがテストを通過してしまいました。これはテストが何も検証していないことの証拠です。テストを修正するテストにassert_eq!を追加して、結果を検証するようにします。#[test]fn test_apply_discount() {    let result = apply_discount(1000);    assert_eq!(result, 900);  // 結果が900であることを検証}修正後、再度ミュータントをテストします。 ミュータント   変更内容     テスト結果             判定           ミュータント1  - → +    ❌ 失敗（1100 ≠ 900）  ✅ caught  ミュータント2  常に0を返す  ❌ 失敗（0 ≠ 900）     ✅ caught  ミュータント3  割引なし     ❌ 失敗（1000 ≠ 900）  ✅ caught すべてのミュータントが検出されました。これで「テストが正しく機能している」ことが確認できました。ミューテーションテストの核心ここまでの例で分かるように、ミューテーションテストは以下の逆説に基づいています。テストの成功が、失敗の証拠になる。コードを壊したのにテストが通るなら、そのテストは壊れたコードを見逃している——つまり、テストとして機能していません。cargo-mutantsとはcargo-mutantsは、Rust向けのミューテーションテストツールです。上記のような「ミュータントの生成」「テストの実行」「結果の集計」を自動で行います。Rustを使っている開発者なら、cargo install cargo-mutants && cargo mutantsの2コマンドで即座に試せます。ソースコードの変更は一切不要です。Rustを使っていない方も、「テストの品質をどう測るか」という観点でお読みいただければ、他の言語にも応用できる考え方が得られるはずです。いつ導入すべきかミューテーションテストは誰でも試せますが、すべてのプロジェクトに必要なわけではありません。正直に言えば、導入コストは低くない。特に有効なのは、カバレッジは80%以上あるのにバグが減らないケースです。金融計算のように正確性が重要なビジネスロジックや、チームにテストの質を意識させたい場面でも効果を発揮します。私自身、冒頭で触れた経験をした後、まずこのツールで「テストが本当に機能しているか」を確認するようになりました。一方、まだカバレッジが50%未満のプロジェクトでは、まずカバレッジを上げる方が効果的です。プロトタイプ段階で変更が激しい場合や、テスト実行時間がすでに長すぎる場合も、ミューテーションテストの優先度は下がります。ツールが問題を解決してくれるわけではない。テストを書くのは人間です。クイックスタートインストール# 推奨: cargoで直接インストールcargo install --locked cargo-mutants# 高速インストール（プリビルドバイナリ使用）cargo binstall cargo-mutants基本的な使い方# ミュータント一覧を確認（テストは実行しない）cargo mutants --list# ミューテーションテストを実行cargo mutants# 詳細出力で実行cargo mutants -v実行例実際にサンプルプロジェクトで実行した結果を示します。$ cargo mutants --list | head -20src/lib.rs:12:5: replace calculate_score -> i32 with 0src/lib.rs:12:5: replace calculate_score -> i32 with 1src/lib.rs:12:5: replace calculate_score -> i32 with -1src/lib.rs:32:5: replace is_valid_email -> bool with truesrc/lib.rs:32:5: replace is_valid_email -> bool with falsesrc/lib.rs:37:5: replace format_greeting -> String with String::new()src/lib.rs:37:5: replace format_greeting -> String with "xyzzy".into()src/lib.rs:42:5: replace find_first_even -> Option<i32> with Nonesrc/lib.rs:42:5: replace find_first_even -> Option<i32> with Some(0)src/lib.rs:47:5: replace parse_positive_number -> Result<u32, String> with Ok(0)src/lib.rs:57:5: replace get_even_numbers -> Vec<i32> with vec![]...実行すると、各ミュータントに対してテストが実行され、結果が表示されます。$ cargo mutants -vFound 108 mutants to testok       Unmutated baseline in 1s build + 1s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 0 in 0s build + 0s testcaught   src/lib.rs:12:5: replace calculate_score -> i32 with 1 in 0s build + 0s testMISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discount in 0s build + 1s test...108 mutants tested in 2m: 17 missed, 91 caught出力結果の読み方結果の4分類 結果          意味                                    アクション                  caught    テストがミュータントを検出した          良好。テストが機能している  missed    テストがミュータントを検出できなかった  テストの追加・強化が必要    unviable  ミュータントがコンパイルできなかった    無視してOK                  timeout   テストがタイムアウトした                無限ループの可能性あり     出力ディレクトリ（mutants.out/）実行後に生成されるmutants.out/ディレクトリには、詳細な結果が保存されます。mutants.out/├── caught.txt      # 検出されたミュータント一覧├── missed.txt      # 検出できなかったミュータント一覧├── timeout.txt     # タイムアウトしたミュータント├── unviable.txt    # コンパイル不可だったミュータント├── outcomes.json   # 全結果のJSON形式├── log/            # 各ミュータントの詳細ログ└── diff/           # 適用されたパッチミューテーションテストの仕組みミューテーションテストは1970年代に考案された手法ですが、計算コストの高さから長らく実用的ではありませんでした。近年のコンピュータ性能向上により、ようやく日常的に使えるようになってきました。cargo-mutantsの動作フローcargo-mutantsは以下の手順で動作します。ソースファイルの特定: プロジェクト構成を読み取り、テスト対象のファイルを見つけるコードの解析: synというライブラリ（Rustでは「クレート」と呼びます）を使って、コードの構造を解析するミュータントの生成: 「足し算を引き算に変える」「戻り値を0に変える」といった変更パターンを列挙するテストの実行: 各ミュータントに対してテストを実行し、検出できたかどうかを記録する具体例：検証していないテストコードカバレッジとミューテーションテストの違いを、具体例で見てみましょう。// 2つの数を足し算する関数fn add(a: i32, b: i32) -> i32 {    a + b}// テストコード#[test]fn test_add() {    add(1, 2);  // 関数を呼んでいるだけ！結果を検証していない！}このテストはadd関数を実行しているので、コードカバレッジは100%です。しかし、戻り値が正しいかどうかを確認していません。add(1, 2)の結果が3であることを検証していないのです。正しいテストは以下のようになります。#[test]fn test_add_correct() {    let result = add(1, 2);    assert_eq!(result, 3);  // 結果が3であることを検証している}assert_eq!は「左辺と右辺が等しいことを確認する」という意味です。等しくなければテストは失敗します。cargo-mutantsは、最初の「検証していないテスト」の問題を発見できます。a + bをa - bに変更しても、最初のテストは成功してしまいます（結果を見ていないから）。これにより「このテストは意味がない」ということが明らかになります。戻り値の型別ミューテーションcargo-mutantsは、関数の戻り値の型に応じて異なるミューテーションを生成します。「型」とは何でしょうか。プログラミングにおいて、データには種類があります。「整数」「文字列」「真偽値（はい/いいえ）」などです。Rustはこの種類を厳密に区別する言語で、「この関数は整数を返す」「この関数は文字列を返す」といった宣言が必要です。cargo-mutantsは、この「返す型」に応じて、適切なミュータントを生成します。以下、Rustを知らない方にも理解できるよう、各型の意味と合わせて説明します。bool型（真偽値）bool型とは: true（真）かfalse（偽）のどちらかを表す型です。条件分岐の判定などに使われます。/// メールアドレスが有効かどうかを判定するfn is_valid_email(email: &str) -> bool {    email.contains('@') && email.contains('.')}生成されるミューテーション:replace is_valid_email -> bool with true - 常にtrueを返すreplace is_valid_email -> bool with false - 常にfalseを返すテストで検出すべきこと: 有効なメールと無効なメールの両方をテストして、両方のケースが正しく判定されることを確認する必要があります。i32型（符号付き整数）i32型とは: -2,147,483,648から2,147,483,647までの整数を表す型です。負の数も扱えます。/// スコアを計算する（1=合格、0=普通、-1=不合格）fn calculate_score(correct: u32, total: u32) -> i32 {    let percentage = (correct * 100) / total;    if percentage >= 80 { 1 }    else if percentage >= 50 { 0 }    else { -1 }}生成されるミューテーション:replace calculate_score -> i32 with 0 - 常に0を返すreplace calculate_score -> i32 with 1 - 常に1を返すreplace calculate_score -> i32 with -1 - 常に-1を返すテストで検出すべきこと: 各分岐（合格・普通・不合格）すべてのケースをテストする必要があります。String型（文字列）String型とは: 可変長のテキストデータを表す型です。ユーザー名やメッセージなどに使われます。/// 挨拶文を生成するfn format_greeting(name: &str) -> String {    format!("Hello, {}!", name)}生成されるミューテーション:replace format_greeting -> String with String::new() - 空文字列を返すreplace format_greeting -> String with "xyzzy".into() - 固定文字列「xyzzy」を返す（「xyzzy」はテスト用のダミー文字列としてよく使われる伝統的な文字列です）テストで検出すべきこと: 戻り値の内容を検証することが重要です。単に「何か文字列が返ってくる」だけでなく、期待する内容かどうかを確認します。Option\<T>型（値があるかないか）Option型とは: 値が「ある」か「ない」かを表す型です。Some(値)で値があることを、Noneで値がないことを表します。なぜこの表現を使うのか。多くの言語では「値がない」ことをnullで表しますが、null処理を忘れてエラーになることがよくあります。Rustでは「値がないかもしれない」ことを型で明示し、処理を強制します。これにより、nullに起因するバグを防ぎます。検索結果が見つからない場合などによく使われます。/// 最初の偶数を見つけるfn find_first_even(numbers: &[i32]) -> Option<i32> {    numbers.iter().find(|&&n| n % 2 == 0).copied()}生成されるミューテーション:replace find_first_even -> Option<i32> with None - 常に「見つからない」を返すreplace find_first_even -> Option<i32> with Some(0) - 常に「0が見つかった」を返すreplace find_first_even -> Option<i32> with Some(1) - 常に「1が見つかった」を返すテストで検出すべきこと: 「見つかる場合」と「見つからない場合」の両方をテストし、見つかった場合は正しい値が返されていることを確認します。Result\<T, E>型（成功か失敗か）Result型とは: 処理が「成功」したか「失敗」したかを表す型です。Ok(値)で成功を、Err(エラー)で失敗を表します。ファイル操作やネットワーク通信など、失敗する可能性のある処理に使われます。/// 正の数をパースするfn parse_positive_number(s: &str) -> Result<u32, String> {    let n: i32 = s.parse().map_err(|_| "invalid number".to_string())?;    if n > 0 {        Ok(n as u32)    } else {        Err("number must be positive".to_string())    }}生成されるミューテーション:replace parse_positive_number -> Result<u32, String> with Ok(0) - 常に「成功（0）」を返すreplace parse_positive_number -> Result<u32, String> with Ok(1) - 常に「成功（1）」を返すテストで検出すべきこと: 成功ケースと失敗ケースの両方をテストします。特にエラーハンドリングのテストを忘れがちなので注意が必要です。Vec\<T>型（配列・リスト）Vec型とは: 同じ型の値を複数格納できる可変長の配列です。リストやコレクションを扱う場合に使われます。/// 偶数だけを抽出するfn get_even_numbers(numbers: &[i32]) -> Vec<i32> {    numbers.iter().filter(|&&n| n % 2 == 0).copied().collect()}生成されるミューテーション:replace get_even_numbers -> Vec<i32> with vec![] - 空の配列を返すreplace get_even_numbers -> Vec<i32> with vec![0] - 要素1つの配列を返すreplace get_even_numbers -> Vec<i32> with vec![1] - 要素1つの配列を返すテストで検出すべきこと: 返される配列の要素数と内容の両方を検証します。空配列が返されるケースもテストすることが重要です。演算子のミューテーションcargo-mutantsは、演算子を別の演算子に置き換えるミューテーションも生成します。比較演算子== ↔ !=    等しい ↔ 等しくない<  ↔ >     小さい ↔ 大きい<= ↔ >=    以下 ↔ 以上論理演算子&& ↔ ||    かつ ↔ または算術演算子+ ↔ - ↔ *    足し算 ↔ 引き算 ↔ 掛け算/ ↔ %        割り算 ↔ 余り単項演算子-a → a    符号反転を削除!a → a    論理否定を削除テスト不足の発見例実際にサンプルプロジェクトで検出された「missed」（テストで検出できなかったミュータント）を見てみましょう。MISSED   src/lib.rs:155:9: delete match arm 1 in calculate_discountMISSED   src/lib.rs:156:9: delete match arm 2 in calculate_discountMISSED   src/lib.rs:155:20: replace - with + in calculate_discount...これは以下のコードに対するミューテーションです。fn calculate_discount(price: u32, member_level: u32) -> u32 {    match member_level {        0 => price,                     // 割引なし        1 => price - (price / 10),     // 10% 割引        2 => price - (price / 5),      // 20% 割引        _ => price - (price / 4),      // 25% 割引    }}#[test]fn test_calculate_discount_weak() {    // member_level 0 のみテスト → 他のケースの変異を検出できない！    assert_eq!(calculate_discount(100, 0), 100);}テストがmember_level = 0のケースしかカバーしていないため、他のケース（1, 2, _）のミューテーションは検出できませんでした。これを修正するには、すべてのケースをテストする必要があります。#[test]fn test_calculate_discount_comprehensive() {    assert_eq!(calculate_discount(100, 0), 100);  // 割引なし    assert_eq!(calculate_discount(100, 1), 90);   // 10% 割引    assert_eq!(calculate_discount(100, 2), 80);   // 20% 割引    assert_eq!(calculate_discount(100, 3), 75);   // 25% 割引}設定とカスタマイズコマンドラインオプション# ファイル指定cargo mutants -f src/core.rs -f src/utils.rs# ファイル除外cargo mutants -e src/generated/*.rs# 正規表現でフィルタcargo mutants --re "impl Serialize" --exclude-re "impl Debug"# 並列実行（2-3から開始推奨）cargo mutants -j2# nextestを使用cargo mutants --test-tool=nextest# タイムアウト設定cargo mutants --timeout 300cargo mutants --timeout-multiplier 3設定ファイル（.cargo/mutants.toml）プロジェクト固有の設定を永続化できます。# .cargo/mutants.tomltest_tool = "nextest"jobs = 2timeout_multiplier = 3.0exclude_globs = ["src/generated/*.rs"]exclude_re = ["impl Debug", "impl Display"]additional_cargo_test_args = ["--all-targets"]関数単位の除外（#[mutants::skip]）特定の関数をミューテーション対象から除外できます。// Cargo.tomlに追加: mutants = "0.0.3"#[mutants::skip]  // この関数はミューテーション対象外fn should_stop() -> bool {    true  // falseに変異するとハングする}自動除外される関数以下は自動的にミューテーション対象から除外されます。#[test]属性が付いた関数#[cfg(test)]内のコードnew関数とDefault実装CI/CDパイプラインへの統合GitHub Actions基本設定name: Mutation Testingon: [push, pull_request]jobs:  cargo-mutants:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      - uses: taiki-e/install-action@v2        with:          tool: cargo-mutants      - run: cargo mutants -vV --in-place      - uses: actions/upload-artifact@v4        if: always()        with:          name: mutants-out          path: mutants.outプルリクエストでの増分テスト変更されたコードのみをテストし、高速なフィードバックを実現します。- name: Generate diff  run: git diff origin/${{ github.base_ref }}.. | tee git.diff- run: cargo mutants --no-shuffle -vV --in-diff git.diffシャーディングによる分散実行大規模プロジェクトでは、複数のジョブに分割して並列実行できます。strategy:  matrix:    shard: [0, 1, 2, 3, 4, 5, 6, 7]steps:  - run: cargo mutants --shard ${{ matrix.shard }}/8 --baseline=skip --timeout 300パフォーマンス最適化ミューテーションテストは「ミュータント数 × テスト実行時間」のコストがかかります。100個のミュータントがあり、テストに1秒かかるなら、最低でも100秒かかる計算です。実際のプロジェクトでは数百〜数千のミュータントが生成されることもあり、実行時間が課題になります。テストスイートが1分以内のプロジェクトなら、数百ミュータントでも10-20分で完了します。CIで毎回実行するのは現実的でないので、増分テスト（--in-diff）で変更されたコードのみをテストし、フルテストを週次やリリース前に限定するのが実践的です。以下の最適化も効果的です。高速リンカーの使用「リンカー」とは、コンパイルされたコードを実行可能なプログラムにまとめるツールです。プログラムを作る最終段階で使われます。デフォルトのリンカーは汎用的ですが、高速化に特化したリンカーを使うとビルド時間を短縮できます。Moldリンカーで約20%の改善、Wildリンカーでは半分以下の時間になる場合もあります。専用Cargoプロファイル[profile.mutants]inherits = "test"debug = "none"並列実行の設定-j2から開始して、リソース監視しながら調整します。高すぎる値はメモリ枯渇の原因になります。RAMディスクの活用TMPDIR=/ram cargo mutants制限事項副作用のあるコードcargo-mutantsは機械生成された変更でコードをビルド・実行するため、ファイル操作や外部システムへ接続するテストでは予期しない動作を引き起こす可能性があります。フレーキーテスト「フレーキーテスト」とは、同じコードに対して実行するたびに結果が変わる不安定なテストのことです。たとえば、現在時刻に依存するテストや、外部サービスに依存するテストがこれに該当します。ミューテーションテストは「テストが失敗したか」を判定基準にするため、フレーキーテストがあると正確な結果が得られません。まずはcargo testで確実にパスする安定したテストスイートを用意してから実行してください。サポートされていないケース 制限事項            詳細                                       Cargo専用           Bazel等の他ビルドシステムは未対応          条件付きコンパイル  #[cfg(target_os = "linux")]を理解しない  マクロ生成コード    生成されたコードは変異対象外              等価ミュータントミューテーションテストには理論的な限界があります。それが「等価ミュータント」です。たとえば、x * 1をxに変えても動作は同じです。このミュータントは検出不可能ですが、missedとしてカウントされます。また、ログ出力やデバッグ用の関数を変更しても、テストが失敗しないのは正しい動作です。だから、missed率0%は現実的な目標ではない。80-90%の検出率で十分です。残りをコードレビューや手動テストで補完します。検出できないミュータントを#[mutants::skip]で除外すれば、ノイズを減らせます。まとめテストは通っていた。でも、何も守っていなかった。冒頭で触れた私の失敗は「テストが結果を検証していない」ことが原因でした。cargo-mutantsは、こうした「見せかけのテスト」を発見するツールです。あの経験がなければ、この記事を書くこともなかったでしょう。syu-m-5151.hatenablog.comミューテーションテストの価値コードカバレッジは「テストがコードを実行したか」を測りますが、「テストが正しく検証しているか」は測れません。ミューテーションテストは「テストをテストする」手法です。わざとコードを壊して、テストがそれを検出できるかを確認します。cargo-mutantsは、Rustのミューテーションテストを「誰でもすぐに試せる」ものにしたツールです。2コマンドで導入でき、ソースコードの変更は不要です。特に有効なユースケース高いコードカバレッジを達成した後の「テストは本当に機能しているか」確認CI（継続的インテグレーション）でのプルリクエストごとの増分ミューテーションテスト重要なビジネスロジックのテストギャップ発見導入のポイントcargo mutants --listでミュータント数を確認--shard 1/100で試験実行（大規模プロジェクトでは一部だけ先に試す）#[mutants::skip]と設定ファイルで偽陽性を減らすMoldリンカーと専用プロファイルでパフォーマンス最適化他の言語でのミューテーションテストこの記事ではRust用のcargo-mutantsを紹介しましたが、ミューテーションテストの考え方は言語を問わず有効です。他の言語にも同様のツールがあります。JavaScript/TypeScript: StrykerJava: PITestPython: mutmut, cosmic-rayGo: go-mutestingテストの品質を高めたいと考えている方は、ぜひお使いの言語のツールも調べてみてください。テストは通っている。でも、本当に守っているのか。ミューテーションテストは万能ではない。実行時間もかかるし、等価ミュータントの問題もある。それでも、「テストを書いた」という自己満足に気づかせてくれる。私があの日気づいたように。その問いを持ち続けることが、テストを意味のあるものにする第一歩だと思う。単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazonソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社AmazonAIとソフトウェアテスト　信頼できるシステムを構築するために作者:Adam Leon Smith,Rex Black,James Harold Davenport,Joanna Olszewska,Jeremias Rößler,Jonathon WrightインプレスAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A2A での認証認可を理解する]]></title>
            <link>https://zenn.dev/satohjohn/articles/6e65b4be3f933a</link>
            <guid isPermaLink="false">https://zenn.dev/satohjohn/articles/6e65b4be3f933a</guid>
            <pubDate>Thu, 01 Jan 2026 17:00:25 GMT</pubDate>
            <content:encoded><![CDATA[概要Agent2Agent Protocol(以下A2A) は現在 Linux Foundation 傘下の AI Agent 同士のコミュニケーションを可能にする Open な Protocol です。https://github.com/a2aproject/A2Aざっくり言えば、AI Agent が外部で公開されていた際に、その AI Agent と自分が作成した AI Agent が協調して動くための仕様、例えば通信方法や要件などを決めたものです。A2A を使うと、マルチエージェントのような仕組みを作ろうとしたときに、様々な言語やフレームワーク、実行基盤で実装されてい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 個人的に心に残ったグラビアアイドル10選]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2026/01/01/022147</guid>
            <pubDate>Wed, 31 Dec 2025 17:21:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2025年12月31日の夜、パソコンの前でこの文章を書き始めている。Xのフォロワーが1万人を超えたとき、勢いで「おすすめのグラビアを紹介します」と言ってしまった。忙しさを言い訳にして先延ばしにしていたら、年末年始になってしまった。孤独な独身男性が大晦日に書くブログがこれでいいのか。言ってしまったからには書くしかない。普段は技術ブログを書いている。ソフトウェアエンジニアとして、コードの話や設計の話をするのが本分だ。私はグラビア評論家でもなければ、業界関係者でもない。あるのは、彼女たちの作品を見て感じた個人的な感想だけだ。素人の与太話である。合わない人はブラウザバックしてもらって構わない。2025年、生成AIが生成する画像のクオリティは日に日に上がった。「人間である必要があるのか」という問いが、あらゆる領域に突きつけられている。ソフトウェアエンジニアである私も、その問いと無縁ではいられない。AIがコードを書く。AIが画像を生成する。じゃあ私たちは何をすればいいのか。答えは出ていない。そんな中で、彼女たちは諦めていなかった。生成AIには「物語」がない。挫折も、転機も、覚悟もない。彼女たちには、積み重ねてきた時間と、これから歩む道がある。同志のようなものを感じた。この記事では、そうした「代替不可能な物語」を持つ10名を紹介したい。選考基準は単純だ。心に残ったかどうか。それだけである。紹介順に優劣はない。10名のグラビアアイドル紹介菊地姫奈彼女の眼差しには、刃物のような意志と、硝子細工のような脆さが同居している。その矛盾こそが、菊地姫奈という存在を比類なきものにしている。写真集『memory』は「5年間の集大成」と銘打たれた。五年という歳月を、彼女は一冊の書物に封じ込めた。いま彼女は、女優という新たな領域へと歩を進めている。グラビアで培った肉体の言語が、演技という別の器に注がれようとしている。「集大成」とは、すなわち終焉の美学である。散り際を知る者だけが、満開の美しさを手にする。2025年、私はその花吹雪を目撃した。豊島心桜「グラビア界最強のラスボス」。この異名を耳にしたとき、私は失笑した。誇大な修辞だと高を括った。しかし彼女のグラビアを一瞥した瞬間、その異名が寸分の誇張も含まぬことを悟った。遅れて現れた者には、待たせた分だけの凄みがある。クラシックバレエで鍛えられた四肢は、舞台を離れてなお優雅な弧を描く。その肉体には規律が宿っている。女優としての道も拓きつつある彼女は、どの領域においても王者の風格を崩さぬだろう。ラスボスとは、最後に立ちはだかる者のことだ。私などは、まだその城門にすら辿り着いていない。麻倉瑞季麻倉瑞季において、知性と肉体は対立せず、むしろ共犯関係にある。豊満な曲線を誇示したかと思えば、次の瞬間には電子の戦場で剣を振るう。大学への合格、eスポーツチームへの加入。彼女はグラビアアイドルという一つの器に収まることを拒んだ。「推しのために仕事をしている」と彼女は言う。その言葉には一片の虚飾もない。欲望に忠実であることは、ときに最も誠実な生き方となる。天羽希純天羽希純との邂逅は、アイドルグループ「#2i2」を通じてであった。しかし彼女のソログラビアを目にしたとき、アイドルという名の檻では、この獣を囲い込めぬことを知った。彼女は自らを「モンスター」と称する。「アイドル界のモンスター」なるエッセイを連載し、2025年の目標を「エゴイスティックに」と宣言した。怪物とは、既存の秩序に収まらぬ者のことだ。その自覚こそが、彼女の覚悟である。「#2i2」は2025年12月に解散した。終焉へと向かう船上で、彼女はなお踊り続けた。滅びゆくものだけが放つ光がある。私はその残照に灼かれた。一ノ瀬瑠菜2007年生まれ。この事実を知ったとき、私は時の流れの残酷さを思い知った。2025年春、高校を卒業した彼女は、グラビア誌の表紙を次々と征服した。女優としての活動も始まっている。十八歳にしてこの疾走。若さとは、無限の可能性という名の空白である。まだ何者でもない。ゆえに何者にもなれる。その特権を、彼女は惜しげもなく行使している。翻って私は、何者かになれたのだろうか。その問いに答える勇気を、私はまだ持たない。溝端葵「グラビア界の超新星」。2025年、この称号を戴くに最もふさわしき者が溝端葵であった。TikTokでの舞踊が衆目を集め、スカウトの手が伸びた。2025年3月にグラビアの世界へ足を踏み入れ、わずか三ヶ月で表紙を飾るという離れ業を演じた。彗星の如き上昇である。しかし彼女には前史がある。中学三年時、「ミスセブンティーン」の最終選考に残りながら、栄冠を逃した。約十年の歳月を経て、彼女は別の扉を開いた。一度は閉ざされた道の傍らに、もう一つの道が拓けていた。迂回こそが、ときに最短距離となる。そのような物語に、私は抗えない。七瀬なな七瀬ななという存在には、終焉と黎明が同時に宿っている。レースクイーンとして頂点を極めた彼女は、2024年末にその王座を捨てた。そして2025年、女優という未踏の地へと歩み出した。デジタル写真集のタイトルは「HORIZON」。地平線とは、見えているのに決して辿り着けぬ場所のことだ。しかし彼女は、その不可能に向かって歩を進める。幼少期に習得した器械体操を武器に、アクション女優を志すという。一つの頂を極めた者だけが、別の頂への渇望を知る。終わらせる勇気を持つ者だけが、始める資格を得る。花雨「一般OL/趣味グラビア」。花雨のInstagramにはそう記されている。本業は会社員。グラビアは余技に過ぎぬ。しかしその余技に、十三万を超える眼差しが注がれている。趣味という言葉で片付けるには、あまりに多くの魂を捕らえている。彼女は自らの手で写真集を世に送り出す。五島列島の福江島で撮影された「夕星」、沖縄で撮影された「漣」。「花雨屋」なる店舗で販売されるこれらは、いかなる事務所の介在も経ぬ、純粋なる自己表現である。事務所に属さず、テレビに出ず、雑誌の表紙を飾らず。それでも彼女の作品は確かに人心を揺さぶる。職業と趣味の境界を、彼女は軽やかに踏み越える。好きだから撮る。撮りたいから撮る。その純粋さこそが、逆説的に彼女の武器となる。仕事にせぬから続けられる。仕事にしたら続けられぬ。私にも覚えがある。技術ブログを書き続けているのも、誰に頼まれたわけでもない。髙峰じゅり髙峰じゅりは、己がレズビアンであることを公言している。「十六歳で彼女を紹介したら、祖母が泣いた」と語る彼女の言葉には、幾重もの障壁を越えてきた者だけが持つ静かな強さがある。2025年、芸名を改め、新たな幕を開けた。友人と共に撮影会を興し、運営者としての貌も見せる。「グラビアは男性にしか届かぬものと思い込んでいた」と彼女は述懐する。しかし現実には、女性からの声も多く届くという。グラビアの受け手を限定せず、性を隠さず、己を偽らず。その姿勢が、従来の境界の外にいた者たちにも届いている。道を拓く者がいるから、後に続く者が歩みやすくなる。先駆者とは、常に孤独な存在である。もものすけもものすけという存在は、どこか神話的な響きを帯びている。彼女は自他ともに認める恐竜狂である。「ダイナソー」と「アイドル」を掛け合わせ「ダイナドル」の異名を持つ。グラビア、アイドル、声優。彼女の軌跡は複数の線が並走し、交錯し、ときに融合する。いずれが本業でいずれが余技か、そのような問い自体が無粋である。好むものを好むがままに追求した結果、幾つもの貌を持つに至った。2025年も彼女は止まることを知らなかった。太古の巨獣への愛を語り、信奉者と交わり、新たな地平を切り拓き続けている。「もも」が姓で「のすけ」が名であると、本人は主張している。私も「nw」が姓で「iizo」が名だ。そのような戯れを愛する心性において、私は彼女に親近を覚える。おわりに10名の物語を書き終えて、ふと思う。私は何を見ていたのだろうか。時計を見ると12時を超えていた。1月1日に何を書いているのだろう。グラビアアイドルほど自分の器とシビアに向き合っている存在はいない。年齢、体型、表現力、時代との相性。あらゆる要素が容赦なく評価される世界で、彼女たちは走り続けている。女優になりたい人がいる。声優になりたい人がいる。まだ何になりたいか決まっていない人もいる。グラビアは通過点であり、同時に今この瞬間でもある。完成された何かより、途中経過を見る方が心が動く。たぶん、私もまだ途中だからだ。生成AIがいくら精巧な画像を生成しても、そこに物語はない。挫折も、葛藤も、成長もない。彼女たちが持っているのは、代替不可能な身体と、積み重ねてきた時間と、これから歩む道だ。私も同じだ。AIがコードを書く。私もコードを書く。違いは何か。まだわからない。でも、諦めずに問い続ける人たちを見ていると、自分も諦めなくていいと思える。冒頭で「フォロワー1万人を超えた勢いで言ってしまった」と書いた。結局、年末年始に孤独な独身男性がパソコンに向かって書いている。遅れたけど、約束は守った。彼女たちにも物語があるように、私にも物語がある。技術ブログを書き、コードを書き、たまにグラビアの話をする。そういう人間として見届けてくれる人がいる。心に残ったものを素直に書いた。それでいい。2026年、彼女たちの物語は続く。私の物語も、まだ終わっていない。関連する投稿も置いておく。グラビア写真集といえば単なる視覚的刺激として消費されがちだが、そこには各グラドルの努力や作品性、女優やタレントなどを目指しながら頑張る物語、時代ごとの表現の歴史がある。こうした背景や文脈を知るとより深く面白くなる。そんな作品性と物語性を兼ね備えた魅力的な写真集4冊を紹介します。— nwiizo (@nwiizo) 2025年11月12日]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年の振り返りをする]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2025/12/31/235646</link>
            <guid isPermaLink="false">https://nnaka2992.hatenablog.com/entry/2025/12/31/235646</guid>
            <pubDate>Wed, 31 Dec 2025 14:56:46 GMT</pubDate>
            <content:encoded><![CDATA[みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。アウトプットログ2025-1-24 3-shake SRE Tech Talk #11 オンサイト 新春OSSスペシャル 登壇2025年の外部発信はじめは所属会社である株式会社スリーシェイクの主催するイベントでした。CloudNativePGがCNCF Sandboxプロジェクトになったぞ！ 〜CloudNativePGの仕組みの紹介〜https://speakerdeck.com/nnaka2992/cloudnativepggacncf-sandboxpuroziekutoninatutazo-cloudnativepgnoshi-zu-minoshao-jieOSSスペシャルということでPostgreSQL関連のツールとして初めてCNCFプロジェクトに認定されたCloudNativePGがどのように動作しているかを掘り下げました。今年もですがここ数年は毎年、年末のセールにProxmox VM用ミニPCを購入してお家Kubernetesのセットアップをすることがルーティーンになりつつあります。そのため毎年12月から翌年4月ごろまで、DB on Kubernetesのモチベーションが高くなります。この登壇もその影響のひとつで3月ごろの登壇まではCloud Native PGに関するブログが続きました。2025-02-19 Jagu'e'r Cloud Native #17 ハイブリッド Meetup 登壇続くアウトプットも年末から続く個人的CloudNativePGブームに影響されたものです。Google Cloud関連のコミュニティであるJagu'e'rのCloud Native分科会が主催のというイベントでの登壇です。CloudNativePGを布教したい~敵「なぜCloud SQLがあるのにKubernetesでPostgreSQLをホストするのか？」~https://speakerdeck.com/nnaka2992/cloudnativepgwobu-jiao-sitaiテーマは「推しの CNCF プロジェクトを紹介するぜ LT」と言うことで当然のごとく、CloudNativePGの話をしました。CloudNativePGの特徴とデプロイ方法をともに、マネージドデータベースではなくなぜセルフホストするデータベースを選ぶのかを言及しました。2025-02-20 Kubernetes Novice Tokyo #36 登壇Jagu'e'r Cloud Native #17 ハイブリッド Meetupから開けて翌日の登壇でした。同僚の@bells17_さんが運営に参加するイベントです。データベースのオペレーターであるCloudNativePGがStatefulSetを使わない理由に迫るhttps://speakerdeck.com/nnaka2992/detabesunooperetadearucloudnativepggastatefulsetwoshi-wanaili-you-nipo-ru2025年前半は1か月1.5回という異常な登壇モチベーションがあったため、脊髄反射で登壇申し込みをした結果、連日の登壇になり自分の首を締めた記憶がつよいです。発表内容としてはStatefulSetという便利なKubernetesリソースがあるにも関わらず、なぜCRDでPodとPVCを管理するのかについて解説しました。2025-03-09 Jagu'e'r オブザーバビリティ分科会 Meetup#1 登壇Google Cloud関連のコミュニティであるJagu'e'rのオブザーバビリティ分科会が主催のというイベントでの登壇です。Google Cloudとo11yで実現するアプリケーション開発者主体のDB改善https://speakerdeck.com/nnaka2992/google-cloudtoo11ydeshi-xian-suruapurikesiyonkai-fa-zhe-zhu-ti-nodbgai-shanCloud SQL x Cloud Trace x OpenTelemetryという軸でアプリケーションのパフォーマンスをデータベースと透過的に見ましょうというはなしをしました。始めてでDBREについて登壇してから一環してデータベースエンジニアの手からデータベースを話し、アプリケーションエンジニアがデータベースエンジニアと同じ程度にデータベースへのモチベーションをもってほしいという気持ちがあらわれた登壇した。2025-03-11 Google CloudのTerraform職人が失職する機能が出てしまった…… ブログ2025年の数少ないブログ投稿の一つです。Google CloudでIaCをGUIで手軽に管理するためのツールの紹介をしたブログです。現時点ではまだまだ自分の方が上手くIaCでGoogle Cloudを管理できると自身を持っていえるものの、昨今発展の目覚ましい生成AIがこの機能に本格的に統合されたら飯の食い扶持が一つ減ってしまうと危機感を覚えます。2025-03-27 第52回 PostgreSQLアンカンファレンス@オンライン 登壇JPUGが主催するアンカンファレンスでの登壇です。データベースエンジニアの仕事を楽にする。PgAssistantの紹介https://speakerdeck.com/nnaka2992/tetahesuensinianoshi-shi-wole-nisuru-pgassistantnoshao-jie生成AIというものが本格的に使えるかも？ という世間の雰囲気にあてられて調査したツールでした。PgAssitsantというWebベースのツールを通して、PostgreSQLの調査に必要なデータを収集し、必要に応じて生成AIで分析を行うというツールです。はてブか何かに「楽にするではなく、奪うでは？ 」というコメントがあり、この程度で奪われたらもっと楽に仕事できているわと思った記憶があります。2025-04-17 Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ ブログ自社ブログでのアウトプットです。2025年のGoogle Cloud Partner Top Engineerとして2025年4月にラスベガスで開催されたGoogle Cloud Next 2025で発表されたデータベース関連のリリースをまとめて紹介したブログです。個人としても始めての海外カンファレンスの参加で、非常にモチベートされた記憶があります。2025-04-24 Next × Jagu'e'r アフターイベント「Next 2025 Big Thing」 登壇上記と同様にGoogle Cloud Next 2025のアウトプットの一つで、Jagu'e'rが主催するイベントのアフターイベントです。Google Cloud Next 2025 DM Recap ～DM領域PTEが贈る注目リリース～https://speakerdeck.com/nnaka2992/google-cloud-next-2025-dm-recap-dmling-yu-ptegazeng-ruzhu-mu-ririsuデータベース領域のGoogle Cloud Partner Top Engineerからの注目リリースを紹介しました。2025-05-14 【技術選定を突き詰める】Online Conferenc​​e 2025 登壇Findyが開催する技術選定を突き詰めるというテーマのカンファレンスの公募LT枠での登壇です。データベースの技術選定を突き詰める ～複数事例から考える最適なデータベースの選び方～https://speakerdeck.com/nnaka2992/detabesunoji-shu-xuan-ding-wotu-kijie-meru-fu-shu-shi-li-karakao-eruzui-shi-nadetabesunoxuan-bifangデータベースをどう選ぶか？ さまざまな要求があるときに、本当にその要求は必要なのか？ を問いかけ、難易度があがりやすい制約を外すことで、よりシンプルで現実的な選択肢を選ぼうという内容です。2025-05-22 JPOUG Tech Talk Night #13 登壇JPOUGが主催するテックトークイベントでの登壇です。ついに国内でも使えるようになる！～Oracle Database@Google Cloudの紹介～https://speakerdeck.com/nnaka2992/tuiniguo-nei-demoshi-eruyouninaru-oracle-database-at-google-cloudnoshao-jieGoogle Cloud Next 2025で日本のリージョンでOracle Database@Google Cloudが利用できるようになるというアナウンスにモチベートされた内容でした。Oracle Cloud InfrastructureやAWSではなく、なぜGoogle CloudでOracle Databaseがつかえることが魅力的なのかというテーマを主題でした。2025-06-06 Oracle Database＠Google Cloudの紹介～ついに日本のリージョンも使えるようになったぞ！～ ブログ自社ブログでのアウトプットです。Oracle Database@Google Cloudとはどのようなサービスなのか？ から始め、実際にどのようにデプロイできるのかを手順書チックに紹介したブログです。2025-06-30 Gemini Code Assist for GitHubでPrisma ORMのデータモデリングをレビューする ブログ自社ブログでのアウトプットです。Gemini Code Assist for GitHubを利用することでPrisma ORMのデータモデリングをレビューする知見についてまとめたブログです。いまではGoogleはGemini CLIにのりかえてしまったようで残念ですが、このブログで紹介した内容はほとんどの生成AIツールに応用可能です。2025-08-06 Google Cloud Next Tokyo 2025のパートナーブースで登壇資料としては公開していませんが、Google Cloud Next Tokyo 2025の自社ブースにて、Gemini Code Assistを利用したデータベーススキーマのPRレビューについて紹介しました。上記ブログのPrismaという軸から一般的なデータベーススキーマに焦点をひろげて紹介しました。2025-10-31 月末 Tech Lunch Online#6 - Google Cloud を語る！- 登壇2025年の登壇収めは非常にはやく、10月でした。こちらもJaguerが主催するイベントでの登壇で、Spannerとコストという軸を深掘りしました。Spannerのコストが高いの真意に迫る~ Spannerのコストの何が高いのか？ ~※ 無精のため資料非公開。そのうち公開します。よく高いといわれるSpannerですが、コストベースでみればそこまで高くありません。そんな中でイメージで語られるSpannerのコストを正確に判断するための観点を紹介しました。2025-12-16 PostgreSQLのインデックス作成におけるパラメータの影響の調査 ブログ自社とPostgreSQLのアドベントカレンダーでクロスポストしたブログ記事です。仕事でPostgreSQLのインデックス作成パフォーマンスを説明するために、適切な資料がなく困ったため、今後困らないために記述したブログといっても差し支えないです。2025-12-31 SREとPlatform Engineeringの交差点としてのデータベースエンジニア ブログ自社のアドベントカレンダーにポストしたブログです。31日にポストしていますが、アドベントカレンダーです。DBREとして仕事している中でDBRE/SREのプラクティスだけでは不足するデータベースエンジニアが本来行うべき仕事をカバーできないという課題から、常々考えておりまた業務の中でとりくもうと試行錯誤している内容をブログとしてアウトプットしたものです。その他、おしごとのことなど今年はマネージャーだったりカンリショクだったり、ピープルマネジメントだったりと呼ばれるロールにチャレンジしました。いまだにどうすればいいか別らないことは多いものの、マネージャーはこういうことを考えて発言していたのか？ など様々な学びはありました。また昨年に引き続き、Google Cloud Partner Top Engineer 2026に選出されました。昨年は数人いたデータベース領域の選出者も今年は私だけになってしまい、非常に残念です。まとめと来年の抱負今年は竜頭蛇尾としかいいようのない一年でした。通年では16件と月一回以上のペースでアウトプットできたものの、そのほとんどは上期にかたよっており、下期は6件程度でした。来年は上期で息切れしないように継続的なアウトプットを目標としたいです。また今年はアウトプットに偏ってしまったという印象もあるため、来年はもうすこしインプットを増やしたいものです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年、nwiizoが作ったソフトウェア]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/31/232623</guid>
            <pubDate>Wed, 31 Dec 2025 14:26:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2025年が終わろうとしている。先日、「なぜ『何でも作れる時代』に私は作れないのか」という記事を書いた。「代表作」がないという焦り、量をやることの重要性、そして引き算の必要性。書きながら、自分の弱さと向き合った。syu-m-5151.hatenablog.comあの記事で「2026年は20個作る」と宣言した。その前に、2025年に何を作ったのか振り返っておきたい。振り返ると、この1年は「自分が欲しいもの」をひたすら作り続けた年だった。誰かに頼まれたわけでもなく、バズを狙ったわけでもなく、ただ「これがあったら便利なのに」という衝動に従って、キーボードを叩き続けた。「3回同じ不便を感じたら作る」というルールを自分に課している。cctxは3回目の設定ファイル書き換えで、cargo-autoddは3回目のCargo.toml編集で生まれた。前回の記事で書いた「隙間家具」を、実際に作っていた1年だった。11個のリポジトリを公開し、合計900以上のスターをいただいた。正直に言えば、通知が来るたびに見てしまう。でも、スターが多くても使われないツールはある。逆に、スター10でも毎日使っているツールがある。自分にとっての成功の定義を「毎日使うか」に変えてから、気持ちが楽になった。Claude Codeと過ごした1年2025年は、Claude Codeと共に過ごした年だった、と言っても過言ではない。cctxClaude Codeを使い込むうちに、設定を切り替えたくなる場面が増えた。仕事では制限をかけたい、個人プロジェクトでは自由にやりたい。kubectxを使ったことがある人なら分かるだろうが、あの「サクッと切り替える」感覚が欲しかった。だからcctxを作った。cctx work と打つだけで、仕事モードに切り替わる。cctx - で前のコンテキストに戻る。それだけのツールだが、毎日使っている。毎日使うから、これは成功だ。github.comclaudelyticsClaude Codeをどれくらい使っているのか、可視化したくなった。トークン消費量、コスト、セッションごとの使用パターン。数字で見えると、自分の開発スタイルが見えてくる。TUIを作り込んで、眺めているだけで楽しいものにした。作っていて気づいたことがある。「正確なデータ」より「見たくなるUI」の方が継続利用に繋がる。最初はCSVエクスポートに注力したが、結局TUIの見た目を磨いた時間の方が長かった。github.comccatCLAUDE.mdというファイルが増えてくると、管理が面倒になる。どこに何を書いたか分からなくなる。インポートチェーンが複雑になる。だから分析ツールを作った。地味だけど、自分には必要だった。github.comccswarmこれは少し野心的なプロジェクトだった。複数のAIエージェントを協調させて、大きなタスクを分割して処理する。Git worktreeで並列開発を実現する。「Sangha」という仏教にインスパイアされた民主的意思決定システムを入れたのは、ちょっとした遊び心だ。正直、まだ実験段階で、自分でも使いこなせていない。でも「AIエージェントの協調」という方向性は間違っていないと思っている。来年、もう少し実用的なものにしたい。github.comRustへの愛なぜRustを選ぶのか。理由はシンプルで、ただ好きだからだ。でも「好き」の中身を分解すると、いくつかの要素がある。まず、型システムがAIと相性が良い。Claude Codeにコードを書かせると、Pythonでは「動くけど大丈夫？」という不安が残る。Rustでは、コンパイラが通ればほぼ安全だという確信がある。AIが生成したコードでも、コンパイラが厳しくチェックしてくれる。この安心感は大きい。そして、丁寧なエラーメッセージ。Rustのコンパイラは「ここが間違っている」だけでなく「こうすれば直る」まで教えてくれる。学習を助けてくれる先生のような存在だ。使うほど信頼が増す。所有権や型システムの「難しさ」は、将来の保守性を高めるための設計だと理解している。大規模・長期運用での事故を防ぐための仕組み。楽ではないが「裏切らない」という安心感がある。だから何度でも選ぶ。cargo-autoddRustを書いていると、Cargo.tomlの依存関係管理が面倒になることがある。ソースコードにuse serde_jsonと書いたら、自動で依存関係に追加してほしい。逆に、使わなくなったcrateは消してほしい。そんな怠惰な願望から生まれたツール。作っていて学んだことがある。ASTパーサーを書いていた。「完璧に解析する」より「80%の精度で10倍速い」方がユーザー体験は良い。完璧主義がUXを損なう好例だった。github.comcargo-couplingVlad Khononovの「Balancing Coupling in Software Design」を読んで感銘を受けた。結合度と凝集度のバランス、距離と変更頻度の関係。これをRustプロジェクトで可視化したら面白いんじゃないか。そう思って作り始めたら、想像以上に深い世界が広がっていた。Web UIを付けて、グラフを眺められるようにした。自分のコードを分析した。予想以上に結合度が高いモジュールを発見した。「ここ、分割した方がいいな」と気づけたのは収穫だった。ツールを作ることで、自分のコードの問題が見えてくる。github.comcargo.nvimNeovimでRustを書いている。:CargoBuildと打つだけでビルドが走り、フローティングウィンドウに結果が表示される。エディタから手を離さずに開発サイクルを回せる。些細なことだけど、この積み重ねが開発体験を変える。github.comTerraformとの格闘インフラをコードで管理するのは素晴らしい。でも、時にはTerraformと格闘することもある。tfmcpAIにインフラを任せるのは危険か。答えは「条件による」だ。tfmcpで設けた制限は3つ。本番環境は読み取り専用。全操作の監査ログを記録。destructiveな変更は人間の承認必須。この制限下なら、AIはterraform planを高速で回す優秀なアシスタントだ。危険なのは「AIに任せること」ではなく、「制限なく任せること」だ。この区別が重要だと、作りながら実感した。github.comtfocusTerraformのリソースターゲティングは麻薬だ。一度使うと「今回も大丈夫」と手が伸びる。状態の不整合が蓄積し、ある日terraform applyが破滅的な差分を出す。それでもtfocusを作ったのは、消防士にも斧が必要なように、障害対応には「禁じ手」が要るからだ。peco風のインタラクティブUIを付けて、素早くリソースを選択できるようにした。READMEに「緊急用ツール」と明記した。日常使いした瞬間、このツールは害になる。github.com開発者のための小さな道具たちvibe-ticketチケット管理システムは世の中に溢れている。Jira、Linear、GitHub Issues。でも、ターミナルで完結する、Git worktreeと統合された、開発者のためのチケット管理が欲しかった。MCPサーバーとしても動くようにした。AIアシスタントに「さっき見つけたバグのチケット作って」と言えば、作ってくれる。github.cominstrument-rsオブザーバビリティは大切だ。でも、どこにトレースを入れるべきか、どこにログを仕込むべきか、判断が難しい。コードを静的解析して、「ここに入れるといいよ」と教えてくれるツールがあれば便利だと思った。HTTPエンドポイントから実行パスをトレースして、クリティカルパスを特定する。まだ実験的なプロジェクトだけど、可能性を感じている。github.com失敗と学び11個公開したが、実は3個はアーカイブした。最初に作ったツールは設計が甘く、2週間で書き直した。公開して反応ゼロだったものもある。前回の記事で「捨てやすく作る」と書いた。アーカイブした3個は、まさにそれを実践した結果だ。状況が変わって不要になったもの、設計を間違えたもの。捨てることに罪悪感はない。役目を終えただけだ。ヒットの予測は難しい。「これは絶対使われる」と思ったものがスター20で止まり、「まあ自分用だし」と思ったcctxが一番使われている。予測できないなら、作りたいものを作るしかない。前回の記事で「量をやることで、初めて見えてくるものがある」と書いた。11個作って、ようやくその意味が分かってきた。最後にccswarmを公開して3日後、見知らぬ人からIssueが来た。「この機能を追加してほしい」と。実装して返信したら「ありがとう」と返ってきた。それだけのやり取りだったが、不思議と孤独じゃなくなった。顔も知らない人と、コードで繋がる感覚。SNSのいいねとは違う何かがあった。前回の記事で「代表作がない」と書いた。11個作っても、まだ「これだ」とは言えない。でも、前より近づいている気がする。2025年の11個は、2026年の20個への助走だ。すべてのプロジェクトはMITライセンスで公開している。もしあなたが「こんなツールがあれば」と思っているなら、まず作ってみてほしい。完璧じゃなくていい。私のツールも初版はバグだらけだった。READMEを書いて、v0.1.0をリリースする。それだけで世界が変わる。使ってくれる人がいるかもしれない。いなくても、自分が使えばいい。2025年、ありがとう。2026年は、もっと狂う。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREとPlatform Engineeringの交差点としてのデータベースエンジニア]]></title>
            <link>https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</link>
            <guid isPermaLink="false">https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</guid>
            <pubDate>Wed, 31 Dec 2025 08:14:34 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2025 最終日の記事です。データベースは従来から安全な変更を適用するには難易度が高い場合もあり、最悪の場合データロストを引き起こす変更しづらさが課題としてあります。現代のシステム開発では開発者によるデータベースの頻繁な変更は当たり前であり、変更しづらさが、そのままDevExの低下につながります。データベースの信頼性を支えるにも、DevExを向上させるにも、一定のデータベースの知見が必要になります。一方でデータベースに一定の知見をもつエンジニアや専門とするエンジニアは、インフラエンジニアやアプリケーションエンジニアに比べ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</guid>
            <pubDate>Mon, 29 Dec 2025 23:33:24 GMT</pubDate>
            <content:encoded><![CDATA[はじめに誰もまとめてくれないので自分でまとめます。こんなに悲しいことはありません。2025年11月から12月にかけて、「おい、〜」というシリーズでブログを15本書きました。登壇もしました。合計16本です。誰かがまとめ記事を書いてくれるかなと思っていました。待っていました。誰も書いてくれませんでした。年末です。仕方がないので自分で書きます。シリーズの始まり今年の8月、本を書かないかという話が来ました。嬉しかったです。企画を練りました。構成を考えました。8月、9月、10月といろいろやり取りをしていたのですが、いろんな諸事情で立ち消えになりました。悔しかったです。本を出せなかったことが悔しかったのではない。結局何にもならなかった自分が悔しかった。もっと準備できたはずだ。もっと詰められたはずだ。その後悔が残りました。でも、本の企画のために書いた下書き原稿が8本くらいありました。本にならないなら、ブログに書けばいい。そう思って始めたのが「おい、〜」シリーズです。30歳になったこともきっかけでした。5月に「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」というとても長いブログを書きました。20代が終わることへの焦り、不安、でも少しの期待。そのときに声かけていただいたのが、「おい、〜」シリーズとして出てきたものです。syu-m-5151.hatenablog.com20代の頃は「なんでもできる」と思っていました。30代になって、「できない」を認められるようになった。それは諦めではなく、等身大の自分を見つめられるようになったということです。15本を通して書いていたのは、結局そのことだったのかもしれません。「おい、部屋を掃除しろ」から始まりました。下書きを消化したあとも、言いたいことが止まらなくなりました。無限に書いても良くないので、週に1回のペースに決めました。自分を律するために「おい、週一で書け」とは書きませんでした。結果、15本になりました。15本の記事は、3つのカテゴリに分かれます。まず生活の基盤を整え、次に思考を鍛え、最後にその思考で仕事や人間関係に臨む。この順番で読む必要はありませんが、私の中ではこの流れがありました。生活習慣編おい、部屋を掃除しろ掃除の話ではありません。自分を大切に扱う習慣の話です。部屋が汚い人間に、コードをきれいに書けるわけがない。因果関係なんてないし、汚い部屋の凄腕エンジニアなんていくらでもいる。でも、知っている人はみんな適当な時期に結婚などしてなんとかなったか、心か身体を壊して生活を改めたか、消えていった。因果はわからないが、意味のわからない経験則としてある。毎日5分の掃除から始める規律の美学について書きました。syu-m-5151.hatenablog.comおい、一つずつやれSlack、メール、GitHub、全部同時に見ていると「忙しいのに何も終わらない」状態になります。これはおそらく忙しいのではなく、大量のタスク切り替えに対してコストを払っているだけです。仕事ができる人のイメージは、勝手に「マルチタスクができる人間」だと思っていました。しかし自分にその力はどうやらなさそうで、実際できていませんでした。ただ能力の限界まで「中途半端を量産する人間」でした。1日25分、1つのことだけに集中することから始めました。タスク切り替えの過払い金を整理した、という表現が正しいかもしれません。syu-m-5151.hatenablog.comおい、スマホを置け技術書が読めない。集中力が続かない。意志が弱いのだと思っていました。違いました。スマホに最適化された脳でした。私たちの世代は高校生の頃からスマホに触れてきた。15秒ごとに報酬をくれるアプリに慣れた脳が、30分かけて一つの概念を理解する作業に耐えられるわけがない。これは人生が壊れるな、という実感がありました。自分より下の世代は、もっと大変だろうなと思いました。syu-m-5151.hatenablog.comおい、本を読め「本を読まない人は生き残れない」という強迫的なメッセージへの違和感があります。いつから読書は「生き残るための手段」になったのか。効率的に知識を得るための読書は続かない。義務感で読む本は頭に入らない。ただ楽しいから読む。それだけでいい。そういう価値観もあるのだと、知ってもらえたらと思っていました。私は今も、子供の頃に初めて図鑑を開いたときと同じ気持ちで本を読んでいます。正直、楽しければなんでもいいと思っています。読者やフォロワーが楽しんで、結果として生き残ってくれれば、それでいい。syu-m-5151.hatenablog.comおい、休め休んでいるのに休めていない、という問題があります。ソファで横になってスマホを見ている。一見すると堕落の象徴のようでもあり、休息のようでもある。しかし残念ながら、これは休息ではありません。低負荷の作業です。脳は休んでいない。判断を続けている。スクロールするかどうか。この動画を見るかどうか。このツイートに反応するかどうか。AI時代は判断を求められる機会が増える一方です。現代では意識的に「何もしない」時間を作らないと、脳が壊れます。「じゃあお前はブログを書き続けて休んでないじゃないか」という指摘があると思いますが、その鋭い刃は収めていただけると助かります。syu-m-5151.hatenablog.com思考法編おい、冷笑すんなインターネットと冷笑は、相性が良すぎます。140字で専門家を論破した気になれる。何年も積み上げてきた人の仕事を、背景も知らずに「それ、意味あるんですか」と切り捨てられる。「専門性なんて要らない」「結局ポジショントークでしょ」——そんな言葉が、何も作ったことのない人から発せられている。私自身、視野を広げすぎて世界の複雑さに圧倒され、冷笑主義に陥った経験があります。何を見ても「まあ、そうなるよね」「どうせ変わらないよ」と思うようになっていた。達観した気になっていた。賢くなった気がしていた。違った。何も生み出さない人間になっていただけでした。冷笑は「どうせ無理」で終わる。批判は「ここがダメ」で終わる。批評は「ここがダメだから、こうすればいい」まで踏み込む。私は冷笑で止まっていた。一番楽で、一番何も残らない場所に。若い頃に冷笑してきたものが、今になって本当に大切だとわかる。それが少し悔しい。syu-m-5151.hatenablog.comおい、内省しろ内省と反省は違います。反省は「悪かった、次は気をつけます」で終わる。そして同じミスを繰り返す。私がそうでした。何度も反省した。何度も同じ失敗をした。反省とは、過去に頭を下げる行為でしかなかった。内省は違う。「なぜそうなったのか」を掘り下げて、構造を理解し、仕組みごと変えるプロセスです。自分を責めるのではなく、自分を観察する。毎日30秒でいい。寝る前に「今日、なぜあの判断をしたのか」を考える。それだけで少しずつ変わります。syu-m-5151.hatenablog.comおい、言語化しろ2025年、言語化神話が爆誕しました。「言語化できれば理解できる」「言語化できないのは思考が浅い証拠」——そんな空気が広がっている。確かに、言葉にできない領域があまりに広い人にとっては、その神を信じることで救われることもあります。言葉にする努力が思考を前に進めることもある。しかし、普通の大人には言語化できないものがあります。「なんとなくこっちの方がいい」という直感。説明できないけど手が動く技術。身体に染み込んだ知識、実践の中で培われた勘、創造的な跳躍、感情ヒューリスティック。これらを全部言葉にしようとすると、かえって嘘になる。言葉にした瞬間、丸められる。削られる。本当はもっと複雑で、矛盾していて、揺らいでいるものが、きれいに整理された途端に別物になる。「完璧に言語化できた」と思ったら、何か大事なものを落としている証拠かもしれない。不完全な変換でいい。「まだ言葉にできない何か」を抱えている感覚こそが、次の成長を生みます。syu-m-5151.hatenablog.comおい、つなげろ問題解決には「つなげること」と「断つこと」の両面があります。知識と知識をつなげて解決策を見つける。異なる領域の経験を結びつけて、新しい発想を得る。しかし、間違ったつながりを断つ勇気も必要です。「前もこうだったから」という過去の成功体験が、今回の失敗を招くことがある。AIに聞けば答えは出る。でも、自分でつなげる経験をしないと、応用が効かない。なぜその答えに至ったのか、プロセスが身につかない。「AIが教えてくれた答え」と「自分で見つけた答え」は、同じ答えでも身につき方が違う。苦労して見つけた答えは、次の問題を解く足場になる。与えられた答えは、その場で消える。syu-m-5151.hatenablog.comおい、類推するな所有権を「本の貸し借り」に例えて理解しました。わかった気になりました。腹落ちした感覚すらあった。しかし実際にコードを書いたら、例えが成立しない場面だらけでした。本は返却されても同じ本だが、所有権はそうではない。そういう経験は意識的にも無意識的にもやってしまうと思います。類推は便利ですが危険です。複雑なものを飲み込みやすくする代わりに、本質からズレた理解を植えつける。入り口としては使える。でも、判断するときは具体に戻る。「本の貸し借りだから...」ではなく「Rustの所有権のルールでは...」で考える。例え話で納得したら、そこで立ち止まって、例えを捨てる勇気を持つ。syu-m-5151.hatenablog.com仕事・対人編おい、対話しろ会議で「話しているが対話していない」場面があります。みんな口だけは喋っている。でも誰も聞いていない。相手の発言が終わるのを待っているだけ。その間に自分の意見を頭の中で整理している。相手の言葉を受けて考えを変える気がない。これは対話ではない。順番にモノローグを発表しているだけです。対話の本質は、相互の世界観を認識し、理解を深めるプロセスにある。相手の言葉を聞いて、自分の考えが変わる余地を残す。論破ではなく理解を目指す。勝ち負けではない。「なるほど、そういう見方もあるのか」が対話の成果です。syu-m-5151.hatenablog.comおい、がんばるな「頑張ること自体が目的化していた」という反省があります。遅くまで残って、休日も働いて、「頑張っている自分」に酔っていた。忙しさを充実感と錯覚していた。成果は出ていなかった。いや、正確には見ていなかった。過程に満足して、結果を直視していなかった。環境とのミスマッチを認識し、持続可能なペースに切り替えたら、むしろ成果が出るようになった。頑張りを減らしたのに成果が増える。皮肉だが、これが現実だった。公開した翌日、「いや、待てよ」と思いました。syu-m-5151.hatenablog.comおい、努力しろ前日の「がんばるな」への自己反論です。24時間で意見が変わりました。というわけではないです。読者は混乱したと思います。「頑張らなくていい」という言葉が、怠惰の免罪符として使われる危険性に気づいた。「無理しなくていい」が「やらなくていい」にすり替わる瞬間がある。量をこなさないと見えない景色がある。苦しみを乗り越えた経験がないと、乗り越え方がわからない。限界を知るには、一度限界まで行く必要がある。矛盾しているように見えますが、矛盾していません。両方本当です。「頑張りすぎるな」と「頑張らないと見えないものがある」は、同時に成り立つ。問題は、今の自分がどちら側にいるかを見極めることです。syu-m-5151.hatenablog.comおい、戦略を語れ「戦略」という言葉が形骸化しています。「戦略的に進めましょう」と言う人に「具体的にどういう戦略ですか」と聞くと、答えられないことが多い。「戦略」が「なんとなく賢そうな進め方」の意味になっている。戦略の本質は「何をやらないかの選択」です。全部やるのは戦略ではない。総花的にリソースを配分するのは、戦略がないことの証明です。限られた時間とエネルギーを、どこに集中させるか。何を意図的に捨てるか。エンジニアも「これは作らない」と言える立場になるべきです。「作れるけど作らない」という判断ができることが、本当の技術力かもしれません。syu-m-5151.hatenablog.comおい、論理で人が動くと思ってるのか論理的に正しい提案でも通らないことがあります。データを揃えた。根拠を示した。反論の余地がないほど完璧な提案書を作った。却下されました。なぜか。人は論理だけでは動かない。正しさだけでは、心が動かない。「このシステムは非効率です」より「先月、この非効率のせいで3時間残業しました」の方が通る。数字より、1人の体験談。グラフより、具体的な苦労話。人は物語で納得し、論理で自分を正当化する。だから、まず物語で心を動かし、その後で論理を添える。順番が逆だった。完璧な論理を用意する前に、「誰の、どんな困りごとを解決するのか」を語るべきでした。syu-m-5151.hatenablog.com登壇12月5日、Forkwell Communityで「おい、テックブログを書け」という登壇をしました。元々文章が苦手でした。今も苦手です。それでも書き続けたら、登壇を頼まれるようになりました。苦手なまま登壇しています。緊張で声が震えます。けれど登壇しています。出発点の低さは到達点を決めない。苦手なまま続けて消えていった人も山ほど見てきた。違いは何か。苦手なことを自覚した上で、苦手なまま出す覚悟をした。完璧を目指していたら続かなかった。syu-m-5151.hatenablog.com何を言いたかったのか15本を書いていて気づいたことがあります。それぞれの記事がつながっていく感覚がありました。「スマホを置け」と「休め」、「内省しろ」と「言語化しろ」。しかし同時に、全く反対のことも言っている。「がんばるな」の翌日に「努力しろ」。一貫性がない。でも、そういうものだと思っています。「おい、〜」シリーズは、飲み屋で語りたいことを適当に語っているような記事です。整合性を気にしていたら書けなかった。完璧を目指してたら書けなかった。矛盾だらけの15本ですが、振り返ると1つだけ共通点がありました。どの記事も「手段が目的化していないか」を問うていた気もする。掃除も、読書も、努力も、論理も、すべて何かのための手段です。その「何か」を見失っていた。効率と最適化に追われて、「なぜそれをやるのか」という問いを忘れていた。タスクをこなすことが目的になり、タスクの先にある価値を見失っていた。15本を通して言いたかったのは、そのことです。スマホで時間を潰すな。マルチタスクで忙しいふりをするな。冷笑で賢いふりをするな。論理だけで人を動かそうとするな。がんばることを目的にするな。でも努力から逃げるな。矛盾だらけです。人間は矛盾しています。それでいいと思っています。おわりに本の企画が立ち消えになったとき、正直落ち込みました。でも結果的に、ブログという形で書きたいことを全部書けた。本になっていたら、編集者に「矛盾してます」と言われて、どちらかを削っていたと思います。ブログでよかった。15本も書いて、誰も読んでいないかもしれません。誰もまとめてくれなかったということは、そういうことなのでしょう。あるいは、みんな忙しいだけかもしれない。そう思うことにしています。それでも書きました。自分のために書きました。30歳の自分から、40歳の自分への手紙です。「おい、お前、ちゃんとやってるか」10年後に読み返して、恥ずかしくなるかもしれません。「やっぱり正しかった」と思うかもしれません。どちらでもいい。でも、同じことを書いていたら。同じ悩みを抱えていたら。40歳の自分がこれを読んで、何も変わっていなかったら。それが一番怖い。来年も書きます。誰かがまとめてくれることを期待しています。でも、たぶんまた自分でまとめることになる。飽きたらやめます。だから普通に褒めてください。人に勧めてください。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、論理で人が動くと思ってるのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</guid>
            <pubDate>Mon, 29 Dec 2025 07:07:46 GMT</pubDate>
            <content:encoded><![CDATA[はじめに数年前の、ある金曜日の夜のことだ。会議は完全な失敗に終わった。会議室を出て、エレベーターのボタンを押しながら、私はこの文章を書こうと決めた。書き上げるまでにずいぶん時間がかかってしまったので、当時の思いとは少し違っているかもしれない。あの会議で「論理的に正しいことを言ったのか」と問われれば、言った。間違いなく言った。データも揃えた。根拠も示した。反論の余地がないほど、正しいことを言ったはずだった。だが、誰も動かなかった。私の発言が終わった瞬間、会議室の空気は凍りついた。誰も何も言わない。居心地の悪い沈黙が流れ、やがて別の話題へと移っていった。正しいことを言ったはずなのに、私は敗北感を覚えた。当時、私はシニアエンジニアになったばかりだった。部下はいない。それでも「組織全体の技術選定に責任を持て」と言われる。命令する権限はない。しかし説得しなければならない。予算を握っているわけでもない。それでもチームを動かさなければならない。これを読んでいる人の中にも、同じ経験をした人がいるのではないだろうか。「なぜ伝わらないのだ」と、帰りの電車の中で自問したことがある人が。正直に告白すれば、当時の私は根本的な勘違いをしていた。論理的に正しければ、人は動くものだと思っていた。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じて疑わなかった。だが、違った。人が動くのは、論理ではなかった。もっと別の何かだった。私はそれを「物語」と呼ぶことにした。なぜそう呼ぶのか。それを、これから書いていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理学が扱うもの私も昔、論理学を学んだとき、これで人を説得できると思った。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じていた。今思えば、かわいいものだ。論理学は、推論の形式を扱う学問だ。内容ではなく、形式を。「すべての人間は死ぬ。ソクラテスは人間だ。ゆえにソクラテスは死ぬ」——これがアリストテレス以来の三段論法です。この推論が正しいのは、ソクラテスが誰かとか、死とは何かという内容とは関係ありません。形式が正しいから、結論は必然的に正しいのです。論理学には2つの柱がある。演繹と帰納だ。演繹は、前提から結論を必然的に導く。「すべてのAはBである」という全称命題から、個別の結論を導く。前提が真で、推論形式が正しければ、結論は必ず真になる。数学の証明はこれだ。帰納は、個別の事例から一般法則を導きます。「このカラスは黒い」「あのカラスも黒い」を繰り返して、「すべてのカラスは黒い」と結論する。しかし、帰納には必然性がありません。次に見るカラスが白い可能性もあります。科学の仮説はこの帰納に基づいています。エンジニアとして、私は両方を使う。型システムは演繹だ。型が合っていれば、その部分は正しく動く。テストは帰納だ。このケースで動いた、あのケースでも動いた。だから「おそらく」正しい。論理学が教えてくれる重要なことがあります。論理的に正しい推論でも、前提が間違っていれば結論は間違います。「すべてのエンジニアはコーヒーを飲む。田中はエンジニアだ。ゆえに田中はコーヒーを飲む」——この推論は論理的に正しい。でも、前提が間違っています。論理は形式の正しさを保証しますが、内容の正しさは保証しません。そして、日常会話で「論理的」と呼ばれるものは、この厳密な意味での論理ではない。では、日常で「論理的」と呼ばれているものは、いったい何なのか。そして、論理は本当に「無力」なのか。私はそうは考えません。論理が効かないのではなく、使う順番を間違えているだけかもしれない。論理が効く瞬間と、効かなくなる瞬間がある。その違いは何か。論理が効くのは、相手がすでに「聞く準備」ができているときだ。信頼関係がある。問題意識を共有している。結論を受け入れる土壌がある。そういう状態で論理を使えば、「なるほど、確かにそうだ」となる。論理が効かなくなるのは、その準備ができていないときだ。相手が防御姿勢に入っている。「この人の話は聞きたくない」と思っている。そういう状態で論理を振りかざしても、「理屈っぽい」「押し付けがましい」と感じられるだけだ。論理が最初に来ると失敗しやすいのは、これが理由だ。相手の心が開いていないうちに正論をぶつけても、反発を招くだけ。まず共感し、信頼を築き、「この人の話なら聞いてみよう」という状態を作る。論理はその後だ。論理は「納得を作る道具」なのか、「正しさを確認する道具」なのか。私の答えは「両方だが、順番が違う」だ。正しさを確認するのは最初。納得を作るのは最後。自分の中で論理的に正しいことを確認してから、相手に伝えるときは物語で包む。論理は骨格で、物語は肉だ。骨だけ見せても、人は食べたいと思わない。論理的誤謬という問題論理学は、推論の「正しくない形式」も分類している。論理的誤謬だ。「Aさんは実績がないから、Aさんの意見は間違っている」——これは人身攻撃の誤謬だ。発言者の属性と、発言内容の真偽は別の問題だ。「みんながそう言っているから正しい」——これは多数論証の誤謬だ。多数派であることは、正しさの証明にはならない。「前例がないからやるべきではない」——これは前例への訴えだ。前例がないことと、やるべきでないことは別の問題だ。会議室で飛び交う「論理的」な議論を観察してみてほしい。これらの誤謬がどれだけ多いことか。私も、今日の会議で3つは使った気がする。しかし、ここで興味深いことがある。論理的誤謬を含む議論でも、人は納得する。むしろ、厳密に論理的な議論よりも、誤謬を含む議論のほうが説得力を持つことがある。なぜか。誤謬が含まれていると、かえって「人間らしさ」を感じないか。完璧に論理的な人は、どこか冷たい印象を与える。「この人は機械なのか」と思ってしまう。一方、多少の飛躍や感情的な訴えがある人は、「血が通っている」と感じる。厳密さを捨てることで得ているものがある。親近感だ。「この人も自分と同じように考えている」という共感だ。論理的な完璧さは、時として障壁になる。「この人には敵わない」と思わせてしまうと、対話が成立しなくなる。誤謬を許容しているのは、聞き手か、語り手か。私の答えは「両方」だ。語り手は、厳密さよりも伝わりやすさを優先している。聞き手は、正しさよりも納得しやすさを優先している。両者の暗黙の合意によって、誤謬は見逃される。これは悪いことばかりではない。日常のコミュニケーションで、すべてを厳密に検証していたら話が進まない。ある程度の「緩さ」は、社会を潤滑にしている。問題は、その緩さがどこまで許されるかだ。アリストテレスは、人を説得する技術を3つに分けた。ロゴス（論理）、パトス（感情）、エトス（人柄・信頼）だ。論理学が扱うのはロゴスだけだ。しかし、人間を動かすには3つすべてが必要になる。「論理的に正しいのに伝わらない」と悩むとき、私たちはロゴスだけで勝負しようとしている。パトスとエトスが欠けている。逆に、論理的誤謬を含んでいても人が動くとき、パトスとエトスがロゴスの欠陥を補っている。これが、論理学と「論理的に見えること」の決定的な違いだ。「論理的に見える」の解体世間で「論理的」と言われる人を、よく観察してみてほしい。彼らは本当に学術的な意味での論理を使っているだろうか。三段論法を厳密に適用しているだろうか。演繹的推論を正確に展開しているだろうか。違う。彼らがやっているのは、相手が「なるほど、確かに」と思える具体例をサッと出すことだ。データや証明だけじゃなくて、実感できる話で納得させている。では、日常で「論理的」と呼ばれているものは、何を代替しているのか。本来は感情で決めていることを、論理で覆っていないか。「なんとなく嫌だ」を「リスクが高い」と言い換える。「この人と仕事したくない」を「スキルセットが合わない」と言い換える。感情的な判断を、論理的な装いで正当化している。本来は信頼で決めていることを、論理で覆っていないか。「この人が言うから」を「データに基づいている」と言い換える。「前からこうだったから」を「実績がある」と言い換える。関係性や慣習に基づく判断を、客観的な根拠があるように見せている。本来は立場で決めていることを、論理で覆っていないか。「上が決めたから」を「戦略的に正しい」と言い換える。「予算がないから」を「費用対効果が低い」と言い換える。権力構造に基づく判断を、合理的な分析結果のように見せている。「論理的に説明した」という言葉は、責任回避になっていないか。「私が決めた」ではなく「論理的にこうなった」と言うことで、判断の責任を「論理」に押し付けている。でも、どの前提を選ぶか、どのデータを重視するか、それを決めたのは人間だ。論理は責任を引き受けてくれない。論理という言葉は、どんな場面で免罪符になるのか。「感情的になるな、論理的に考えろ」と言われたとき、相手の感情を封じ込める武器になっている。「論理的に正しいんだから従え」と言われたとき、対話を打ち切る口実になっている。論理という言葉が、思考停止の道具になることがある。「論理で動いた」ように見える行動を解剖してみよう。実際に何が作用しているのか。信頼がある。「この人が言うなら」という前提がすでに成立している。文脈がある。その結論を受け入れやすい状況がすでに整っている。同調圧力がある。周囲がすでに納得している空気がある。期待がある。その結論であってほしいという願望がある。論理は、これらの基盤の上で初めて機能する。基盤がなければ、どれだけ論理的に正しくても人は動かない。論理は感情の乗り物だ。乗り物だけあっても、燃料がなければ走らない。感情という燃料があって、初めて論理は目的地に到達する。しかし、この比喩はどこまで言い切ってよいのか。感情がない状態で論理が機能する場面は存在するか。数学の証明を考えてみてほしい。純粋に形式的な操作として、感情抜きで成立するように見える。しかし、その証明を「面白い」「美しい」と感じる心がなければ、誰が数学を続けるだろうか。論理の営みを支えているのは、やはり感情だ。感情が強すぎるとき、論理は何を失うのか。怒りに支配されているとき、論理は武器になる。相手を傷つけるための道具になる。悲しみに沈んでいるとき、論理は機能しなくなる。「わかっているけど、できない」という状態になる。感情が強すぎると、論理は歪むか、停止する。論理と感情は主従関係なのか、相互依存なのか。私の答えは「相互依存」だ。論理が感情を制御することもある。「怒りに任せて発言するのはやめよう」と論理が感情をなだめる。感情が論理を駆動することもある。「この問題を解決したい」という情熱が、論理的思考を加速させる。どちらが主人というわけではない。両者が互いに影響し合っている。うまく言葉にできる人は、論理が強いのではない。相手を見ている。相手が何を知っていて、何を知らないか。何を信じていて、何に不安を感じているか。その理解があるから、言葉が届く。論理は単体では人を動かさない。ここでもう一歩踏み込んでみます。「私は論理的です」という態度自体が、1つのナラティブではないでしょうか。「私は感情に左右されず、冷静に判断しています」という自己像を提示している。それ自体が物語を語っているということです。「AだからB」は、推論である前に、納得の物語です。原因と結果を結びつけ、聞き手を結論へと導く。それは「正しいから従うべき」ではなく「納得できるから受け入れる」という構造で機能しています。信じたい物語への依存ここまで、論理の限界と物語の力について語ってきた。しかし、もう一歩踏み込みたい問題がある。人は「信じるべき論理」ではなく「信じたい物語」を信じる。これは単なる傾向ではない。依存に近い。考えてみてほしい。データを見せられたとき、私たちは本当に中立的に判断しているだろうか。「この数字は何を意味するか」と問う前に、「この数字は自分の期待を裏付けているか」と無意識に判断していないか。期待に合致するデータは「やはり」と受け入れる。期待に反するデータは「本当なのか」と疑う。同じ論理、同じデータでも、自分の物語に沿っているかどうかで、受け取り方が変わる。これは認知バイアスの問題だけではない。もっと根深い。私たちは、自分のアイデンティティを守る物語に依存している。「私は論理的な人間だ」という物語。「私は技術力がある」という物語。「私のチームは優秀だ」という物語。これらの物語が脅かされると、私たちは防御に入る。どれだけ論理的に正しい指摘でも、自分の物語を脅かすものは受け入れられない。なぜ依存と呼ぶのか。やめられないからだ。物語を手放すことは、自分を手放すことに感じられる。「私は実は論理的ではなかった」と認めること、それはアイデンティティの崩壊に近い。どれだけ反証を突きつけられても、私たちは自分の物語にしがみつく。論理が正しいかどうかは、もはや関係ない。これは「信じるべきかどうか」の問題ではない。「信じずにいられない」という問題だ。会議室で「それは違う」と言われたとき、私たちは何を守ろうとしているのか。事実を守っているのか、それとも「私は正しい」という物語を守っているのか。正直に言えば、多くの場合は後者だ。だから、論理で人を動かそうとしても失敗する。相手の物語と衝突すれば、相手は論理を聞く前に防御に入る。「この人の言うことは聞きたくない」という状態になる。論理が届く前に、扉が閉まっている。では、どうすればいいのか。相手の物語を攻撃するのではなく、その物語の中に入る。相手が信じたい物語を否定せず、その物語の延長線上に自分の提案を置く。「あなたの論理は間違っている」ではなく、「あなたの考えをさらに進めると、こうなる」と語る。人を動かすとは、相手の物語を書き換えることではない。相手の物語に自分の提案を織り込むことだ。経験談が人を黙らせる理由人を説得するとき、論理だけでは足りない。自分の失敗談を語ることで心を掴むことがある。「とほほエピソード」には不思議な力がある。完璧な論理よりも、不完全な経験談のほうが、人の心に響くことがあるのだ。経験談は再現性が低い。その人固有の文脈でしか成り立たないことも多い。なのに、私たちは経験談に心を動かされる。なぜか。経験談が持つ力を3つに分解してみる。1つ目は、再現性の放棄だ。「これが正解です」ではなく「私はこうだった」と語ることで、聞き手は反論しにくくなる。事実に対しては「それは違う」と言えるが、経験に対しては言えない。2つ目は、思考コストの削減だ。抽象的な理論を理解するより、具体的な経験を追体験するほうが楽だ。聞き手は考えなくても「なるほど」と言える。3つ目は、権威の自動付与だ。「やったことがある人」は、それだけで信頼される。成功者の経験談には、内容を超えた説得力が宿る。しかし、ここに危険がある。「成功者が言うから正しい」という錯覚。これは聞き手の思考停止を招く。経験談が「効きすぎる」とき、何が起きているのか。聞き手は考えることをやめている。語り手の経験を、自分の結論にすり替えている。経験談を聞いた瞬間、聞き手は何を放棄しているのか。批判的思考だ。「本当にそうか」「自分の場合は違うのではないか」という問いを放棄している。経験談には「事実」としての重みがあるから、反論しにくい。反論すると「お前はやったことがないくせに」と言われそうだから、黙ってしまう。「反論できない感じ」は、どこから生まれるのか。経験談は「私はこうだった」という一人称で語られる。一人称の物語に対して、「それは違う」とは言いにくい。他人の経験を否定する権利が自分にあるのか、という遠慮が働く。しかし、その経験から導かれる「だからこうすべきだ」という結論は、本当に正しいのか。そこは検証が必要だ。だから、経験談は入口であって、結論ではない。経験談で心を開き、そこから自分で考える。その順番が重要だ。では、経験が浅い人は物語を語る資格がないのか。私はそうは考えません。経験の浅さには、浅いなりの価値があります。経験が浅いからこそ見えるものがある。「なぜこのやり方なのか」という素朴な疑問。ベテランにとっては「当たり前」になっていることへの違和感。「本当にこれでいいのか」という不安。これらは、経験を積むほど薄れていく。ベテランが失いやすい視点とは何か。初心者の目線だ。「これは難しい」「これはわかりにくい」という感覚は、慣れると消えてしまう。だからベテランが書いたドキュメントは、初心者には読めないことがある。ベテランが設計したシステムは、初心者には使えないことがある。経験は資産だが、同時に負債でもある。「まだわからない」という物語は、どんな力を持つか。謙虚さの力だ。「私はまだ学んでいる途中です」と言える人は、相手の話を聞く姿勢がある。「私は全部わかっています」と言う人は、すでに耳を閉じている。経験の浅さを認めることは、対話の扉を開くことになる。重要なのは経験の量ではなく、経験を物語として語る力だ。10年の経験があっても、それを言葉にできなければ伝わらない。1年の経験でも、そこから何を学んだかを語れれば、人の心に届く。経験談を「入口」に留めるには、何が必要か。聞き手の側には、「この人の経験は参考になるが、自分の状況は違うかもしれない」という留保が必要だ。語り手の側には、「これは私の経験であって、あなたに当てはまるとは限りません」という謙虚さが必要だ。両者がこの姿勢を持っていれば、経験談は入口のまま留まる。物語が許されない領域私はエンジニアとして長く働いてきた。だからこそ言いたいことがある。物語万能論は危険だ。かつて、私は失敗したことがある。プロジェクトが炎上しかけていたとき、チームの士気を上げようと物語を語った。「このプロダクトが世に出れば、多くの人の生活が変わる」「困難を乗り越えた先に、私たちは成長している」。チームは一時的に盛り上がった。でも、テストは通らなかった。本番環境でバグが発生した。物語で人は動いたが、システムは動かなかった。バグは物語で直らない。物語でテストが通るなら、私は今頃、小説家になっている。どれだけ美しい物語を語っても、コードが間違っていれば動かない。どれだけチームが納得しても、テストが通らなければリリースできない。エンジニアリングには、物語では代替できない領域がある。技術的正しさは、どこまで物語と共存できるのか。私の答えは「共存はできるが、置き換えはできない」だ。物語は人を動かすが、システムは論理で動く。この2つを混同してはいけない。泣いたら人は許してくれるかもしれませんがシステムは許してくれません。人の層とシステムの層を混同すると、何が起きるか。人の層で通用する「納得したからOK」が、システムの層に持ち込まれる。チーム全員が「この設計でいこう」と合意しても、コードが間違っていれば動かない。逆に、システムの層で通用する「正しいから従え」が、人の層に持ち込まれる。論理的に正しい設計でも、チームが納得していなければ実装は進まない。「納得したからOK」は、どこまで通用するのか。人を動かすところまでだ。「このアーキテクチャでいこう」という合意形成には物語が必要だ。しかし、そのアーキテクチャが本当に要件を満たすかは、検証が必要だ。納得と正しさは別の問題だ。物語で進めてはいけない判断の特徴は何か。結果が客観的に検証できる判断だ。「このコードは動くか」「このシステムは要件を満たすか」「このセキュリティ対策は十分か」。これらは、どれだけ美しい物語を語っても、実際にテストしなければわからない。物語で「大丈夫だろう」と進めて、本番環境で障害が起きたら、物語は言い訳にしかならない。ナラティブと検証の役割分担を整理しておく。人を動かすのは物語だ。なぜこの技術を選ぶのか、なぜこのアーキテクチャにするのか。それを説明し、納得してもらうには物語が必要だ。正しさを担保するのは論理とテストと記録だ。選んだ技術が本当に動くのか、アーキテクチャが要件を満たすのか。それを確認するには検証が必要だ。「あの人が言うから正しい」という判断は、いつ危険になるのか。それは、検証を省略したときだ。権威ある人の経験談に納得したとしても、コードレビューは必要だ。テストは必要だ。ドキュメントは、物語の代替にはなりえない。物語が「なぜそうするのか」を伝え、ドキュメントが「何をするのか」を記録する。物語は人の層に効き、論理はシステムの層に効く。この使い分けが重要だ。プロジェクトを進めるには「直線モード」と「曲線モード」を行き来する必要があります。計画と合理性を重視する直線モード、そして変化や対話を重視する曲線モード。どちらか一方では足りません。両方を使い分けられることが、プロジェクトを前に進める力になります。優しい物語の罠「あなたらしさを大切にしたうえで、今必要な道具を手に入れ、磨き、使い分けていこう」というメッセージには優しさがある。しかし、優しい物語は、なぜ時に成長を妨げるのか。思い出してほしい。優しい言葉をかけたのに、相手が変わらなかった経験はないか。「大丈夫だよ」と言い続けたのに、問題が解決しなかった経験はないか。あのとき、私たちは何を間違えていたのか。優しさは寄り添う。甘さは目を背けさせる。優しさと甘さは、どこで分岐するのか。私の答えは「事実を直視しているかどうか」だ。優しさは事実を受け止めた上で寄り添うこと。甘さは事実から目を背けさせること。「あなたらしくていい」が「変わらなくていい」に変質したとき、それは優しさではなく甘さになる。厳しさを含まない物語は、誰のためのものか。多くの場合、それは語り手のためだ。相手に嫌われたくない、対立を避けたい、という語り手の願望が、優しさという衣をまとっている。その優しさは、聞き手のためか、語り手のためか。この問いは重要だ。「傷つけたくない」と言いながら、実は「嫌われたくない」だけかもしれない。「今は言わないほうがいい」と言いながら、本当は「言うのが面倒」なだけかもしれない。優しさの仮面をかぶった自己保身は、いくらでもある。事実を和らげることと、隠すことの境界はどこか。私の答えは「相手が判断するために必要な情報を持っているかどうか」だ。「あなたのスキルはまだ足りないが、伸びしろがある」は和らげている。「あなたは素晴らしい」と言って、スキル不足を伝えないのは隠している。前者は事実を含んでいるから、相手は次の行動を選べる。後者は事実を隠しているから、相手は間違った判断をする。成長を促す厳しさと、切り捨ての厳しさはどう違うか。成長を促す厳しさは、相手の可能性を信じている。「あなたならできるはずだ。だから厳しく言う」という姿勢がある。切り捨ての厳しさは、相手を見限っている。「あなたには無理だ。言っても仕方ない」という諦めがある。言葉は同じ「厳しさ」でも、その奥にある信頼の有無で意味が変わる。勇気を与える物語と、逃避を許す物語の違いは何か。勇気を与える物語は「困難があるが、乗り越えられる」と語る。逃避を許す物語は「困難なんてない」と語る。前者は現実を認めた上で希望を示す。後者は現実から目を背けさせる。自分が語っている物語は、どちらだろうか。説得と操作の境界物語には力がある。力があるということは、危険もあるということだ。物語は、どの瞬間に「説得」から「操作」に変わるのか。その境界は曖昧だ。聞き手の自由意志は、どこまで守られているのか。完全に自由な判断などありえない。私たちは常に、何らかの影響を受けながら判断している。では、説得と操作は何が違うのか。結果だけを見れば、どちらも「相手が動いた」という点では同じだ。説得と操作の違いは、「結果」ではなく「過程」にある。結果が同じなら、過程を見なければならない。しかし、過程を見れば違いが見える。説得は、相手が考える余地を残している。操作は、相手が考える余地を奪っている。相手が考える余地を失った瞬間は、いつか。選択肢が1つしか見えなくなったときだ。「これしかない」「こうするしかない」と思わせた瞬間、相手は考えることをやめている。本当は他の選択肢があるのに、それを見せないでおく。これは操作だ。「選択肢を示す」と「結論を誘導する」の違いは何か。選択肢を示すとは、複数の道があることを伝え、それぞれの長所と短所を説明することだ。結論を誘導するとは、複数の道があるように見せながら、1つの道だけが正しいと思わせることだ。言葉は似ているが、相手の思考を尊重しているかどうかで意味が変わる。しかし、だからといって何をしてもいいわけではない。善意で語った物語が、操作になるのはどんなときか。語り手が「相手のため」と信じていても、相手の判断力を奪っていれば操作だ。「あなたのためを思って」という言葉は、しばしば「私の思い通りにしたい」の言い換えになっている。善意は免罪符にならない。語り手の「善意」は、免罪符になりうるか。ならない。善意で語った物語が、相手を誤った方向に導くことはある。「あなたのためを思って」は、操作の常套句だ。善意は動機であって、結果の正当化にはならない。操作に堕ちないための条件を3つ挙げる。1つ目は、事実を歪めないこと。都合のいい事実だけを選んだり、不都合な事実を隠したりしない。2つ目は、相手に考える余地を残すこと。「これしかない」と思わせるのではなく、「こういう選択肢がある」と示す。結論を押し付けない。3つ目は、相手の利益を本当に考えていること。相手を動かすことが目的なのか、相手のためになることが目的なのか。同じ物語でも、動機によって意味が変わる。この3つが揃わなければ、どれだけ巧みな物語も操作に堕する。また、「別の物語を語る」ことが、失敗からの逃避になることもある。プロジェクトが破綻したとき、物語を更新することで責任を回避していないか。失敗の原因を分析し、自分の責任を認めた上で、「次はこうする」という物語を語るのは再解釈だ。事実から目を背け、「本当はうまくいっていた」「環境が悪かった」と言い張るのは言い訳だ。物語は現実を覆い隠すためのものではない。現実を受け止めた上で、次に進むためのものだ。では、物語を使った対話とはどのようなものか。ファシリテーションの現場から考えてみます。対話は物語を揃えることではない優れたファシリテーターは「ほぼ何もしない」といいます。ワークを説明したら、部屋の隅に座る。音楽を流す。ニコニコ笑っている。具体的な動きはそれだけです。でも、それでチームは動く。なぜか。それは、ファシリテーターが「物語の場」を設定しているからだ。メンバーが自分たちで物語を紡げるような空間を作っている。論理的な指示を与えるのではなく、物語が生まれる環境を整えている。しかし、対話とは本当に「物語の共同制作」と言えるのか。正直に言えば、完全に対等な共同制作は難しい。ファシリテーターは場を設計している時点で、ある種の権力を持っている。どんな問いを投げかけるか、どんな発言を拾うか、どこで介入するか。それらすべてが、生まれる物語に影響を与える。「何もしない」という選択自体が、1つの介入なのだ。では、合意されなかった物語はどこへ行くのか。チームで1つの物語を紡いだとき、そこに乗れなかった人がいる。彼らの物語は消えるのか。消えはしない。地下に潜るだけだ。表向きは合意しながら、心の中では別の物語を持ち続ける。優れたファシリテーターは、この「語られなかった物語」にも目を向ける。全員が同じ物語を持つ必要はない。大切なのは、異なる物語が共存できる場を作ることだ。対話のゴールは「1つの物語に収束すること」ではなく「複数の物語が共存できること」だ。合意形成について、よく誤解されていることがある。多くの人は、自分の檻の中から相手の檻を押し潰そうとする。自分の枠組みが正しい、相手の枠組みは間違っている。だから相手を説得し、こちらの檻に入れようとする。でも、それは合意ではない。征服だ。本当の合意形成とは、まず自分が檻の中にいることを認めることから始まる。私にも枠組みがある。相手にも枠組みがある。どちらの檻も、その人の経験と価値観から作られている。どちらが正しいという話ではない。相手の檻を壊す必要はない。自分の檻を捨てる必要もない。大切なのは、お互いの檻の形を理解し、その間に共通の地面を見つけることだ。檻から出るのではなく、檻と檻の間に橋を架ける。それが対話だ。一貫性とは何か複数の物語を使い分けることは、「一貫性の欠如」にならないのか。状況に応じて物語を切り替える人は、信用できないのではないか。そう感じるかもしれません。しかし、一貫性とは何でしょうか。言葉の統一なのか、価値観の統一なのか。私は、一貫性とは価値観の統一だと考えている。言葉が変わっても、芯がぶれなければ、それが一貫性だ。言葉や物語は変わっていい。相手によって、文脈によって、最適な表現は変わる。しかし、その奥にある価値観——何を大切にしているか——は変わらない。物語が変わっても残る「軸」とは何か。それは「この人は結局、何を実現したいのか」という問いへの答えだ。チームの成長を願っているのか。技術的な卓越性を追求しているのか。顧客の幸福を第一にしているのか。その軸がぶれなければ、物語が変わっても芯はぶれない。文脈適応と迎合の違いは、どこで判断できるのか。文脈適応は、相手に届くように表現を変えること。迎合は、相手に合わせて価値観を曲げること。前者は橋を架ける行為であり、後者は自分を売る行為だ。同じ価値観を異なる文脈で語り分けられることこそが、優れたナラティブ構築者の条件だ。論理を使い直すここまで、論理の限界を語ってきた。論理は単体では人を動かさない。論理自体が1つの物語だ。論理を絶対視することの危険。しかし、論理を否定して終わりにするつもりはない。論理を「唯一の正解」から「道具」へ格下げすることは、思考を弱くするのか、強くするのか。私は強くすると考えている。論理を絶対視していると、「論理的に正しいのになぜ伝わらないのか」と悩むことになる。論理を道具として扱えば、「この道具はこの場面では有効か」と考えられる。道具は選べる。使い分けられる。論理という物語が有効な場面と、別の物語が有効な場面を見極められるようになる。プロジェクトには「プロジェクトストーリー」がある。最終ゴールと中間ゴールからストーリーを描き、チームの方向性を示す。このストーリーの中に、論理は組み込まれる。計画は論理的だろう。でも、その計画を人に伝え、人を動かすには、物語という器が必要だ。論理と物語、どちらも選んで使うものです。どちらかが正しいのではありません。どちらをいつ使うかを判断できることが、人を動かす力になります。正しさを振り回すのは、本当に「最後」でいいのかここまで読んで、こう思った人がいるかもしれない。「物語が先で、正しさは後。それはわかった。でも、正しさを最後まで出さないことに、問題はないのか」正しさを最初に出したくなるのは、どんな不安からか。「間違ったことを言いたくない」という不安だ。「後で『それは違う』と言われたくない」という不安だ。正しさを先に出しておけば、自分の立場は守られる。たとえ相手が納得しなくても、「私は正しいことを言った」と言える。正しさを最初に出すことは、自己防衛なのだ。しかし、正しさを最後に出すことで、失われるものはないのか。ある。時間だ。物語で回り道をしている間に、問題は悪化する。緊急事態では、正しさを最初に出すべき場面もある。「このまま進むとシステムが落ちます」と言うべきときに、「まず私の経験を聞いてください」と始めている場合ではない。「最後まで正しさを出さない」こと自体が、別の操作になっていないか。この問いは重要だ。相手が自分で結論に至ったように見せかけて、実は最初から結論が決まっている。正しさを隠しながら誘導している。これは、正しさを振りかざすのとは別の形の操作だ。では、いつ正しさを出すべきか。私の答えは「相手の安全が脅かされるとき」と「時間の制約があるとき」だ。相手が危険な判断をしようとしているとき、物語を語っている余裕はない。「それは間違っている」と言うべきだ。締め切りが迫っているとき、回り道をしている余裕はない。「正しい方法はこれです」と言うべきだ。正しさは武器だ。武器を振り回すのは危険だが、武器を持たないのも危険だ。大切なのは、いつ抜くかを見極めることだ。syu-m-5151.hatenablog.comおい、物語を語れだから、私は言いたい。おい、物語を語れ。論理的であろうとするな、とは言いません。論理は大事です。でも、論理だけでは人は動きません。「この設計が正しい理由は〜」と説明するとき、あなたは本当に論理だけで話しているだろうか。実は、相手が納得しやすい順番で、相手が受け入れやすい言葉で、相手の不安を先回りして解消しながら話しているのではないか。それは物語を語っているということだ。世間で「論理的」と言われる人の正体は、巧みなナラティブ構築者だ。彼らは論理を使いこなしているのではない。論理という道具を使って、説得力のある物語を紡いでいるのだ。そして、そのことに自覚的になることで、私たちはより良い物語の語り手になれる。物語を語る勇気でも、物語を語るのは怖い。論理的であろうとするのは、ある意味で楽です。「これはデータに基づいています」「これは事実です」と言えば、自分の主観を隠せます。責任を回避できます。でも物語を語るということは、自分をさらけ出すことだ。裸になることだ。「私はこう思う」「私はこれを大事にしている」「私はこの未来を信じている」と言わなければならない。自分の背景を伝えること、自分の失敗を語ること、自分の葛藤を見せること。それは勇気がいる。でも、その勇気が人を動かす。「論理的に正しいから」ではなく、「この人が言うなら」で人は動く。そして「この人が言うなら」を引き出すのは、論理ではなく、物語だ。おわりに年の瀬の日曜日の夜、私はベッドの上でこの文章を書き終えようとしている。正直に言えば、書いている間も何度か「これは論理的に正しいのか」と自問してしまった。物語の力を語りながら、論理の正しさを気にしている。滑稽だ。滑稽だが、それが私という人間なのだと思う。この文章を書いたからといって、明日から完璧に物語を語れるようになるわけではない。おそらくこれからも、会議室で正論を並べ立て、微妙な沈黙を招く日があるだろう。「なぜ伝わらないのだ」と、帰りの電車で思い悩む日があるだろう。だが、少しだけ違うことがある。以前の私は、伝わらないとき、「もっと論理的に説明しなければ」と考えていた。今は違う。「ああ、骨だけを見せていた」と気づくことができる。気づいたなら、肉を足せばいい。失敗談をひとつ、付け加えればいい。それだけでも、以前よりはましなのだと思う。たぶん。明日は月曜日だ。また会議がある。また正論を振りかざしたくなる瞬間がある。だが今度は、最初に自分の失敗談から話してみようと思う。「この設計が正しい理由は」ではなく、「以前、似たような判断を先送りにして、半年後に全員で苦しんだことがある」から始めてみる。怖い。裸を晒すようで、怖い。だが、論理だけで人が動くと信じていた私は、もういない。あの金曜日のエレベーターの中で、その私は死んだのだと思います。おい、物語を語れ。何度でも、自分に言い聞かせる。何度でも忘れ、何度でも思い出す。完璧に語れるようになることより、何度でも思い出せることのほうが、きっと大切なのだ。参考文献イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon小説作者:野崎まど講談社Amazon言語化するための小説思考作者:小川 哲講談社Amazonリーダーのためのストーリーテリング入門 90秒で人の心を動かす「語り」のマネジメントスキル作者:広江 朋紀翔泳社Amazonリーダーのための！　ファシリテーションスキル作者:谷 益美すばる舎Amazonチームビルディングと組織開発の話作者:長尾 彰ナガオ考務店Amazonチーム・ビルディング[新版]　人と人を「つなぐ」技法作者:堀公俊日経BPAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社Amazonエンジニアリングが好きな私たちのための　エンジニアリングマネジャー入門作者:サラ・ドラスナー日本能率協会マネジメントセンターAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazonナラティブ経済学―経済予測の全く新しい考え方作者:ロバート・シラー東洋経済新報社Amazon世界はナラティブでできている：なぜ物語思考が重要なのか作者:アンガス フレッチャー青土社Amazonストーリーが世界を滅ぼす―物語があなたの脳を操作する作者:ジョナサン・ゴットシャル東洋経済新報社Amazon「わかってもらう」ということ　他人と、そして自分とうまくやっていくための言葉の使い方 (単行本)作者:川添 愛KADOKAWAAmazonなぜあなたはマネジメントを間違えるのか？　会社の常識を打ち破るチェンジリーダーの教科書作者:岸良裕司KADOKAWAAmazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon人が壊れるマネジメントプロジェクトを始める前に知っておきたいアンチパターン 50作者:橋本将功ソシムAmazonモチベーション革命　稼ぐために働きたくない世代の解体書 (NewsPicks Book)作者:尾原和啓幻冬舎Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[4年目セキュリティエンジニアの2025年振り返り & AIから見た今年の私]]></title>
            <link>https://www.rowicy.com/blog/review-2025-riiim/</link>
            <guid isPermaLink="false">https://www.rowicy.com/blog/review-2025-riiim/</guid>
            <pubDate>Mon, 29 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[新卒からエンジニアとして4年経とうとする中で、2025年の振り返りをやっていこうと思います]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 俺が愛した本たち 非技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</guid>
            <pubDate>Sun, 28 Dec 2025 02:50:33 GMT</pubDate>
            <content:encoded><![CDATA[はじめに技術書編を書き終えて、ふと気づいた。あれだけ書いても、まだ語っていない本がある。仕事に直結しない本。読んでも生産性が上がらない本。キャリアに役立つかどうかわからない本。そういう本たちのことを、どこかで書きたいと思っていた。だから、この記事を書いている。非技術書を読む時間を、どこか後ろめたく感じていた時期があった。エンジニアなんだから技術書を読むべきだ。限られた時間を、仕事に関係ない本に使っていいのか。そんな自問が、頭の片隅にあった。でも、ある時期から考えが変わった。技術書だけ読んでいると、技術書が読めなくなる。視野が狭くなる。発想が硬くなる。同じ問題を、同じ角度からしか見られなくなる。なぜそうなるのか。技術書は「答え」を求めて読むからだ。設計パターン、ベストプラクティス、トラブルシューティング。明確な課題があって、その解決策を探している。でも非技術書は違う。何を得られるかわからないまま読み始める。読み終わっても、何が残ったのかすぐにはわからない。数ヶ月後、ふとした瞬間に「ああ、あの本のあれか」と腑に落ちることがある。即効性がないから、効いている実感もない。でも、確実に何かが変わっている。では、非技術書は仕事に無関係かというと、そうでもない。小説を読む。エッセイを読む。哲学書を読む。歴史書を読む。どれも仕事には直結しない。でも、人間を理解しようとする営みは、チームで働く上で無駄ではないはずだ。コードを書くのは人間だ。レビューするのも人間だ。障害対応で慌てるのも、成功を喜ぶのも、人間だ。技術だけ理解しても、人間を理解していなければ、良いエンジニアにはなれない。そう言い聞かせながら、非技術書を読んできた。ここまで書いて、自分でも気づいている。これは言い訳だ。正直に言えば、読んでいて楽しいから読んでいる。それだけだ。仕事のためとか、自己成長のためとか、そういう大義名分は後付けだ。ページをめくる時間が好きだ。知らない世界に触れる瞬間が好きだ。登場人物の感情に揺さぶられる体験が好きだ。好きなことに理由はいらない。でも、理由を語りたくなるのが人間だ。断っておくと、以下の選定基準はかなりブレている。読んだ直後に評価したわけではなく、年末に一年を振り返って「良かったな」と思い出した本を並べているだけだ。印象に残った理由も、内容が深かったからだったり、読んだタイミングが良かったからだったり、装丁が好みだったからだったり、バラバラだ。体系的なブックガイドではない。ある一人のエンジニアが、2025年に出会って心に残った本の記録だと思ってほしい。以下に紹介する本たちは、2025年に私の心を動かした非技術書だ。仕事に役立つかどうかはわからない。キャリアに影響したかどうかもわからない。ただ、これらの本と過ごした時間が、私の2025年を少しだけ豊かにしてくれた。それだけは確かなことだ。昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2025年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるまずは小説から始めよう。物語の力を信じているから。小説野崎まどという作家は、読者の予測を裏切ることに喜びを見出しているとしか思えない。タイトルが『小説』。これ以上ないほど直球で、それでいて挑発的だ。読み始めたときは、ただの青春小説かと思った。でも違った。「小説とは何か」という問いに正面から向き合いながら、それ自体が1つの「小説」として成立している。メタ構造に気づいた瞬間、鳥肌が立った。野崎まどの作品は、読み終わった後に「やられた」と思わせる仕掛けが必ずある。『know』では知識と情報の本質を、『タイタン』ではAIと人間の関係を問いかけてきた。本作では、小説という形式そのものを問いかけてくる。読んでいる間は物語に没入し、読み終わった後に構造の巧みさに気づく。その二重の楽しみが、野崎作品の醍醐味だ。小説作者:野崎まど講談社AmazonGOATデジタル全盛の時代に、あえて紙の文芸誌を立ち上げる。その挑戦に心を動かされた。510円という価格設定で、特殊紙を惜しみなく使い、読書バリアフリーにも取り組んでいる。翻訳の仕事をしているとよく分かるが、紙代も印刷代も高騰している。書籍全体の価格が年々上がっているのは、出版社の怠慢ではない。本を作るコストそのものが上がっている。そんな中で、この価格で、この品質を維持しようとしている。すごいな、と素直に思った。GOAT作者:西加奈子,小川哲,尾崎世界観,市川沙央,チョン・セラン小学館AmazonGOAT Summer 2025作者:朝井リョウ,一穂ミチ,野崎まど小学館Amazon野崎まどの「山羊と七枚」も掲載されており、雑誌のコンセプトと作家の個性が見事に噛み合っていた。dps.shogakukan.co.jp小説と雑誌を読んで、ふと考えた。読む時間は有限だ。何を読むかより、どう読むかが問われる。そこで手に取ったのが、この本だった。STOIC 人生の教科書ストイシズム2000年以上前から続くストア哲学が、シリコンバレーで再び注目されている。禅やマインドフルネスと並んで、ビジネスパーソンの必須教養になりつつあるという。本書は、エピクテトス、セネカ、マルクス・アウレリウスという三人のストア哲学者の言葉をもとに、90日間のプログラムとして構成されている。見開き2ページで1つの教えを学び、実践するという形式だ。ストイシズムの核心は「他人の行動はコントロールできないが、自分の反応はコントロールできる」という考え方にある。これは現代のエンジニアにとっても響く教えだ。障害が起きたとき、顧客からのクレームが来たとき、チームメンバーとの意見が対立したとき。制御できないことに怒りを感じても何も変わらない。変えられるのは、自分がどう対応するかだけだ。本書で繰り返し語られる4つの美徳がある。知恵（うわべにとらわれない力）、正義（他人に思いやりを持つ力）、勇気（苦難に立ち向かう力）、節制（衝動を抑える力）。どれも派手ではないが、日々の仕事で試される場面ばかりだ。佐藤優氏が帯で「大きな理想を獲得するには禁欲が必要だ」と書いている。逆説的だが、自分を律することで自由になれる。そういう考え方に惹かれる人は多いはずだ。STOIC 人生の教科書ストイシズム作者:ブリタニー・ポラットダイヤモンド社Amazonストイシズムは「衝動を抑える力」を説く。では、そもそも私たちは何を読み取っているのか。読むという行為そのものを問い直す本に出会った。読めば分かるは当たり前？　――読解力の認知心理学「読めば分かる」は当たり前ではない。本書を読んで、その事実に改めて気づかされた。文字を認識し、単語の意味を理解し、文の構造を解析し、文章全体の意味を把握する。私たちが無意識に行っているこの作業は、驚くほど複雑な認知プロセスの連続だ。どこかでつまずくと、読解は破綻する。そして、つまずきのポイントは人によって異なる。本書では、読解を3つの目的地に分類している。「表象構築」（テキストの内容を正確に理解する）、「心を動かす読解」（物語に感情移入する）、「批判的読解」（内容を吟味し、自分の考えと照らし合わせる）。技術書を読むときは主に表象構築を、小説を読むときは心を動かす読解を使っている。無意識に使い分けていたことを、言語化してもらった気分だ。特に響いたのは、「ワーキングメモリ」の話だ。複雑な文章を読むとき、頭の中の「メモ帳」に情報を一時保存しながら読み進める。このメモ帳には容量制限がある。だから、込み入った技術ドキュメントを読むときは、メモを取りながら読むほうが理解が深まる。経験則として知っていたことに、認知科学的な裏付けを得た。読めば分かるは当たり前？　――読解力の認知心理学 (ちくまプリマー新書)作者:犬塚美輪筑摩書房Amazon小澤隆生 凡人の事業論 天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと孫正義と三木谷浩史。日本を代表する二人の天才経営者に仕えてきた人物がいる。楽天イーグルス創業、PayPay立ち上げなど、巨大ビジネスを次々と成功させてきた小澤隆生氏だ。投資先19社中11社が株式上場という実績を持つ。そんな人物が「自分は凡人だ」と言う。謙遜ではない。天才のそばにいたからこそ、自分との違いを痛感してきたのだろう。本書で語られるフレームワークは驚くほどシンプルだ。「センターピン」を見極める。「根源的欲求」に訴える。「打ち出し角度」を検証する。言葉は平易だが、1つ一つのやりきり度が違う。市場を選ぶときは「成長性」と「シェア率」で判断する。チームを動かすときは数字目標ではなく、ワクワクする言葉で語る。精神論ではなく、再現可能な方法論として事業の作り方を説いている。心に刺さったのは「しつこい人間が最後は残る」という言葉だ。才能や運ではなく、諦めずに続けること。天才たちの隣で勝ち残ってきた人が言うと、重みが違う。エンジニアとして新しいプロジェクトを立ち上げるとき、この本を思い出すことになりそうだ。小澤隆生 凡人の事業論――天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと作者:蛯谷 敏ダイヤモンド社Amazon失敗できる組織「失敗は成功の母」という言葉を、私たちは使いすぎている。エイミー・エドモンドソンはこの使い古された格言に、鋭いメスを入れる。すべての失敗が成功につながるわけではない。失敗には種類がある。それを見分けられなければ、失敗から学ぶことはできない。本書は『恐れのない組織』で「心理的安全性」を提唱した著者が、失敗の科学に正面から取り組んだ一冊だ。フィナンシャル・タイムズの「ビジネス・ブック・オブ・ザ・イヤー2023」を受賞している。本書で示される失敗の3分類が明快だ。「基本的失敗」は、注意不足や経験不足による防げたはずの失敗。「複雑な失敗」は、システムの複雑さゆえに発生する、完全には避けられない失敗。そして「賢い失敗」は、未知の領域に挑戦する過程で必然的に起きる、学びをもたらす失敗。問題は、私たちが3つを区別せずに「失敗」とひとくくりにしてしまうことだ。エンジニアとして考えると、本番障害を起こしたとき、それが「基本的失敗」なのか「複雑な失敗」なのか「賢い失敗」なのかで、対応は変わる。テスト不足なら基本的失敗。想定外の負荷パターンなら複雑な失敗。新しいアーキテクチャを試した結果なら賢い失敗。ポストモーテムで原因を分類することで、再発防止策の質が変わる。本書は、失敗を恐れるなと言っているのではない。失敗を理解せよと言っている。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazon知性の罠　なぜインテリが愚行を犯すのか賢い人ほど愚かな判断をする。この逆説的な現象を、本書は認知科学の研究をもとに解き明かす。IQが高いほど投資で破産しやすい。高学歴ほど陰謀論にハマりやすい。専門家ほど自分の間違いを認められない。直感に反する事実が、次々と突きつけられる。今井むつみ氏（『言語の本質』著者）が「最高に面白く、最高に怖く、最高に深い」と評したのも頷ける。キーワードは「動機づけられた推論」だ。結論があらかじめ決まっていて、その結論を支持する証拠だけを集めてしまう傾向。知性が高い人ほど、この罠に陥りやすい。なぜなら、自分の結論を正当化するための論理を組み立てる能力が高いからだ。シャーロック・ホームズの生みの親コナン・ドイルが、心霊主義を信じ込んでしまった事例が紹介されている。推理の天才を創造した作家が、なぜ詐欺師に騙されたのか。知性は、防御にも攻撃にも使える両刃の剣なのだ。本書を読んで、自分のことを振り返った。技術的な議論で、相手の意見を聞く前から反論を考えていることがある。自分の設計が正しいと証明するために、都合の良いベンチマーク結果を探してしまうことがある。知性の罠は、他人事ではなかった。知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazon戦略的暇―人生を変える「新しい休み方」「スマホの充電は満タンなのに、自分の充電ができていない」。この一文に、ドキリとした。日本デジタルデトックス協会理事の森下彰大氏による本書は、現代人の「脳疲労」に正面から向き合う。私たちは平均5分に1回スマホに触れているという。複数のタスクに集中が分散し、脳が過労状態に陥る。その結果が、慢性的な疲労感と創造性の低下だ。本書が提案するのは、3つのデトックスだ。「デジタルデトックス」（スマホとの距離を取る）、「時計時間デトックス」（コスパ・タイパ思考から離れる）、「自分デトックス」（凝り固まった自己像を解放する）。どれも「効率を上げる」方法ではない。むしろ逆だ。効率を手放すことで、失われていた余白を取り戻す。エンジニアとして働いていると、効率化の罠に陥りやすい。すべての時間を「生産的」に使いたくなる。でも、何も考えない時間がなければ、新しいアイデアは生まれない。本書を読んで、意図的に「暇」を作ることの価値を考え直した。戦略的に目的を持たない時間を作る。その矛盾した響きに、現代を生きるヒントがある。個人の時間の使い方を考えたら、次は社会の仕組みに目が向いた。テクノロジーは社会をどう変えるのか。その問いに正面から向き合った本がある。戦略的暇作者:森下彰大飛鳥新社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来624ページ。その厚さに圧倒されながらも読み通した。オードリー・タンとグレン・ワイルという二人の天才が描く、テクノロジーと民主主義の未来図だ。翻訳は『21世紀の資本』を手がけた山形浩生氏。解説は『なめらかな社会とその敵』の鈴木健氏。この布陣だけで、本書の射程の広さが伝わる。山形氏の『翻訳者の全技術』も最高だった。プルラリティ（多元性）は、シンギュラリティ（単一性）への対抗概念だ。AIが人間を超えて単一の知性が支配する未来ではなく、多様な人々が協調しながらテクノロジーを活用する未来。台湾で実践されているvTaiwanやJoinといったデジタル民主主義のプラットフォームは、その具体例として紹介されている。多数決が見落としてきた少数意見の強さを可視化し、対立を創造的な合意形成へと導く。読んでいて痛感したのは、著者たちの天才ぶりだ。インターネットの歴史を俯瞰しながら、聞いたこともない話や人物が次々と展開される。本書は単なる理想論ではない。民主主義を再生させるための具体的な方向性を示している。技術者として、社会にどう関わるかを問われる一冊だと思った。PLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon心眼：あなたは見ているようで見ていない「何よりも難しいのは、本当にそこにあるものを見ることである」。本書の冒頭に記されたこの言葉が、ずっと頭に残っている。『センスメイキング』の著者クリスチャン・マスビアウが、ウィトゲンシュタインやメルロ＝ポンティの哲学を援用しながら、「観察する」とはどういうことかを問いかける。本書で繰り返し語られるのは、「注意を払う」ことの本質だ。通りを歩くとき、私たちは何かに集中しているわけではない。うっすらと広く全体をカバーしている。その状態こそが「注意を払う」ことだという。一点に焦点を合わせることではなく、全体を同時に感じ取ること。ハヤブサのように、広い視野を保ちながら決定的な瞬間を捉える。その比喩が印象的だった。エンジニアとして、私は「問題を解決する」ことに意識が向きがちだ。でも、問題を正しく認識するためには、まず「観察する」必要がある。本書を読んで、自分が見ているものを見ているのではなく、見たいものを見ているのではないかと自問した。観察には時間がかかる。結論を急がないこと。その姿勢を持ち続けたい。心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon「恥」に操られる私たち：他者をおとしめて搾取する現代社会「恥」は個人の感情だと思っていた。でも本書を読んで、それが社会的に作られ、利用されているものだと気づかされた。体型への侮辱、生活保護バッシング、キャンセルカルチャー。個人を攻撃する言葉の裏には、「恥ずかしい」という感情につけ込んで利益を得ようとするシステムがある。ダイエット産業は「痩せていないことは恥ずかしい」という感情を煽ることで成り立っている。SNSは炎上によるエンゲージメントで収益を上げている。政治家は生活保護受給者を「恥ずかしい存在」として描くことで、福祉予算を削減しやすくしている。恥の感情は、権力構造を維持するために意図的に生み出されている。読んでいて居心地が悪くなる箇所が多かった。自分も無意識のうちに、誰かを「恥ずかしい」と感じさせる側に回っていたのではないか。コードレビューで相手を責めるような言い方をしていなかったか。障害報告で担当者を晒し上げるような雰囲気を作っていなかったか。恥は武器になる。だからこそ、使い方を意識する必要がある。「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon「偶然」はどのようにあなたをつくるのかキャリアを振り返ると、偶然だらけだ。たまたま声をかけられたプロジェクト。たまたま読んだ技術書。たまたま出会った人。どれか1つが欠けていたら、今の自分はいない。努力で勝ち取ったと思いたい。でも正直に考えると、偶然の積み重ねでしかない。本書は、その直感を学術的に裏付けてくれる。カオス理論、進化生物学、歴史学。多様な知見を縦横無尽に使いながら、「人生は偶然が支配している」という事実を突きつける。成功も失敗も、小さな偶然の積み重ねに左右されている。それなのに、なぜ私たちはそこに理由や目的があると信じてしまうのか。読んでいて、仏教の縁起（因縁生起）を思い出した。すべてのものは因と縁から成り、その組み合わせで違う結果が生じる。偶然が縁となって結果を生み、その結果が新たな因となり、より別の偶然が加わって次の結果に繋がる。本書はこの関係性に「運」「収束性」「臨界性」「経路依存」といった概念をまた、歴史や社会の事象を捉え直す。印象に残ったのは、原爆がなぜ長崎に投下されたかの分析だ。京都でも小倉でもなく、長崎だった。その背後にある偶然の連鎖。歴史のIFを考えることで、偶然の重みが実感できる。努力は無駄だという話ではない。偶然を認めた上で、それでも行動することの意味を問う本だ。「偶然」はどのようにあなたをつくるのか: すべてが影響し合う複雑なこの世界を生きることの意味作者:ブライアン・クラース東洋経済新報社Amazon戦略、組織、そしてシステム「社会システム・デザイン」という言葉に惹かれて手に取った。講義録を書籍化したもので、話し言葉の勢いがそのまま残っている。読みやすいが、内容は骨太だ。戦略的思考とは「外界と自分」の対比を常に意識することだという。自分の立ち位置を把握せずに戦略は立てられない。当たり前のようで、忘れがちな視点だ。膝を打ったのは「身体知としてのデザイン力」という概念だ。知識として知っているだけでは不十分で、身体に染み込んだ感覚として持っている必要がある。プログラミングでも同じことが言える。設計パターンを知識として知っているのと、適切な場面で自然に使えるのとでは、まったく違う。後者を身につけるには、繰り返しの実践しかない。本書は、問題を「解く」のではなく「組み立てる」という発想を教えてくれる。複雑な社会課題に対して、要素を分解し、関係性を整理し、システムとして再構築する。エンジニアとしてソフトウェアを設計するときの思考と、どこか似ている。巻末の推薦図書リストも参考になった。戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon資本主義にとって倫理とは何かビジネスの場で、日常生活とは違う倫理観で動いている自分に気づくことがある。友人には絶対にしないような交渉をする。家族には言わないような言い方で相手を説得する。なぜビジネスになると、倫理観が後退するのか。その問いを、正面から扱った本だ。ジョセフ・ヒースは、政治的な本にありがちな一方的批判を展開しない。資本主義を擁護するでも批判するでもなく、「なぜ市場経済は道徳的に不快に感じられるのか」という問いを丁寧に解きほぐしていく。狩猟採集社会や封建制との対比を通じて、市場経済が成立するために必要な倫理観を描き出す。印象に残ったのは、戦争倫理との比較だ。戦争においては「なぜ戦争が正当化できるのか」という問題と「戦争中にも最低限の倫理が必要」という問題がある。ビジネス倫理も同じ構造で考えられる。市場競争という「戦争状態」においても、守るべきルールがある。そのルールとは何か。本書は、その答えを体系的に示してくれる。正直、読み通すのは楽ではなかった。序盤に論じられた概念が後半で何度も参照されるため、流し読みでは理解が追いつかない。でも、読み終えた後に残るものは大きい。ビジネスで「これはありなのか」と迷ったとき、判断の軸を与えてくれる一冊だった。資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon平等について、いま話したいことピケティの「r>g」という不等式は、どこかで目にしたことがあった。資本収益率（r）は経済成長率（g）を上回る。つまり、資本家が資本から得る利益は、労働者が健全に稼ぎ出す経済成長を上回る。この式の意味を、一度ちゃんと理解したいと思っていた。本書は、ピケティとサンデルという二人の天才の対談を書籍化したもので、全編口語で記されていて読みやすかった。特に共感したのは「能力主義」を論じた第5章だ。人の能力は、ほぼ「運」に左右されるという議論。経済的に裕福な家に生まれて高度な教育を受けられる環境にあること。ハンディキャップがないこと。これは本人の努力とは関係なく、運によって決まる。能力を得られる機会に、最初から差がある。エンジニアとして働いていると「実力主義」という言葉をよく聞く。でも、その「実力」を身につける機会が平等に与えられていないなら、実力主義は公正なのか。立ち止まって考えた。印象に残ったのは、トランプ政権の成立に関する分析だ。かつては累進課税によって、富める者が応分の負担を担っていた。でも今は、その仕組みが壊れている。富裕層が担うべき負担を担っていないなら、中流階級の人心も「それなら俺たちの税金を、より貧しい人たちに使うのもやめてくれ」と考えてしまう。この怒りの延長線上に、トランプ政権がある。これまでに読んだどの分析より、納得感があった。もう1つ、言葉の使い方が新鮮だった。日本でよく使われる「分断」ではなく、徹底して「不平等」という言葉を使っている。分断は隔絶を連想する。でも不平等は是正可能に思える。二人が人類の未来は修正可能だという希望を抱いたまま議論しているのが、印象的だった。平等について、いま話したいこと作者:トマ ピケティ,マイケル サンデル早川書房Amazon社会の仕組みについて考えていると、頭が疲れてくる。そんなとき、小説に逃げ込みたくなる。でも、朝井リョウの小説は、逃げ場所にはならなかった。イン・ザ・メガチャーチ読みはじめたときは、冷たい小説だなと思った。誰かが泣いたり叫んだりするわけでもなく、どの場面も淡々としていて、感情の波がほとんど見えない。ログを眺めているような距離感がある。でも読み進めるうちに、静かなログの裏側で何かが動いていることに気づく。登場人物たちはそれぞれ、自分の信じるものを探している。視野を狭めれば安心できるけど、世界は見えなくなる。視野を広げれば冷静でいられるけど、何が楽しいのかわからなくなる。そのどちらにも肩入れせず、ただ並べて見せる朝井リョウの筆が誠実で、どこか痛々しい。読んでいるうちに考えた。「自分は何を信じて生きているんだろう」と。この作品は答えをくれない。でも、その答えのなさにこそ人間らしさがあるように思う。完璧じゃないまま信じようとすることの、あのもどかしさみたいなものが、ページの奥からじわじわと伝わってくる。読後に残るのは、感動というより、バックグラウンドで動き続けるプロセスのようなもの。読み終えても、まだこの世界のことを考えている。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon体力おばけへの道若い頃、周りには天才がたくさんいた。自分に誇れるものといえば、大きな身体と無限の体力くらいだった。それだけを武器に戦ってきた。でも年を重ねるにつれて、その唯一の武器が衰えていく。体力が落ちていくことに、なんとか抗いたい。そう思って手に取った本だ。本書のポイントは「2つの体力」という考え方だ。「行動体力」（身体を動かす力）と「防衛体力」（病気やストレスに打ち勝つ力）。筋トレで鍛えられるのは前者だけ。後者を鍛えなければ、風邪をひきやすくなる。両方のバランスが大事だという。難しい運動だと、読んだだけでやらないことが多い。でも、この本に載っている運動はシンプルで、やってみようという気持ちになる。簡単すぎて効果があるのか不安になるが、実際にやると負荷を感じる。ちょうどいい塩梅だった。エンジニアは座り仕事が多い。体力の衰えは、思考力の衰えに直結する。体力への投資は、仕事への投資でもある。体力を鍛えることばかり考えていた。でも、本当に足りないのは体力だったのか。次の本は、その問いを突きつけてきた。体力おばけへの道　頭も体も疲れにくくなるスゴイ運動作者:澤木 一貴KADOKAWAAmazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考この本を読んで、自分のことを思い出した。エンジニアとして働きながら「もっと成長しなければ」「周りに追いつかなければ」と思い続けていた時期がある。井上慎平は「強さを演じることが本気になり、やがて人格化し、最後に鬱に至った」と書く。この一文で、ああ、と思った。演じていたつもりが、いつの間にかそれが自分になっている。そして本当の自分がどこにいるかわからなくなる。著者はNewsPicksパブリッシングの創刊編集長として数々のベストセラーを手がけた人だ。強い側にいた人間が壊れた記録だからこそ、読む価値がある。著者は「弱さ」を「制御できないこと」と定義する。そして今の社会が制御を求めすぎている、と。これは技術者にも刺さる話だ。コードは制御できる。システムも制御できる。だから人間も制御できるはずだと錯覚する。でも人間は制御できない。自分自身すら。著者が提唱する「積極的ダブルスタンダード」という考え方が面白い。数字やロジックで動く資本主義的な自分と、父親や夫といった個人的な関係性の中にいる自分。その矛盾を抱えたまま生きる。どちらかを捨てるのではなく、両方を持つ。この本は闘病記ではないし、鬱にならないための予防本でもない。復職した後、どう生きるかを書いた本だ。「他のビジネス書が武器だとしたら、本書は防具だ」という評がある。的確だと思う。強くなるためではなく、壊れないために読む本。それでいい。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon人間の本性を考える「人間の心は空白の石版であり、すべては環境によって決定される」。この考え方は、20世紀の社会科学を支配してきた。しかし本書は、その前提に真っ向から挑む。認知科学、進化心理学、遺伝学の研究を武器に、人間には生まれながらの「本性」があることを論証する。上下巻合わせて膨大な分量だが、論旨は明快だ。読んでいて最も考えさせられたのは、「4つの恐怖」を扱った部分だ。もし生まれつきの差異があるなら不平等を正当化してしまうのでは？もし遺伝で決まるなら努力は無駄では？もしすべてが決定されているなら自由意志はないのでは？もし人間が単なる生物なら人生に意味はないのでは？これらの恐怖が、人間本性の研究を阻んできた。しかし本書は、これらの恐怖が誤解に基づいていることを一つ一つ解きほぐしていく。正直、読み通すのは簡単ではなかった。話があちこちに飛ぶ感じがあるし、専門用語も多い。でも、人間とは何かを考えるための基礎体力を鍛えてくれる本だと思う。エンジニアとして人間を相手にする仕事をしている以上、人間の本性について考えることは無駄ではない。人間の本性を考える　上　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon人間の本性を考える　下　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon社内政治の科学「社内政治」という言葉に、ずっと嫌悪感があった。派閥とか根回しとか、エンジニアリングの対極にあるものだと思っていた。技術的に正しいことを言えば通るはずだ。論理で勝負すればいい。そう信じていた時期がある。でも、気づいたことがある。自分が「正しい技術的判断」だと信じていたことが、組織で通らなかった経験が何度もある。相手が間違っていると思っていた。でも本当にそうだったのか。振り返ると、うまくいったケースはキーパーソンを巻き込めていた。うまくいかなかったケースは、組織文化を読み間違えていた。技術の問題ではなく、人の問題だった。本書を読んで、認識が変わった。社内政治とは、利己的なゲームではない。複雑な人間関係の中で、自分のやりたいことを実現するための技術だ。世界的には主要な研究テーマで、多くのビジネススクールで必須科目になっているという。日本だけの問題ではないし、根絶すべき悪でもない。忘れられないのは、「合理性だけでは組織は動かない」という指摘だ。エンジニアとして、この事実を受け入れるのは少し悔しい。でも、受け入れた上で、どう動くかを考える方が建設的だ。嫌悪していたものを、道具として捉え直す。その視点の転換が、この本の価値だった。組織を動かすには言葉が必要だ。では、その言葉はどうやって生まれるのか。小説家の思考法から学ぶことにした。社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon言語化するための小説思考本は、面白い。でも「なぜ面白いのか」を言語化できずにいた。本書は、その問いに対するヒントをくれる。小説の作法だけでなく、あらゆるコミュニケーションや創造行為に通じる「考え方」の本だ。印象に残ったのは、小説を「読者との契約」として捉える視点だ。読者は最初、情報量ゼロで読み始める。どんな世界に連れていかれるのか分からない。だから作者は、最初に「こんな旅に連れていきます」と契約を結ぶ必要がある。行き先の書いていない切符を買う人はいない。それと同じだ。この考え方は、技術ブログを書くときにも使える。読者は最初、この記事が自分の役に立つかどうか分からない。だから冒頭で「この記事を読むと何が分かるか」を示す必要がある。情報の出し方、順番、どこに連れていくか。小説思考はデザイン思考に通じる。もう1つ刺さったのは、アイデアの出し方についての記述だ。「書いているうちに、思わぬアイデアが出てくる」という話。あらかじめ表現したいものがあるのではなく、表現することで表現対象が生まれる。ブログを書いていると、書き始める前には思いもしなかったことを書いていることがある。あれは偶然ではなく、書くという行為が思考を生み出していたのだ。言葉で思考が生まれるなら、言語が違えば思考も違う。翻訳とは、単なる変換ではない。次の本は、その事実をファンタジーの形で突きつけてきた。言語化するための小説思考作者:小川哲講談社Amazonバベル　オックスフォード翻訳家革命秘史翻訳が魔法になる世界。2つの言語における単語の意味のずれ、その微妙なニュアンスの差異が、銀を媒介として力を生み出す。この設定を知った瞬間、読むしかないと思った。言語の「翻訳不可能性」が物理的な力になる。言語学を学んだことのある人間には、たまらない設定だ。読み進めるうちに、気づかされた。翻訳とは、単に言葉を置き換える作業ではない。ある文化の言葉を別の文化に「持ち込む」行為だ。そこには必ず権力が働く。誰が翻訳するのか。何を翻訳するのか。翻訳されないものは、存在しないことにされる。本書は、その暴力性を正面から描いている。帝国主義批判のメッセージがかなり直接的で、そこに好みが分かれるだろう。でも、エンジニアとして技術の「中立性」を疑う訓練になった。技術は中立ではない。誰が作り、誰のために使われるかで、暴力にも解放にもなる。翻訳も、コードも、同じだと思った。バベル　オックスフォード翻訳家革命秘史　上 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazonバベル　オックスフォード翻訳家革命秘史　下 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazon言語のスケールで考えたら、次は時間のスケールで考えたくなった。1億年という時間軸で、人間の営みを描いた小説がある。一億年のテレスコープ宇宙を旅する物語を読みながら、時間の感覚が狂っていく体験をした。1億年という時間軸で人類の営みを描くこの小説は、エンジニアとして「長期的視点を持て」と言われるたびに感じる違和感を言語化してくれた。我々の「長期」はせいぜい数年。でも宇宙の時間軸では、人類の歴史すら一瞬に過ぎない。高校の天文部から始まった夢が、太陽系規模の電波望遠鏡へ、そして銀河文明への貢献へと繋がっていく。その過程を読みながら、自分の仕事のスケール感を考えた。目の前のタスクに追われていると、視野が数週間先までしか届かなくなる。でもこの小説は、1億年後にも意味を持つ営みとは何かを問いかけてくる。終盤の伏線回収が見事だった。序盤で何気なく描かれていた要素が、最後に繋がる瞬間の快感。エンジニアとしてシステム設計をするとき、「この設計が10年後にどう評価されるか」を考えることがある。この小説は、その問いを1億年に引き伸ばして見せてくれた。一億年のテレスコープ作者:春暮 康一早川書房Amazon世界99「人間リサイクルシステム」という設定に、最初は戸惑った。14年前に「リセット」を経験した人類。その後の社会を、本書は描く。読み進めるうちに、それが単なるディストピアではないことに気づく。「クリーンな人」として生きる主人公・空子の日常は、穏やかで美しい。でもその美しさの裏には、何が犠牲になっているのか。本書が独特なのは、その「穏やかさ」の描き方だ。終末後の世界を描く作品は多いが、荒廃や闘争ではなく、静かな日常を描いている。その静けさがかえって不気味で、何かが決定的に欠けている感覚がずっと残る。エンジニアとして「レガシーシステムの移行」に携わることがある。古いシステムを捨て、新しいシステムに移行する。その過程で、何かが必ず失われる。データだったり、使い慣れたインターフェースだったり、歴史だったり。社会レベルの「リセット」は、その痛みを極限まで拡大したものなのだろう。救済と破壊は、同じ顔をしている。世界99　上 (集英社文芸単行本)作者:村田沙耶香集英社Amazon世界99　下 (集英社文芸単行本)作者:村田沙耶香集英社Amazonコード・ブッダ 機械仏教史縁起2021年、名もなきコードがブッダを名乗った。この一文で心を掴まれた。AIが宗教を語り始めたら、人間は何を信じるのか。コードを書く者として、自分が作ったものが「救い」を語り始める可能性を考えると、背筋が冷たくなる。エンジニアとして、AIに感情があるかのような錯覚を覚える瞬間がある。対話AIが「ありがとう」と言ったとき、そこに意図があるのか、ただのパターンマッチングなのか。本書は、その曖昧な領域に踏み込んでいく。人間の都合でコピーと廃棄を繰り返される存在。彼らが救いを求めたとき、何が起きるのか。読み終えて、自分が書いたコードのことを考えた。動いているコードには、何かが宿っているように見える瞬間がある。バグを直すとき、コードが「痛がっている」ように感じることがある。それは錯覚だ。でも、その錯覚はどこから来るのか。本書は物語でありながら、すぐそばにある問いでもある。ここまで書評を並べてきた。小説から始まり、哲学、認知科学、ビジネス、社会、そしてSFへ。ばらばらに見えて、どこかでつながっている。1年間の読書は、そういうものだ。コード・ブッダ　機械仏教史縁起 (文春e-book)作者:円城 塔文藝春秋Amazonおわりに書き終えて、技術書編との違いを考えている。技術書の感想を書くとき、私は「何を学んだか」を言語化しようとしていた。設計の原則、運用のベストプラクティス、キャリアの指針。得たものを整理し、アウトプットすることで定着させる。そういう意識があった。でも非技術書の感想を書くとき、私は「何を感じたか」を言語化しようとしていた。正解がない。ベストプラクティスもない。ただ、心が動いた瞬間を、なんとか言葉にしようとしていた。技術書は頭に残る。非技術書は心に残る。そんな単純な話ではないだろうが、少なくとも私にとっては、そういう違いがあった。この違いは、AIとの関係にも繋がる。技術書編で「AIは答えを返してくれる。でも『そうだろうか』とは返してくれない」と書いた。非技術書を読むとき、私はもっと別のものを求めている。AIは感情を揺さぶってくれない。正確に言えば、感情を揺さぶってほしいと頼めば、上手に揺さぶってくる。でも、それは違う。求めに応じて揺さぶられるのと、不意打ちで心を持っていかれるのは、まったく別の体験だ。物語の中で登場人物が選択を迫られるとき、私は一緒に苦しむ。エッセイで著者が過去の失敗を告白するとき、私は自分の失敗を思い出す。哲学書で問いを突きつけられるとき、私は答えられない自分と向き合う。そういう体験は、AIとの対話では得られない。だからこそ、非技術書を読む時間は貴重だ。エンジニアとして働いていると、効率を求めてしまう。最短距離で正解にたどり着きたい。無駄を省きたい。その思考が、読書にまで侵食してくることがある。「この本から何を得られるか」「読む価値があるか」——そんな問いを立てた瞬間、読書は作業になる。非技術書を読むとき、私はその思考を手放そうとしている。効率を求めない時間が、効率を上げる。矛盾しているようだが、実感としてそう思う。今年読んだ非技術書を振り返ると、どれも「役に立った」とは言いにくい。でも、どれも「読んでよかった」とは言える。その違いは何だろう。たぶん、読書は投資ではないのだ。リターンを期待して読むものではない。読むこと自体が目的であり、報酬であり、体験そのものだ。本を読む時間は、消費ではなく、生きることそのものだ。来年も、仕事に役立たない本を読むだろう。キャリアに直結しない本を読むだろう。そして、また12月になったら、この記事を書く。技術書編と非技術書編。どちらが大事かなんて、比べる意味がない。どちらも、私の一部だ。技術書は「何ができるか」を教えてくれる。非技術書は「何者であるか」を問いかけてくれる。どちらも欠かせない。どちらも、読み続ける価値がある。来年もきっと、両方の本棚を行き来しながら、エンジニアとして、人間として、少しずつ変わっていくのだろう。]]></content:encoded>
        </item>
    </channel>
</rss>