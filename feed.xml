<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 16 Dec 2025 06:42:37 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[地球規模の「時間のずれ」を Cloud Spanner はどう解決したか]]></title>
            <link>https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</link>
            <guid isPermaLink="false">https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</guid>
            <pubDate>Tue, 16 Dec 2025 01:39:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake 事業部の芳賀雅樹 (@silasolla) です．普段はアプリケーションの開発支援を担当していますが，今回はその基盤となるデータベースの裏側の仕組みが気になり，深掘りしてみました． 早速ですが，G […]The post 地球規模の「時間のずれ」を Cloud Spanner はどう解決したか first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代の異常系テストについて考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</guid>
            <pubDate>Tue, 16 Dec 2025 01:22:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに深夜2時、本番環境のアラートが鳴り響きます。外部APIがタイムアウトを返し始め、リトライが暴発し、システム全体が連鎖的に停止しました。原因を調べると、外部サービスの一時的な遅延でした。たった数秒の遅延が、なぜシステム全体を止めたのか。答えは単純です。「外部APIが遅延したらどうなるか」を、誰もテストしていなかったからです。私自身、このような障害を何度か経験してきました。コードをマージした翌朝にSlackが炎上していたこともあります。「なぜこのケースを考えなかったのか」と自分を責めながら、ホットフィックスを書いた夜もあります。そのたびに思います。あのとき、たった1つのテストを書いていれば。これは「異常系テスト」の不足が引き起こした障害です。正常系のテストは比較的書きやすいです。入力があり、期待する出力があり、それを検証します。しかし、プロダクション環境で本当に問題になるのは異常系です。ネットワークが切断されたとき、システムはどう振る舞うべきか。データベースがタイムアウトしたとき、ユーザーには何を伝えるべきか。想定外の入力が来たとき、エラーメッセージは適切か。こうした問いに答えるのが、異常系テストです。そして今、この異常系テストの世界が大きく変わりつつあります。2024年、AIがOpenSSLに20年間潜伏していた脆弱性を発見しました。人間が書いたファジング（ランダムなデータを入力してバグを探す手法）では見つけられなかった欠陥です。Google OSS-FuzzはAIによるファズターゲット生成で26件の脆弱性を発見し、既存の人間作成ターゲットから最大29%のカバレッジ向上を実現しました。人間だけでは見つけられなかった異常を、AIが発見する時代になりました。本記事では、この変化を踏まえて異常系テストの考え方をまとめました。まず基本的な技法を押さえ、その上でAIやカオスエンジニアリングといったものを紹介します。あの深夜のアラートを、未来の自分や読者が経験しなくて済むように。本題に入る前に本記事を読む前に、いくつか断っておきたいことがあります。私はテストの専門家ではありません。日々コードを書きながら、「この処理が失敗したらどうなるだろう」と考える、一人のエンジニアです。ここに書いてあることは、思いついたものをまとめただけなので不足もあるでしょう。実装しながら単体テストやエラーハンドリングを考える際のヒントとして使ってもらえればと思います。もう一つ、大事なことがあります。すべてのパターンをテストする必要はありません。過度なテストパターンは無駄な工数を生むだけではありません。テストが増えれば増えるほどCIの実行時間は長くなり、開発サイクルは遅くなります。テストコードを読んで理解するにも認知コストがかかります。テストが多すぎると、「このテストは何を確認しているのか」を把握するだけで疲弊してしまいます。テストのROI（投資対効果）を意識し、リスクの高い箇所に集中することが重要です。とはいえ、最近は生成AIのモデル精度が上がったおかげで、文脈を読み取ってテストコードを生成してくれるようになりました。「何をテストすべきか」を判断し、AIに生成を任せる。その使い分けが、今のエンジニアに求められています。そして、ここが難しいところなのですが、異常系テストがどれくらい必要かは、その人の経験に大きく依存します。本番障害で痛い目を見た人は「ここまでテストすべきだ」と感じます。幸運にも大きな障害を経験していない人は「そこまでやる必要があるのか」と思います。これは良い悪いではなく、思考の枠組みそのものが異なるのです。だからこそ、チームとして、組織として「どこまでの異常を許容するのか」を明確にしておく必要があります。暗黙の了解ではなく、言語化する。そうしないと、「テストが多すぎる」「テストが足りない」という不毛な議論が続くことになります。では、本題に入りましょう。異常系テストとは異常系テストとは、システムが想定外の状況に遭遇したとき、適切にエラーハンドリングできるかを検証するテストです。正常系テストが「うまくいくパス」を確認するのに対し、異常系テストは「うまくいかないパス」を確認します。異常系と一口に言っても、その原因はさまざまです。「どこから異常が来るか」という視点で整理すると、4つの観点に分けられます。入力値の異常: ユーザーやクライアントから来ます。空文字、境界値超過、不正な形式など状態の異常: システム内部のデータに起因します。リソースが見つからない、すでに処理済み、権限不足など環境の異常: 外部依存に起因します。ネットワーク障害、DB接続失敗、ディスク容量不足など競合の異常: 並行処理に起因します。同時更新、デッドロック、レースコンディションなどこの順番には意味があります。入力値の異常は最も頻繁に発生し、テストも書きやすいです。状態の異常はビジネスロジックと密接に関わります。環境の異常はテストが難しいですが、本番では必ず起きます。競合の異常は最も見つけにくく、再現も難しいです。つまり、テストの書きやすさと、問題の発見しにくさは、おおむね逆の関係にあります。それぞれについて見ていきましょう。入力値の異常フォームに全角スペースだけを入力して送信したら、システムがエラーを吐いた。そんな経験はないでしょうか。あるいは、絵文字を含む名前を登録しようとしたら、データベースエラーが返ってきた。ユーザーは悪意を持っていたわけではありません。ただ、開発者が「想定していなかった」だけです。どれだけ想像力を働かせても、ユーザーは必ずその想像の外側から来ます。ユーザーからの入力は信用できません。これはセキュリティの基本原則ですが、テストにおいても同様です。境界値分析（Boundary Value Analysis）境界値分析は、ソフトウェアテストの古典的な技法です。入力値の境界付近でエラーが発生しやすいという経験則に基づいています。# 例: 文字数制限が255文字の場合- 255文字 → 成功するべき- 256文字 → エラーになるべき- 0文字（空文字） → 要件によるよくある境界値のテストケース：最大値・最小値最大値+1・最小値-1ゼロ負の値（許可されていない場合）この技法は同値分割法（Equivalence Partitioning）と組み合わせて使うことが多いです。同値分割法では、入力値を「同じ振る舞いをするグループ」に分割し、各グループから代表値を選んでテストします。たとえば「1〜255文字」「256文字以上」「0文字」の3グループに分け、それぞれの代表値と境界値をテストします。現代のAPI開発では、境界値分析の対象は数値入力を超えて拡張されています。APIのページネーション制限（page size=99, 100, 101）、リクエストペイロードサイズ制限、タイムアウト閾値、レートリミットの境界などが現代的なBVA対象です。空値の扱い境界値の中でも、特に扱いが難しいのが「空」という概念です。空値の扱いは設計上の判断が必要になります。 値  検討ポイント  空文字 ""  許容するか、エラーにするか  スペースのみ "   "  トリムするか、エラーにするか  NULL  必須項目か、オプショナルか  undefined  デフォルト値を使うか テストを書くことで、こうした設計の曖昧さが明確になることがあります。「空文字を許容するか」という問いに対して、チームで合意を取る機会になります。ここで気づくべき重要なことがあります。異常系テストの気付きにくい価値は、バグを見つけることではありません。設計を問い直すことです。「この入力が来たらどうするか」という問いを立てることで、仕様の穴が見えます。テストを書く行為そのものが、システムの堅牢性を高めています。テストが通るかどうかは、実は二次的な問題なのです。文字種と特殊文字空値に続いて、もう一つ厄介なのが文字種です。日本語を扱うシステムでは、文字種のテストが特に重要になります。カタカナ・半角カタカナ環境依存文字（㈱、①など）サロゲートペア（𠮷野家の「𠮷」など）絵文字これらの文字が入力されたとき、システムがどう振る舞うかを確認します。データベースの文字コード設定やAPIのエンコーディングによっては、予期しない動作をすることがあります。セキュリティ関連の入力ここまでは「意図しない入力」の話でした。しかし、世の中には「意図的に悪意のある入力」を送りつけてくる人もいます。セキュリティ関連の入力値テストは、インジェクション攻撃（悪意のあるコードを入力に紛れ込ませる攻撃）への耐性を確認します。OWASP Testing Guideは、このようなセキュリティテストの標準的な指針を提供しています。XSS（クロスサイトスクリプティング）: <script>alert('XSS')</script> — Webページに悪意のあるスクリプトを埋め込む攻撃SQLインジェクション: '; DROP TABLE users;-- — データベースを不正に操作する攻撃コマンドインジェクション: ; rm -rf / — サーバーで不正なコマンドを実行させる攻撃パストラバーサル: ../../../etc/passwd — 本来アクセスできないファイルを読み取る攻撃インジェクション攻撃への対策はセキュリティテストの領域でもありますが、異常系テストとして「不正な入力が来たときにシステムが適切にエラーを返すか」を確認しておくことは重要です。エラー推測（Error Guessing）という経験ベースの技法も有効です。過去のバグ傾向から共通パターン（NullPointerException、ゼロ除算、日時パース問題など）を識別し、重点的にテストします。AIとファジングによる入力値テストここまで紹介した技法は、人間がテストケースを考えるものでした。しかし、人間の想像力には限界があります。そこで注目されているのが、ランダムな入力を自動生成してバグを探すファジング（Fuzzing）です。冒頭で触れたGoogle OSS-FuzzのAI活用は、まさにこの領域での成果です。AIが生成したファズターゲットにより26件の脆弱性が発見され、OpenSSLに20年間潜伏していた欠陥も見つかりました。人間が「こういう入力が来るかも」と想像する範囲を超えて、AIが異常な入力パターンを生成します。www.theregister.comもう一つ、Property-based testing（性質ベーステスト）という手法も企業での採用が加速しています。従来のテストは「入力Aに対して出力Bが返る」という具体的なペアを書きます。Property-based testingでは「どんな入力に対しても、この性質が成り立つ」という形で定義します。たとえば「リストをソートして逆順にしても、要素数は変わらない」といった性質です。Python向けのHypothesisは週間300万ダウンロードを超え、numpyやastropyなどの科学ライブラリでバグを発見した実績があります。QuickCheck（Haskell）、fast-check（JavaScript）、proptest（Rust）など、各言語でエコシステムが成熟しています。入力値の異常は、ユーザーから直接来るものでした。次に見るのは、システムの内部で起きる異常です。状態の異常「さっきまで動いていたのに」。この言葉に覚えはないでしょうか。ユーザーが画面を開いている間に、別のユーザーがデータを削除します。システムの状態は常に変化しています。画面に表示された瞬間、それはもう過去です。リソースの状態に関するテストでは、以下のようなケースを考慮します。存在しないリソース存在しないIDでアクセスしたときに、適切なエラー（404 Not Foundなど）が返ることを確認します。削除済みリソース削除されたリソースに再度アクセスしたときの動作を確認します。ユーザーがブックマークしていたページが、管理者によって削除されていた。よくある話です。「404 Not Found」で終わりなのか、「このコンテンツは削除されました」と丁寧に伝えるのか。論理削除と物理削除では挙動が異なります。論理削除なら「削除済み」というステータスを返せます。物理削除ならレコード自体が存在しないため、404を返すことになります。どちらの設計を採用しているかで、テストの期待値も変わります。処理中のリソース処理中（アップロード中、変換中など）のリソースにアクセスしたときの動作を確認します。「まだ準備ができていない」ことをクライアントに適切に伝えられるか。不正な状態遷移状態遷移が定義されているシステムでは、不正な遷移を試みたときの動作を確認します。# 例: 注文のステータス遷移作成 → 確定 → 発送 → 完了# 不正な遷移作成 → 完了（確定と発送をスキップ）完了 → 作成（逆方向の遷移）入力値の異常、状態の異常は、どちらもアプリケーション内部の話でした。しかし、システムは単独で動いているわけではありません。次は、システムの外側から来る異常を見ていきます。環境の異常環境の異常は、テストが最も難しい領域です。開発環境では再現しにくいですが、プロダクション環境では必ず発生します。ローカルで動いたからといって、本番で動く保証はありません。開発環境は、ある意味で嘘をつきます。ネットワークは常に安定し、データベースは常に応答し、ディスクは無限にあります。そんな理想的な環境でテストしても、現実の障害には備えられません。だからこそ、どういう異常が起こりうるかを知っておくことが重要です。近年ではChaos Engineering（カオスエンジニアリング）という手法が注目されています。Netflixが提唱したこのアプローチでは、本番環境に意図的に障害を注入し、システムの回復力を検証します。AWS Fault Injection ServiceやAzure Chaos Studioといったクラウドサービスも登場しています。これは上級者向けの手法ですが、まずは以下のような基本的な異常パターンを理解しておきましょう。ネットワーク障害通信経路の遮断タイムアウトオンライン→オフラインの遷移対応方法としては、タイムアウト設定、リトライ、サーキットブレーカーなどがあります。サーキットブレーカーとは、外部サービスへのリクエストが連続して失敗したとき、一時的にリクエストを遮断する仕組みです。電気のブレーカーが過電流を検知して回路を遮断するのと同じ発想で、障害の連鎖を防ぎます。データベース障害DB応答不可コネクションプール枯渇デッドロック対応方法としては、コネクションプールの適切な設定、リトライ、タイムアウトなどがあります。外部サービス障害API応答不可レートリミット予期しないレスポンス形式対応方法としては、サーキットブレーカー、フォールバック、キャッシュなどがあります。リソース枯渇ディスク容量不足メモリ不足ファイルディスクリプタ枯渇リソース枯渇は、テストで再現するより監視とアラートで早期に検知する方が現実的です。とはいえ、リソースが枯渇したときにシステムがどう振る舞うか（gracefulに停止するか、エラーメッセージを出すか）は、設計段階で決めておく必要があります。カオスエンジニアリングの実践「本番環境に障害を注入する？ 正気か？」。最初は誰もがそう思います。しかし、問いを変えてみましょう。「本番で障害が起きたとき、それが予期せぬものであることと、計画されたものであること、どちらがマシか？」カオスエンジニアリングの市場規模は2025年に23.6億ドル、2030年には35.1億ドルに達すると予測されています。もはやニッチな手法ではなく、エンタープライズ標準になりつつあります。www.mordorintelligence.comKubernetes環境ではLitmusChaosとChaos Meshが代表的なツールです。LitmusChaosはCNCFインキュベーティングプロジェクトとして活発に開発が続いています。Chaos MeshはPodChaos、NetworkChaos、IOChaos、StressChaosなど多様な障害タイプを提供します。hub.litmuschaos.ioGameDay（計画的なカオス実験演習）の実践も広がっています。まず最小の爆発半径（障害の影響範囲）から開始し、単一コンテナ→サービス→ゾーンと段階的にスケールアップします。本番環境を最初のターゲットにしてはなりません。レジリエンスパターン環境の異常に備えるには、コードにレジリエンスパターンを組み込む必要があります。先に紹介したサーキットブレーカーに加え、以下のパターンが重要です。Bulkhead（バルクヘッド）: 船の隔壁のように、リソースを区画化して一部の障害が全体に波及することを防ぎますRetry with Exponential Backoff（指数バックオフ付きリトライ）: 失敗したら1秒後、2秒後、4秒後…と間隔を広げてリトライします。リトライストームを防止しながら一時的障害から回復しますこれらのパターンを実装したら、カオスエンジニアリングで実際に障害を注入し、期待通りに動作するか検証します。パターンを実装しただけでは不十分で、テストして初めて信頼できます。ここまで、入力値、状態、環境の異常を見てきました。最後に残るのは、最も厄介な異常です。複数のユーザーが同時にシステムを使うときに起きる問題、競合の異常です。競合の異常「ローカルでは動いたのに」。開発者なら誰もが経験するこの言葉の裏には、しばしば競合の問題が潜んでいます。開発環境では自分一人しかアクセスしません。しかし本番環境では、何百人ものユーザーが同時にボタンを押します。本番は、常に渋滞しています。その渋滞の中で、単体テストでは見えなかった問題が姿を現します。複数のユーザーやプロセスが同時にリソースにアクセスすると、競合が発生しえます。これは単体テストでは見つけにくく、負荷テストや本番環境で初めて発覚することも多いです。だからこそ、「競合が起きたらどうなるか」を事前に設計しておくことが重要です。同時更新典型的なシナリオを考えてみましょう。1. ユーザーAがデータを取得2. ユーザーBが同じデータを取得3. ユーザーAが更新を実行4. ユーザーBが更新を実行 → どうなるべきか？ユーザーBの更新時点で、データはすでにユーザーAによって変更されています。このとき、システムはどう振る舞うべきでしょうか。主な対応方法は3つあります。楽観的ロック: データ取得時にバージョン番号を記録し、更新時に照合します。バージョンが変わっていれば「誰かが先に更新した」と判断し、後から更新しようとした側にエラーを返します悲観的ロック: 更新する意思を示した時点で排他ロックを取得し、他者は同じデータを更新できなくなります。確実ですが、ロック待ちによる遅延が発生しえます最後の更新が勝つ: 競合を検出せず、後から来た更新で上書きします。シンプルですが、先の更新は失われますどの方法を採用するかは、ビジネス要件によります。在庫数のように「先の更新が失われると困る」データには楽観的ロックか悲観的ロック、ユーザーのプロフィールのように「最新の状態が正」でよいデータには最後の更新が勝つ方式、といった使い分けになります。ボタン連打UIにおいて、ユーザーがボタンを連打した場合の動作を確認します。「送信ボタンを押したけど反応がない。もう一度押そう」。ユーザーは待ってくれません。ネットワークが遅いとき、ボタンが反応しないとき、人は本能的に連打します。「購入する」ボタンを連打したら2回購入されてしまった、という事故は避けたいところです。対応方法としては、デバウンス（一定時間内の連続クリックを1回とみなす）や、送信中はボタンを無効化する二重送信防止の仕組みがあります。サーバー側でも、同一リクエストを検出するためにリクエストIDを使った冪等性の担保を検討します。ここまで、4種類の異常（入力値、状態、環境、競合）を見てきました。これらの異常が発生したとき、システムは何らかのエラーを返す必要があります。では、どのようなエラーを返すべきでしょうか。次は、エラーレスポンスの設計について考えていきます。エラーレスポンスの設計異常系テストでは、「エラーが起きないこと」ではなく「適切なエラーが返ること」を検証します。エラーレスポンスの設計は、クライアント側のエラーハンドリングに大きく影響します。適切なエラーを返せば、呼び出し側は何が起きたかを判断し、適切に対処できます。ステータスコードの使い分けステータスコードとは、サーバーがクライアント（ブラウザやアプリ）に返す3桁の数字です。この数字を見れば、リクエストが成功したのか、失敗したのか、何が原因なのかが分かります。HTTPの場合：400 Bad Request: 入力値が不正401 Unauthorized: 認証失敗（ログインが必要）403 Forbidden: 権限不足（ログイン済みだがアクセス権がない）404 Not Found: リソースが存在しない409 Conflict: 競合（同時更新など）429 Too Many Requests: レートリミット（リクエストが多すぎる）500 Internal Server Error: サーバー内部エラー503 Service Unavailable: サービス利用不可（メンテナンス中など）gRPCの場合（gRPCはGoogleが開発した高速な通信方式）：INVALID_ARGUMENT: 入力値が不正NOT_FOUND: リソースが存在しないALREADY_EXISTS: リソースが既に存在FAILED_PRECONDITION: 前提条件不成立PERMISSION_DENIED: 権限不足RESOURCE_EXHAUSTED: リソース枯渇セキュリティ観点でのエラー設計他ユーザーのリソースへのアクセスには、エラーコードの選び方に注意が必要です。ここには、多くの開発者が見落としている盲点があります。素直に考えると、「存在するが権限がない」なら403 Forbiddenを返したくなります。HTTPの仕様としては正しいです。しかし、これには問題があります。攻撃者がIDを総当たりで試したとき、403が返れば「このIDのリソースは存在する」と分かってしまいます。つまり、正しいエラーコードを返すことが、セキュリティホールになるという逆説です。そこで、他ユーザーのリソースへのアクセスには404 Not Foundを返すという設計があります。「存在するが権限がない」と「存在しない」を区別できないようにすることで、攻撃者に情報を与えません。GitHubのプライベートリポジトリも、この設計を採用しています。権限のないリポジトリにアクセスすると、「存在しない」と表示されます。これは「嘘をつく」のではなく、「必要以上の情報を与えない」という設計です。エラーメッセージは親切であるべきですが、攻撃者にも親切である必要はありません。異常の種類と、返すべきエラーレスポンスが分かりました。では、実際にどうやってテストを書けばいいのでしょうか。ここからは、異常系テストの書き方について説明します。テストの書き方期待するエラーの検証異常系テストで最も基本的なのは、「期待するエラーが返ること」の検証です。正常系では「期待する結果が返ること」を確認しますが、異常系では「期待するエラーが返ること」を確認します。# 例: 存在しないリソースへのアクセスで404が返ることを検証def test_get_not_found():    response = client.get("/resources/nonexistent-id")    assert response.status_code == 404テストの独立性各テストは独立して実行できるようにします。テスト間でデータを共有しません。# テストごとに一意のIDを使用TEST_ID="test-$(date +%s)"クリーンアップテスト終了後は作成したリソースを削除します。テストデータが残っていると、次回のテスト実行に影響を与える可能性があります。テストピラミッドにおける異常系テストMike Cohnの伝統的なテストピラミッド（ユニット→インテグレーション→E2E）では「各要件に対し少なくとも2つのテスト、1つは正常系、1つは異常系」が原則です。Kent C. Doddsの「Testing Trophy」モデルでは、インテグレーションテストを重視します。「テストがソフトウェアの使用方法に似ているほど、より多くの信頼を与える」という原則のもと、インテグレーションテストはユニットテストが見逃すエラー（コンポーネント間の相互作用問題）を捕捉します。AIによるテスト生成「テストケースを考えるのが面倒」「どこまでカバーすればいいか分からない」。そんな悩みを抱えたことはないでしょうか。AIによるテスト生成は、この問題に一つの解を与えます。NVIDIAのHEPHフレームワークはLLM（大規模言語モデル）を用いてドキュメントからテストを自動生成します。Diffblue CoverはJavaコードの静的解析からユニットテストを生成します。qodo（旧Codium）はコード動作を分析してエッジケースを含むテストケースを生成します。これらのツールはエラーシナリオ、境界条件、例外処理パスを自動的に導出します。ただし、AIが生成したテストをそのまま使うのは危険です。「何をテストすべきか」の判断は人間がすべきであり、AIはその実装を支援するツールに過ぎません。テストの質を検証する：Mutation Testingテストを書きました。カバレッジも高いです。しかし、そのテストは本当にバグを見つけられるのでしょうか。Mutation testing（変異テスト）は、コードに意図的なバグを埋め込み、テストがそれを検出できるか評価する手法です。たとえばif (x > 0)をif (x >= 0)に変更します。この変更をテストが検出できなければ、そのテストには穴があります。PITest（Java）、Stryker Mutator（JS/TS/C#）、cargo-mutants（Rust）などのツールがCI/CDへの統合を進めています。cargo-mutantsはRustConf 2024で発表され、ソースコード変更なしで任意のRustプロジェクトに適用できます。 speakerdeck.com異常系テストの優先順位すべての異常をテストする時間はありません。リスクベースで優先順位をつけます。Priority 1（毎スプリント）: セキュリティ敏感入力（SQLインジェクション、XSS）、金融・トランザクション操作、認証・認可障害Priority 2（毎リリース）: コアビジネス機能のエラーパス、統合ポイント障害、境界値違反Priority 3（定期テスト）: 複雑なエラーハンドリングフロー、二次機能のエッジケースPriority 4（メジャーリリース前）: 安定したレガシー機能、低トラフィック機能のエラーハンドリングまとめ異常系テストは「何が起きたら困るか」を事前に洗い出し、システムが適切に対処できることを検証する作業です。本記事で紹介した内容を振り返ると、以下の5点が重要になります。すべてをテストする必要はない - リスクの高い箇所に集中します。テストにもROIがあります。チームで「どこまでの異常を許容するか」を言語化しておきましょうAIとツールを活用する - ファジング、Property-based testing、Mutation testingなど、人間の想像力を超える異常を発見する手法があります。AIによるテスト生成も現実的な選択肢になりました環境の異常にはカオスエンジニアリング - 本番環境で必ず起きる障害を、事前に計画して注入します。レジリエンスパターン（サーキットブレーカー、バルクヘッド、指数バックオフ）を実装し、実際にテストしますセキュリティ観点を忘れない - エラーメッセージやエラーコードが情報漏洩につながることがあります。403と404の使い分けはその典型例ですテストを書くことで設計が明確になる - 「空文字を許容するか」「同時更新をどう扱うか」といった曖昧だった仕様が、テストを書く過程で具体化されます異常系テストは面倒に感じることもあります。しかし、プロダクション環境で障害が発生してから対処するコストに比べれば、事前にテストを書くコストは安いです。深夜2時のアラート対応、原因調査、ホットフィックス、ポストモーテム。そのすべてを、1つのテストが防いでくれることがあります。障害が起きたら、その教訓をテストとして残す。それが本当の意味での振り返りです。異常系テストは、将来の自分を助けるための投資です。3ヶ月後の深夜2時、アラートが鳴らなかったとき、過去の自分へ感謝するでしょう。明日からできること大げさに考える必要はありません。次にコードを書くとき、1つだけ試してみてください。「この処理が失敗したら、何が起きるか」を考える。その問いを立てるだけで、異常系テストは始まっています。APIを呼ぶコードを書いたら、「このAPIがタイムアウトしたらどうなるか」と考えます。データベースに保存するコードを書いたら、「保存に失敗したらどうなるか」と考えます。その問いに対する答えをテストとして書く。それだけでいいのです。完璧を目指す必要はありません。昨日より1つだけ、システムを堅牢にする。その積み重ねが、深夜のアラートを1回減らし、ユーザーの信頼を1つ守ります。今日書いた1つのテストが、3ヶ月後の深夜2時を救います。AIがテスト生成を支援してくれる時代だからこそ、この「問いを立てる力」は人間にしかできない価値になります。3ヶ月後の深夜2時。あなたのスマートフォンは静かなままです。アラートは鳴りません。それは偶然ではありません。過去のあなたが書いた1つのテストが、その夜の安眠を守っています。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料ソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonソフトウェアテスト技法練習帳 ~知識を経験に変える40問~作者:梅津 正洋,竹内 亜未,伊藤 由貴,浦山 さつき,佐々木 千絵美,高橋 理,武田 春恵,根本 紀之,藤沢 耕助,真鍋 俊之,山岡 悠,吉田 直史技術評論社Amazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon知識ゼロから学ぶソフトウェアテスト 第3版 アジャイル・AI時代の必携教科書作者:高橋 寿一翔泳社Amazonフルスタックテスティング【リフロー型】 10のテスト手法で実践する高品質ソフトウェア開発作者:Gayathri Mohan翔泳社Amazonソフトウェア品質保証入門: 高品質を実現する考え方とマネジメントの要点作者:保田 勝通,奈良 隆正日科技連出版社Amazonソフトウェア品質保証の極意 ―経験者が語る、組織を強く進化させる勘所―オーム社Amazon生成AIによるソフトウェア開発 ―設計からテスト,マネジメントまでをすべて変革するLLM活用の実践体系―オーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Spanner の記事を書きました (+ 技術的な蛇足)]]></title>
            <link>https://silasol.la/posts/2025-12-16-01_cloud-spanner/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2025-12-16-01_cloud-spanner/</guid>
            <pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Cloud Spanner のコアアーキテクチャについて，職場の Tech Blog 補足と技術的な余談 (Paxos, CAP 定理, NewSQL) をまとめました．]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[クラウド破産回避ガイド - AWSコスト管理の実践]]></title>
            <link>https://zenn.dev/r4ynode/articles/aws-cost-management</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/aws-cost-management</guid>
            <pubDate>Mon, 15 Dec 2025 22:00:06 GMT</pubDate>
            <content:encoded><![CDATA[要約AWSのコスト管理は「Billing and Cost Management」の機能を知るところから「AWS Budgets」も良いけど、「AWS Cost Anomaly Detection」も一緒に使うといいよ原因調査は、、がんばろう、、、（頑張るTipsは紹介します） はじめにAWSを利用し、高額な請求が来てクラウド破産する方々を見かけます。きっとこれからもそのような経験をする方は絶えないでしょう。原因としてサービスの多さやクラウドの料金体系の複雑さが挙げられます。これを真に理解するには時間を要し面倒に思えますが、すべてを理解しなくても事前に対策することは容...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PostgreSQLのインデックス作成におけるパラメータの影響の調査]]></title>
            <link>https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation</link>
            <guid isPermaLink="false">https://zenn.dev/nnaka2992/articles/performance_measurement_on_pg_index_creation</guid>
            <pubDate>Mon, 15 Dec 2025 15:43:00 GMT</pubDate>
            <content:encoded><![CDATA[このブログは3-shake Advent Calendar 2025 およびPostgreSQL Advent Calendar 2025のクロスポストです。PostgreSQLのインデックス作成のパフォーマンスには下記の2つのパラメータが特に大きく影響する。maintenance_work_memほとんどのインデックスメソッドにおいて、インデックス作成速度はmaintenance_work_memの設定に依存します。 より大きな値を設定すると、インデックス作成に必要となる時間が短縮されます。 ただし、実際に使用できるメモリ量を超えるほど大きくすると、マシンがスワップ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Langfuseに入門しないか？ ~ローカルホストで使ってみよう~]]></title>
            <link>https://zenn.dev/akasan/articles/langfuse_localhost</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/langfuse_localhost</guid>
            <pubDate>Mon, 15 Dec 2025 12:39:39 GMT</pubDate>
            <content:encoded><![CDATA[今回からLangfuseも取り扱っていこうと思います。Langfuseを利用することで、LLMの挙動をトレースすることができます。 Langfuseとは？Langfuseは、オープンソースのLLMエンジニアリングプラットフォームです。チームがLLMアプリケーションを共同でデバッグや分析、反復開発するのを支援してくれます。また、プラットフォームのすべての機能はネイティブに統合されており、開発ワークフローを加速します。Langfuseはオープンで、セルフホスト可能、そして拡張性に優れています。https://langfuse.com/docs主なインテグレーションについては以下にま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、戦略を語れ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/15/130000</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/15/130000</guid>
            <pubDate>Mon, 15 Dec 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに会議室で誰かが「戦略」と言った瞬間、空気が変わる。みんなの背筋が伸びる。うなずきが深くなる。誰かがおもむろにホワイトボードの前に立ち、矢印を描き始める。私も「なるほど」という顔をしてみる。眉間にしわを寄せ、顎に手を当て、いかにも深く考えているふうを装う。会議室にいる全員が、突然「戦略を理解している側の人間」になる。ただ、私は知っている。この部屋にいる何人かは、私と同じことを思っているはずだ。「で、結局、何をするの？」言えない。絶対に言えない。「戦略」という言葉が持つ重厚感に押しつぶされて、そんな素朴な疑問は喉の奥に引っ込んでしまう。分かっていないことがバレたら終わりだ。「あいつ、戦略を理解していない」というレッテルを貼られたら、もうこの会議室での発言権はない。だから黙る。黙って、賢そうな顔を続ける。不思議なのは、誰もが同じ演技をしているように見えることだ。部長も、課長も、隣に座っている同僚も。みんな「戦略」という言葉に真剣な顔で向き合っている。でも、その「真剣な顔」は、本当に理解しているから出てくる表情なのだろうか。それとも、理解していないことを悟られないための防衛反応なのだろうか。私には、区別がつかない。会議が終わると、みんな自分のデスクに戻っていく。誰も「さっきの戦略、よく分からなかったね」とは言わない。私も言わない。言ったら負けだ。何に負けるのかは分からないけど、とにかく負ける気がする。だから、分かったふりを続ける。これは、そういう自分への苛立ちから始まった文章だ。「戦略的に考えろ」と言われるたびに、心の中で「戦略的って何だよ」と毒づいてきた。でも調べなかった。調べるのが怖かった。調べて、やっぱり分からなかったらどうしよう。そんな不安があった。聞くこともできなかった。「戦略って何ですか」なんて質問は、新卒1年目ならまだ許される。でも、何年も働いてきた人間が今さら聞けるわけがない。だから分かったふりを続けてきた。その居心地の悪さを、いい加減どうにかしたかった。だからこの文章を書いている。誰かのためではない。自分のためだ。「おい、戦略を語れ」という言葉は、会議室の誰かに向けているようで、実は鏡の中の自分に向けている。お前は本当に分かっているのか。分かったふりをしているだけじゃないのか。その問いに、いい加減決着をつけたかった。戦略という言葉の氾濫私たちの周りには、「戦略」という言葉が溢れている。経営戦略。マーケティング戦略。販売戦略。顧客戦略。人材戦略。DX戦略。グローバル戦略。デジタル田園都市国家構想総合戦略。こんなに幅広く使われている「戦略」だが、その核心が何なのかと聞かれると、答えられない。いや、答えられないだけならまだいい。答えが人によって違いすぎる。ある人は言う。「戦略とは、目標を達成するための手段だ」。別の人は言う。「戦略とは、ビジョンを実現するための計画だ」。また別の人は言う。「戦略とは、競合に勝つための差別化だ」。どれも間違ってはいない。しかし、どれも正しくはない。なぜなら、これは戦略の「結果」であって、戦略の「核心」ではないからだ。戦略会議で何が起きているか、もう一度見てみよう。「今期の戦略は、売上を前年比130%にすることです」。これは戦略ではない。目標だ。どうやって達成するのかは、何も語られていない。「我々の戦略は、顧客第一、品質重視、イノベーション推進です」。これも戦略ではない。スローガンだ。具体的に何をするのかは、何も示されていない。「我々のマーケティング戦略は、デジタルチャネルの強化、SNS活用の拡大です」。これも戦略ではない。施策の羅列だ。なぜその打ち手なのか、どうつながっているのか、何が問題でそれがどう解決するのかは説明されていない。そして、最悪なのは、これらを「悪い戦略」と呼ぶことさえ正しくないということだ。悪い戦略とは、内部の対立を曖昧にするための妥協の産物である、という指摘がある。経営会議で、営業部と開発部が対立する。営業は「もっと新機能を」と言う。開発は「品質を優先すべき」と言う。すると、誰かが言う。「では、両方やりましょう。それが我々の戦略です」。これは妥協だ。誰も傷つけないための八方美人だ。でも、これを「戦略」と呼んではいけない。なぜなら、戦略とは、選択だからだ。何をやるかを決めることではない。何をやらないかを決めることだ。しかし、私たちは選択できない。なぜか。もちろん、個人の心理もある。選択することは、責任を負うことだ。「これをやる」と決めた人間は、それが間違っていた時、責任を取らなければならない。だから、選択を避ける。全部やると言えば、誰も傷つかない。ただ、問題は個人の心理だけではない。組織の構造が、選択を妨げている。まず、インセンティブの問題がある。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっている。「うちの部門の予算を削るな」という力学が働く。次に、権限の曖昧さがある。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確だ。だから、誰も決めない。決めなければ、責任を問われない。また、評価制度との不整合がある。「やらないと決めた」ことは、評価されにくい。成果として見えないからだ。「100のことをやって80点」より「30に絞って95点」の方が戦略的には正しい。しかし、評価制度が前者を高く評価することがある。だからといって、個人の責任がないわけではない。選択する勇気は必要だ。ただ、勇気だけで組織を変えることはできない。構造を変えなければ、選択は起きない。「全部やる」は、個人の弱さであると同時に、構造の帰結でもある。選択を避け、妥協を繰り返す。その結果、戦略という言葉は、中身のない器になった。何を入れても受け入れる、便利な箱になった。目標を入れる。スローガンを入れる。希望を入れる。妥協を入れる。蓋を閉じて、「戦略」というラベルを貼る。これが、私たちが「戦略」と呼んでいるものの正体なのだろう。この空洞さは、どの立場にいても感じることがあるだろう。ただ、私のように技術寄りの立場にいると、余計に気になることがある。技術顧問として呼ばれているのに、いつの間にか「経営戦略」のスライドを見せられている。自分はシステムのアーキテクチャについて聞かれると思っていたのに、気づくと「売上130%」のスライドの前に立たされている。その「戦略」がどのレイヤーの話なのか、技術側から見るとよくわからない。事業の話なのか、組織の話なのか、プロダクトの話なのか。全部が「戦略」という言葉で括られている。しかし、だからといってエンジニアが戦略と無縁でいられるわけではない。プロダクトのどこにリソースを割くか。どの技術的負債を今返し、どれを後回しにするか。このアーキテクチャで将来の拡張性を取るか、今のシンプルさを取るか。これはすべて戦略的な判断だ。経営会議に出なくても、コードを書いていても、私たちは日々、戦略的な選択をしている。だからこそ、「戦略とは何か」を理解することは、エンジニアにとっても他人事ではない。私自身、最近作った資料を振り返ることがある。「戦略」と書いたスライド。本当に「解決すべき最重要課題と、その解き方」になっていたか。目標やスローガン、施策の羅列に留まっていなかったか。正直、自信がない。核心を見極める戦略を一言で表すなら、こうなる。「戦略とは、解決可能な最重要課題を見極め、それを解決する方法を見つけることだ」。シンプルだ。しかし、深い。まず、「解決可能な最重要課題」とは何か。組織が直面している問題は無数にある。しかし、すべてが同じ重さではない。ある問題を解決すると、他の問題も連鎖的に解決に向かう。そういう問題がある。それが「核心的な課題」だ。技術選定を考えてみよう。新しいプロジェクトを始める時、検討すべきことは無数にある。言語は何にするか。フレームワークは何を使うか。データベースは何が適切か。インフラはどう構成するか。すべて重要だ。ただ、すべてを同時には最適化できない。ここで、核心を見極める必要がある。たとえば、「チームの習熟度」が核心だとする。どんなに優れた技術でも、チームが使いこなせなければ意味がない。だから、チームが慣れている言語を選ぶ。すると、立ち上がりが早くなり、バグも減り、メンテナンスも楽になる。1つの核心を押さえたら、他の問題も動き始めた。戦略も同じだ。核心的な課題を見つけ、そこにリソースを集中させる。戦略とは、この課題を見つけることから始まる。会社が直面している問題は無数にある。売上が伸びない。競合が強い。人材が足りない。技術が古い。すべて問題だ。すべて解決したい。だが、すべてを同時に解決できない。だから、見極める。どれが核心的な課題なのか。どれを解決すれば、他の問題も動き始めるのか。私が関わったある組織で、プラットフォームエンジニアリングチームを立ち上げようとした時、無数の技術的課題があった。どれも難しい。どれも重要だ。Kubernetesの運用。CI/CDパイプラインの整備。監視基盤の構築。セキュリティポリシーの策定。ただ、本当の核心的な課題は、別のところにあった。「開発者がインフラを触るまでのリードタイムが長すぎる」。これが核心だった。どんなに優れた基盤があっても、開発者が使い始めるまでに2週間かかるなら、誰も使わない。だから、セルフサービス化を最優先にした。申請から環境構築までを30分に短縮した。すると、利用率が上がり、開発速度も上がり、プラットフォームチームへの信頼も高まった。1つの核心を解いたら、他の問題も動き始めた。これが、戦略だ。核心的な課題を見つける。解決策を見つける。実行する。もう1つ、私自身のプラットフォームエンジニアリングの経験を話そう。以前いたチームでは、コードの品質、テストのカバレッジ、ドキュメントの不足、レガシーシステムとの連携と、無数の課題があった。ただ、本当の核心的な課題は別のところにあった。「開発者がステージング環境を立てるのに2日かかる」。これが核心だった。インフラチームへの申請、承認待ち、手動でのセットアップ。ステージング環境が作れなければ、検証できない。検証できなければ、リリースできない。Terraformでインフラをコード化し、GitHubのPRをマージするだけで環境が立ち上がるようにした。30分で完了する。すると、リリース頻度が上がり、バグも減り、開発者体験も改善された。1つの核心を解いたら、他の問題も動き始めた。シンプルだが、簡単ではない。課題を見極めることは、選択だからだ。「これが最も重要だ」と決めることは、「他は優先しない」と決めることでもある。戦略会議を思い出そう。「売上を前年比130%にする」は核心的な課題ではない。売上を伸ばすことは結果であって、問題ではない。問題は、なぜ売上が伸びないのか、だ。競合が強いのか。商品が古いのか。チャネルが弱いのか。ブランドが知られていないのか。価格が高いのか。営業力が足りないのか。どれが核心なのか。どれを解決すれば、売上が伸びるのか。それを見極めることが、戦略の第一歩だ。しかし、私たちはそれをしない。見極めることは、責任を負うことだからだ。「これが核心だ」と言った人間は、それが間違っていた時、責任を取らなければならない。だから、誰も言わない。全部重要だと言う。全部やると言う。そして、何も解決しない。選択から逃げる方法は、もう1つある。パーパスやミッションに逃げ込むことだ。パーパスやミッションは、戦略ではない。パーパスとは、企業の存在意義だ。ミッションは、企業が果たすべき使命だ。どちらも重要だ。だが、戦略ではない。「世界中の人々に幸せを届ける」。美しいパーパスだ。では、どうやって届けるのか。それが戦略だ。パーパスは方向を示す。道を示すのは戦略だ。多くの企業が、パーパスを掲げて満足してしまう。具体的に何をするのかは、曖昧なままだ。これは、戦略の放棄だ。難しい選択から逃げているだけだ。これは事業側の話だけではない。技術側にも同じ罠がある。「技術負債をなくす」「きれいなアーキテクチャにする」「開発者体験を向上させる」。美しい技術パーパスだ。しかし、具体的にどの負債を、いつまでに、どうやって返すのか。何を「きれい」と定義し、どの部分から手をつけるのか。開発者体験のどの側面を、どの程度まで改善するのか。それが示されていなければ、技術パーパスもまた、戦略ではない。事業側であれ技術側であれ、パーパスごっこに陥りやすい。美しい言葉を掲げて、具体的な選択から逃げる。私自身、「解決可能な最重要課題」を1つだけ挙げろと言われると、考え込んでしまうことがある。なぜそれが「最重要」だと言えるのか。即答できない時、見極めができていないと気づく。戦略はストーリーであるここまで、戦略の「内容」について語ってきた。何を解決するか。どこに集中するか。これが内容だ。次は、戦略の「形」について考えよう。同じ内容でも、伝え方によって実行力が変わる。バラバラの施策として並べるか、一貫したストーリーとして語るか。この違いが、戦略の成否を分ける。良い戦略は、施策ではなくストーリーだ。ストーリーとは何か。物語だ。因果の連鎖だ。「AだからB、BだからC、CだからD」という流れだ。良い戦略は、この流れがある。個々の施策が、バラバラに存在するのではない。互いに補強し合っている。前の手が、次の手を可能にする。次の手が、前の手の効果を高める。プロダクト開発で考えてみよう。「このアーキテクチャにしたからこそ、新機能の実験が低コストで回せる」。「このモジュール分割をしておくから、将来の料金プランのバリエーションを増やせる」。「このAPIの設計にしたから、パートナー連携がスムーズにできる」。コードの書き方と、事業側の選択肢が、一本の物語になっているかどうか。技術的な決定が、事業の可能性を広げている。事業の方向性が、技術的な決定を正当化している。この双方向のつながりがあるかどうか。それが、技術戦略がストーリーになっているかどうかの分かれ目だ。逆に、悪い戦略には、ストーリーがない。「我々は、高品質な商品を、低価格で、迅速に提供します」。一見、良さそうだ。でも、これはストーリーではない。施策の羅列だ。高品質と低価格は矛盾する。高品質にはコストがかかり、低価格にするにはコストを削る。迅速さも、品質と矛盾することが多い。これらの施策は、互いに補強し合っていない。むしろ、打ち消し合っている。因果の連鎖がないから、実行できない。なぜ、こうなるのか。多くの場合、「あれもこれも」と欲張るからだ。高品質が欲しい。低価格だって欲しい。迅速さまで欲しい。全部欲しい。でも、全部は取れない。ストーリーを一貫させるには、「これ一本」が必要になる。何かを選び、何かを捨てる。この「これ一本」の考え方は、企業の戦略だけでなく、チームや個人にも当てはまる。私が特に強く感じるのは、専業性の強さだ。誤解のないように言えば、多角化がつねに悪いわけではない。あるプラットフォームチームは、CI/CDパイプラインの整備から始まり、監視基盤、セキュリティスキャン、開発者ポータルへと領域を広げた。別のチームは、Kubernetesクラスタの運用から、GitOpsの導入、Terraformによるインフラ管理、コスト最適化へと拡張した。これは成功した多角化だ。しかし、共通するのは、核となる強みから派生して広がったことだ。前者は「開発者体験の向上」を軸に広がった。後者は「セルフサービス化による開発者の自律性」を軸に広がった。つまり、多角化と専業性は二項対立ではない。「何を軸にするか」が明確かどうかが分かれ目だ。問題なのは、軸のない多角化だ。「他のチームがやっているから自分たちも」「とりあえずKubernetesを入れよう」。このタイプの多角化は、リソースを分散させ、どの領域も「そこそこ」にしてしまう。専業的なチームが強いのは、専業だからではない。1つのことを徹底的に掘り下げているからだ。多角化していても、軸が明確で、そこを徹底的に掘り下げているチームは強い。チームの話をしてきたが、これは個人のキャリアにも当てはまる。私は、エンジニアとして働いている。プログラミングができる。インフラも分かる。データベースも触れる。フロントエンドもできる。「フルスタックエンジニア」という肩書きを持っている。しかし、あるとき気づいた。私は、多くのことを「そこそこ」できる。ただ、何1つ「徹底的に」できない。専門性がない。深さがない。だから、代替可能だ。誰かが、私より少し上手にできる。常に、そういう誰かがいる。専業性。1つのことを、徹底的に掘る。それが、競争優位の源泉だ。もしあなたが「何でもそこそこできる人」なのであれば、それをどうポジショニングするのかも戦略だ。「何でも屋」として埋もれるのか、「事業と技術をつなぐ翻訳者」として立つのか。どちらを選ぶかは、「何をやらないか」の選択だ。翻訳者として立つなら、深い専門性を追求することは諦める。代わりに、異なる専門性を持つ人々の間を橋渡しする能力を磨く。これも戦略的な選択だ。私自身、この問いを自分に向けることがある。戦略を説明する時、ストーリーになっているか。キーワードの寄せ集めか。専業性があるのか、何でもそこそこなのか。流されてそうなっているだけではないか。答えは、いつも曖昧だ。明確に「できている」とは言えない。ただ、問い続けること自体に意味があると思っている。まだ顧客ではない人を見つけるあるとき、プラットフォームチームのダッシュボードを眺めていて、違和感を覚えた。利用者数が伸びていない。一方で、既存ユーザーからの機能要望は山のように来ている。私たちは、その要望に応え続けていた。新機能を追加した。ドキュメントを充実させた。既存ユーザーは喜んだ。しかし、利用者数は変わらなかった。何かがおかしい。ふと疑問が浮かんだ。「使っていない人は、なぜ使っていないのか」。私たちは、その問いを持っていなかった。ここまで、戦略の「何を」「どう」の話をしてきた。次は、「誰に」の話だ。戦略を考える時、私たちは既存の顧客ばかり見てしまう。「この機能がほしい」「ここが使いにくい」。フィードバックは大事だ。ただ、本当の成長機会は、別のところにあることが多い。本当の顧客は、まだ顧客ではない。「まだ顧客ではない人」とは、ただ「使っていない人」ではない。彼らは、その機能を必要としていないのではない。「高すぎる」「難しすぎる」「面倒くさすぎる」など、どこかでバリアに引っかかっている。価格のバリア。複雑さのバリア。心理的なバリア。面倒くささのバリア。どのバリアが最も高いのかを見極め、それを下げる。これが、潜在顧客へのアプローチだ。私が関わったあるプラットフォームエンジニアリングのプロジェクトでは、社内の開発者向けに整備したCI/CDパイプラインやKubernetesクラスタが、なかなか使われない問題があった。機能を追加しても、ドキュメントを増やしても、利用率は上がらなかった。調べてみると、問題は別のところにあった。「初期設定が面倒」。パイプラインの機能は十分だった。ただ、自分のプロジェクトに適用するには、YAMLを何十行も書き、権限設定を複数箇所で行う必要があった。これがバリアだった。テンプレートを用意し、3つの質問に答えるだけで初期設定が完了するCLIツールを作った。利用率は上がった。機能の問題でも、ドキュメントの問題でもなかった。面倒くささのバリアだった。別の例を挙げよう。ある組織で、SREチームの構築した本格的な開発者プラットフォームがあったとする。Kubernetesクラスタ、Terraformによるインフラ管理、Prometheusによる監視、ArgoCD によるGitOps。高機能で、クラウドネイティブな開発には必須の基盤だ。ただ、使いこなすにはKubernetesの知識が必要で、YAMLの書き方を理解し、GitOpsのワークフローに慣れなければならない。このプラットフォームの「まだ顧客ではない人」は誰か。入社したばかりの新人エンジニアだ。別チームから異動してきたバックエンドエンジニアだ。彼らも同じ課題を抱えている。「自分のアプリケーションを安定して動かしたい」という同じ「進歩」を求めている。ただ、学習コストが高すぎる。複雑すぎる。だから、ローカル環境や古いVMで我慢している。ここで、セルフサービスポータルが登場したとする。Webの画面でアプリ名と言語を選ぶだけ。裏側ではKubernetesが動いているが、ユーザーはそれを意識しなくていい。すると、今までプラットフォームを使っていなかった新人や他チームのエンジニアが、ユーザーになる。使っているうちに理解が深まり、もっと高度なカスタマイズがしたくなる。直接YAMLを書くようになる。「まだユーザーではない人」が、ユーザーになる。そして、成長とともにプラットフォームのパワーユーザーになる。重要なのは、「機能を削った劣化版」を作ることではない。「まだ顧客ではない人」が抱えているバリアを特定し、そのバリアを下げることだ。価格がバリアなら、価格を下げる。複雑さがバリアなら、シンプルにする。心理的なハードルがバリアなら、入口を低くする。どのバリアが最も高いかを見誤ると、的外れな施策になる。「まだ顧客ではない人」を見つけて、バリアを下げる。この視点は、開発のやり方そのものを変える。開発には2つのアプローチがある。1つは「押しつけ」型だ。上から降りてきた仕様をそのまま実装する。なぜこの機能が必要なのか。誰のどんな課題を解決するのか。それが見えないまま、言われた通りに作る。すると、何が起きるか。作ったものが使われない。ユーザーが喜ばない。現場のモチベーションが下がる。もう1つは「引き寄せ」型だ。ユーザーの「本当に欲しい進歩」を理解する。そこから逆算して、仕様を決める。機能がユーザーのニーズに「引き寄せられている」状態だ。「まだ顧客ではない人」を見つけ、彼らのバリアを理解し、そこから仕様を導く。これこそが、戦略と開発が噛み合っている状態だ。私自身、「まだ顧客ではない人」を見落としていることに気づくことがある。既存ユーザーの声ばかり聞いて、「まだ使っていない人」のことを考えていない。彼らは何を求めているのか。何がバリアになっているのか。この視点を持つだけで、見える景色が変わる。ここで、1つ問いを立てたい。「まだ顧客ではない人」を見つけるのは、誰の仕事だろうか。マーケティング部門の仕事だと思われがちだ。しかし、現場こそ、潜在顧客のバリアを理解できる独自の視点を持っている。セールスは「買わない理由」を知っている。CSは「使い続けない理由」を知っている。そしてエンジニアは、バリアの多くが技術的な問題であることを知っている。「設定が複雑すぎる」。これは技術で解決できる。「動作が遅すぎる」。これも技術で解決できる。「他のツールと連携できない」。これも技術で解決できる。マーケティング部門は「バリアがある」と気づくことはできる。だが、「そのバリアをどう下げるか」を具体的に設計できるのは、現場だ。ここまで読むと、「現場が重要だ」という話に聞こえる。確かにそうだ。ただ、もう1つ、見落としがちな点がある。現場が価値を発揮できるのは、ある条件が揃っている時だけだ。その条件とは、制約だ。制約がなければ、現場は潜在顧客について何も語れない。逆説的に聞こえるだろう。説明しよう。どういうことか。もしリソースに何の制約もなければ、「全部やればいい」で終わる。高速にする。簡単にする。安くする。連携できるようにする。全部やる。それで解決だ。でも、現実にはリソースは有限だ。時間も、人も、予算も。だから、「どのバリアを下げるか」を選ばなければならない。この「選ぶ」という行為において、現場の知見が活きる。エンジニアなら「このバリアを下げるには3ヶ月かかる。でも、こっちのバリアなら1週間で下げられる」と判断できる。セールスなら「このバリアを下げれば、商談の成約率が上がる」と判断できる。制約があるからこそ、優先順位が生まれる。優先順位があるからこそ、戦略が必要になる。制約こそが、現場の貢献を可能にしている。つまり、「まだ顧客ではない人」を見つけて、そのバリアを下げる方法を提案すること。これは、現場ができる最大の「事業への貢献」の1つだ。指示を待つだけの現場には、この貢献はできない。「誰が使っていないのか」「なぜ使っていないのか」「どうすれば使えるようになるのか」。そして、「限られたリソースで、どのバリアから下げるべきか」。この問いを持つ現場だけが、事業の成長に直接貢献できる。理論と実践の間でここまで、戦略について語ってきた。核心的な課題を見極めること。ストーリーとしての一貫性。専業性の強さ。「まだ顧客ではない人」という視点。これらの考え方は、理解できる。頭では分かる。しかし、1つ重要な疑問が残る。これらの考え方を、どう使えばいいのか。正直に言えば、私はエンジニアだ。設計パターンやアーキテクチャの本を何冊も読んできた。ドメイン駆動設計。クリーンアーキテクチャ。マイクロサービス。モジュラーモノリス。どれも「ソフトウェアをどう構造化するか」についての理論だ。複雑さをどう分割するか。変更をどう局所化するか。チーム間の依存をどう減らすか。これらの理論や仕組みについて、語ることはできる。だが、それを自分のプロジェクトに適用できるかは、別の話だ。どの理論が自分たちの状況に適用可能なのか。どのパターンが今の組織規模とスキルセットに合っているのか。それを判断するには、理論を超えた洞察が必要だ。理論を語れることと、戦略を立てられることは、別だ。ただ、「戦略を語れない」ことと「戦略を実行できない」ことは、同じだろうか。私は「戦略を語れ」と言っている。しかし、語れることと実行できることは別だ。美しい戦略を語れても、実行できなければ意味がない。逆に、言葉にできなくても、体で分かっている人もいる。私は、どちらだろうか。語れるけど実行できないのか。実行できるけど語れないのか。それとも、どちらもできていないのか。正直に言えば、分からない。理論は、現実を説明する。「なぜこうなったのか」を教えてくれる。しかし、「どうすればいいのか」は教えてくれない。マイクロサービスアーキテクチャは、システムを小さな独立したサービスに分割する手法だ。各チームが自分のサービスを独立してデプロイできる。大規模組織では強力だ。ただ、5人のチームで導入すべきか。サービス間の通信、障害の伝播、デバッグの難しさ。小さなチームには重荷になる。モノリスのままでいいのか。将来の拡張性は諦めるのか。ドメイン駆動設計は、複雑なビジネスロジックを「境界づけられたコンテキスト」で整理する手法だ。だが、今のプロジェクトは、本当にそこまで複雑か。学習コストに見合う複雑さがあるのか。それを判断するには、理論を超えた洞察が必要だ。理論は、説明する。しかし、処方箋は出さない。これは、理論の限界だ。いや、限界というより、理論というものの性質だ。理論は、世界を理解するためのツールだ。世界を変えるためのツールではない。理論には、必ず適用範囲がある。マイクロサービスは、組織がスケールしている時に有効だ。ただ、チームが小さい時は、むしろ足かせになる。クリーンアーキテクチャは、ビジネスロジックを外部依存から切り離す設計思想だ。データベースやフレームワークを後から差し替えられる。長期保守が前提のプロダクトでは有効だ。一方、3ヶ月で検証して捨てるプロトタイプでは、過剰投資になる。テスト駆動開発は、テストを先に書き、そのテストを通すコードを後から書く手法だ。仕様が明確な時に有効だ。けれど、何を作るか探索している段階では、テストが足かせになることもある。つまり、理論を使うには、まず「どの理論が適用可能か」を判断しなければならない。だが、それを判断するには、理論を超えた洞察が必要だ。これは、逆説だ。理論を使うために、理論を超えた何かが必要だ。その「何か」とは何か。経験だ。直感だ。センスだ。結局、理論は、センスの補助線に過ぎない。センスのある人が理論を使えば、より深く考えられる。一方、センスのない人は理論だけに頼っても、何もできない。では、センスはどう磨くのか。「経験を積め」では答えになっていない。私なりに考えた方法を3つ挙げる。第一に、「判断の言語化」を習慣にする。何かを決めた時、なぜその判断をしたのかを書き残す。1ヶ月後、3ヶ月後に振り返る。当時の判断は正しかったか。何を見落としていたか。この繰り返しが、判断の精度を上げる。第二に、「他者の判断を追体験する」。本を読む時、著者がなぜその結論に至ったかを考える。「自分ならどう判断したか」を先に考えてから、著者の結論を読む。このギャップが学びになる。成功事例だけでなく、失敗事例を読むことも重要だ。第三に、「小さな賭けを繰り返す」。大きな戦略を立てる機会は少ない。ただ、小さな判断は毎日ある。「このタスクを先にやるか、後にやるか」「この機能を入れるか、外すか」。この小さな判断を意識的に行い、結果を観察する。センスは、大きな決断ではなく、小さな判断の積み重ねで磨かれる。センスは才能ではない、と私は思う。観察と振り返りの習慣なのではないか。私自身、この「センス」の不足を痛感したことがある。プラットフォームエンジニアとして「開発者体験を向上させるべきだ」と理論を実践しようとした。ツールのドキュメントを整備し、社内ドキュメントにまとめて共有した。ところが、利用率は変わらなかった。理論を機械的に適用したからだ。開発者体験は、ドキュメントだけでは向上しない。開発者が実際につまずく瞬間を観察する必要がある。「困ったらあの人に聞こう」と思われるプラットフォームチームが必要だ。これは信頼関係であり、組織文化だ。理論の外にある領域だが、理論を機能させるには不可欠だ。理論と実践の間には、常にギャップがある。理論は一般化された知識だ。実践は個別の状況だ。一般を個別に適用する翻訳こそが、実践者のスキルだ。だから、私は「この技術を使うべきか」と聞かれた時、即答しない。「チームの規模は」「プロダクトのフェーズは」「今の技術的負債はどこにある」と聞き返す。理論を適用する前に、文脈を理解しなければならない。文脈なき理論の適用は、害にすらなる。私はエンジニアだ。だから、目の前の現実と向き合うしかなかった。うまくいかないことを何度も経験した。その度に、なぜうまくいかなかったのかを考えた。理論を読み、現実と照らし合わせ、自分なりの理解を深めていった。この捻り出した思考は、今、個人やチームの戦略を立てる時に役立っている。理論を知っている。ただ、理論に頼りすぎない。現場を見る。人を見る。文脈を理解する。その状況に合った答えを探す。これが、実践者の仕事だ。小さな適応範囲なら、語れる。自分のチームで、どういう問題があって、どう解決しようとしたか。何がうまくいって、何がうまくいかなかったか。次はどうするか。この小さな範囲での試行錯誤が、戦略を立てる力を育てる。しかし、この「小さな適応範囲」の中には、純粋な技術領域だけでなく、事業寄りの判断もじわじわと入り込んでくる。「プロダクトのどこにリソースを割くか」「どの顧客セグメントに寄せるか」「この機能を今作るか、後で作るか」。これは、技術的な判断に見えて、実は事業の方向性に関わる判断だ。技術の現場にいながら、事業の戦略にも口を出すことになる。企業全体の戦略を立てることは、私にはできない。立場も違う。経験も足りない。だが、自分の責任範囲では、できる。自分のチームでは、できる。個人の仕事では、できる。この小さな範囲での実践こそが、本当の学びになる。理論を読むことは、重要だ。ただ、理論を読んだだけでは、何も変わらない。理論を使って、現場で試す。失敗する。振り返る。この繰り返しの中でしか、戦略を立てる力は身につかない。私自身、「戦略と言いながら、実は何も捨てていない」ものに関わってきた。理論やフレームワークを「そのまま」適用して、うまくいかなかったことも多い。足りなかったのは、現場の事情への理解だった。人の感情への配慮だった。技術戦略と事業戦略の距離を縮めるここまで、戦略を立てる「個人」の話をしてきた。だが、戦略は組織の中で機能する。特にエンジニアとして気になるのは、技術戦略と事業戦略の関係だ。長いあいだ、自分の中に「事業戦略→技術戦略」という一方向の矢印があった。事業側が「何を作るか」を決め、技術側は「どう作るか」を決める。経営が方向を決めて、エンジニアはそれを実装する。この一方向依存のメンタルモデルは、長らく私の中に染みついていた。しかし、現実には、「どう作るか」が「何ができるか」を大きく変える。変更コストの低いアーキテクチャだから、競合が半年かかる機能を1ヶ月で検証できる。このモジュールの切り方にしておくから、「この部分だけを切り出して別料金プランにする」という事業のオプションが生まれる。このAPIの設計にしておくから、将来のパートナー連携がスムーズにいく。技術戦略は、事業の選択肢を増やす。事業戦略から技術戦略への一方向ではなく、双方向の依存関係がある。技術が事業を制約することもあれば、技術が事業の可能性を広げることもある。この双方向性を理解すると、開発現場で起きる摩擦の見え方が変わる。技術的チャレンジは、想定外の遅延や不具合を生む。これを「技術の問題」として閉じてしまうと、現場は追い詰められる。「なんとかしろ」という圧力だけがかかる。しかし、技術的な課題を「事業戦略を動かす材料」として扱うと、話が変わる。「この技術的な制約があるなら、ローンチ時期をずらすか」。「このリスクがあるなら、この機能は一旦やめて、こっちの顧客セグメントを先に取るか」。技術の現場からの情報が、事業側の判断材料になる。不確実性を飼いならすための対話が生まれる。エンジニアだけでなく、デザイナー、PdM、ドメインエキスパートも同じだ。現場でプロダクトの手触りを一番知っている人たちが、事業戦略の「定数」ではなく「変数」をいじれる立場になっていい。「この仕様だとユーザーは混乱する」というデザイナーの声。「この機能は、実はこの顧客セグメントには刺さらない」というPdMの洞察。「この業界の慣習を考えると、この方向は難しい」というドメインエキスパートの知見。これは、事業戦略を修正するクリティカルなインプットだ。越権行為ではない。むしろ、健康な組織の姿だ。ここまで、技術と事業の対話について語ってきた。対話の相手は人間を想定してきた。しかし最近、対話の相手が変わりつつある。AIを戦略の壁打ち相手にする場面が増えた。試しにAIへ聞いてみたことがある。「戦略を考えてください」。出てきた答えは、驚くほど整っていた。SWOT分析。ファイブフォース分析。「デジタルチャネルの強化」「顧客体験の向上」といった施策。ロジックも通っている。これは、先ほど述べた「理論の限界」と同じ構造だ。AIは理論を適用できる。分析もできる。ただ、「どの理論が今の状況に適用可能か」を判断するのは、AIではなく人間だ。そして、最後に「これでいく」と賭けるのも人間だ。技術戦略と事業戦略の対話において、AIは優秀な壁打ち相手になる。「この技術的制約がある時、事業戦略はどう変わりうるか」と問えば、選択肢を整理してくれる。ただ、その選択肢の中からどれを選ぶかは、現場を知り、責任を負う人間が決める。これは、技術と事業の対話が人間同士であるべき理由と、根は同じだ。私自身、「本当はもっとこうすれば速く進めるのに」と感じることがある。技術の現場から見えている事業の可能性。それを戦略の議論にインプットしようとしたことはある。うまくいった時もあれば、スルーされた時もある。それでも、言い続けることに意味があると思っている。現場こそが仮説を持つべきだここまで、戦略について語ってきた。しかし、1つ疑問が残るだろう。現場の人間は、そもそも戦略なんて考える必要があるのか。与えられた目標を追いかけ、仕様通りに実装するのが仕事ではないのか。私の答えは明確だ。現場こそ、仮説を持つべきだ。エンジニアも、デザイナーも、セールスも、CSもだ。現場は、ビジネスの「手触り」を最も知っている立場だからだ。エンジニアは、プロダクトの構造的な手触りを知っている。「この機能は技術的に難しい」「ここがボトルネックになる」。これはコードを書く人間にしか分からない。同様に、セールスは顧客の「断る理由」の手触りを知っている。CSはユーザーが「つまづく瞬間」の手触りを知っている。本部で数字をこねくり回している時には見えない「事実の断片」を、現場は握っている。この手触りを「仮説」に昇華できた時、現場は戦略を変える力を持つ。たとえば、カスタマーサクセス（CS）。彼らは日々、「解約」という事実に直面する。戦略のないCSは、解約阻止のマニュアル通りに動き、ダメなら「顧客の事情」として処理する。しかし、仮説を持つCSは問う。「なぜ、このタイミングで解約するのか」。彼らは気づく。「機能不足ではなく、オンボーディングの3日目に発生する『設定の面倒さ』に心が折れているのではないか」。この仮説があれば、開発チームに「新機能より設定ウィザードの改善を」と要求できる。それは単なるクレーム処理ではない。立派な「チャーン（解約）阻止戦略」だ。たとえば、セールス。「価格が高いと言われました」と報告するだけなら、誰でもできる。AIでも集計できる。しかし、仮説を持つセールスは考える。「高いと言われるのは、価値が伝わっていないからか、それとも比較対象が間違っているからか」。もし顧客が、競合他社のツールではなく、Excelと比較して「高い」と言っているなら、戦い方は変わる。機能の多さをアピールするのではなく、「手入力のコスト」を訴求すべきだ。その気づきは、マーケティング戦略やプライシング戦略を根底から覆す可能性がある。仮説を持たない現場は、ただの「手足」になる。言われた通りに作り、言われた通りに売る。なぜやるのかは考えない。楽だが、キャリアとしては危うい。「言われたことを正確にやる」だけなら、代替可能だからだ。一方、仮説を持つ現場は、戦略の「センサー」になる。「本社が考えている戦略は、現場感覚とズレているぞ」と気づける。そのズレを言語化し、フィードバックする。時にそれは、経営陣にとって不都合な真実だろう。「今の売り方では絶対に売れない」「この機能は誰も使わない」。しかし、その不都合な真実こそが、組織を救う。仮説を持つことの有用性は、職種を問わず共通している。第一に、学習速度が上がる。仮説を持っていると、結果との差分が学びになる。「このトークなら刺さるはずだ」と思っていたことが、刺さらなかった。このギャップが、次の商談の精度を上げる。仮説がなければ、何が起きても「そんなものか」で終わる。第二に、議論に参加できる。仮説を持っていれば、それをぶつけることができる。「開発側はこう見ていますが、セールス側はどうですか」と問える。これは、単なる状況確認ではない。お互いの「手触り」を照らし合わせる行為だ。この対話の中で、事業の解像度が上がる。第三に、主体性が生まれる。仮説を持つと、「自分ごと」になる。この仮説が正しいかどうか、確かめたくなる。うまくいけば嬉しいし、間違っていれば悔しい。この感情が、仕事へのコミットメントを高める。私はエンジニアだ。だからコードを通じて事業を見る。セールスは対話を通じて、デザイナーは体験を通じて事業を見る。それぞれの「現場」からしか見えない景色がある。その景色を「仮説」という形にしてテーブルに乗せること。それが、私たちが戦略に参加する唯一の方法だ。現場は、戦略の「消費者」ではない。戦略の「参加者」になれる。そのためには、仮説を持つこと。問いを持つこと。それを声に出すこと。これが、現場と経営の距離、技術と事業の距離を縮める第一歩だ。戦略を語れ、責任を持ってここまで、戦略について長々と語ってきた。最後に、個人的な話をしたい。あの会議から、数年が経った。今も、お手伝いしてきた会社で、技術顧問として経営者たちと話をすることがある。会議で、誰かが「戦略」という言葉を使う。相変わらず、中身のない戦略が語られる。正直に言えば、私はそこで「それは戦略ですか」とは言えない。言えなかった。なぜなら、それは私の仕事の範疇を超えているからだ。技術顧問として呼ばれている。システムのアーキテクチャについて助言する立場だ。経営戦略に口を出すのは、越権行為だ。それでも、心のどこかで引っかかっている。本当に必要な場面であれば、立場を超えてでも言うべきではないのか。会社が明らかに間違った方向に進もうとしている時。誰も指摘しない時。そういう時こそ、言うべきではないのか。だが、言わない。言えない。その境界線がどこにあるのか、自分でもわからない。だから、内心では思っている。「その戦略で、どんな問題を解決するのか」。「その問題は、本当に最も重要な問題なのか」。「なぜ、その解決策なのか」。「他の選択肢は、検討したのか」。「何を捨てたのか」。これらの疑問が、頭の中を巡る。だが、口には出さない。出せない。立場が違う。責任の範囲が違う。その代わり、私は慎重に言葉を選ぶ。技術的な観点から、問いを投げかける。「その施策を実現するには、どんな技術的な課題がありますか」。「優先順位をつけるとしたら、どの順番で進めますか」。「リソースの制約を考えると、何かを諦める必要がありませんか」。気を使いながら、遠回しに。それでも、核心を突く問いを。これらの質問は、時に受け入れられる。時に、無視される。経営陣は、自分たちの「戦略」を語り続ける。ただ、不思議なことに、この経験が無駄になることはなかった。経営会議で言えなかったこと。内心で感じていたこと。絞り出した思考。気を使って口に出した言葉。すべて蓄積されていった。自分のチームを持った時、個人として仕事をする時、この経験が役に立った。エンジニアリングチームの方向性を決める時。技術的な選択をする時。プロジェクトの優先順位を決める時。そこでは、私は問うことができた。「この取り組みで、何を解決するのか」。「本当に、それが最も重要な課題なのか」。「なぜ、この方法なのか」。「他にやり方はないのか」。「何を捨てるのか」。チームメンバーと話す。一対一で。ホワイトボードの前で。Slackで。経営会議とは違う。ここでは、私が責任を持てる。私の範疇だ。だから、問える。そして、気づいた。戦略は、スケールの問題ではない。企業全体の戦略でも、チームの戦略でも、個人の戦略でも、根っこは同じだ。核心的な課題を見極める。解決策を見つける。何かを捨てる。実行する。経営会議で見てきた「戦略ごっこ」。あれを、自分のチームでは繰り返さない。そう決めた。チームの目標を立てる時。「全部やる」とは言わない。「これをやる。これはやらない」と明確にする。新しい技術を導入する時。「なんとなく良さそう」では進めない。「どの問題を解決するのか」を明確にする。プロジェクトの優先順位を決める時。「全部重要」とは言わない。「これが最重要。他は後回し」と決める。これは、不快だ。チームメンバーから反発されることもある。「なぜ、私のタスクは優先されないのか」。「なぜ、この技術は使わないのか」。それでも、説明する。なぜその判断をしたのか。何を最優先にしたのか。何を捨てたのか。時に、判断が間違っていることもある。やってみて、うまくいかない。その時は、認める。修正する。ただ、少なくとも、判断はしている。選択はしている。「全部やる」という逃げ方はしていない。これが、私なりの戦略だ。企業全体ではない。自分の責任範囲での戦略だ。それで十分だ。いや、それこそが核心だ。ただ、「小さな戦略で十分だ」と言っているが、それは「逃げ」ではないか。本当は、もっと大きな影響力を持ちたいのに、怖くて小さな範囲に留まっているだけだろう。「小さな戦略」という言葉で、自分の臆病さを正当化しているだけだろう。逆も考えられる。大きな戦略を語りたがる人の中には、目の前の小さな選択から逃げている人もいる。抽象的な「ビジョン」を語ることで、具体的な「何を捨てるか」から逃げている人。私は、少なくともそうはなりたくない。だから、小さな範囲でもいいから、選択し続ける。それが「逃げ」かどうかは、結果が教えてくれるだろう。戦略を立てるスキルは、3つの要素で形成される。第一に、本当に重要なものとそうでないものを見極める能力。第二に、その重要な問題が手持ちのリソースで解決可能かを判断する能力。第三に、リソースを集中投入する決断を下す能力。見極める。判断する。決断する。フレームワークでは学べない。理論でも教えられない。AIにも任せられない。では、どうやって身につけるのか。経験だ。失敗だ。振り返りだ。そして、自分の責任範囲で実践することだ。経営会議では言えなくても、自分のチームでは実践できる。そこで、何度も試す。何度も失敗する。何度も学ぶ。数年間、何度も失敗した。ある時、プラットフォームエンジニアとして、CI/CDパイプラインの刷新を提案した。分析は完璧だった。ビルド時間の短縮率も、デプロイ頻度の改善予測も計算した。しかし、導入されなかった。なぜなら、開発チームの理解が得られなかったからだ。彼らは、新しいパイプラインを信じていなかった。今のJenkinsで十分だと思っていた。彼らの視点を理解していなかった。だから、提案は受け入れられなかった。別の時、Kubernetesへの移行について相談された。コスト分析も、リスク分析も、移行計画も、調べて用意した。しかし、実行されなかった。なぜなら、組織がリスクを取れなかったからだ。今の運用で手一杯だった。新しい基盤に投資する余裕がなかった。組織の状況を理解していなかった。だから、提案は棚上げされた。自分のチームでも失敗した。開発者プラットフォームの改善プログラムを進めようとした。どこを改善すれば、どれだけ効果が出るか、細かく計算した。しかし、実行は中途半端に終わった。なぜなら、改善すべきものを明確にしなかったからだ。「全体的に改善しましょう」と言った。結果、誰もが「自分のところは変えなくていい」と思った。中途半端に変えて、効果も中途半端だった。選択する勇気がなかった。だから、失敗した。これらの失敗から、私は学んだ。戦略は、論理だけでは動かない。人を動かさなければならない。人を動かすには、彼らの視点を理解しなければならない。彼らの懸念を理解しなければならない。彼らの制約を理解しなければならない。戦略は、分析だけでは生まれない。判断が必要だ。「これが最重要だ」という判断。「これは捨てる」という判断。判断には、勇気が必要だ。間違うだろう恐怖と向き合う勇気が。戦略は、計画だけでは実現しない。実行が必要だ。実行には、コミットメントが必要だ。「これをやり遂げる」というコミットメント。困難に直面しても、諦めないコミットメント。論理。判断。コミットメント。この三つが揃って、初めて戦略は機能する。そして、これは、本を読むだけでは身につかない。理論を学ぶだけでは得られない。AIに聞いても教えてくれない。現場で、実際に戦略を作る。実行する。失敗する。振り返る。この繰り返しの中でしか、身につかない。経営は、科学ではない。人に依る。どれだけ理論を学んでも、どれだけデータを分析しても、最後は人の判断だ。その人が、どう見るか。どう感じるか。どう決めるか。そして、その判断は、再現性が低い。同じ状況でも、違う人なら、違う判断をする。同じ人でも、違うタイミングなら、違う判断をする。だから、経営には「正解」がない。あるのは、「その時、その人が、最善だと信じた選択」だけだ。これは、不安だ。頼りない。でも、これが現実だ。戦略を語る人は、多い。でも、戦略を作る人は、少ない。戦略を作ることは、快適ではないからだ。答えのない問いと向き合う。対立を引き受ける。リスクを負う。責任を取る。だからこそ、「語れ」と言いたい。しかし、責任を持って。美しい言葉を並べるだけではなく。フレームワークを使って終わりではなく。スライドを作って満足するのではなく。本当の戦略は、もっと地味だ。もっと泥臭い。現場を見る。数字を見る。人と話す。何度も考える。何度も見直す。何度も修正する。そして、決める。やると決める。やらないと決める。これが、戦略だ。企業全体の戦略を作ることは、私にはできない。立場が違う。責任の範囲が違う。でも、自分の責任範囲では、できる。そして、それで十分だ。小さな範囲でも、根っこは同じだからだ。問題を見極める。解決策を見つける。選択する。実行する。これができれば、それは戦略だ。私自身、最近やったことがある。自分の「責任範囲」で、今週中にやめると決められることを1つだけ、紙に書き出した。それをやめることで、どんなリソースが解放されるか考えた。そして、「戦略」という言葉を使わずに、これから1年の方針を「問題→選択→行動」の3行で書いてみた。書けた時、少しだけ、戦略を作る側に立てた気がした。そして、もう1つ。声に出すことの価値について。私は長いあいだ、「立場を超えて意見するのは越権行為だ」と思っていた。技術顧問は技術のことだけ言えばいい。経営戦略に口を出すのは筋違いだ。そう思っていた。でも、最近は少し考えが変わった。黙っていても、組織が良くなることはない。「これ、おかしいのではないか」と感じた時、黙っていれば波風が立たない。ただ、波風を立てないことと、組織を良くすることは別だ。誰かが声を上げなければ、おかしいことはおかしいままだ。もちろん、声の上げ方は重要だ。対立を煽る言い方ではなく、建設的な問いかけとして。「これは戦略ですか」と詰問するのではなく、「この戦略で解決したい最重要課題は何ですか」と問う。相手を追い詰めるのではなく、一緒に考える姿勢で。「おい、戦略を語れ」。このタイトルには、怒りがある。「おい」という呼びかけには、苛立ちがある。会議で空虚な戦略を語る人たちへの怒り。それもある。しかし、正直に言えば、怒りの多くは自分に向いている。かつての自分も、同じことをしていたから。今でも、完璧にはできていないから。「戦略を語れ」と他人に言いながら、自分は語れているのか。この怒りの裏には、期待がある。もっとうまくやれるはずだ、という期待。自分に対しても、組織に対しても。その期待が裏切られるたびに、怒りが生まれる。そして、その怒りを誰かにぶつけたくなる。「おい、戦略を語れ」と。しかし、怒りだけでは何も変わらない。怒りを、行動に変えなければならない。自分の責任範囲で、選択し続けること。声を上げ続けること。それが、怒りを建設的なものに変える唯一の方法だ。だから、この言葉は、他人に向けているようで、実は自分に向けている。お前は本当に戦略を語れているのか。中身のない言葉を並べていないか。選択から逃げていないか。そう自分に問いかけている。でも同時に、この言葉は、外に向けても発したい。会議で空虚な「戦略」が語られている時。誰もがうなずいているけれど、誰も本当には信じていない時。そういう時に、「それは本当に戦略ですか」と問いかける勇気を持ちたい。声を上げることは、リスクだ。嫌われるだろう。場の空気を壊すだろう。「余計なことを言う奴」と思われるだろう。それでも、本当に重要なことは、声に出さなければ伝わらない。心の中で思っているだけでは、何も変わらない。自分の責任範囲で戦略を実践すること。そして、必要な時には、声を上げること。この2つが揃って、初めて「戦略を語れ」というタイトルに応えられる気がする。「それだけ」の難しさ結局、戦略とは何なのか。長々と書いてきたが、煎じ詰めれば、やるべきことはシンプルだ。核心的な課題を見極めているか、確認する。その課題を本当に解決できているか、問い続ける。妥協なく、選択と集中ができているか、点検する。うまくいっていないなら、うまくいきそうな方に舵を切る。それだけだ。こう書くと、「そんなの当然だ」と感じるだろう。しかし、自分の仕事を振り返ってみてほしい。本当にこれができているだろうか。「課題を見極めているか」を確認するとは、自分たちの判断を直視することだ。これは、自分たちの見立て違いや判断ミスと向き合うことでもある。誰だって、自分が間違っていたとは認めたくない。だから、別の指標を見てしまう。納期に間に合ったか、予算内に収まったか、上司に怒られなかったか。「核心を突けているか」ではなく、「うまくやり過ごせているか」を見てしまう。仕事をしていると、いつの間にか「課題を解決する」という目的が薄れていく。たとえば、内部開発者プラットフォームの構築プロジェクト。最初は「開発者の生産性を上げる」という明確な目的があったはずだ。しかし、プロジェクトが進むにつれて、目的は変質していく。「Kubernetesクラスタを予定通りに構築する」「監視ツールを導入する」「経営層への報告をうまくまとめる」。気づけば、開発者が本当に使いやすいかどうかより、プロジェクトとして「成功」と言えるかどうかが関心事になっている。「課題を解決しているか」という問いは、常に意識しないと蒸発してしまう。なぜなら、その問いに向き合うのは苦しいからだ。解決できていないという不安と向き合わなければならない。「妥協なく」という言葉も、簡単ではない。妥協は悪意からではなく、善意や現実主義から生まれる。「この機能、完璧ではないけど、ないよりましだろう」「全員が満足するものを作れないから、ある程度のところで折り合いをつけよう」「理想を追求していたら、いつまでも終わらない」。一見、成熟した判断に見える。しかし、この「妥協」が積み重なると、最後に出来上がるものが「そこそこ」になる。誰も強く不満を言わないが、強く満足する人もいない。一応使えるが、積極的に使いたいとは思わない。「そこそこ」は、失敗より危険だ。失敗は直せる。「そこそこ」は直せない。明らかな失敗なら、原因を追求して改善できる。しかし「そこそこ」は改善の動機を奪う。「一応は使われている」「致命的な問題はない」という状態は、変化への意欲を殺す。その状態が何年も続いた先に、誰も欲しがらないが捨てることもできない、ゾンビのようなプロダクトやサービスが生まれる。「うまくいっていないなら、舵を切る」。この言葉の中で、最も実行が難しいのはこの部分だろう。まず、「うまくいっていない」と認めることが難しい。これまでの努力を否定することになるからだ。「方向性は間違っていないが、やり方に問題があった」「もう少し続ければ成果が出る」と思いたい。次に、「うまくいきそうな方向」を見つけることが難しい。うまくいっていないことは分かっても、代わりにどうすればいいかは分からない。だから、現状維持を選んでしまう。少なくとも、今のやり方なら「最悪ではない」ことは分かっている。未知の方向に舵を切るのは、博打に見える。では、この「それだけ」を実践するには何が必要なのか。目的を見失わない仕組み。日常の作業に埋没すると、なぜこれをやっているのかを忘れる。定期的に、しかも形式的にではなく真剣に、「何のためにやっているのか」を問い直す機会が必要だ。週に一度でも、チームで「これは本当に問題を解決しているか」と話し合う。その習慣があるかないかで、結果は大きく変わる。小さく試す文化。大きな賭けは、舵を切りにくくする。三年かけて作ったものを「やっぱりダメでした」とは言いにくい。しかし、二週間で作ったものなら、「これは違った、次を試そう」と言える。小さく作り、早く確認し、素早く方向修正する。このサイクルを速く回せる環境があれば、舵取りは格段に楽になる。失敗を許容する空気。「うまくいっていない」と言えるかどうかは、それを言った時に何が起こるかで決まる。責められるなら、誰も言わない。隠す。ごまかす。「うまくいっていない」という報告が、責任追及ではなく改善の起点として扱われる組織でなければ、正直な確認はできない。判断の軸を持つこと。舵を切る方向を決めるには、判断の軸が必要だ。「顧客の困りごとを減らす」「使う人の時間を節約する」「この体験を心地よくする」。何でもいい、しかし具体的で、検証可能な軸。それがあれば、「こっちの方がうまくいくだろう」という仮説を立てられる。軸がなければ、どこに舵を切っていいか分からない。「それだけ」という言葉は、謙遜ではない。本当に、やるべきことはそれだけなのだ。作れているかを見る。問題を解決しているかを問う。妥協しない。確認し続ける。必要なら方向を変える。しかし、この「それだけ」を本当に実践している組織やチームや個人は驚くほど少ない。私たちは目的を忘れ、妥協に流され、現実から目を逸らし、変化を恐れる。「それだけ」の中に、ものづくりの、いや、あらゆる仕事の核心がある。そして、その核心を貫くことの難しさと向き合い続けることが、良い仕事をするということなのだろう。おわりにここまで読んでしまった人がいるとしたら、申し訳ない気持ちが少しある。この文章を読んでも、明日から「戦略が立てられる人」にはならない。私自身がそうだったから分かる。本を読んだ直後は「分かった」と思う。会議で使えそうなフレーズをいくつかメモする。「核心的な課題を見極める」「何をやらないかを決める」。いい言葉だ。これを使えば、自分も戦略を語れる側の人間になれる気がする。でも翌週、いざ自分の仕事で使おうとすると手が止まる。「で、何から始めるんだっけ」。頭の中でフレーズは踊っているのに、目の前の仕事にどう適用すればいいか分からない。結局、また賢そうな顔をして会議に座っている。何も変わっていない。たぶん、戦略を立てる力は、戦略を立てることでしか身につかない。走り方の本を読んでも走れるようにならないのと同じだ。転んで、膝を擦りむいて、また走る。そうやってしか身につかない。身も蓋もないけど、そうとしか言いようがない。だから、この文章には限界がある。読んだだけでは何も変わらない。でも、もしかしたら、何かが引っかかるかもしれない。次の会議で「戦略」という言葉を聞いた時、「それ、本当に戦略？」と心の中でツッコめるようになったら、それだけで意味がある。自分のチームの方向性を考える時に「で、何を捨てるの？」という問いが頭をよぎるようになったら、それで十分だ。その小さな引っかかりが、いつか行動に変わるかもしれない。変わらないかもしれない。でも、引っかかりがなければ、変わる可能性すらない。正直に言えば、この文章は誰かのためというより、自分のために書いた。書きながら「お前、分かってないじゃん」と何度も思った。調べれば調べるほど、自分の理解の浅さが見えてくる。偉そうに「戦略とは何か」を語っているけど、じゃあお前は実践できているのか。そう問われたら、黙るしかない。「おい、戦略を語れ」という怒りは、他人への苛立ちではなかった。鏡に映った自分への問いかけだった。語れているのか。実行できているのか。逃げていないか。分かったふりを続けていないか。その問いに、まだ答えられていない。明日も会議がある。誰かが「戦略」と言うだろう。私はまた、眉間にしわを寄せて「なるほど」という顔をするだろう。それは変わらない。でも、今度は少しだけ、違う気持ちで聞けるかもしれない。「それ、本当に戦略？」と心の中で問いかけながら。その問いかけは、きっと会議室の誰かにではなく、自分自身に向けられている。そう思えるだけで、この長い文章を書いた甲斐はあった。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍ストーリーとしての競争戦略 Hitotsubashi Business Review Books作者:楠木 建東洋経済新報社Amazon戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon「暗記する」戦略思考　「唱えるだけで」深く、面白い「解」を作り出す破壊的なコンサル思考【電子限定特典付】作者:高松智史かんき出版AmazonArchitecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazonプラットフォームエンジニアリング ―成功するプラットフォームとチームを作るガイドライン作者:Camille Fournier,Ian Nowland,松浦 隼人（翻訳）オーム社AmazonKubernetesで実践する Platform Engineering作者:Mauricio Salatino翔泳社Amazonジョブ理論　イノベーションを予測可能にする消費のメカニズム作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションの経済学　「繁栄のパラドクス」に学ぶ巨大市場の創り方作者:クレイトン・Ｍ・クリステンセンHarperCollinsAmazonイノベーションのジレンマ 増補改訂版 Harvard business school press作者:Clayton M. Christensen翔泳社Amazon【Amazon.co.jp 限定】戦略のデザイン ゼロから「勝ち筋」を導き出す10の問い（ダウンロード特典：『戦略デザイン力』セルフ診断シート データ配信）: ゼロから「勝ち筋」を導き出す１０の問い作者:坂田 幸樹ダイヤモンド社Amazon良い戦略、悪い戦略 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon君は戦略を立てることができるか 視点と考え方を実感する４時間作者:音部大輔Amazon戦略的思考とは何か 改版 (中公新書 700)作者:岡崎 久彦中央公論新社Amazon戦略、組織、そしてシステム: 「組み立てる」戦略思考の方法論作者:横山　禎徳東洋経済新報社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~Redis lists編~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_data_list</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_data_list</guid>
            <pubDate>Sun, 14 Dec 2025 09:21:41 GMT</pubDate>
            <content:encoded><![CDATA[今回はredisで使えるlistsについてみていきます。先日公開したHashesについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_data_hash 早速検証redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis listsのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/lists/#performance ス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年版 PDE（Personal Development Environment）のすすめ：自分だけの刀を打つ開発環境構築]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/14/132552</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/14/132552</guid>
            <pubDate>Sun, 14 Dec 2025 04:25:52 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、Vim Advent Calendar 2025 13日目のエントリ記事です。はじめにVSCodeやJetBrains製品は、膨大な開発リソースを投じて作られた最強の武器だ。補完、デバッグ、Git統合、拡張機能——すべてが高度に洗練されている。多くの開発者にとって、これらを選ぶのは賢明な判断だと思う。それでも、私は自分で刀を打ちたい。ただし、誤解のないように言っておくと、名刀を打ちたいわけではない。美術館に飾られるような、完璧な一振りを目指しているわけではない。私が欲しいのは、戦場で戦うための道具だ。多少キズがあってもいい。見栄えが悪くてもいい。自分の手に馴染んで、明日の仕事で使えればそれでいい。では、なぜ自分で作るのか。正直に言えば、効率の問題ではない。もっと根本的な、性分の問題だ。思い返すと、私は子供の頃から構造や仕組みがどうしても気になって、分解してしまうクセがあった。おもちゃ、家電、何でも中がどうなっているか知りたくなる。そして仕組みを理解したら、自分なりに改修して「自分だけのもの」を作りたくなる。完成品を受け取るより、自分で手を入れる余地があるものに惹かれる。開発環境も同じだ。私は元々Vimユーザーで、その後Neovimに移行した。途中でVSCode、JetBrains、Cursorに浮気したこともある。どれも素晴らしいツールだった。だが、どうしても「自分で鍛えている」という感覚がなかった。「自分のもの」という実感が湧かなかった。具体的に言うと、こういうことだ。VSCodeを使っていたとき、settings.jsonをいじり、拡張機能を入れ替え、キーバインドを変え——気づけば「VSCodeをカスタマイズする」こと自体が目的になっていた。ならば、最初からカスタマイズ前提のツールを使えばいい。そう考えてNeovimに戻った。理由を論理的に説明するのは難しい。効率だけで言えば、IDEを使いこなす方が早いかもしれない。それでも、自分の手で環境を組み上げ、日々磨き、少しずつ自分の形に変えていく。その過程そのものに惹かれている。これは性分だ。こうした考え方には、実は名前がある。PDE（Personal Development Environment）——「個人開発環境」だ。自分のワークフローに最適化された、自分だけの開発環境を指す。私が10年かけてやってきたことは、まさにこのPDEの構築だった。この記事では、2025年現在の私のPDE構成を紹介する。Rust、Go、TypeScript、Pythonでの開発、そしてKubernetesやTerraformを使ったインフラ作業を想定した構成だ。IDEが合う人にはIDEを勧める。でも、もし「自分で作ってみたい」という気持ちがあるなら、この記事が参考になれば嬉しい。PDEとIDEの違いIDEは万人向けに最適化されており、インストール直後から高い生産性が得られる。学習曲線は緩やか、メンテナンスはベンダー任せ。一方PDEは個人最適化の代わりに、学習コストとメンテナンスを自分で負担する。どちらが優れているかではなく、「すぐ使える便利さ」と「自分で作る楽しさ」のトレードオフだ。もちろん、IDEにも自分の設定を入れられることは知っている。キーバインドを変更できるし、拡張機能は豊富だし、自分でプラグインを開発できる。VSCodeのsettings.jsonを何百行も書いた。それでも、私には「自分で作っている」という実感が足りなかった。論理的に説明するのは難しい。ただ、その実感の有無が、私にとっては大きかった。では、PDEとは結局何なのか。PDEの本質は「自分の手に馴染む道具を自分で作る」こと。職人が道具を磨くように、開発者も環境を育てていく。ただし、職人の道具は飾るためではなく使うためにある。PDEも同じだ。完璧な環境を作ることが目的ではなく、日々の開発で戦えることが目的だ。効率だけを求めるなら、IDEを使った方がいい場面も多い。私のPDE構成概要基盤はWarp Terminal。その上でFish Shellを動かし、プロンプトにはStarshipを使っている。エディタはNeovim（NvChadベース）で、LSPとTreesitterで補完とシンタックスハイライトを実現している。CLIツールはUnixの古典を現代版に置き換えた。lsの代わりにeza、catの代わりにbat、grepの代わりにripgrep。ディレクトリ移動はzoxide、リポジトリ管理はghq + fzf、差分表示はdeltaを使っている。AIアシスタントは複数導入しているが、主軸はClaude Code。Neovim内ではCopilotとAvanteも使っている。1. ターミナル：Warpwww.warp.devかつてはtmux + iTerm2の組み合わせを使っていた。しかし2024年、Warpに移行した。tmuxでやりたかったこと（ペイン分割、セッション管理）がWarp単体でできるし、見た目もかっこいい。使っていて特に不満もない。正直なところ、tmuxの設定をメンテナンスするのが面倒になっていた。tmux + Bash時代は.tmux.confが600行を超えていて、何がどう動いているのか自分でも把握しきれなくなっていた。現在はWarp + Fishという構成で、tmuxの設定は丸ごと不要になった。設定ファイルが減るのは精神衛生上とても良い。あと、Warpはモダンなターミナルらしく、補完がよく効く。コマンドを途中まで打つと候補が出てくる。tmux時代は「あのコマンドなんだっけ」とhistoryを漁ることが多かったが、その頻度が減った。気に入っている点ブロックベースの出力: コマンドの出力が独立したブロックとして扱われ、コピーや再利用が容易。長いログの一部だけコピーしたいときに便利セッション管理の内蔵: tmuxのペイン分割・セッション管理相当の機能が標準搭載。tmuxのプレフィックスキーを覚えなくていいAIアシスタント: 自然言語でコマンドを生成できる。正直あまり使っていないが、たまに「あのコマンドなんだっけ」というときに便利見た目: 単純にかっこいい。毎日使うものなので、見た目の満足度は意外と大事設定のポイント# ~/.warp/keybindings.yamlkeybindings:  # Vim風のペインナビゲーション  - command: move_focus_to_left_pane    keys: ctrl-h  - command: move_focus_to_right_pane    keys: ctrl-l  - command: move_focus_to_pane_above    keys: ctrl-k  - command: move_focus_to_pane_below    keys: ctrl-jtmuxの設定をメンテナンスする必要がなくなったのは大きい。.tmux.confの600行が不要になった。2. シェル：Fish Shellfishshell.comBashやZshではなくFishを選んだ理由は明確だ。設定なしで賢い。「それならIDEを使えばいいのでは」と思うかもしれないが、シェルは基盤だ。基盤が安定しているからこそ、その上で動くエディタやツールを自由にカスタマイズできる。すべてを自分で作る必要はない。Fish選択の決め手補完がすごい: 設定なしでコマンド履歴、ファイルパス、オプションを補完シンタックスハイライト: コマンド入力中にエラーが分かる設定の簡潔さ: ZshからFishに移行して、設定行数が600行から400行に減ったモダンCLIツール統合Unixの古典的コマンドを現代版に置き換えている。# ~/.config/fish/config.fish# ls → eza (icons + git status)if type -q eza    function ls --wraps eza        eza --icons --group-directories-first $argv    endend# cat → bat (syntax highlighting)if type -q bat    function cat --wraps bat        bat --paging=never $argv    endend# grep → ripgrep (faster + smarter)if type -q rg    function grep --wraps rg        rg $argv    endendgithub.comgithub.comgithub.com省略形（abbr）Fishにはabbr（abbreviation、省略形）という機能がある。入力してスペースを押すと、その場で展開される。# ~/.config/fish/config.fish# Git省略形abbr -a g gitabbr -a ga "git add"abbr -a gc "git commit"abbr -a gco "git checkout"abbr -a gd "git diff"abbr -a gp "git push"abbr -a gl "git pull"abbr -a gs "git status"abbr -a glog "git log --oneline --graph"# Docker省略形abbr -a d dockerabbr -a dc "docker compose"abbr -a dcu "docker compose up -d"abbr -a dcd "docker compose down"abbr -a dps "docker ps"# Kubernetes省略形abbr -a k kubectlabbr -a kgp "kubectl get pods"abbr -a kgs "kubectl get svc"abbr -a kgd "kubectl get deploy"abbr -a kd "kubectl describe"abbr -a kl "kubectl logs"abbr -a kex "kubectl exec -it"gsと入力してスペースを押すとgit statusに展開される。私がabbrを気に入っている理由は、展開後のコマンドが履歴に残ること、そして展開後に編集できることだ。Gitコマンドを1日に数十回打つ私にとって、この小さな省力化の積み重ねは大きい。ディレクトリ移動の革命：zoxidecdコマンドをzoxideで置き換えた。一度訪れたディレクトリは、部分一致でジャンプできる。# zoxideの有効化if type -q zoxide    zoxide init fish --cmd z | sourceend# 例：~/ghq/github.com/nwiizo/projectに移動z project  # これだけでOKgithub.comghq + fzf によるリポジトリ管理全てのリポジトリをghqで管理し、fzfで瞬時に移動する。function ghq_fzf_repo -d "Select repository with fzf"    set -l selected (ghq list -p | fzf \        --prompt="Repository: " \        --preview='ls -la {}')    if test -n "$selected"        cd $selected    endend# Ctrl+G でリポジトリ選択bind \cg ghq_fzf_repogithub.comdirenv による環境の自動切り替えプロジェクトごとの環境変数を.envrcで管理。ディレクトリに入ると自動で読み込まれる。# direnvの有効化（2025年現在のベストプラクティス）if type -q direnv    set -g direnv_fish_mode eval_on_arrow    direnv hook fish | sourceenddirenv.net3. プロンプト：Starshipstarship.rsStarshipは、Rustで書かれた高速なクロスシェルプロンプト。Git状態、言語バージョン、クラウド環境を一目で確認できる。# ~/.config/starship.tomlformat = """$directory\$git_branch\$git_status\$golang\$rust\$python\$kubernetes\$cmd_duration\$line_break\$character"""[character]success_symbol = "[❯](bold green)"error_symbol = "[❯](bold red)"[kubernetes]symbol = "☸ "disabled = falseKubernetes contextが常に表示されるので、本番環境で作業しているか一目で分かる。これで何度か事故を防げた。4. エディタ：Neovim + NvChadneovim.ionvchad.comVim/Neovimを使い始めて10年以上になる。途中でVSCode、JetBrains、Cursorを試したこともあるが、どれも1ヶ月以上メインに居座ったことはない。併用はしても、結局Neovimに戻ってきた。VSCodeもJetBrainsも素晴らしいエディタで、今でもそう思っている。ただ、私は自分で環境を組み立てたかった。その欲求が、他のエディタでは満たされなかった。2025年版 Minimal UI アーキテクチャ2025年の私のNeovim設定で最も特徴的なのは、statusline-less workflowだ。従来のstatuslineやtabuflineを廃止し、必要な情報のみをfloating windowで表示する。編集領域を最大化しつつ、必要な情報は失わない。 コンポーネント  プラグイン  役割  ファイル情報  incline.nvim  右下floating statusline  モード表示  modes.nvim  cursorline色でモード表示  コマンドライン  noice.nvim  floating cmdline (cmdheight=0)  バッファ薄暗化  vimade  非アクティブバッファをdim  コードピーク  overlook.nvim  LSP定義をstackable popup表示  ファイル選択  Snacks.nvim  smart pickerでbufferline代替 github.comincline.nvimは画面右下に小さなfloating windowでファイル情報を表示する。ファイルアイコン、ファイル名、未保存マーク、診断数が一目で分かる。init.luaのような汎用的なファイル名の場合は親ディレクトリも表示される（plugins/init.luaのように）。github.commodes.nvimはInsert/Visual/Deleteなどのモードをcursorlineの色で表現する。Insertはシアン、Visualは紫、Deleteは赤。-- INSERT --のようなテキスト表示が不要になり、視覚的に直感的。-- options.lua での設定vim.o.cmdheight = 0      -- コマンドライン非表示（noice.nvimが代替）vim.o.laststatus = 0     -- statusline非表示（incline.nvimが代替）vim.o.showmode = false   -- モード表示非表示（modes.nvimが代替）キーマップの発見性：which-key.nvimgithub.com2025年のNeovim設定で欠かせないのがwhich-key.nvimだ。キーを押すと、次に押せるキーの一覧がポップアップで表示される。「あのキーマップなんだったっけ」という問題が解消される。{  "folke/which-key.nvim",  opts = {    preset = "helix",    spec = {      { "<leader>a", group = "AI" },      { "<leader>g", group = "Git" },      { "<leader>s", group = "Search" },      { "<leader>x", group = "Diagnostics" },    },  },  keys = {    { "<leader>?", function() require("which-key").show() end, desc = "Buffer Keymaps" },  },}<leader>を押して少し待つと、aでAI、gでGit、sでSearch...とグループ分けされたキーマップが表示される。新しいプラグインを入れてもキーマップを覚える必要がない。ナビゲーションSnacks.nvim - 2025年のモダンユーティリティ集。github.comSnacks.nvimはfolke氏による新しいプラグインで、picker、lazygit統合、buffer削除などを統合している。特にsmart pickerが便利で、ファイル・バッファ・最近使用したファイルを一つのインターフェースで検索できる。{  "folke/snacks.nvim",  keys = {    { "<leader><leader>", function() Snacks.picker.smart() end, desc = "Smart Picker" },    { "<leader>gg", function() Snacks.lazygit.open() end, desc = "LazyGit" },    { "<leader>sf", function() Snacks.picker.files() end, desc = "Find Files" },    { "<leader>sg", function() Snacks.picker.grep() end, desc = "Grep" },  },}lazygit統合ではeditPreset = "nvim-remote"を設定することで、lazygit内でファイルを開くと現在のNeovimインスタンスで開かれる。別ウィンドウが立ち上がらない。Telescope - 検索のハブ（サブとして併用）。github.com{  "nvim-telescope/telescope.nvim",  keys = {    { "<leader>ff", "<cmd>Telescope find_files<cr>", desc = "Find Files" },    { "<leader>fg", "<cmd>Telescope live_grep<cr>", desc = "Live Grep" },    { "<C-p>", "<cmd>Telescope find_files<cr>", desc = "Find Files" },  },}oil.nvim - ファイルシステムをバッファとして編集。github.comneo-treeのようなツリー表示ではなく、ファイルシステムを通常のバッファとして扱う。ファイル名の変更は行の編集、削除は行の削除。Vimユーザーには直感的。{  "stevearc/oil.nvim",  keys = {    { "-", "<cmd>Oil<cr>", desc = "Open parent directory" },  },}flash.nvim - 画面内の任意の位置にジャンプ。github.comsを押して文字を入力すると、その文字にラベルが表示される。ラベルを押すとジャンプ。hop.nvimの後継で、メンテナンスも活発。overlook.nvim - コードピーク。github.comLSPの定義をfloating popupで表示する。ファイルを開かずに定義を確認できる。popupはスタック可能で、複数の定義を同時に表示できる。{  "WilliamHsieh/overlook.nvim",  keys = {    { "<leader>pd", function() require("overlook").open_definition() end, desc = "Peek Definition" },    { "<leader>pc", function() require("overlook").close_all() end, desc = "Close All Popups" },  },}診断・デバッグtrouble.nvim v3 - 診断情報のUI。github.com2024年にv3として完全書き直しされた。ツリービュー対応で、エラーの階層構造が見やすい。{  "folke/trouble.nvim",  keys = {    { "<leader>xx", "<cmd>Trouble diagnostics toggle<cr>" },    { "<leader>xX", "<cmd>Trouble diagnostics toggle filter.buf=0<cr>" },    { "<leader>xs", "<cmd>Trouble symbols toggle<cr>" },  },}todo-comments.nvim - TODO/FIXME/NOTEのハイライト。コード内のTODOコメントを自動検出してハイライト。Telescopeと連携してプロジェクト全体のTODOを一覧表示できる。Git統合gitsigns.nvim - インラインGit情報。github.com変更行の横にサイン（│）が表示される。hunk単位でのステージ、リセット、プレビューが可能。{  "lewis6991/gitsigns.nvim",  opts = {    on_attach = function(bufnr)      local gs = package.loaded.gitsigns      vim.keymap.set("n", "]c", gs.next_hunk, { buffer = bufnr, desc = "Next Hunk" })      vim.keymap.set("n", "[c", gs.prev_hunk, { buffer = bufnr, desc = "Prev Hunk" })      vim.keymap.set("n", "<leader>gp", gs.preview_hunk, { buffer = bufnr, desc = "Preview Hunk" })      vim.keymap.set("n", "<leader>gb", function() gs.blame_line { full = true } end, { buffer = bufnr, desc = "Blame Line" })    end,  },}diffview.nvim - Git diffの可視化。github.comGit差分をNeovim内で確認できる。ファイル履歴も見やすい。2025年版では、より多くのキーマップを設定している。{  "sindrets/diffview.nvim",  keys = {    { "<leader>gd", "<cmd>DiffviewOpen<cr>", desc = "Git Diff (working tree)" },    { "<leader>gD", "<cmd>DiffviewOpen HEAD~1<cr>", desc = "Diff vs previous commit" },    { "<leader>gh", "<cmd>DiffviewFileHistory %<cr>", desc = "File History" },    { "<leader>gH", "<cmd>DiffviewFileHistory<cr>", desc = "Branch History" },    { "<leader>gm", "<cmd>DiffviewOpen main...HEAD<cr>", desc = "Diff vs main branch" },    { "<leader>gs", "<cmd>DiffviewOpen --staged<cr>", desc = "Staged changes" },    { "<leader>gq", "<cmd>DiffviewClose<cr>", desc = "Close Diffview" },  },}Diffview内では-でステージ/アンステージ、Sで全てステージ、Xで変更を復元。コンフリクト解決も<leader>co（ours）、<leader>ct（theirs）で直感的に操作できる。LSP設定Mason.nvimで言語サーバーを管理。主要な言語はすべてカバー。ensure_installed = {  -- Rust  "rust-analyzer",  -- Go  "gopls", "gofumpt", "goimports",  -- TypeScript/JavaScript  "typescript-language-server", "prettier",  -- Python  "pyright", "black", "isort",  -- Infrastructure  "terraform-ls", "yaml-language-server",  -- Shell  "bash-language-server", "shellcheck",}2025年のポイントとして、JSON/YAMLにはSchemaStoreを統合している。package.jsonやdocker-compose.ymlの補完がスキーマベースで効くようになる。github.com5. AIアシスタント統合2024年から2025年にかけて、開発環境で最も大きく変わったのはAIの存在だ。コード補完、生成、レビュー、デバッグ——あらゆる場面でAIが介在するようになった。2025年のPDEにおいて、AIツールは最も重要な要素になっている。私は複数のAIツールを導入しているが、主軸はClaude Codeだ。Claude Code - 開発の中心docs.anthropic.comターミナルで起動し、コード生成、リファクタリング、デバッグ、質問——ほとんどの作業をClaude Codeで完結させている。私の使い方の特徴は、プロジェクトごとにカスタマイズしている点だ。やっていることはシンプルで、3つのファイルを育て続けている。project/├── CLAUDE.md              # プロジェクト固有の指示├── .claude/│   ├── commands/          # カスタムスラッシュコマンド│   │   ├── review.md│   │   └── test.md│   └── agents/            # 特化型エージェント│       └── reviewer.mdCLAUDE.md にはプロジェクトの文脈を書く。使用技術、コーディング規約、避けるべきパターンなど。これがあるとClaude Codeの回答精度が劇的に上がる。commands にはよく使う操作をスラッシュコマンドとして定義する。/reviewでコードレビュー、/testでテスト生成など。毎回同じプロンプトを書く手間が省ける。agents には特定タスクに特化したエージェントを定義する。レビュー専門、リファクタリング専門など、役割を分けることで精度が上がる。重要なのは、これらを使いながら修正し続けること。「この指示だと意図と違う結果になる」と気づいたらCLAUDE.mdを更新する。コマンドの出力が物足りなければcommandを調整する。PDEと同じで、日々の開発の中で育てていく。Neovimとの連携にはclaude-code.nvimを使っている。github.com{  "greggh/claude-code.nvim",  keys = {    { "<leader>cc", "<cmd>ClaudeCode<cr>", desc = "Claude Code" },    { "<leader>cr", "<cmd>ClaudeCodeResume<cr>", desc = "Resume Conversation" },  },}<leader>ccでClaude Codeのターミナルウィンドウをトグル。エディタで開いているファイルをそのままClaude Codeに渡せる。Neovim内のAIツールNeovim内ではCopilotとAvanteを併用している。github.comCopilotはインライン補完用。コードを書いている最中に候補が表示され、Tabで確定する。考えながら書くときに便利。copilot-cmpと組み合わせて、補完メニューの最上位にCopilotの提案が表示されるようにしている。github.comCopilotChatはAIチャット用。コードの説明、修正、テスト生成、ドキュメント生成などをチャット形式で行える。モデルはclaude-sonnet-4を使用。{  "CopilotC-Nvim/CopilotChat.nvim",  opts = { model = "claude-sonnet-4" },  keys = {    { "<leader>ao", "<cmd>CopilotChatOpen<cr>", desc = "Open Chat" },    { "<leader>ae", "<cmd>CopilotChatExplain<cr>", desc = "Explain Code", mode = { "n", "v" } },    { "<leader>af", "<cmd>CopilotChatFix<cr>", desc = "Fix Code", mode = { "n", "v" } },    { "<leader>at", "<cmd>CopilotChatTests<cr>", desc = "Generate Tests", mode = { "n", "v" } },    { "<leader>ad", "<cmd>CopilotChatDocs<cr>", desc = "Generate Docs", mode = { "n", "v" } },    { "<leader>aR", "<cmd>CopilotChatReview<cr>", desc = "Review Code", mode = { "n", "v" } },  },}github.comAvanteはCursorエディタのAI機能をNeovim上に再現するプラグイン。ファイル横断の変更や設計相談に使う。<leader>aaで質問すると、サイドパネルが開いてAIとの対話が始まる。{  "yetone/avante.nvim",  opts = {    provider = "copilot",    mode = "agentic",    providers = {      copilot = { model = "claude-sonnet-4" },    },    mappings = {      ask = "<leader>aa",      edit = "<leader>ax",    },  },}AI統合のキーマップまとめ キー  プラグイン  説明  <leader>aa  Avante  AI質問  <leader>ao  CopilotChat  チャットを開く  <leader>ae  CopilotChat  コードを説明  <leader>af  CopilotChat  コードを修正  <leader>at  CopilotChat  テスト生成  <leader>ad  CopilotChat  ドキュメント生成  <leader>aR  CopilotChat  コードレビュー  <leader>cc  Claude Code  Claude Code起動  <leader>cr  Claude Code  会話を再開 6. 言語別の設定Rustは私のメイン言語なので、専用プラグインを導入している。rustaceanvimでrust-analyzerを強化し、crates.nvimでCargo.tomlのバージョンを管理する。Cargo.tomlを開くと、各クレートの最新バージョンがインラインで表示される。github.comgithub.comGo、TypeScript、Pythonは特別な設定をしていない。LSP設定セクションで示したensure_installedにより、各言語サーバーが自動でセットアップされる。保存時の自動フォーマットはconform.nvimに任せている。詳細な設定はdotfilesリポジトリを参照してほしい。7. フォーマッター統合conform.nvimで保存時に自動フォーマット。言語ごとに適切なフォーマッターを設定。{  "stevearc/conform.nvim",  opts = {    formatters_by_ft = {      lua = { "stylua" },      rust = { "rustfmt" },      go = { "gofmt", "goimports", "gofumpt" },      python = { "black", "isort" },      typescript = { "prettier" },      javascript = { "prettier" },      yaml = { "prettier" },      json = { "prettier" },      markdown = { "prettier" },    },    format_on_save = { timeout_ms = 500, lsp_fallback = true },  },}github.comPDEを育てるということPDEは完成することがない。日々の開発の中で、少しずつ手を入れ続ける。刀から庭へこの記事のタイトルには「刀を打つ」と書いた。実際、PDEには刀を打つ行為がある。ターミナルを選び、シェルを設定し、エディタを組み上げる。ゼロから自分の道具を作り上げていく。ただ、刀には完成がある。名刀は打ち上がれば、あとは研ぎ澄ますだけ。床の間に飾られ、鑑賞される。しかしPDEには完成がない。プラグインは更新され、新しいツールが登場し、自分の作業スタイルも変わる。「完成した」と思った翌週には、また何かをいじっている。最初は名刀を打つつもりだった。「理想の開発環境を作り上げる」という完成形を目指していた。だが10年経って気づいた。私が欲しかったのは名刀ではなく、戦場で使える道具だった。戦場で使える道具とは何か。それは、完成を待たずに使い始められるものだ。使いながら調整し、壊れたら直し、足りなければ足す。常に未完成で、常に変化している。ここで気づいた。私がやっていることは、刀を打つだけではない。打った刀を、日々手入れし続けている。使いながら研ぎ、傷がつけば直し、必要に応じて改良する。この「手入れし続ける」という感覚——何かに似ている。そうだ、庭だ。庭も完成しない。季節ごとに姿を変え、草木は勝手に育ち、手入れを怠れば荒れる。人間が設計するが、人間の思い通りにはならない。それでも手を入れ続けることで、少しずつ自分の形になっていく。宇野常寛さんの『庭の話』という本が、この感覚を言語化してくれた。www.kodansha.co.jp宇野さんは、現代のプラットフォーム（SNS）を「相互評価のゲームに特化した空間」として批判し、対抗概念として「庭」を提示する。プラットフォームが画一化された承認欲求の交換の場であるのに対し、庭は「完全にはコントロールできないもの」との共存の場だ。草木が勝手に育ち、虫が飛び交い、季節によって姿を変える。人間が設計するが、人間の思い通りにはならない。この説明を読んだとき、私は自分のPDEのことを思い浮かべた。プラグインが勝手にアップデートされ、設定が壊れ、新しいツールが登場する。思い通りにならない。でも、手を入れ続けることで、少しずつ自分の形になっていく。宇野さんの言う「プラットフォーム」と「庭」の対比は、そのまま開発環境にも当てはまる。IDEはプラットフォームだ。ベンダーが設計し、万人に最適化されたサービスを提供する。ユーザーはそれを消費する。便利で、効率的で、すぐに使える。しかし、自分でコントロールできる範囲は限られている。一方、PDEは刀を打ち、庭として育てるものだ。自分で道具を作り、その道具を手入れし続ける。プラグインが競合し、設定が壊れ、アップデートで挙動が変わる。それでも、手を入れ続けることで、少しずつ自分の形になっていく。消費ではなく、制作。受け取るのではなく、育てる。宇野さんは「消費から制作へ」という転換を説く。プラットフォームで承認を求めるのではなく、制作に没頭すること。エンジニアとして、私たちは「正解」を求めがちだ。最適解を見つけ、効率を最大化し、その成果で報われたいと思う。だが、PDEにはそういう正解がない。「正しい設定」も「最適なプラグイン構成」も存在しない。ネットで見つけた「おすすめ設定」をコピペしても、それは自分の刀にはならない。正解を求めて報われようとするのをやめる。他者から評価される「模範解答」を探すのではなく、自分の手に馴染む道具を、自分のために作る。PDEを構築する行為は、まさにこの「制作」だ。誰かに見せるためではなく、自分のために作る。その過程で、ツールとの対話が生まれる。「家庭」という言葉は「家」と「庭」でできている。宇野さんは「家」の内部で承認を交換するだけでは見えないものが「庭」にはあると言う。開発環境も同じだ。IDEという「家」の中で完結するのではなく、PDEという「庭」に出ることで、ツールとの新しい関係が見えてくる。ツールと思考の相互作用ツールとの新しい関係とは何か。PDEを10年実践する中で、1つ気づいたことがある。ツールは思考に影響し、思考はツールに影響される。これは単なる比喩ではない。以前、AIエージェントとの協働について書いた記事で、私は「集中とは自分の能力ではなく環境との関係である」と述べた。syu-m-5151.hatenablog.com環境との関係——これはPDEにも当てはまる。具体的な例を挙げよう。Vimのモーダル編集を使い始めると、テキスト操作を「動詞＋名詞」で考えるようになる。d（削除）+ w（単語）で「単語を削除」。この思考パターンは、コードを書くときの発想にも影響する。操作を小さな単位に分解し、組み合わせて目的を達成する。逆に、自分の思考スタイルに合わないツールは、どれだけ高機能でも使いこなせない。合わないものは合わない。それだけのことだ。重要なのは、この相互作用を意識的に活用することだ。新しいツールを導入するとき、私は「このツールは自分の思考をどう変えるか」を考える。AIエージェントを使い始めたとき、深く没入する集中から、複数タスクを並行監視する集中へと、思考のモードを切り替える必要があった。環境が変われば、思考も変わるべきなのだ。PDEとは、単にツールをカスタマイズすることではない。自分の思考とツールの関係を最適化し続けることだ。AIは庭の一部か、庭師か2025年のPDEを語る上で、AIツールの位置づけは避けて通れない。私はClaude Codeを「主軸」と書いた。しかし、これは従来のツールとは異なる存在だ。Neovimは私が設定し、私が操作する。一方Claude Codeは、私と対話し、私の意図を解釈し、時に私が思いつかなかったアプローチを提案する。これは庭の一部なのか、それとも共に庭を育てる存在なのか。正直に言えば、まだ答えは出ていない。ただ、1つ確かなことがある。CLAUDE.mdを更新し、カスタムコマンドを調整し、エージェントを育てる——この作業は、Neovimのプラグイン設定と同じ感覚だ。AIツールもまた、PDEの一部として「育てる」対象になっている。同時に、Claude Codeは私のPDEを育てる側でもある。「この設定、冗長では」「こういうプラグインがある」と提案してくる。人間が庭を育て、庭が人間を育てる。その関係がAIツールとの間にも成り立っている。私のPDE改善サイクルでは、具体的にどうやってPDEを育てているのか。私の場合、こんなサイクルを回している。気づく: 「この操作、毎日10回はやってるな」調べる: 既存のプラグインや設定で解決できないか試す: 設定を追加して数日使ってみる磨く: 使いにくければ調整、良ければ定着このサイクルを回し続けていると、つい完璧を目指したくなる。だが、ここで立ち止まる必要がある。すべてを自作する必要はない。すべてをOSSで揃える必要もない。それをやると疲れる。Fish、Warp、Starshipを選んだのも「設定なしで賢い」からだ。力を入れるところと抜くところを分ける。適度にやっていくことが、PDEを長く続けるコツだと思う。これもまた、刀を打ち、庭として育てることの本質だ。名刀を打つなら妥協は許されない。だが戦場で使う刀は違う。多少キズがあっても戦えればいい。庭も同じだ。すべてを自分で育てる必要はなく、買ってきた苗を植えてもいい。大事なのは、戦場で戦えること。実際の開発で使えること。完璧な道具を作ることではない。設定ファイルの管理dotfilesはGitで管理。どのマシンでも同じ環境を再現できる。dotfiles/├── fish/           # Fish shell├── nvim/           # Neovim├── warp/           # Warp terminal├── starship/       # Starship prompt└── git/            # Git config5年後、PDEは存在するかAIの進化を見ていると、ふと考えることがある。5年後、開発環境を「自分で構築する」という行為に意味はあるのか。AIがコードを書き、テストを実行し、デプロイまで行う時代が来るかもしれない。そのとき、エディタの設定にこだわる意味があるのか。Neovimのキーバインドを覚える価値があるのか。正直に言えば、分からない。5年後の開発がどうなっているか、誰にも予測できない。ただ、こうも思う。むしろ逆かもしれない、と。従来、PDEの構築には学習コストとメンテナンスコストがかかり、それに見合う生産性向上が得られるかは不透明だった。しかしAIは、このトレードオフを限りなく等価に近づけてくれる。環境を改善すれば、その改善がAIを介して直接生産性に反映される。CLAUDE.mdを1行書き足せば、その分だけAIの出力が良くなる。PDEが「趣味」から「現実的に有効な投資」になる時代が来ているのかもしれない。ただ、1つだけ確信していることがある。「自分で作りたい」という欲求は消えない。ツールが変わっても、プラットフォームが変わっても、「与えられたものをそのまま使うのではなく、自分の手を入れたい」という欲求は残る。少なくとも、私はそういう人間だ。AIがすべてを生成する時代が来ても、そのAIをどう使うか、どうカスタマイズするか、どう自分のワークフローに組み込むか——そこにPDEの精神は生き続けると思う。道具は変わっても、道具との関係を自分で設計したいという欲求は変わらない。まとめここまで私のPDE構成を紹介してきた。Warp上でFishを動かし、NeovimとClaude Codeを併用する——これらを組み合わせて、自分だけの「刀」を作り上げて「庭」を育てている。PDEを選ぶ理由は効率では説明できない。最初の2週間は生産性が落ちるし、1ヶ月かけて元に戻る。それでも、自分で組み上げ、日々改善していく過程そのものに価値がある。消費ではなく制作、受け取るのではなく育てる。だからといって、完璧を目指す必要はない。名刀を打つ必要はない。すべてを自作する必要もない。大事なのは、明日の開発で戦えること。そのために、今日少しだけ環境を良くする。その繰り返しがPDEだ。もし「自分で作ってみたい」という気持ちがあるなら、試してみてほしい。合わなかったら戻ればいい。IDEという最強の武器は、いつでもそこにある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。この記事で紹介した設定ファイルは以下のリポジトリで公開している。github.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Raycast Extension 開発のすすめ]]></title>
            <link>https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev</link>
            <guid isPermaLink="false">https://zenn.dev/iorandd/articles/20251215_start-raycast-extension-dev</guid>
            <pubDate>Sat, 13 Dec 2025 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本記事は 3-shake Advent Calendar 2025 14日目の記事です。Raycast Advent Calendar 2025 でも2025年10月下旬に行われたRaycast Community Japan 主催イベントに3連続で参加した話を書きます。Raycast Extension開発やコミュニティに興味を持ったきっかけとなったイベントなので、よければ読んでください。この記事ではRaycast Extension をローカルで作ってStoreに出すまでの手順を解説します。 1. Extensionを作るべき理由 RaycastとはRaycast は...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[デタッチドマウントとコンテナランタイム]]></title>
            <link>https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7</link>
            <guid isPermaLink="false">https://qiita.com/ys1/items/eac9727ec1d4e71a3cd7</guid>
            <pubDate>Sat, 13 Dec 2025 11:58:19 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ13日目の記事です。最近、低レベルコンテナランタイムである youki にコントリビュートしており、特にデタッチドマウントについて調べる機会があったので、その内容を共有しま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『おい、テックブログを書け』というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/13/145159</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/13/145159</guid>
            <pubDate>Sat, 13 Dec 2025 05:51:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに正直に言うと、私はキャリアの序盤、破滅的な文章を書く人間だった。誰が読むのか考えていない文章を書きまくっていた。学生時代に読書感想文のコンクールで優勝したこともなければ、文章を褒められた経験もほとんどない。それでも書き続けて、今はこうして登壇の機会をいただけるようになった。2025年12月5日、Forkwell Communityのイベント「おい、テックブログを書け」で登壇しました。forkwell.connpass.com発表資料はこちらです。 speakerdeck.com「おい、」シリーズがイベントになった私は「おい、」シリーズというブログを書いている。元々は書籍用に書き溜めていた文章を公開する場所として始めたものだが、ありがたいことに多くの反響をいただいている。syu-m-5151.hatenablog.com今回のイベントは、Forkwellのかわまたさんにお誘いいただいて実現した。かわまたさんには以前も「転職したらMCPサーバーだった件」というイベントでお声がけいただいた。 speakerdeck.com貴重な登壇の機会をいただいているのにこんなことを言うのはあれだが、結構変なことをさせてくれる。変な人だ（褒めている）。自分もこれぐらいふざけた企画をできるくらい組織で信用されたい。とめちゃくちゃに思う。こうした機会をもらえるのは、発信を続けてきたからだ。私よりエンジニアとしても語り手や書き手としても才能のある人はたくさんいる。でも、その才能を発揮せずに誰からも見つからないままでいる人も多い。なぜ発信しないのか。まず、炎上が怖い。間違ったことを書いたら叩かれるんじゃないか。知識不足を晒して恥をかくんじゃないか。そう思うと、公開ボタンを押す手が止まる。次に、時間がない。業務が終わってから記事を書くのは大変だ。言いたいことを整理して、文章にまとめて、推敲して。そこまでの気力が残っていない日も多い。組織の問題もある。評価制度が発信を評価しない会社では、ブログを書いても給料は上がらない。それどころか「そんな暇があったらコードを書け」と言われることもある。発信は「業務外の趣味」として扱われる。こうした障壁は確かに存在する。でも、それらすべてを解決してから書き始める必要はない。まず書いてみることなら、今日からでもできる。炎上が怖いなら、小さな技術メモから始めればいい。時間がないなら、完璧を目指さず短い記事でいい。組織が変わらなくても、自分のブログは自分で始められる。書き始めるとき、人は出発点ばかり気にしがちだ。「自分には文章の才能がない」「最初からうまく書ける人には敵わない」──そう思って発信をためらう人がいる。でも、書く力は後天的になんとかなる。出発点が低くても、続けていれば追いつける。追い越せることだってある。見てくれた皆さんには、発信やアウトプットを通じて才能を発揮し、それに見合った評価や機会を得てほしい。そう思って今回の登壇資料を作った。書くときに大切にしていること資料では「どう書くか」の型を紹介したが、その前提にある考え方も書いておきたい。私が意識しているのは3つある。「なぜ」を問うこと、「変化」を描くこと、「ゆらぎ」を残すこと。この3つは独立しているようで、実は重なり合っているので紹介していきたい。「なぜ」を問い続ける単なる事実や記録ではなく、理由や背景を深掘りする姿勢が大切だ。たとえば「Aを使った」だけでなく「なぜAを選んだのか」「なぜBではダメだったのか」を書く。読者が最も知りたいのは「なぜ」の部分だ。選択の理由を言語化することで、自分の理解も深まる。ところが、技術ブログでありがちなのは、手順だけを淡々と書いてしまうこと。「この設定を入れます」「このコマンドを実行します」──それだけでは公式ドキュメントの劣化コピーになる。「なぜこの設定なのか」「なぜこの順番なのか」「なぜ他の方法ではダメだったのか」を書くことで、初めて読む価値が生まれる。「なぜ？」の部分が業務事情に抵触する場合もある。具体的な数値や社内の意思決定プロセスは書けない。そういうときは、一般的な観点に置き換える工夫をすればいい。「弊社の事情で」ではなく「〇〇のようなケースでは」と書く。具体的な比較ができないなら「一般的にAとBにはこういう違いがある」と整理する。工夫次第で、機密を守りながら「なぜ」を伝える方法はいくらでもある。「なぜ？」を問い続けると、自分の理解の浅さに気づくこともある。それでいい。書くことは、自分の理解を試す行為でもある。書けないということは、わかっていないということだ。その気づきこそが成長の起点になる。「行動」と「変化」のあるストーリーにする「なぜ」を問い続けていると、自然と「変化」が見えてくる。最初はこう思っていた、でも調べていくうちにこう変わった。その変化こそが、記事の核になる。人は変化の物語に心を動かされる。問題に出会い、試行錯誤し、解決に至る。その過程で自分の理解がどう変わったか。「わからない」から「わかった」への変化こそが、読者にとって価値のある情報だ。だから、静的な情報の羅列は退屈だ。「Kubernetesのリソース制限には以下の種類があります」と書くより、「OOMKilledで3時間溶かした。原因を調べていくうちに、リソース制限の仕組みが腹落ちした」と書く方が読まれる。同じ情報でも、変化の物語として語ることで、読者は追体験できる。行動と変化を意識すると、自然と時系列が生まれる。最初に何を思っていたか、何をしたか、何が起きたか、どう理解が変わったか。この流れがあるだけで、記事は格段に読みやすくなる。そして、変化には「失敗」も含まれる。むしろ失敗からの学びの方が読者には刺さる。「最初からうまくいきました」という記事より、「こう考えて失敗し、別のアプローチで解決した」という記事の方が、読者の記憶に残る。失敗を隠さず、そこから何を学んだかを書くことで、記事に深みが出る。「気持ちのゆらぎ」を素直に残す失敗を書くとき、その時の迷いや不安も一緒に残しておくといい。整いすぎた文章は、かえって心に響かない。なぜか。人間味が消えてしまうからだ。「最初は〇〇だと思っていたけど、実際は違った」「正直、これでいいのか迷った」「ここは今でも自信がない」──そうした揺れを正直に書くことで、読者との距離が縮まる。完璧を装う必要はない。技術ブログを書くとき、つい「わかっている人」として振る舞いたくなる。でも、読者が共感するのは「わかっていなかった人がわかるようになる過程」だ。迷い、間違え、遠回りした経験こそが、読者にとって価値がある。気持ちのゆらぎを残すことには、もう1つ意味がある。後から読み返したとき、その時の自分に出会える。「あの頃はこんなことで悩んでいたのか」と思えるのは、整いすぎていない文章だからこそだ。ゆらぎを残すことに抵抗がある人もいるだろう。弱く見えるのではないか、と。でも私の考えは違う。ゆらぎを残すことは、弱さを見せることではない。誠実さを見せることだ。「これが正解です」と断言する記事より、「私はこう考えてこうした、でも別の方法もあるかもしれない」と書く記事の方が、読者は信頼する。技術の世界に絶対の正解は少ない。その不確かさに正直であることが、かえって記事の信頼性を高める。おわりに技術ブログを書くことは、自分の成長のためだ。「なぜ？」を問い続け、変化の物語として語り、気持ちのゆらぎを素直に残す。結果として、それが誰かを救うこともあるかもしれない。私自身がそうだった。冒頭で書いたように、私は「破滅的な文章を書く人間」だった。それでも書き続けて、今がある。苦手から逃げても、その先にあるのはまた別の苦手だ「文章が苦手だから書かない」「人前で話すのが苦手だから発信しない」──そう言って避け続ける人は多い。気持ちはわかる。苦手なことに向き合うのは辛い。できない自分を直視するのは苦しい。でも、逃げた先に何があるだろうか。苦手なことを避け続けても、人生から苦手がなくなるわけではない。文章から逃げれば、別の場面でまた「苦手」にぶつかる。逃げ続けた結果、選択肢がどんどん狭まっていく。気づいたときには、逃げ場すらなくなっている。いま苦手であることと、将来成果を出せるかどうかには、おそらく何の因果関係もない。初期能力が高い人が最終的に優れた成果を出すとは限らない。むしろ、最初から得意な人は壁にぶつかったとき折れやすい。苦手だった人の方が、泥臭く続ける力を持っていたりする。私は明らかに後者だった。最初からうまく書けたわけではない。読み返すと恥ずかしい文章をたくさん書いた。それでも書き続けた結果、今がある。出発点の低さは、到達点を決めない。「自分探し」という名の逃避「自分に向いていることを見つければ、苦労せずに成果が出る」──そんな幻想がある。「自分探し」という言葉は、その幻想を正当化する。本当の自分を見つければ、努力なしに輝ける場所がある。そう信じたい気持ちはわかる。でも、多くの場合それは苦手や欠損から逃れるための言い訳でしかない。向いていないから別のことを探す。それも向いていないから、また別のことを探す。その繰り返しで時間だけが過ぎていく。本当の自分は、探すものではない。目の前のことに向き合い、苦手なことに取り組み続ける中で、少しずつ形作られていくものだ。「これが自分だ」と思えるようになるのは、何かをやり抜いた後だ。やる前からわかるものではない。向いていることを探すより、目の前のことに向き合う方が、よほど確実に成長できる。向いているかどうかは、やってみなければわからない。やり続けてみなければわからない。最初の苦手意識だけで判断するのは、あまりに早すぎる。正しい方向に努力すれば、必ず上達するとはいえ、漫然と続けるだけでは上達しない。書くことと、うまくなることは、自動的にはつながらない。読者の反応を見る。うまい人の文章を読んで、何が違うのか考える。自分の過去記事を読み返して、恥ずかしくなる。そうやってフィードバックを受け取り、意識的に改善しようとすることで、少しずつ書けるようになる。大事なのは、フィードバックループを回すことだ。書く→反応を見る→改善点を見つける→また書く。このサイクルを回し続ければ、必ず上達する。才能の有無ではなく、このループを回し続けられるかどうかが、成長を決める。こう書くと「それは書けた側の言い分だ」と思う人もいるかもしれない。生存者バイアスじゃないか、と。確かにそうだ。書けなかった人の声は届かない。でも、だからこそ書けた側が伝えるしかない。書けないと思っている人、文章に自信がない人に、「それでも書ける」と伝えられるのは、同じ場所から歩いてきた人間だけだ。だから、今日からでも始めてほしい。まずは今日学んだこと、ハマったこと、気づいたことを3行だけ書いてみる。下書きのまま放置している記事があるなら、不完全でもいいから公開してみる。完璧を待っていたら、いつまでも始まらない。苦手だと思っていることほど、始めてしまえば案外なんとかなる。登壇・技術顧問のご依頼について登壇依頼はいつでも募集しています。今回のようなちょっと変わった企画でも大歓迎です。気軽にDMしてください。また、技術顧問業もやっています。SRE、プラットフォームエンジニアリング、組織づくりなど、雑多な質問でもお待ちしております。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA 認定資格奮闘記 ~Professional Agentic AI編~]]></title>
            <link>https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/nvidia_pro_agentic_ai</guid>
            <pubDate>Sat, 13 Dec 2025 05:21:28 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAの認定資格であるProfessional Agentic AIを取得したので、その内容を共有しようと思います。 Professional Agentic AIとは？Professional Agentic AI（以下、NCP-AAI）は、マルチエージェントインタラクションや分散推論、スケーラビリティ、倫理的セーフガードに重点を置き、高度なエージェントAIソリューションを設計、開発、展開、管理する能力を試される試験です。エージェント開発だけなくそのサービングやモニタリングなど、DevOpsやMLOpsに関わるような内容が網羅的に出されるのが特徴です。https:/...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[短編：ブログネタってどうやって探してる？お答えします]]></title>
            <link>https://zenn.dev/akasan/articles/blog_neta_howto</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/blog_neta_howto</guid>
            <pubDate>Fri, 12 Dec 2025 14:01:24 GMT</pubDate>
            <content:encoded><![CDATA[今回は短編です。のべ240日程度連日テックブログを書いている私ですが、どのようにネタを探しているのかを共有しようと思います。 そもそも何で毎日ブログ書いてるの？詳細は以下の記事にて共有していますが、今改めて毎日書いているモチベをまとめると以下になります。自分の技術に対する興味をせっかくなら発信したいそもそも三日坊主だったので、ちゃんと習慣化できるようになりたかった今更引けないw単純に楽しいhttps://zenn.dev/akasan/articles/4aba4d3a0616ce ネタの探し方私のブログではいくつかの要因によってネタが決まっています。選び方の順...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[専門家は話さないですよ(『専門家が「力」をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい』を読んで)]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/12/163220</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/12/163220</guid>
            <pubDate>Fri, 12 Dec 2025 07:32:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに正直に言う。この文章を書くかどうか、ずいぶん迷った。「専門家はもっと声を上げるべきだ」という意見に対して、「いや、話さないんですよ」と返すのは、なんだか後ろ向きに見えるかもしれない。諦めているように聞こえるかもしれない。そういう風に受け取られるのは、ちょっと嫌だな、と思った。でも、書くことにした。なぜなら、「話せばいいじゃん」「振りかざせばいいじゃん」という言葉に、ずっと違和感を抱えてきたからだ。その違和感の正体を、自分なりに言葉にしてみたかった。これは、専門家として組織の中で働いてきた、私個人の経験と考えだ。すべての人に当てはまるとは思わない。でも、同じような経験をしている人が、もしかしたらいるかもしれない。そういう人に届いたらいいな、と思いながら書いている。「専門性の刃で殴りかかってこい」への違和感「専門家が『力』をセーブせずに全力で専門性を振り回してもリスペクトされる組織をつくりたい」という記事を読んだ。専門家はプロらしく専門知識を振りかざしてほしい。そこに忖度はいらない。殺す気でかかってきていい。言っていることが難しくて良い。専門家ってのは、そういうもんだろ、と。痛快だし、気持ちはわかる。専門家がセーブせずに力を振るえる組織という理想像は、多くのエンジニアやデザイナーが心の底で望んでいることだろう。その理想を堂々と語る姿勢には敬意を覚える。フジイさんの記事は、専門家の側に立って「もっと力を発揮していいんだ」と背中を押してくれる。それ自体は素晴らしいことだ。でも、私はこの説明に違和感がある。そして、専門家としては、そういう組織を期待して待っていても仕方ないと思っている。専門家は話さない。振りかざす以前の問題として、そもそも話さない。fujii-yuji.net話すことの面倒くささ専門家が話さない理由は、実はとても単純だ。面倒くさいのだ。自分の中にある専門的な知見を言葉にして口から出した瞬間、それは相手の解釈に委ねられる。どれだけ正確に伝えようとしても、相手の受け取り方は相手次第だ。ずれが生じる。これはいかなるコミュニケーションにおいても不可避だ。そして、ずれた理解に基づいて余計なことを言われる。「それってつまりこういうことですよね」と、全然違う解釈を返される。「でもそれって現実的じゃないですよね」と、文脈を無視した反論が来る。そのたびに「いや、そういうことではなくて」と釈明しなければならない。これが、本当に面倒くさい。だから専門家は話さない。話しても伝わらないし、伝わらなかったときの釈明が面倒くさいから。専門家の言葉が届かなくなるとき他にも組織の中で、専門家の言葉が届かなくなる瞬間がある。エンジニアが「この設計だと将来困ります」と言っても、「今はそれどころではない」と退けられる。デザイナーが「このUIは使いにくい」と指摘しても、「ユーザーは慣れる」と押し切られる。セキュリティの専門家が「この実装は危険です」と警告しても、「リリースを優先して」と言われる。なぜこうなるのか。専門家の意見と非専門家の意見が、同じ重みで扱われるからだ。あるいは、声の大きさや立場の強さで、専門家の意見が上書きされるからだ。「それはあなたの感想ですよね」と言われる。「他の見方もある」と言われる。正しいことを言っているのに、「意見の違い」として処理される。これは単なる無関心ではない。専門知への拒絶だ。専門家が何か言うと、面倒くさがられる。「また難しいことを言っている」「理想論だ」「現場を知らない」と思われる。そのうち、専門家の発言自体が疎まれるようになる。私はこれを「専門家の言葉が死ぬ瞬間」だと思っている。言葉が発せられても、届かない。届いても、受け止められない。受け止められても、行動に変わらない。そういう組織では、専門家は黙るようになる。分業が生む視野の狭さなぜこうなるのか。私なりに考えてみた。こんな経験がある。セキュリティの観点から「この実装は危険だ」と2回警告した。2回とも「リリースを優先して」と言われた。3回目は言わなかった。そして半年後、その実装が遠因でインシデントが起きた。「なぜ発生した」と言われた。言ったんだけどな、と思った。組織が大きくなると、分業が進む。営業、開発、デザイン、マーケティング。それぞれが専門性を高め、効率よく仕事を回せるようになる。これ自体は正しい。でも、分業には副作用がある。自分の担当範囲だけを見るようになる。隣のチームが何をしているか、知らなくても仕事は回る。全体像が見えなくなる。自分の視野がどんどん狭くなっていることに、気づかない。視野が狭くなると、判断がずれる。自分の担当範囲では正しいことが、全体で見ると間違っていることがある。でも、全体が見えないから、そのずれに気づけない。そして、何かを変えようとしても、壁にぶつかる。「それは私の管轄じゃない」「そっちのチームに言ってくれ」「今はそれどころじゃない」。組織の境界線が、行動を阻む。やがて、組織全体が「どうもうまくいっていない」と感じるようになる。でも、何が問題なのかがわからない。みんなが自分の持ち場で懸命に働いているのに、全体としては空回りしている。これが、ある程度成熟した組織が陥る罠だ。誰かが悪いわけではない。構造がそうさせている。話しても届かない構造この構造の中で、専門家はどうなるか。まず、自分の視野が狭くなっていることに気づかなくなる。自分の担当領域のことしか見えない。全体像が見えないから、自分の懸念が組織全体にとってどれだけ重要か、判断できない。「言っても仕方ない」と思ってしまう。次に、何か言っても壁にぶつかる経験を重ねる。「それは私の管轄ではない」「今はそれどころではない」と言われる。何度かそういう経験をすると、言うこと自体をやめる。学習性無力感だ。そして、本質的な問題を指摘しても、表面的な対応で済まされる。「技術的負債を返済しないと」と言っても、「今月のリリースが優先だ」と返される。根本的な問題が見えない組織では、根本的な指摘は届かない。専門家が話さないのは、怠けているからではない。プロ意識が低いからでもない。話しても届かない構造の中に置かれているからだ。何度も壁にぶつかって、学習した結果だ。専門家と非専門家の間にある溝専門家の言葉が届かないのは、誰かが悪いからではない。専門家は自分の領域を深く知っている。だからこそ、何が重要で何が危険かがわかる。でも、その「わかる」が、相手に伝わるとは限らない。非専門家には、非専門家の世界がある。締め切りがあり、予算があり、上からのプレッシャーがある。彼らは彼らなりに合理的に判断している。専門家の言うことが理解できないとき、「今は優先度が低い」と判断するのは、彼らにとっては当然のことだ。つまり、どちらも自分の世界では正しいことを言っている。問題は、それぞれの世界が交差しないことだ。専門家の「危険です」と、非専門家の「今はそれどころじゃない」が、同じ言語で話されているようで、まったく違う文脈に立っている。この溝を埋めるには、お互いの世界を理解しようとする努力がいる。でも、その努力には時間がかかる。そして、時間をかける余裕がない組織では、溝は埋まらないまま放置される。専門知識を振りかざしても、この溝は埋まらない。むしろ、溝を広げてしまうことさえある。「振りかざす」だけでは何も変わらないフジイさんは「専門知識を振りかざせ」と言う。力をセーブするな、忖度するな、と。気持ちはわかる。でも、私の経験では、振りかざしてもうまくいかなかった。専門家が強く主張すればするほど、相手は身構える。「また難しいことを言い始めた」「仕事を遅らせるつもりか」と思われる。こちらは正しいことを言っているつもりなのに、「面倒くさい人」として扱われる。そして、一度そういう印象を持たれると、次から話を聞いてもらえなくなる。「あの人はいつも理想論ばかり言う」というレッテルが貼られる。正しいことを言っているのに、聞いてもらえない。悪循環だ。振りかざすという態度は、相手に「自分の世界を押し付けられている」と感じさせる。人は押し付けられると、反発する。これは自然な反応だ。だから、振りかざしても状況は良くならない。むしろ、悪くなることのほうが多い。対話とは何かじゃあ、どうすればいいのか。私は「対話」だと思っている。ただし、ここで言う対話は「話し合う」という単純なものではない。対話とは、相手の世界に入っていくことだ。相手が何を見ているのか。何を気にしているのか。何を恐れているのか。どういうプレッシャーの中にいるのか。それを理解しようとすること。そして、理解した上で、相手の言葉で、相手の文脈で、自分の知っていることを伝えること。これは「振りかざす」とは正反対の態度だ。振りかざすとは、自分の世界から一歩も出ないまま、相手に自分の言葉を投げつけること。相手が理解できないなら、相手が悪い。対話とは、自分の世界を一度脇に置いて、相手の世界に足を踏み入れること。相手の言葉で考え、相手の文脈で説明する。これは、とても難しい。そして、とても面倒くさい。対話のコストを払える組織対話には膨大なコストがかかる。相手の世界を理解するために時間をかける。相手の言葉で説明するために言葉を選ぶ。ずれが生じたら、丁寧に修正する。誤解が生まれたら、根気強く解きほぐす。このコストを、組織が払えるかどうか。「今月のリリースが優先だ」「そんな時間はない」「とにかく早く作れ」という組織では、対話のコストは払えない。対話に時間をかける人は「仕事が遅い人」として評価を下げられる。対話のコストを払える組織とは、どういう組織か。意思決定のプロセスに専門家を巻き込む組織。評価制度が「言われたものを早く作る」ではなく「価値あるものを作る」を評価する組織。専門家の意見が「めんどくさいこと」ではなく「必要なこと」として扱われる組織。そして、相手の世界を理解しようとする姿勢が、当たり前のこととして共有されている組織。対立を放っておかない対立は放っておくと腐る。私自身、何度も失敗した。相手の話を遮って、自分の正しさを主張して、結局何も変わらなかった。そのたびに学んだのは、急いで反応しないことの価値だ。対立を放っておくと気まずさが積み重なる。仕事の判断がぶれ、人が協力しにくくなる。でも、対立が起きた瞬間に「正しさ」で押し切ろうとすると、もっと悪くなる。私はそれを何度も経験した。だから今は、衝突の場面では一度立ち止まるようにしている。相手の話を最後まで聞く。相手が何を恐れているのか、何を守ろうとしているのかを理解しようとする。それだけで、相手の硬さがゆるむことがある。争点をはっきりさせると、不要な言い合いが減る。「ここは合意できる」「ここは意見が違う」と整理するだけで、議論が前に進む。小さな合意を積み上げると、相手への不信が弱まる。これは言うのは簡単だが、やるのは難しい。私も何度も失敗した。でも、やる価値はある。専門家が話せる組織を作るというのは、対立を避けることではない。対立が起きたときに、それを丁寧に扱える組織を作ることだ。「あなたになら話したい」専門家が話すのは、話しても大丈夫だと思える相手に対してだけだ。自分の言葉が曲解されない。余計な解釈を加えられない。「そういうことではない」と釈明する必要がない。相手が自分の世界を理解しようとしてくれている。そういう相手に対してだけ、専門家は話す。「あなたになら話したい」——この感覚が、専門家に話をさせる。話すことのリスクでも、「あなたになら話したい」と思える相手は、実はとても少ない。専門家が話さないのは、構造の問題だけではない。話すこと自体に、あまりにもリスクがある。曲解される。余計なことを言われる。釈明が必要になる。プライドを刺激する。張り合われる。情報を軽々しく扱われる。他の人に言いふらされる。これだけのリスクを負って、それでも話す価値があるか。多くの場合、ない。だから専門家は黙る。専門知識を振りかざすどころか、そもそも口を開かない。コミュニケーションの不可避的なずれどれだけ丁寧に対話しても、ずれは生じる。私が話したい出来事が言葉となって口から出た時点で、それは私のものではなくなる。相手がどう受け取るかは、相手次第だ。これは、いかなるコミュニケーションにおいても不可避だ。だからこそ、対話のコストを払う意志があるかどうかが重要になる。ずれが生じたときに、「そういうことではない」と切り捨てるのではなく、「どうずれているのか」を一緒に探る。誤解が生まれたときに、「わかってないですね」と責めるのではなく、「どう誤解されたのか」を一緒に確認する。そして、聞いたことを軽々しく他の人に話さない。他者の情報を、自分の優越感のために消費しない。そのコストを払う意志があり、その倫理観を共有できる組織に対してだけ、専門家は話す。組織に期待しても仕方ない専門家が専門家としてリスペクトされる組織。フジイさんが描く理想は、私も心から望んでいる。でも、そういう組織を期待して待っていても、来ない。組織が変わるのを待っていたら、専門家は永遠に黙ったままだ。「いつか理解してくれる組織に出会えるはず」「いつかリスペクトされる日が来るはず」。そう思って待っていても、その日は来ない。だから、専門家の側から動くしかない。振りかざすのではなく、対話する。相手の世界に入っていく。相手の言葉で、相手の文脈で、自分の知っていることを伝える。面倒くさいけど、そのコストを自分から払う。組織が対話のコストを払ってくれるのを待つのではなく、自分から払う。相手が自分の世界を理解してくれるのを待つのではなく、自分から相手の世界を理解しにいく。これは不公平だ。専門家の側だけが努力するのはおかしい。でも、待っていても状況は変わらない。専門家に「振りかざせ」と言うのは、順番が逆だ。でも、「組織が変われ」と言うのも、期待しすぎだ。組織は簡単には変わらない。変わるのを待っていたら、自分が消耗するだけだ。だから、自分から動く。対話のコストを、自分から払う。専門家は話さない、でも専門家は話さない。話しても届かないから。話しても曲解されるから。話しても釈明が面倒くさいから。話したことを軽々しく扱われるから。他人を嫌いになりたくないから。専門家の言葉が届かなくなった組織では、専門家は黙る。それは怠慢ではない。何度も壁にぶつかった結果の、合理的な適応だ。でも、黙ったままでいいのか。フジイさんの理想は素晴らしい。専門家がリスペクトされる組織。専門家が力をセーブせずに振るえる組織。私もそういう組織で働きたい。でも、そういう組織を待っていても来ない。だから、自分から動くしかない。振りかざすのではなく、対話する。面倒くさいけど、相手の世界に入っていく。組織が変わるのを待つのではなく、自分から対話のコストを払う。「あなたになら話したい」——そう思ってもらえる相手に、自分からなる。組織に期待するのではなく、自分がその一人目になる。振りかざせと言う前に、自分から対話のコストを払う。それが、専門家として生き残る唯一の方法だと、私は思っている。私もまだ道半ばだ。何度も失敗するし、面倒くさいと思うこともある。でも、やるしかない。一緒にやっていこう。おわりにここまで書いてきて、ふと思う。結局、私は何を言いたかったんだろう。「専門家は話さない」という事実を伝えたかったのか。「組織に期待するな」と言いたかったのか。「自分から動け」と説教したかったのか。たぶん、どれでもない。私が本当に言いたかったのは、「話さないことを選んでいる自分を、責めなくていい」ということかもしれない。黙っているのは怠慢じゃない。何度も壁にぶつかって、学習した結果だ。それは合理的な適応だ。でも同時に、「黙ったままでいいのか」という問いも、ずっと抱えている。この矛盾を、私はまだ解決できていない。だから、「自分から対話のコストを払う」という答えを、自分自身に言い聞かせているのかもしれない。フジイさんの記事に対する反論というより、自分への言い訳、あるいは自分への励まし。そういう側面もあると思う。この文章を読んで、「わかる」と思ってくれた人がいたら嬉しい。「違う」と思った人もいるだろう。それでいい。ただ、もし同じような経験をして、同じように黙ることを選んでいる人がいたら、伝えたい。あなたは間違っていない。でも、黙ったままでいいのか、という問いは、たぶん消えない。その問いと一緒に、私はこれからも対話のコストを払い続けるんだと思う。面倒くさいけど。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Workstations入門: 安全かつ再現可能な開発環境の作り方]]></title>
            <link>https://qiita.com/aminevg/items/b953ae647c81eef59e95</link>
            <guid isPermaLink="false">https://qiita.com/aminevg/items/b953ae647c81eef59e95</guid>
            <pubDate>Thu, 11 Dec 2025 22:08:14 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2025 (12 日目) の投稿です。こんにちは！ スリーシェイクのイリドリシ愛民 (@realaminevg) です。最近は主にクライアントワークを行なっているため、セキュリティやオンボーディングを徹底する必...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA NeMo Agent Toolkitを使ってみた]]></title>
            <link>https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/</link>
            <guid isPermaLink="false">https://sreake.com/blog/how-to-use-nvidia-nemo-agent-toolkit/</guid>
            <pubDate>Thu, 11 Dec 2025 13:35:36 GMT</pubDate>
            <content:encoded><![CDATA[概要 こんにちは佐藤慧太@SatohJohnです。 NVIDIA NeMo Agent Toolkit（以下、この記事ではNATと呼ぶことにします）は生成AIに関する様々なツール・フレームワーク・言語モデルを組み合わせて […]The post NVIDIA NeMo Agent Toolkitを使ってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[登壇記録：NVIDIA NIMとNVIDAI NeMo Guardrailsの紹介]]></title>
            <link>https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/nvidia_nim_nemo_toudann</guid>
            <pubDate>Thu, 11 Dec 2025 13:28:09 GMT</pubDate>
            <content:encoded><![CDATA[今回は本日以下のイベントで登壇しましたので、そちらの資料の共有と簡単な概要の共有になります。https://3-shake.connpass.com/event/373638/ 登壇資料の共有今回の登壇資料は以下のspeackerdeckにアップロードしておりますのでぜひご覧ください。 登壇内容今回の登壇では主に以下のトピックについて取り扱いました。NVIDIA NIMを用いた最適化された環境でのモデルのサービングについてgarakを用いたLLMの脆弱性診断NeMo Guardrailsを用いたLLMに対するガードレールの設定LLMをアプリケーションを組み込む...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 俺が愛した本たち 技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/11/104143</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/11/104143</guid>
            <pubDate>Thu, 11 Dec 2025 01:41:43 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「今年読んで良かった本」という記事を書こうとしている自分に、ふと気づく。また書くのか。毎年書いている。誰に頼まれたわけでもないのに、12月になると決まってこの作業を始めてしまう。習慣なのか、義務感なのか、それとも単なる自己顕示欲なのか。たぶん、全部だ。100冊近く読んだ、と書こうとして手が止まる。この数字を出した瞬間、どこかで「すごいですね」と言われたい自分がいる。同時に、「いや、冊数なんて意味ないですから」と予防線を張りたがっている自分もいる。めんどくさい人間だ。でも正直に言えば、100冊読んだことより、1冊を血肉にできた人のほうがよほど偉いと本気で思っている。思っているのに、冊数を書いてしまう。そういう矛盾を抱えたまま、この文章を書いている。AIに聞けば答えは返ってくる。2025年はそういう年だった。コードを書いてもらい、設計を相談し、ドキュメントを要約させた。便利だ。本当に便利だ。では、なぜ本を読むのか。300ページもある本を、わざわざ最初から最後まで読む必要があるのか。たぶん、効率の悪さが必要なのだ。AIは正解を返してくれる。でも正解だけでは、何かが足りない。正解を得ることだけが目的なら、エンジニアをやっている意味がない。でも、そうじゃないはずだ。著者が失敗した話。遠回りした話。「今思えば、あれは間違いだった」という告白。そういう「ノイズ」が、不思議と頭に残る。正解は忘れる。でも、誰かの失敗談は覚えている。本を読んでいる時間、私は著者と対話している。いや、対話というより、ほとんど独り言だ。「それはそうだろう」と頷いたり、「いや、それは違うんじゃないか」と反発したりする。声には出さないけれど、頭の中ではずっと喋っている。その過程で、借り物の知識が少しずつ自分の言葉に変わっていく。検索では得られないもの。それを「身体性」と呼ぶのは大げさかもしれないけれど、他に適切な言葉が見つからない。読んだだけでは意味がない、と言われてきた。アウトプットしないと身につかない。実践しないと血肉にならない。わかっている。わかっているけれど、私は本を読むこと自体が好きなのだ。ページをめくる時間が好きだ。知らない概念や文脈に出会う瞬間が好きだ。だからブログを書き、登壇し、実務で試してきた。好きなことを正当化するために、アウトプットという免罪符を手に入れようとしていたのかもしれない。以下に紹介する26冊は、今年の「ベスト」ではない。そんな客観的な評価ができるほど、私は公平な人間ではない。単に「私に刺さった本」を並べただけだ。他の人には響かないかもしれない。でも、この26冊との出会いが、私の2025年を形作った。それだけは確かなことだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめに昨年以前に紹介した本2025年に読んでよかった技術書Beyond Vibe CodingLLMOpsGenerative AI Design PatternsBuilding Applications with AI AgentsLearning GitHub CopilotTerraform in DepthArgo CD: Up and RunningEffective Platform EngineeringData Engineering Design Patternsソフトウェア設計の結合バランスFacilitating Software ArchitectureArchitecture ModernizationBuilding Event-Driven Microservices, 2nd EditionTaming Your Dragon: Addressing Your Technical DebtRefactoring to RustJust Use Postgres!The Software Engineer's Guidebookバックエンドエンジニアのためのインフラ・クラウド大全作る、試す、正す。アジャイルなモノづくりのための全体戦略良いコードの道しるべClean Code, 2nd Edition型システムのしくみFundamentals of Software EngineeringThe Product-Minded EngineerThe Engineering Leader"Looks Good to Me"おわりに昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年に読んでよかった技術書Beyond Vibe Codinglearning.oreilly.comwww.oreilly.co.jp※日本語翻訳版が出版予定です。AIツールの導入が進む現場で、私が感じていた違和感がありました。生産性は上がっている。コードは早く書ける。しかし、チームメンバーがAI生成コードについて質問されたとき、「なぜこう書いたのか」を説明できない場面が増えている。Google ChromeチームのAddy Osmani氏による本書は、この違和感に「Vibe Coding」という名前を与えてくれました。Vibe Codingとは、AIが生成したコードを深く理解せずに受け入れてしまう傾向のことです。動くコードと、理解しているコードは違う——この区別は、個人の学習だけでなく、チームの品質管理にも直結します。レビューで「なぜこの実装なのか」と聞かれたとき、「AIがそう書いたから」では通らない。コードの責任は、書いた人間にある。著者は、AIを「単独で使うツール」ではなく「ペアプログラマ」として捉えることを提唱しています。この主張には同意するが、同時に違和感もある。ペアプログラマは、隣に座って一緒に考える存在だ。しかしAIは、こちらが何を求めているか察してくれない。問いを投げなければ答えは返ってこない。つまり、AIを「ペア」として機能させるためには、人間の側に「何を聞くべきか」を知っている力が必要になる。結局、AIを活かせるかどうかは、使う側の問いの質で決まる。ペアプログラマという比喩は美しいが、その美しさに甘えてはいけない。本書の終盤では、自律型コーディングエージェントがもたらす未来像が描かれています。テスト失敗時に自動で修正を試みたり、依存関係の更新PRを生成したりする世界。技術的には魅力的ですが、著者は冷静です。「AIが生成したコードの責任は、承認者にある」——この原則は変わらない。むしろ、エージェントが自律的に動くほど、人間による検証の重要性は高まる。この視点は、運用の現場を知っている人間には納得感があります。AIは相棒であって、魔法使いではない。本書は、その現実を直視しながら、AIとの協働をチームに根付かせるための実践的な指針を提供してくれます。Beyond Vibe Coding: From Coder to AI-Era Developer (English Edition)作者:Osmani, AddyO'Reilly MediaAmazonLLMOpslearning.oreilly.comLLM（Large Language Model、大規模言語モデル）を本番環境で運用し始めると、従来のMLOpsの知見だけでは対応できない課題に直面します。モデルの挙動が予測しにくい、コストが桁違いに高い、出力の品質をどう保証するか分からない——そんな困難にぶつかったとき、本書を手に取りました。著者が掲げるLLMOpsの4つの目標——信頼性、スケーラビリティ、堅牢性、セキュリティ——を見たとき、既視感がありました。これは、システムを運用する人間が長年追求してきた目標と重なる。新しい技術領域でも、運用の本質は変わらない。これまで培ってきた原則は、LLMにも適用できる——その確信を得られたことは、本書を読んだ大きな収穫でした。しかし、ここで私は立ち止まる。「従来の原則が適用できる」という安心感は、危うさも孕んでいる。LLMには従来のシステムにはない難しさがあるからだ。従来のMLモデルは、入力に対して比較的予測可能な出力を返す。しかしLLMは、同じプロンプトでも異なる応答を返すことがある。そもそも「正しい出力とは何か」が曖昧なのです。従来のシステムでは「期待する出力」を定義できた。LLMでは、それ自体が困難になる。この不確実性を前提に、どうSLO（Service Level Objective、サービスレベル目標）を設計し、どうモニタリングするか。本書はその実践的なアプローチを示してくれます。コスト管理の章も現実的で良かった。LLMのAPI呼び出しは、従来のマイクロサービス呼び出しと比較して桁違いにコストがかかる。機能要件を満たすことと、コストを現実的な範囲に収めること。このトレードオフを意識した設計と運用の知見は、実務で即座に役立つものばかりです。「正しい出力」が定義できないシステムを、どう運用するか。答えは、まだ業界全体で模索中です。正解がないから、難しい。正解がないから、面白い。本書はその議論の出発点として、LLMを本番で動かす人が押さえておくべき基盤を提供してくれます。LLMOps: Managing Large Language Models in Production (English Edition)作者:Aryan, AbiO'Reilly MediaAmazonGenerative AI Design Patternslearning.oreilly.comLLMを使ったアプリケーションを作り始めると、繰り返し同じような問題にぶつかります。ハルシネーション（AIが事実と異なる内容をもっともらしく生成してしまう現象）をどう防ぐか。長いコンテキストをどう扱うか。出力の品質をどう担保するか。これらの問題には、すでに先人たちが見つけた解決策がある。本書は、そうしたLLMの限界を克服するための32のデザインパターンを体系化した一冊です。RAG（Retrieval-Augmented Generation、検索拡張生成）、Chain of Thought（思考の連鎖）、Guardrails（安全装置）といったパターンは、今やLLMアプリケーション開発の共通言語になりつつあります。これらのパターンを知っているかどうかで、設計の議論がスムーズになるし、チーム内での認識合わせも早くなる。本書の価値は、単にパターンを列挙していることにあるのではありません。各パターンがなぜ必要か、どのような問題を解決するのか、そしてどのようなトレードオフがあるのか——その背景まで丁寧に解説している点にあります。例えば、RAGパターン。ハルシネーションの軽減策として有効なのは広く知られている。しかし本書は、RAGの導入がもたらす新たな課題も明確に指摘しています。ベクトルデータベースという新しいコンポーネントが加わり、監視対象と障害点が増える。検索の精度がLLMの出力品質を左右するため、検索システムの品質保証という新たな運用課題が生まれる。解決策は、新しい問題を連れてくる——技術選定の現場では、この現実を織り込んだ上で判断する必要があります。Chain of Thoughtパターンも同様です。複雑な推論を段階的に行わせることで出力精度が向上する。しかし、精度を上げれば、コストも上がる。APIコールが複数回になり、レイテンシーとコストが増加する。プロダクトとして許容できるコストとレイテンシーの範囲内で、どこまで精度を追求するか。このトレードオフは、技術だけでなくビジネス要件との兼ね合いで決まります。パターンを知っているかどうかで、設計の選択肢が変わる——本書は、パターンカタログとしても、チームでアーキテクチャを議論するための共通言語としても活用できます。Generative AI Design Patterns: Solutions to Common Challenges When Building GenAI Agents and Applications (English Edition)作者:Lakshmanan, Valliappa,Hapke, HannesO'Reilly MediaAmazonBuilding Applications with AI Agentslearning.oreilly.comLLMを使ったアプリケーションの次のステップとして、AIエージェントへの関心が高まっています。単に質問に答えるだけでなく、タスクを自律的に実行するシステム。しかし、エージェントを本番環境に投入しようとすると、従来のシステム運用とは異なる課題に直面します。従来のAPIは、リクエストを送れば決まった形式でレスポンスが返ってくる。処理時間もおおよそ予測できる。しかしエージェントは違う。どんな行動を取るか予測しにくい。タスクによって実行時間が大きく変わる。外部サービスへの呼び出しも、エージェント自身が判断して行う。従来のSLOの考え方が、そのままでは通用しない。では、どう運用設計するのか。本書を読んで改めて考えさせられたのは、ガードレールの設計です。エージェントは自律的に動く。自律的に動くからこそ、想定外の行動を取る可能性がある。どこまで自律性を許し、どこで人間が介入するか。この境界線を曖昧にしたまま本番投入すると、インシデント時の対応が混乱します。自律的に動くものを、どこまで信頼するか。その答えを、運用設計の段階で明確にしておく必要がある。信頼の境界線を引くのは、AIではなく人間の仕事だ。本書はその設計指針を与えてくれます。Learning GitHub Copilotlearning.oreilly.comGitHub Copilotを使い始めたころ、私はこれを「賢いオートコンプリート」だと思っていました。しかし、最近のCopilotは違います。コード補完だけでなく、チャットで質問に答え、コードの説明を生成し、テストまで書いてくれる。開発ワークフロー全体を変革する可能性を持っている。その進化に追いつくために、本書を手に取りました。インフラエンジニアとしても興味深い内容が多かった。IaC（Infrastructure as Code、インフラのコード化）の自動化、マニフェスト（Kubernetesなどの設定ファイル）の生成、パイプラインの構築。私自身、本書のテクニックが役立った場面は少なくありません。ただ、便利になればなるほど、新しい課題も生まれます。AIが生成したコードを、誰がどうレビューするのか。生成されたコードにバグがあったとき、責任は誰にあるのか。「AIがそう書いたから」では済まされない。コードの責任は、承認した人間にある。便利さの代償は、新しい責任——その両面を理解した上でCopilotを活用していきます。楽になった分だけ、考える責任が増えた。Building Applications with AI Agents: Designing and Implementing Multiagent Systems (English Edition)作者:Albada, MichaelO'Reilly MediaAmazonTerraform in Depthlearning.oreilly.comインフラをコードで管理する。Infrastructure as Code（IaC）は、もはや当たり前の実践になりました。その中でもTerraformは、クラウドを問わず広く使われている。しかし、基本的な使い方を覚えた後、どう深めていくか。本書は、TerraformとOpenTofuの両方をカバーしている点に惹かれて手に取りました。HashiCorpのライセンス変更以降、OpenTofuへの移行を検討している組織も多いでしょう。どちらを選んでも、基本的な概念やスキルは共通しています。ライセンスが変わっても、スキルは変わらない——その安心感は大きいと感じました。大規模環境でのTerraform運用では、ステート管理が最も頭を悩ませる課題の1つです。ステートとは、Terraformが管理するインフラの「現在の状態」を記録したファイルです。このファイルが壊れたり、実際のインフラと食い違ったりすると、意図しない変更が発生する危険がある。ステートが壊れたら、インフラが壊れる——この現実に正面から向き合う必要があります。インフラの信頼性を高めるためには、IaCの品質向上が不可欠です。アプリケーションコードにはテストを書くのが当たり前になっていますが、インフラコードはどうでしょうか。インフラコードも、テストなしには信頼できない——私はこの原則を実践に落とし込むために、本書を読みました。Terraform in Depth: Infrastructure as Code with Terraform and OpenTofu作者:Hafner, RobertManningAmazonArgo CD: Up and Runninglearning.oreilly.comIaCでインフラを定義できるようになったら、次はデプロイをどう自動化するか。GitOps（Gitリポジトリを中心にインフラやアプリケーションのデプロイを管理する手法）は、その答えの1つです。Gitリポジトリを唯一の真実の源とし、インフラの状態を宣言的に管理する。そのGitOpsの標準ツールとなったArgo CDを深く理解したくて手に取りました。公式ドキュメントには書かれていない設計判断の背景を知ることで、ツールの使い方だけでなく、思想を理解できると感じています。実践者が書いた本には、公式ドキュメントにはない「なぜ」がある——それが技術書を読む理由の1つです。大規模な環境でも管理可能なGitOpsワークフローを構築するためのテクニックを学べました。GitOpsの導入は、デプロイの信頼性を高めるだけではありません。変更管理の透明性が向上し、何か起きたときの原因追跡が容易になる。Gitを見れば、本番が分かる——宣言的なインフラ管理とGitによるバージョン管理の組み合わせは、チーム開発との相性が非常に良いと感じています。Argo CD: Up and Running: A Hands-On Guide to GitOps and Kubernetes (English Edition)作者:Block, Andrew,Hernandez, ChristianO'Reilly MediaAmazonEffective Platform Engineeringwww.manning.comIaCやGitOpsを導入し、インフラの自動化が進むと、次の課題が見えてきます。これらのツールやプラクティスを、どうやって開発チーム全体に展開するか。個人が使いこなしていても、チーム全体のものにならなければ意味がない。プラットフォームエンジニアリングは、その課題に対するアプローチです。しかし、技術的に優れたプラットフォームを作っても、開発者に使ってもらえなければ意味がない。使われないプラットフォームは、存在しないのと同じ——この現実は、プラットフォームチームにいると身に染みてわかります。本書が一貫して主張するのは、プラットフォームを「プロダクト」として扱うというマインドセットです。プラットフォームチームはインフラを提供するだけでなく、開発者体験を向上させる製品を開発している。開発者は顧客であり、彼らのフィードバックを受けて改善を続ける。インフラチームではなく、プロダクトチームである——この視点の転換は、チームの動き方を根本から変えます。この主張には強く共感する一方で、現実の難しさも感じている。「開発者は顧客」と言うのは簡単だ。しかし、顧客である開発者の要望をすべて聞いていたら、プラットフォームは一貫性を失う。標準化と柔軟性のバランス。セキュリティと利便性のトレードオフ。「顧客の声を聞く」と「顧客の言いなりになる」は違う。プロダクトチームとして振る舞うなら、時には「それはできません」と言う勇気も必要になる。本書はその難しさにも触れているが、私はもっと掘り下げてほしかった。開発者の認知負荷を下げながら、システムの信頼性を維持する。このバランスは、簡単ではありません。抽象化しすぎると、開発者がトラブルシューティングできなくなる。抽象化が足りないと、認知負荷が下がらない。プラットフォームの成功は、開発者の生産性で測る——この原則を軸に、どこまで抽象化するかを判断していく必要があります。Effective Platform Engineering (English Edition)作者:Chankramath, Ajay,Alvarez, Sean,Oliver, Bryan,Cheneweth, NicManningAmazonチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計作者:マシュー・スケルトン,マニュエル・パイス日本能率協会マネジメントセンターAmazonData Engineering Design Patternslearning.oreilly.comプラットフォームを運用していると、アプリケーションだけでなくデータパイプラインの信頼性も課題になってきます。データはシステムの血液のようなもので、流れが止まれば、ビジネスも止まる。データエンジニアリングにおけるデザインパターンを学びたくて手に取りました。デザインパターンとは、繰り返し現れる問題に対する定石のようなものです。先人たちが試行錯誤の末にたどり着いた解決策が、パターンとして整理されている。パターンには、先人の失敗が詰まっている——だから学ぶ価値がある。データパイプラインの信頼性、データ品質のモニタリング、レイテンシーの管理。これらの課題は、従来のアプリケーション開発とは異なるアプローチが必要です。たとえば、データパイプラインでエラーが発生したとき、どう対処するか。エラーを無視すればデータ品質が下がる。かといって、パイプライン全体を停止させれば、正常なデータまで届かなくなる。本書が紹介するパターンの1つは、問題のあるレコードを別の場所に退避させて後から対処する、というものです。1件のエラーで、100万件を止めるな——このパターンを知っているかどうかで、障害発生時の影響範囲が大きく変わります。また、データが届かないことも障害です。この視点も重要でした。アプリケーションの障害は目に見えやすいですが、データパイプラインの遅延や欠損は気づきにくい。データの品質をどう保証するか。本書から多くのヒントを得ました。Data Engineering Design Patterns: Recipes for Solving the Most Common Data Engineering Problems (English Edition)作者:Konieczny, BartoszO'Reilly MediaAmazonソフトウェア設計の結合バランスbook.impress.co.jpデータパイプラインでもアプリケーションでも、システムを構成する要素間の「結合」は避けて通れない課題です。疎結合が良い、密結合は悪い——そう教わってきたけれど、本当にそれだけで設計できるのか。この疑問に答えてくれるのが本書です。Vlad Khononov著『Balancing Coupling in Software Design: Universal Design Principles for Architecting Modular Software Systems』の翻訳本です。島田浩二さんの翻訳が秀逸で、原著の概念を自然な日本語で読めることに感謝しています。learning.oreilly.comしかし本書は、その固定観念を覆します。結合がなければ、ソフトウェアはシステムになれない。結合は悪ではない。結合は、システムを成り立たせる力だ。この主張を読んだとき、私は自分の設計判断を振り返った。「疎結合にしなければ」という呪縛に囚われて、過剰に分離したことはなかったか。分離した結果、かえって複雑になったことはなかったか。あった。確実にあった。マイクロサービスに分割したはいいが、サービス間の通信が増えて、障害の原因追跡が困難になった経験。本書の主張は、そうした失敗を言語化してくれた。本書の価値は、「結合」という概念を多次元で捉え直すところにあります。結合の強さだけでなく、結合の距離、結合の揮発性——複数の軸で分析することで、設計の判断基準が明確になる。これは手順書でもルールブックでもない。設計の意思決定に迷ったとき、インプットとして参照するための本です。どこまで結合を許容し、どこで切り離すか。その判断を支える思考の枠組みを、本書は与えてくれます。ある書評では「今後10年くらいの基礎知識になる」と評されていました。私も同感です。マイクロサービス、モジュラーモノリス、ドメイン駆動設計——どのアーキテクチャを選んでも、結合のバランスは避けて通れない。正解を教えてくれる本ではなく、正解を見つけるための視点をくれる本。そういう本こそ、長く手元に置いておきたい。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonFacilitating Software Architecturelearning.oreilly.comsyu-m-5151.hatenablog.com結合のバランスを考え、設計判断を重ねていく。しかし、その判断は誰がするのか。アーキテクトの役割が変わりつつあります。一人の天才が全てを決める時代から、チーム全体でアーキテクチャを育てていく時代へ。アーキテクトは、決める人から、決められるようにする人へ——この変化は、私自身の仕事のやり方にも影響を与えています。本書が提唱するのは、決定の権限を分散しつつ、責任の所在を明確にするアプローチです。誰でもアーキテクチャに関する決定を下せる。しかし、その前に適切な人々から助言を求めなければならない。権限は分散されるが、責任は決定者に残る。このバランスが、スピードと品質のトレードオフを緩和してくれます。実務で特に役立っているのは、ADR（Architecture Decision Records、アーキテクチャ決定記録）の考え方です。なぜその設計判断をしたのかを記録しておく。これは、将来のインシデント対応や技術的負債の評価において価値がある。なぜこのシステムはこうなっているのか。その説明ができる状態を維持することは、チームの意思決定の質を高め、運用の効率化にも直結する。決定を記録しないのは、忘れるためである——だから記録が重要なのです。Facilitating Software Architecture: Empowering Teams to Make Architectural Decisions (English Edition)作者:Harmel-Law, AndrewO'Reilly MediaAmazonArchitecture Modernizationlearning.oreilly.comsyu-m-5151.hatenablog.com設計判断を記録し、チームでアーキテクチャを育てる。しかし、既存のレガシーシステムはどうするのか。新規システムなら理想的なアーキテクチャを追求できるが、現実には10年、20年と動き続けているシステムがある。レガシーシステムのモダナイゼーションに関わった経験がある人なら、技術だけでは解決しない問題があることを知っているはずです。コードを書き直しても、組織構造や開発プロセスが同じままでは、また同じ問題が生まれる。コードだけを変えても、問題は戻ってくる——本書は、この現実を正面から扱っています。全てのシステムが同じ重要度ではない。競争優位の源泉となる部分と、汎用的な部分を区別し、限られたリソースをどこに集中すべきかを判断する。全部は直せない。だから、どこを直すか決める——この優先順位付けの考え方は、経営層との対話でも役立ちます。「なぜこのシステムを優先するのか」を説明できるようになる。Collaborative Software Design もかなり良かったので副読本としてオススメしたいです。システムだけを変えても、組織が変わらなければ意味がない——この全体像を把握することは、ソフトウェアに関わるすべての人にとって重要です。なぜこのシステムがこの設計になっているのか。なぜこのチームがこの範囲を担当しているのか。技術的な判断の背景には、組織の歴史や力学がある。それを理解することで、日々の判断もより適切になるし、関係者との対話もスムーズになります。Architecture Modernization: Socio-technical alignment of software, strategy, and structure (English Edition)作者:Tune, Nick,Perrin, Jean-GeorgesManningAmazonBuilding Event-Driven Microservices, 2nd Editionlearning.oreilly.comマイクロサービスを設計するとき、私たちはつい「サービス間の通信をどうするか」という問いから始めてしまう。しかし本書を読んで、その問いの立て方自体が間違っていたのかもしれないと気づかされました。Adam Bellemare氏による本書の初版は2020年に出版され、イベント駆動型アーキテクチャの実践的な指針として多くのエンジニアに読まれてきました。この第2版では、その後の技術進化と実践知が大幅に加筆されています。本書が冒頭で引用するマクルーハンの「媒体はメッセージである」という言葉が象徴的です。私たちがどのような通信手段を選ぶかが、システムの設計だけでなく、組織構造やチーム間のコミュニケーションまで規定してしまう。リクエスト・レスポンス型の同期通信を選べば、サービス間の密結合が生まれる。イベントストリームを選べば、疎結合と自律性が生まれる。技術選択は、組織の形を決める選択でもある——コンウェイの法則を逆手に取るような視点が、本書には一貫して流れています。著者が強調するのは、データ通信構造（Data Communication Structure）という概念です。ビジネスコミュニケーション構造（チームの編成）と実装コミュニケーション構造（コードとAPI）は多くの組織で意識されている。しかし、データをどう流通させるかという構造は、往々にして後回しにされる。その結果、他チームのデータが必要になるたびに、場当たり的なAPI連携やデータコピーが生まれ、システムは複雑化していく。データ通信構造の欠如が、モノリスを肥大化させる——この指摘は、私自身の経験とも重なります。イベント駆動型マイクロサービスの本質は、データを「イベント」として永続化し、それを組織全体で共有可能にすることにあります。プロデューサーはイベントを発行する責任だけを負い、コンシューマーは必要なイベントを自分のペースで消費して独自のデータモデルを構築する。この分離によって、サービス間の依存関係が劇的に減少する。データは、実装に閉じ込めるものではなく、流れるものである——この発想の転換が、本書の核心です。ただし、私はこの主張を手放しで受け入れているわけではない。イベント駆動型アーキテクチャには、リクエスト・レスポンス型にはない複雑さがある。イベントの順序保証、べき等性の担保、結果整合性への対応。「疎結合になる」という美しい言葉の裏には、新たな運用課題が潜んでいる。本書はその課題にも誠実に向き合っているが、現場で直面する泥臭い問題——たとえば、イベントスキーマの進化をどう管理するか、障害時のリカバリをどう設計するか——については、もっと深掘りしてほしかった部分もある。本書の価値は、イベント駆動型アーキテクチャの「なぜ」を丁寧に解説している点にあります。単にKafkaの使い方を説明するのではなく、なぜイベントストリームが必要なのか、なぜ従来のアプローチでは限界があるのかを、組織論まで含めて論じている。リクエスト・レスポンス型マイクロサービスの欠点——ポイントツーポイント結合、依存スケーリング、分散モノリス化——を明確に言語化してくれたことで、私自身が過去に経験した失敗の原因が腑に落ちました。イベントは、サービス間の会話ではなく、組織の記憶である——本書を読んで、私はイベントストリームの捉え方が変わりました。データパイプラインやメッセージキューとしてではなく、ビジネスの出来事を永続化した「正典的な記録」として捉える。その視点があれば、新しいサービスを立ち上げるときも、過去のイベントを再生してデータモデルを構築できる。実装の寿命よりもデータの寿命のほうが長い——この現実を直視したアーキテクチャが、イベント駆動型マイクロサービスなのだと理解しました。Building Event-Driven Microservices: Leveraging Organizational Data at Scale (English Edition)作者:Bellemare, AdamO'Reilly MediaAmazonTaming Your Dragon: Addressing Your Technical Debtlearning.oreilly.comsyu-m-5151.hatenablog.comシステム開発で必ず直面するのが、技術的負債です。どこを優先的に直すかを判断するには、技術的負債の性質を理解する必要がある。技術的負債は「ドラゴン」のようなものです。放っておけば大きくなり、いつか手に負えなくなる。しかし、完全に倒すこともできない。なぜなら、技術的負債は開発を進める限り必ず生まれるものだからです。だから、敵として戦うのではなく、適切に付き合い、共存の道を探る。ドラゴンは殺せない。だから、飼い慣らす——この比喩が、私には刺さりました。本書を読んで、技術的負債を単なる技術的問題ではなく、トレードオフの問題、組織の問題、経済の問題として捉える視点を得ました。「技術的負債」という言葉は、金融の「負債」から借りてきた比喩です。しかし、両者には決定的な違いがあります。金融的負債は明確な金額があり、返済計画を立てられる。しかし技術的負債は、その量を正確に測定することが困難であり、返済のコストも不確実です。借金は金額がわかる。技術的負債は、わからない——このアナロジーの限界を、私たちはもっと意識すべきだと感じています。ここで著者の主張に、私は半分同意し、半分疑問を持つ。「ドラゴンを飼い慣らす」という比喩は美しい。しかし、飼い慣らせるドラゴンと、飼い慣らせないドラゴンがいるのではないか。ある種の技術的負債は、時間が経つほど返済コストが指数関数的に増大する。そういう負債は、早めに倒すべきだ。すべての負債を「共存する相手」として扱うのは、危険な楽観主義に陥る可能性がある。本書の比喩を鵜呑みにせず、「このドラゴンは飼い慣らせるのか、それとも早めに倒すべきなのか」を見極める目が必要だと、私は考える。技術的負債がなぜ蓄積していくのか、なぜ返済が後回しにされるのか。本書はその構造的な原因を可視化してくれます。原因がわかれば、より効果的な介入点を見つけることができる。技術的負債は倒すものではなく、飼い慣らすもの——「なぜこの改善が必要なのか」を経営層に説明するための理論的基盤を、本書から得ました。Taming Your Dragon: Addressing Your Technical Debt (English Edition)作者:Brown, Dr. Andrew RichardApressAmazonRefactoring to Rustlearning.oreilly.comsyu-m-5151.hatenablog.com技術的負債に対処する具体的な手法の1つとして、言語の移行があります。既存のコードベースを一から書き直すのではなく、段階的にRustに置き換えていくアプローチに興味があって手に取りました。全面的な書き直しはリスクが高い。だから、パフォーマンスクリティカルな部分から少しずつ置き換える。全部を書き直すな、一部を置き換えろ——この原則は、私の考え方にも合っています。「Rustを学ぶ」本ではなく、「Rustを実務で使う」本だと感じました。言語を学ぶのと、言語で仕事をするのは違う——その差を埋めてくれる本です。パフォーマンスクリティカルな部分や、メモリ安全性が重要な部分をRustに置き換えることで、システム全体の信頼性を向上させる。全面的な書き換えのリスクを避けながら、段階的に改善を進める方法論は、運用中のシステムを改善する際の参考になるでしょう。Refactoring to Rust (English Edition)作者:Mara, Lily,Holmes, JoelManningAmazonJust Use Postgres!learning.oreilly.comsyu-m-5151.hatenablog.com言語の選択、アーキテクチャの設計、技術的負債の返済——これまで見てきた本は、どれも「何を選ぶか」の判断を扱っていました。しかし、時には「選ばない」という選択が最良のこともある。「PostgreSQLだけで十分」という主張は、時に過激に聞こえるだろう。しかし本書を読んで、その主張にはしっかりとした根拠があることがわかりました。新しい技術スタックを追加することは、運用の複雑性を高める。だから、既存の技術でできることは、既存の技術で解決すべきです。新しいデータベースを導入する前に、Postgresでできないか考える。この姿勢が、私の技術選択の基準になっています。PostgreSQLは、リレーショナルデータベースとしての堅実な機能に加え、JSON処理、全文検索、地理空間データ、時系列データ、ベクトル検索まで対応しています。Postgresは、データベースではなく、プラットフォームである——この主張には説得力があります。ただし、この主張を額面通りに受け取るのは危険だとも思う。「Postgresで十分」という言葉が、技術的判断の放棄に使われることがある。本当にPostgresで十分なのか、それとも単に新しい技術を学ぶのが面倒なのか。その区別は、案外難しい。本書の価値は「Postgresを使え」という結論にあるのではなく、「なぜPostgresで十分なのか」を考えるフレームワークにある。シンプルさには価値がある。しかし、シンプルさを言い訳にして、必要な複雑さから逃げてはいけない。データベースの種類を減らすことで、運用の複雑性が下がるというメリットがあります。監視対象が減り、バックアップ戦略が統一され、チームが習得すべき技術スタックがシンプルになる。もちろん、PostgreSQLが適さないケースもあります。万能ではないことを認めた上で、どこまで対応できるかを知る。複雑さを減らすことも、エンジニアリングである——その境界線を理解することが、適切な技術選択には重要です。Just Use Postgres!: All the database you need (English Edition)作者:Magda, DenisManningAmazonThe Software Engineer's Guidebooklearning.oreilly.comここまで、技術的なトピックの本を紹介してきました。しかし、技術を身につけるだけでは、キャリアは作れない。ジュニアからシニア、そしてスタッフエンジニアへ。キャリアの各段階で求められるスキルは異なります。しかし、次の段階で何が必要になるかは、今の段階からは見えにくい。キャリアの次の段階で必要なスキルは、今の段階では見えない——本書は、その見通しを与えてくれます。技術的なスキルだけではキャリアは作れない。これは、ある程度経験を積むと実感することです。コードレビューの仕方、技術的な意思決定への関わり方、メンタリングの方法、組織への影響力の広げ方。コードを書く力と、キャリアを作る力は別物——両方を意識的に伸ばす必要があります。技術力は武器になる。しかし、武器だけでは戦場を選べない。ここで私は、本書の主張に対してある種の居心地の悪さを感じる。キャリアを「設計」するという発想自体に、違和感がある。私のキャリアは、計画通りに進んだことがない。偶然の出会い、予期せぬ異動、想定外のプロジェクト。そうした「偶然」の積み重ねが、今の自分を作っている。本書が示すロードマップは参考になる。しかし、ロードマップ通りに進むことが正解だとは思わない。計画を持つことと、計画に縛られることは違う。本書を読みながら、私は自分のキャリアを「設計」するのではなく、「振り返る」ことの方が多かった。ソフトウェアエンジニアガイドブック ―世界基準エンジニアの成功戦略ロードマップ作者:Gergely Orosz,久富木 隆一（翻訳）オーム社Amazonバックエンドエンジニアのためのインフラ・クラウド大全www.shoeisha.co.jpキャリアを考えるとき、自分に影響を与えてくれた人の存在は大きい。尊敬するnetmarkjpさんの著書です。私がエンジニアとして仕事をする中で、netmarkjpさんから学んだことは数え切れません。その方が書いた本となれば、読まないわけにはいかなかった。本書は「基礎知識」と銘打たれた23章から構成されています。可用性、キャパシティ、パフォーマンス、監視、セキュリティ、DevOps、SRE——インフラに関わるエンジニアが押さえるべき領域を網羅的にカバーしている。しかし、この本の価値は網羅性だけではありません。各章に、実務経験に裏打ちされた「なぜそうするのか」が詰まっている。基礎とは、簡単という意味ではない。基礎とは、すべての基盤になるという意味だ。バックエンドエンジニアがインフラを理解することの意味は、年々大きくなっていると感じます。クラウドネイティブな環境では、アプリケーションとインフラの境界が曖昧になっている。コンテナ、Kubernetes、オブザーバビリティ——これらを理解せずに、本番環境で動くシステムは作れない。アプリだけ書けても、本番では動かせない。本書は、その橋渡しをしてくれる一冊です。 speakerdeck.comバックエンドエンジニアのためのインフラ・クラウド大全【リフロー型】作者:馬場 俊彰,株式会社X-Tech5翔泳社Amazon作る、試す、正す。アジャイルなモノづくりのための全体戦略作る、試す、正す。　アジャイルなモノづくりのための全体戦略bnn.co.jp技術の基礎を固め、システムを作る。しかし、作ったものが「正しいもの」かどうかは、また別の問題です。市谷聡啓さんの到達点とも言える一冊です。『カイゼン・ジャーニー』『正しいものを正しくつくる』を経て、20年以上の実践知が凝縮されています。note.com本書のタイトル「作る、試す、正す」は、ものづくりの本質を端的に表しています。作って終わりではない。試して、学んで、正す。その繰り返しの中で、少しずつ「正しさ」に近づいていく。完成形を目指すのではなく、動き続けることがゴールだという考え方です。私がこの本で最も考えさせられたのは、「正しさ」の捉え方でした。最初から正しいものを作ろうとすると、動けなくなる。かといって、何も考えずに作り始めると、迷子になる。本書が提示するのは、その中間にある姿勢です。「正しさ」は最初から存在するものではなく、作り、試し、正す過程で立ち現れてくるもの。だから、完璧な計画を立てることより、素早く試して学ぶ仕組みを整えることのほうが大事だと言う。この考え方は、ソフトウェア開発に限った話ではないと思います。仕事全般、もっと言えば生き方にも通じる。最初から「正解」を知っている人はいない。やってみて、失敗して、修正して——その繰り返しの中で、少しずつ「あるべき姿」が見えてくる。正しさを探すのではなく、正しくなる状況をつくる。本書のこの言葉は、私の仕事だけでなく、物事への向き合い方そのものを言語化してくれました。作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazon良いコードの道しるべbook.mynavi.jp素早く適応しながら開発を進める。しかし、その過程で生まれるコードの品質はどう担保するか。この本を読んで、私は「説明の仕方」を学びました。動くコードを書くことは、実はさほど難しくない。大事なのは、書いたコードを他の人や将来の自分が読んで正しく理解できること——本書を通して伝えられる。本書の内容自体は、経験を積んだエンジニアにとって目新しいものではありません。命名、コメント、関数やクラスの分割、依存関係の整理、自動化テスト。どれも「基本」と呼ばれるものばかりです。しかし、この本の価値は内容の新しさではなく、説明の丁寧さにあります。なぜその原則が有用なのか、どうしてそう書くべきなのか——「なぜ」を省略せずに解説している。私がこの本を評価するのは、「人に説明するときの参考になる」からです。チームに若手が入ってきたとき、コードレビューで指摘するとき、「なぜこう書くべきか」を説明する必要がある。そのとき、自分の頭の中にある暗黙知を言語化するのは意外と難しい。本書は、その言語化の手本を見せてくれます。基本を、基本のまま、分かりやすく伝える。それは簡単なことではない。良いコードの道しるべ　変化に強いソフトウェアを作る原則と実践作者:森 篤史マイナビ出版AmazonClean Code, 2nd Editionlearning.oreilly.com良いコードの基本を学んだら、次はその原則を深く考えたい。Robert C. Martin（Uncle Bob）による『Clean Code』の第2版です。2008年に出版された初版から16年、全面的に書き直されました。初版を読んだのは何年も前のことです。その後、私のコードは変わったのか。正直に言えば、変わった部分もあれば、変わらなかった部分もある。だからこそ、第2版を手に取りました。自分がどこまで成長したのか、どこで止まっているのか、確認したかった。第2版で印象的だったのは、AI時代に対する著者の姿勢です。「コードはいずれなくなる」「AIがすべて書いてくれる」——そんな予測に対して、Uncle Bobは明確に反論しています。コードは要求の詳細を表現したものであり、その詳細は抽象化できない。AIがどれだけ賢くなっても、仕様を厳密に記述する行為——つまりプログラミング——はなくならない。コードは消えない。なぜなら、コードとは要求そのものだから。この主張に私は強く共感する。そして驚いたのは、第2版がここまで大幅にアップデートされていたことだ。16年という歳月は、ソフトウェア開発の世界では永遠に等しい。にもかかわらず、Uncle Bobは単なる改訂ではなく、現代の開発環境——AI、クラウド、分散システム——を踏まえた上で原則を再構築している。初版の「良いコードとは何か」という問いは変わらないが、その答え方が2025年の文脈に合わせて書き直されている。古典を現代に蘇らせるとは、こういうことなのだと思った。本書の核心は、タイトルの通り「クリーン」であることです。しかし、「クリーン」とは完璧を意味しない。住めない「ショーハウス」ではなく、住める「クリーンな家」を目指す。クリーンなコードとは、維持し、拡張し、進化させても、その住みやすさを損なわないコードのこと。完璧ではないが、手入れされている。クリーンとは、完璧ではなく、ケアされている状態だ。もう1つ、心に残った言葉があります。「私たちは書くよりも読む時間の方が圧倒的に長い」——だからこそ、読みやすいコードを書くことが、結果として書きやすさにつながる。速く行きたければ、うまくやれ（The only way to go fast is to go well）。この原則は、初版から変わらない。そして、16年経っても色褪せない。型システムのしくみ型システムのしくみ ― TypeScriptで実装しながら学ぶ型とプログラミング言語www.lambdanote.comクリーンなコードを書くための原則を学んだ。では、その原則を支える道具——型システム——はどう動いているのか。遠藤侑介さんの著書です。Rubyコミッタであり、TypeProfの開発者であり、『型システム入門』の訳者でもある。その方が「型システムを実装しながら学ぶ」本を書いた。読まないわけにはいかなかった。現代の開発環境では、コードを書いている最中にエラーが判明し、文脈に適した補完候補が提示される。当たり前のように使っているこの機能、その裏側で何が起きているのか。本書は、TypeScriptのサブ言語に対する型検査器を実装しながら、その「しくみ」を解き明かしていきます。型システムの理論を学ぶ方法は、数学的な教科書を読むことだけではない。実装を通じて理解する道がある——本書はその道を示してくれます。真偽値と数値の型から始まり、関数型、オブジェクト型、再帰型、ジェネリクスへと段階的に進んでいく構成が秀逸です。各章で型検査器を拡張しながら、「なぜこの機能が必要なのか」「どう実装するのか」を体験的に学べる。私がこの本を読んで得たのは、型システムへの「畏れ」と「親しみ」の両方でした。型システムは魔法ではない。人間が設計し、実装したものだ。しかし、その設計には深い思慮がある。エディタが「このコードは間違っている」と教えてくれるとき、その背後には型検査器の地道な仕事がある。その仕事の中身を知ることで、型に対する見方が変わりました。型は、プログラムを制約するものではなく、プログラムを守るものだ。Fundamentals of Software Engineeringlearning.oreilly.com型システム、クリーンコード、アーキテクチャ——ここまで個別の技術トピックを深掘りしてきました。しかし、それらを俯瞰的に捉える視点も必要です。ソフトウェアエンジニアリングの基礎を幅広くカバーしている一冊です。流行のフレームワークは数年で入れ替わる。しかし、基礎的な原則は変わらない。フレームワークは変わる。基礎は変わらない——長くこの業界にいると、この事実を繰り返し実感します。AIがコードを生成してくれる時代になって、基礎の重要性はむしろ高まっていると感じます。AIの出力をそのまま受け入れるのではなく、評価し、改善し、統合する。その判断ができるのは、基礎を理解している人間だけです。AIの出力を評価できるのは、基礎を知っている人だけ——特定の技術やフレームワークに依存しない普遍的な原則を、改めて確認するために本書を読みました。Fundamentals of Software Engineering: From Coder to Engineer (English Edition)作者:Schutta, Nathaniel,Vega, DanO'Reilly MediaAmazonThe Product-Minded Engineerlearning.oreilly.com基礎を学び、技術を深め、システムを作る。しかし、技術的に正しいものを作ることと、ユーザーに価値を届けることは、必ずしも同じではありません。エンジニアとして長く仕事をしていると、技術的に正しいことと、ビジネスとして正しいことが一致しない場面に何度も遭遇します。コードが動くだけでは十分ではない。そのコードが、ユーザーにどんな価値を届けているのか。コードを書くことと、価値を届けることは違う——この違いを理解することは、プロダクトに関わるエンジニアにとって必須のスキルです。エンジニアとして仕事をしていると、「ユーザーにとっての価値」と「技術的な正しさ」の間にギャップがあることに気づきます。たとえば、99.9%の可用性は技術者にとっては誇らしい成果でしょう。しかし、99.9%を裏返すと0.1%のダウンタイム。年間に換算すると約8時間の停止を意味する。ユーザーにとって、その8時間がどれだけ痛いか。99.9%は、ユーザーにとっては年間8時間の停止を意味する——技術的な数値をビジネスインパクトに翻訳できること。それがプロダクト思考の1つの形であり、本書はその視点を養う上で役立ちました。The Product-Minded Engineer: Building Impactful Software for Your Users (English Edition)作者:Hoskins, DrewO'Reilly MediaAmazonThe Engineering Leaderlearning.oreilly.comプロダクト思考を身につけ、技術とビジネスの両方を見られるようになる。すると、次に見えてくるのはリーダーシップの課題です。リーダーシップについて書かれた本は多いですが、本書は地に足のついた実践的なアドバイスが詰まっています。誰かがキャリアを設計してくれるわけではない。自分で考え、自分で動く必要がある。自分のキャリアの責任者は、自分である——ある程度経験を積むと、この現実を受け入れざるを得なくなります。本書は、その受け入れた後に何をすべきかを具体的に示してくれます。自分自身を導くこと、他者を導くこと、チームを導くこと、そしてチームを超えて導くこと。まず自分を導けないなら、他者は導けない——この順序は重要です。自己管理ができていない人間が、チームをまとめられるはずがない。「マネージャーになる」ことだけがリーダーシップではない。ポジションに関係なく、チームに良い影響を与えることはできる。リーダーシップは、ポジションではなく行動である——この考え方は、IC（Individual Contributor）としてのキャリアを続ける上でも指針になっています。The Engineering Leader: Strategies for Scaling Teams and Yourself (English Edition)作者:Huston, CateO'Reilly MediaAmazonエンジニアリングリーダー ―技術組織を育てるリーダーシップとセルフマネジメント作者:Cate Huston,岩瀬 義昌（翻訳）,岩瀬 迪子（翻訳）オーム社Amazon"Looks Good to Me"learning.oreilly.comリーダーシップを発揮する場面は、会議室だけではありません。日々の開発で最も頻繁に行われるコミュニケーションの1つが、コードレビューです。コードレビューは、品質保証の手段であると同時に、チームの学習機会でもある。バグを見つけるだけがレビューの役割ではない。知識を共有し、コードの意図を確認し、チーム全体の理解を揃える。レビューは、コードのためではなく、チームのためにある——この視点で見ると、レビューの仕方が変わってきます。コードレビューを「チームスポーツ」として捉える考え方に共感しました。個人の技術力を競う場ではなく、チーム全体の品質とスキルを向上させるための協働の場として位置づける。レビューコメントは、批判ではなく、贈り物である——この姿勢を持てるかどうかで、チームの雰囲気は大きく変わります。しかし、私はこの「贈り物」という表現に、少しだけ引っかかる。贈り物は、受け取る側が喜ぶものだ。しかしコードレビューのコメントは、時に厳しいことも言わなければならない。「ここは根本的に設計を見直すべきだ」と指摘することは、贈り物というより、苦い薬に近い。「贈り物」という美しい比喩に逃げて、言うべきことを言わなくなるのは本末転倒だ。本書の主張は正しいが、その比喩を鵜呑みにすると、レビューが馴れ合いになる危険がある。厳しさと敬意は両立できる。そのバランスこそが、本当の意味での「贈り物」なのだと思う。最後に「LGTM」と承認するのは人間です。その承認は、コードへの同意であると同時に、チームメンバーへの信頼の表明でもある。LGTMは、チームの信頼の証である——この認識を共有できているチームは、レビューが建設的になるし、心理的安全性も高まります。"Looks Good to Me": Constructive code reviews (English Edition)作者:Braganza, AdrienneManningAmazonLooks Good To Me作者:Adrienne Braganza秀和システムAmazonおわりに26冊。感想文を書き終えて、その数字を見つめている。多いのか少ないのか、正直わからない。まぁ多いか。「今年もたくさん読みましたね」と言われれば悪い気はしないし、「それだけ？」と言われればちょっとへこむ。結局、他人の評価を気にしている。読書量なんて自己満足だと言いながら、どこかで認めてほしがっている。振り返ると、今年の本には共通点があった。『Beyond Vibe Coding』は、AIに頼りすぎている自分を突きつけてきた。『LLMOps』は、正解が定義できないシステムの難しさを教えてくれた。『ソフトウェア設計の結合バランス』は、疎結合という呪縛から解放してくれた。『Taming Your Dragon』は、技術的負債と共存する道を示してくれた。どの本も、私に「それでいいのか」と問いかけてきた。『Terraform in Depth』を読んだ夜のことを思い出す。ステート管理のベストプラクティスなんて、AIに聞けば30秒で返ってくる。でも私は、著者が過去にやらかした失敗談のほうを覚えている。「これで痛い目を見た」という告白。公式ドキュメントには絶対に載らない、その生々しさ。なぜか、そっちのほうが頭に残る。正解より失敗のほうが記憶に焼きつくのは、私という人間の性質なのかもしれない。『Beyond Vibe Coding』を読んだとき、嫌な気持ちになった。自分のことを書かれている気がしたからだ。AIに聞いて、答えをもらって、なんとなくわかった気になる。その繰り返し。「なぜ」を考えなくなっていた。本を読むという行為は、その怠惰な自分への処方箋だったのかもしれない。ページをめくる時間だけ、「なぜ」を考え続けることができる。本は答えをくれない。くれるのは「そうだろうか」という違和感だ。著者の主張に首をかしげる。その違和感を言語化しようとする。そうやって、自分の考えが少しずつ形になっていく。AIは答えを返してくれる。でも「そうだろうか」とは返してくれない。たぶん、そこが決定的に違う。今年は、AI/LLMの運用が本格化した年だった。プラットフォームエンジニアリングが変わり、組織の話が増えた。技術だけ見ていればよかった時代は、とっくに終わっている。その変化に追いつこうとして、本を読んだ。読んで、ブログを書いて、登壇した。アウトプットしないと身につかない。言い聞かせるように、繰り返してきた。でも、本当のことを言えば、追いつこうとしていたわけではないのかもしれない。変化の中で、自分が何者であるかを確かめたかった。AIがコードを書いてくれる時代に、なぜ私はエンジニアをやっているのか。答えは出ていない。出ていないけれど、本を読むたびに、その輪郭が少しだけ見えてくる気がする。2025年はまだ3週間ほど残っている。年末年始に読んだ本は、来年の記事で。毎年同じことを書いている気がする。でも来年も、たぶんまた書くのだろう。誰に頼まれたわけでもないのに、12月になると、この作業を始めてしまう。本を読むことに意味があるのか。正直、わからない。わからないけれど、やめられない。AIがどれだけ賢くなっても、300ページを読み通した時間は消えない。その時間が、自分を少しだけ変えてくれたような気がする。気がするだけかもしれない。でも、その「気がする」を信じて、来年も本を開くのだと思う。正解を得ることだけが目的なら、エンジニアをやっている意味がない。はじめにで書いたこの言葉が、25冊の感想文を書き終えた今、少しだけ違って聞こえる。正解がないから難しい。正解がないから面白い。正解がないから、エンジニアを続ける価値がある。本を読む意味がある。来年もきっと、答えの出ない本を読み続けるのだろう。そして、また12月になったら、この記事を書く。それでいい。それがいい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[とあるMLエンジニアの年末年始の予定の呟き]]></title>
            <link>https://zenn.dev/akasan/articles/2025_new_years_eve</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/2025_new_years_eve</guid>
            <pubDate>Wed, 10 Dec 2025 13:25:20 GMT</pubDate>
            <content:encoded><![CDATA[今回はMLエンジニアとしてひたすら精進を頑張っている私が今年の年末年始どのように過ごす予定か、誰得ではありますしこんなことをzennに書いている人がいるかわからないですが、まとめてみます。 まずはこのアドベントカレンダーについて2025/04/18に爆誕してすでに230日を超えていますが、まずは2025/12/25までは毎日投稿を続ける予定です！その後についてですが、年末年始は流石にちょっとお休みしようかなと思っており、2025/12/26から2026/1/4はお休みしようと思っています。もちろん、途中で急に書きたいことがあれば発信しますが、謎の義務感・使命感によって続けられている...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年版 私がAIエージェントと協働しながら集中する方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/10/092706</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/10/092706</guid>
            <pubDate>Wed, 10 Dec 2025 00:27:06 GMT</pubDate>
            <content:encoded><![CDATA[集中できなくなった何かがおかしい。AIエージェントを使い始めてから、自分が壊れていくのを感じていた。以前は4〜5時間ぶっ通しで集中できた。コードを書き始めたら、気づいたら夕方になっていた。あの没入感。あの充実感。それが、完全に消えた。30分も持たない。いや、10分だろうか。1つの作業に没頭しようとしても、すぐに別の作業に引き戻される。戻ってきたら、さっき何をしていたか忘れている。頭の中が常にざわついている。自分の脳が、自分のものではなくなっていく感覚があった。最初は自分を責めた。集中力が落ちたのは、体力のせいか。年齢のせいか。怠けているのか。スマホの見すぎか。でも違った。同じように苦しんでいる人が、周りにもいた。きっと、最初からうまく馴染める人もいるのだろう。複数のエージェントを同時に回しながら、涼しい顔で成果を出せる人。元々、全体を俯瞰しながら動くのが得意な司令官タイプ。私は違った。複数のエージェントが並行して動いている。1つのエージェントに指示を出して、出力を待っている間に別のエージェントの出力を確認する。確認が終わったら修正指示を出して、また別の作業に移る。案件も複数が同時に走っている。厄介だったのは、見せかけ上の効率は上がっていたことだ。タスクは消化されている。アウトプットも出ている。だから最初は原因に気づけなかった。でも、何かがおかしい。同じ時間、同じ環境で働いているのに、以前のように深く没入できない。達成感がない。自分は変わっていないはずなのに、なぜ？数字に現れない損失があった。タスクの消化数は増えた。しかし、1つ1つの仕事に対する理解の深さが落ちていた。コードをAIと共に書いているのに、なぜそう書いたのか説明できない。レビューを通しているのに、本当に良いコードなのか判断できていない。量は出ている。でも、自分の中に何も残らない。学習効率が落ちていた。成長している実感がなかった。品質の問題もあった。アウトプットは出ている。しかし、それは本当に良いアウトプットなのか。深く考える時間がないまま、次々とタスクを流していく。表面的には回っている。後から振り返ると「なぜこんな設計にしたんだ」と感じることが増えていた。速く走っているつもりが、同じ場所をぐるぐる回っていただけだった。そして何より、このペースや仕事のやり方が続くのかという不安があった。毎日、頭の中が騒がしい。仕事が終わっても、脳が休まらない。週末になっても回復しきれない。短期的には回っている。でも、1年後、3年後も同じように働けるのか。効率が上がったように見えて、実は遠回りしている道を走っていたり自分を前借りしているだけではないのか。ポモドーロ・テクニックを再稼働させた。25分の作業と5分の休憩を繰り返す方法だ。効果はあった。でもAIエージェントとの協働が始まってからは、25分の中での集中すら維持できなくなっていたというた25分のタスクというのを見積もれなくなった。通知を切った。効果なし。まとまった時間を確保した。効果なし。瞑想アプリを入れた。効果なし。何をやっても、うまくいかなかった。追い詰められていた。このままでは仕事にならない。でも、AIエージェントなしで働くという選択肢はもうなかった。環境を変えるのではなく、自分を変えるしかなかった。観察するという発見行き詰まっていたとき、『大人のADHDのためのマインドフルネス』という本に出会った。ADHDの当事者向けに書かれた本だが、読んでいて「これは自分のことだ」と思う記述が多かった。注意が散漫になる。複数のことが同時に気になる。1つのことに没頭できない。ADHDかどうかは関係なかった。今の自分が抱えている問題そのものだった。本の中で紹介されていた手法の1つが、「観察する」ということだった。作業中、ふと自分自身を観察してみる。今どんな気分か。注意はどこに向いているか。身体の感覚はどうか。判断せず、ただ気づく。最初は半信半疑だった。自分を観察しながら作業するなんて、むしろ集中の妨げになるのではないか。リソースを分散させているだけではないか。でも、他に試す手段がなかった。藁にもすがる思いだった。やってみると、不思議なことが起きた。集中が途切れにくくなったのだ。いや、正確には違う。集中は途切れる。でも、途切れた瞬間に気づけるようになった。観察している自分がいるから、「あ、今逸れた」とすぐにわかる。わかるから、すぐに戻れる。これまで私は、集中を「途切れないように維持するもの」だと思っていた。途切れたら負け。だから途切れないように必死に守ろうとしていた。でも違った。集中は「維持するもの」ではなく「戻るもの」だったのだ。途切れること自体は問題ではない。戻れるかどうかが問題だった。この発見は、私の集中に対する考え方を根本から変えた。完璧な集中を目指すのではなく、素早い復帰を目指す。壁を作って守るのではなく、柔軟に戻る力を育てる。防御から回復へ。発想の転換だった。今では複数の案件を並行して回しながら、開発タスクを5本同時に進め、ブログも2〜3本並列で書けるようになった。ポモドーロの25分間、集中が途切れることはほとんどない。途切れても、数秒で戻れる。この実践を、私は「微観法」と呼んでいる。自分の微細な変化を観察する方法、という意味だ。正式な名称があればぜひ教えてほしい。この節の内容は『大人のADHDのためのマインドフルネス』（リディア・ザイローウスカ著）を参考にして自分なりに実践していたものです。また、表現について @tsumikino_ さんの投稿に影響を受けていたため、修正いたしました。参照元を明記せずご不快な思いをさせてしまい、申し訳ありませんでした。ご指摘いただきありがとうございました。以前の集中と何が違うのか以前の私にとって、最良の集中状態とは湖の底に沈んでいくような感覚だった。体の感覚はどこか希薄になる。なぜ自分がキーボードを打っているのかわからなくなる。意識と作業の境界が溶けて、ただコードが生まれ、ただ文章が流れていく。水面の光が遠ざかり、静かな深みに降りていく。その状態に入れたとき、驚くほどの量と質の仕事ができた。あの深さを、私は愛していた。この「深く沈む」集中は、1つの大きなタスクに長時間取り組むときには最適だった。中断がなく、自分のペースで進められるソフトウェア開発や執筆の環境では、これ以上の方法はなかった。しかしAIエージェントと協働する環境では、この方法が通用しなくなった。深く沈もうとしても、エージェントの出力確認で水面に引き戻される。複数の案件を抱えていれば、1つに没入できない。深く沈むには、水面が静かでなければならない。でも今の水面は常に波立っている。そこで発想を変えることにした。深く沈むのではなく、水面近くに留まる。没入するのではなく、観察する。集中の「深さ」ではなく、「復帰の速さ」を重視する。ここで1つ、重要なことに気づいた。集中は、環境次第で形を変える。静かな水面なら深く沈む集中が最適だし、波立つ水面なら水面近くを泳ぐ集中が最適だ。どちらが優れているわけではない。環境に合った集中の持ち方がある。つまり、集中とは「自分の能力」ではなく「環境との関係」なのだ。同じ人間でも、環境が変われば最適な集中の形は変わる。集中できないのは能力の問題ではない。環境と方法のミスマッチだ。私は長い間、自分の集中力が落ちたと思っていた。でも違った。環境が変わったのに、方法を変えていなかっただけだった。なぜ観察すると集中できるのかここで疑問が生じる。作業に100%集中したほうが効率的なはずではないか。なぜ10〜20%を「自分の観察」に割くと、かえって集中できるのか。理由はおそらく「注意の逸脱」の仕組みにある。人間の注意は、放っておくと必ず逸れる。これは避けられない。問題は、逸れること自体ではなく、逸れたことに気づくまでの時間だ。普通は、気が逸れてから5分、10分経って「あ、逸れてた」と気づく。スマホを開いて、気づいたら15分経っていた。そういう経験は誰にでもある。この5分、10分、15分が積み重なって、1日の生産性を静かに破壊していく。微観法では、意識の一部を「自分を観察する視点」として常に確保しておく。すると、注意が逸れ始める瞬間を捉えられるようになる。「スマホを見ようかな」と思った瞬間。「積んである本を読みたいな」と思った瞬間。「コーヒーを淹れに行こうかな」と思った瞬間。「このタスク面倒だな」と感じた瞬間。逸れてから3秒で気づき、すぐ戻れる。5分後に気づくのと、3秒後に気づくのでは、累積の損失がまったく違う。100%集中しようとして5分ごとに逸れるより、90%の集中を安定して維持するほうが、結果的に多くの仕事ができる。もう1つ理由があると思っている。「退屈の無効化」だ。脳は刺激が足りないと退屈を感じ、新しい刺激を求める。SNSを見たくなるのはこのためだ。作業が単調になると、脳が「もっと刺激をくれ」と要求してくる。しかし自分の内面を観察対象にすると、そこには常に微細な変化がある。呼吸の深さ、肩の緊張、思考の流れ、感情の揺らぎ。これは揺らぐ炎のように、予測不能だが安定していて、見続けることができる。外部刺激に頼らなくても、脳が求める新規性は内側から供給できる。具体的なやり方方法は単純だ。ある日、疲れ果てて帰ってきた夜のことだった。だるい。本当にだるい。でも仕事が残っている。そのだるさを抱えたまま、仕方なくキーボードに向かった。そのとき、ふと気づいた。「だるいな」と感じている自分を、どこかで観察している。だるさはある。でも、だるさを見ている自分もいる。その「見ている自分」は、意外と冷静だった。不思議なことに、観察を続けていると作業が進んだ。だるさは消えない。でも、だるさに飲み込まれない。その感覚を忘れたくなくて、言語化しておくことにした。それが微観法の始まりだった。ポイントは、観察の「解像度」を下げることだ。「今、自分は何を考えているか」「なぜそう感じているか」と分析しようとすると、認知資源を食う。作業と同時にはできない。分析せず、ただ「ある」と気づくだけでいい。「退屈だな」と感じたら、なぜ退屈かは考えない。「退屈がある」とだけ認識する。それだけで十分だ。例えば、作業を始める前に5秒だけ自分の状態を確認する。呼吸は浅いか、深いか。肩に力が入っているか。頭の中は静かか、騒がしいか。答えを出す必要はない。ただ気づくだけでいい。これで観察モードが起動する。作業に入ったら、意識の10〜20%を「自分を観察する視点」に割り当てる。残りの80〜90%で作業しながら、バックグラウンドで自分の変化を捉え続ける。「今、少し退屈になってきた」「焦りが出てきた」「集中が浅くなっている」。この観察は論理的に行う必要はない。分析しなくていい。揺らぐ炎を眺めるように、ただ見ていればいい。観察を続けていると、注意が逸れ始める瞬間を捉えられるようになる。「スマホを見ようかな」という考えが浮かんだ瞬間に気づく。気づいたら、その考えを追いかけずに作業へ戻る。「このタスク面倒だな」と感じたら、その感覚を認めて、それでも続ける。別のことを考え始めたら、気づいた時点で戻る。それだけだ。シンプルだが、これが全てだ。作業の構造微観法と組み合わせて効果が上がった作業の構造がある。まず、案件は混ぜない。案件Aで開発をしていて、案件Bのメールに返信して、また案件Aに戻る。以前はこれを普通にやっていた。普通に効率の悪いマルチタスク。でもこれはAIエージェントと働いていても同じだった。案件を切り替えるとき、脳は多くのことを読み込み直している。関係者は誰か。この人にはどう接するべきか。過去にどんな経緯があったか。暗黙の制約は何か。自分はこの案件でどういう立ち位置か。これは単なる情報ではなく、人間関係のシミュレーションだ。技術的は話だけではない。だから重い。案件の「重さ」には差がある。関係者が多い案件は重い。長期で複雑な経緯がある案件は重い。緊張感のある関係を含む案件はより重い。これらを頻繁に切り替えると、作業そのものより切り替えで消耗する。だから案件単位で時間を区切っている。この2時間は案件A、次の2時間は案件B。案件の中で完結させる。次に、同一案件内ではモードを切り替える。開発モードではコーディングや設計、AIエージェントへの指示出しをする。執筆モードではドキュメントや企画書、翻訳に取り組む。準備モードでは開発や執筆を円滑に進めるための下調べ、環境構築、資料整理、Slackの確認などをする。Slackの通知は基本的に無視している。見るのは準備モードのときだけだ。開発中や執筆中にSlackへ戻っていたら、何も進まない。通知は他人の優先順位だ。自分の優先順位を守れ。ポモドーロの25分をモード単位で使っている。アプリはBe Focusedは有料版を買い上げで使っている。随分前に購入したのですがとにかく困ることがないので別に移ろうと思ったことがないなので比較などはできない。Be Focused Pro - Focus TimerDenys Ievenko仕事効率化¥2,000apps.apple.com同じ種類の作業は並列で回す同じモード内であれば、複数の作業を並列で回せる。ブログを書くとき、1本だけを最初から最後まで書くのではなく、2〜3本を並列で進める。1本目の導入を書いて、詰まったら2本目に移る。2本目の本論を書いて、また1本目に戻る。開発でも同様で、5本程度のタスクを並列で回している。なぜこれができるのか。「書くモード」や「開発モード」を維持したまま、対象だけを切り替えているからだ。モードを起動するコストは高いが、一度起動してしまえば、対象を変えるコストは低い。しかし並列できる数には限界がある。開発は5本程度いけるが、ブログは2〜3本が限界だ。この差は「状態の外部化」で説明できる。開発はgit worktree（複数のブランチを同時に扱える開発ツール）やコード自体が「どこまでやったか」「何をしようとしていたか」を保持してくれる。見れば思い出せる。脳が状態を覚えておく必要がない。だから多くを並列にできる。ブログは違う。「この記事で何を言いたかったか」「どういう構成にするつもりだったか」が頭の中にしかない。外部化されていないから、並列の限界が低い。二重の飽き防止ここまで来て、自分が二重の飽き防止システムを走らせていることに気づいた。飽きは敵だ。でも飽きは設計で無効化できる。マクロレベルでは、同種作業の並列によって、外から新規性を供給している。ブログ1からブログ2へ、またブログ1へ。1つの記事を長時間書き続けると退屈になる。でも複数を回していれば、戻ってきたときに新鮮な目で見られる。ミクロレベルでは、微観法によって、内から新規性を生成している。自分自身の微細な変化を「見るもの」として扱っている。外部刺激がなくても退屈しない。この二重構造があるから、飽きによる集中力低下を防ぎながら、並列作業中に「自分がどこにいるか」を見失わずにいられる。実際、微観法がなければ並列作業は成立しない。複数の作業を回していると、「あれ、今どこにいたっけ」「何をしようとしてたんだっけ」となりやすい。微観法で自分の認知状態を観察し続けているから、位置感覚を保てる。迷子にならないから、遠くまで行ける。ようやく気づいたことここまで来て、ようやく気づいた。開発という仕事の性質そのものが変わっていたように思える。戦国無双と信長の野望というゲームがある。どちらも戦国時代を舞台にしているが、まったく別のゲームだ。戦国無双は自分が武将となって敵を斬りまくるアクションゲーム。信長の野望は君主となって複数の武将に指示を出し、国全体を動かすシミュレーションゲーム。自分で戦うか、全体を指揮するかの違いだ。AIエージェントとの協働は、仕事を戦国無双から信長の野望に変えた。プレイヤーから司令官へ。自分で剣を振るうのではなく、複数の部下に指示を出して全体を動かす。求められる集中の質が、根本から違う。私は最初、戦国無双の集中法で信長の野望をプレイしようとしていた。一人で深く没入しようとしていた。だからうまくいかなかった。私にとって微観法は、信長の野望のための集中法だったのだ。自分の状態を観察し続けることで、複数の部下（エージェント）の動きを把握し、全体を俯瞰する。深く沈むのではなく、広く見渡す。集中の形が変わったのではない。仕事の形が変わったのだ。深い集中が戻ってきた微観法を続けて数ヶ月、予想していなかった変化があった。諦めたはずのものが、形を変えて戻ってきた。以前の「湖に沈む」ような深い集中が、少しずつ戻ってきている。最初は水面近くを泳ぐだけだった。浅いけれど安定した集中。それはそれで十分に機能していた。でも続けているうちに、観察しながらでも深く入れる瞬間が出てきた。観察が自動化されてきたのだろう。最初は意識的に10〜20%を割り当てていた。それが習慣になり、無意識でも観察が走るようになった。すると、残りの意識をより深く作業へ向けられるようになった。意識して始めたことが、やがて無意識になる。それが習得だ。今は、水面近くで泳ぎながら、ときどき深く潜れる。潜っている間も、どこかで自分を観察している感覚がある。以前の「なぜキーボードを打っているかわからなくなる」状態とは少し違う。意識はあるのに、深い。完全に以前と同じではない。でも深さと柔軟さの両方を持てるようになりつつある。そして気づいた。あの「見せかけの効率」が消えていた。タスクは消化されている。でも今は、なぜそう書いたか説明できる。自分の中に残るものがある。量だけでなく、質も戻ってきた。集中の持ち方を変えたことで、仕事との向き合い方そのものが変わっていた。最近、もう1つ変化が起きている。案件Aの開発をしている待ち時間に、同じ案件の軽い調整作業ができるようになってきた。エージェントが処理している間の数十秒から数分の隙間で、ちょっとした修正や確認を挟める。自分がどこにいるかを常に把握できているから、短い寄り道をしても迷子にならない。進化は、まだ続いている。これからこれが2025年現在、AIエージェントと協働しながら働いている一人のソフトウェアエンジニアの集中法だ。完璧ではない。でも機能している。環境が変われば、集中の持ち方も変わる。以前の「深く沈む」集中法は、中断と再開が前提の環境には合わなくなった。代わりに見つけたのが、微観法だった。自分の微細な変化を観察し続けることで、注意の逸脱を早期に検知し、復帰を速くする。深さではなく、復帰の速さで勝負する。エージェントはこれからも進化する。集中の持ち方も、また変わるだろう。今の方法が最終形ではない。でも、変化に適応する方法は見つけた。微観法は才能ではなく方法だ。次の作業を始める前に、5秒だけ自分の呼吸を確認してみてほしい。5秒でいい。そこから全てが始まる。かつて愛した湖の深みに、今は違う形で戻れるようになった。水面近くを泳ぎながら、好きなときに深く潜れる。そして、いつでも水面に戻れる。参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon一点集中術――限られた時間で次々とやりたいことを実現できる作者:デボラ・ザックダイヤモンド社Amazon集中力がすべてを解決する　精神科医が教える「ゾーン」に入る方法作者:樺沢 紫苑SBクリエイティブAmazonイェール大学集中講義 思考の穴――わかっていても間違える全人類のための思考法作者:アン・ウーキョンダイヤモンド社Amazon大人のADHDのためのマインドフルネス作者:リディア・ジラウスカ,大野裕,中野有美金剛出版Amazon多動脳―ＡＤＨＤの真実―（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonヤバい集中力　1日ブッ通しでアタマが冴えわたる神ライフハック45作者:鈴木 祐SBクリエイティブAmazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[rustで非同期ランタイム実装してみた]]></title>
            <link>https://zenn.dev/sraku/articles/2e50371363cbaa</link>
            <guid isPermaLink="false">https://zenn.dev/sraku/articles/2e50371363cbaa</guid>
            <pubDate>Tue, 09 Dec 2025 15:00:05 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事はQiita 3-shake Advent Calendar 2025 シリーズ10日目の記事です。以前Rustのイベントに参加した時に非同期周りの話がでて、少し興味が湧いたので実装してみたというお話になります。リポジトリはこちらですhttps://github.com/sraku2159/async_runtimeはじめにRustにおける非同期処理の特徴を概説します。 Rustの非同期処理の特徴Rustはいわゆる協調的マルチタスクと呼ばれる機構によって非同期処理を実現しています。つまり、シグナルなどによってプリエンプトされるのではなく、async関...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[最近読んでいて興味深かった記事紹介 Vol.3]]></title>
            <link>https://zenn.dev/akasan/articles/interesting_tech_blogs_3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/interesting_tech_blogs_3</guid>
            <pubDate>Tue, 09 Dec 2025 13:02:46 GMT</pubDate>
            <content:encoded><![CDATA[今回は読んでいて良かった記事を紹介するシリーズの第3弾になります。過去のシリーズは以下にまとめていますのでぜひご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Open Source for DevelopersこちらはNVIDIAのエンジニアの方がコントリビュートしているOSSのリストが載っています。世界最高峰レベルのエンジニアがどのようなOSSに関わっておられるのか興味がありみていました。https://developer.nvidia.com/open-source?sortBy=open_source_projec...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[地方リモートエンジニア歴3年、やってよかった7つのこと]]></title>
            <link>https://zenn.dev/yuu0w0yuu/articles/f44cceadef5a53</link>
            <guid isPermaLink="false">https://zenn.dev/yuu0w0yuu/articles/f44cceadef5a53</guid>
            <pubDate>Tue, 09 Dec 2025 07:23:08 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2025の11日目の記事です。おぼろげながら浮かんできたんです。7という数字が。 朝のラジオ体操私が住んでいる長野県の松本市は、晴天率が全国的に見ても高く、一年を通して晴れていることが多いです。ある朝、「こんな爽やかな朝、何かせねば」と思って始めたのがラジオ体操でした。第一だけなら約3分ほど。ほどよい負荷で爽やかな朝を迎えることができます。旅行先でも必ずやります。漫然とやるのではなく、お手本動画のように綺麗なフォームを意識することが重要です。肩周り・腰回りをブンブン回すので、デスクワークで姿勢が歪みがちなあなた、特...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[実力とは“最悪の自分”が決める]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/09/092256</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/09/092256</guid>
            <pubDate>Tue, 09 Dec 2025 00:22:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに私たちは「実力」という言葉を履き違えています。特に私がそうでした。様々な人の助力で得た結果、たまたま条件が揃って出せた最高到達点を「自分の実力」だと勘違いしていました。そして、その水準に届かない日々の自分を見て、「なんでもっとできないんだ」と追い込んでいました。結果は散々なものでした。心身ともに疲弊し、パフォーマンスはさらに落ち、悪循環に陥りました。しかし、その経験から大きな学びもありました。ゾーンに入り、神がかった速度でコードを書く自分。難解なバグを一瞬で特定する自分。私たちは、あの奇跡的な瞬間を「自分の実力」だと信じ、そうでない日を「調子が悪かった」と言い訳します。逆です。何もやる気が起きず、頭も回らず、ただ惰性でキーボードを叩いている日。その泥のような日に絞り出したアウトプット。それこそが、紛れもない私の「実力」です。 絶好調のときの成果は、再現性のない「運」や「上振れ」に過ぎません。この記事では、なぜそう言えるのか、そしてその認識がなぜ重要なのかを考えていきます。これは鬱屈とした日々を過ごしていたかつての自分に向けて書いています。「最高出力」という幻想まず、私たちが「実力」だと思い込んでいるものの正体を見てみましょう。過去半年を振り返ってみてください。「奇跡的にうまくいった日」は何日あったでしょうか。全てが噛み合い、コードがスラスラ書けて、レビューも一発で通り、障害対応も華麗にこなせた日。おそらく、片手で数えられる程度ではないでしょうか。なぜそんなに少ないのでしょうか。理由は単純です。「最高のパフォーマンス」を出すためには、無数の条件を揃える必要があります。十分な睡眠。適度なストレス。興味のある課題。邪魔の入らない環境。体調の良さ。プライベートの安定。これらすべてが揃う日は、人生において稀なのです。その稀な瞬間にしか出せないものを「実力」と呼ぶのは、ギャンブルで勝った日の収支を「年収」と呼ぶようなものです。 奇跡を前提にした人生設計は、破綻することが約束されています。それは本人にもコントロールできない「可能性の上限」であって、信頼できる「能力」ではありません。私自身の話をしましょう。このブログには、いわゆる「おい、」シリーズと呼ばれる記事があります。「おい、本を読め」「おい、スマホを置け」「おい、対話しろ」。ありがたいことに、これらの記事は多くの人に読まれています。はてなブックマークでもたくさんのコメントをいただきました。Xをフォローしてくれている人は知っていると思うのですが4冊紹介するフォーマットも実力以上にアウトプットを出せたと思います。syu-m-5151.hatenablog.comしかし、正直に言いましょう。あれは私の実力からかなり上振れしています。あの記事を書いたとき、たまたま言葉がスラスラと出てきました。たまたま自分の経験と文章のリズムが噛み合いました。たまたま読者の琴線に触れるタイミングでした。書籍レベルの何かを目指してブログとして色々出した。同じクオリティのものを、明日また書けるかと問われれば、自信を持ってイエスとは言えません。あれが私の「実力」だと思い込んでしまうと、危険です。次に書く記事が同じように読まれなかったとき、「調子が悪かった」「本来の力が出せなかった」と言い訳をしてしまいます。しかし実際には、「おい、」シリーズの方が例外なのです。私の本当の実力は、誰にも読まれない記事を淡々と書き続けられるかどうか、そちらの方にあります。では、なぜ私たちは「最高の自分」を実力だと思い込んでしまうのでしょうか。それは、そう思いたいからです。「あれが本当の自分だ」と信じることで、今の不甲斐ない自分を一時的なものとして処理できます。「今日は調子が悪いだけ」という言い訳は、私たちの自尊心を守ってくれます。しかし、その言い訳に甘えていると、現実を直視する機会を失ってしまいます。信頼は「下限」に支払われる「最高の自分」を実力だと思い込むのは、自分一人の問題なら、まだいいかもしれません。しかし、私たちは一人で働いているわけではありません。では、社会はどちらを評価するのでしょうか。「最高の自分」か、「最悪の自分」か。仕事を誰かに頼むとき、私ならどちらを選ぶでしょうか。「調子が良ければ神がかったコードを書くが、悪ければ全く動かないものを出してくる天才」か、「どんなに最悪の状況でも、必ずそこそこ動くものは持ってくる凡人」か。チームで働いていれば、答えは明らかです。前者はリスクであり、後者は計算できる資産です。天才は賭けられる。凡人は任せられる。 組織が求めているのは、後者です。なぜでしょうか。仕事には締め切りがあります。依存関係があります。他のメンバーのスケジュールがあります。私の成果物を待っている人がいます。私が遅れれば、その人も遅れます。その人が遅れれば、次の人も遅れます。「今日は調子が悪いので」という言葉は、その連鎖の中では通用しません。だから、周囲からの信頼とは、「最高の自分」ではなく「最悪の自分」に対して支払われます。あのシニアエンジニアが信頼されているのは、華麗なワンライナーを書けるからではありません。障害が起きたとき、体調が悪いときでも、最低限の品質で対応を完了させるからです。レビューが溜まっているとき、モチベーションが上がらないときでも、的確なコメントを返すからです。「この人に任せれば、最悪でもこのレベルは下回らない」という安心感。それが信頼の正体です。プロフェッショナルとは、派手なファインプレーをする人ではありません。どんな悪条件でも、期待された成果を淡々と、確実に納品できる人のことです。野球で言えば、たまにホームランを打つ選手ではなく、どんな状況でも確実にヒットを打てる選手。料理で言えば、たまに絶品を作る料理人ではなく、毎日安定して美味しいものを出せる料理人。派手さはありませんが、計算できます。それがプロです。なぜマニュアル本を読んでも「床」は上がらないのか「下限」が大事だということはわかった。では、どうすれば下限を上げられるのか。その答えを求めて、私たちは成功者の話に耳を傾けます。本、セミナー、SNS。「こうすればうまくいく」と教えてくれる人はたくさんいます。しかし、残念ながら、それらは役に立ちません。なぜでしょうか。成功とは「その人固有の条件」と「その時点での環境」が噛み合った結果であり、その組み合わせは二度と再現されないからです。10年のキャリアがあった人と、始めたばかりの人では前提が違います。たまたま有名な人にリツイートされた人と、そうでない人では運が違います。他人の成功パターンをコピーしても意味がありません。だから、私たちがやるべきことは、誰かの成功法則を学ぶことではありません。自分自身の「下限」を把握し、その下限を少しずつ上げていく仕組みを作ることです。 それは誰にも教えてもらえません。自分で試行錯誤するしかないのです。能力は文脈の中にしかない他人の成功パターンをコピーしても意味がない。自分の下限を自分で上げていくしかない。そう書きました。しかし、ここで少し立ち止まって考えたいことがあります。そもそも「能力」とは何なのでしょうか。私たちが上げようとしている「下限」とは、何の下限なのでしょうか。私たちは「能力」を、自分の中に固定的に存在するパラメータのように考えがちです。技術力がいくつ、コミュニケーション力がいくつ、というように。しかし、私はそうは思いません。能力は、環境によって大きく変わるものです。私は自分の技術力や業務遂行力を、完全に文脈依存だと思っています。ある環境では、私の思考パターンや働き方が完璧に噛み合い、高いパフォーマンスが出ます。しかし、別の環境では、私は無能になるでしょう。政治的な調整が最優先される組織や、レガシーな技術に固執する現場では、私の強みは発揮されません。あのプロジェクトがうまくいったのは、自分の技術力が高かったからでしょうか。それとも、チームメンバーが優秀だったからでしょうか。上司が適切にスコープを切ってくれたからでしょうか。インフラが安定していたからでしょうか。ドキュメントが整っていたからでしょうか。締め切りに余裕があったからでしょうか。その支えが消えた場合、同じクオリティを出せるでしょうか。「自分には能力がある」と過信するのは危険です。正しい認識はこうです。「この文脈において、これまでの経験と仕組みが噛み合って、たまたま価値が出せている」。この認識があれば、傲慢にはなれません。自分が成果を出せているのは、周囲の環境や、他者のサポートのおかげであるという事実が見えてきます。そして、その環境が変わったときに自分がどうなるかを、冷静に想像できるようになります。たとえるなら、魚と水の関係に似ています。魚は水の中では自由に泳げますが、陸に上がれば何もできません。 私たちは常に、自分の能力が機能する「水」の中にいます。その「水」がなくなったとき、私たちは何もできません。だからこそ、2つのことが必要だと私は思っています。1つは、自分に合った「水」を見つけること。自分の能力が活きる環境を選ぶこと。もう1つは、「水」がなくなったときにも最低限動けるように、自分の「下限」を上げておくことです。環境に恵まれなくても、最低限のアウトプットは出せる状態を作っておくこと。「頑張り」という免罪符能力は文脈に依存する。環境が変われば、同じ人間でも発揮できるパフォーマンスは変わる。だからこそ、自分に合った環境を見つけ、下限を上げる仕組みを作ることが大事だと書きました。ここまで読んで、こう思った人もいるかもしれません。「環境だの仕組みだの言っているけど、結局は頑張れば何とかなるのではないか」と。気持ちはわかります。私もそう思っていた時期がありました。しかし、残念ながら、そうではありません。多くの人は、能力の不足を「頑張り」で埋めようとします。環境が悪くても、仕組みがなくても、気合で乗り越えようとします。私もそうでした。しかし、「頑張り」は実力ではありません。なぜそう言えるのでしょうか。思い返してみてください。「頑張っています」という言葉を、どんなときに使ったでしょうか。私の場合、成果が出ていないときほど、その言葉を使っていました。深夜まで残業した。休日も勉強した。ドキュメントも読んだ。だから許してほしい。私も例外ではありません。締め切り前に焦って残業した経験は何度もあります。そのとき、「これだけやっているのだから」という気持ちが、どこかにありました。成果が出なくても、頑張った事実が自分を守ってくれるような気がしていました。しかし、「これだけ苦労したのだから」という免罪符は、プロの世界では通用しません。 専門的な仕事に対する報酬は、流した汗の量ではなく、生み出した価値に対して支払われるからです。私が「頑張ったのにできなかった」と最後に言ったのはいつだったでしょうか。その頑張りは、成果とどう結びついていたでしょうか。正直に振り返ると、「頑張り」と「成果」の間には、驚くほど相関がありませんでした。もう少し踏み込んで考えてみましょう。なぜ「頑張り」は実力にならないのでしょうか。人間の精神力や体力といった不安定なリソースに依存したシステムは、いずれ破綻するからです。徹夜で乗り切った。気合で押し切った。それは一時的には機能するでしょう。しかし、そのやり方は再現できません。翌週も同じことをやれと言われたら、身体が壊れます。翌月も同じことをやれと言われたら、心が壊れます。「頑張り」で出した成果は、「最高の自分」と同じです。再現性がありません。だから、実力とは呼べないのです。来月も同じことができないなら、それは実力ではありません。誤解しないでほしいのは、「頑張るな」と言いたいわけではないということです。踏ん張るべき時は、踏ん張らなければなりません。問題は、頑張ることそれ自体が目的化してしまうことです。方向を考えずにただ頑張る。成果ではなく、頑張っている姿勢で自分を守ろうとする。それは努力ではなく、努力のふりです。目指すべきは「頑張らなくても成果が出る状態」です。 怠けることではありません。頑張りに依存しなくても回る仕組みを作ることです。そうすれば、本当に踏ん張るべき時に、余力を残しておけます。環境構築という本当の能力「頑張り」に頼らない。では、具体的に何をすればいいのでしょうか。私なりの答えは、「最悪の自分でも動ける仕組みを作る」 ことです。気力ゼロの日でも実行できる仕組みを、私はいくつ持っているだろうか。この問いを自分に投げかけたとき、意外なほど少ないことに気づきました。エディタを開いたら自動でテストを走らせる。プルリクエストを出したら自動でレビュワーをアサインする。障害が起きたらアラートを飛ばし、対応手順書を自動で開く。毎朝同じ時間に、昨日のタスクの振り返りをSlackに届ける。毎週同じ曜日に、今週やるべきことをリストアップする。これはすべて、最悪の状態でも最低限の品質を担保するための仕組みです。私が目指しているのは、最悪の日でも自動的に手が動き、最低限のクオリティのものが出来上がってしまう状態を作ることです。意志の力で動くのではなく、意志がなくても動いてしまう仕組みを作る。これこそが「環境構築能力」であり、本当の意味での「実力」です。逆に、仕組み化されていない行動を見てみましょう。タスク管理ツールを開くのが面倒だから、頭の中で覚えておく。テストを書くのが面倒だから、動作確認は目視でやる。ドキュメントを書くのが面倒だから、後で誰かに聞けばいいと放置する。コードレビューを依頼するのが面倒だから、自分で何度も見直す。これはすべて、調子が良いときにしか機能しないシステムです。調子が悪くなった瞬間、すべてが崩壊します。頭の中のタスクは忘れます。目視の確認は見落とします。誰かに聞こうと思っていたことは、聞きそびれます。手を動かすまでのハードルはどこに潜んでいるでしょうか。それを仕組み化ではなく気合で乗り越えていないでしょうか。私はそう思って、少しずつ仕組みを増やしてきました。「人」を「環境」に合わせるな仕組みを作る話をしてきました。しかし、仕組みを作ろうとするとき、多くの人がある罠にはまります。「自分を変えなければ」という罠です。たとえば、こんなふうに自分を責めていないでしょうか。「なぜ自分はこんなに集中力がないのか」。「なぜ自分はこんなにやる気が出ないのか」。「なぜ自分は普通の人のように働けないのか」。その問いの立て方が、そもそも間違っています。「人」を「環境」に合わせようとするから苦しくなります。「自分を変えなければ」「自分が適応しなければ」と考えるから、うまくいかない自分を責めてしまいます。発想を逆転させるべきです。「集中力がなくても成果が出る環境を作れないか」と考える。「やる気がなくても手が動く仕組みを作れないか」と工夫する。「普通の働き方ができなくても、自分なりの働き方で成果を出せないか」と模索する。「障害」は人側にあるのではありません。環境側にあります。人を直すのではなく、環境を直す。それがエンジニアリングです。これは、私たちエンジニアにとっては馴染みのある考え方のはずです。ユーザーがシステムを使いこなせないとき、「ユーザーの能力が低い」とは言いません。「UIが悪い」と言います。システムがユーザーに合わせるべきであって、ユーザーがシステムに合わせるべきではありません。同じことが、自分自身にも言えます。自分という「ユーザー」が動きやすいように、自分の環境という「システム」を設計する。自分の弱点を克服しようとするのではなく、弱点があっても回るように環境を設計する。私たちは日々、他者のためにシステムを設計しています。そのシステムが、特定の「正常」を前提にしていないでしょうか。最高のコンディションの人間しか使えないように設計されていないでしょうか。最悪の状態の人間でも最低限動けるように設計されているでしょうか。自分自身の働き方も、同じように設計すべきです。「正常」な自分を前提にしない。「最悪」の自分でも回るように設計する。弱さこそが、堅牢なシステムを作る「人」を「環境」に合わせるのではなく、「環境」を「人」に合わせる。自分の弱点を克服しようとするのではなく、弱点があっても回るように環境を設計する。そう書くと、まるで弱さを隠すための工夫のように聞こえるかもしれません。弱い自分を誤魔化して、なんとかやり過ごすためのハックのように。しかし、私が言いたいのは、そういうことではありません。むしろ逆です。弱さは、隠すものではありません。弱さこそが、堅牢なシステムを作るための仕様書になります。私たちは誰でも、何かしら「苦手なこと」を抱えています。朝が弱い。人前で話すのが苦手。細かい作業が続かない。逆に、一度集中すると周りが見えなくなる。そういった、ごく普通の凸凹です。「このエラーメッセージは不親切だ」と感じるのは、かつて自分が同じような場面で困った経験があるからです。「このドキュメントはわかりにくい」と感じるのは、かつて自分がわからなくて苦しんだ経験があるからです。「このUIは使いにくい」と感じるのは、かつて自分が同じように躓いた経験があるからです。欠損は、視点を生みます。 困った経験は、問題を発見する能力になります。痛みを知っているからこそ、他者の痛みに気づけます。うまくいった人には、うまくいかない人の気持ちがわかりません。私自身、そうでした。「正常」に適応できていた頃の私には、「正常」の問題点が見えませんでした。システムにうまく乗れていた頃の私には、そのシステムから弾かれる人の存在が見えませんでした。自分が躓いて初めて、躓く人のための設計ができるようになりました。だから、過去の「苦手」を恥じる必要はありません。それは、視点の源泉です。「最悪の自分」を知っているからこそ、「最悪の状態でも動けるシステム」を設計できるのです。 自分のバグを知り尽くしているからこそ、バグに強いシステムを作れます。評価されるとは、下限が固定されることここまで、「下限を上げることが大事だ」と書いてきました。自分の苦手を知り、それを視点として活かし、最悪の状態でも動ける仕組みを作る。それが実力になると。ここまで読むと、「じゃあ下限を上げ続ければいいんだな」と思うかもしれません。しかし、話はそう単純ではありません。ここで1つ、厄介な問題について触れておかなければなりません。キャリアを積み、シニアになり、周囲から「できる人」として扱われるようになると、ある種の息苦しさが生まれます。「あの人ならこのレベル」という期待。それは信頼の証であると同時に、私たちを縛る鎖でもあります。評価されるということは、自分の「下限」が社会的に可視化され、固定されることを意味します。そして、ここに厄介な問題があります。下限が固定されると、それを下げることが許されなくなるのです。本来、下限を上げていくためには、一時的に下限を下げる必要があります。これは矛盾しているように聞こえるでしょうが、考えてみれば当然のことです。新しい領域に挑戦すれば、最初は当然うまくいきません。慣れない技術を使えば、普段の半分のクオリティしか出せません。未経験の役割を引き受ければ、しばらくは無能に見えます。たとえば、10年間Javaを書いてきたエンジニアがRustを学び始めたとします。最初の数ヶ月、その人の「下限」は確実に下がります。Javaなら寝ぼけていても書けたコードが、Rustでは何時間もかかります。しかし、その一時的な後退を経て、やがてRustでも安定した成果を出せるようになります。同様に、初めてチームリーダーを務める人は、最初は判断を誤り、メンバーとの関係構築に苦労するでしょう。しかし、その経験を経て、リーダーとしての「下限」が形成されていきます。これは成長のための必要なコストです。一時的に下がった下限は、経験を積むことで元の水準を超えていきます。しかし、「あの人ならこのレベル」という期待が固定されてしまうと、その期待を下回ることが許されなくなります。失敗が許されません。実験が許されません。成長のための一時的な後退が、信頼の毀損として記録されてしまいます。だから私は、仕事を選ぶようになりました。自分の下限が確実に通用する領域、自分のシステムが機能する文脈を選ばざるを得なくなりました。「結果を出す以外の選択肢がない」状況で、わざわざ未知の領域に踏み込むリスクを取れなくなりました。これは成長の鈍化を意味します。安全圏に留まり続けることで、下限は維持されますが、それ以上には上がりません。皮肉なことに、「信頼される」ことが「成長できなくなる」ことと表裏一体になっています。 評価されることの代償は、挑戦する自由を失うことです。期待に応え続けることと、成長し続けることは、両立しません。だからこそ、意識的に「失敗してもいい場所」を確保しておく必要があります。誰にも見せないプロジェクト。評価と切り離された実験。下限を一時的に下げることが許される、安全な砂場。それがなければ、私たちは自分の「実力」に閉じ込められてしまいます。余白がなければ成長できない評価されることで挑戦する自由を失う。「失敗してもいい場所」を意識的に確保しなければならない。ここまで書いてきて、気づいたことがあります。これは私個人の問題ではありません。もっと広い話です。「下限」の問題は、個人だけで解決できるものではありません。先ほど書いたように、下限を上げるためには、一時的に下限を下げる必要があります。新しいことに挑戦すれば、最初は失敗します。失敗が許されない環境では、挑戦ができません。挑戦ができなければ、成長もできません。つまり、成長には「余白」が必要なのです。「余白」とは何でしょうか。失敗しても致命傷にならない空間のことです。期待値を下回っても、信頼が毀損されない関係性のことです。最悪の状態を見せても、それを受け入れてもらえる場所のことです。エンジニアは強くなければならない。弱音を吐いてはいけない。立ち止まってはいけない。誰よりも速く学び、誰よりも多くのコードを書き、誰よりも深く技術を理解する。その強迫観念は、私たちを奮い立たせるガソリンであると同時に、余白を奪う呪いでもあります。常に100%を出し続けなければならない。そう思い込んでいる人は多いです。しかし、100%を出し続けることは、人間には不可能です。そして、100%を要求される環境では、人は80%の自分を見せることを恐れます。80%の自分を見せることを恐れるから、新しいことに挑戦できません。新しいことに挑戦できないから、100%のまま停滞します。完璧主義は、成長の敵です。「挑戦しろ」と背中を押す一方で、いざ失敗すれば「自己責任」の名の下に切り捨てる。そんな構造の中では、誰も本当の意味での挑戦ができません。みんな、自分の下限が確実に通用する範囲でしか動かなくなります。結果として、組織全体の成長が止まります。だから、「余白」は個人で確保するだけでなく、チームや組織として設計する必要があります。「最悪の日でも最低限の成果を出せる環境」を作るのは、個人の努力だけでは限界があります。チームとして、組織として、メンバーの「下限」を支える仕組みを作る。失敗を許容する文化を作る。一時的な後退を、成長のための投資として認める空気を作る。それが本当の意味での「強いチーム」です。 全員が常に100%を出し続けるチームではありません。誰かが50%しか出せない日があっても、チーム全体としては回るように設計されたチームです。個人の「下限」を上げる努力と、組織として「余白」を確保する努力。この両方が揃って初めて、持続的な成長が可能になります。床を1ミリずつ上げていくここまで、長々と書いてきました。「最高の自分」ではなく「最悪の自分」が実力である。信頼は下限に支払われる。能力は文脈に依存する。頑張りは実力ではない。環境を設計する。弱さを視点にする。評価は下限を固定する。成長には余白が必要。いろいろ書きましたが、言いたかったことはシンプルです。「能力」の定義を変えてほしい、ということです。「最高のときに出せるもの」から「最悪のときにも出せるもの」へ。自分の状態がベストであることを前提にしない。10分の1のコンディションでも形になるように設計する。緊張しても、失敗しても、体調が悪くてもいい。そのボロボロの状態から這いつくばって出したアウトプットだけを見る。それが、今の私の揺るぎない実力です。絶望する必要はありません。自分の「下限」、つまり床がどこにあるかを知っていれば、その床の上にレンガを積んでいくことができます。半年前の自分は、最悪の日に何ができていなかったでしょうか。タスク管理は頭の中だったでしょうか。テストは書いていなかったでしょうか。ドキュメントは後回しにしていたでしょうか。今はそのうち、どれだけ自動化・習慣化されているでしょうか。継続とは、平均値を上げることではありません。この床を1ミリずつ底上げしていく作業のことです。派手な成功は、運です。華々しい成果は、上振れです。 そんなものを基準にしてはいけません。運は二度来るとは限りませんが、仕組みは何度でも動きます。淡々と、最悪の日でも最低限のことをやる。その積み重ねだけが、誰にも奪われない実力になります。いつかその床の高さが、誰かの天井を超えたとき、私は誰からも信頼されるプロフェッショナルになっているはずです。おわりに最後に、この記事自体の話をさせてください。この記事を書きながら、私自身も自分の「下限」と向き合っています。正直に言えば、この文章を書いている今日も、絶好調とは言えません。頭がぼんやりして、言葉がすぐに出てきません。何度も書いては消し、消しては書いています。「おい、」シリーズのように言葉がスラスラ出てくる日ではありません。しかし、それでいいのです。この記事の価値は、私が絶好調のときに華麗な文章を書けることではありません。調子が悪い日でも、キーボードへ向かい、一文字ずつ積み上げ、最後まで形にできるかどうか。それこそが、私の「書く実力」です。冒頭で書いたように、私はかつて「最高の自分」を実力だと勘違いし、そこに届かない自分を責め続けていました。なんでもっとできないんだ、と。鬱屈とした日々を過ごし、心身ともに疲弊し、パフォーマンスはさらに落ちました。この記事は、あの頃の自分に向けて書きました。伝えたいのは、「基準が間違っている」ということです。私たちは、自分の「最高の瞬間」に執着しすぎています。あの日の自分、あのプロジェクトでの自分、あの輝いていた自分。しかし、その輝きは再現できません。再現できないものを基準にすれば、永遠に自分を肯定できません。だから、視点を変えました。最悪の日に、机に向かえるか。最悪の状態で、最低限のものを出せるか。その「下限」こそが、私の本当の実力です。そしてその下限は、仕組みと環境と、少しずつの積み重ねで、確実に上げていくことができます。派手な成功を追いかける必要はありません。ただ、最悪の日でも崩れない床を、1ミリずつ上げていけばいいのです。その床の高さが、いつか私を支えます。誰にも奪えない、揺るぎない実力として。そして、もう1つ。自分の弱さを恥じる必要はありません。その弱さがあったからこそ、私は「自分を助けるための仕組み」を発明できました。その仕組みは、いずれ同じ弱さを持つ誰かを救うことになります。私の「最悪の日」の対処法は、誰かにとっての「最高のノウハウ」になります。自分の下限を知ることは、諦めではありません。出発点です。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIに手順書を書かせよう! 手順書作成で向き合うAIの不確実性]]></title>
            <link>https://zenn.dev/kamos/articles/procedure_book_with_ai</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/procedure_book_with_ai</guid>
            <pubDate>Mon, 08 Dec 2025 15:23:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIに手順書を書かせてみよう! 手順書にはいくつか必要なポイントがあるね!明確な作業目的作業内容の確実性手順の網羅性影響範囲AIはここに書かれていること、結構苦手だよね。特に作業内容の確実性を担保することは苦手なんだよね!だから、AIに手順書を書かせるときは、AIが苦手なポイントを補うように工夫する必要があるよ!今回は、AIに｢災害時検証: CloudSQLリージョン移行｣の手順書を書かせてみて、一緒に工夫してみよう! 手順作成 まずはそのまままずは、AIにそのまま手順書を書かせてみよう! 以下のプロンプトを使用してみたよ!Cloud SQLの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[メモリ安全なC言語実装「Fil-C」について紹介]]></title>
            <link>https://dev.mix64.com/2025/12/08/post-397/</link>
            <guid isPermaLink="false">https://dev.mix64.com/2025/12/08/post-397/</guid>
            <pubDate>Mon, 08 Dec 2025 13:03:10 GMT</pubDate>
            <content:encoded><![CDATA[今回はメモリ安全なC言語実装を提供できる「Fil-C」について紹介します。既存のC言語プログラムに対しても互換性を持ち、再コンパイルすること...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初心で挑むredis入門 ~Redis hashes編~]]></title>
            <link>https://zenn.dev/akasan/articles/redis_data_hash</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/redis_data_hash</guid>
            <pubDate>Mon, 08 Dec 2025 12:19:17 GMT</pubDate>
            <content:encoded><![CDATA[今回はredisで使えるhashesについてみていきます。昨日公開したStringsについてもぜひご覧ください。https://zenn.dev/akasan/articles/redis_datatypes 早速検証！！redisの環境構築については先日公開した以下の記事を参考にしてください。https://zenn.dev/akasan/articles/redis_quickstartRedis hashesのドキュメントは以下になります。https://redis.io/docs/latest/develop/data-types/hashes/ hashesに...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【初参加】CODE BLUE 2025レポート：体感したトレンドとAIの脅威]]></title>
            <link>https://qiita.com/yutaf11/items/239101da0bf5265b61df</link>
            <guid isPermaLink="false">https://qiita.com/yutaf11/items/239101da0bf5265b61df</guid>
            <pubDate>Mon, 08 Dec 2025 08:35:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめに先月、CODE BLUE 2025に参加してきました。私は普段、SRE兼セキュリティエンジニアとして働いています。過去、SREとして技術系のイベントにはいくつか参加してきましたが、セキュリティ特化のオフラインイベントは今回のCODE BLUEが初めてでした。こ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[技術広報はちゃんとなめてやれ（技術広報をなめるなを読んで）　]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/08/152614</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/08/152614</guid>
            <pubDate>Mon, 08 Dec 2025 06:26:14 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、whywaita Advent Calendar 2025 8日目のエントリ記事です。whywaita Advent Calendar 10周年ということで、自分もwhywaitaとの出会いと10年という節目を掛けて何か書きたいと考えたのですが、うまいネタが思いつかず。とはいえ、whywaitaと出会ったきっかけがお祭り的な技術イベントだったので、今回は技術イベントの「お祭り性」について語っていきます。思い返すと、技術コミュニティとの出会いは、いつもお祭りのようでした。見知らぬ人と技術の話で盛り上がり、気づいたらとんでもない深い時間になっていた懇親会。準備段階から当日まで、ワクワクしながら作り上げた勉強会。あの空気感こそが、私をエンジニアとして成長させてくれた原動力でもありました。そんな私が最近読んで、考えさせられた記事があります。はじめにSakutaroさんが書かれた「技術広報をなめるな」を読みました。note.comSakutaroさんの主張をこの記事で使うために要約すると、技術広報とは「技術に関する情報流通を最適化すること」であり、採用やブランディングにじわじわ効いてくる組織の筋肉である、ということです。片手間でやるものではなく、専門性を持って取り組むべき重要な機能だと。その主張には100%同意します。技術広報を軽視する組織への警鐘として、価値のある記事でした。詳しくは読んで下さい。ただ、読み終わったあと、ひとつ気になることがありました。「なめるな」と言われて、真面目に取り組んだ人は、どうなるだろう。技術広報の重要性を理解した。だから本気で取り組んだ。毎週ブログを書き、登壇の機会を作り、勉強会を企画した。でも、半年後、1年後、その人はまだ続けているだろうか。私が見てきた現実では、真面目に取り組んだ人ほど、燃え尽きていく。「技術広報は大事だ」と理解しているからこそ、手を抜けない。手を抜けないから、疲弊する。疲弊するから、続かない。続かないから、また新しい誰かが「大事だから」と引き継いで、同じサイクルを繰り返す。ここで断っておくと、私は専任のDevRelや技術広報をやっていたわけではありません。エンジニアとしてブログを書いたり、登壇したり、勉強会を企画したり、そういう活動に参加してきた側です。だから以下は、「現場で技術広報に関わってきたエンジニア」としての個人的な意見です。Sakutaroさんへの反論や批判ではなく、同じテーマを別の角度から眺めてみた、という試みです。Sakutaroさんが「技術広報の重要性」を語ったのなら、私は「技術広報の持続可能性」を語りたい。Sakutaroさんが「なめるな」と言ったのなら、私は「ちゃんとなめてやれ」と言いたい。「なめる」というのは、軽視することではありません。肩の力を抜いて、それでも真剣に向き合うこと。重く構えすぎず、軽やかに、本気で楽しむこと。そういう姿勢を指しています。この記事で言いたいのは、技術広報を「お祭り」として捉え直すことで、どう持続可能な形に設計できるか、という話です。「技術広報を続けられない」のは、個人の努力不足なのか技術広報が続かない。ブログの更新が止まる。勉強会の開催頻度が落ちる。登壇者が見つからない。こうした現象を見たとき、私たちはつい「担当者の努力が足りない」「モチベーションの問題だ」と考えがちです。でも、本当にそうでしょうか。私が見てきた限り、技術広報に関わる人は真面目な人が多い。「会社のためになる」「エンジニアの成長につながる」と信じているからこそ、時間を割いて取り組んでいる。努力が足りないのではなく、むしろ、努力しすぎて燃え尽きている。つまり、個人の努力ではなく、構造に原因があるのではないか。技術広報を「重要な業務」として位置づけるほど、プレッシャーは増す。「会社の顔としてふさわしい記事を」「PVやシェア数で成果を示さないと」「毎月コンスタントに発信を」。こうした期待は、真面目な人ほど重く受け止める。結果として、技術広報は「楽しいからやる」ものではなく「やらなければならない」ものになる。義務感で動く活動は、長くは続きません。だから私は、技術広報を「お祭り」として捉え直すことを提案したい。技術広報を「お祭り」として捉えたとき、何が変わるのか「お祭り」と「業務」の違いは何か。業務には、目標がある。KPIがある。期限がある。評価がある。達成できなければ、失敗になる。お祭りには、もちろん準備や段取りがある。でも、本質は違う。非日常性があって、ワクワクして、参加は自由で、失敗しても笑って済む。みんなで作り上げる。終わったあとに「楽しかったね」と言い合える。思い出してみてください。あなたが「楽しかった」と感じた技術イベントには、何がありましたか。KPIはなかったはずです。評価もなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていた。それだけで、あの場は価値があった。技術広報を「業務」として捉えると、タスクになり、KPIになり、疲弊の原因になります。でも「お祭り」として捉えると、楽しみになり、創造性の源泉になり、持続可能な活動になる。もちろん、会社という組織なのでKPIは必要です。数字で語らないと理解されないこともある。大人ですから、建前として必要なものは必要です。でも本音の部分では、お祭りなんです。Sakutaroさんは技術広報を「技術に関する情報流通を最適化すること」と定義しました。私はその定義に異論はありません。ただ「情報流通の最適化」という言葉は正確ですが、人を動かす力は弱い。「今月の情報流通を最適化しよう」と言われても、イメージが湧かない。でも「お祭りを企画して盛り上げよう」と言い換えると、途端にイメージが湧きます。人は「最適化」という目標には動きにくいけど、「お祭り」という体験には参加したがるんです。そして面白いことに、良いお祭りを企画しようとすると、自然と「情報流通の最適化」が達成されます。読みたくなるブログは情報が届く。参加したくなる勉強会は知見が共有される。面白いカンファレンスブースはブランドが伝わる。お祭りが楽しいのは、予定調和じゃないからです。神輿が予想外の方向に進んだり、知らない人と急に仲良くなったり、思いもよらない出来事が起きる。その「意外性」がお祭りの醍醐味です。技術広報も同じで、完璧に計画されたブログより、思いつきで書いた記事がバズることもある。意外性こそが人の心を動かします。でも、意外性は余裕がないと生まれません。タスクに追われている人に、遊び心は出てこない。「やらなきゃいけない」という義務感からは、「やってみたら面白かった」という発見は生まれない。だから、技術広報には「精神的な遊び」が必要です。お祭りを「業務」として100%真面目にやると、それはもはやお祭りではなくなります。参加の形は、ひとつじゃないお祭りには色んな参加の仕方があります。神輿を担ぐ人もいれば、屋台で焼きそばを売る人もいる。踊る人もいれば、見ているだけの人もいる。写真を撮る人も、SNSで実況する人もいる。ゴミを拾う人も、場所取りをする人もいる。どの参加の仕方も、お祭りの一部です。技術広報も同じです。記事を書く人だけが貢献者ではない。レビューする人も貢献者です。アイデアを出す人も貢献者です。社内で記事をシェアする人も貢献者です。「この前のあの話、ブログにしたら面白そう」と声をかける人も貢献者です。登壇者の練習に付き合う人も貢献者です。「ブログを書いてもらえない」「登壇してもらえない」と悩んでいるなら、視点を変えてみてください。「書いてもらう」「登壇してもらう」以外の参加の形を、用意できているだろうか。神輿を担げる人は限られています。でも、お祭りを楽しむ方法は無数にある。担ぎ手だけがお祭りの参加者ではないんです。「ブログを書いてください」ではなく「先週のSlackでのやり取り、そのままブログにしませんか。私がタイトルと導入書きますよ」。「登壇してください」ではなく「5分のLTでいいので、この前の話をしてくれませんか」。義務ではなく、招待として。「ブログ書いてください」はお願い（義務感）。「ブログ書きませんか」は招待（選択肢）。この違いは大きいんです。あなた自身は、どうでしょうか。技術広報にどんな形でなら、無理なく関われそうですか。「怒られない範囲」は誰が決めているのかお祭りにも「やっていいこと」と「やってはいけないこと」がある。技術広報も同じです。失敗談を書け、人間臭さを出せ、と言われても、リスクが怖い。その懸念は正しいです。だからこそ、「怒られない範囲」を見極める力が必要になります。ただ、その「怒られない範囲」は、誰が決めているのでしょうか。明文化されたルールがあるのか、暗黙の了解なのか。上司が決めているのか、広報部門が決めているのか、法務が決めているのか。あるいは、なんとなく「空気」で決まっているのか。多くの組織では、「怒られない範囲」は明確に定義されていません。だから、発信する側は常に不安を抱えることになる。「これ、出していいのかな」「怒られないかな」。その不安が、発信のハードルを上げている。社内的にはOKだけど、社外的にNGになるケースがあります。「技術的には正しいけど、今その話題は炎上しやすい」という場合です。社外的にはOKだけど、社内的にNGになるケースもあります。「業界では普通の話題だけど、うちの会社ではタブー」という場合です。「怒られない範囲」を見極める能力とは、社内外の文脈を読む力です。これは経験を積むことでしか身につきません。小さく発信して、反応を見て、学んでいく。でも、もし組織として技術広報を続けたいなら、「怒られない範囲」を個人の判断に委ねるのではなく、組織として明確にする努力が必要ではないでしょうか。「ここまではOK」「これはNG」「迷ったらこの人に相談」。そういった指針があるだけで、発信のハードルはぐっと下がります。あなたの組織では、「怒られない範囲」はどのように決まっていますか。誰が決めていますか。それは明文化されていますか。持続可能にするために最後に、どうすれば技術広報を続けられるのか、という話をします。技術広報に関わる人が陥りがちな罠は、自分一人で全部やろうとすることです。ブログの企画、執筆依頼、レビュー、公開作業、SNSでの拡散。全部一人でやると、短期的には回ります。でも、長期的には崩壊します。お祭りは、主催者一人では成立しません。屋台を出す人、演奏する人、ゴミを拾う人、写真を撮る人、SNSで拡散する人。みんなが違う形で参加して、初めてお祭りは盛り上がります。「一人が100やる」のではなく、「10やる人、5やる人、1でも協力してくれる人を探す」これが持続の秘訣です。例えば、こんな工夫ができます。月に1回「ブログネタ出し会」を30分だけ開く。Slackに「こんな話をブログにしたい」と投げるだけのチャンネルを作る。「書けそうな人」ではなく「話が面白かった人」に声をかける。小さな仕組みを作っておくだけで、協力者は見つかりやすくなります。そして、もう1つ大事なこと。人間には波があるということです。10やれる時期もあれば、5しかやれない時期もある。1すらもやれない時期もある。プロジェクトが佳境に入っている時期。体調を崩している時期。家庭の事情がある時期。メンタルが落ちている時期。これは恥ずかしいことでも、甘えでもありません。人間だもの。「去年できたから、今年もできる」という思い込みこそが、燃え尽きの原因なんです。10やれる時は10やる。5しかやれない時は5でいい。やれない時は、休む。大事なのは、この「波」を組織として受け入れられているかどうかです。「先月は3本記事を出したのに、今月は1本もない。どうしたの」というプレッシャーがかかるなら、それは持続可能な仕組みとは言えません。「今月は厳しいので、来月がんばります」と言える文化があるかどうか。あなたのチームでは、パフォーマンスの波を受け入れられていますか。「今は無理」と言える空気がありますか。おわりに冒頭で書いた通り、私とwhywaitaの出会いは、お祭り的な技術イベントでした。あの場には「情報流通の最適化」なんて言葉はなかった。ただ、技術の好きな人たちが集まって、ワイワイやっていただけです。でも、今ならわかります。私がワイワイと参加していたあのイベントの裏側には、真面目に予算を集めてきた人がいた。色んなステークホルダーの合意をまとめてきた人がいた。会場を押さえ、スケジュールを調整し、トラブルに備えていた「ちゃんとした大人」がいた。私はその恩恵を受けて、楽しんでいただけだったんです。10年経って、そのことがようやくわかるようになりました。いずれ自分も、あの「ちゃんとした大人」の側に回らなければならない。恩返しをしなければならない。その自覚はあります。でも、それでも。いや、だからこそ。次の世代の人たちには、お祭り感を味わってほしい。「裏側の苦労」を見せずに、「楽しかったね」と言ってもらえるイベントを作りたい。真面目に準備しながら、参加者には「お祭り」として届ける。それが、私なりの恩返しの形だと思っています。技術広報に関わるすべての人へ。疲れたら、休んでください。無理したら、倒れます。真面目すぎたら、続きません。でも、楽しさだけでも続きません。楽しさと、仕組みと、仲間が必要です。もしあなたが今「何もやれない時期」にいるなら、それでいいんです。休んでください。お祭りは、また元気になってから参加すればいい。技術広報は、あなたがいないと回らないほど脆弱なものであってはいけない。でも、あなたがいると、もっと楽しくなる。それくらいの距離感がちょうどいい。10年前のあの日、技術イベントで会った人と、今もこうしてAdvent Calendarで繋がっている。これこそが、お祭り駆動の技術広報の成果です。どこかのカンファレンスの懇親会で会ったら、お祭りの話をしましょう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年AWS Community Builderの活動報告]]></title>
            <link>https://blog.masasuzu.net/entry/2025/12/08/100000</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/12/08/100000</guid>
            <pubDate>Mon, 08 Dec 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[今年はブログ4本(純粋なAWSの記事はなし)、登壇5本(内社内2本)という結果でした。勉強会参加自体はそこそこしてたんですが、アウトプットという点では少し物足りない結果になったなという感想です。要因としてはGoogle Cloud関連の活動が比較的多くて、AWS関連にリソースを割けなかったというのもあります。第二の理由としては今年後半が特に業務が多忙で身動きが取れない月があったのも事実です。とはいえ忙しいは言い訳に過ぎないので、なんとアウトプットする仕組み作りをしていきたいとことです。来年はもっとアウトプットを増やしていきたいです。そこで以下の数値を目標にやっていきたいと考えています。社外登壇: 月0.5本AWSテーマのブログ: 月1本以上やってくぞ。以下今年のアウトプットを置いておきます。ブログAWS関連なしクラウドニュートラルblog.masasuzu.netdiary.masasuzu.netdiary.masasuzu.netblog.masasuzu.net登壇AWS関連 speakerdeck.com speakerdeck.com speakerdeck.comクラウドニュートラル speakerdeck.com speakerdeck.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代のスキーマファースト開発 FastAPI × GitHub Packages で型安全なSDKを自動配布する]]></title>
            <link>https://zenn.dev/meziron/articles/32ac2241bbec38</link>
            <guid isPermaLink="false">https://zenn.dev/meziron/articles/32ac2241bbec38</guid>
            <pubDate>Sun, 07 Dec 2025 15:00:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事は 3-shake Advent Calendar 2025 の記事です。フロントエンド開発者とバックエンド開発者の間で「APIの仕様が違う」「ドキュメントが古い」といった問題に悩まされたことはありませんか？さらにAI時代になり、Claude CodeやCursorなどのAIコーディングツールを使う機会が増えてきました。しかし、AIにAPI呼び出しを実装させると、存在しないエンドポイントを「想像」で実装してしまったり、パラメータの型を間違えたりすることがあります。本記事では、FastAPIのOpenAPI自動生成機能を活用し、GitHub ActionsでTy...]]></content:encoded>
        </item>
    </channel>
</rss>