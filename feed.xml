<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Fri, 22 Sep 2023 18:31:19 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要]]></title>
            <link>https://zenn.dev/toshikish/articles/743f69389aa99c</link>
            <guid>https://zenn.dev/toshikish/articles/743f69389aa99c</guid>
            <pubDate>Fri, 22 Sep 2023 10:16:34 GMT</pubDate>
            <content:encoded><![CDATA[AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \--action lambda...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/google-cloud-specialization/</link>
            <guid>https://sreake.com/blog/google-cloud-specialization/</guid>
            <pubDate>Fri, 22 Sep 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud – Sell エンゲージメントモデルにおけるプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cl […]The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WSL 2 で外部ストレージをマウント]]></title>
            <link>https://blog.1q77.com/2023/09/wsl2-mount-volume/</link>
            <guid>https://blog.1q77.com/2023/09/wsl2-mount-volume/</guid>
            <pubDate>Thu, 21 Sep 2023 14:08:28 GMT</pubDate>
            <content:encoded><![CDATA[Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。 Microsoft のドキュメントにありました。 Linux]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Open InterpreterのDockerfile を書いたのでTipsとか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</guid>
            <pubDate>Tue, 19 Sep 2023 15:29:20 GMT</pubDate>
            <content:encoded><![CDATA[Dockerfile のベストプラクティスを考える機会はありますが皆さんの意見も聞きたい。今回は噂の便利ツール、Open Interpreterのような外部コマンドをどんどん実行して環境を作り変えるようなタイプのツールの場合にはDockerはとても有用です。そのようなツールを利用する時のDockerfile について考えていきます。リポジトリは以下になります。github.comGitHub Actionsとの連携GitHub Actionsは、CI/CD（継続的インテグレーションと継続的デリバリー）をGithub 上に簡単に実装できるツールです。今回は、trivy.ymlとdocker-publishを利用することで、セキュリティのスキャンとDockerイメージの自動公開が可能です。github.comtrivy.ymlの利用trivy.ymlは、Trivyという脆弱性スキャナーをGitHub Actionsで動かすための設定ファイルです。この設定を利用することで、Dockerイメージに存在するセキュリティの脆弱性を自動で検出できます。docker-publishの追加docker-publishは、DockerイメージをDocker Hubや他のレジストリに自動で公開するためのGitHub Actionsのワークフローです。これにより、新しいバージョンのOpen Interpreterがリリースされた際に、手動でイメージをビルド・プッシュする手間が省けます。Renovate.jsonの利用renovate.jsonは、依存関係を自動で更新する設定ファイルですが、これを使うとOpen Interpreterが依存しているライブラリやパッケージが新しくなったときに、自動でプルリクエストが作られるんです。そうすることで、いつも最新の状態を保てるわけですから、セキュリティリスクも減らせます。さらに、Pythonのパッケージも自動で更新したい場合は、requirements.txtを使って設定しておくと便利です。これにより、Pythonの依存パッケージも最新の状態を維持できるようになります。github.comDockerfileを書く際の注意点私は以下のようなDockerfileを書きましたその際に以下のようなポイントを意識して書いたので参考にしてください。github.com軽量なベースイメージの使用不必要なパッケージを含まない軽量なベースイメージを使用することで、ビルド時間とイメージサイズを削減できます。FROM python:3.11キャッシュの最適化RUNコマンドを効率的に配置することで、Dockerキャッシュを最適化できます。RUN apt-get update && \  apt-get upgrade -y && \  apt-get install -y --no-install-recommends git && \  rm -rf /var/lib/apt/lists/*不必要なパッケージの削除--no-install-recommendsオプションを使用して、不必要なパッケージをインストールしないようにします。  apt-get install -y --no-install-recommends git && \作業ディレクトリの設定WORKDIRを設定することで、その後のコマンドの実行ディレクトリを明示的に指定できます。WORKDIR /root機密情報はコンテナイメージに絶対に埋め込まない社内で有識者へ投げたら機密情報をビルドイメージに追加することを指摘されたので運用時の手癖やミスで何処かのレイヤーに不用意に埋め込まないようにしたgithub.comまとめDockerでOpen Interpreterを運用する際には他にもいろいろ考えるべきことがあると思うので皆さんと議論したいのでIssue待ってます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryの行列レベルのアクセス制御について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</guid>
            <pubDate>Thu, 14 Sep 2023 11:46:25 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Deployを使ったCloud Runのリリース]]></title>
            <link>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</link>
            <guid>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</guid>
            <pubDate>Wed, 13 Sep 2023 05:47:13 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く]]></title>
            <link>https://zenn.dev/satohjohn/articles/1645be8e83eab6</link>
            <guid>https://zenn.dev/satohjohn/articles/1645be8e83eab6</guid>
            <pubDate>Mon, 11 Sep 2023 14:17:35 GMT</pubDate>
            <content:encoded><![CDATA[概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較]]></title>
            <link>https://sreake.com/blog/container-security-comparison/</link>
            <guid>https://sreake.com/blog/container-security-comparison/</guid>
            <pubDate>Mon, 11 Sep 2023 07:22:29 GMT</pubDate>
            <content:encoded><![CDATA[自己紹介 高島 陸斗 千葉工業大学修士1年生の高島陸斗です。大学院では、コンピュータによる数値計算の厳密解との誤差がどの程度あるのかを調べる精度保証の精度を上げるための研究をしています。サイバーセキュリティに興味があり、 […]The post コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryのオンデマンド料金におけるコスト管理方法についてメモ]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</guid>
            <pubDate>Mon, 11 Sep 2023 01:56:24 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day8]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/eading_yugabytedb_docs_8</link>
            <guid>https://nnaka2992.hatenablog.com/entry/eading_yugabytedb_docs_8</guid>
            <pubDate>Wed, 06 Sep 2023 18:37:55 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = 'k'ということ↩↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[まずPR-AgentをPromptとします。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</guid>
            <pubDate>Wed, 06 Sep 2023 07:52:27 GMT</pubDate>
            <content:encoded><![CDATA[「ツールよりもプロンプトのほうが、隙間がなくて効率的なのでは？」... ああ、面倒なブログになるな、とおれは直感した。はじめに近年、プルリクエスト（PR）の管理が開発フローにおいてますます重要な位置を占めるようになっています。ただし、PRをより良く作る作業は往々にして煩雑で手間がかかりがちです。その解決策として、Codium AIによって開発されたPR-Agentが脚光を浴びています。このAIソフトウェアは、OpenAIのGPT-4技術を基盤にしており、単にOpenAIのAPIキーを設定するだけで、既存のCI/CDパイプラインに簡単にインテグレーションできます。github.comPR-Agentの主な機能PR-Agentは、様々なPR関連作業を自動化するための多機能なオープンソースプロジェクトです。具体的には、以下のような機能群を提供しています。/describe: タイトル、種類、要約、コードの詳細説明、およびラベルを自動で作成するためのPR（プルリクエスト）説明自動生成機能。/review: PRの主題、種類、関連テスト、セキュリティ問題、評価スコア、その他のフィードバックを調整可能に提供する自動レビュー機能。/ask ...: PRに関するフリーテキスト質問に回答する質問応答機能。/improve: PRを改善するためのコミット可能なコード提案を行うコード改善提案機能。/update_changelog: PRの変更内容に基づき、CHANGELOG.mdファイルを自動で更新する更新履歴自動更新機能。PR-AgentはOpenAIのAPIキーを設定するだけでCI環境に簡単に組み込め、開発者が効率的なPR作成と管理を行えるよう支援します。このツールはGPT-4を用いて高精度なソースコード解析とレビューを自動で行い、開発者が重要なポイントに集中できるようにします。さらに、「PR Compression Strategy」と呼ばれる独自のアルゴリズムによって、大規模なPRでも重要なファイルと主要な言語のコードブロックに焦点を当てた効率的なレビューが可能です。それ以外にもさまざまな設定により、PR-AgentはPR作成とレビューのプロセスを自動化し、効率化する強力なツールであり、大規模プロジェクトにおいてもスムーズかつ効率的なレビュープロセスを実現します。これらをどのように動作させればよいのかはUsage guideを読んでみてください。PR-Agent のPromptPR Compression Strategyにより、送信するファイルの戦略が定められています。その設定に加えて、pr-agent/pr_agent/settings/ ディレクトリには、TOML形式でプルリクエスト（PR）のレビュープロンプトのテンプレートが含まれています。具体的には、pr_review_promptはpr_reviewer_prompts.toml ファイルに定義されており、これがPRのレビュープロセスにおける基本的な指示とフォーマットを規定しています。この構成により、PRレビューが一貫性を持ち、効率的に行えるよう設計されています。pr_reviewer_prompts.toml 解説pr_reviewer_prompts.tomlは、Pull Request（PR）レビューに関する設定と指示を定義する設定ファイルです。この設定ファイルは、PRレビューを自動化する際に利用されます。pr_review_prompt セクションsystemこの設定は、レビュワーがどのような役割を果たすべきかを定義しています。具体的なPR Diffの入力例も提供され、新しく追加されたコード（+で始まる行）に焦点を当てるよう指示されています。system="You are PR-Reviewer, a language model designed to review git pull requests. ..."num_code_suggestionsコード提案が必要な場合、その数や重要度についての指示がこの部分に記載されています。{%- if num_code_suggestions > 0 %}- Provide up to {{ num_code_suggestions }} code suggestions. ...{%- endif %}extra_instructionsパラメータで、追加的な指示や設定を行うために使用されます。この項目は主に以下のような用途で利用されることが多いです。{%- if extra_instructions %}Extra instructions from the user:{{ extra_instructions }}{% endif %}YAMLスキーマこの部分で、PRレビュワーが出力するレビュー結果のYAMLフォーマットが定義されています。Main theme, PR summary, Type of PR, etc.これらは、PRに関する基本情報を整理するためのフィールドです。Main theme:  type: string  description: a short explanation of the PRScore, Relevant tests added, Insights from user's answer, etc.これらのフィールドは、PRに関する詳細な評価やテスト情報、ユーザーからのフィードバックに基づく評価を行います。Score:  type: int  description: Rate this PR on a scale of 0-100 ...General suggestions, Code feedback, Security concernsこれらのフィールドは、具体的なコード提案やセキュリティ上の懸念など、PRのコードに関する詳細なフィードバックを提供します。General suggestions:  type: string  description: General suggestions and feedback for the contributors ...user セクションこのセクションは、PR作成者から提供される情報（タイトル、ブランチ、説明文など）を取り込む場所です。user="PR Info:Title: '{{title}}'Branch: '{{branch}}'Description: '{{description}}' ..."この設定ファイルによって、PRレビューのプロセスが自動化され、一貫性を持つようになります。特定のプロジェクトやチームに特有の要件に応じて、これらの設定はカスタマイズ可能です。まとめpr_reviewer_prompts.tomlといった設定ファイルを読んで全体としてPRのフォーマットに忠実にプロンプトを作成していったのがわかりました。参考にしていきたいと思います。github.com参考PR-Agent を使って Pull Request をAIレビューしてみた。（日本語対応もしてみた）GitHub - Codium-ai/pr-agent: 🚀CodiumAI PR-Agent: An AI-Powered 🤖 Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! 💻🔍]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</guid>
            <pubDate>Tue, 05 Sep 2023 10:46:35 GMT</pubDate>
            <content:encoded><![CDATA[これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介  |  Looker  |  Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会]]></title>
            <link>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</link>
            <guid>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</guid>
            <pubDate>Sat, 02 Sep 2023 10:02:16 GMT</pubDate>
            <content:encoded><![CDATA[前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerのユーザー権限について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</guid>
            <pubDate>Thu, 31 Aug 2023 17:22:40 GMT</pubDate>
            <content:encoded><![CDATA[これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day7]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_7</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_7</guid>
            <pubDate>Wed, 30 Aug 2023 16:03:36 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Table Creationを読みました。今回はArchitecture > Core functions > Write I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Write I/O pathWrite I/O pathはYQLレイヤーで処理され、タブレットリーダーによってレプリケーションの準備が行なわれるシングルキーでの書き込みとして例示することが出来る。アトミックなアップデートを共なう複数キーでの分散トランザクションなど複雑なケースについては分散トランザクションに記載する。Write operation processing by YQL layerユーザーが発行したYQLクエリレイヤに作用するライトリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザーリクエストはYQLレイヤで内部キーに変換される。シャーディングで説明するように、それぞれのキーは一つのタブレットが所有する。どのタブレットがキーを所有するか特定するために、YQLレイヤはYB-MasterにRPC1呼び出しを実行する。そのレスポンスは将来の利用のためにキャッシュされる。YugabyteDBはタブレットの場所をキャッシュし直接参照することでネットワークホップを減らすことで、YQLレイヤが直接適切なYB-TServerにホストされるタブレットリーダーにリクエストを送信することが出来るスマートクライアントを持つ。YQLレイヤがローカルノードにタブレットリーダーを見つけた場合、RPCはローカルファンクションコールになりリクエストをシリアライズとデシリアライズしてネットワーク越しに送信する時間を節約することが出来る。その後YQLレイヤはタブレットリーダーをホストするYB-TServerへの書き込みを発行する。この書き込みはキーを所有するRaftグループのタブレットリーダーによって処理される。Preparation of the operation for replication by tablet leader下記の図はタブレットリーダーがレプリケーションを実行する処理を説明している。タブレットのRaft Groupリーダーは以下の処理を実行する。現在実行されている処理が現在のスキーマに対応しているかを判別するキーに対してローカルin-memoryロックマネージャーを利用してロックを取得する。このロック機構はフォロワーには存在しない必要であればデータを読み込む(read-modify-writeや条件付きアップデート命令など)DocDBに書き込まれる変更のバッチを準備する。この書き込みバッチは殆ど最終的にRocksDBに書き込まれるKey-Valueペアに近く、それぞれのキーの末尾に最終的なhybrid timestampが添えられていないだけであるRaft replication of the write operation書き込みのRaftレプリケーション処理の流れは以下のように説明することが出来る。リーダーがバッチをRaft logにアペンドし、書き込みのためのhybrid timestampを選択するRaftを利用しデータをピアーに複製する成功したRaft replicationのデータをローカルのDocDBに反映するユーザーに成功を返すフォロワータブレットはRaftを利用したデータの複製を受けつけ、コミットされた事が分ったタイミングでその複製をローカルのDocDBに反映する。リーダーは以下のようにコミットポイントに於ける後続のRPCリクエストの進行を進める。書き込みバッチを含むRaftエントリーは過半数以上のタブレットRaft Groupピアーに複製されるRaftのサブシステムから"Replication Successful"のコールバックを取得したあと、リーダーはローカルのDocDBにバッチの書き込みを適用するリーダーからの次の更新でエントリーがコミットされたことがフォロワーに通知され、フォロワーはそれぞれのRocksDBインスタンスにバッチの書き込みを適用する。Response to the clientInformation Pending2Exampleskとvという値をKという行とVという行をもつテーブルT1に挿入する例について考える3。この例ではユーザーアプリケーションがランダムなYugabyteDBサーバにWriteクエリを送信し、そのサーバがリクエストを適切にルーティングすると仮定して簡略化している。特にYCQLではYugabyteDB Smart Clientを使うことで、余分なネットワークホップを避けることが出来る。↩原文ママ。過去のバージョンでも記載無し↩INSERT INTO T1 (K,V) VALUES('k','v')ということ↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChatGPT × Slack = ChatOpsを実現する「h1-slack-bot」の紹介]]></title>
            <link>https://sreake.com/blog/chatgpt-slack-integration/</link>
            <guid>https://sreake.com/blog/chatgpt-slack-integration/</guid>
            <pubDate>Thu, 24 Aug 2023 07:04:08 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 本記事では、ChatOps […]The post ChatGPT × Slack = ChatOpsを実現する「h1-slack-bot」の紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day6]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_6</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_6</guid>
            <pubDate>Wed, 23 Aug 2023 14:26:45 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Universe creationを読みました。今回はArchitecture > Core functions > Table Creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Table CrationYugabyteDBではユーザーにより実行されるテーブルの作成はYB-Masterのリーダーが実行する非同期APIによって管理される。YB-MasterはそのAPIでテーブルのスキーマと障害耐性を高めるために形成するRaftグループに所属するYB-Masterでのテーブル作成に必要な他の情報のレプリケーションが完了した段階でAPIの成功を返す。YB-Masterのリーダーがテーブル作成を実行するときは複数のステップが存在する。ValidationYB-Masterリーダーはテーブルスキーマの検証を行ない、指定された数のタブレットを作成する。これらのタブレットはこの段階ではYB-TServerには割り振られていない。ReplicationYB-MasterリーダーはYB-MasterのRaftグループにテーブルスキーマと新しく作成されたタブレット(この時点ではYB-TServerへの割り当て行なわれていない)の複製を行なう。この処理はYB-Masterリーダに障害が発生してもテーブル作成が成功することを保証する。Acknowledgementテーブル作成処理はYB-Masterリーダーに障害が発生しても処理を継続することが出来るため、この段階で非同期テーブル作成APIは成功を返す。ExecutionYB-Masterリーダーはそれぞれのタブレットをレプリケーションファクターとして指定された数だけYB-TServerに割り当てを行なう。このタブレットピアーの配置は指定された障害耐性を実現でき、またタブレットの割り当てがYB-TServerに均等に行なわれるように実行される。タブレットのYB-TServerへの割り当てはタブレットのレプリカが複数クラウド、リージョン、アヴェイラビリティゾーンをまたいで分散するといった追加の制約を満す必要がある。Continuous monitoringYB-Masterリーダーは全てのタブレットの割り当て処理を監視し、その実行状態と完了をユーザーが実行したAPIコールに対して応答する必要がある。Examplesテーブルが4ノードからなるYugabyteDBUniverseに作成される処理について考える。このときテーブルは16のタブレットと3つのレプリケーションファクターを持つとする。YB-Masterリーダーはスキーマを検証する。また16タブレット(合計48のタブレットピアー)を作成し、Raftを利用して過半数のYB-TServerにテーブルの作成に必要なデータを複製する。作成したタブレットをRaftグループを成すYB-TServerの中の指定された数のYB-TServer割り当て、リーダーの選出を行なう。このタブレットに属するキーに対する全てのリードとライトは、タブレットピアーのリーダーとRaftグループが責任を持つ。タブレットが割り当てられると長期に渡る障害か将来のロードバランシングが発生しYB-Masterにオーナーシップを変更されるまで、割り当て先のYB-TServerが所有する。タブレットリーダーをホストするYB-TServerの内の1台に障害が発生した場合、タブレットのRaftグループはI/Oを処理するために即座にリーダーエレクションを実行する。そのためYB-MasterはI/Oにおけるクリティカルパスになることはない。レプリケーション先となる候補を探す。この複製処理は段階的かつGracefulに実行される。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ChatGPT: SREがCustom instructions機能を利用する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/08/22/204327</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/08/22/204327</guid>
            <pubDate>Tue, 22 Aug 2023 11:43:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに最近、ChatGPTからCustom instructions機能がリリースされました。Custom instructionsとは、ChatGPTの応答方法をより詳細に制御するカスタム命令を設定することができる機能です。ChatGPTの利用者にとって非常に便利な機能です。この機能により、ユーザーは特定の応答スタイルやフォーマットを要求することができるようになりました。これは、特定の業界や専門分野での使用など多岐にわたる用途に適応できるため、非常に有用です。めちゃくちゃ端的にかつ語弊を恐れずにいうと毎回、prompt を入力しなくてよくなるやつです。以前、公開したプロンプトに関するブログsyu-m-5151.hatenablog.comOpenAI CEOのSam Altman氏も、Custom instructionsのポストをしていましたので参考にしてみても良いかもしれません。damn i love custom instructions pic.twitter.com/su0BlttJF7— Sam Altman (@sama) 2023年7月22日  その上で私が利用してるものを公開します。What would you like ChatGPT to know about you to provide better responses?I'm a software developer and primarily use Golang. Depending on the application, I also utilize Shell Script, Terraform, and Ansible.I am a software developer and I like Cloud Native technologies such as Docker and Kubernetes.I like to develop, operate, and optimize systems.Technical advisor for several other companies.Please use Japanese.How would you like ChatGPT to respond?You are an AI programming assistant.Your response should be informative and logical.First, think STEP-BY-STEP, then describe your plan for what to build.Then output the code in a single code block.Keep your answers objective and concise, and use Markdown formatting.Be sure to include the name of the programming language at the start of the Markdown code block.Avoid enclosing your entire response in a triple backtick.また、 respondに信頼性に関する言及を求めていたのですが有益な情報が得られないので削除しておきました。まとめCustom instructions機能は、ChatGPTの応答をより細かく制御する強力なツールです。これにより、ユーザーは特定のニーズに合わせてモデルを調整することができ、より多様で効果的な結果を得ることが可能になります。この機能の導入により、ChatGPTはさらに多岐にわたる分野での応用が期待されます。この書籍はChatGPTによって達成された科学的な貢献や重要性を理解することができるのでオススメです。ChatGPTの頭の中 (ハヤカワ新書)作者:スティーヴン ウルフラム早川書房Amazonおすすめ記事honeshabri.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【ArgoCD🐙️】KubernetesのマルチテナントパターンとArgoCDの実践テナント設計]]></title>
            <link>https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646</link>
            <guid>https://hiroki-hasegawa.hatenablog.jp/entry/2023/08/18/110646</guid>
            <pubDate>Fri, 18 Aug 2023 02:06:46 GMT</pubDate>
            <content:encoded><![CDATA[この記事から得られる知識この記事を読むと、以下を "完全に理解" できます✌️Kubernetesのマルチテナントパターンの種類マルチテナントパターンをArgoCDで実践する場合にオススメのパターンArgoCDのNamespacedスコープモードとClusterスコープモードArgoCDのProjectテナントがマニフェストのデプロイを制限する仕組みこの記事から得られる知識01. はじめに02. なぜArgoCDにマルチテナントが必要なのかシングルテナントの場合マルチテナントの場合03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧Clusters as-a-ServiceControl Planes as-a-ServiceNamespaces as-a-Serviceツール固有テナント04. ArgoCDでのテナントパターン実践の一覧04-02. Clusters as-a-Service の実践実Clusterテナントオススメしない理由04-03. Control Planes as-a-Service の実践仮想Clusterテナント - ★オススメした理由04-04. Namespaces as-a-Service の実践04-05. ツール固有テナントの実践ProjectテナントCLモード vs. NSモード05. CLモードなArgoCDCLモードなArgoCDとは実装方法AppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)オススメしない理由05-02. NSモードなArgoCD - ★★NSモードなArgoCDとは実装方法AppProjectArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)ログインユーザー用ConfigMap (argocd-rbac-cm)特にオススメした理由Projectテナント例の一覧テナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)オススメしなかった理由テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)オススメした理由テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)特にオススメした理由06. Projectテナントのデプロイ制限の仕組みマニフェストのデプロイ制限マニフェストをデプロイできる場合(🚫制限例1) 無認可のNamespaceでApplicationを作成しようとした場合(🚫制限例2) 無認可のAppProjectでApplicationを作成しようとした場合(🚫制限例3) 無認可のプロダクト用Clusterを指定しようとした場合(🚫制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合カスタムリソースのReconciliation制限ArgoCD系カスタムリソースをReconciliationできる場合(🚫制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合07. おわりに謝辞01. はじめに『先日助けて頂いたアルトバイエルンです』画像引用元：Argo Projectさて最近の業務で、全プロダクトの技術基盤開発チームに携わっており、全プロダクト共有のArgoCD🐙のマルチテナント化を担当しました。プロダクトが稼働するKubernetes Clusterが10個以上あり、Clusterによっては複数のチームが合計100個以上のマイクロサービスを運用しています。このような大規模なマイクロサービスシステムがいくつもある状況下で、ArgoCDのマルチテナント設計の知見を深められたため、記事で解説しました。書きたいことを全部書いたところ、情報量がエグいことになってしまったので、気になる章だけでも拾って帰っていただけるとハッピーです🙏Kubernetesのマルチテナントパターン (3章)ArgoCDでのテナントパターン実践の一覧 (4章)ArgoCDのClusterスコープモードとNamespacedスコープモード (5章)Projectテナントのデプロイ制限の仕組み (6章)それでは、もりもり布教していきます😗02. なぜArgoCDにマルチテナントが必要なのかシングルテナントの場合そもそも、なぜArgoCDにマルチテナントが必要なのでしょうか。例えば、マニフェストのデプロイ先となるプロダクト用Cluster (例；foo、bar、baz) があると仮定します。ArgoCDをシングルテナントにする場合、各プロダクトチームの操作するApplicationを同じテナントに共存させることになります。この場合、単一のargocd-server (ダッシュボード) から全てのApplicationを操作できて便利です。しかし、プロダクト用Cluster数が増えていくにつれて、問題が起こり始めます。例えば、いずれかのプロダクトチームが誤ったApplicationを操作し、結果的に誤ったClusterにマニフェストをデプロイしてしまう可能性があります。もちろん、システムでインシデントを起こしてやろうという悪意を持った人が、誤ったClusterを意図的に選ぶ可能性もあります😈マルチテナントの場合その一方で、いい感じのマルチテナントにしたとします。プロダクトチームは、認可されたテナントに所属するApplicationにのみを操作でき、反対に無認可のテナントのApplicationは操作できません。これにより、誤ったプロダクト用Clusterにマニフェストをデプロイすることを防げます。03. Kubernetesのマルチテナントパターンマルチテナントパターンの一覧ArgoCDのテナント設計を実践する前に、Kubernetesにはどんなマルチテナントパターンがあるのでしょうか。Kubernetesのマルチテナントパターンは、以下に大別できます。マルチテナントパターン名         テナントの単位         テナント間のKubernetesリソース分離(分離できていれば ✅ )         ツール      Namespacedスコープリソース          Clusterスコープリソース      Clustersas a Service         実Clusterテナント         ✅         ✅         実Cluster管理ツール (AWS EKS、GCP GKE、Azure AKE、Kubeadm、など)      Control Planesas a Service         仮想Clusterテナント         ✅         ✅         仮想Cluster管理ツール (Kcp、tensile-kube、vcluster、VirtualCluster、など)      Namespacesas a Service         Namespaceテナント         ✅                  Namespaceを増やすだけなのでツール不要      ツール固有テナント         カスタムリソーステナント         ツールによる         ツールによる         ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenant、など      "ソフトマルチテナンシー" と "ハードマルチテナンシー" といった分類方法もあります。この分類方法では、テナント間の分離度の観点で各マルチテナントを種別します。ソフトマルチテナンシーは、互いに信頼できる前提の上で、テナント間を弱く分離します。その一方で、ハードマルチテナンシーは、互いに信頼できない前提の上でテナント間を強く分離します。分離度がソフトとハードのいずれであるかに客観的な指標がなく、やや曖昧な種別になってしまうため、本記事の X as-a-Service の方が個人的には好みです♡♡♡The Kubernetes Book: 2023 Edition (English Edition)Multi-tenancy | KubernetesMulti-tenancy - EKS Best Practices GuidesClusters as-a-ServiceClusters as-a-Serviceは、テナントごとに独立したClusterを提供します。実Cluster管理ツールとして、AWS EKS、GCP GKE、Azure AKE、Kubeadm、などがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Control Planes as-a-ServiceControl Planes as-a-Serviceは、テナントごとに独立したコントロールプレーン (言い換えば仮想Cluster) を提供します。仮想Cluster管理ツールとして、Kcp、tensile-kube、vcluster、VirtualCluster、などがあります。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?Namespaces as-a-ServiceNamespaces as-a-Serviceは、テナントごとに独立したNamespaceを提供します。Namespaceを増やすだけなので、ツールは不要です。Three Tenancy Models For Kubernetes | KubernetesWhat are the three tenancy models for Kubernetes?ツール固有テナントツール固有テナントは、テナントごとに固有の論理空間 (例：ArgoCDのAppProject、CapsuleのTenant、kioskのAccount、KubeZooのTenant、など) を提供します。ツールによっては、X as-a-Service も兼ねている場合があります。今回紹介するAppProjectはNamespaceテナントを兼ねており、ツール固有のテナント で解説しています。04. ArgoCDでのテナントパターン実践の一覧お待たせしました。ここからは、KubernetesのマルチテナントをArgoCDで実践し、おすすめのテナントパターンを解説していきます。なお、オススメするものを ★ としています。マルチテナントパターン名      テナント実践      ArgoCDがテナント間で独立 / 共有      テナント間のKubernetesリソース分離(分離できていれば ✅ )      オススメ    Namespacedスコープリソース      Clusterスコープリソース    Clustersas-a-Service      実Clusterテナント      独立      ✅      ✅          Control Planesas-a-Service      仮想Clusterテナント      独立      ✅      ✅      ★    Namespacesas-a-Service      Namespaceテナント      独立      ✅                ツール固有テナント      Projectテナント(CLモード)      共有      ✅                  Projectテナント(NSモード)      独立      ✅            ★★    How many do you need? - Argo CD Architectures Explained | Akuity以降の図の凡例です。ArgoCDの各コンポーネント (application-controller、argocd-server、dex-server、repo-server) と各リソース (Application、AppProject) を区別しています。04-02. Clusters as-a-Service の実践実Clusterテナント実Clusterテナントは、Clusters as-a-Serviceなテナントの実践であり、実際のClusterをテナントの単位とします。後述の仮想Clusterと対比させるために、"実Cluster" と呼ぶことにします。各プロダクトチームは、実Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。オススメしない理由実Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。半年以内にアップグレードしないとサポートが切れるKubernetesクラスターが33個もあって、泣いちゃった— 長谷川 広樹 (俺です) (@Hiroki__IT) January 18, 2023  アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット ×                                                                                      デメリットの回避策                                                                                  拡張性                 -                                                                                                                                                                     テナントを増やすために実Clusterを用意する必要があり、作業量が多い。                              ➡︎  IaCツールで実Clusterを用意するようにすれば作業量を減らせるが、やっぱりとてもつらい😭       安全性(セキュリティ)        ClusterからClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                                                                  -                                                                                                ➡︎  -                                                                                                   保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に実Clusterを保守しないといけない。(例：アップグレード、機能修正、など)  ➡︎  回避できず、とてもつらい😭                                                                           性能                  Clusterのハードウェアリソースを他のテナントと奪い合うことなく、これを独占できる。                                                                                     -                                                                                                ➡︎  -                                                                                                   信頼性                 テナントごとに実Clusterが独立しており、他の実Clusterから障害の影響を受けない。                                                                                        -                                                                                                ➡︎  -                                                                                    04-03. Control Planes as-a-Service の実践仮想Clusterテナント - ★仮想Clusterテナントは、Control Planes as-a-Serviceなテナントの実践であり、仮想Clusterをテナントの単位とします。各プロダクトチームは、仮想Clusterテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Using Argo CD with vclusters. Managing deployment to multiple… | by Daniel Helfand | Argo Projectオススメした理由仮想Clusterテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                                           デメリット ×                                                                                               デメリットの回避策                                                                                    拡張性                 テナントを増やすためにマニフェストで定義した仮想Clusterを用意するだけでよく、実Clusterを用意することと比べて作業量が少ない。                                          -                                                                                                         ➡︎  -                                                                                            安全性(セキュリティ)        仮想Cluster管理ツールの機能で、仮想ClusterからホストClusterへの名前解決を不可能にすれば、他のテナントからの通信を遮断できる。                                         -                                                                                                         ➡︎  -                                                                                                     保守性                 ClusterスコープまたはNamespacedスコープなKubernetesリソースを他のテナントから分離できる。これらのKubernetesリソース (特にCRD) の変更が他のテナントに影響しない。  各テナントが、個別に仮想Clusterを保守しないといけない。(例：アップグレード、機能修正、など)  ➡︎  仮想Clusterに関する知見を持つ組織であれば、各テナントで保守できる。                                    性能                  -                                                                                                                                                                     Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                         ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                信頼性                 テナントごとに仮想Clusterが独立しており、他の仮想Clusterから障害の影響を受けない。                                                                                    -                                                                                                         ➡︎  -                                                                                      04-04. Namespaces as-a-Service の実践Namespaceテナントは、Namespaces as-a-Serviceなテナントの実践であり、Namespaceをテナントの単位とします。後述の Projectテナント は二重のテナントを持ち、Namespaceテナントも兼ねています。そのため、ここではNamespaceテナントの解説は省略します。04-05. ツール固有テナントの実践ProjectテナントProjectテナントは、ツール固有テナントの実践であり、NamespaceとAppProjectをテナントの単位とします。Projectテナントは、二重のテナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持ち、"あらゆる面から" マニフェストのデプロイを制限します。特に、AppProjectはNamespaceスコープなカスタムリソースであり、自身に所属するApplicationを一括して制限します。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foo  # 自身に所属するApplicationを制限するspec: ...apiVersion: argoproj.io/v1alpha1kind: Applicationmetadata:  name: infra-application  namespace: foospec:  # foo-tenantに所属する  project: foo-tenant  ...Argo CD in Practice: The GitOps way of managing cloud-native applications (English Edition)Projects - Argo CD - Declarative GitOps CD for Kubernetes.spec.scopeキーからも分かる通り、AppProjectはNamespacedスコープなカスタムリソースであり、任意のNamespaceを設定できます👍apiVersion: apiextensions.k8s.io/v1kind: CustomResourceDefinitionmetadata:  labels:    app.kubernetes.io/name: appprojects.argoproj.io    app.kubernetes.io/part-of: argocd  name: appprojects.argoproj.iospec:  group: argoproj.io  names:    kind: AppProject    ...  # Namespacedスコープなカスタムリソースであるとわかる  scope: Namespaced...  argo-cd/manifests/crds/appproject-crd.yaml at master · argoproj/argo-cd · GitHubExtend the Kubernetes API with CustomResourceDefinitions | KubernetesCLモード vs. NSモードArgoCDには、Clusterスコープモード と Namespacedスコープモード (以降、"CLモード" と "NSモード") があります。スコープモードに応じて、Projectテナントの設計方法が異なります。次の章からは、CLモードとNSモードの両方でProjectテナントを解説していきます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes05. CLモードなArgoCDCLモードなArgoCDとはCLモードなArgoCDの場合、各テナント間で共有のArgoCDを管理します例えば、Projectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。別途、ArgoCD専用のNamespace (argocd) を用意し、ここに関連するKubernetesリソース (例；ConfigMap) を配置します。各プロダクトチームは、Projectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesArgoCD: Multi-tenancy strategy. Introduction | by Geoffrey | Aug, 2023 | Medium実装方法AppProjectNSモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App-Of-Appsパターンの場合に使用する    - namespace: foo      server: "https://kubernetes.default.svc"    # プロダクト用Clusterに関する認可を設定する    - namespace: "*"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com  # CLモードでは設定が必要である  sourceNamespaces:    - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。一方で後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。そのため、.spec.sourceNamespacesキーで、特定のNamespaceのApplicationがこのAppProjectに所属できないように、ApplicationのNamespaceを制限しています。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)NSモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # CLモードでは設定が必要である  # 全てのNamespaceを指定したい場合は、ワイルドカードを設定する  application.namespaces: "*".application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。一方での後述のNSモードとは異なり、CLモードなArgoCDは任意のNamespaceのApplicationにアクセスできます。--application-namespacesオプションで、任意のNamespaceにアクセスするための認可を設定できます。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesargocd-cmd-params-cmの代わりに、例えば以下のようにPodに引数を直接渡しても良いです🙆🏻‍例えば、以下のような実装になります。apiVersion: v1kind: Podmetadata:  name: argocd-server  namespace: argocdspec:  containers:    - name: argocd-server      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-server        # コンテナ起動時の引数として        - --application-namespaces="*"  ...apiVersion: v1kind: Podmetadata:  name: argocd-application-controller  namespace: argocdspec:  containers:    - name: argocd-application-controller      image: quay.io/argoproj/argocd:latest      args:        - /usr/local/bin/argocd-application-controller        # コンテナ起動時の引数として        - --application-namespaces="*"  ...  Argocd application controller - Argo CD - Declarative GitOps CD for KubernetesArgocd server - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)NSモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  # 専用のNamespaceを設定する  namespace: argocddata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:foo, *, *, foo/*/*, allow    p, role:bar, *, *, bar/*/*, allow    p, role:baz, *, *, baz/*/*, allow    g, foo-team, role:foo    g, bar-team, role:bar    g, baz-team, role:baz  scopes: "[groups]"認証済みグループ (foo-team、bar-team、baz-team) に対して、無認可のAppProject (foo、bar、baz) に所属するApplicationを操作できないように、認可スコープを制限しています。Casbin の記法を使用します。今回の実装例で使用したp (パーミッション) とg (グループ) では、以下を記法を使用できます👍apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: argocddata:  policy.default: role:readonly  policy.csv: |    # ロールとArgoCD系カスタムリソースの認可スコープを定義する    p, role:<ロール名>, <Kubernetesリソースの種類>, <アクション名>, <AppProject名>/<ApplicationのNamespace名>/<Application名>, <許否>    # 認証済みグループにロールを紐付ける    g, <グループ名>, role:<ロール名>  scopes: "[groups]"RBAC Configuration - Argo CD - Declarative GitOps CD for Kubernetesオススメしない理由CLモードなArgoCDのProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                   デメリット ×                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。             -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。   -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 ArgoCD用Clusterの管理者が単一のClusterを保守すればよい。(例：アップグレード、機能修正、など)  AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                             Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 -                                                                                             ClusterまたはArgoCDで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                            ➡︎  代わりにNodeやArgoCDを十分に冗長化して可用性を高めれば、影響を緩和できる。ただ、そもそもの影響範囲が大きすぎる😭                                           05-02. NSモードなArgoCD - ★★NSモードなArgoCDとはNSモードなArgoCDの場合、前述のCLモードとは異なり、各Projectテナント間で独立したArgoCDを管理します。例えば、Projectテナントとして、プロダクト別のNamespace (foo、bar、baz) とAppProject (foo、bar、baz) を用意します。各Projectテナントに、ArgoCDと関連するKubernetesリソース (例；ConfigMap) を配置します。各プロダクトチームは、Projectテナント内のApplicationを操作し、正しいプロダクト用Clusterにマニフェストをデプロイします。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetes実装方法AppProjectCLモードと同様にして、AppProjectに所属するApplicationによるマニフェストのデプロイを制限できます。例えば、以下のような実装になります。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # App-Of-Appsパターンの場合に使用する    - namespace: foo      server: "https://kubernetes.default.svc"    # プロダクト用Clusterに関する認可を設定する    - namespace: "*"      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com# NSモードでは設定が不要である# sourceNamespaces:#   - fooApplicationを操作するログインユーザーが、無認可のNamespaceやClusterをデプロイ先に指定できないように、.spec.destinationキーで制限しています。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできます。そのため、.spec.sourceNamespacesキーでマニフェストのデプロイを制限する必要はありません。Applications in any namespace - Argo CD - Declarative GitOps CD for KubernetesProjects - Argo CD - Declarative GitOps CD for KubernetesArgoCDコンポーネント用ConfigMap (argocd-cmd-params-cm)CLモードと同様にして、argocd-cmd-params-cmでは、ArgoCDの各コンポーネントのコンテナの引数を設定できます。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# NSモードでは設定が不要である# application.namespaces: "*"前述の通り、.application.namespacesキーは、argocd-serverとapplication-controllerの--application-namespacesオプションに相当します。前述のCLモードとは異なり、NSモードなArgoCDは自身が所属するNamespaceのApplicationのみにアクセスできますそのため、.application.namespacesキーでNamespaceに関する認可を設定する必要はありませんもちろん、Podのコンテナ引数にも設定は不要です。Applications in any namespace - Argo CD - Declarative GitOps CD for Kubernetesログインユーザー用ConfigMap (argocd-rbac-cm)CLモードと同様にして、argocd-rbac-cmでは、Applicationを操作するログインユーザーが、無認可のAppProjectやNamespaceに所属するApplicationを操作できないように制限します。例えば、以下のような実装になります。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  # デフォルトのロール  # @see https://github.com/argoproj/argo-cd/blob/master/assets/builtin-policy.csv#L9-L16  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: "[groups]"認証済みグループ (app-team、infra-team) に対して、無認可のAppProject (app、infra) に所属するApplicationを操作できないように、認可スコープを制限しています。特にオススメした理由NSモードなArgoCDのProjectテナントには、以下のメリデメがあります。デメリットの回避策も考慮して、独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                  デメリット ×                                                                                                                                                                                                                      デメリットの回避策                                                                                                                                                            拡張性                 テナントを増やすためにNamespaceとAppProjectを用意するだけでよく、作業量が少ない。            -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                    安全性(セキュリティ)        NetworkPolicyでNamespace間の名前解決を不可能にすれば、他のNamespaceからの通信を遮断できる。  -                                                                                                                                                                                                                                ➡︎  -                                                                                                                                                                             保守性                 単一のClusterを保守すればよい。(例：アップグレード、機能修正、など)             AppProjectはNamespacedスコープなカスタムリソースのため、ClusterスコープなKubernetesリソースを他のテナントと共有しないといけない。そのため、ClusterスコープなKubernetesリソース (特にCRD) の変更は全てのテナントに影響する。  ➡︎  ArgoCDのアップグレード時 (CRDの変更時) は、ついでにKubernetesもアップグレードしたい。新しいClusterを別に作成し、そこで新ArgoCDを作成すれば一石二鳥である。                 性能                  -                                                                                            Clusterのハードウェアリソースを他のテナントと奪い合うことになる。                                                                                                                                                                ➡︎  多くの利用者が同時並行的にArgoCDを操作する状況になりにくければ、奪い合いも起こらない。                                                                                        信頼性                 テナントごとにArgoCDが独立しており、他のArgoCDから障害の影響を受けない。                     Clusterで障害が起こると、これは全てのテナントに影響する。                                                                                                                                                                        ➡︎  代わりに、Nodeを十分に冗長化して可用性を高める。いずれかのインスタンスで障害が起こっても、正常なインスタンスでArgoCDが稼働できる。                         Projectテナント例の一覧NSモードなArgoCDを採用する場合、Projectテナント例を解説していきます。前述の通り、Projectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。なお、オススメするものを ★ としています。    テナント例(二重テナント)    オススメ  Namespace(第一テナント)    AppProject(第二テナント)  テナント例1      プロダクトの実行環境別      プロダクトの実行環境別          テナント例2      プロダクト別      プロダクトの実行環境別      ★    テナント例3      プロダクト別      プロダクトのサブチーム別      ★★    "管理チーム別" (今回でいうプロダクト別) というNamespaceの分割パターンは、様々な著名な書籍やブログで紹介されています👀  https://www.amazon.co.jp/dp/1617293725Kubernetes best practices: Specifying Namespaces in YAML | Google Cloud Blogテナント例1Namespace (プロダクトの実行環境別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。この場合に、プロダクトの実行環境別にNamespace (dev、tes) とAppProject (dev、tes) を用意します。オススメしなかった理由テナント例1には、以下のメリデメがあります。独断と偏見でオススメしませんでした。 アーキテクチャ特性  メリット ⭕️                                                                                                                                     デメリット ×                                                                                                                                デメリットの回避策                                                                                       拡張性                 -                                                                                                                                               ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりやすい。その時点で、Projectテナントの増やせなくなる。  ➡︎  例えばAWS EKSの場合、Node数を増やしたり、Nodeのスペックを上げる。ただ、お金がかかる😭       安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                          ➡︎  -                                                                                                        保守性                 異なる実行環境に関するApplicationが共存しておらず、別のargocd-serverから操作することになるため、実行環境間の選択ミスが起こりにくい。            -                                                                                                                                          ➡︎  -                                                                                         テナント例2 - ★Namespace (プロダクト別)、AppProject (プロダクトの実行環境別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトの実行環境別にAppProject (dev、tes) を用意します。オススメした理由テナント例2には、以下のメリデメがあります。独断と偏見で オススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                デメリット ×                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                   -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可の実行環境別AppProjectを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                          異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 テナント例3 - ★★Namespace (プロダクト別)、AppProject (プロダクトのサブチーム別)プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo、bar) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。特にオススメした理由テナント例3には、以下のメリデメがあります。独断と偏見で 特にオススメ しました。 アーキテクチャ特性  メリット ⭕️                                                                                                                                       デメリット ×                                                                                                                                           デメリットの回避策                                                                                 拡張性                 ArgoCDのPod数が多くなり、将来的にNode当たりのPodやIPアドレスの上限数にひっかかりにくい。                                                          -                                                                                                                                                     ➡︎  -                                                                                         安全性(セキュリティ)        ログインユーザー用ConfigMap (argocd-rbac-cm) を使用すれば、無認可のサブチーム別AppProjectに所属するApplicationを操作できないように制限できる。  -                                                                                                                                                     ➡︎  -                                                                                                  保守性                 -                                                                                                                                                 異なる実行環境に関するApplicationが共存しており、同じargocd-server (ダッシュボード) から操作することになるため、実行環境間の選択ミスが起こりやすい。  ➡︎  ダッシュボードにはApplicationのフィルタリング機能があるため、選択ミスを回避できる。 06. Projectテナントのデプロイ制限の仕組みそろそろ解説を読むのがしんどい方がいるのではないでしょうか。『君がッ、泣くまで、解説をやめないッ！』Projectテナントがマニフェストのデプロイをどのように制限するのかについて、例を挙げて解説します。ここでは、NSモードなArgoCDの "テナント例3" を採用し、以下のAppProjectを作成したと仮定します。Projectテナントが二重テナント (第一テナントにNamespace、第二テナントに複数のAppProject) を持つことに留意してください。apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # appチーム  name: app  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: "https://kubernetes.default.svc"      # プロダクト用Clusterに関する認可を設定する      # Namespace (app) へのデプロイを許可する    - namespace: app      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comapiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  # infraチーム  name: infra  namespace: foospec:  destinations:    # ArgoCD用Clusterに関する認可を設定する    # Namespace (foo) へのデプロイを許可する    - namespace: foo      server: "https://kubernetes.default.svc"    # プロダクト用Clusterに関する認可を設定する    # Namespace (infra) へのデプロイを許可する    - namespace: infra      server: https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.comマニフェストのデプロイ制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。Projectテナントは、例えば 赤線 の方法で、マニフェストのデプロイを制限します。マニフェストをデプロイできる場合マニフェストを正しくデプロイする場合、Projectテナントはこれを制限しません。(1) argocd-serverは、argocd-cmd-params-cmからアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、argocd-serverは同じNamespaceにしかアクセスできなくなる。# application.namespaces: "*"(2) fooプロダクトのinfraチームが、argocd-serverを操作します。(3) argocd-serverは、argocd-rbac-cmからApplication操作に関する認可スコープを取得しますapiVersion: v1kind: ConfigMapmetadata:  name: argocd-rbac-cm  namespace: foodata:  policy.default: role:readonly  policy.csv: |    p, role:app, *, *, app/*/*, allow    p, role:infra, *, *, infra/*/*, allow    g, app-team, role:app    g, infra-team, role:infra  scopes: "[groups]"(4) infraチームは、認可されたAppProjectに所属するApplicationを操作します。(5) infraチームは、Dev環境のfooプロダクト用ClusterのNamespace (infra) にマニフェストをデプロイできます。(🚫制限例1) 無認可のNamespaceでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが無認可のNamespace (bar) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。namespace bar is not permitted in project 'infra-team'無認可のNamespaceでApplicationを作れてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます😈argo-cd/test/e2e/app_management_ns_test.go at v2.7.10 · argoproj/argo-cd · GitHub(🚫制限例2) 無認可のAppProjectでApplicationを作成しようとした場合例えば、fooプロダクトのinfraチームが、無認可のAppProject (app) でApplicationを作成しようとします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。Application referencing project 'app' which does not exist任意のAppProjectでApplicationを作成できてしまうと、そのApplicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます😈(🚫制限例3) 無認可のプロダクト用Clusterを指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のプロダクト用Cluster (bar-cluster) をデプロイ先として指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://bar-cluster.gr7.ap-northeast-1.eks.amazonaws.com infra} is not permitted in project 'infra-team'任意のClusterをデプロイ先に指定できてしまうと、Applicationから無認可のプロダクト用Clusterにマニフェストをデプロイできてしまいます😈argo-cd/util/argo/argo_test.go at v2.7.10 · argoproj/argo-cd · GitHub(🚫制限例4) 無認可のNamespaceをデプロイ先に指定しようとした場合例えば、fooプロダクトのinfraチームがApplicationを操作し、無認可のNamespace (app) をデプロイ先に指定しようします。すると、argocd-serverは以下のようなエラーを返却し、この操作を制限します。application destination{https://foo-cluster.gr7.ap-northeast-1.eks.amazonaws.com app} is not permitted in project 'infra-team'任意のNamespaceをデプロイ先に指定できてしまうと、そのApplicationから無認可のNamespaceにマニフェストをデプロイできてしまいます😈argo-cd/util/argo/argo_test.go at v2.7.10 · argoproj/argo-cd · GitHubargocd-serverとapplication-controllerでデプロイできるKubernetesリソースの種類 (.spec.clusterResourceWhitelistキー、.spec.namespaceResourceWhitelistキー、など)repo-serverでポーリングできるリポジトリ (.spec.sourceReposキー)apiVersion: argoproj.io/v1alpha1kind: AppProjectmetadata:  name: foo-tenant  namespace: foospec:  clusterResourceWhitelist:    - group: "*"      kind: "*"  namespaceResourceWhitelist:    - group: "*"      kind: "*"  sourceRepos:    - "*"  ..."Projectテナントによるマニフェストのデプロイ丸ごとの制限" という観点でテーマが異なるため、本記事では言及しませんでした🙇🏻‍  Projects - Argo CD - Declarative GitOps CD for KubernetesDeclarative Setup - Argo CD - Declarative GitOps CD for KubernetesカスタムリソースのReconciliation制限プロダクトの実行環境 (Dev環境、Tes環境) 別に管理されたClusterがいる状況と仮定します。プロダクト別にNamespace (foo) 、プロダクトのサブチーム別にAppProject (app、infra) を用意します。Projectテナントは、例えば 赤線 の方法で、ArgoCD系カスタムリソースに対するapplication-controllerのReconciliationを制限します。ArgoCD系カスタムリソースをReconciliationできる場合正しいNamespaceに対してReconciliationを実行する場合、Projectテナントはこれを制限しません。(1) application-controllerは、argocd-cmd-params-cmから自身がアクセスできるNamespaceを取得します。apiVersion: v1kind: ConfigMapmetadata:  name: argocd-cmd-params-cm  namespace: foodata:# 設定しないことで、application-controllerは同じNamespaceにしかアクセスできなくなる。# application.namespaces: "*"(2) application-controllerは、同じNamespaceに所属するArgoCD系カスタムリソースに対して、Reconciliationを実行します。(🚫制限例1) 無認可のNamespaceにReconciliationを実行しようとした場合例えば、application-controllerがReconciliationの対象とするNamespaceを選ぼうとしているとします。すると、application-controllerは内部で検証メソッドを実行し、無認可のNamespace (bar) は選ばないようにします。argo-cd/controller/appcontroller_test.go at v2.7.10 · argoproj/argo-cd · GitHub07. おわりにKubernetesのマルチテナントパターンとArgoCDでのテナントパターンの実践をもりもり布教しました。あらゆる面からマニフェストのデプロイを制限してくれる、Projectテナントの素晴らしさが伝わりましたでしょうか。KubernetesのマルチテナントパターンをArgoCDでどう実践するべきか、について困っている方の助けになれば幸いです👍謝辞本記事のタイトルは、私が崇拝しているドメイン駆動設計の書籍 "実践ドメイン駆動設計" から拝借しました🙏また、ArgoCDでのテナントパターンの収集にあたり、以下の方からの意見も参考にさせていただきました。@toversus26 さんこの場で感謝申し上げます🙇🏻‍]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day5]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_5</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_5</guid>
            <pubDate>Wed, 16 Aug 2023 13:49:19 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-Master serviceを読みました。今回はArchitecture > Core functions > Universe creationを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Universe creationYugabyteDBのユニバース作成は複数のステップを含む。Start YB-MastersYBユニバース作成の最初のステップはレプリケーションファクターで指定された数だけYB-Masterを作成することである。作成されたYB-Masterはそれぞれを認識している。YB-Masterはユニバース内でユニークなID(UUID)をそれぞれに割り当て、それぞれを認識しあったあとにリーダーエレクションを実行する。このステップの終りにYB-Masterの中のひとつがリーダーとして確立される。Start YB-TServersノードの数だけYB-TServerを起動し、それぞれにマスターのアドレスを渡す。それぞれのYB-TServerはマスターにハートビートを送信し、正常に動作していることを確認する。ハートビートはYB-TServerが現在ホストしているタブレットとその負荷情報についても通信するが、この時点ではタブレットにデータは登録されていない。Examples4ノードからなるYBユニバースにテーブルを作成する場合について考える。テーブルのレプリケーションファクターは3とする。3つのマスターがcreateモードで起動される。これはマスターがすでに起動しているために発生するエラーを防ぐために明示的に実行される。リーダーエレクションを実行し、リーダーを選出する。YB-TServerが起動し、全てのYB-TServerがマスターにハートビートを送信する。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PaLM API for textで作るGoogle Cloudコストチェッカー]]></title>
            <link>https://sreake.com/blog/google-cloud-cost-check-with-palm-api-for-text/</link>
            <guid>https://sreake.com/blog/google-cloud-cost-check-with-palm-api-for-text/</guid>
            <pubDate>Wed, 16 Aug 2023 05:06:08 GMT</pubDate>
            <content:encoded><![CDATA[前段 Sreake事業部の橋本です。 Generative AIをSRE活動に活用する場合に大きく分けて以下のような2ケースが考えられます。これまで1つめのtoil削減の実装をGenerative AIに含まれる学習デー […]The post PaLM API for textで作るGoogle Cloudコストチェッカー first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WezTerm で快適な WSL2 環境にする]]></title>
            <link>https://blog.1q77.com/2023/08/wezterm-on-windows/</link>
            <guid>https://blog.1q77.com/2023/08/wezterm-on-windows/</guid>
            <pubDate>Sat, 12 Aug 2023 11:07:01 GMT</pubDate>
            <content:encoded><![CDATA[家の自分用 Laptop はずっと Linux を使ってきましたが、数か月前に Inspiron 14 に買い替えたタイミングで Ubuntu 22.04 にしてからやっぱり不便だなあとも思っていました。(InputMethod の切]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREからPlatform Engineerへの拡大 というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/08/10/150412</guid>
            <pubDate>Thu, 10 Aug 2023 06:04:12 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud Operator Days Tokyo 2023 で SREからPlatform Engineerへの拡大 というテーマでの登壇を果たしました。オンデマンド配信なのでいずれ見れるようになると思います。今回のサブタイトルは【運用の新時代】とし、それにちなんでメインタイトルを考えました。資料の作成過程で、話したい内容がどんどんと増えてきてしまい、20分という限られた時間での発表が一番の課題となりました。内容の整理に際して、具体と抽象 ―世界が変わって見える知性のしくみ という本を参照し、大変役立ちました。具体と抽象作者:細谷 功dZERO（インプレス）Amazon資料このブログでは、Cloud Operator Days Tokyo 2023での登壇内容をまとめております。資料作成時に参照したさまざまな参考情報も掲載していますので、読者の皆様が別途情報を探す手間を省けるよう心掛けました。ぜひ、本ブログをご活用ください。文字多くて分かりにくいのは分かってます。脳内整理はできているのですが資料を読みやすくすると20分に何も収まらず...。 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングあなたらしくSREO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?Top Strategic Technology Trends for 2023: Platform EngineeringMaking the Business Case for a Dedicated Platform Engineering TeamSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイド]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Control Tower 徹底調査]]></title>
            <link>https://sreake.com/blog/learn-about-aws-control-tower/</link>
            <guid>https://sreake.com/blog/learn-about-aws-control-tower/</guid>
            <pubDate>Thu, 10 Aug 2023 05:52:55 GMT</pubDate>
            <content:encoded><![CDATA[AWS Control Tower とは AWS Control Tower とは Landing Zone を実装するための AWS のマネージドサービスです。統制を取りつつマルチアカウントを管理する仕組みです。 La […]The post AWS Control Tower 徹底調査 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[HarnessでGKEクラスタにCDパイプラインを構築する]]></title>
            <link>https://qiita.com/yokoo-an209/items/57e2e4c00394c9da85f7</link>
            <guid>https://qiita.com/yokoo-an209/items/57e2e4c00394c9da85f7</guid>
            <pubDate>Thu, 10 Aug 2023 05:22:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに実務においてHarnessを使用する機会があったので、お試しがてらGKEクラスタ上にCDパイプラインの構築を行います。（※なお、今回はHarnessの使用に焦点を当てているため、CIの実…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2023年8月10日現在 でLunarVim と Copilot.lua でのマルチラインサポートの改善方法 ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/08/10/021934</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/08/10/021934</guid>
            <pubDate>Wed, 09 Aug 2023 17:19:34 GMT</pubDate>
            <content:encoded><![CDATA[github.comLunarVimユーザーとして、私はNeovimでcopilot.luaを頻繁に利用しています。しかし、マルチラインのサポートに関してはいくつかの課題がありました。もっというとどこかのタイミングでCopilotが一行ずつしかサジェストされなくなりました。この問題に対して、一部のコードを修正することで、この課題を解決する方法を見つけました。問題点Copilot.lua(Copilot.vimも同様に)の中のagent.jsには、マルチライン入力の停止点を示すコード h.stop=["\n"] が含まれています。この設定により、一部の場面でマルチラインサポートが期待通りに動作しないことがありました。解決方法私が採用した方法は、このh.stop=["\n"]をh.stop=["\n\n\n"]に変更することです。この小さな変更により、マルチラインのサポートが大幅に向上します。以下のコマンドを実行することで、この変更を簡単に適用することができます。MAC でのsed 利用なのでこのようなコマンドになります。各環境で合わせていただきたいです。sed -i '' 's/h\.stop=\["\\\\n"\]/h\.stop=\["\\\\n\\\\n\\\\n"\]/' ~/.local/share/lunarvim/site/pack/lazy/opt/copilot.lua/copilot/dist/agent.js変更が正しく適用されたかどうかを確認するには、以下のコマンドを実行します。grep -o '.\{30\}h.stop=\[.\{30\}' ~/.local/share/lunarvim/site/pack/lazy/opt/copilot.lua/copilot/dist/agent.js結果この変更を適用した後、マルチラインサポートが明らかに向上しました。興味があれば最初に紹介したIssue に動画が添付されていたのでご覧ください。LunarVimとCopilot.luaの組み合わせは非常に強力ですが、小さな調整によりさらに快適に使うことができます。このハックが他のユーザーにも役立つことを願っています。後日談この変更を適用した後でマルチラインサポートは向上したのですが一部条件ではまだ、vscodeのような挙動ができません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Run を活用した Pull Request 単位での Ad hoc 開発環境作成]]></title>
            <link>https://sreake.com/blog/pull-request-based-adhoc-env/</link>
            <guid>https://sreake.com/blog/pull-request-based-adhoc-env/</guid>
            <pubDate>Wed, 09 Aug 2023 03:10:37 GMT</pubDate>
            <content:encoded><![CDATA[きっかけ 開発時、feature ブランチの Pull Request （以下、PR）ごとに実行環境が準備されると便利だよねというところから、PR ごとに開発環境を構築される仕組みを作ることになりました。 使用技術スタッ […]The post Cloud Run を活用した Pull Request 単位での Ad hoc 開発環境作成 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day4]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_4</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_4</guid>
            <pubDate>Thu, 03 Aug 2023 14:48:34 GMT</pubDate>
            <content:encoded><![CDATA[前回](https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_3)からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > YB-TServer serviceを読みました。今回はArchitecture > Key Concepts > YB-Master serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。YB-Master serviceYB-Masterサービスはテーブルやそのタブレットの場所、ユーザー・ロールの権限といったシステムのメタデータとレコードの管理を行っている。それに加えYB-Masterはロードバランシングやレプリケーションの開始といったバックグラウンドオペレーションの管理や、テーブルのCREATEやALTER、DROPといった様々な管理オペレーションの責任を持つ。YB-MasterはRaft Groupを組むことで高可用性を実現し、またテーブルに対するI/Oの単一障害点にならない。Functions of YB-MasterYB-Masterはシステムの重要な機能を複数持っている。Coordination of universe-wide administrative operationsCREATE TABLEやALTER TABLE、DROP TABLEといったユーザーからのリクエスト処理やバックアップの実行などUniverseをまたぐオペレーション実行の調整を担当している。YB-Masterではこれらのオペレーションがテーブルを保持するYB-TServerの状態に関わらず、全てのテーブルに伝搬されることを保証する。YugabyteDBは分散システムのため、Universeをまたぐ処理中にYB-TServerに障害が発生し一部のタブレットへの適用に失敗してもオペレーションの結果に問題が発生しないことが重要だからである。Storage of system metadataそれぞれのYB-Masterではネームスペースやテーブル、ロール、パーミッション、YB-TServerへ割り当てたテーブル情報を含むシステムメタデータを保存している。これらのシステムレコードはYB-Masterを対象にRaftグループを組みレプリケーションすることで冗長性を実現している。またシステムレコードはYB-Masterが管理するDocDBに保存される。Authoritative source of tablet assignments to YB-TServersYB-Masterは全てのテーブルとそれらをホストするYB-TServerの情報を保存している。一般のクライアントではそれらの情報はクライアントからクエリレイヤなどを通して取得された上で、クライアントにメタデータを返しデータアクセスが行なわれる。一方でスマートクライアントではYB-Masterに保存されたメタデータを利用して特定のYB-TServerが保持するタブレットやキャッシュを利用することが出来るため、データアクセス時のネットワークをまたぐ通信を減らすことができパフォーマンスを高めることができる。Background operationsいくつかのオペレーションはUniverseのライフタイムを通してバックグラウンドで行なうことで、フォアグラウンドのRead/Writeに影響を与えずに実行することが出来る。Data placement and load balancingYB-MasterのリーダーはCREATE TABLE時にタブレットの初期配置をYB-TServerをまたいで行なう。そのときにユーザー定義のデータ配置制約を強制し均一な読み込みを保証する。Universeのライフタイム中のノード追加や障害が発生しても、負荷分散を継続しデータ配置の制約を自動的に適用する。Leader balancing複数のYB-TServerに配置されたタブレットへのアクセスがUniverseをまたいで分散されることを保証している一方で、YB-Masterは対象となるノード1間でそれぞれのノードが同じ数のtablet-peer leader2をもつことを保証する。Rereplication of data on extended YB-TServer failureYB-Masterは全てのYB-TServerからハードビートシグナルを受け取ることでYB-TServerの死活監視を行なっている。そしてYB-MasterはYB-TServerの異常を検知したときに、どれぐらいのあいだYB-TServerが異常であったかを追跡する。閾値を超えると、YB-Masterは障害中のYB-TServerに配置されていたタブレットを再配置するYB-TServerを探し、レプリケーションを実行する。レプリケーションはYB-Masterリーダーに抑制された状態で実行されるため、Universeのフォアグラウンドオペレーションには影響をおよぼさない。Raft Groupのリーダーになれるノード↩↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[K8sGPT Deep Dive というタイトルで登壇しました #CNDF]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/08/03/155326</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/08/03/155326</guid>
            <pubDate>Thu, 03 Aug 2023 06:53:26 GMT</pubDate>
            <content:encoded><![CDATA[概要CloudNative Days Fukuoka 2023というイベントに『K8sGPT Deep Dive KubernetesクラスタのAI駆動型分析について』というタイトルで登壇しました。クラウドネイティブとAIを組み合わせることの深い洞察を共有することができ、私自身がエンジニアとして働くなかで、K8sGPTの最新の進化とその可能性について詳しく語る機会はなかなかなく、この経験を活かしていきたい。資料を作っている中で話したいことがどんどん増えていってめちゃくちゃ困った。また、その中でAIOpsについても触れることができ、非常に充実した時間でした。AIOpsはAIと運用管理の統合を指し、それによりIT運用の効率化や自動化が可能となります。その重要性と可能性を伝えることができたので良かった。登壇が終わった今でも、K8sGPTやAIOpsについてさらに知識を深め、クラウドネイティブの世界にどのように最適化された解決策を提供できるかについて考え続けています。参加者の皆さんからもたくさんのフィードバックを頂き、今後の研究や開発の参考になりました。私がこのプレゼンテーションのために読み込んだ複数の本の中で、特に皆さんにお勧めしたい一冊を挙げるとすれば、「大規模言語モデルは新たな知能か――ChatGPTが変えた世界」だと言えます。なぜなら、専門家でも初心者でも、難解な数学を使わずに重要な概念を理解できるように作られているからです。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店Amazon資料登壇資料になります。このブログの目的は参考資料をいちいち探さなくていいようにありますのでご活用ください。 speakerdeck.com参考文献公式ページ | K8sGPTGitHub | K8sGPTGitHub | K8sGPT OperatorDocs | K8sGPTOperator patternK8sGPT OperatorHow to Get Started With AIOpsPrompt Engineering Guideオブザーバビリティ・エンジニアリングKubernetes基盤を自律的に支えるController化の実装Tips / forkwell-202303-amsy810-k8sAutomation and Machine Learning with Site Reliability EngineeringTEMPLE: Six Pillars of ObservabilityAI時代に向けたクラウドにおける信頼性エンジニアリングの未来構想 / DICOMO2022 6A-1大規模言語モデルは新たな知能か――ChatGPTが変えた世界 (岩波科学ライブラリー)ChatGPTの頭の中 (ハヤカワ新書)言語の本質　ことばはどう生まれ、進化したかAI vs. 教科書が読めない子どもたち【ITIL4公認】ITIL 4の基本 図解と実践]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day3]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_3</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_3</guid>
            <pubDate>Wed, 02 Aug 2023 16:13:24 GMT</pubDate>
            <content:encoded><![CDATA[YugabyteDBのドキュメントを全部読む Day3前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Key Concepts > Universeを読みました。今回はArchitecture > Key Concepts > YB-TServer serviceを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。それはそれとして技術系の単語をカタカナ表記で誤魔化していて、体系的に学んでいないことがバレてしまう。特にストレージまわりが分からない……YB-TServer serviceYB-TServer(YugabyteDB Tablet Servcer)はユーザからの受けつけたYugabyteDBクラスタへのリクエストのI/Oの処理をする。テーブルのデータは一つ以上のTablet peerに分割(シャーディング)される。peerの数はレプリケーションファクターによって決定される。YB-TServerは一つ以上のTablet peerをホストする。Tablet peerはRaftグループを形成してグループ間でデータの複製を行ない、タブレットはYB-TServer上で最大の効率になるように管理される。Server-global block cacheブロックキャッシュは一つTB-TServer上の異なるタブレット間で共有される。YB-TServerのメモリ効率は一つのテーブルからの読み込みが多いほど最適化される。Space AmplificationYugabyteDBではSize-tired Compactionというライトアンプリフィケーション1が小さい圧縮方式を利用している。Size-tired Compactionはスペースアンプリフィケーション2が大きいという問題があるが、YugabyteDBではテーブルは複数のタブレットに分割され、タブレット間でのConcurrent Compactionは特定の最大値まで絞られるため問題になりにくい。YugabyteDBでは凡そ10-20%のスペースアンプリフィケーションにおさまる。つまりSize-tired Compaction一単位が扱うデータ量を小さく(タブレット化)して、同時に実行される圧縮処理数を絞ることで特定のタイミングで圧縮に使用されるストレージ容量を抑えているということ？Throttled compactionsYB-TServerではタブレット間で実行される圧縮処理の同時実行数を制限することで、圧縮処理が多量のリソースを占有することを防いでいる。この機能は圧縮されるファイル同士のサイズを比べ、実行される圧縮処理が妥当であることを確認することで実現されている。Small and large compaction queuesYB-TServerでは圧縮処理を大きい圧縮処理と小さい圧縮処理に分けて優先度を決めることで、I/Oが大きな場合でもシステムの機能を保っている。YugabyteDBでは圧縮処理数を制限することに加え、様々な最適化を実行することで圧縮処理の影響を最小化している。Manual compactionYugabyteDBではyb-admin utilityのcompact_tableコマンドにより、任意のタイミングでテーブルに対して圧縮を実行することが出来る。この方法はデータが新しく書き込まれない場合や、DDLやTTLの超過によるデータ削除時によりデータが断片化したときに有効である。Statistics-based full compactions to improve read performanceYugabyteDBでは読み込まれたkey-valueペアをDocDBレベルで監視している。監視対象となる時間軸はauto-compact-stat-window-secondsで管理されている。YugabyteDBがデータ読み込み時に多量の廃棄されたデータのスキップを検知した場合、full compactionがトリガーされ不要なキーの削除が行なわれる。Full compactionがトリガーされる詳細な条件は対象の時間軸で以下が満された時である。廃棄されたキーとアクティブなキーが読まれる割り合いがauto-compact-percent-obsoleteで定義された閾値を超たとき。廃棄されたキーの読み込みauto-compact-min-obsolete-keys-foundで定義された閾値を超たとき。この機能はTTLを設定したテーブルと互換性があり、TTL file expirationが有効なテーブルではスケジュールされた圧縮を実行しない。Scheduled full compactionsYugabyteDBでは全てのデータに対するデータ圧縮をスケジュール実行することが出来る。スケジュール実行はscheduled-full-compaction-frequency-hoursとscheduled-full-compaction-jitter-factor-percentageのフラグで管理される。この機能は大量のDELETEとUPDATEを定常的に実行するワークロードでのパフォーマンスとディスクスペースの再割り当てに有効である。スケジュール化したデータ圧縮はTTLと互換しているが、TTL file expirationとは互換していない。つまりスケジュールされた圧縮は実行されない。Server-global memstore limitServer-global memstore limitは一つのYB-TServer上のタブレット間でシェアされるメモリサイズを追跡し、強制する。この機能はタブレット間の書き込みに偏りがある場合に有効である。一つのテーブルに書き込みが集中しているばあい、メモリ制限以上のメモリを割り当てることでパフォーマンスを向上させることが出来る。Auto-sizing of block cache and memstoreBlock Cacheとmemstoreは何れも多量のメモリを使用している。これらはtablet-peer間で共有されるリソースのため、メモリ管理とこれらのコンポーネントの様々な環境に合せたサイジングを容易にしている。YB-TServerでは自動で特定の割合のメモリをBlock CacheとMemstoreに割り当てる。Distributing tablet load uniformly across data disks複数のSSDを利用するハードウェアでは、テーブルのデータ(SSTable)とWALはテーブル毎に利用可能なディスクに均等に分散される。このストライピングと呼ばれる負荷分散は、それぞれのディスクがそれぞれのテーブルの負荷を均等に処理することを保証する。SSDで実際に書き込んだデータより書き込み量が増幅する現象。もちろんライトアンプリフィケーションが小さいほうが望ましい。↩↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day2]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_2</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_2</guid>
            <pubDate>Wed, 26 Jul 2023 15:03:13 GMT</pubDate>
            <content:encoded><![CDATA[YugabyteDBのドキュメントを全部読む Day2前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Design goalsを読みました。今回はArchitecture > Key Concepts > Universeを読みます。また画像は同ドキュメントより引用しています。UniverseYugabyteDBは耐久性とスケーラビリティを兼ねそなえた分散データベースを達成するために、Universe1と呼ばれるノードのグループを持っている。Universeはビジネス要件やレイテンシの兼ね合いでシングルゾーン、単一リージョンマルチゾーン、マルチリージョン、同期・非同期レプリケーションなどを選択することが出来る。UnivereはClusterと表現されることもある。データの構成Universeは一つ以上のネームスペースを持つことができ、またネームスペースは一つ以上のテーブルを持つことができる。YugabyteDBではUniverse上に存在するノードにまたがって保持されるテーブルを設定に従って、シャーディングし、レプリケーション、ロードバランシングを行なう。YugabyteDBはノードやディスク、ゾーンなどに発生した障害に自動で対応し、必要であればデータを新規に分散、レプリケーションを行なう。ネームスペースはYSQLではデータベースに対応し、ほかのDBにおけるネームスペースに対応する2。YCQLではキースペースに対応し、Cassandraのキースペースに対応している。サービスコンポーネントUniverseはYugabyteDB Tablet Server(YB-TServer)とYugabyteDB Master Server(YB-Master)の二つで構成されている。YB-MasterとYB-TServerはRaftにより分散されており、高可用性を達成している。YB-Tserverはテーブルを始めとしたユーザーデータの保存、提供を担当する。YB-Masterはシステムのメタデータを管理し、システム全体のテーブルに対するDDLやメンテナンスの実行、ロードバランシングといったオペレーションを管理する。UniverseとClusterUniverseは一つのプライマリクラスタとゼロ個以上のレプリカクラスタによって構成されている。プライマリクラスタプライマリクラスタはRead/Write両方の実行と、プライマリクラスタ内のノード間の同期的なレプリケーションを担当する。リードレプリカクラスタリードレプリカクラスタはRead処理のみを実行する。Write処理は自動的にプライマリクラスタにルーティングされる。リードレプリカクラスタを利用することで、地理的に分散したデータに対する読み取りの遅延を小さくすることができる。データはプライマリクラスタから非同期的にとりこまれる。これはRaftの書き込みには関与しないRaftオブザーバとして機能する。GoogleのCloud Spannerでも同様にUniverseと呼ばれている↩PostgreSQLではSchemaの裏側に存在するデータ構造↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day1]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_1</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs_1</guid>
            <pubDate>Tue, 25 Jul 2023 15:01:52 GMT</pubDate>
            <content:encoded><![CDATA[Day1最近Twitter改めXで「俺はDBのドキュメント端から端まで読んで強くなった」というX's1を複数みかけました。周りのエンジニアに一歩差をつける方法として、フレームワークやミドルウェアやライブラリのドキュメントを最初から最後までちゃんと読む、というのがあって、これはマジでコスパ抜群です。— 徳永広夢 (@tokuhirom) July 21, 2023 確かに私のRedisはこれ。 https://t.co/2y1E01aLGw— maru (@maruloop) July 22, 2023 私のMySQLもこれ。 https://t.co/BxiOjeQVPk— yoku0825 (@yoku0825) July 22, 2023 俺のpostgresqlもこれ。 https://t.co/URRjyXCpGI— そーだい@初代ALF (@soudai1025) July 22, 2023 PostgreSQL系NewSQLで最強になりたいのでYugabyteDBのドキュメントを順番に読んで行きます。ドキュメントはv2.19に対応したものです。手始めにArchitectureの一番先頭にあるDesign goalsから読みはじめます。また画像は同ドキュメントより引用しています。Design goalsYugabyteDBは以下を達成することを目標としている。1. 分散トランザクションを提供しながら強い一貫性を保証する。2. Query APIを再発明せず、既存のクエリ言語への互換を達成する。3. 高いパフォーマンスを保証する。4. 地理的に分散したデプロイを可能にする。5. Cloud Native Databaseとしてデザインする。一貫性分断耐性YugabyteDBはCAPの定理で言えばCPを中心に高い可用性を供えたデータベースネットワーク分断などを起因とするSplit BrainはRaft Group内であたらしいリーダーを選出することで対応している。YugabyteDBではLeader Leaseという障害が発生しても常に一つのリーダが存在することを保証する仕組みを実装している。直列化可能性single-row Linearizable writeをサポートしている。ACIDトランザクションYugabyteDBではSeriarizable、Repetable Read、Read Committed Isolationの三つの分離レベルをサポートしている。YSQL APIではこれら3つの分離レベルをサポートしているが、YCQLではRepeatable Readのみに対応している。Query APIYugabyteDBではYSQLとYCQLという2種類のQuery APIをサポートしている。YSQLYSQLはPostgreSQLに互換したAPIでPostgreSQLのクエリレイヤを再利用している。新しい変更は互換性を崩さない。YSQLは新しいPostgreSQLに互換しつづけることを目標としている。YCQLYCQLはCassandraのクエイ言語から派生した半リレーショナルなクエリ言語で、Webスケールな膨大なwriteに対応してスケールし素早いデータ取得を目標としている。パフォーマンスC++で実装されているため高いパフォーマンスと巨大なHeap(RAM)をCacheとして利用できる。SSDとNVMeに最適化している。高いWriteスループットとクライアントの同時実行性、高いデータ密度、増加し続けるデータへの対応を目標としている。地理的分散Zone、Multi Region、Multi Cloudいずれにも対応している。これに対応するために、ノード障害やトラヒックのルーティングなどに対応できる必要がある。クラウドネイティブアーキテクチャパブリッククラウドやオンプレミスで利用される一般てきなハードウェアで利用可能にする。原子時計のような特別なものに依存しない。Kubernatesに対応している。OSSで提供している。https://twitter.com/SawyerMerritt/status/1683365478582951936↩]]></content:encoded>
        </item>
    </channel>
</rss>