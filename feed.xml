<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sat, 14 Dec 2024 22:34:19 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Japan.R 2024に参加した]]></title>
            <link>https://blog.atusy.net/2024/12/15/japanr-2024/</link>
            <guid>https://blog.atusy.net/2024/12/15/japanr-2024/</guid>
            <pubDate>Sun, 15 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Hadley氏を筆頭に、本番環境や実務でRを使う話が多くて印象深かった回。色々な話を聞けてよかった。2019年以来のオフライン開催で久しくお会いしていなかった方とお話できたこと、光栄にも私に会ってみたかったという方に挨拶頂けたりブログが参考になったと言っていただけたこと、発表に対して直に感想をやりとりできたことなど、現地入りしてよかったなあと思います。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: Database DevOps: CD for Stateful Applicationsのセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/14/database_devops_cd_for_stateful_applications</guid>
            <pubDate>Sat, 14 Dec 2024 18:55:02 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー14日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1Database DevOps: CD for Stateful Applications セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7na/database-devops-cd-for-stateful-applications-stephen-atwell-harnessio-christopher-crow-pure-storage?linkback=grid-fullセッションスライドhttps://static.sched.com/hosted_files/kccncna2024/86/Harness-Portworx%20Kubecon%202024.pdfこの記事内の画像は全てこのスライドより引用しています。セッション動画  www.youtube.comこのレポートでは、KubeCon + CloudNativeCon North America 2024 のセッション「Database DevOps: CD for Stateful Applications」の内容をまとめたもので、DatabaseのDevOpsとステートフルアプリケーションの継続的デリバリについてです。データベースCDの課題と解決策セッションでは、データパイプラインのデータテストをデリバリパイプラインに統合することの重要性が強調されていました。従来、データベースのテストは、BIツールなどを用いたカスタマイズされた方法で行われることが多かったようですが、最も信頼性の高いテスト方法は、新旧バージョンで同じデータに対してテストを実行することだとスピーカーは主張していました。そして、Kubernetesはこのようなテストを大幅に簡略化できるとのことでした。この主張は、データベースの変更がアプリケーション全体に及ぼす影響を正確に把握し、本番環境へのデプロイ前に潜在的な問題を早期に発見するために非常に重要です。Kubernetesによるデータベース運用の進化セッションで紹介されたアーキテクチャの進化は、Kubernetesがデータベース運用にもたらす利点を明確に示していました。初期のアーキテクチャでは、アプリケーション、データベース、インフラストラクチャの変更が個別に管理されていましたが、発展したアーキテクチャでは、これらが統合されたCI/CDパイプラインで管理されています。この統合により、アプリケーション、データベース、インフラストラクチャの変更をE2Eでテストできるようになり、本番環境へのデプロイリスクを大幅に軽減できます。このアーキテクチャの進化は、マイクロサービスアーキテクチャやクラウドネイティブ開発との親和性が高いと言えます。マイクロサービスでは、個々のサービスが独立してデプロイされるため、データベースの変更が他のサービスに及ぼす影響を正確に把握することが重要です。Kubernetesはこのような複雑な依存関係を管理し、安全なデプロイを実現するための強力なプラットフォームを提供します。デモのオーバービューセッションでは、具体的なスキーママイグレーションのシナリオを例に、ダウンタイムゼロでのデータベース変更を実現する方法が紹介されていました。WarehouseテーブルのLocationカラムの衝突問題を解決するために、CityとStateカラムを追加し、Locationカラムとの同期をトリガーで実現する方法は、実務で非常に役立つアプローチです。この手法は、データベースの変更によるアプリケーションへの影響を最小限に抑え、ユーザー体験を損なうことなくシステムを進化させることを可能にします。デモで利用されるCDパイプラインデモで適用されるデータベースへの変更個人的にはこのようなユースケースのテストシナリオは複雑になることが多いと考えていたため、自動化を行うには相当のカスタマイズが必要になると思っていたので、この後のデモの手軽さには非常に驚かされました。デモのハイライトとHarnessの活用youtu.beこのセッションはデモが全体のほとんどを閉めています。デモ開始時点のリンクがブログ記事の中盤にあるので、デモ部分だけでもご覧になることを強く推奨します。セッションのデモでは、Harnessというツールが使用され、変更プロセスとロールバック手順が分かりやすく可視化されていました。Harnessは、GitLab CI/CDやGitHub ActionsのようなUIを提供し、各ステップの成功/失敗を容易に確認できる点が優れていると感じました。特に、ArgoCDとの連携によるデータベースとアプリケーションの協調動作は、複雑なデプロイプロセスを簡素化する上で非常に効果的です。デモで紹介された、望ましい状態になっていないことを確認し、変更を加えるプロセスは、実践的な知見を提供していました。また、データベースの変更セットの一部として事前にロールバック手順を定義しておくことは、本番環境での予期せぬ問題発生時に迅速な対応を可能にするベストプラクティスと言えるでしょう。LiquibaseやFlywayなどのツールはこのような機能を提供しており、データベースDevOpsの実践において不可欠です。HarnessではデータベースのDevOpsをアプリケーション、インフラストラクチャー込みで実現しており、非常に理想的なツールのように見えました。一方でこのセッションのスピーカーのひとりはHarnes.ioのエンジニアであるため、ポジショントークや見せたい部分しか見せていないことが十分考えられるので全てを鵜呑みにするのは危険です。それを差し引いても興味深いデモだったので、セッションで紹介された技術スタックを検証してみたいと思っています。まとめこのセッションは、Kubernetesとツールを活用することで、データベースの変更を安全かつ効率的に行う方法を示していました。E2Eテスト、ダウンタイムゼロのスキーママイグレーション、そしてロールバック手順の自動化は、データベースDevOpsを実現するための重要な要素です。これらの手法を適切に組み合わせることで、開発速度を向上させながら、システムの安定性と信頼性を維持することが可能になります。しかし、ここで紹介された手法は全ての状況に適用できるわけではありません。例えば、大規模なデータベースや複雑なトランザクション処理を行うシステムでは、ダウンタイムゼロのマイグレーションが困難な場合があります。そのようなケースでは、段階的なロールアウトやカナリアリリースなどの手法を検討する必要があります. また、ツールの導入や運用にはコストがかかるため、組織の規模やリソースに合わせて適切なツールを選択することが重要です。今後のデータベース運用においては、自動化と可観測性をさらに強化し、自己修復機能を備えた自律的なデータベース運用を目指していくことが重要だと考えます。Kubernetesやクラウドネイティブ技術は、この目標を実現するための基盤となるでしょう。またこのセッションを見るまで、個人的にDatabase on KubernetesはKubernetesを利用している組織でマネージドデータベースのコストを安くしたい場合や、データを自分たちのコントロールできる場所におきたい時に利用する選択肢と思っていました。しかしデータベースをKubenetesにデプロイすることでアプリケーションと密接に結合したテストを簡単に行えることがわかり、データベースの運用コストさえ許容できれば、他のメリットがなくてもデータベースをKubernetesで運用するのは十分ありなのではないかと意見が変わりました。今後は単なるデータベースのホスティング環境としてのKubernetes以外の部分にも注目していきたいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[初回実行が遅ければ遅延初期化でやればいいじゃない - RustのTUIアプリケーション改善]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/14/121545</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/14/121545</guid>
            <pubDate>Sat, 14 Dec 2024 03:15:45 GMT</pubDate>
            <content:encoded><![CDATA[この記事はRust Advent Calendar 2024 シリーズ3の15日目の記事です。はじめにみなさん、アプリケーションの初回実行の遅さに悩んでいませんか？「初回の検索が遅い...」「起動に時間がかかる...」「ユーザーから苦情が...」といった問題は、多くの開発者が直面する共通の課題です。実は、こういった問題の多くは初期化のタイミングを工夫することで効果的に解決できます。特にRustの場合、遅延初期化の仕組みを積極的に活用することで、パフォーマンスとユーザー体験を大きく改善することが可能です。初期化処理を適切なタイミングで実行することで、アプリケーションの応答性を保ちながら、必要なデータの準備を効率的に行うことができるのです。今回は郵便番号検索アプリケーション（jposta）を具体例として、初期化の最適化手法について詳しく見ていきましょう。この実践的なケーススタディを通じて、効果的な初期化戦略の実装方法を学んでいきます。github.com遅延初期化とは遅延初期化は、「必要になるまで初期化を待つ」という考え方を基本とする重要な最適化テクニックです。アプリケーションの起動時に全てのデータを一度に読み込むのではなく、そのデータが実際に使用されるタイミングまで読み込みを延期することで、システムの効率性を高めることができます。ja.wikipedia.org特に重要な利点として、アプリケーションの起動時間の大幅な短縮が挙げられます。全ての機能を一度に初期化する代わりに、必要な機能から順次初期化することで、ユーザーは最小限の待ち時間でアプリケーションの使用を開始できます。また、大きな設定ファイルの読み込みやデータベース接続の確立、重いライブラリの初期化、キャッシュの構築といったリソース集約的な操作を必要なタイミングまで延期することで、メモリやCPUなどの限られたリソースを効率的に活用することが可能となります。さらに、遅延初期化は複雑な依存関係を持つシステムにおいても効果的です。複数のコンポーネントが互いに依存し合う状況では、初期化の順序が問題となることがありますが、各コンポーネントを必要に応じて初期化することで、この課題を自然に解決できます。加えて、テスト容易性の向上も重要な利点です。必要なコンポーネントだけを初期化できることで、単体テストやモジュールテストが容易になり、テストの実行速度も向上します。また、エラーハンドリングの改善にも貢献します。初期化時のエラーを早期に検出できるだけでなく、実際に使用されないコンポーネントの初期化エラーを回避することができます。運用環境での柔軟性も高まり、システムの一部機能が利用できない状況でも、他の機能を正常に動作させることが可能になります。このように、遅延初期化は現代のソフトウェア開発において、パフォーマンス、保守性、信頼性の面で多くのメリットをもたらす重要な設計パターンとなっています。blog1.mammb.comRustにおける遅延初期化の進化Rustにおける遅延初期化の歴史は、2014年に登場したlazy_staticから始まり、これはマクロベースの実装でスレッドセーフ性に課題があり、型の制約も厳しいものでした。github.comその後、2020年にはonce_cellが登場し、マクロを必要としないシンプルなAPIとスレッドセーフな実装、より柔軟な型のサポートを提供することで、遅延初期化の実装が大きく改善されました。github.comそして2024年になると、LazyCell/LazyLockが標準ライブラリに統合され、さらなる最適化と依存関係の削減が実現され、Rustの遅延初期化機能は新たな段階へと進化を遂げています。blog.rust-lang.orgこのように、Rustの遅延初期化は時代とともに進化し、より使いやすく堅牢な実装へと発展してきました。techblog.paild.co.jp問題の理解：なぜ初期処理が必要か？まず、jpostcode_rsライブラリの実装を見てみましょう：use std::sync::LazyLock;static ADDRESS_MAP: LazyLock<HashMap<String, Vec<Address>>> = LazyLock::new(|| {    let data = include_str!(concat!(env!("OUT_DIR"), "/address_data.json"));    let raw_map: HashMap<String, Value> =        serde_json::from_str(data).expect("Failed to parse raw data");    // ...});このコードの重要なポイントは、LazyLockによる遅延初期化を採用することで、JSONデータの初回アクセス時までパースを延期し、必要なタイミングでメモリへの展開を行う設計となっているということです。このコードから分かるように、初回アクセス時のパフォーマンス低下は遅延初期化の仕組みに起因しています。そこで私たちは、この遅延初期化の特性を活用し、ユーザーが実際にアクセスする前に初期化を完了させる戦略を考案しました。解決策：遅延初期化を活用した初期処理従来の初期化パターンfn new() -> App {    let (search_tx, search_rx) = mpsc::channel::<String>();    let (result_tx, result_rx) = mpsc::channel();    thread::spawn(move || {        while let Ok(query) = search_rx.recv() {            // 初回検索時にデータ初期化が発生 = 遅い！        }    });    App { /* ... */ }}改善後：標準ライブラリの機能を活用use std::sync::{LazyLock, Mutex};// グローバルな初期化フラグstatic INITIALIZED: LazyLock<Mutex<bool>> = LazyLock::new(|| Mutex::new(false));impl App {    fn new() -> App {        let (search_tx, search_rx) = mpsc::channel::<String>();        let (result_tx, result_rx) = mpsc::channel();        thread::spawn(move || {            // バックグラウンドで初期化            {                let mut init = INITIALIZED.lock().unwrap();                if !*init {                    // 軽いクエリで事前初期化をトリガー                    let _ = lookup_addresses("100");                    let _ = search_by_address("東京");                    *init = true;                }            }            // 以降の検索は初期化済みのデータを使用            let mut cache: HashMap<String, Vec<String>> = HashMap::new();            while let Ok(query) = search_rx.recv() {                // 通常の検索処理            }        });        App { /* ... */ }    }}この手法の効果とメリットとデメリットこの手法の中核となる標準ライブラリのLazyLockやMutexなどの基本機能は、追加のライブラリを必要としない堅牢な実装を可能にします。既存のRustプログラマーにとって馴染みのある仕組みを使用しているため、コードの理解や保守が容易であり、依存関係も最小限に抑えることができます。また、これらの機能は既にRustチームによって最適化され、徹底的にテストされているため、高いパフォーマンスと信頼性が保証されています。システムの保守性と運用面では、初期化ロジックの集中管理により、状態管理が大幅に簡素化されます。INITIALIZEDフラグを用いた明示的な制御により、初期化状態の追跡が容易になり、デバッグ性も向上します。さらに、初期化処理をバックグラウンドスレッドで実行することで、メインスレッドのブロッキングを避け、UIの即時表示とレスポンシブな操作感を実現できます。スケーラビリティの観点からは、新機能の追加や初期化順序の制御が柔軟に行えるため、システムの成長に合わせた拡張が容易です。Mutexによる適切な同期制御により、複数スレッドからの安全なアクセスが保証され、並行処理との親和性も高くなっています。また、必要なデータの予測的な先読みとメモリ使用の最適化により、効率的なリソース管理が可能です。初期化処理のモジュール化により、新しい機能の追加時も既存コードへの影響を最小限に抑えられ、キャッシュの効果的な活用によって、大規模なアプリケーションでも高いパフォーマンスを維持できます。一方で、この手法にはいくつかの重要な課題も存在します。まず、メモリ使用量の増加が挙げられます。事前初期化アプローチでは、実際には使用されない可能性のあるデータ構造も含めて、すべてのデータをメモリに展開する必要があります。これは特にメモリリソースが限られている環境において深刻な問題となる可能性があり、システムの全体的なパフォーマンスに影響を与える可能性があります。また、起動時のリソース消費も重要な課題です。バックグラウンドでの初期化処理は、システムの起動時により多くのCPUとメモリリソースを必要とします。特にモバイルデバイスやバッテリー駆動の機器では、この追加のリソース消費が電力効率に悪影響を及ぼす可能性があります。ユーザーの使用パターンによっては、この初期化コストが実際の便益を上回ってしまう場合もあります。さらに、実装の複雑性が増加することも大きな課題です。遅延初期化と事前初期化を組み合わせることで、コードベースの複雑性が著しく増加します。特に初期化の順序や依存関係の管理が複雑になり、開発者がシステムの動作を理解し、デバッグすることが困難になる可能性があります。この複雑性は、新しい機能の追加や既存機能の修正時にも影響を及ぼし、開発効率の低下につながる可能性があります。テストの複雑化も見過ごせない問題です。バックグラウンド初期化を含むコードのテストでは、タイミングや状態管理の観点から、適切なテストケースの作成と実行が困難になります。特に並行処理に関連するバグの再現や検証が複雑になり、品質保証のプロセスに追加の負担がかかる可能性があります。最後に、エラーハンドリングの複雑化も重要な課題です。バックグラウンドでの初期化中に発生したエラーの適切な処理と、それに対するユーザーへの適切なフィードバック提供が技術的な課題となります。エラーが発生した場合の回復処理や、部分的な機能提供の実装も複雑になり、システムの信頼性と保守性に影響を与える可能性があります。このように、標準ライブラリの機能を活用した実装は多くの利点をもたらす一方で、システムの要件や制約に応じて、これらのデメリットを慎重に検討する必要があります。実装時には、これらのトレードオフを考慮しながら、適切な設計判断を行うことが重要となります。実装時の注意点デッドロックの防止{  // スコープによるロックの制限    let mut init = INITIALIZED.lock().unwrap();    if !*init {        *init = true;    }}  // ロックの自動解放初期化の冪等性if !*init {    // 複数回実行されても安全な実装に    let _ = lookup_addresses("100");    *init = true;}まとめ私たちは「初回アクセスが遅いなら、事前に必要な処理を済ませておこう」というシンプルながら実用的なアプローチについて、Rustの標準ライブラリの遅延初期化機構を通じて検討してきました。この手法には、メモリ使用量の増加やコードの複雑化といった課題も存在しますが、適切に実装することで大きな効果が期待できます。標準ライブラリの機能を活用し、依存関係を最小限に抑えながら、スレッドセーフな実装を実現することで、効率的かつ安全な初期化処理が可能となります。このように、遅延初期化と事前初期化を組み合わせたアプローチは、システムの特性や要件に応じて検討すべき重要な最適化パターンの一つと言えるでしょう。参考文献The Rust Standard Library - std::sync::LazyLockThe Rust Standard Library - std::cell::LazyCellRust Performance Book]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes のセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/13/building_resilienc_effective_backup_and_disaster_recovery_for_database_on_lubernetes</guid>
            <pubDate>Fri, 13 Dec 2024 08:57:05 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー13日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconawww.youtube.comKubeCon + CloudNativeCon North America 2024 のセッション "Building Resilience: Effective Backup and Disaster Recovery for Vector Databases on Kubernetes" は、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の必要性を強調した示唆に富む内容でした。マーケティング的な観点や、聴衆の興味を引くためといった理由からかタイトルでベクトルデータベースとなっていますが、バックアップの部分ではあらゆるデータベースやステートフルワークロードに応用ができる内容でした。AI and Kubernetesセッションは、AI がアプリケーションにもたらす変革的な影響についての概説から始まりました。リソース需要予測による動的スケーリング、異常検知によるセキュリティ向上、UX の改善、そして事前の障害予測による可用性向上など、AI はアプリケーションのあらゆる側面を最適化する可能性を秘めています。そして、これらのメリットを実現する上で、Kubernetes が最適なプラットフォームとして位置づけられています。迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロード管理の効率化、そして効率的なバックアップとリカバリといった Kubernetes の特徴は、AI ワークロードの運用に不可欠な要素です。特に、データベースを Kubernetes 上で運用する組織が増加しているという Data on Kubernetes のレポートの言及は、AI/ML ワークロードとデータベース運用の密接な関係性を示唆しており、データベースエンジニアとして注目すべき点でした。Kubernetes がステートフルなアプリケーションの運用基盤として成熟しつつあることを改めて認識させられました。Kubernetes上でAIアプリケーションをデプロイする理由セッションでは、Kubernetes上でAIアプリケーションをデプロイする理由として、迅速なデプロイ、高可用性とスケーラビリティ、可搬性と柔軟性、分散ワークロードの管理の効率化、効率的なバックアップとリカバリ、そしてエコシステムとコミュニティの発展が挙げられていました。これらの利点は、クラウドネイティブな開発と運用を目指す上で非常に重要です。特に、マイクロサービスアーキテクチャを採用する際に、Kubernetes はサービスのデプロイと管理を簡素化し、スケーラビリティと可用性を向上させる上で強力なツールとなります。さらに、ベクトルデータベースのようなステートフルなサービスを Kubernetes 上で運用することで、データの永続性と可用性を確保し、AI アプリケーションの信頼性を向上させることができます。Vector Databases and RAGセッションの中核を成すのが、ベクトルデータベースと RAG (Retrieval Augmented Generation) の解説です。非構造化データの増加に伴い、従来のデータベースでは対応が難しくなってきた画像、テキスト、音声といったデータの効率的な処理が求められています。ベクトルデータベースは、これらの非構造化データをベクトル表現に変換し、類似度検索によって関連性の高い情報を高速に取得することを可能にします。Embedding Model を用いたベクトル化によって、意味的な検索が可能になり、AI アプリケーションの精度と効率性が向上する点が強調されていました。特に、生成 AI アプリケーションにおけるハルシネーション軽減とコンテキスト付与におけるベクトルデータベースの役割は重要です。RAG は、ベクトルデータベースを用いて関連情報を取得し、生成 AI の出力に信頼性を与える手法として紹介されており、今後の AI アプリケーション開発において不可欠な要素となるでしょう。ベクトルデータベースのユースケースセッションでは、ベクトルデータベースのユースケースとして、検索エンジン、画像検索、推薦アルゴリズム、異常検知、そしてチャットボットなどの生成 AI アプリケーションが挙げられていました。これらのユースケースは、現代のアプリケーション開発において非常に重要であり、ベクトルデータベースの適用範囲の広さを示しています。特に、マイクロサービスアーキテクチャにおいて、ベクトルデータベースを独立したサービスとして提供することで、様々なサービスから容易にアクセスできるようになり、システム全体の柔軟性と拡張性を向上させることができます。また、DevOps/SRE の実践においては、ベクトルデータベースの監視と運用を自動化することで、システムの信頼性と可用性を向上させることができます。Data Protectionデータ保護は、Kubernetes 上で運用されるベクトルデータベースにとって不可欠な要素です。データの整合性とセキュリティ、災害復旧、コストと時間の効率化、バージョンコントロール、そしてコンプライアンス規制への準拠など、データ保護は多岐にわたるメリットを提供します。セッションでは、Kubernetes 上でのベクトルデータベースのデータ保護方法として、ストレージスナップショット、データサービスを利用したストレージスナップショット、データサービスレベルのスナップショット、そしてこれらの組み合わせが紹介されました。PVC を利用した永続化データの保護は、Kubernetes ネイティブなデータ保護戦略を構築する上で重要なポイントです。Kanister のようなデータ保護ワークフロー管理ツールは、バックアップとリストアの手順を抽象化し、自動化することで、運用効率を大幅に向上させることができます。Kanister の Blueprint、Profile、ActionSet といった CRD を活用することで、柔軟なデータ保護ワークフローを定義し、Kubernetes の宣言的な運用を実現できます。Kanisterの動作Kanister の動作は、ActionSet が Controller に動作を開始するようにトリガーし、Controller が Blueprint を参照して定義されたオペレーションに従ってベクトルデータベースからバックアップを取得し、オブジェクトストレージに保存するという流れで実行されます。動作完了後、Controller は ActionSet に完了を伝え、ActionSet がユーザーに完了を通知します。この自動化されたワークフローは、データベースエンジニアの運用負荷を軽減し、ヒューマンエラーのリスクを最小限に抑える上で非常に有効です。また、バックアップとリストアのプロセスをコード化することで、再現性と信頼性を向上させることができます。Demoデモでは、書籍推薦チャットボット BookNest を例に、PostgreSQL と PGVector を利用したベクトルデータベースのバックアップとリストアのワークフローが紹介されました。提供された図とデモ動画は、Kanister を用いたデータ保護の実践的な方法を理解する上で非常に役立ちました。具体的な構成例を示すことで、視聴者は自身の環境に合わせたデータ保護戦略を検討する際の参考にすることができます。また、デモを通じて Kanister の操作方法やワークフローの定義方法を視覚的に理解することができ、実践的な知識を深めることができます。Kanister の Blueprint は Kubernetes の manifest 内で ShellScript を書くようなイメージでかけるため、すでに Kubernetesを利用している組織であれば利用に大きなハードルは少なそうだと感じました。Operator 化されたデータベースでは大きなメリットはないかもしれないですが、そうでないデータベースのバックアップや、Operator を使っていても複数の種類がある場合オペレーションの使用ツールの共通化という面で十分メリットがあるでしょう。Call to Actionセッションの締めくくりとして、AI アプリケーションとベクトルデータベースの重要性、そしてデータ保護の必要性が改めて強調されました。データ保護を Day 0 Operation と位置づけるというメッセージは、システム設計の初期段階からデータ保護を考慮することの重要性を示唆しています。システムの保守性、スケーラビリティ、セキュリティを確保する上で、データ保護は不可欠な要素であり、アプリケーション開発ライフサイクル全体を通じて考慮する必要があります。まとめこのセッションは、AI アプリケーションにおけるベクトルデータベースの重要性と、Kubernetes 上での堅牢なデータ保護戦略の構築方法について、具体的な例を交えながら分かりやすく解説していました。特に、Kanister のようなデータ保護ツールを活用することで、複雑なバックアップとリカバリのワークフローを簡素化し、自動化できる点が印象的でした。データベースを Kubernetes 上で運用する際には、データ保護を Day 0 Operation として捉え、Kanister のようなツールを活用することで、システムの信頼性と可用性を向上させることができます. セッションで提示された情報は、今後のデータベース運用戦略を検討する上で非常に貴重な示唆を与えてくれました。このセッションで扱われなかった点として、ベクトルデータベースの選択基準やパフォーマンスチューニング、そして異なるベクトルデータベースにおけるデータ保護戦略の差異などが挙げられます。今後のセッションでは、これらの点についても掘り下げて議論されることを期待します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ｻｯとかざして即起動! 推しグッズを神曲再生アイテムに(*°∀°)]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/9db9d10902ec03</guid>
            <pubDate>Thu, 12 Dec 2024 15:00:01 GMT</pubDate>
            <content:encoded><![CDATA[※3-shake Advent Calendar 2024の13日目のエントリー記事です。本日、12月13日は金曜日。世の中では「ジェイソンの日」なんて言われています。とはいえ、生まれてこの方ジェイソンの映画を見ることがなかったためこの手の話についてはかなり縁遠い気がしていします。(JSONの方先に連想しちゃいますし)むしろ「華金だーー＼(^o^)／」くらいしか考えていません。それしかありません。そんな社会人です。さて、今年もやってまいりましたアドベントカレンダー。2024年も引き続き参加させていただく運びとなりました。テーマは前回同様「技術・非技術関係なし!自由!」ということ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Japan.R 2024で地域コミュニティのOsaka.Rについて発表した]]></title>
            <link>https://blog.atusy.net/2024/12/12/japanr-logging/</link>
            <guid>https://blog.atusy.net/2024/12/12/japanr-logging/</guid>
            <pubDate>Thu, 12 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[前の発表で力尽きてて、何も考えずに楽しくお話しちゃった回。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust 再学習戦記]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/12/013950</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/12/013950</guid>
            <pubDate>Wed, 11 Dec 2024 16:39:50 GMT</pubDate>
            <content:encoded><![CDATA[プログラミング言語の再入門とは、未知の大地への探求というよりも、私たちが知っているはずの領域を新たな視点で見つめ直す営みです。それは初めての出会いのような激しい高揚感とは異なり、むしろ静かな再発見の過程といえるでしょう。この記事は3-shake Advent Calendar 2024 シリーズ2の12日目の記事です。はじめに2017年、私の心にRustという言語が静かに灯りを点しました。その光は、システムプログラミングの深い理解への憧れを呼び覚まし、私を導いていきました。情熱に突き動かされるように、DevOpsツールの創造から始まり、パケット解析の探究へ、そしてWebフレームワークの実装へと、私の歩みは広がっていきました。高速な実行速度と安全性という輝きに心を奪われながらも、未熟なエコシステムという現実が私たちの前に立ちはだかりました。パッケージの追従に心を砕き、破壊的な変更に耐え、そして孤独なメンテナンスの重みを感じながら、私は一時の別れを告げることを選びました。しかし2024年を迎えた今、私の目の前で世界は確かな変化を見せています。Rustの開発者満足度は非常に高い一方で、実務での採用はまだ限定的です。これは、現時点ではRustを業務で使用している開発者が比較的少なく、主に技術的な興味や言語の特徴に惹かれて自発的に選択している人が多いためかもしれません。まぁ何はともあれ、私もその魅力に惹かれた1人のエンジニア。最新のRustを探究すべく、再入門することにしました。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazonなぜ今、Rustなのか技術的な成熟Rustのエコシステムは大きく進化し、この数年で安定性が著しく向上しています。パッケージの破壊的変更は目に見えて減少し、Zero To Production In Rustをはじめとした実践的な運用ガイドの登場により、本番環境での運用ノウハウが充実してきました。さらに、日本語での技術記事や登壇資料も増え、日本語でのコミュニケーションも充実してきています。主要パッケージの品質向上と運用実績の蓄積により、開発環境全体の信頼性は大幅に高まっています。また、言語サーバーの進化やツールチェーンの充実により、開発効率も飛躍的に向上しました。実践的な機能面においても、目覚ましい進歩が見られます。エラーハンドリングの改善やWebAssemblyサポートの強化により、クロスプラットフォーム対応も一層充実しました。また、コンパイラの最適化改善による実行時オーバーヘッドの最小化や、所有権システムによるメモリ安全性の保証など、Rustの基本的な強みはさらに磨きがかかっています。特に、非同期プログラミングのエコシステムは大きく成熟し、堅牢な基盤が確立されています。また、2025年には2024 Rdition がリリースされる。SREとしての展望今後は、Rustで構築されたマイクロサービスや高性能なバックエンドサービスのためのインフラ構築や運用の機会が増えていくことが予想されます。特に、コンテナ環境でのデプロイメントやクラウドネイティブな環境でのインフラ構築において、Rustアプリケーションの特性を最大限に活かすための設計が求められるでしょう。例えば、Rustの低メモリ消費という特徴を活かしたコンテナリソースの最適化や、高速な実行速度を考慮したオートスケーリングの設計など、アプリケーションの特性に合わせたインフラストラクチャの構築が重要になってきます。また、モニタリングやログ収集といった運用基盤においても、Rustアプリケーションに適した構成を検討していく必要があるでしょう。SREとしてRustのプロダクションデプロイメントに関わる場合は、Zero To Production In Rustを参照することをお勧めします。この書籍では、Rustアプリケーションの本番環境への展開に関する実践的なガイドラインが提供されています。www.zero2prod.comRustの再入門のための学習コンテンツ再入門にあたり、Rustの最新のプラクティスやエコシステムの変化をキャッチアップするため、いくつかの資料に取り組みました。特に有用だった書籍を紹介していきます。書籍の良さは情報を俯瞰できる点にあると考えています。わからない点があればLLMに質問することができますので⋯。なお、この記事はRustの基礎知識がある方向けの再入門という観点で資料を選定しているため、完全な初学者向けの内容は含んでいません。参照したドキュメントや内容の詳細については、Xで共有しているドキュメントをご確認ください。プログラミングRust 第2版 を読んで可能な限り手を動かす会を実施します。https://t.co/rmUpbPtK9O— nwiizo (@nwiizo) 2024年11月21日   読んだ本についての定義についてはこちらを参考にしてほしいです。読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazonまた、yuk1tydさんのドキュメントは2021年時点の情報ですが、現在も十分に有用な内容となっているためおすすめです。blog-dry.com書籍Programming Rust, 2nd EditionO'Reilly Mediaから出版されている本書は、Rustの基本的な概念から高度な機能まで包括的に解説する定番の教科書です。特に所有権やライフタイム、並行処理といったRustの特徴的な機能について、実践的な例を交えながら詳細に説明されています。本当に再入門してから何度も読んでいる。生成AIに聞くか本を読むか実際に書いていくかの三択である。Programming Rust: Fast, Safe Systems Development作者:Blandy, Jim,Orendorff, Jason,Tindall, Leonora F SO'Reilly MediaAmazon2021年の第2版では、Rust 2021 Editionに対応し、非同期プログラミングやトレイト、ジェネリクス、マクロなど、モダンなRustの重要な機能が大幅に加筆されました。特に、パフォーマンスとメモリ安全性を両立させるためのRustの機能を、システムプログラマの視点から解説している点が特徴です。再三にはなるが2024 Rdition がリリースされる。それに合わせて再び書籍が出されるのが楽しみである。3年毎にリリースがあるのは早すぎず遅すぎずちょうど嬉しい。これまでと違う学び方をしたら挫折せずにRustを学べた話 / Programming Rust techramen24conf LTでも紹介されているように、本書は体系的な学習を可能にする構成と、実践的な例示の豊富さが特徴です。特に、Rustの概念モデルを丁寧に解説している点は、言語仕様の深い理解につながります。再入門時の体系的な知識のアップデートに最適な一冊といえるでしょう。 speakerdeck.comまた、日本語の書籍も出ているので感謝すべきである。プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonバックエンドエンジニアを目指す人のためのRust翔泳社から出版されているこの入門書は、実践的なプロジェクトを通じてRustを学ぶアプローチを採用しています。計算クイズからTODOアプリまで、段階的に難易度を上げながら、バックエンドエンジニアに必要な技術要素をカバーしている点が特徴です。バックエンドエンジニアを目指す人のためのRust作者:安東 一慈,大西 諒,徳永 裕介,中村 謙弘,山中 雄大翔泳社Amazon本書の優れている点は、各プロジェクトを通じて特定のRustの概念を深く掘り下げる構成にあります。例えば、ポーカーゲームの実装を通じてデータ構造の理解を深め、家計簿プログラムでファイルI/Oを学び、画像処理ツールで並列処理を実践的に理解できます。また、Cargoによるパッケージ管理、ユニットテスト、リンター、フォーマッターといった実務で重要となる開発ツールの活用方法も丁寧に解説されています。特筆すべきは、エラーハンドリングやOption/Result型の扱いなど、Rustの特徴的な機能を実際のユースケースに即して学べる点です。さらに、Webアプリケーション開発からデプロイメントまでをカバーしており、現代のバックエンド開発の実践的なスキルが身につく構成となっています。ただし、この本はプログラミング言語としてのRustの入門書として優れているものの、プログラミング未経験者にはRust自体の学習難度が高いため、他の言語での開発経験がある方に特にお勧めします。体系的な構成と実践的なプロジェクトを通じた学習アプローチは、技術書の模範となる一冊といえるでしょう。www.estie.jpコミュニティと情報源Rustの再入門において、コミュニティへの参加は技術的な成長と最新動向の把握に重要な役割を果たしています。日本のRustコミュニティは活発な技術交流が行われています。Rust.TokyoRust.Tokyoは日本最大のRustカンファレンスで、年に一度開催される重要なイベントです。私は再入門直後にこのカンファレンスに参加することになり、登壇資料の準備に追われる事態となりましたが、結果的に学習のよい動機付けとなりました。カンファレンスでは、企業での採用事例や実装のベストプラクティス、パフォーマンスチューニングの知見など、実践的な内容が数多く共有されます。また、国内外のRustコミュニティのメンバーとの交流を通じて、最新のトレンドやツール、開発手法について直接学ぶ機会も得られます。Rust-jp ZulipRust-jp Zulipは、日本のRustコミュニティの中心的なコミュニケーション基盤です。SlackやDiscordと異なり、トピックベースの会話構造を持つZulipを採用することで、過去の議論や質問への回答を効率的に検索できる点が特徴です。このプラットフォームでは、初心者向けの基本的な質問から、高度な実装の相談まで、幅広いディスカッションが日本語で行われています。特に、実務での問題解決やコードレビュー、アーキテクチャの相談など、実践的な議論が活発に行われており、再入門者にとって貴重な学習リソースとなっています。学びの記録2017年の実践パケット解析の実装Webフレームワーク検証Rust関連記事一覧2024 年やったことRustでterraform plan/apply のターゲット指定を簡単にするツールを作ってみた - tfocusの仕組みと使い方退屈なことはRust Build Scripts にやらせようRustで郵便番号・住所検索TUIツールを開発した - jpostaRustによる郵便番号検索API (yubin_api) の技術解説tfocusexpjpostcode_rsおわりに2017年の経験は、今となっては貴重な財産です。言語に入門し、一度は挫折を経験しながらもプロダクトへの導入に挑戦したこと、そして結果的に撤退を選択せざるを得なかったことは、私にとって大きな学びとなりました。この貴重な経験と適切な判断へと導いてくれた当時のメンターには感謝しています。パッケージ管理の困難さ、破壊的変更への対応、そして継続的な開発の課題 - これらの経験があったからこそ、現在のRustエコシステムの進化をより深く理解できています。Rustは単なるプログラミング言語の進化を超えて、エコシステム全体として大きく成長しました。特に、かつて私が直面した課題の多くが、コミュニティの成熟とツールチェーンの進化によって解決されつつあります。実践的なユースケースの蓄積は、次世代のシステム開発における新たな可能性を示唆しています。Rust 2024エディションのリリースを控え、言語とエコシステムはさらなる進化を遂げようとしています。SREとしても、このような発展を続けるRustの動向を把握し、実践的な知識を蓄積していくことは、将来への重要な投資になると確信しています。この記事を読んでいる方々も、ぜひこの成長と進化の過程に参加してみませんか？初めての方も、かつて離れた方も、今こそRustと再会するベストなタイミングかもしれません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GolangからPagerdutyのインシデントを発砲する]]></title>
            <link>https://zenn.dev/tayusa/articles/9091399d6a9018</link>
            <guid>https://zenn.dev/tayusa/articles/9091399d6a9018</guid>
            <pubDate>Wed, 11 Dec 2024 13:30:34 GMT</pubDate>
            <content:encoded><![CDATA[目的Golangで作成したアプリケーションからPagerdutyの任意のインシデントを発砲する Event API v2https://developer.pagerduty.com/docs/3d063fd4814a6-events-api-v2-overview高信頼性、高可用性の非同期APIでシステムからマシンイベントを取り込みます。このAPIに送られたイベントは最終的にPagerDutyサービスにルーティングされ処理されます Event Types Alert監視システムの問題。 既存のアラートを確認または解決するためにイベントを送信することができる...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud monitoringのアラートをGitHub Issueに通知する]]></title>
            <link>https://kechigon.hatenablog.com/entry/2024/12/11/182649</link>
            <guid>https://kechigon.hatenablog.com/entry/2024/12/11/182649</guid>
            <pubDate>Wed, 11 Dec 2024 09:26:49 GMT</pubDate>
            <content:encoded><![CDATA[タイトルの通り、Google Cloud monitoringのアラートをGitHub Issueに通知するシステムの構築方法を紹介します。terrafromを使って作成します。コードはGitHubリポジトリにまとまっています。github.comこのコードをapplyすることで、Webサービス(EasyBuggy)、監視、アラートをIssueに持っていくパイプラインがデプロイされます。システム図このような構成をとっています。main.tf早速コードを紹介していきます。このファイルでは、EasyBuggyという脆弱なWebサービスをGCEにデプロイします。terraform {  required_providers {    google = {        source = "hashicorp/google"        version = "5.39.0"    }  }}provider "google" {  credentials = var.credential_file  project     = var.project  region      = var.region}resource "google_compute_instance" "easybuggy" {  name         = "easybuggy-instance"  machine_type = "n1-standard-1"  zone         = var.zone  boot_disk {    initialize_params {      image = "debian-cloud/debian-11"    }  }  network_interface {    network = "default"        access_config {}  }  metadata = {    "enable-osconfig" = "true"  }     metadata_startup_script = <<EOF#!/bin/bashsudo apt-get updatefor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; donesudo apt-get install -y ca-certificates curl git sudo install -m 0755 -d /etc/apt/keyringssudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.ascsudo chmod a+r /etc/apt/keyrings/docker.ascecho \  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \sudo tee /etc/apt/sources.list.d/docker.list > /dev/nullsudo apt-get updatesudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-pluginsudo git clone https://github.com/k-tamura/easybuggy.gitcd easybuggysudo docker build . -t easybuggy:local sudo docker run -p 8080:8080 easybuggy:local EOF}resource "google_compute_firewall" "allow-home-ip" {  name    = "allow-home-ip"  network = "default"   allow {    protocol = "tcp"    ports    = ["8080"]  }  source_ranges = [var.my_ip]}output "instance_ip" {  value = google_compute_instance.easybuggy.network_interface[0].access_config[0].nat_ip}monitoring.tfこちらのファイルでは監視、アラートをIssueに持っていくパイプラインをデプロイします。main.tfでデプロイしたインスタンスのCPU使用率が80%を超えるとアラートが発生します。resource "google_pubsub_topic" "alerts_topic" {  name = "alerts-topic"}resource "google_pubsub_subscription" "alerts_subscription" {  name  = "alerts-subscription"  topic = google_pubsub_topic.alerts_topic.name}resource "google_monitoring_notification_channel" "pubsub_channel" {  display_name = "Pub/Sub to Cloud Function"  type         = "pubsub"  labels = {    "topic" = google_pubsub_topic.alerts_topic.id  }}resource "google_pubsub_topic_iam_binding" "alerts_topic_publisher" {  topic = google_pubsub_topic.alerts_topic.name  role    = "roles/pubsub.publisher"  members = [    "serviceAccount:service-${var.project_id}@gcp-sa-monitoring-notification.iam.gserviceaccount.com"  ]}resource "google_storage_bucket" "easybuggy_monitoring_function_bucket" {  name          = "easybubby_monitoring-functions-bucket"  location      = "ASIA-NORTHEAST1"  force_destroy = true}resource "google_storage_bucket_object" "function_source_object" {  name   = "function-source.zip"  bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source = "function-source.zip"}resource "google_cloudfunctions_function" "issue_creator_function" {  name        = "issue-creator-function"  description = "Receive Pub/Sub message from Google Cloud Monitoring and create a GitHub issue"  runtime    = "python39"  source_archive_bucket = google_storage_bucket.easybuggy_monitoring_function_bucket.name  source_archive_object = google_storage_bucket_object.function_source_object.name  entry_point           = "main"  region                = var.region  environment_variables = {    "GITHUB_API_TOKEN" = var.github_api_token    "GITHUB_REPO"      = var.github_repo    "GITHUB_OWNER"     = var.github_owner  }  event_trigger {    event_type = "providers/cloud.pubsub/eventTypes/topic.publish"    resource   = google_pubsub_topic.alerts_topic.id  }}resource "google_monitoring_alert_policy" "cpu_usage_policy" {  display_name = "High CPU Utilization Alert"  combiner     = "OR"  conditions {    display_name  = "CPU usage over 80%"    condition_threshold {      filter          = "metric.type=\"compute.googleapis.com/instance/cpu/utilization\" AND resource.type=\"gce_instance\""      duration        = "60s"      comparison      = "COMPARISON_GT"      threshold_value = 0.8      }  }  enabled = true  notification_channels = [google_monitoring_notification_channel.pubsub_channel.id]}main.pyfunctionsで実行されるコードです。pub/subから受け取ったデータからアラートのtitleとbodyを抜き出してGithub Issueにポストします。import base64import jsonimport osimport loggingimport requestsfrom flask import Flask, requestapp = Flask(__name__)GITHUB_API_TOKEN = os.environ.get('GITHUB_API_TOKEN')GITHUB_REPO = os.environ.get('GITHUB_REPO')GITHUB_OWNER = os.environ.get('GITHUB_OWNER')logging.basicConfig(level=logging.INFO)logger = logging.getLogger(__name__)def create_github_issue(data):    issue_title = f"Alert: {data['incident']['incident_id']}"    issue_body = data['incident']['summary']    logger.info(f"Creating issue with title: {issue_title} body: {issue_body}")    response = requests.post(        f"https://api.github.com/repos/{GITHUB_OWNER}/{GITHUB_REPO}/issues",        headers={            "Authorization": f"token {GITHUB_API_TOKEN}",            "Accept": "application/vnd.github.v3+json",        },        json={            "title": issue_title,            "body": issue_body,        },    )    if response.status_code == 201:        logger.info("Issue created successfully")        return "Issue created successfully", 201    else:        logger.error(f"Failed to create issue: {response.content}")        return f"Failed to create issue: {response.content}", response.status_code@app.route('/', methods=['POST'])def main(d, context): #Need to receive arguments    envelope = request.get_json()        if not envelope:        logger.error("No envelope received")        return "Bad Request", 400        logger.info(f"envelope: {envelope}")    pubsub_data = envelope.get('data', {})    logger.info(f"pub_sub_data")    if not pubsub_data:        logger.error(f"No outside data received: ")        return "Bad Request", 400    try:        data_base64 = pubsub_data.get('data', '')        if not data_base64:            raise ValueError("No data field in outside data")                data = base64.b64decode(data_base64.encode('utf-8')).decode('utf-8')        logger.info(f"Decoded data: {data}")        data = json.loads(data)                logger.info(f"Received data: {data}")    except Exception as e:        logger.error(f"Error processing message: {e}")        return "Bad Request", 400        return create_github_issue(data)if __name__ == "__main__":    app.run()デプロイ内容を理解したらterraform applyしましょう。アプライが成功したらインスタンスIPが表示されます。動作確認http://instance_ip:8080にブラウザでアクセスするとこのような画面になります。「無限ループ」のリンクを押し、無限ループを発生させましょう。CPU使用率が80%を超えたことを確認し、GitHub Issueを確認すると、アラートが通知されています。以上がGoogle Cloud monitoringのアラートをGitHub Issueに通知する流れとなります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド一発で、本格的なおうちKubernetesを構築する]]></title>
            <link>https://speakerdeck.com/melanmeg/komando-fa-de-ben-ge-de-naoutikuberneteswogou-zhu-suru</link>
            <guid>https://speakerdeck.com/melanmeg/komando-fa-de-ben-ge-de-naoutikuberneteswogou-zhu-suru</guid>
            <pubDate>Tue, 10 Dec 2024 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[作成したリポジトリ：https://github.com/melanmeg/k8s_1-30_on_noble参考：https://github.com/unchama/kube-cluster-on-proxmoxhttps://k8sh.net/arch/https://www.server-world.info/query?os=Ubuntu_24.04&p=kubernetes&f=1https://www.youtube.com/watch?v=7BLmtR1nhcY]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイクインタビュー: 技術顧問 うたもくさん編]]></title>
            <link>https://sreake.com/blog/interview-utam0k/</link>
            <guid>https://sreake.com/blog/interview-utam0k/</guid>
            <pubDate>Tue, 10 Dec 2024 04:16:19 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは。スリーシェイクのSreake事業部所属の早川(@bells17)です。 今回は7月からスリーシェイクの技術顧問に就任してもらったうたもくさん(@utam0k)に対談形式でインタビューをさせていただきましたので […]The post スリーシェイクインタビュー: 技術顧問 うたもくさん編 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Japan.R 2024で構造化ログについて発表した]]></title>
            <link>https://blog.atusy.net/2024/12/10/japanr-logging/</link>
            <guid>https://blog.atusy.net/2024/12/10/japanr-logging/</guid>
            <pubDate>Tue, 10 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[オフラインイベントはリアクションがもらえて楽しい。準備や質問を通じて学びもいっぱい。またやりたい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLで値を変換したい？それならcaseはいかが?]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/c677f78d5ae2b0</guid>
            <pubDate>Mon, 09 Dec 2024 16:42:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに※本投稿はLooker Advent Calendar 2024 の10日目の記事となりますはじめまして。偶然業務でLookerに出会い、そこから色々触っているデータエンジニアです。Lookerについてはまだまだ駆け出しの身ではありますが、少しずつ分かる事が増え、Lookerへの理解が深まってきたと感じています。今回はそんな初心者がLookerのフィールドパラメータであるcaseを触ってみた話です。 想定読者Lookerについて基本概要を知っているLookMLを知っているLookMLを触ったことがある・実装したことがある 背景・経緯※情報に関して...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[オレのNeovim見て！ 2024]]></title>
            <link>https://blog.atusy.net/2024/12/09/awesome-my-neovim/</link>
            <guid>https://blog.atusy.net/2024/12/09/awesome-my-neovim/</guid>
            <pubDate>Mon, 09 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Vim/Neovimに興味を持ってほしくて、私のNeovimのカッコイイところ集を作ってみました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ KubeCon NA 2024: The Future of DBaaS on Kubernetesのセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/08/kubecon_na_the_future_of_dbaas_ob_kubernetes</guid>
            <pubDate>Sun, 08 Dec 2024 03:00:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー8日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ2The Future of DBaaS on Kubernetesのセッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kL/the-future-of-dbaas-on-kubernetes-melissa-logan-constantia-sergey-pronin-percona-deepthi-sigireddi-planetscale-gabriele-bartolini-edbセッション動画:https://www.youtube.com/watch?v=Z35SlsYd1ds「The Future of DBaaS on Kubernetes」は、Data on Kubernetes Communityのメンバーによるパネルディスカッション形式で、Kubernetes上で動作するDBaaSの将来について議論されました。ここ数年でデータベースをKubernetes上で動かすにあたりどう便利になったか？セッションでは、Kubernetesにおけるストレージとネットワーキングの進化が、データベース運用を大きく改善した点が強調されました。Volume Snapshotなどのストレージ関連機能の向上は、バックアップとリカバリといったDay 2 Operationを効率化し、Local Persistent Volumeの導入と改善は、データベースの高可用性とディザスタリカバリ構成をシンプルに実現可能にしました。また、Cilium Network PolicyやIngress/Egressといったネットワーキング機能は、マルチテナントサービスにおけるアクセス制御を容易にし、セキュリティ強化に貢献しています。これらの改善により、増加するデータベースと、優秀なデータベースエンジニア不足という課題に対し、Kubernetesは少ない人員でデータベースをスケールさせる有効な手段となっています。数年前に比べ、Kubernetes上でのデータベース運用はより現実的になり、エンタープライズグレードの運用にも耐えうるレベルに達しています。これは、Kubernetesがステートレスなアプリケーションだけでなく、ステートフルなデータベースにも適したプラットフォームへと進化したことを示しています。私がKubernetesを触り始めた時点ではここで紹介されているほとんどの機能はサポートされており、なぜKubernetesでデータベースを運用することが難しいのかを理解しきれない面がありました。このセクションによる直近のデータベース観点でのKubernetesのアップデートの紹介により、何が障壁でそれがどのように解決されたのかの理解が深まりました。Kubernetes上でデータベースを動かしている顧客についてシェアできる事例はあるか？セッションでは、Nokia、Broadcom、HubSpot、Shopify、IBMなど、様々な企業がKubernetes上でデータベースを運用している事例が紹介されました。これらの事例は、マイクロサービスアーキテクチャの普及と密接に関連しています。マイクロサービス化されたアプリケーションでは、単一のモノリシックなデータベースではなく、サービスごとにデータベースを持つ傾向があり、Kubernetesはそのような分散データベース環境の構築と管理を容易にします。特に、開発者がデータベースを所有し、インフラ管理者がDBaaSをインターフェイスとしてデータベースを払い出すという新しい運用モデルは、今後の主流となる可能性を示唆しています。これは、DevOpsの原則をデータベース運用に取り入れることで、開発速度と運用効率を向上させるアプローチと言えるでしょう。セクション内で紹介されている開発者がデータベースを所有し、インフラ管理者がデータベースを払い出すという体制はパブリッククラウドで運用されるマイクロサービスアーキテクチャでは当たり前のように実践されており、Kubernetesでも今後の主流となると考えることは不思議ではないでしょう。そしてそれは従来のVMやベアメタルベースのDBAがデータベース管理を行うには多すぎるデータベースが運用され、限界を迎えることは想像に難くなく、KubernetesとOperatorによる運用の簡略化は必須と言えるかもしれません。Kubernetes上でデータベースを動かすにあたりベストプラクティスはなにか？ベストプラクティスとして、クラウド中立性、クラウドレディネス、セルフサービス、セキュリティ、アーキテクチャ設計などが挙げられました。Operatorの活用は、クラウドベンダーに依存しない運用を実現する上で重要であり、UI/APIの整備やArgoCDなどのツールとの連携により、データベースのプロビジョニングと管理を自動化できます。また、開発者が容易にスケーリングやテスト環境構築を行えるセルフサービス環境も重要です。セキュリティについては、業界標準やコンプライアンス要件に合わせたポリシー設定が不可欠です。アーキテクチャ設計では、PostgreSQLを例に、Kubernetesの機能を活用した高可用性構成や、複数のアベイラビリティゾーンを考慮した設計が重要となります。さらに、Kubernetesの標準APIを活用することで、オブザーバビリティやセキュリティ、証明書の管理を簡素化し、他のコンポーネントとの統合を容易にすることが推奨されています。VMからの移行時には、ストレージを分離することでリソース管理の予測精度を高めることが重要です。ここではベストプラクティスとしてユーザーがセルフサービスでデータベースを立ち上げる方法としてGUIとAPIとツール連携による自動化二つの観点が出ていました。個人的にはパブリッククラウドとIaCの流れを見るにGUIベースよりAPIによる自動化が主流になっていくのではないかと考えます。またデータベースではないですがオンプレミスのVMベースシステムからKubernetesのコンテナベースに移行するプロジェクトに関わった時は独自のプロトコルによる通信をVMで実装しており、その方法をコンテナの世界に持ち込もうとした結果非常に複雑になっていた事例を見たことがあります。そのため、ここで紹介されているKubernetesとそのエコシステムに合わせることは不可欠ではないかと感じます。データベースをKubenetesで動かす場合の課題や落とし穴はあるか？セッションでは、VM環境での運用とKubernetes環境での運用を混同してしまうこと、マイグレーション計画の不足、リソースの過剰確保、そして人材育成の課題が議論されました。既存のVM向けスクリプトをそのままKubernetesに適用しようとするのではなく、クラウドネイティブな考え方を取り入れ、スケーラビリティと信頼性の向上に焦点を当てるべきです。マイグレーションにおいては、全てのワークロードの移行と、ダウンタイム最小化を両立するための綿密な計画が必要です。リソース管理においては、Kubernetesの柔軟性を活かし、適切なリソース割り当てを行うための実験と調整が重要です。さらに、DBAがKubernetesの基礎知識を習得し、データベース運用における新たなパラダイムシフトに対応できるよう、人材育成に力を入れる必要があります。このセッションを通して一番に感じたのはオンプレからパブリッククラウドへの移行と気にするところは同じだということと、DBAとKubernetesの距離を近づけることはやはり大事だということでした。特にDBAとKubernetesについてはより簡単なソリューションとして存在してしまっているマネージドデータベースが、Kubernetesを利用することから目を背けさせてしまう要因になっていると感じます。しかしDBAがより求められるのはデータベースをセルフホストする場合で、今後DBAとして活躍していくにはLinuxに適応してきたようにKubernetesに適応していく日強うがあると考えています。DBaaSの将来はどのように変わっていくと考えるか？将来のDBaaSは、Kubernetesとの統合がさらに深まり、データベースとKubernetesの境界が曖昧になっていくと予測されています。PostgreSQLの例では、Kubernetesとの親和性を高めるためのパッチ適用や、拡張機能のコンテナ化などが進んでいます。また、プライベートDBaaSだけでなく、商用DBaaSのKubernetes上での提供も増加し、データベースサービスの利用がさらに容易になると考えられます。Google Cloudなどのクラウドプロバイダーも、将来的にKubernetes上でマネージドデータベースサービスを提供する可能性があり、これにより、数千規模のデータベース管理が容易になるでしょう。Kubernetesの普及と成熟に伴い、Helm ChartやYAML以外の、より洗練されたUXも期待されます。セッション内ではGoogle CloudではCloud SQLがKubenetes1で運用される未来があるかもしれないと言及していましたが、すでにSpannerはKubernetesで動いています。商用DBaaSがKubernetesで動くことについてはよくある構成ですが、プライベートDBaaSがKubernetes上で動き、さまざまなエコシステムと組み合わせてAPIベースなど自動化に適したUXが提供されていくことには非常に注目しています。まとめ「The Future of DBaaS on Kubernetes」セッションは、Kubernetes上でのデータベース運用が成熟期を迎えていることを示しました。ストレージとネットワーキングの進化、Operatorの普及、そして様々な企業での成功事例は、Kubernetesがデータベース運用のための堅牢でスケーラブルなプラットフォームであることを証明しています。クラウドネイティブなアプローチ、セルフサービス化、セキュリティ強化、そして適切なアーキテクチャ設計は、Kubernetes上でのデータベース運用を成功させるための鍵となります。同時に、VM環境からの移行、リソース管理、人材育成といった課題にも適切に対処する必要があります。今後のDBaaSは、Kubernetesとの統合がさらに進み、データベースサービスの利用がより容易になると期待されます。このセッションで得られた知見は、今後のデータベース運用戦略策定に役立つ貴重な情報源となるでしょう。特に、オンプレミスでマイクロサービスアーキテクチャを採用する組織にとって、Kubernetesはデータベース運用における重要な選択肢となるでしょう。↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2024: When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story のセッションレポート]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2024/12/11/when_life_gives_you_containers_make_an_open_source_rds_a_kubernetes_love_story</guid>
            <pubDate>Sun, 08 Dec 2024 02:42:58 GMT</pubDate>
            <content:encoded><![CDATA[この記事は以下アドベントカレンダー11日目の記事です。3-shake Advent Calendar 2024 シリーズ2Kubernetes Advent Calendar 2024 シリーズ1When Life Gives You Containers, Make an Open Source RDS: A Kubernetes Love Story セッションレポートセッション概要:https://kccncna2024.sched.com/event/1i7kn/when-life-gives-you-containers-make-an-open-source-rds-a-kubernetes-love-story-sergey-pronin-perconaセッション動画:https://www.youtube.com/watch?v=0gSSmdNB-Zoこのセッションは、オープンソースRDS、あるいはオープンソースDBaaSをKubernetes上で構築・運用する道のりを、物語風に語っています。セッションを通して、Kubernetes上でデータベースを運用することへの不安や課題を解消し、そのメリットと可能性を提示することを目指していると感じました。なぜKubernetesでデータベースを動かすのか？セッション冒頭では、スピーカーが4年前はKubernetesでデータベースを動かすことに懐疑的だったものの、現在は大きく考えが変わっていることが語られています。その理由として、クラウドニュートラル戦略、コスト削減、そして自動化の3点が挙げられています。特に自動化は、高可用性構成、Blue/Greenデプロイ、フェイルオーバーなどを容易にする点で重要です。これらのメリットは、マイクロサービスアーキテクチャやクラウドネイティブ開発において、データベース運用を効率化し、DevOps実践を促進する上で大きな力となります。従来の運用では、データベースのデプロイや管理に多くの手作業が必要でしたが、Kubernetesと自動化ツールを組み合わせることで、これらの作業を大幅に簡素化し、開発スピードの向上に貢献できます。一方、Kubernetes上でのデータベース運用に対する懸念として、パフォーマンスの劣化、Kubernetes自体の成熟度、そして複雑さが挙げられています。これらの懸念は、データベースエンジニアとして当然抱くものであり、セッション全体を通してこれらの懸念への回答が提示されています。このセクションでは、Kubernetes上でデータベースを運用する上でのメリットと課題が明確に示されており、導入を検討する上で重要なポイントが提示されています。特に、クラウドネイティブな環境におけるデータベース運用の重要性が強調されていました。また単純なメリット・デメリット以上にユーザーの感情面にフォーカスしているところが印象的でした。Chapter 1: Enthusiasm and Kubernetes 101: Kubernetesの基本と進化この章では、Kubernetes上でデータベースを動かすための基本的なステップが段階的に示されています。Pod、Persistent Volume Claim (PVC)、Service、Secret、ConfigMap、StatefulSet、そしてHA構成のためのエージェントとProxyの導入といった流れは、Kubernetesにおけるデータベース運用の進化を理解する上で非常に有用です。特に、StatefulSetの導入は、データベースのようなステートフルアプリケーションの運用において大きな進歩です。Podの順序付けられたデプロイ、安定したネットワークID、永続ストレージへのアクセスなど、StatefulSetが提供する機能は、データベースの高可用性と安定運用に不可欠です。しかし、これらの構成要素を手作業で管理することは複雑でエラーを起こしやすいため、IaCの導入が推奨されています。IaCを用いることで、インフラストラクチャのコード化、自動化、バージョン管理が可能となり、再現性と信頼性の高いデプロイを実現できます。TerraformやAnsible、ArgoCD、HelmなどのIaCツールは、Kubernetesの構成管理を簡素化し、複数環境へのデプロイを容易にします。これは、DevOpsの原則である「Infrastructure as Code」を実践する上で非常に重要なステップです。この章では、Kubernetes上でデータベースを動かすための基本的な構成要素と、IaCの重要性が説明されています。IaCを用いることで、複雑なKubernetes環境を効率的に管理し、再現性と信頼性を向上させることができる点が強調されていました。またIaCのパラメータを変更することで複数環境をデプロイできるところからDBaaSの最初の一歩を踏み出したととらえることができました。Chapter 2: Disillusionment and Operators 101: OperatorによるDay 2 Operationの簡素化IaCによってデプロイは容易になりますが、運用、つまりDay 2 Operationは依然として複雑です。アップグレード、スケーリング、フェイルオーバー、バックアップ、モニタリング、メンテナンス、リカバリといったタスクは、手作業で行うと大きな負担となります。ここでOperatorが登場します。Operatorは、Kubernetesの拡張機能であり、特定のアプリケーションのデプロイと管理を自動化します。データベースOperatorは、データベースのライフサイクル全体を管理し、Day 2 Operationを大幅に簡素化します。Operatorの導入により、データベース管理者はKubernetesの内部構造を深く理解する必要がなくなり、データベース運用に集中できます。これは、運用コストの削減と効率性の向上に大きく貢献します。また、Operatorは宣言的な設定をサポートしており、運用作業の自動化と標準化を促進します。しかし、Operatorだけでは真のDBaaSとは言えません。セルフサービスポータル、マルチクラスタ対応、詳細なモニタリング、課金機能など、DBaaSに必要な機能は多岐に渡ります。この章では、OperatorがDay 2 Operationを簡素化する上で重要な役割を果たすことが説明されています。Operatorは、データベース管理者の負担を軽減し、運用効率を向上させる強力なツールです。これはデータベースエンジニアといわれるロールが採用市場に少ない日本では特に重要な点です。大規模なデータベース運用に合わせてデータベースエンジニアの採用を増やすことは難しいため、様々なツールを利用して負荷を下げ、省力化し、より本質的な業務を行う必要があるためです。一方でOperatorだけではDBaaSの全てをカバーできない点にも注意が必要です。Chapter 3: Hope and DBaaS: Percona Everestの紹介Percona Everestは、オープンソースのDBaaSソリューションであり、Kubernetes上でデータベースサービスを提供します。ReactとMaterial UIで構築された直感的なUI、Golangで実装されたバックエンド、そしてAPIによるアクセスを提供することで、ユーザーフレンドリーな操作性を実現しています。Everestのアーキテクチャは、複数のOperatorをOperator Managerで管理する構造を採用しています。これにより、Operatorのバージョン管理、依存関係の解決、相互運用性の確保が容易になります。ユーザーは、GUIまたはAPIを介してデータベースサービスを操作し、そのリクエストはEverest Operatorによって各データベースOperatorに変換されます。Everestは、オープンソースDBaaSとして、ベンダーロックインを回避し、柔軟なデータベース運用を可能にします。また、コミュニティベースの開発により、迅速な機能追加とバグ修正が期待できます。この章では、Percona EverestがオープンソースDBaaSとして、Kubernetes上でデータベースサービスを提供する仕組みが説明されています。Everestは、ユーザーフレンドリーなUI、Operator ManagerによるOperator管理、そしてオープンソースとしてのメリットを提供することで、柔軟で効率的なデータベース運用を支援します。セッション中ではGUIやAPIは利用しない導入例もあると話されており、個人的にはKubernetesリソースの管理に余計なUIを追加する方法は大規模化したときにデメリットが増えるのではないかと感じました。またこのセッションのスピーカーはPerconaのエンジニアであるためある程度ポジショントークが含まれているであろうことも注意が必要です。Epilogue: Kubernetesとデータベースの未来セッションの締めくくりとして、Kubernetes上でのデータベース運用は困難な側面もあるものの、OperatorやDBaaSソリューションの活用により、効率的でスケーラブルな運用が可能になることが強調されています。Kubernetes上でデータベースを運用することは、もはや一部の先進的な企業だけの選択肢ではなく、一般的な選択肢になりつつあります。クラウドネイティブな環境でデータベースを運用することは、ビジネスの俊敏性と競争力を高める上で重要な要素となります。Kubernetes上でのデータベース運用に対する不安や懸念を解消し、その可能性を示す上で非常に有益な内容でした。Percona EverestのようなオープンソースDBaaSソリューションの登場は、Kubernetesにおけるデータベース運用の楽にする選択肢の一つと言えるでしょう。まとめこのセッションを通して、Kubernetes上でのデータベース運用は、進化を続け、成熟しつつあることが理解できました。初期の懸念は解消されつつあり、OperatorやDBaaSソリューションの登場により、運用効率とスケーラビリティが大幅に向上しています。特に定型的なデプロイと運用を自動化できることでデータベースエンジニアはアプリケーション特性に応じた最適化やリリースマネジメントといったユーザーに価値を提供することを最大化することに注力することができます。今後、Kubernetes上でのデータベース運用はさらに普及し、クラウドネイティブなアプリケーション開発の中核を担うことになるでしょう。一定以上の規模の組織ではオンプレ回帰やクラウドコストの最小化といった観点からKubernetes上にデータベースをホストするソリューションが求められ生ます。そのためデータベースエンジニアは、Kubernetesの基礎知識を習得し、OperatorやDBaaSソリューションの活用方法を学ぶことで、より効率的で本質的な業務を遂行できるようになるはずです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[バッチ処理をCloud RunからCloud Run jobsに変更してみた話]]></title>
            <link>https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc</link>
            <guid>https://qiita.com/bayobayo0324/items/71f7e19a051261d1adfc</guid>
            <pubDate>Sat, 07 Dec 2024 22:06:20 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2024 シリーズ1の8日目の記事ですはじめましてあるいはこんにちは、@bayobayo0324 です。株式会社スリーシェイクでクラウド…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CUDAを利用したプログラムの高速化とNvidia Container Toolkit]]></title>
            <link>https://sreake.com/blog/cuda-nvidia-container-toolkit/</link>
            <guid>https://sreake.com/blog/cuda-nvidia-container-toolkit/</guid>
            <pubDate>Fri, 06 Dec 2024 01:51:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部インターン生の高島陸斗です。インターン生としてSRE技術の調査・検証を行っています。私は、情報系の大学院生で、普段は数値解析に関する研究をしています。学部時代は、今回のブログ内容とも関係する並 […]The post CUDAを利用したプログラムの高速化とNvidia Container Toolkit first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇]]></title>
            <link>https://sreake.com/blog/sre_kaigi_2025/</link>
            <guid>https://sreake.com/blog/sre_kaigi_2025/</guid>
            <pubDate>Thu, 05 Dec 2024 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）に在籍するエンジニアが、2025年1月26日（日）に開催される「SRE Kaigi 2025」にセッション登壇することをお知らせします。The post 「SRE Kaigi 2025」にスリーシェイクのエンジニアが登壇 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rustによる郵便番号検索API (yubin_api) の技術解説]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/04/233641</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/04/233641</guid>
            <pubDate>Wed, 04 Dec 2024 14:36:41 GMT</pubDate>
            <content:encoded><![CDATA[こちらの記事は Rust Advent Calendar 2024 シリーズ 3 7日目の記事です！qiita.comはじめにRustを使用したWebアプリケーション開発は、高いパフォーマンスと堅牢性を両立させる方法として注目を集めています。本記事では、日本の郵便番号システムにアクセスするRESTful API「yubin_api」の実装を通じて、Rustの実践的な開発手法を解説します。workspace_2024/yubin_api at main · nwiizo/workspace_2024 · GitHubこのプロジェクトでは、axumを使用したWebサーバーの構築、非同期プログラミング（async/await）、構造化されたエラーハンドリングを実装しています。また、プロダクション環境を想定したメトリクス収集とモニタリング、型安全なAPIデザインにも焦点を当てています。ちなみに元ライブラリーの実装についてはsyumai さんの実装を全面的に参考にさせていただいております。blog.syum.ai1. プロジェクトの構成まず、Cargo.tomlの依存関係から見ていきましょう：[dependencies]# Webフレームワーク関連axum = { version = "0.7", features = ["macros"] }  # Webフレームワークtokio = { version = "1.0", features = ["full"] }   # 非同期ランタイムtower = { version = "0.4", features = ["full"] }   # HTTPサービス抽象化tower-http = { version = "0.5", features = ["cors", "trace", "limit", "request-id"] }# ロギングと監視tracing = "0.1"                # ログ出力tracing-subscriber = "0.3"     # ログ設定metrics = "0.21"              # メトリクス収集metrics-exporter-prometheus = "0.12"  # Prometheus形式出力# シリアライズ/デシリアライズserde = { version = "1.0", features = ["derive"] }serde_json = "1.0"# ユーティリティthiserror = "1.0"   # エラー定義uuid = { version = "1.0", features = ["v4"] }  # ユニークID生成utoipa = { version = "4.1", features = ["uuid"] }  # OpenAPI生成# 郵便番号データベースjpostcode_rs = "0.1.3"2. エラー処理の実装（error.rs）エラー処理は、APIの信頼性を確保する重要な部分です：use axum::{    http::StatusCode,    response::{IntoResponse, Response},    Json,};use thiserror::Error;use tracing::warn;// APIのエラー型を定義#[derive(Debug, Error)]pub enum ApiError {    #[error("Invalid postal code format")]    InvalidPostalCode,    #[error("Address not found")]    NotFound,    #[error("Internal server error: {0}")]    Internal(String),}// エラーをHTTPレスポンスに変換する実装impl IntoResponse for ApiError {    fn into_response(self) -> Response {        // エラーの種類に応じてステータスコードを設定        let (status, error_message) = match self {            ApiError::InvalidPostalCode => (StatusCode::BAD_REQUEST, self.to_string()),            ApiError::NotFound => (StatusCode::NOT_FOUND, self.to_string()),            ApiError::Internal(ref e) => {                // 内部エラーはログに記録                warn!("Internal server error: {}", e);                (                    StatusCode::INTERNAL_SERVER_ERROR,                    "Internal server error".to_string(),                )            }        };        // JSONレスポンスの構築        let body = Json(serde_json::json!({            "error": error_message,            "status": status.as_u16(),            // エラー追跡用のユニークID            "request_id": uuid::Uuid::new_v4().to_string()        }));        (status, body).into_response()    }}3. データモデルの定義（models.rs）APIで使用するデータ構造を定義します：use serde::{Deserialize, Serialize};// 住所情報のレスポンス構造体#[derive(Debug, Serialize, Deserialize, utoipa::ToSchema)]pub struct AddressResponse {    pub postal_code: String,    pub prefecture: String,    pub prefecture_kana: String,    pub prefecture_code: i32,    pub city: String,    pub city_kana: String,    pub town: String,    pub town_kana: String,    pub street: Option<String>,    pub office_name: Option<String>,    pub office_name_kana: Option<String>,}// jpostcode_rsのAddress型からの変換を実装impl From<jpostcode_rs::Address> for AddressResponse {    fn from(addr: jpostcode_rs::Address) -> Self {        AddressResponse {            postal_code: addr.postcode,            prefecture: addr.prefecture,            prefecture_kana: addr.prefecture_kana,            prefecture_code: addr.prefecture_code,            city: addr.city,            city_kana: addr.city_kana,            town: addr.town,            town_kana: addr.town_kana,            street: addr.street,            office_name: addr.office_name,            office_name_kana: addr.office_name_kana,        }    }}// 住所検索用のクエリ構造体#[derive(Debug, Deserialize, utoipa::ToSchema)]pub struct AddressQuery {    pub query: String,    #[serde(default = "default_limit")]    pub limit: usize,}// デフォルトの検索結果制限数fn default_limit() -> usize {    10}4. メトリクス収集の設定（metrics.rs）アプリケーションのパフォーマンスを監視するためのメトリクス設定：use metrics::{describe_counter, describe_histogram, register_counter, register_histogram};use metrics_exporter_prometheus::PrometheusBuilder;pub fn setup_metrics() {    // リクエスト数のカウンター    describe_counter!(        "yubin_api_postal_lookups_total",        "Total number of postal code lookups"    );    describe_counter!(        "yubin_api_address_searches_total",        "Total number of address searches"    );    // レスポンス時間のヒストグラム    describe_histogram!(        "yubin_api_postal_lookup_duration_seconds",        "Duration of postal code lookups in seconds"    );    describe_histogram!(        "yubin_api_address_search_duration_seconds",        "Duration of address searches in seconds"    );    // メトリクスの登録    register_counter!("yubin_api_postal_lookups_total");    register_counter!("yubin_api_address_searches_total");    register_histogram!("yubin_api_postal_lookup_duration_seconds");    register_histogram!("yubin_api_address_search_duration_seconds");    // Prometheusレコーダーの設定    PrometheusBuilder::new()        .install()        .expect("Failed to install Prometheus recorder");}Rustの知っておいたほうがいいポイント解説(前編)属性マクロの使用#[derive(...)]: 自動実装の導入#[error(...)]: エラーメッセージの定義#[serde(...)]: シリアライズ設定トレイトの実装From<T>: 型変換の実装IntoResponse: HTTPレスポンスへの変換Error: カスタムエラー型の定義ジェネリクスとライフタイムOption<T>: 省略可能な値の表現Result<T, E>: エラーハンドリングVec<T>: 可変長配列の使用型システムの活用カスタム構造体の定義列挙型によるエラー表現デフォルト値の実装Rust初学者のためのyubin_api実装解説 - 後編5. APIルートの実装（routes.rs）APIの実際のエンドポイントを実装します：use axum::{extract::Path, http::StatusCode, response::IntoResponse, Json};use metrics::{counter, histogram};use tracing::info;// ヘルスチェックエンドポイントpub async fn health_check() -> impl IntoResponse {    StatusCode::OK}// 郵便番号検索エンドポイントpub async fn lookup_by_postal_code(    Path(code): Path<String>,  // URLパスからパラメータを取得) -> Result<Json<Vec<AddressResponse>>, ApiError> {    // リクエストのログ記録    info!("Looking up postal code: {}", code);        // メトリクスのカウントアップ    counter!("yubin_api_postal_lookups_total", 1);        // 処理時間の計測開始    let start = std::time::Instant::now();    // 郵便番号検索の実行    let result = jpostcode_rs::lookup_address(&code).map_err(|e| match e {        jpostcode_rs::JPostError::InvalidFormat => ApiError::InvalidPostalCode,        jpostcode_rs::JPostError::NotFound => ApiError::NotFound,    })?;    // 処理時間の計測と記録    let duration = start.elapsed().as_secs_f64();    histogram!("yubin_api_postal_lookup_duration_seconds", duration);    // 結果の返却    Ok(Json(result.into_iter().map(Into::into).collect()))}// 住所検索エンドポイントpub async fn search_by_address(    Json(query): Json<AddressQuery>,  // リクエストボディからのJSONパース) -> Result<Json<Vec<AddressResponse>>, ApiError> {    info!("Searching address with query: {}", query.query);        // 入力値の検証    if query.query.trim().is_empty() {        return Err(ApiError::InvalidPostalCode);    }    counter!("yubin_api_address_searches_total", 1);    let start = std::time::Instant::now();    // 住所検索の実行    let mut results: Vec<AddressResponse> = jpostcode_rs::search_by_address(&query.query)        .into_iter()        .map(Into::into)        .collect();    // 結果数の制限適用    results.truncate(query.limit);    let duration = start.elapsed().as_secs_f64();    histogram!("yubin_api_address_search_duration_seconds", duration);    Ok(Json(results))}6. メインアプリケーションの実装（main.rs）アプリケーションのエントリーポイントとサーバーの設定：use axum::{routing::{get, post}, Router};use std::net::SocketAddr;use tower::ServiceBuilder;use tower_http::{    cors::{Any, CorsLayer},    trace::{DefaultMakeSpan, DefaultOnResponse, TraceLayer},};use tracing::info;#[tokio::main]async fn main() {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| "yubin_api=debug,tower_http=debug".into()),        )        .init();    // メトリクス収集の初期化    setup_metrics();    // リクエストトレース設定    let trace_layer = TraceLayer::new_for_http()        .make_span_with(DefaultMakeSpan::new().include_headers(true))        .on_response(DefaultOnResponse::new().include_headers(true));    // CORS設定    let cors = CorsLayer::new()        .allow_methods(Any)        .allow_headers(Any)        .allow_origin(Any);    // ルーターの設定    let app = Router::new()        .route("/health", get(health_check))        .route("/postal/:code", get(lookup_by_postal_code))        .route("/address/search", post(search_by_address))        .layer(ServiceBuilder::new()            .layer(trace_layer)            .layer(cors));    // サーバーアドレスの設定    let addr = SocketAddr::from(([127, 0, 0, 1], 3000));    info!("Server listening on {}", addr);    // サーバーの起動    let listener = tokio::net::TcpListener::bind(addr).await.unwrap();    axum::serve(listener, app).await.unwrap();}7. 重要な実装パターンの解説非同期処理// 非同期関数の定義pub async fn lookup_by_postal_code(...) -> Result<...> {    // 非同期処理の実行    let result = jpostcode_rs::lookup_address(&code)?;    // ...}// 非同期ランタイムの設定#[tokio::main]async fn main() {    // ...}エラーハンドリング// Result型を使用したエラー処理let result = jpostcode_rs::lookup_address(&code).map_err(|e| match e {    JPostError::InvalidFormat => ApiError::InvalidPostalCode,    JPostError::NotFound => ApiError::NotFound,})?;ミドルウェアの構成let app = Router::new()    .route(...)    .layer(ServiceBuilder::new()        .layer(trace_layer)        .layer(cors));8. API使用例郵便番号による検索curl http://localhost:3000/postal/1000001レスポンス例：[  {    "postal_code": "1000001",    "prefecture": "東京都",    "city": "千代田区",    "town": "千代田",    ...  }]住所による検索curl -X POST http://localhost:3000/address/search \  -H "Content-Type: application/json" \  -d '{"query": "東京都千代田区", "limit": 10}'9. Rustの知っておいたほうがいいポイント解説(後編)非同期プログラミングasync/awaitの使用方法tokioランタイムの理解非同期関数の定義と呼び出しエラーハンドリングパターンResult型の活用エラー変換のベストプラクティスエラーの伝播（?演算子）HTTPサーバーの実装ルーティング設定ミドルウェアの活用リクエスト/レスポンスの処理テスト可能な設計モジュール分割依存性の分離エラー処理の一貫性おわりにyubin_apiの実装を通じて、Rustによる実践的なWeb API開発の全体像を見てきました。このプロジェクトでは、カスタムエラー型の定義や型安全なデータ変換、トレイトの実装といった堅牢な型システムの活用を行いました。また、tokioによる非同期ランタイムやasync/awaitの効果的な使用、エラーハンドリングとの統合などの非同期プログラミングの実践も重要な要素となっています。さらに、メトリクス収集や構造化ログ、エラートラッキングといった運用面の考慮など、重要な概念と技術を学ぶことができました。このプロジェクトは、単なる郵便番号検索APIの実装を超えて、Rustの実践的な使用方法と、プロダクション品質のWebサービス開発の基本を学ぶ良い例となっています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[構造化ログのスキーマを考えてみる]]></title>
            <link>https://blog.atusy.net/2024/12/04/log-schema/</link>
            <guid>https://blog.atusy.net/2024/12/04/log-schema/</guid>
            <pubDate>Wed, 04 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[ログ設計初心者なりに、分析しやすいログってなにかなと考えてみた。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[argocd コマンドで別ブランチとの差分を確認する]]></title>
            <link>https://qiita.com/yteraoka/items/aea03d50288375f85183</link>
            <guid>https://qiita.com/yteraoka/items/aea03d50288375f85183</guid>
            <pubDate>Tue, 03 Dec 2024 15:14:17 GMT</pubDate>
            <content:encoded><![CDATA[ArgoCD の GitOps で Merge 前に manifest の差分を見たいArgoCD は Application リソースで source に指定した Git などの定義と実際に K…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LLMのモデル更新や廃止による影響を考える]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/12/03/232856</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/12/03/232856</guid>
            <pubDate>Tue, 03 Dec 2024 14:28:56 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、MLOps（LLMOps、生成AIOps） Advent Calendar 2024 4日目の記事です。生成AIの普及により、アプリケーションに組み込んで実運用を始めた方も増えてきたと思います。LLMOpsをする中で気をつけたいことを考えてみました。モデルの更新まず、思い浮かぶのがモデルの更新よる影響です。モデルの更新によって性能が上がるなどのメリットを享受できる反面、挙動変更によって、困ることもあります。私の場合、システムの実運用では無いですが、LLM技術書のサンプルコードが動かなくなる事態がありました。06_agent/agent_5.py で2回目の実行結果が正しく表示されません · Issue #3 · harukaxq/langchain-book · GitHubgpt-3.5-turboをAgentとして使用したときの挙動が変わったという内容です。アプリに組み込んでいたら、機能が使えなくなる可能性があり、使えなくなった場合の代替案も用意しておく必要があると考えました。また、LLMのリリース情報もウォッチしておく必要があるでしょう。Geminiはリリースの最新情報を日本語で提供しています。gemini.google.comChatGPTはリリースノートを英語のみですが提供しています。ChatGPT — Release Notes | OpenAI Help CenterAnthropic製品（Claude）のリリースノートは日本語で提供されています。docs.anthropic.comモデルの廃止モデルの廃止もウォッチする必要があるでしょう。GPT-3.5 Turbo終了はニュースになりました。xtech.nikkei.com↑日経クロステックの有料会員記事ですが、会員でなくても1ページ目で内容は把握できます。learn.microsoft.comAzure OpenAIでは、GPTの各種マイナーバージョンが提供されていますが、適宜廃止になるので注意が必要です。廃止になる場合、モデルのVersion UPが必要なので、早めに開発環境でVersion UPしたモデルの挙動確認をする必要があるでしょう。Version UPしたモデルだと、LLMの利用料が高くなることも念頭に置いて、コスト試算しましょう。まとめモデル更新や廃止を早く知るために、LLM公式サイトのリリースノートなどのウォッチをして、早めに対策をしましょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rustで郵便番号・住所検索TUIツールを開発した - jposta]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/03/230030</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/03/230030</guid>
            <pubDate>Tue, 03 Dec 2024 14:00:30 GMT</pubDate>
            <content:encoded><![CDATA[こちらの記事は Rust Advent Calendar 2024 シリーズ 3 5日目の記事です！qiita.comはじめにこんにちは！jposta を紹介させてください。jpostaは、日本の郵便番号・住所をターミナルから手軽に検索できるTUIツール 🔍 です。Rustで書かれており ⚡、使いやすさを重視してリアルタイム検索を実装しました 🖥️。jposta の動作イメージ元ライブラリーの実装についてはsyumai さんの実装を全面的に参考にさせていただいております。美しい実装すぎて震えました。blog.syum.ai機能紹介この小さなツールでは、郵便番号から住所の簡単検索 🏠 はもちろん、住所からの郵便番号検索 🔢 もラクラクできます。入力しながらサクサク表示されるリアルタイム検索 ⚡ や、キーボードだけでスイスイ操作 ⌨️ が可能で、スクロールもサクサク動き 📜、もちろん日本語もバッチリ対応 🗾 しています。ぜひGitHubをチェックしてみてください！github.comインストールcargo install --git https://github.com/nwiizo/jpostaもしくはcargo install jpostaこちら、みんなだいすきcrate.ioにちゃんとあげました。https://crates.io/crates/jposta基本操作Tab: 郵便番号/住所検索モード切替↑↓: 結果スクロールEsc: 終了検索モード郵便番号検索数字を入力すると自動で該当する住所を表示部分一致対応（"100"で始まる郵便番号すべて等）住所検索漢字やかなで住所を入力部分一致対応（"渋谷"等）Rustでの実装解説1. 基本構造の定義#[derive(Clone)]enum InputMode {    Postal,   // 郵便番号検索    Address,  // 住所検索}struct App {    input: String,    results: Vec<String>,    input_mode: InputMode,    scroll_state: ScrollbarState,    scroll_position: u16,    search_tx: mpsc::Sender<String>,    result_rx: mpsc::Receiver<Vec<String>>,}InputModeは検索モードを表す列挙型です。Cloneトレイトを導出することで、値のコピーが可能になります。App構造体はアプリケーションの状態を管理します。input: 現在の入力文字列results: 検索結果の配列input_mode: 現在の検索モードscroll_stateとscroll_position: スクロール状態の管理search_txとresult_rx: スレッド間通信用のチャンネル2. アプリケーションの初期化impl App {    fn new() -> App {        let (search_tx, search_rx) = mpsc::channel::<String>();        let (result_tx, result_rx) = mpsc::channel();        thread::spawn(move || {            let mut last_query = String::new();            let mut input_mode = InputMode::Postal;                        while let Ok(query) = search_rx.recv() {                // 検索処理（後述）            }        });        App {            input: String::new(),            results: Vec::new(),            input_mode: InputMode::Postal,            scroll_state: ScrollbarState::default(),            scroll_position: 0,            search_tx,            result_rx,        }    }}new()関数では、2つのチャンネルを作成（検索クエリ用と結果用）検索処理を行うワーカースレッドを起動初期状態のAppインスタンスを返す3. 検索処理の実装// 検索スレッド内の処理if query.starts_with("MODE_CHANGE:") {    input_mode = match &query[11..] {        "postal" => InputMode::Postal,        _ => InputMode::Address,    };    continue;}if query == last_query { continue; }last_query = query.clone();if query.is_empty() {    let _ = result_tx.send(Vec::new());    continue;}thread::sleep(Duration::from_millis(100));let results = match input_mode {    InputMode::Postal => lookup_addresses(&query)        .map(|addresses| {            addresses                .into_iter()                .map(|addr| addr.formatted_with_kana())                .collect()        })        .unwrap_or_default(),    InputMode::Address => search_by_address(&query)        .into_iter()        .map(|addr| addr.formatted_with_kana())        .collect(),};let _ = result_tx.send(results);検索処理では、モード変更メッセージの確認と処理重複クエリのスキップ空クエリの即時処理ディバウンス処理（100ms）モードに応じた検索実行結果の送信4. UIとイベント処理fn main() -> io::Result<()> {    enable_raw_mode()?;    let mut stdout = stdout();    execute!(stdout, EnterAlternateScreen)?;    let backend = CrosstermBackend::new(stdout);    let mut terminal = Terminal::new(backend)?;    let mut app = App::new();    loop {        app.check_results();        terminal.draw(|f| {            let chunks = Layout::default()                .direction(Direction::Vertical)                .constraints([                    Constraint::Length(3),                    Constraint::Min(0)                ])                .split(f.size());            // 入力欄の描画            let input_block = Block::default()                .title(match app.input_mode {                    InputMode::Postal => "郵便番号検索",                    InputMode::Address => "住所検索",                })                .borders(Borders::ALL);                        let input = Paragraph::new(app.input.as_str())                .block(input_block)                .style(Style::default().fg(Color::Yellow));            f.render_widget(input, chunks[0]);            // 結果表示の描画            let results_block = Block::default()                .title(format!("検索結果 ({} 件)", app.results.len()))                .borders(Borders::ALL);                        let results = Paragraph::new(app.results.join("\n"))                .block(results_block)                .scroll((app.scroll_position, 0));            f.render_widget(results, chunks[1]);        })?;        // キー入力処理        if let Event::Key(key) = event::read()? {            match key.code {                KeyCode::Char(c) => {                    app.input.push(c);                    app.search();                }                KeyCode::Backspace => {                    app.input.pop();                    app.search();                }                KeyCode::Up => app.scroll_up(),                KeyCode::Down => app.scroll_down(),                KeyCode::Tab => app.change_mode(match app.input_mode {                    InputMode::Postal => InputMode::Address,                    InputMode::Address => InputMode::Postal,                }),                KeyCode::Esc => break,                _ => {}            }        }    }    // 終了処理    execute!(terminal.backend_mut(), LeaveAlternateScreen)?;    disable_raw_mode()?;    Ok(())}UIとイベント処理では、ターミナルの初期化メインループ検索結果の確認画面描画キー入力処理終了時のクリーンアップ5. 補助機能の実装impl App {    fn search(&mut self) {        let _ = self.search_tx.send(self.input.clone());    }    fn check_results(&mut self) {        if let Ok(new_results) = self.result_rx.try_recv() {            self.results = new_results;            self.scroll_position = 0;            self.scroll_state = ScrollbarState::new(self.results.len());        }    }    fn scroll_up(&mut self) {        self.scroll_position = self.scroll_position.saturating_sub(1);    }    fn scroll_down(&mut self) {        if !self.results.is_empty() {            self.scroll_position = self                .scroll_position                .saturating_add(1)                .min((self.results.len() as u16).saturating_sub(1));        }    }    fn change_mode(&mut self, mode: InputMode) {        self.input_mode = mode;        let mode_str = match self.input_mode {            InputMode::Postal => "postal",            InputMode::Address => "address",        };        let _ = self.search_tx.send(format!("MODE_CHANGE:{}", mode_str));        self.input.clear();        self.results.clear();    }}補助機能として、1. 検索リクエストの送信2. 検索結果の確認と更新3. スクロール処理4. モード切替処理これらの機能により、スムーズな検索体験を実現しています。使用ライブラリratatui: TUI（テキストユーザーインターフェース）フレームワークcrossterm: ターミナル操作ライブラリjpostcode_rs: 郵便番号データ処理ライブラリRust学習リソース1. 基礎学習The Rust Programming Language - 公式ガイドブックRust by Example - 実例で学ぶRustRustlings - 対話型学習ツール2. 基本概念構造体（Structs）列挙型（Enums）メソッド実装3. メモリ管理所有権システム参照と借用4. 言語機能パターンマッチングクロージャ5. エラー処理と型システムエラー処理Result型境界チェック演算子さいごにこのプロジェクトは、Rustの実践的な学習と日本の住所システムへの理解を深める良い機会となりました 📚。非同期処理やTUIの実装を通じて、Rustの強力な型システムと安全性を活かしたコーディングを実践できました ⚡。ぜひ使ってみて、フィードバックをいただければ幸いです 🙏。プルリクエストも大歓迎です 🎉！ソースコード🦀GitHub - jposta]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[退屈なことはRust Build Scripts にやらせよう]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/12/03/143149</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/12/03/143149</guid>
            <pubDate>Tue, 03 Dec 2024 05:31:49 GMT</pubDate>
            <content:encoded><![CDATA[こちらの記事は Rust Advent Calendar 2024 シリーズ 3 3日目の記事です！qiita.comはじめにRustのビルドスクリプト（build.rs）は、コンパイル前のデータ処理や環境設定を自動化する強力なツールです。しかし、大いなる力には、大いなる責任が伴います。コードの生成、リソースの最適化、プラットフォーム固有の設定管理など、ビルド時の様々なタスクを効率的に処理できます。今回は、そのユースケースの1つとして、郵便番号データを処理するビルドスクリプトの実装を詳しく解説します。この例を通じて、build.rsの基本的な使い方から実践的な活用方法まで、段階的に理解を深めていきましょう。doc.rust-lang.orgはじめにユースケース：郵便番号データの処理実装の全体像実装の詳細解説1. ファイル変更の監視設定2. パスの設定3. データの処理4. 結果の出力生成したデータの利用方法1. アプリケーションでのデータ読み込み2. 検索機能の実装build.rsの主要な機能1. 環境変数の設定2. リンカ設定3. コードの生成実践的な利用シーン1. 設定ファイルの統合と生成2. プロトコル定義ファイルの生成3. アセットファイルの埋め込み4. データベースマイグレーションファイルの統合参考資料まとめユースケース：郵便番号データの処理このビルドスクリプトは、複数のJSONファイルに分散された郵便番号データを1つのファイルにマージする処理を行います。github.com実装の全体像use serde_json::Value;use std::collections::HashMap;use std::fs;use std::path::Path;use walkdir::WalkDir;fn main() {    println!("cargo:rerun-if-changed=jpostcode-data/data/json");    let json_dir = Path::new("jpostcode-data/data/json");    let out_dir = std::env::var("OUT_DIR").unwrap();    let dest_path = Path::new(&out_dir).join("address_data.json");    let mut merged_data = HashMap::new();    // ... データ処理ロジック ...}実装の詳細解説1. ファイル変更の監視設定println!("cargo:rerun-if-changed=jpostcode-data/data/json");この行は、指定したディレクトリ内のファイルが変更された場合にのみビルドスクリプトを再実行するように設定します。これにより、不必要なビルド時間を削減できます。2. パスの設定let json_dir = Path::new("jpostcode-data/data/json");let out_dir = std::env::var("OUT_DIR").unwrap();let dest_path = Path::new(&out_dir).join("address_data.json");json_dir: 入力となるJSONファイルが格納されているディレクトリout_dir: Cargoが提供するビルド出力ディレクトリdest_path: 生成されるファイルの出力先3. データの処理for entry in WalkDir::new(json_dir).into_iter().filter_map(|e| e.ok()) {    if entry.file_type().is_file()        && entry.path().extension().map_or(false, |ext| ext == "json")    {        let content = fs::read_to_string(entry.path()).unwrap();        let file_data: HashMap<String, Value> = serde_json::from_str(&content).unwrap();        let prefix = entry.path().file_stem().unwrap().to_str().unwrap();        for (suffix, data) in file_data {            let full_postcode = format!("{}{}", prefix, suffix);            merged_data.insert(full_postcode, data);        }    }}このコードブロックでは以下の処理を行っています。WalkDirを使用してディレクトリを再帰的に走査JSONファイルのみを対象にフィルタリング各ファイルの内容を読み込みとパースファイル名とデータを組み合わせて完全な郵便番号を生成マージされたデータに追加4. 結果の出力fs::write(dest_path, serde_json::to_string(&merged_data).unwrap()).unwrap();処理したデータを1つのJSONファイルとして出力します。生成したデータの利用方法1. アプリケーションでのデータ読み込みuse once_cell::sync::Lazy;use serde::{Deserialize, Serialize};use std::collections::HashMap;#[derive(Debug, Serialize, Deserialize)]struct Address {    postcode: String,    prefecture: String,    city: String,    // ... 他のフィールド}static ADDRESS_MAP: Lazy<HashMap<String, Vec<Address>>> = Lazy::new(|| {    let data = include_str!(concat!(env!("OUT_DIR"), "/address_data.json"));    serde_json::from_str(data).expect("Failed to parse address data")});2. 検索機能の実装fn lookup_address(postal_code: &str) -> Option<&Vec<Address>> {    ADDRESS_MAP.get(postal_code)}fn search_by_prefecture(prefecture: &str) -> Vec<&Address> {    ADDRESS_MAP        .values()        .flat_map(|addresses| addresses.iter())        .filter(|addr| addr.prefecture == prefecture)        .collect()}build.rsの主要な機能1. 環境変数の設定// コンパイル時の条件設定println!("cargo:rustc-cfg=feature=\"custom_feature\"");// 環境変数の設定println!("cargo:rustc-env=APP_VERSION=1.0.0");2. リンカ設定// 外部ライブラリのリンクprintln!("cargo:rustc-link-lib=sqlite3");println!("cargo:rustc-link-search=native=/usr/local/lib");3. コードの生成// バージョン情報の生成let version_code = format!(    "pub const VERSION: &str = \"{}\";\n",    env!("CARGO_PKG_VERSION"));fs::write("version.rs", version_code)?;実践的な利用シーン1. 設定ファイルの統合と生成複数の環境向けの設定ファイルを1つに統合する例：use std::collections::HashMap;use serde_json::Value;fn main() {    println!("cargo:rerun-if-changed=config/");        let environments = ["development", "staging", "production"];    let mut merged_config = HashMap::new();        for env in environments {        let config_path = format!("config/{}.json", env);        let config_content = std::fs::read_to_string(&config_path).unwrap();        let config: Value = serde_json::from_str(&config_content).unwrap();                merged_config.insert(env, config);    }        let out_dir = std::env::var("OUT_DIR").unwrap();    let dest_path = Path::new(&out_dir).join("config.rs");        // 設定をRustのコードとして出力    let config_code = format!(        "pub static CONFIG: Lazy<HashMap<&str, Value>> = Lazy::new(|| {{            serde_json::from_str({}).unwrap()        }});",        serde_json::to_string(&merged_config).unwrap()    );        std::fs::write(dest_path, config_code).unwrap();}使用例：// main.rsuse once_cell::sync::Lazy;include!(concat!(env!("OUT_DIR"), "/config.rs"));fn get_database_url(env: &str) -> String {    CONFIG[env]["database"]["url"].as_str().unwrap().to_string()}2. プロトコル定義ファイルの生成Protocol Buffersの定義ファイルからRustコードを生成する例：use std::process::Command;fn main() {    println!("cargo:rerun-if-changed=proto/");        // protoファイルのコンパイル    let status = Command::new("protoc")        .args(&[            "--rust_out=src/generated",            "--proto_path=proto",            "service.proto"        ])        .status()        .unwrap();            if !status.success() {        panic!("Failed to compile proto files");    }        // 生成されたコードをモジュールとして登録    let mod_content = r#"        pub mod generated {            include!("generated/service.rs");        }    "#;        std::fs::write("src/proto_mod.rs", mod_content).unwrap();}使用例：// lib.rsmod proto_mod;use proto_mod::generated::{UserRequest, UserResponse};pub async fn handle_user_request(req: UserRequest) -> UserResponse {    // プロトコル定義に基づいた処理}3. アセットファイルの埋め込み画像やテキストファイルをバイナリに埋め込む例：use std::collections::HashMap;use base64;fn main() {    println!("cargo:rerun-if-changed=assets/");        let mut assets = HashMap::new();        // 画像ファイルの埋め込み    for entry in std::fs::read_dir("assets").unwrap() {        let entry = entry.unwrap();        let path = entry.path();                if path.extension().map_or(false, |ext| ext == "png" || ext == "jpg") {            let content = std::fs::read(&path).unwrap();            let encoded = base64::encode(&content);                        let asset_name = path.file_name().unwrap().to_str().unwrap();            assets.insert(asset_name.to_string(), encoded);        }    }        // アセットデータをRustコードとして出力    let out_dir = std::env::var("OUT_DIR").unwrap();    let dest_path = Path::new(&out_dir).join("assets.rs");        let assets_code = format!(        "pub static ASSETS: Lazy<HashMap<String, String>> = Lazy::new(|| {{            let mut m = HashMap::new();            {}            m        }});",        assets.iter().map(|(k, v)| {            format!("m.insert(\"{}\".to_string(), \"{}\".to_string());", k, v)        }).collect::<Vec<_>>().join("\n")    );        std::fs::write(dest_path, assets_code).unwrap();}使用例：// lib.rsuse once_cell::sync::Lazy;include!(concat!(env!("OUT_DIR"), "/assets.rs"));pub fn get_image_data(name: &str) -> Option<Vec<u8>> {    ASSETS.get(name)        .map(|encoded| base64::decode(encoded).unwrap())}4. データベースマイグレーションファイルの統合SQLマイグレーションファイルを1つのモジュールにまとめる例：fn main() {    println!("cargo:rerun-if-changed=migrations/");        let mut migrations = Vec::new();        // マイグレーションファイルの収集    for entry in std::fs::read_dir("migrations").unwrap() {        let entry = entry.unwrap();        let path = entry.path();                if path.extension().map_or(false, |ext| ext == "sql") {            let version = path.file_stem().unwrap().to_str().unwrap()                .split('_').next().unwrap();            let content = std::fs::read_to_string(&path).unwrap();                        migrations.push((version.to_string(), content));        }    }        // マイグレーションをRustコードとして出力    let migrations_code = format!(        "pub static MIGRATIONS: &[(&str, &str)] = &[{}];",        migrations.iter()            .map(|(ver, sql)| format!("(\"{}\", \"{}\")", ver, sql.replace("\"", "\\\"")))            .collect::<Vec<_>>()            .join(",\n")    );        let out_dir = std::env::var("OUT_DIR").unwrap();    let dest_path = Path::new(&out_dir).join("migrations.rs");    std::fs::write(dest_path, migrations_code).unwrap();}使用例：// database.rsinclude!(concat!(env!("OUT_DIR"), "/migrations.rs"));pub async fn run_migrations(db: &SqlitePool) -> Result<()> {    for (version, sql) in MIGRATIONS {        db.execute(sql).await?;        println!("Applied migration version {}", version);    }    Ok(())}これらの例は、build.rsの実践的な使用方法を示しています。各例で以下のような利点があります。コンパイル時のリソース最適化開発時の利便性向上ランタイムパフォーマンスの改善コードの保守性向上実際のプロジェクトでは、これらの手法を組み合わせたり、プロジェクトの要件に合わせてカスタマイズしたりすることで、より効率的な開発環境を構築できます。しかし、魔環境もしくはビルド地獄を顕現させることもできるので注意が必要だと思いました。参考資料The Cargo Book - Build ScriptsRust By Example - Build Scriptsまとめこのビルドスクリプトの実装例を通じて、build.rsの有用性が明確になりました。コンパイル時のデータ最適化や複数ファイルの統合処理、動的なコード生成、そしてプラットフォーム固有の設定管理など、多岐にわたる機能を提供します。実際のプロジェクトでは、これらの機能を組み合わせることで、効率的な開発環境とビルドプロセスを実現できます。build.rsを活用することで、コンパイル時に必要なリソースの最適化や設定の自動化が可能となり、開発効率の向上とコードの保守性改善に大きく貢献します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Transformer論文を生成AIで要約してみた]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/12/02/233507</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/12/02/233507</guid>
            <pubDate>Mon, 02 Dec 2024 14:35:07 GMT</pubDate>
            <content:encoded><![CDATA[この記事は生成AI Advent Calendar 2024の3日目の記事です。AIの歴史は60年ほどで、「冬の時代」と呼ばれる停滞期もありましたが、昨今の生成AIの発展は「Transformer」と呼ばれる論文から始まりました。この「Transformer」論文をわかりやすいように生成AIに要約させてみました。arxiv.org「Transformer」論文は上記サイトで見ることができます。論文の正式名称は「Attention Is All You Need」で、現在 v7。右側のAccess Paper:から閲覧することができます。なお、PDFの直リンクはこちらGoogle CloudのVertex AIでGeminiに要約させた結果は以下です。プロンプト「この論文を日本語で高校3年生レベルにもわかるように要約してください。」この論文は、「Transformer」という、機械翻訳などのシーケンス変換タスクに革新をもたらした新しいニューラルネットワークアーキテクチャを提案しています。高校3年生にもわかるように要約すると、以下のようになります。従来の機械翻訳の問題点:従来の機械翻訳は、RNN（再帰型ニューラルネットワーク）という技術を主に使っていました。RNNは文章を単語ごとに順番に処理していくため、長い文章だと処理に時間がかかります。また、並列処理が難しいため、計算速度を上げるのが困難でした。Transformerの革新的な点:Transformerは、「Attention（注意機構）」という仕組みに完全に基づいており、RNNのような順番に処理する仕組みを完全に排除しました。Attention機構は、翻訳したい単語を生成する際に、入力文全体の中でどの単語に注目すべきかを判断する仕組みです。人間の翻訳作業で例えると、翻訳する際に原文の関連する部分に注目するのと同じような働きをします。この仕組みにより、以下の利点が生まれました。並列処理が可能: 単語を順番に処理する必要がないため、並列処理が可能になり、計算速度が大幅に向上しました。長い文章への対応力向上: RNNでは、文章が長くなるほど精度が落ちやすいという問題がありましたが、Attention機構は入力文全体を一度に見ることができるため、長い文章でも高い精度を維持できます。Transformerの成果:Transformerは、従来のモデルよりも高い精度を達成し、さらに学習時間も大幅に短縮しました。具体的には、英語からドイツ語への翻訳と英語からフランス語への翻訳タスクで、当時の最高精度を更新しました。Transformerの仕組みを簡単に説明すると:Transformerは、エンコーダとデコーダという2つの部分から構成されています。エンコーダ: 入力文を解析し、各単語の意味をベクトル表現に変換します。デコーダ: エンコーダの出力とAttention機構を利用して、翻訳文を生成します。エンコーダとデコーダは、それぞれ複数の層が積み重なった構造になっています。各層は、Attention機構と全結合層という2つのサブ層から構成されています。Transformerの今後の展望:Transformerは、テキスト以外のデータ（画像、音声、動画など）にも応用できる可能性があり、様々な分野での活用が期待されています。また、文章生成をより効率的に行うための研究も進められています。簡単に言うと、Transformerは、人間の「注意」の仕組みに似た仕組みを使って、従来よりも高速で高精度な機械翻訳を実現した画期的な技術です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年の崖から考える我々のパーパス（序章）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/12/01/232229</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/12/01/232229</guid>
            <pubDate>Sun, 01 Dec 2024 14:22:29 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事は3-shake Advent Calendar 2024 シリーズ1の2日目の記事です。1日目はシリーズ1がYutaro ShirayamaさんのポストCloud9？クラウドIDE CoderでPlatform Engineeringを実践する2日目はシリーズ2がYoshinori Teraokaさんのvector で kubernetes の container log を CloudWatch Logs に転送するでした。なお、シリーズ2の2日目はshingo919さんの 九州旅行記（ドライブでの九州一週旅行は大変だった！）です。2025年の崖今回は「2025年の崖」について軽くご紹介したいと思います。いよいよ2025年になりますが、ITでは「2025年の崖」という言葉が存在します。2025年の崖がある中で、スリーシェイクのSreake事業部が果たす役割を考えていきたいと思います。「2025年の崖」をググったら色々出てきますが、経済産業省のレポートが1次情報源的かつわかりやすいでしょう。www.meti.go.jpなお、DXレポート ～ITシステム「2025年の崖」の克服とDXの本格的な展開～（サマリー）はスライド5枚にまとまっており、さっと読みやすいです。「2025年の崖」は要するに何なのかというと、IT人材が不足しており、レガシーシステムを保守するのに限界が来ている。DXも推進しないといけない。何とかしないともう後が無い。という状況。2015年時点で、IT人材の不足が約17万人とされていたところ、2025年には約43万人にまで上ります。既存のレガシーシステムの保守がブラックボックス、属人的になっており、DX化の足枷に → デジタル競争の敗者に技術的負債が溜まる一方保守運用の担い手不足で、サイバーセキュリティ事故が起きやすくこんな厳しい状況を打破するには、ユーザとベンダーそれぞれで対策していく必要があります。ユーザは人材・資金を保守からDXにシフトベンダーも同様に人材・資金を保守からDXにシフトベンダーはAI、アジャイル、マイクロサービス等最新技術を用いたビジネスにシフトやることはわかっていても、そう簡単にはいきません。ただし、スリーシェイクのSreake事業では、内製化支援も行っており、これまで数々の企業様の支援を行ってまいりました。Sreakeという商材は難しく、入社して1年が経った私もストンと腹落ちできる説明ができないままでしたが、「2025年の崖」をどう克服するかが我々のパーパスだと感じました。私は生成AIアプリケーション開発支援というDXを担当しておりますが、案件の推進を通して、「DX推進」を語れるようになっていきたいと思います。今回は、序章のような形で今後も2025年の崖について書いていければと思います。次の3-shake Advent Calendar 2024はシリーズ1がkechigonさんの「Google Cloud monitoringのアラートをGitHub issueに通知する」シリーズ2がtryu___さんの「kubebuilder使ってpodの監視してみた」です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[vector で kubernetes の container log を CloudWatch Logs に転送する]]></title>
            <link>https://qiita.com/yteraoka/items/df0777cdcb403a7af750</link>
            <guid>https://qiita.com/yteraoka/items/df0777cdcb403a7af750</guid>
            <pubDate>Sun, 01 Dec 2024 12:20:46 GMT</pubDate>
            <content:encoded><![CDATA[Vector とはvector は timber とともに買収され datadog がメンテナンスしているオープンソースプロジェクトのようです。(Datadog acquires Timber T…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[週間アトデ 2024-12-01]]></title>
            <link>https://blog.atusy.net/2024/12/01/atodeyomanakata/</link>
            <guid>https://blog.atusy.net/2024/12/01/atodeyomanakata/</guid>
            <pubDate>Sun, 01 Dec 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[アトデヨム、ウソジャナイ、ヨムノタノシー]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Geminiのビジネス利用でのメリットを語る]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/11/30/233039</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/11/30/233039</guid>
            <pubDate>Sat, 30 Nov 2024 14:30:39 GMT</pubDate>
            <content:encoded><![CDATA[この記事はGCP(Google Cloud Platform) Advent Calendar 2024 1日目の記事です。2024年はIT業界にとって、最も話題に上がったトピックは生成AIだったのではないでしょうか？2023年までは生成AIと家は、ChatGPTでしたが、2024年はGoogleがBardをリブランディングして、Gemini（ジェミニ）とし、しのぎを削っています。私はGoogle Cloudのパートナー企業である株式会社スリーシェイク Sreake事業部にて、Geminiを用いた生成AIアプリケーション開発に携わっており、Geminiのビジネス利用でのメリットを語りたいと思います。Gemini-1.5-Proは最大200万トークンの読み込みが可能Geminiの強みの中で、最も他の生成AIモデルと差別化できているのが、トークン数の長さです。これにより、動画解析などへの利用もしやすくなりました。Geminiはマルチモーダルなので、音声、画像、動画なども処理可能です。量の目安としては以下になります。書籍15〜20冊程度の分量動画約2時間音声約22時間BigQueryで容易にデータ分析基盤を構築可能他のクラウドには同様のサービスがなく、同じ機能を実現するためには複数のサービスを組み合わせる必要があります。AzureやAWS、オンプレのデータはそのままで読み込みだけ行う機能もあります。今お使いのシステム構成はほぼ変えず、追加構築可能となります。Geminiは他のモデルと比較してトークンあたりの利用料が安いGoogle Cloud上で稼働させるのに最適化しているためです。他社のクラウドで使える生成AIモデルは別会社のものなので、クラウドも生成AIもGoogleのGeminiによって、この点も強みです！もしもGeminiの出力結果が著作権侵害で係争が発生してもGoogle Cloudがサポート他クラウドにはないサービスです。こちらも、クラウドも生成AIも会社が揃っている強みと言えるでしょう。真実性1位！Gemini 1.5 ProがNIKKEI Digital Governanceが調査した真実性のスコアで1位となりました！以下の記事は最初日経で見れていたと思うのですが、今はNIKKEI Digital Governanceに登録しないと見れないようです。博識のGoogle､主観強いMeta　生成AIの｢真実性｣を検証上記画像は下記記事から引用させていただきました。note.com2024年もあと少し。2025年もGeminiとともに生成AIを盛り上げていきたいと思います！GCP(Google Cloud Platform) Advent Calendar 2024 次の記事はknak72さんによる企業のセキュリティ強化に！ Chrome Enterprise Premium のURLフィルタリングとマルウェアスキャン機能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[3-shake Advent Calendar 2024 やっていきます #3SHAKE]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/11/30/142710</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/11/30/142710</guid>
            <pubDate>Sat, 30 Nov 2024 05:27:10 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、nwiizoです。晩秋の肌寒さが身にしみるこの11月も今日で終わりですね。ついこの前、昨年のAdvent Calendarで記事埋めを依頼され、慌ただしく準備した記憶が鮮明です。まったく、時の流れとは不思議なものです。今年もスリーシェイクのAdvent Calendarを開催することができます。この企画が実現したのは、ひとえに社内の方々の温かいご協力の賜物であり、その事実に深い感謝の念を抱いております。qiita.comスリーシェイクは「インフラをシンプルにしてイノベーションを起こす」というビジョンのもと、クラウド、セキュリティ、データ連携、HR領域で4つのサービスを展開しているテクノロジーカンパニーです。3-shake.com先日、シリーズB追加ラウンドとしてNTTデータ、SCSKから10億円の資金調達を実施し、資本業務提携を締結するニュースが出るなど、着実に成長を続けています。prtimes.jp今年のAdvent Calendarでも、エンジニアの技術的な記事だけでなく、スリーシェイクで働く様々な職種のメンバーによる記事をお届けする予定です。エンジニア以外にも営業、カスタマーサクセス、広報、経営企画など、多様なバックグラウンドを持つメンバーたちが、それぞれの視点からスリーシェイクでの経験や日々の発見を共有していきます。なぜ技術的な記事に限定しないのか。それは、私たちが目指すイノベーションには、技術だけでなく、様々な専門性や視点が必要だと考えているからです。このAdvent Calendarを通じて、スリーシェイクがどのような会社で、どんな人たちが働いているのか、より深く知っていただければ幸いです。記事の更新情報は、スリーシェイクの公式Xアカウント（@3shake_Inc）でお知らせしていきますので、ぜひフォローをお願いします！また、Advent Calendarも合わせてチェックしていただければと思います。成長を続けるスリーシェイクの「今」を知るきっかけとして、どうぞお楽しみください！jobs-3-shake.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞]]></title>
            <link>https://sreake.com/blog/%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%80%81google-cloud-japan-%e3%81%ae%e3%80%8c-google-cloud-partner-top-engineer-2025-%e3%80%8d%e3%81%ab%e3%81%a63%e5%90%8d%e3%81%ae/</link>
            <guid>https://sreake.com/blog/%e3%82%b9%e3%83%aa%e3%83%bc%e3%82%b7%e3%82%a7%e3%82%a4%e3%82%af%e3%80%81google-cloud-japan-%e3%81%ae%e3%80%8c-google-cloud-partner-top-engineer-2025-%e3%80%8d%e3%81%ab%e3%81%a63%e5%90%8d%e3%81%ae/</guid>
            <pubDate>Thu, 28 Nov 2024 06:03:47 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）のエンジニア3名が、Google Cloud Japan が高い技術力を持ったエンジニアを表彰するプログラムである「 Google Cloud Partner Top Engineer 2025 」に選出されたことをお知らせします。The post スリーシェイク、Google Cloud Japan の「 Google Cloud Partner Top Engineer 2025 」にて3名のエンジニアが受賞 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
    </channel>
</rss>