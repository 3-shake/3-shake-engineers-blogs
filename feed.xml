<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sat, 01 Jul 2023 18:32:08 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Copilotでらくらくコードリーディング]]></title>
            <link>https://zenn.dev/nnaka2992/articles/code_reading_with_copilot</link>
            <guid>https://zenn.dev/nnaka2992/articles/code_reading_with_copilot</guid>
            <pubDate>Wed, 28 Jun 2023 14:41:21 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud RunのSidecarでJVMのmetricsの取得してみた]]></title>
            <link>https://zenn.dev/satohjohn/articles/25bc5879de7832</link>
            <guid>https://zenn.dev/satohjohn/articles/25bc5879de7832</guid>
            <pubDate>Wed, 28 Jun 2023 12:03:00 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話]]></title>
            <link>https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d</link>
            <guid>https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d</guid>
            <pubDate>Tue, 27 Jun 2023 12:31:17 GMT</pubDate>
            <content:encoded><![CDATA[この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強する…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PagerDutyがたくさん機能追加しているみたいなのでまとめてみた]]></title>
            <link>https://sreake.com/blog/pagerduty-release-updates/</link>
            <guid>https://sreake.com/blog/pagerduty-release-updates/</guid>
            <pubDate>Tue, 27 Jun 2023 06:38:36 GMT</pubDate>
            <content:encoded><![CDATA[はじめに PagerDutyはインシデントの管理、オンコール通知のサービスとして、とても優秀なサービスです。直近も、様々な新機能が出ていますが、旧機能から新機能への移行も同時に行われています。 弊社では、PagerDut […]The post PagerDutyがたくさん機能追加しているみたいなのでまとめてみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[アプリ開発者のための kubectl 講座]]></title>
            <link>https://zenn.dev/toshikish/articles/6a06017747cbba</link>
            <guid>https://zenn.dev/toshikish/articles/6a06017747cbba</guid>
            <pubDate>Mon, 19 Jun 2023 06:03:18 GMT</pubDate>
            <content:encoded><![CDATA[これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 静的検査ツール比較]]></title>
            <link>https://zenn.dev/tayusa/articles/9829faf765ab67</link>
            <guid>https://zenn.dev/tayusa/articles/9829faf765ab67</guid>
            <pubDate>Thu, 15 Jun 2023 17:00:00 GMT</pubDate>
            <content:encoded><![CDATA[対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す]]></title>
            <link>https://blog.1q77.com/2023/06/editcap/</link>
            <guid>https://blog.1q77.com/2023/06/editcap/</guid>
            <pubDate>Thu, 15 Jun 2023 14:46:42 GMT</pubDate>
            <content:encoded><![CDATA[ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。 見たい時間帯だけに絞ったファイル]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub の Reusable workflow で working-directory に変数を使う]]></title>
            <link>https://zenn.dev/toshikish/articles/be970407f02098</link>
            <guid>https://zenn.dev/toshikish/articles/be970407f02098</guid>
            <pubDate>Thu, 15 Jun 2023 05:22:24 GMT</pubDate>
            <content:encoded><![CDATA[やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する]]></title>
            <link>https://zenn.dev/tayusa/articles/1aa96e6ceb838a</link>
            <guid>https://zenn.dev/tayusa/articles/1aa96e6ceb838a</guid>
            <pubDate>Sun, 11 Jun 2023 17:19:45 GMT</pubDate>
            <content:encoded><![CDATA[はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する]]></title>
            <link>https://zenn.dev/tayusa/articles/79a3f54d8f21bc</link>
            <guid>https://zenn.dev/tayusa/articles/79a3f54d8f21bc</guid>
            <pubDate>Sun, 11 Jun 2023 17:18:13 GMT</pubDate>
            <content:encoded><![CDATA[はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Istio Canary Upgrade by Helm]]></title>
            <link>https://zenn.dev/tayusa/articles/03cf961e2409bd</link>
            <guid>https://zenn.dev/tayusa/articles/03cf961e2409bd</guid>
            <pubDate>Sun, 11 Jun 2023 17:17:37 GMT</pubDate>
            <content:encoded><![CDATA[前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Helmに入門したので、躓いたところを振り返る]]></title>
            <link>https://zenn.dev/tayusa/articles/e9285c6c4c09a1</link>
            <guid>https://zenn.dev/tayusa/articles/e9285c6c4c09a1</guid>
            <pubDate>Sun, 11 Jun 2023 17:16:25 GMT</pubDate>
            <content:encoded><![CDATA[はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes 1.27 以降のバッチ処理の改善]]></title>
            <link>https://zenn.dev/toversus/articles/d6065bea460871</link>
            <guid>https://zenn.dev/toversus/articles/d6065bea460871</guid>
            <pubDate>Thu, 08 Jun 2023 03:46:32 GMT</pubDate>
            <content:encoded><![CDATA[Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[asdf の代わりに rtx を使う]]></title>
            <link>https://blog.1q77.com/2023/06/rtx/</link>
            <guid>https://blog.1q77.com/2023/06/rtx/</guid>
            <pubDate>Wed, 07 Jun 2023 01:25:11 GMT</pubDate>
            <content:encoded><![CDATA[nodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[お前のパケットはもう死んでいる。TCPに死亡フラグを実装してみた]]></title>
            <link>https://zenn.dev/satoken/articles/golang-rfc9401</link>
            <guid>https://zenn.dev/satoken/articles/golang-rfc9401</guid>
            <pubDate>Wed, 07 Jun 2023 00:32:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめにプロトコルの仕様などIETFが発行しているRFCにはジョークRFCというものが存在しています。伝書鳩でIP通信するとか、コーヒーポットを制御するなどが有名です。鳥類キャリアによるIPHyper Text Coffee Pot Control Protocol (HTCPCP/1.0) 日本語訳今年そんなジョークRFCに、TCPに死亡フラグを実装するというRFC9401が追加されました。The Addition of the Death (DTH) Flag to TCP 日本語訳この記事ではこのTCPに死亡フラグを実装するというRFC9401を真面目に実装してみ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenAI API を利用して Terraform から構成図っぽい Mermaid を出力してくれるコマンドを作った話]]></title>
            <link>https://sreake.com/blog/mermaid-with-openai-api/</link>
            <guid>https://sreake.com/blog/mermaid-with-openai-api/</guid>
            <pubDate>Tue, 06 Jun 2023 02:44:12 GMT</pubDate>
            <content:encoded><![CDATA[前段 Sreake事業部の橋本です。 ChatGPTで話題のOpenAIのモデルは、現在画像の取り扱いはまだ発展途上です。文章から画像を作るAPIや画像入力が検討されていますが、システム運用にクリティカルに使えそうになる […]The post OpenAI API を利用して Terraform から構成図っぽい Mermaid を出力してくれるコマンドを作った話 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Redis公式のGoクライアントライブラリrueidisを試してみた]]></title>
            <link>https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2</link>
            <guid>https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2</guid>
            <pubDate>Wed, 31 May 2023 12:02:25 GMT</pubDate>
            <content:encoded><![CDATA[This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 1.5 で既存リソースからの HCL 生成ができるようになるので試してみる]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-generate-config</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-generate-config</guid>
            <pubDate>Mon, 29 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Terraform 1.5 のベータ版がリリースされています。https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta1https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta2Terraform 1.5 で追加される機能の中には以下のようなものが含まれています。import ブロックterraform plan の -generate-config-out オプションTerraform では手作業などで作成済みの既存リソースも ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OLAPデータベースを支える技術]]></title>
            <link>https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database</link>
            <guid>https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database</guid>
            <pubDate>Thu, 25 May 2023 00:02:49 GMT</pubDate>
            <content:encoded><![CDATA[今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes の運用効率化を ChatGPT-4 で実現する 障害対応編]]></title>
            <link>https://sreake.com/blog/kubernetes-operation-with-chatgpt4/</link>
            <guid>https://sreake.com/blog/kubernetes-operation-with-chatgpt4/</guid>
            <pubDate>Mon, 22 May 2023 23:46:38 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上秀一です。 Sreake事業部はSRE関連技術に強みを持つエンジニアによるコンサルテーションサービスを提供する事業部であり、私たちもSRE技術の調査と研究 […]The post Kubernetes の運用効率化を ChatGPT-4 で実現する 障害対応編 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 1.5 で追加される import ブロックの使い方]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-import-block</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-import-block</guid>
            <pubDate>Mon, 22 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[先日 Terraform v1.5.0-beta1 がリリースされました。https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta1NEW FEATURES を眺めてみると、どうやら import ブロックというものが追加されているみたいです。今までは既存のリソースを Terraform の管理下に追加するためには terraform import コマンドを使用して 1 つ 1 つ import する必要がありました。import ブロックを使用することでリソースの import を宣言的に実行することができ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform Modules で再利用できるので最高ではないでしょうか？]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346</guid>
            <pubDate>Fri, 19 May 2023 06:43:46 GMT</pubDate>
            <content:encoded><![CDATA[概要ModuleはTerraformの複数のリソースをまとめて再利用可能な単位として扱うことができます。Moduleを使うことで複雑なリソース構成を抽象化し、システムの構造の把握やリソース構成の再利用が可能になり、読みやすさや可読性が向上し、修正箇所が単一になるなどのメリットがあります。ただし、理解には初期コストが必要です。Moduleの設計では、1つの機能を持つように小さくシンプルに保つことが重要で、それが難しい場合は大抵複雑と言えます。また、公式のModuleを利用することで、自身で定義やドキュメントの整備、メンテナンスの手間を省きつつ、プロジェクトを超えて共通認識として扱えるため、Module理解のコストが減ります。しかし、どのタイミングでModuleに組み込むかの正解は、個々のプロジェクトの特性や開発チームの状況により大いに変わるでしょう。絶えず試行錯誤を繰り返しながら個々のプロジェクトごとに最適な解を見つけることが求められます。このブログではそれらの話の前にTerraform Modulesについて利用方法をまとめてみました。概要Module を利用するmoduleの使い方moduleの入力ローカルをうまく利用するmoduleの出力module を使ったときの失敗についてバージョン状態の差分は可能な限り小さくすべきアップグレードは自動されるべきファイルパスインラインブロックいい感じのデフォルトの変数最後に参考Module を利用するシステムを構築するにあたって開発、検証、本番環境をそれぞれ用意することが多いですが、Terraformを環境ごと（例：開発環境、ステージング環境、本番環境）にシンプルなWebサーバーの構成を例にしてModuleを使わないときと使ったときの構成を比較してみましょう。Terraform Configuration|--- Development Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Staging Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Production Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)この構成では、 環境毎にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されていて環境間で異なるリソース設定を利用します。一方、moduleを使用した場合の構成は以下のようになります。Terraform Configuration|--- modules|   |--- user_service_cluster|       |--- main.tf|       |   |--- VM Instances (Web servers)|       |   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|       |   |--- Load Balancer (Balance traffic among VM instances)|       |   |--- Storage Bucket (Store static content)|       |--- variables.tf|       |--- output.tf|--- Development Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)|--- Staging Environment|   |--- User-Service-Cluster Module (source: ../modules/user_service_cluster)|--- Production Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)この構成では、 user_service_cluster moduleのmain.tfファイル内にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されています。各環境はこのuser_service_clustermoduleを参照しており、環境間で共通のリソース設定を再利用します。これによって再利用性、可読性が上がり維持管理性を高める事ができると思います。moduleの使い方Terraformの moduleは、リソース設定の再利用可能な部品で、コードの抽象化と組織化をサポートします。 moduleは一つ以上のリソースを定義し、それらをまとめて管理することができます。 moduleを使用するためには、 moduleブロックをmain.tf（またはその他の.tfファイル）に追加し、そこでmoduleのソースと任意の入力変数を指定します。以下に、user_service_cluster moduleを使用するための基本的なmodule ブロックの例を示します。module "user_service_cluster" {  source = "../modules/user_service_cluster"  instance_type  = "n1-standard-1"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = "HTTP"    port     = 80  }  bucket_name = "dev-bucket"}source属性にmoduleのソースコードが存在するパスを指定しています。そして、user_service_cluster moduleが定義する各入力変数を設定しています。moduleは、そのソース内でvariableブロックを使用して入力変数を定義します。これらの入力変数は、moduleの使用者が値を提供することでmoduleの振る舞いをカスタマイズできます。また、moduleはoutputブロックを使用して出力値を定義します。出力値は、moduleの内部リソースの属性をmoduleの外部に公開するために使用されます。これにより、他のリソースやmoduleがmoduleから生成されるリソースを参照することが可能になります。module化はTerraformのコードベースを組織化し、再利用可能なコードを作成するための重要な手段です。これにより、一貫性が保たれ、メンテナンスが容易になり、エラーの可能性も低減します。moduleの入力Terraformのmoduleは再利用可能なコードブロックで、入力変数（input variables）を使用してカスタマイズできます。これらの入力変数は、moduleブロックで設定します。以下に、user_service_cluster moduleで使用する入力変数の例を示します。まず、module自体のvariables.tfファイルには以下のように入力変数を定義しますvariable "instance_type" {  description = "The type of instance to start"  type        = string  default     = "n1-standard-1"}variable "instance_count" {  description = "Number of instances to create"  type        = number  default     = 1}variable "firewall_rules" {  description = "Firewall rules for instances"  type        = map(any)  default     = {}}variable "load_balancer_config" {  description = "Configuration for load balancer"  type        = map(any)  default     = {}}variable "bucket_name" {  description = "Name of the storage bucket"  type        = string  default     = "default-bucket"}そして、このmodule を呼び出す際に、具体的な値を設定します：module "user_service_cluster" {  source = "../modules/user_service_cluster"  instance_type  = "n1-standard-1"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = "HTTP"    port     = 80  }  bucket_name = "dev-bucket"}上記の例では、user_service_cluster moduleはsourceで指定されたソースからロードされ、instance_type、instance_count、firewall_rules、load_balancer_config、bucket_nameという入力変数を設定しています。module に入力変数を提供することで、module の動作をカスタマイズし、異なる環境や条件で再利用することが可能になります。ローカルをうまく利用するTerraformのlocalsブロックを使用すると、再利用可能な内部変数をmodule内で定義することができます。localsはmodule内で共有され、module外からは参照できません。以下に、user_service_cluster module のlocalsの例を示します。この例では、HTTPポート、任意のポート、任意のプロトコル、TCPプロトコル、そして全てのIPアドレスをローカル変数として定義しています。locals {  http_port    = 80  any_port     = 0  any_protocol = "-1"  tcp_protocol = "tcp"  all_ips      = ["0.0.0.0/0"]}ローカル変数はlocal.<NAME>の形式で参照します。以下のリソース定義では、ロードバランサーリスナーとセキュリティグループの設定にローカル変数を使用しています。resource "google_compute_instance" "http" {  name         = "web-instance"  machine_type = "n1-standard-1"  network_interface {    network = "default"    access_config {      // Assign an ephemeral IP to the instance    }  }    // Other configuration...}resource "google_compute_firewall" "default" {  name    = "default-firewall"  network = "default"  allow {    protocol = local.tcp_protocol    ports    = [local.http_port]  }  source_ranges = local.all_ips}上記の例では、ロードバランサーリスナーとセキュリティグループでlocalsブロックに定義したローカル変数を参照しています。local.http_port、local.tcp_protocol、local.all_ipsを各リソースブロックで参照することで、コードがDRYに保たれ、より読みやすく、メンテナンスがしやすくなります。localsブロックを使用することで、コードの冗長性を減らし、module全体の一貫性を保つことができます。また、ローカル変数を使用することで、moduleの一部で使用する変数をmodule全体で共有することが可能になります。moduleの出力Terraformのmoduleは、出力変数（outputs）を提供できます。出力変数はmoduleの値を外部に公開するための手段で、moduleを使用しているコードからアクセスできます。また、Terraformがapplyコマンドを実行した後にこれらの値を表示することもできます。以下に、user_service_cluster moduleの出力変数の例を示します。この例では、output.tf にクラスタのURLとインスタンスのIDを出力しています。output "cluster_url" {  description = "The URL of the load balancer for the cluster"  value       = "http://${google_compute_global_address.default.address}"}output "instance_ids" {  description = "The IDs of the instances in the cluster"  value       = google_compute_instance.default.*.id}これらの出力をmodule の使用側でアクセスするためには、moduleの名前と出力の名前を組み合わせて参照します。output "user_service_cluster_url" {  description = "The URL of the load balancer for the user service cluster"  value       = module.user_service_cluster.cluster_url}output "user_service_cluster_instance_ids" {  description = "The IDs of the instances in the user service cluster"  value       = module.user_service_cluster.instance_ids}このようにして、moduleの出力変数を使用することで、moduleの内部データをmodule外部に公開し、他のTerraformコードがそのデータを参照できるようにします。出力変数はmodule間の情報共有を可能にし、moduleの再利用性を向上させます。Terraformはファイル名に特別な意味を持たせません。すなわち、variables.tfやoutputs.tfという名前は慣習にすぎないので、入力変数と出力変数を1つのファイルにまとめることも技術的には可能です。module を使ったときの失敗についてmodule を作る時に注意する点について実際にハマったことをベースに3つ紹介します。バージョンModuleのバージョンが異なると意図しない挙動やエラーが引き起こされる可能性があるので、バージョンを固定し実行環境を統一しましょう。Providerやパッケージにしても同じでバージョンを指定して再利用性を高めろ！！！状態の差分は可能な限り小さくすべきいつでもアップグレードを状態差分なしで行うことはできません。依存するリソースの変更やセキュリティ問題ができるだけ早くパッチを適用する必要があるなど、破壊的な変更を導入する必要がある場合があります。その場合、コストをどのように減らすかについて考える必要があります。状態の差分が少なければ、アップグレードのコストは少なくなります。破壊的な変更を導入するときは、それを文書化できるCHANGELOGやユーザーガイドを通じてユーザーに伝える必要がありますアップグレードは自動されるべきアップグレードは長期的に開発されるソフトウェアの最も重要なタスクの一つです。ただし、一般的に使用され、広く使用されているTerraform Moduleの場合、これは大きな問題でもあります。また、Moduleを頻繁に更新する場合、自動アップデートの機能を準備する必要があります。ユーザーにアップグレードを依頼しても、通常、彼らはより重要なタスクを行うためにそれを行うことはありません。そのため、代わりに、彼らのためにPRを作成します。PRがTerraformの差分がない場合に自動的にマージされるメカニズムを持っています。これと後方互換性の維持の組み合わせにより、最新バージョンのModuleを使用するユーザーの率を増やすことができますファイルパスTerraformのtemplatefile関数を使用する際、ファイルパスは絶対パスではなく相対パスを使用する必要があります。しかし、これはどのパスに対して相対的なのでしょうか？デフォルトでは、Terraformはパスを現在の作業ディレクトリに対して相対的に解釈します。そのため、terraform applyを実行しているディレクトリと同じディレクトリにTerraform設定ファイルがある場合、これはうまく動作します。しかし、別のフォルダに定義されたmodule内でtemplatefileを使用する場合、これは問題となります。この問題を解決するためには、path.moduleなどのパス参照を使用します。これを使用すると、module自体に対する相対パスが得られます。インラインブロックTerraformリソースの一部の設定は、インラインブロックか別のリソースとして定義することができます。インラインブロックとは、リソース内で設定する引数のことで、次の形式を持っています。resource "xxx" "yyy" {  <NAME> {    [CONFIG...]  }}ここでNAMEはインラインブロックの名前（例えば、ingress）、CONFIGはそのインラインブロックに特有の一つ以上の引数（例えば、from_portやto_port）です。しかし、インラインブロックと別のリソースを混在して使用すると、Terraformの設計上、設定が衝突し互いに上書きされてエラーが発生します。したがって、どちらか一方を使用する必要があります。moduleを作成する際には、別のリソースを使用することを常に推奨します。これらの注意点を理解しておくことで、Terraformのmoduleをより効果的に利用することができます。いい感じのデフォルトの変数完全にカスタマイズできるModuleには魅力がないです。Moduleの変数には、80％のユーザーをカバーするスマートデフォルト値を持つべきです。ただし、同時に、通常のユーザーとは異なる方法でModuleを使用するパワーユーザーのための設定も用意するべきです。変数を変更したときに何が起こるかは、ユーザーにとって明白で予測可能でなければなりません。この設定は適切に設計され、安易に浅いインターフェースを持つべきではありません最後にmoduleを活用することで、インフラストラクチャの再利用性と効率性が大幅に向上します。開発者は証明済み、テスト済み、文書化済みのインフラストラクチャの一部を再利用できるようになるため、迅速かつ確実にシステムを構築できます。例えば、マイクロサービスのデプロイメントを定義するmoduleを作成し、各チームが数行のコードで自身のマイクロサービスを管理できるようにすることが可能です。しかし、このようなmoduleを複数のチームで活用するためには、module内のTerraformコードは柔軟性と設定可能性が必要です。異なるチームや状況に応じて、ロードバランサーなしの単一インスタンスやロードバランサー付きの複数インスタンスといった、さまざまなデプロイメント要件を満たすことができます。Terraformの柔軟な構文を活用することで、より多機能なmoduleを設計し、インフラストラクチャの構築を一層楽しく効果的に行うことができます。また、どれぐらいの規模からmodule化するのかなど迷う場面が多いと思いますがこの辺は経験としか言えずにみんな雰囲気でやっているなぁって思いました。このブログが伸びたらもっと実装に基づいた話をしていこうと思います。ちなみにベストプラクティスなんかは俺にはわからない。自分を信じても…信頼に足る仲間を信じても…誰にもわからない…今の構成が一番変更しやすくて誇れるものならそれが正解なんだとおもう。実践Terraform　AWSにおけるシステム設計とベストプラクティス (技術の泉シリーズ（NextPublishing）)作者:野村 友規インプレスR&DAmazon参考Terraform: Up & Running; Writing Infrastructure As CodeDeveloper/Terraform/Configuration Language/Modulesterraform-module/terraform-module-blueprinthttps://registry.terraform.io/namespaces/terraform-aws-moduleshttps://registry.terraform.io/namespaces/terraform-google-modulesHashiCorp LearnModule Creation - Recommended PatternAWSとTerraformで学ぶプロダクションレディなKubernetes 技術の泉シリーズ (技術の泉シリーズ（NextPublishing）)]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLab トラブル事例紹介]]></title>
            <link>https://sreake.com/blog/gitlab-trouble-case-study/</link>
            <guid>https://sreake.com/blog/gitlab-trouble-case-study/</guid>
            <pubDate>Tue, 16 May 2023 02:23:30 GMT</pubDate>
            <content:encoded><![CDATA[本ドキュメントでは、トラブルシューティングの事例を取り上げ、それぞれのトラブルの原因調査の流れと判明した原因、解決方法について記載します。 また、トラブルシューティングを円滑に進められるように心がけていることをご紹介しま […]The post GitLab トラブル事例紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go で GitHub CLI 拡張機能を作る]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-cli-extension-in-go</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-cli-extension-in-go</guid>
            <pubDate>Mon, 15 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[先日 gh-grass という Go 製の GitHub CLI 拡張機能を開発してみたのですが、意外と簡単にできたので手順のメモです。gh-grass については次の記事をご参照ください。https://zenn.dev/kou_pg_0131/articles/gh-grass-introduction 拡張機能を作成する!GitHub CLI がインストールされている必要があります。GitHub CLI のインストール方法については GitHub CLI 公式リポジトリの README をご参照ください。まずは gh extension create を次のように...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[現在のDremelの実装を解説した論文を読みました ]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/05/15/111420</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/05/15/111420</guid>
            <pubDate>Mon, 15 May 2023 02:14:20 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Connection draining for Service type LoadBalancer]]></title>
            <link>https://zenn.dev/toversus/articles/1682d275ef1bb7</link>
            <guid>https://zenn.dev/toversus/articles/1682d275ef1bb7</guid>
            <pubDate>Thu, 11 May 2023 09:43:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめにService リソースは Kubernetes のサービス検出を支えるコアリソースです。Service のデータプレーンとして kube-proxy を使用している場合は、各ノード上の iptables や ipvs を設定することで L4 負荷分散を実現しています。Kubernetes は、結果整合性 (Eventual Consistency) の上に成り立つ分散システムです。Kubernetes のコントロールプレーンが Pod を削除する時に、全てのノード上のルーティングルールを更新してから Pod を削除したりはしません。削除中の Pod にもトラフィックが流...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2022 年の Accelerate State of DevOps Report の内容をまとめてみた]]></title>
            <link>https://sreake.com/blog/accelerate-state-of-devops-report-2022/</link>
            <guid>https://sreake.com/blog/accelerate-state-of-devops-report-2022/</guid>
            <pubDate>Thu, 11 May 2023 05:07:56 GMT</pubDate>
            <content:encoded><![CDATA[１．はじめに Sreake 事業部でインターンしている村山です。インターンをするにあたり、DevOps の理解と最近の動向を掴むことが必要であると感じ、Accelerate State of DevOps Report  […]The post 2022 年の Accelerate State of DevOps Report の内容をまとめてみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TiDBで学ぶNewSQLのアーキテクチャ for Beginners]]></title>
            <link>https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner</link>
            <guid>https://zenn.dev/nnaka2992/articles/learning_tidb_internal_for_beginner</guid>
            <pubDate>Thu, 11 May 2023 01:18:19 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事ではNewSQLの特徴であるノード間の分散とトランザクションや分断耐性などがTiDBではどのような技術によって実現されているかを説明することを目的としています。Spannerの論文が2012年に発表されてから10年以上の年月が流れ、優れた論文や実装ドキュメント、個人による解説ブログなど技術的詳細について述べた資料は多くあります。加えてこの記事を入門的なものと位置づけているため各コンポーネントを網羅的に解説するというよりは、キーコンセプトをどのように実装しているのかを実験を混じえながら動作の実現方法の解説を中心に扱います。また今回はTiDBをベースに説明し...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub の Secret scanning’s push protection を試してみる]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-secret-scannings-push-protection</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-secret-scannings-push-protection</guid>
            <pubDate>Wed, 10 May 2023 10:00:00 GMT</pubDate>
            <content:encoded><![CDATA[GitHub の Secret scanning's push protection がパブリックリポジトリで無料で使えるようになりました 🎉🎉🎉https://github.blog/changelog/2023-05-09-secret-scannings-push-protection-is-available-on-public-repositories-for-free/Secret scanning's push protection を使うと、例えば AWS のアクセスキーなどといったシークレットをリポジトリへ push するのをブロックすることができます。シークレッ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[はてなブログのコードブロックを”クリップボードにコピーする方法”について]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/05/09/181943</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/05/09/181943</guid>
            <pubDate>Tue, 09 May 2023 09:19:43 GMT</pubDate>
            <content:encoded><![CDATA[はてなブログの設定から、Markdown記法で書いた記事にコードブロックのコピーボタンを自動的に追加することができます。また、こちらのブログは完全に非公式ですし自分のブログ以外では試してません。🦾 デザインの設定まず、はてなブログの管理画面にログインし、デザイン設定を開きます。🦾 CSS の設定を行うデザイン設定で、「カスタマイズ」タブをクリックし、「デザインCSS」を開きます。ここで、先ほど紹介したコピーボタンのスタイルを追加します。pre.code {  position: relative;}.copy-button {  position: absolute;  top: 4px;  right: 4px;  display: inline-block;  padding: 8px 16px;  border: none;  border-radius: 4px;  background-color: #1e90ff;  color: #ffffff;  cursor: pointer;  font-size: 14px;  font-weight: bold;  text-decoration: none;  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);  transition: background-color 0.3s, box-shadow 0.3s;  opacity: 0;  transition: opacity 0.3s;}pre.code:hover .copy-button {  opacity: 1;}.copy-button:hover {  background-color: #2980b9;  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.4);}.copy-button:focus {  outline: none;}.copy-button:active {  box-shadow: none;  transform: translateY(2px);}🦾 フッターHTMLの設定を行う 次に、「カスタマイズ」タブの「フッターHTML」に、以下のコードを追加します。<script>  document.addEventListener('DOMContentLoaded', function() {    // コードブロックを取得    var codeBlocks = document.querySelectorAll('pre.code');        // すべてのコードブロックにコピーボタンを追加    for (var i = 0; i < codeBlocks.length; i++) {      var copyButton = document.createElement('button');      copyButton.className = 'copy-button';      copyButton.textContent = 'Copy code';      copyButton.onclick = function() {        var codeElem = this.parentNode.querySelector('code') || this.parentNode;        var textArea = document.createElement('textarea');        textArea.value = codeElem.textContent.replace(/Copy code$/, ''); // "Copy code" テキストを削除        document.body.appendChild(textArea);        textArea.select();        document.execCommand('copy');        document.body.removeChild(textArea);      }      codeBlocks[i].appendChild(copyButton);    }  });</script>🔍 確認していくhttps://syu-m-5151.hatenablog.com/entry/2023/04/11/084428 にて確認]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[リッチなプログレスバー付きの sleep コマンド「slp」の紹介]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/slp-introduction</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/slp-introduction</guid>
            <pubDate>Mon, 08 May 2023 09:32:10 GMT</pubDate>
            <content:encoded><![CDATA[リッチなプログレスバー付きの sleep コマンドである slp を作りました。https://github.com/koki-develop/slpこういうのこの記事では slp のインストール方法 ~ 使い方についてまとめます。インストール使い方まとめ インストールHomebrew を使用している場合は brew install でインストールできます。$ brew install koki-develop/tap/slpもしくは、 slp は Go で作られているため go install でインストールすることもできます。$ go install g...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[クエリオプティマイザの精度を検証した論文を読みました]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/05/08/111343</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/05/08/111343</guid>
            <pubDate>Mon, 08 May 2023 02:13:43 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2015年に発表されたクエリオプティマイザにおけるカーディナリティ推定とコストモデル、列挙アルゴリズムの貢献度を評価した論文を読んでいきます。How Good Are Query Optimizers, Really?著者についてViktor Leis、Andrey Gubichev、Atanas Mirchev、Peter Boncz、Alfons Kemper、Thomas Neumannらのグループによる論文。ほとんどのメンバーはDBMSにおける最適化について研究しているが、Atanas Mirchevはより統計や探索といった最適化よりの研究をしている。問題意識良い結合順序を見つけることはクエリの性能に対して大きな影響を与えるため、熱心に研究されてきた。古典的なクエリ最適化のアプローチでは以下のステップで動的計画方に基づいた最適化を行なう。1. 有効な結合順序の列挙1. カーディナリティ推定値を入力としたコストモデルの選択理論的にはカーディナリティとコストモデルの推定値が正確であれば、最適なクエリプランを選択することができる。しかし現実にはカーディナリティ推定は一様性や独立性といった単純化された仮定に基づいており、しばしばそのような仮定は間違っているため悲惨な計画を作成する。手法この論文ではカーディナリティ推定器の評価と正確なコストモデルの重要性の評価、そして列挙された結合順序の空間がどの程度影響するのかを以下の方法で検証し、貢献を行なっている。1. IMDBデータを用いたJoin Order BenchmarkというJOINにフォーカスしたベンチマークによる評価を行なう1. 実世界のデータセットにおける現実的なクエリを用いたE2Eの検証を行なう。1. クエリ性能に対するカーディナリティ・コストモデル・列挙アルゴリズムの貢献度を定量化し、最適なクエリプラン生成のためのガイドラインを策定している。作業時間read29:3829:38author33:083:30summary48:4414:36感想時間が無くまとめ途中で切り上げてしまった。やらないよりマシではあるものの、ちゃんと纏めるときにくらべて理解度に影響が出そうなので時間に余裕を持っておきたい。内容自体はGW中にPostgreSQLの実装を読んでいたこともあり、わりと理解しやすかった。]]></content:encoded>
        </item>
    </channel>
</rss>