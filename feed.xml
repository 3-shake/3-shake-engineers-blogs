<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Wed, 03 Jul 2024 18:32:46 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[soci-snapshotter によるコンテナの起動時間削減について]]></title>
            <link>https://sreake.com/blog/container-lazy-pull-soci-snapshotter/</link>
            <guid>https://sreake.com/blog/container-lazy-pull-soci-snapshotter/</guid>
            <pubDate>Wed, 03 Jul 2024 09:04:51 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 近年、機械学習を使ったアプリケーションの需要が高まっており、Kubernetes と GPU を組み合わせて使うパターンが多く存在します。その中で問題となることの 1 つが、コンテナイメージのサイズが大きくなる […]The post soci-snapshotter によるコンテナの起動時間削減について first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[space-agonを通して触るゲームインフラ]]></title>
            <link>https://sreake.com/blog/learn-game-infrastructure-from-space-agon/</link>
            <guid>https://sreake.com/blog/learn-game-infrastructure-from-space-agon/</guid>
            <pubDate>Wed, 03 Jul 2024 09:04:48 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake 事業部でインターンをしている小川です。主にパブリッククラウド周辺に触れながら、 Kubernetes 関連の OSS の技術検証・調査をしています。 本調査では、Agones と Open Mat […]The post space-agonを通して触るゲームインフラ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerでもpivotがしたい!!]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/8c70b7bfa0cef4</guid>
            <pubDate>Tue, 02 Jul 2024 14:05:01 GMT</pubDate>
            <content:encoded><![CDATA[whatLooker上でpivotテーブルができるかを調べてやってみたメモ Q． Lookerでpivotできるの…？A.できるhttps://www.cloudskillsboost.google/course_templates/323/video/432948?locale=jaLooker自身の仕様上、ExcelやLooker Studioのような操作感と少し違う点に注意。 対応グラフ表グラフ表グラフ(レガシー) やってみるExplorerを利用してできるので、簡単なデータを入れたテーブルを用意してやってみる。 利用環境データソース:...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[マイクロサービスの現場からプラットフォームエンジニアリングの可能性を探る！]]></title>
            <link>https://speakerdeck.com/abnoumaru/maikurosabisunoxian-chang-karapuratutohuomuenziniaringunoke-neng-xing-wotan-ru</link>
            <guid>https://speakerdeck.com/abnoumaru/maikurosabisunoxian-chang-karapuratutohuomuenziniaringunoke-neng-xing-wotan-ru</guid>
            <pubDate>Fri, 28 Jun 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[開発生産性Conference 2024に登壇したときの資料です。技術的な内容は後半を担当してくれた https://speakerdeck.com/hiroki_hasegawa/marutipurodakutonozu-zhi-demaikurosabisuakitekutiyawozhi-erucicdpuratutohuomushe-ji にまかせています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[運用者の各領域で向き合うLLM]]></title>
            <link>https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm</link>
            <guid>https://speakerdeck.com/nwiizo/yun-yong-zhe-noge-ling-yu-dexiang-kihe-ullm</guid>
            <pubDate>Fri, 28 Jun 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[運用者の各領域で向き合うLLM というタイトルで登壇しました。イベント名: Cloud Operator Days Tokyo 2024 イベントURL:https://cloudopsdays.com/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ReckonerとATBeX Service LinkのGCP接続を検証してみた]]></title>
            <link>https://sreake.com/blog/reckoner-atbex-service-link-gcp/</link>
            <guid>https://sreake.com/blog/reckoner-atbex-service-link-gcp/</guid>
            <pubDate>Tue, 25 Jun 2024 07:15:31 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部のsatokenです。 普段はお客様向けのSRE案件も担当していますが、弊社SaaSのReckonerのSREも兼務しています。 これまでReckonerからDataソースにアクセスするときは […]The post ReckonerとATBeX Service LinkのGCP接続を検証してみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go開発者のための遊び場を用意する - Kindで始めるKubernetesの開発環境構築]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/06/21/135855</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/06/21/135855</guid>
            <pubDate>Fri, 21 Jun 2024 04:58:55 GMT</pubDate>
            <content:encoded><![CDATA[はじめにKind (Kubernetes in Docker) は、ローカル環境でKubernetesクラスタを簡単に構築できるツールです。そう、「簡単に」と言いましたが、「簡単」の定義は人によって大きく異なりますから。ある人にとっては「簡単」でも、他の人には「アラート対応を猫に教えるくらい難しい」かもしれません。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonさあ、気軽に「簡単な」Kubernetes体験の世界へ飛び込みましょう。途中で迷子になっても、パニックにならないでください。結局のところ、私たちプログラマーは迷子になることが仕事なのですから。サンプルコード動いているものをおいておくと記事の安心感と信頼性に繋がるので置いておきます。github.comKind公式ドキュメントkind.sigs.k8s.io環境情報環境としてはLimaを利用しております。syu-m-5151.hatenablog.com参考リンクKindクラスタの作成ローカルイメージのロードKindクラスタの設定KindのネットワーキングKindでの永続ボリュームの使用Kindのセットアップと基本的な使用方法KindのインストールKindはHomebrewやバイナリのダウンロード、Go言語を使用したインストールなど複数の方法でインストールすることができます。kind.sigs.k8s.io私はbrew で入れているので一応、コマンド記載しときます。brew install kind基本的なクラスタの作成最も基本的なKindクラスタを作成するには、以下のコマンドを使用します。kind create clusterこれにより、単一ノードのKubernetesクラスタが作成されます。カスタム設定でのクラスタ作成より詳細な設定を行う場合は、YAML設定ファイルを使用します。# kind-config.yamlkind: ClusterapiVersion: kind.x-k8s.io/v1alpha4nodes:- role: control-plane- role: worker- role: workerこのファイルを使用してクラスタを作成するにはkind create cluster --config kind-config.yamlクラスタの管理クラスタの一覧を表示：kind get clusters特定のクラスタを削除：kind delete cluster --name cluster-name特定のクラスタのkubeconfigを取得：kind get kubeconfig --name cluster-name1. Skaffoldとの統合による高速な開発サイクルの実現ホットリロード可能なローカル開発環境は、DockerとAirの組み合わせで構築できますが、SkaffoldとKindを用いることで、Kubernetes環境で同等の機能を持つ開発環境を実現することも可能です。skaffold.devサービスのソースコード変更が分かりやすければ正直なんでも良いのでこちらです。// main.gopackage mainimport (    "fmt"    "net/http")func main() {    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, "Hello, World from Go!")    })    http.ListenAndServe(":8080", nil)}Dockerfileの作成go.mod のバージョンとベースイメージがズレているとエラーが出るので修正しなきゃいけないですわねー# DockerfileFROM golang:1.22 as builderWORKDIR /app# Copy go mod and sum filesCOPY go.mod ./# Download all dependencies. Dependencies will be cached if the go.mod and go.sum files are not changedRUN go mod tidy# Copy the source from the current directory to the Working Directory inside the containerCOPY . .# Build the Go appRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o go-app .FROM alpine:latest  RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /app/go-app .CMD ["./go-app"]Kubernetes設定ファイルの作成deployment.yaml にServiceも入れてます。# k8s-deployment.yamlapiVersion: apps/v1kind: Deploymentmetadata:  name: go-appspec:  replicas: 1  selector:    matchLabels:      app: go-app  template:    metadata:      labels:        app: go-app    spec:      containers:      - name: go-app        image: go-app        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: go-appspec:  type: NodePort  ports:  - port: 8080    targetPort: 8080  selector:    app: go-appSkaffold設定ファイルの作成Skaffold設定ファイルの作成します。プロジェクトのルートディレクトリに skaffold.yaml ファイルを作成します。Dockerfileのビルドとkubectl でのデプロイの両方をやってくれます。# skaffold.yaml# Skaffoldの設定ファイル# このファイルはDockerイメージのビルドとKubernetesへのデプロイを自動化しますapiVersion: skaffold/v2beta26kind: Config# ビルド設定build:  artifacts:  - image: go-app  # ビルドされるイメージの名前    context: .     # ビルドコンテキストのパス（通常はプロジェクトのルートディレクトリ）    docker:      dockerfile: Dockerfile  # 使用するDockerfileの名前# デプロイ設定deploy:  kubectl:    manifests:    - k8s-*.yaml  # デプロイに使用するKubernetesマニフェストファイルのパターン# 注意点:# 1. `go-app`はあなたのアプリケーション名に合わせて変更してください。# 2. Dockerfileがルートディレクトリにない場合は、パスを適切に調整してください。# 3. `k8s-*.yaml`は実際のマニフェストファイル名のパターンに合わせて変更してください。# 4. 必要に応じて、プロファイルやテスト設定を追加することができます。アプリケーションの実行とテストKindクラスタを作成し、Skaffoldを起動してます。kind create clusterskaffold dev --port-forwardこの後、main.goやDockerfileを編集してください。ファイルを保存すると、Skaffoldが自動的に以下の処理を行います。変更を検知新しいDockerイメージをビルドビルドしたイメージをKindクラスタにロードアプリケーションを再デプロイ変更の確認ブラウザやcurlコマンドを使用して、アプリケーションにアクセスし、変更が反映されていることを確認します。curl http://localhost:80802. マイクロサービスアーキテクチャのシミュレーションSkaffoldを使用して、2つのGoマイクロサービスを含む環境をKindでシミュレートします。Kindクラスタの作成# kind-multi-node.yamlkind: ClusterapiVersion: kind.x-k8s.io/v1alpha4nodes:- role: control-plane  extraPortMappings:  - containerPort: 30000    hostPort: 8080  - containerPort: 30001    hostPort: 8081- role: worker- role: workerデプロイじゃいkind create cluster --config kind-multi-node.yamlサービスのソースコード その1// service-a/main.gopackage mainimport (    "fmt"    "net/http")func main() {    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, "Hello from Service A!")    })    http.ListenAndServe(":8080", nil)}サービスのソースコード その2// service-b/main.gopackage mainimport (    "fmt"    "net/http")func main() {    http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {        fmt.Fprintf(w, "Hello from Service B!")    })    http.ListenAndServe(":8081", nil)}Dockerfileの作成各サービスのディレクトリに以下のDockerfileを作成します。# service-a/Dockerfile と service-b/DockerfileFROM golang:1.22 as builderWORKDIR /appCOPY go.mod .COPY main.go .RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o main .FROM alpine:latest  RUN apk --no-cache add ca-certificatesWORKDIR /root/COPY --from=builder /app/main .CMD ["./main"]Kubernetes設定ファイルの作成service-aとservice-bのファイルを適切なディレクトリに設置します。# k8s-manifests.yamlapiVersion: apps/v1kind: Deploymentmetadata:  name: service-aspec:  replicas: 1  selector:    matchLabels:      app: service-a  template:    metadata:      labels:        app: service-a    spec:      containers:      - name: service-a        image: service-a        ports:        - containerPort: 8080---apiVersion: v1kind: Servicemetadata:  name: service-aspec:  type: NodePort  ports:  - port: 8080    targetPort: 8080    nodePort: 30000  selector:    app: service-a---apiVersion: apps/v1kind: Deploymentmetadata:  name: service-bspec:  replicas: 1  selector:    matchLabels:      app: service-b  template:    metadata:      labels:        app: service-b    spec:      containers:      - name: service-b        image: service-b        ports:        - containerPort: 8081---apiVersion: v1kind: Servicemetadata:  name: service-bspec:  type: NodePort  ports:  - port: 8081    targetPort: 8081    nodePort: 30001  selector:    app: service-bSkaffold設定ファイルの作成プロジェクトのルートディレクトリに skaffold.yaml ファイルを作成します。# skaffold.yamlapiVersion: skaffold/v2beta29kind: Configbuild:  artifacts:  - image: service-a    context: service-a    docker:      dockerfile: Dockerfile  - image: service-b    context: service-b    docker:      dockerfile: Dockerfiledeploy:  kubectl:    manifests:    - k8s-manifests.yamlアプリケーションの実行とテストSkaffoldを使用してアプリケーションをビルド、デプロイ、そして監視します。skaffold dev --port-forwardこのコマンドは以下の動作を行います。- サービスAとサービスBのDockerイメージをビルド- ビルドしたイメージをKindクラスタにロード- Kubernetes マニフェストを適用してサービスをデプロイ- ポートフォワーディングを設定- ファイルの変更を監視し、変更があれば上記のプロセスを再実行確認別のターミナルウィンドウで以下のコマンドを実行して、サービスにアクセスできることを確認します。curl http://localhost:8080  # Service Acurl http://localhost:8081  # Service Bこれで、2つのマイクロサービスがKindクラスタ上で実行され、Skaffoldによって自動的に管理されます。ソースコードを変更すると、Skaffoldが自動的に再ビルドとデプロイを行います。おわりに本記事では、Kind（Kubernetes in Docker）を使用したGoアプリケーションの開発について詳しく解説しました。Kindの基本的なセットアップから、Skaffoldとの統合による高速な開発サイクルの実現、そしてマイクロサービスアーキテクチャのシミュレーションまで、実践的なアプローチで解説しました。ここで学んだtipsとセットアップ方法を活用することで、アプリケーション開発者は以下の利点を得ることができます効率的な開発サイクル: Skaffoldとの統合により、コード変更から再デプロイまでのプロセスが自動化され、開発速度が大幅に向上します。本番環境に近いテスト環境: Kindの柔軟性により、マイクロサービスアーキテクチャや複雑なネットワーク構成を、ローカル環境で簡単にシミュレートできます。Kindの強力な機能を利用することで、本番環境に近い状態でアプリケーションをテストし、開発サイクルを迅速化できます。これは、特にクラウドネイティブな開発において非常に重要です。今後のステップとして、以下のような発展的なトピックにチャレンジすることをおすすめします。まぁ一番は俺が書けって話ですけどね。本番環境に近いテスト環境の構築設定管理の簡素化データの永続化セキュリティの強化Kindを使用したCI/CDパイプラインの構築サービスメッシュ（例：Istio）のKind環境への導入Kindを使用したカオスエンジニアリングの実践マルチクラスタ環境のシミュレーションとフェデレーション最後に、Kindはあくまでもローカル開発とテストのためのツールであることを忘れないでください。本番環境への移行時には、クラウドプロバイダーやマネージドKubernetesサービスの特性を考慮し、適切な調整を行う必要があります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Packer + Ansible で ftp-server: No such file or directory でコケたら]]></title>
            <link>https://qiita.com/yteraoka/items/9576de9392fc5db6053a</link>
            <guid>https://qiita.com/yteraoka/items/9576de9392fc5db6053a</guid>
            <pubDate>Wed, 19 Jun 2024 15:32:52 GMT</pubDate>
            <content:encoded><![CDATA[事象久々に packer + ansible で AWS の AMI を作成しようとしたら次のようなエラーでコケてしまいました。fatal: [default]: UNREACHABLE! =>…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[知識のunlearningをちゃんとやる - Learning Go, 2nd Editionの読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/06/19/154201</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/06/19/154201</guid>
            <pubDate>Wed, 19 Jun 2024 06:42:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめにGo言語の入門書として広く知られている"Learning Go"の第二版が発刊されました。第一版を読んだ際、Go言語のシンプルさと美しく整然とした構文に感銘を受けたものの、常に進化を続けているため、過去の知識にとらわれることなく、新しい概念や手法を柔軟に取り入れていく姿勢が何よりも重要であると感じました。learning.oreilly.comソフトウェアエンジニアとして成長を続けるには、アンラーニング(unlearning)の精神、つまり過去の知識にとらわれることなく、絶え間なく新しい知識を吸収し続ける姿勢が欠かせません。どんな達人でも鍛錬を怠れば老いるのが自明ですから、知識の新陳代謝のための学び直しが必要不可欠なのです。この第二版では、中身がかなり改訂されており、Go言語のベストプラクティスがより深く理解できるようになっています。特に、ジェネリクスのサポートについての記述が追加されているのが嬉しいポイントです。これまでのGoの型システムの制限を克服し、より柔軟で表現力の豊かなコードが書けるようになるはずです(使えるようになるとは言っていません)。Unlearn（アンラーン）　人生100年時代の新しい「学び」作者:柳川 範之,為末 大日経BPAmazonまた、並行処理やメモリ管理、パフォーマンスチューニングなどの話題も充実しており、Go言語でシステム開発を行う上で必須の知識が得られます。サンプルコードや練習問題を動かしながら、Go言語の深淵に迫っていくことができます。本書は初心者には基礎知識と理解を、中級者にはステップアップのための明確な道筋を、そして上級者にはさらなる深い洞察と広がりを教えてくれる。一冊だと思います。ちなみに第一版には日本語版もあります。初めてのGo言語 ―他言語プログラマーのためのイディオマティックGo実践ガイド作者:Jon Bodnerオーム社Amazonこの本を読みながら、過去の知識にとらわれずに新しい概念を柔軟に取り入れる姿勢の重要性を改めて実感しました。Go言語はシンプルな設計思想を貫きながらも、常に進化を続けています。私自身もGo言語を使った開発を行っており、アンラーニングの精神を持ち続け、新しい知識を積極的に吸収していく必要があります。そうすることで、Go言語を最大限に活用し、よりよいソフトウェアを作り上げていくことができるはずです。個人的におすすめの書籍としては、「実用 Go言語―システム開発の現場で知っておきたいアドバイス」もあります。Go言語を実務で使う際の実践的なアドバイスが詰まっており、ぜひ合わせて読むことをおすすめします。実用 Go言語 ―システム開発の現場で知っておきたいアドバイス作者:渋川 よしき,辻 大志郎,真野 隼記オライリージャパンAmazonこの本の構成序文では、第1版から第2版への変更点、本書の対象読者、表記規則、サンプルコードの使用方法などが説明されています。第1章でGo開発環境のセットアップ方法が解説され、第2章から第5章でGo言語の基本的な要素である型、宣言、複合型、ブロック、シャドーイング、制御構文、関数などが取り上げられます。第6章から第8章では、ポインタ、型、メソッド、インターフェース、ジェネリクスといったGo言語の特徴的な機能が詳しく説明されています。第9章ではエラー処理、第10章ではモジュール、パッケージ、インポートが解説されます。第11章でGoのツールエコシステムが紹介され、第12章でGo の並行処理機能が取り上げられています。第13章と第14章では標準ライブラリとcontextパッケージについて詳しく説明されています。さらに、第15章でテストの書き方、第16章でreflect、unsafe、cgoといったより高度なトピックが解説されています。最後に演習問題が用意されており、Go言語を体系的に学ぶことができる構成となっています。Chapter 1. Setting Up Your Go Environment「Chapter 1. Setting Up Your Go Environment」を読んで、改めてGo言語の開発環境について理解を深めることができました。私自身、以前からGo言語を使っていましたが、この章を通して新たな発見もありました。私は普段、開発環境としてNeovimを使っています。VSCodeやGoLandのような統合開発環境を目指していろいろやっているのですがデフォルトでここまでやれると羨ましくも思います。ただ、Neovimでもプラグインを使えば、コード補完やフォーマットなどの基本的な機能は十分に使えるので、不便は感じていません。設定ファイルはこちらです。アンラーンが大事とか言いながら絶対に譲らないのは草です。github.comそれでも、VSCodeやGoLandのようなIDEの充実ぶりには驚かされました。特にデバッガやリファクタリング機能は、本格的な開発では重宝しそうです。私としては、プロジェクトの規模や用途に応じて、適切な開発環境を選ぶことが大切だと思いましたが別に変える予定はありまえせん。The Go Playgroundについては、以前から愛用していました。サンプルコードを試したり、コードを共有したりするのに非常に便利ですよね。複数のファイルを扱うこともできるので、ちょっとしたプロトタイプを作るのにも役立ちます。ただ、機密情報をPlaygroundに貼り付けてしまわないよう、くれぐれも注意が必要だと改めて認識しました。Makefileの活用方法については、自分でもよく使っているテクニックです。go fmtやgo vet、go buildといったコマンドを個別に実行するのは手間なので、Makefileにまとめておくことで開発の効率化が図れます。さらに、以下のようにcleanターゲットを追加しておけば、生成されたバイナリやキャッシュの削除も簡単にできて便利ですね。かつて登壇したので共有しておきます。 speakerdeck.com.DEFAULT_GOAL := build.PHONY:fmt vet buildfmt:        go fmt ./...vet: fmt        go vet ./...build: vet         go buildclean:    go clean    rm -f hello_worldGo言語の後方互換性については、開発者にとって大きなメリットだと感じています。APIの互換性が保証されているおかげで、バージョンアップによる影響を最小限に抑えられるのは、長期的なプロジェクトの維持においては特に重要なポイントだと思います。一方で、goコマンドについては後方互換性が保証されていないため、注意深くアップデートする必要があるのは確かです。moneyforward-dev.jp総じて、この章では改めてGo言語の開発環境について体系的に学ぶことができました。すでにGoを使っている人にとっても、開発環境の選択肢や、コーディングの規約、Makefileの活用など、参考になる情報が多く含まれていたと思います。実際の開発で役立つテクニックが詰まった章だったと言えるでしょう。私自身、今後もNeovimを主な開発環境として使っていく予定ですが、プロジェクトによってはVSCodeやGoLandの導入も今後も検討したいと思います。検討を重ねて検討を加速させます。みなさんは、どのような開発環境を使っているのか、そのメリットやデメリットも含めて教えていただけると嬉しいです。この章で得た知見を活かし、より効率的な環境でGoのコードを書けるようになりたいですね。次の章以降では、いよいよ言語の基本的な要素について学んでいくことになります。Goならではの特性を理解し、実践で役立てていきたいと思います。Chapter 2. Predeclared Types and Declarations「Chapter 2. Predeclared Types and Declarations」では、Go言語の組み込み型と変数宣言について詳しく解説されていました。この章を通して、Go言語の型システムと変数の扱い方について理解を深めることができました。go.devGo言語の変数宣言は、varキーワードを使う方法と:=を使う方法の2通りがあります。varを使う方法は、変数の型を明示的に指定できるので、意図が明確になります。一方、:=を使う方法は、型推論によって変数の型が自動的に決定されるので、コードがすっきりします。ただし、:=は関数内でしか使えないという制約があるので、適材適所で使い分ける必要があります。Go言語のリテラルは、デフォルトでは型を持たない（untyped）という特徴があります。これにより、リテラルを柔軟に使うことができます。例えば、整数リテラルを浮動小数点数型の変数に代入することができます。ただし、型を持たないリテラルは、デフォルトの型を持っていて、それが変数の型として使われます。定数はconstキーワードを使って宣言します。Go言語の定数は、コンパイル時に値が決定するという特徴があります。そのため、定数には数値リテラルや文字列リテラル、true/falseなどの値しか代入できません。定数は型を持つ場合と持たない場合があり、型を持たない定数はリテラルと同じように柔軟に使うことができます。変数名の付け方には、Go言語らしい流儀があります。キャメルケースを使うのが一般的で、スネークケースはあまり使われません。また、変数のスコープが小さいほど、短い名前を使うのが慣例です。例えば、forループのインデックス変数にはiやjといった1文字の名前がよく使われます。総括すると、この章ではGo言語の型システムと変数宣言について網羅的に解説されていました。Go言語の型システムは、シンプルでありながら多様な型を提供しており、柔軟性と安全性のバランスが取れていると感じました。変数宣言の方法も、varと:=の2通りがあり、使い分けることでコードの意図を明確にできます。また、リテラルと定数の扱い方にも、Go言語らしい特徴があることがわかりました。私としては、今後Go言語でコードを書く際は、この章で学んだ知識を活かして、型の選択と変数宣言を適切に行っていきたいと思います。特に、変数のスコープに応じて適切な名前を付けることは、コードの可読性を高めるために重要だと感じました。みなさんは、普段どのようなルールで変数名を付けているでしょうか。私としては、キャメルケースを使い、スコープが小さい変数には短い名前を使うようにしたいと思います。例えば、以下のように書くのがよいと思います。func main() {    n := 10    for i := 0; i < n; i++ {        fmt.Println(i)    }}ここでは、nという変数名を使って、ループの上限を表しています。また、ループ変数にはiという1文字の名前を使っています。このように、変数名を適切に付けることで、コードの意図が明確になり、可読性が高まります。Chapter 3. Composite Types「Chapter 3. Composite Types」では、Go言語の複合型について詳しく解説されていました。配列、スライス、マップ、構造体といった複合型は、Go言語でデータを扱う上で欠かせない要素です。この章を通して、Go言語の複合型の特徴と使い方について理解を深めることができました。まず、配列の扱いにくさが印象的でした。Go言語の配列は、サイズが型の一部となっているため、非常に硬直的です。関数に任意のサイズの配列を渡すことができないなど、利用シーンが限られています。そのため、ほとんどの場合は配列ではなくスライスを使うのが一般的だと学びました。スライスは、Go言語で最もよく使われるデータ構造の一つです。宣言方法は複数ありますが、makeを使ってサイズと容量を指定する方法が適切だと感じました。スライスは参照型なので、関数に渡した場合は元のスライスが変更されることに注意が必要です。また、のように、スライスから別のスライスを作る際は、意図しない部分が共有されてしまうことがあるので、注意が必要だと学びました。マップは、キーと値のペアを格納するデータ構造です。宣言時にキーの型と値の型を指定します。マップに値を格納するには、m[key] = valueのように角括弧を使います。のように、存在しないキーにアクセスしようとすると、値の型のゼロ値が返されるのが特徴的でした。また、マップはスライス同様、参照型なので、関数に渡すと元のマップが変更されることを理解しました。構造体は、任意の型のフィールドを持つ複合型です。構造体を使えば、関連するデータをまとめて扱うことができます。構造体リテラルを使えば、簡潔に構造体を初期化できます。フィールド名を指定しない場合は、宣言された順番で値を指定する必要があります。構造体は比較可能な型のフィールドのみで構成されている場合、==や!=で比較できるのが便利だと感じました。Exercisesは、学んだ内容を実践的に使う良い機会だと思います。スライスのサブスライスを作ったり、文字列のルーンにアクセスしたり、構造体を色々な方法で初期化したりと、複合型の基本的な使い方が身につきそうな課題ばかりでした。github.comこの章ではGo言語の複合型について網羅的に学ぶことができました。スライスとマップの使い方、構造体の定義方法など、データを扱う上で欠かせない知識が身についたと実感しています。特に、スライスとマップが参照型であることや、意図しないメモリ共有に注意が必要だということは、頭に入れておくべき重要なポイントだと感じました。Chapter 4. Blocks, Shadows, and Control Structures「Chapter 4. Blocks, Shadows, and Control Structures」では、Go言語のブロックスコープ、シャドーイング、制御構文について深く理解することができました。これらの概念は、Go言語でコードを書く上で避けて通れない重要なトピックです。Uber Go Style Guide も良いのでおすすめです。github.comまず、ブロックスコープについては、変数の生存期間と可視性を適切に管理するために欠かせない概念だと感じました。Go言語では、{}で囲まれた部分がブロックを形成し、そのブロック内で宣言された変数は、ブロックの外からはアクセスできません。これにより、コードの可読性が高まり、意図しない変数の変更を防ぐことができます。シャドーイングについては、内側のブロックで宣言された変数が、外側のブロックの変数を隠してしまう現象のことを指します。これは、うっかりミスを引き起こしやすいので注意が必要です。特に、forステートメントの中で変数を再宣言してしまうと、期待した結果が得られないことがあります。一方、制御構文については、if、for、switch、gotoの4つが紹介されていました。覚えることが少ないことは良いことです。なぜなら人はコードを書くより読む時間の方が一般的に長いからです。ifステートメントは、他の言語と同様に条件分岐を行うための構文ですが、Go言語では条件式の前に簡単なステートメントを書くことができるのが特徴的です。これにより、条件式で使う変数をifステートメントのスコープ内に閉じ込めることができ、コードの可読性が向上します。forステートメントは、Go言語で唯一のループ構文であり、4つの形式があります。特に、rangeキーワードを使ったループ処理は、配列やスライス、マップなどの複合型を簡単に反復処理できるので、とても便利です。switchステートメントは、式を評価し、その値に基づいて条件分岐を行う構文です。Go言語のswitchは、breakを書かなくてもフォールスルーしないのがデフォルトの挙動なので、コードの可読性が高くなります。また、式を書かずに条件式だけを列挙するブランクスイッチも用意されており、複数の条件を簡潔に表現できます。gotoステートメントについては、安易に使うとコードの可読性を下げてしまうので、慎重に使う必要があると感じました。ただし、ネストが深いループを抜けるために使うなど、限定的な状況では有用であることも分かりました。本章で学んだ制御構文を使ったコーディングの練習問題が用意されていました。ランダムな数値を生成してスライスに格納したり、forループとifステートメントを組み合わせて条件分岐を行ったりと、基本的な制御構文の使い方が身につく内容でした。解答例を見ると、GoらしいコードのベストプラクティスがEe察でき、とても勉強になりました。github.com本章のまとめとして、ブロックスコープ、シャドーイング、制御構文を適切に使いこなすことの重要性が述べられていました。特に、制御構文を適切に使いこなすことで、Goのコードの流れを思い通りに制御できるようになることが強調されていました。技術的な観点からは、forステートメントの4つの形式についての理解が深まりました。特に、rangeキーワードを使ったforステートメントは、Goでデータ構造を反復処理する上で非常に重要だと感じました。また、switchステートメントのブランクスイッチについても、複数の条件を簡潔に表現できる点が印象的でした。gotoステートメントについては、使うべきシーンを見極めるのが難しいですが、限定的な状況では有用であることが分かりました。func main() {    evenVals := []int{2, 4, 6, 8, 10, 12}    for i, v := range evenVals {        if i%2 == 0 {            fmt.Println(v, "is at an even index")        } else {            fmt.Println(v, "is at an odd index")        }    }}上のコードは、forステートメントとifステートメントを組み合わせて、スライスの要素のインデックスの偶奇を判定しています。このように、制御構文を適切に使いこなすことで、シンプルかつ読みやすいコードを書くことができます。Chapter 5. Functions「Chapter 5. Functions」では、Go言語の関数について詳しく学ぶことができました。関数は、プログラムを構成する上で欠かせない要素であり、Go言語らしい特徴を備えています。この辺は実際に手を動かさないとピンとこないので動かしていってほしいです。go.devGo言語の関数宣言は、キーワードfuncに続いて関数名、入力パラメータ、戻り値の型を指定する形式です。C言語などと同様に、複数の値を返すことができるのが特徴的でした。これにより、関数の戻り値を介してエラーを返すことが可能になり、Goらしいエラーハンドリングが実現できます。また、名前付き戻り値という機能も印象的でした。これは、関数の戻り値に名前を付けることで、関数内で直接それらの変数を操作できるようにするものです。ただし、可読性を損なわないよう、この機能は慎重に使う必要があると感じました。一方で、Go言語の関数には、可変長引数がありこれは、任意の数の引数を関数に渡すことができる機能で、fmt.Printlnなどでも使われています。また、無名関数を利用することで、関数内で動的に関数を生成することも可能です。これらの機能は、柔軟かつ表現力豊かなコードを書く上で重要だと感じました。クロージャは、Go言語の強力な機能の一つです。関数の外で定義された変数を関数内で参照し、その値を変更できるのがクロージャの特徴です。これを応用することで、関数に状態を持たせることができ、より高度なプログラミングが可能になります。例えば、sort.Sliceでは、クロージャを利用してソート条件を指定しています。また、defer文は、関数の終了時に必ず実行されるコードを登録するための機能です。これを使えば、ファイルのクローズ処理などを簡潔に記述でき、リソースの適切な管理が容易になります。deferは名前付き戻り値と組み合わせることで、エラーハンドリングにも活用できます。Go言語では、すべての型がValueセマンティクスを持つため、関数の引数として渡された変数は、常にコピーが渡されます。これにより、関数内で引数の値を変更しても、呼び出し元の変数には影響を与えません。ただし、マップやスライスは参照型なので、関数内での変更が呼び出し元に反映されるという特殊な挙動を示します。は、この違いを端的に表した例だと思います。Exercisesでは、これまで学んだ関数に関する知識を活用する問題が用意されていました。計算機のプログラムにエラーハンドリングを追加したり、ファイルの長さを返す関数を書いたりと、実践的なコーディングの練習になりました。また、クロージャを使って、プレフィックスを付ける関数を生成する問題もあり、Go言語らしい関数の使い方が身につく内容でした。github.comWrapping Upでは、この章で学んだことの総括として、Go言語の関数の特徴と、それを活かしたプログラミングの重要性が述べられていました。関数を適切に使いこなすことで、Goのコードをより効果的に構成できるようになるでしょう。技術的な観点からは、可変長引数やクロージャ、名前付き戻り値など、Go言語特有の関数の機能についての理解が深まりました。特に、クロージャを利用した関数の実装は、Go言語らしいイディオムの一つだと感じました。また、defer文についても、リソース管理やエラーハンドリングにおける有用性を実感できました。func main() {    nums := []int{1, 2, 3, 4, 5}    doubles := transform(nums, func(x int) int {        return x * 2    })    fmt.Println(doubles)}func transform(slice []int, f func(int) int) []int {    transformed := make([]int, len(slice))    for i, v := range slice {        transformed[i] = f(v)    }    return transformed}上のコードは、クロージャを利用して、スライスの各要素を変換するtransform関数の例です。このように、関数を引数として受け取ることで、柔軟な処理を実現できます。総括すると、この章ではGo言語の関数について網羅的かつ体系的に学ぶことができました。関数宣言や複数の戻り値、可変長引数など、他の言語と共通する機能に加えて、クロージャやdeferなど、Go言語特有の機能についても詳しく解説されていました。これらを適切に使いこなすことが、Goらしいコードを書く上で重要だと感じました。また、学んだ関数の機能を実際のコードに落とし込む練習ができたのも良かったです。エラーハンドリングやファイル操作など、実用的な関数の書き方が身についたと思います。関数は、プログラムを構成する上で中心的な役割を果たします。**Go言語の関数には、シンプルな書き方を維持しつつ、高度なことを実現するための機能が備わっています。Chapter 6. Pointers「Chapter 6. Pointers」は、Goプログラミングにおけるポインタの概念と活用方法を深く理解するために非常に重要な章です。ポインタは、他の言語ではしばしば難解で危険なものとして扱われることがありますが、Goではその扱いやすさと効率性が際立っています。著者は、まずポインタの基本的な文法と動作について丁寧に解説しています。ポインタは、変数が格納されているメモリアドレスを保持する特別な変数であり、アドレス演算子（&）とデリファレンス演算子（*）を用いて操作します。そして、ポインタ型の宣言方法やnilポインタの概念についても触れています。次に、著者はポインタの活用方法について、他の言語との比較を交えながら詳しく説明しています。Goでは、ポインタを使用するかどうかを開発者が選択できるため、不変性を保ちつつ、必要に応じてデータの変更を行うことができます。この柔軟性は、Goの強力な特徴の一つと言えるでしょう。また、ポインタを関数の引数や戻り値として使用する際の注意点についても言及されています。特に、nilポインタを関数に渡した場合の動作や、ポインタのコピーがもたらす影響について、具体的なコード例を用いて解説されています。さらに、著者はポインタの性能面でのメリットについても触れています。大きなデータ構造体をポインタで渡すことで、関数呼び出しのオーバーヘッドを削減できることが示されています。ただし、著者は安易なポインタの使用を戒めており、可能な限り値型を使用するべきだと主張しています。Figure 6-5. The memory layout of a slice より引用マップとスライスのポインタ実装の違いについても、詳細に解説されています。マップはポインタとして実装されているため、関数に渡すと元の変数に影響を与えますが、スライスは長さと容量の情報も含むため、より複雑な動作をします。特に、スライスの長さを変更しても元の変数には影響しないという特性は、バッファとしてスライスを活用する際に重要です。Figure 6-9. Changing the capacity changes the storage より引用メモリ割り当てとガベージコレクションについても、Goの特徴が詳しく解説されています。Goは、スタックとヒープを適切に使い分けることで、効率的なメモリ管理を実現しています。著者は、ヒープ割り当てを最小限に抑え、ガベージコレクターの負荷を減らすことの重要性を強調しています。この「機械的な共感」の考え方は、Goプログラミングにおいて非常に重要な概念だと言えます。最後に、著者はガベージコレクターのチューニング方法についても触れています。GOGCとGOMEMLIMITの環境変数を適切に設定することで、ガベージコレクションの頻度やメモリ使用量を制御できることが示されています。ポインタに関する実践的な演習問題が提供されています。Personの構造体を使ったポインタの活用や、スライスの動作の理解を深める問題など、ポインタの理解を深めるために有益な問題が用意されています。これらの演習を通して、読者はポインタの概念を実際のコードに落とし込む力を身につけることができるでしょう。この章でポインタの重要性と適切な使用方法について再確認できました。著者は、次章で扱うメソッド、インターフェース、型についても、ポインタの理解が役立つことを示唆しています。Chapter 7. Types, Methods, and Interfaces「Chapter 7. Types, Methods, and Interfaces」は、Go言語のオブジェクト指向プログラミングの特徴を理解する上で非常に重要な章です。著者は、Goが他の言語とは異なるアプローチを取っていることを強調しつつ、型、メソッド、インターフェースの使い方とベストプラクティスを丁寧に解説しています。Goの型システムは、シンプルでありながら非常に強力です。 著者は、ユーザー定義型の宣言方法や、型宣言が「実行可能なドキュメンテーション」としての役割を果たすことを説明しています。また、iotaを使った列挙型の定義方法についても触れ、iotaの適切な使用方法を示しています。メソッドについては、レシーバーの指定方法や、ポインタレシーバーとバリューレシーバーの使い分けが重要なポイントです。著者は、nilインスタンスを適切に扱うためのテクニックや、メソッドが関数としても扱えることを示し、メソッドと関数の使い分け方についても言及しています。Goのインターフェースは、型安全な「ダックタイピング（Duck typing）」を実現する強力な機能です。ダックタイピングとは、オブジェクトの 型(クラス)を明示的に宣言せずに 、オブジェクトの振る舞い(メソッド)やプロパティを利用することで、そのオブジェクトの型(クラス)を推測する手法です。。 著者は、インターフェースの暗黙的な実装がもたらす柔軟性と、明示的なインターフェースに比べた利点を詳しく説明しています。また、インターフェースとnilの関係や、インターフェースの比較可能性についても触れ、インターフェースを適切に使いこなすためのヒントを提供しています。特に印象的だったのは、「Accept Interfaces, Return Structs」というアドバイスです。関数やメソッドの引数としてインターフェースを受け取り、戻り値としてコンクリートな型を返すことで、APIの柔軟性と保守性を高めることができます。 ただし、パフォーマンスとのトレードオフにも注意が必要です。著者は、Goの暗黙的なインターフェースが、依存性の注入を容易にすることも指摘しています。サンプルコードを用いて、インターフェースを介して依存関係を外部化する方法を具体的に示しており、読者は実践的なスキルを身につけることができます。type DataStore interface {    UserNameForID(userID string) (string, bool)}type Logger interface {    Log(message string)}type SimpleLogic struct {    l  Logger    ds DataStore}func (sl SimpleLogic) SayHello(userID string) (string, error) {    sl.l.Log("in SayHello for " + userID)    name, ok := sl.ds.UserNameForID(userID)    if !ok {        return "", errors.New("unknown user")    }    return "Hello, " + name, nil}func (sl SimpleLogic) SayGoodbye(userID string) (string, error) {    sl.l.Log("in SayGoodbye for " + userID)    name, ok := sl.ds.UserNameForID(userID)    if !ok {        return "", errors.New("unknown user")    }    return "Goodbye, " + name, nil}これまで学んだ概念を応用する練習問題が用意されています。バスケットボールリーグを管理するプログラムを作成する過程で、型、メソッド、インターフェースの使い方を体験的に学ぶことができます。これらの演習を通して、読者はGoの型システムに対する理解を深め、実践的なスキルを磨くことができると思います。章全体としてGoの型システムの特徴とベストプラクティスについて再確認しています。Chapter 8. Generics「Chapter 8. Generics」は、Go言語におけるジェネリクスの概念と使用方法を深く理解するために非常に重要な章です。ジェネリクスは、Go言語の型システムに大きな変革をもたらす機能であり、コードの再利用性と柔軟性を大幅に向上させることができます。 著者は、この章を通して、ジェネリクスの必要性、基本的な使い方、制限事項、そして適切な活用方法について丁寧に解説しています。まず、著者はジェネリクスの必要性について説明しています。Go言語は静的型付け言語であり、関数やデータ構造の型を明示的に指定する必要があります。しかし、異なる型に対して同じロジックを適用したい場合、ジェネリクスがないと、コードの重複が避けられません。これは、コードの保守性を低下させ、バグを引き起こす可能性があります。ジェネリクスを使うことで、型に依存しないアルゴリズムを一度だけ実装し、様々な型に対して再利用できるようになります。次に、著者はジェネリクスの基本的な使い方について説明しています。Go言語のジェネリクスは、型パラメータを使って実現されます。型パラメータは、関数やデータ構造の定義時に指定し、具体的な型の代わりに使用します。型パラメータには制約を設けることができ、許容する型を限定することができます。 これにより、コンパイル時の型安全性を確保しつつ、柔軟性を維持することができます。著者は、スタック（stack）のデータ構造を例に、ジェネリクスの使い方を具体的に示しています。ジェネリックなスタックの実装では、要素の型を型パラメータで表現し、anyとcomparableという組み込みのインターフェースを制約として使用しています。これにより、任意の型の要素を持つスタックを、一つの実装で表現できます。また、comparableを使うことで、要素の比較が必要な操作も、型安全に行えるようになります。さらに、著者はジェネリックな関数 Map 、 Reduce 、 Filter の実装を紹介しています。これらの関数は、スライスに対する一般的な操作を抽象化したもので、様々な型のスライスに適用できます。これにより、コードの重複を大幅に削減でき、アルゴリズムの本質に集中できるようになります。また、著者はジェネリクスとインターフェースの関係についても説明しています。インターフェースを型制約として使うことで、ジェネリックな型に特定のメソッドを要求できます。 これにより、より細かな制約を設けることができ、コードの安全性を高められます。さらに、インターフェース自体をジェネリック化することで、より柔軟な抽象化が可能になります。型の要素（type elements）についても詳しく解説されています。型の要素を使うことで、特定の演算子をサポートする型だけを受け入れるジェネリックな関数を定義できます。 これは、数値計算などで特に役立ちます。著者は、Integerというインターフェースを定義し、整数型に対する演算を抽象化する例を示しています。ジェネリックな関数とデータ構造を組み合わせることで、より汎用的なコードを書くことができます。著者は、バイナリツリーの例を用いて、比較関数をジェネリック化することで、任意の型に対応できるようになることを示しています。これにより、コードの再利用性が大幅に向上します。type OrderableFunc[T any] func(t1, t2 T) intfunc NewTree[T any](f OrderableFunc[T]) *Tree[T] {    return &Tree[T]{        f: f,    }}comparableインターフェースとジェネリクスの関係についても、注意点が説明されています。comparableを型制約として使う場合、比較可能でない型が渡されるとランタイムパニックが発生する可能性があります。これを防ぐためには、コンパイル時に型チェックを行う必要があります。また、著者はジェネリクスの現在の制限についても言及しています。Go言語のジェネリクスは、他の言語に比べてシンプルな設計になっており、特殊化やカリー化、メタプログラミングなどの機能は提供されていません。 これは、Go言語のシンプルさと読みやすさを維持するための判断だと考えられます。ジェネリクスの導入により、Go言語のイディオマティックな書き方にも変化が生じます。著者は、float64を汎用的な数値型として使う慣習が廃れ、anyがinterface{}に取って代わることを指摘しています。また、ジェネリクスを使うことで、異なる型のスライスを統一的に扱えるようになります。ただし、既存のコードをジェネリクスに置き換える際は、慎重に行う必要があります。パフォーマンスへの影響については、まだ評価が定まっていません。一部のケースでは、ジェネリクスを使うことでコードが遅くなることが報告されています。しかし、ソートアルゴリズムでは、ジェネリクスを使うことで速度が向上するという報告もあります。著者は、可読性と保守性を重視しつつ、必要に応じてベンチマークを取ることを推奨しています。標準ライブラリへのジェネリクスの導入は慎重に行われています。 当初はanyとcomparableのみが追加されましたが、Go 1.21からは、スライスとマップ、並行処理に関する関数が追加されています。これらの関数は、よく使われる操作を抽象化し、コードの重複を削減するのに役立ちます。今後も、ジェネリクスを活用した新しい関数やデータ型が追加されていくことが期待されます。最後に、著者はジェネリクスによって可能になる将来の機能について言及しています。ジェネリクスを基礎として、より高度な型システムを構築できる可能性があります。 例えば、和型（sum types）を導入することで、型安全性を高めつつ、柔軟なデータ表現が可能になります。また、Goの列挙型の弱点を克服する手段としても、和型は有望視されています。本章ではジェネリクスに関する実践的な演習問題が用意されています。整数と浮動小数点数の両方に対応する関数の作成や、特定の型を要求するインターフェースの定義など、ジェネリクスの基本的な使い方から応用までを網羅しています。これらの演習を通して、読者はジェネリクスの概念を実際のコードに落とし込む力を身につけることができるでしょう。github.com章全体の内容を振り返り、ジェネリクスの重要性と将来の可能性について再確認できました。著者は、ジェネリクスがGo言語の表現力を高め、コードの再利用性を向上させる強力な機能であると強調しています。 一方で、Go言語のシンプルさを維持するために、ジェネリクスの機能は意図的に制限されています。これからのGo言語の発展において、ジェネリクスがどのように活用されていくのか、楽しみにしていると述べています。ジェネリクスは、Go言語の未来を切り拓く重要な機能であると言えます。 それを適切に使いこなすことで、より柔軟で保守性の高いコードを書けるようになるでしょう。一方で、ジェネリクスの濫用は、かえってコードの複雑さを増し、可読性を損なう恐れがあります。今後、Go言語のエコシステムにおいて、ジェネリクスを活用したライブラリやフレームワークが登場することが期待されますが、それらを適切に評価し、選択していく眼を養う必要があります。Chapter 9. Errors「Chapter 9. Errors」は、Go言語におけるエラーハンドリングの基本から応用までを網羅的に解説した章です。この章を通して、Go言語のエラー処理の特徴と、それを適切に使いこなすためのテクニックについて理解を深めることができました。Go言語のエラー処理は、他の言語の例外処理とは一線を画しています。Goでは、エラーは関数の戻り値として返され、呼び出し元で明示的にチェックする必要があります。 これは一見、冗長で面倒に感じるかもしれませんが、実際には、コードの流れを明確にし、エラーを見落とすリスクを減らすことができます。著者は、この設計の背景にある「Goの哲学」について丁寧に説明しており、納得感を持って読み進めることができました。Go言語のベストプラクティスとして、「Accept interfaces, return structs」という原則があります。これは、関数やメソッドの引数としてインターフェースを受け取り、戻り値として具体的な構造体を返すことを推奨するものです。エラー処理においても、この原則を応用し、具体的なエラー型を返すことで、呼び出し元が適切にエラーを処理できるようになります。特に印象的だったのは、カスタムエラー型の定義方法と活用方法です。Goでは、エラーをただの文字列ではなく、構造体として定義することができます。これにより、エラーに付加情報を持たせたり、エラーの種類によって処理を変えたりすることが可能になります。著者は、カスタムエラー型の定義方法から、そのメソッドの実装、そしてerrors.Isやerrors.Asを使った高度なエラー処理までを、具体的なコード例を交えて解説しています。type MyError struct {    Codes []int}func (me MyError) Error() string {    return fmt.Sprintf("codes: %v", me.Codes)}func (me MyError) Is(target error) bool {    if me2, ok := target.(MyError); ok {        return slices.Equal(me.Codes, me2.Codes)    }    return false}また、エラーのラップ（wrapping）とアンラップ（unwrapping）についても詳しく解説されていました。fmt.Errorfの%w動詞を使えば、元のエラーを失わずに新しいエラーメッセージを追加できます。これにより、エラーが発生した場所や状況を詳細に伝えつつ、根本原因を追跡することができます。逆に、errors.Unwrapを使えば、ラップされたエラーから元のエラーを取り出すことができます。実際にカスタムエラー型を定義し、エラーをラップ・アンラップする練習問題が用意されていました。これらの問題を通して、エラー処理の基本的な書き方だけでなく、より実践的なテクニックも身につけることができました。特に、複数のエラーをまとめて返す方法や、deferを使ったエラーハンドリングの例は、実際のプロジェクトでも役立つと感じました。github.com一方で、panicとrecoverについては、慎重に使うべきだと改めて認識しました。 panicは、回復不可能なエラーが発生した場合に使うべきであり、安易に使うとかえってコードの可読性を損ねてしまいます。recoverは、panicからの復帰を可能にしますが、ライブラリのAPI境界を越えてpanicを伝播させるべきではありません。著者は、panicとrecoverの適切な使い方について、具体的な指針を示しています。func div60(i int) {    defer func() {        if v := recover(); v != nil {            fmt.Println(v)        }    }()    fmt.Println(60 / i)}この章でGo言語のエラー処理の特徴とベストプラクティスが再確認されています。 エラーを単なる例外ではなく、値として扱うことで、より柔軟で表現力豊かなエラーハンドリングが可能になります。一方で、その自由度ゆえに、適切なエラー処理を行うには、一定の規律と経験が必要になります。総括すると、この章ではGo言語のエラー処理について体系的に学ぶことができました。 エラーを値として扱う考え方や、カスタムエラー型の定義方法、エラーのラップとアンラップ、panicとrecoverの適切な使い方など、Go言語ならではのエラー処理の特徴と、それを活かすためのベストプラクティスについて理解を深めることができました。特に、実際のコードを書く上では、エラー処理を適切に行うことが、コードの品質と保守性を大きく左右します。 単にエラーを無視するのではなく、適切にエラーをハンドリングし、ログ出力や監視システムと連携させることが重要です。また、ライブラリやパッケージを設計する際は、エラーをどのように定義し、どのように返すかを慎重に検討する必要があります。Chapter 10. Modules, Packages, and Imports「Chapter 10. Modules, Packages, and Imports」は、Go言語におけるコード管理と外部ライブラリの利用について、非常に重要な概念を丁寧に解説した章です。この章を通して、私はGoのモジュールシステムの特徴と、それを活用するためのベストプラクティスについて理解を深めることができました。まず、モジュール、パッケージ、レポジトリの関係性について明確に説明されていました。モジュールはソースコードの集合体であり、バージョン管理されるユニットです。パッケージはモジュールを構成する要素であり、ディレクトリと1対1で対応します。レポジトリはモジュールを格納する場所です。これらの概念を正しく理解することは、Goでのコード管理を行う上で欠かせません。次に、go.modファイルの役割と記述方法について解説されていました。go.modファイルは、モジュールのメタデータとその依存関係を記述するファイルです。moduleディレクティブでモジュールのパスを宣言し、goディレクティブで必要なGoのバージョンを指定し、requireディレクティブで依存モジュールとそのバージョンを記述する。この構文を理解することで、自分のモジュールを適切に定義し、外部モジュールを利用できるようになります。また、パッケージの作成方法と命名規則、内部パッケージの役割などについても詳しく説明されていました。パッケージ名はディレクトリ名と一致させるべきであり、機能を適切に分割し、依存関係を最小限に抑えるべきです。 内部パッケージを使えば、モジュール内だけで共有したいコードを適切に隠蔽できます。これらのベストプラクティスを意識することで、保守性の高いコードを書けるようになるでしょう。さらに、GoDocコメントの書き方と、pkg.go.devを使ったドキュメントの公開方法も紹介されていました。適切なGoDocコメントを書くことで、自分のパッケージをわかりやすく説明でき、pkg.go.devで自動的にドキュメントを公開できます。これにより、他の開発者が自分のパッケージを使いやすくなり、オープンソースへの貢献にもつながります。モジュールのバージョニングについては、セマンティックバージョニングのルールに従うべきだと強調されていました。APIの互換性を維持しつつ、適切にバージョンを上げていくことが重要です。不適切なバージョンを公開してしまった場合の対処方法として、retractディレクティブの使い方も説明されていました。モジュールプロキシとチェックサムデータベースの仕組みについても、セキュリティの観点から重要な説明がありました。デフォルトではGoogleが運営するプロキシサーバとチェックサムデータベースが使われ、モジュールの整合性が検証されます。 必要に応じて、独自のプロキシサーバを立てたり、プロキシを無効化したりできることも示されていました。また、GoのWorkspaceを使えば、複数のモジュールを同時に編集できることが紹介されていました。これにより、モジュール間の変更を簡単にテストでき、開発の効率が上がります。 ただし、Workspaceの情報をバージョン管理システムにコミットしないよう注意が必要です。サンプルコードを見ると、モジュールの作成から公開、利用までの一連の流れが具体的に示されていました。go mod initでモジュールを初期化し、go getで依存関係を解決し、go buildでビルドする。このような一連のコマンドを適切に使いこなすことが、Goでの開発には欠かせません。$ go mod init github.com/learning-go-book-2e/money$ go get ./...$ go buildExercisesでは、自分でモジュールを作成し、バージョニングやドキュメンティングを実践する課題が用意されていました。実際にコードを書いて、モジュールの作成から公開までの流れを体験することは、理解を深める上で非常に有効だと感じました。// Add adds two numbers together and returns the result. //// More information on addition can be found at [https://www.mathsisfun.com/numbers/addition.html](https://www.mathsisfun.com/numbers/addition.html).func Add[T Number](a, b T) T {    return a + b}Goの優れたモジュールシステムを活用することで、コードの管理がしやすくなり、外部ライブラリも安全に利用できるようになります。一方で、適切なバージョニングやドキュメンティングを行うことが、モジュールの作者としての責務であることも強調されていました。この章ではGoにおけるコード管理と外部ライブラリ利用のベストプラクティスについて、体系的に学ぶことができました。モジュール、パッケージ、レポジトリの関係性、go.modファイルの記述方法、パッケージの設計原則など、Goでの開発に欠かせない知識が丁寧に解説されていました。またモジュールのバージョニングやドキュメンティングの重要性についても、実例を交えて説明されていました。特に、モジュールプロキシとチェックサムデータベースの仕組みは、Goの優れたエコシステムを支える重要な基盤だと感じました。セキュリティと利便性を高いレベルで両立させているGoの設計思想に、改めて感銘を受けました(以前、何かの勉強会で聞いた気がするがすっかり忘れていた)。Chapter 11. Go Tooling「Chapter 11. Go Tooling」は、Goプログラミングにおける開発ツールの重要性と活用方法について深く理解するための重要な章でした。この章を通して、私はGoの豊富な標準ツールと、サードパーティのツールを組み合わせることで、より効率的で高品質なコードを書けるようになると実感しました。著者は、まずgo runを使って小さなプログラムを素早く試す方法を紹介しました。これにより、コンパイルと実行を一度に行え、スクリプト言語のような気軽さでGoを使えるようになります。Goがコンパイル言語でありながら、インタプリタ言語のような利便性も兼ね備えている点が印象的でした。次に、go installを使ってサードパーティのツールをインストールする方法が解説されました。Goのツールエコシステムは非常に充実しており、多くの優れたツールがオープンソースで公開されています。go installを使えば、それらのツールを簡単にインストールし、自分の開発環境に取り込むことができます。また、著者はgoimportsを使ってインポートの整形を改善する方法も紹介しました。これはgo fmtの機能を拡張したもので、不要なインポートを削除し、必要なインポートを自動的に追加してくれます。コードの可読性と保守性を高めるために、goimportsを活用すべきだと感じました。コード品質をチェックするツールとして、staticcheck、revive、golangci-lintが紹介されていました。これらのツールは、潜在的なバグや非効率的なコードを検出し、Goのベストプラクティスに沿ったコードを書くのに役立ちます。特にgolangci-lintは、多数のリンターを統合的に使える便利なツールだと感じました。また、著者はgovulncheckを使って脆弱性のある依存関係をスキャンする方法も解説しました。サードパーティのライブラリを利用する際は、既知の脆弱性がないかチェックすることが重要です。govulncheckを活用することで、セキュリティリスクを早期に発見し、対処できるようになります。さらに、go:embedを使ってコンテンツをプログラムに埋め込む方法や、go generateを使ってコード生成を自動化する方法も紹介されていました。これらの機能を活用することで、より柔軟でメンテナンスしやすいコードを書けるようになると感じました。著者は、クロスコンパイルやビルドタグを使って、異なるプラットフォームやバージョンのGoに対応する方法も解説しました。Goのポータビリティの高さを活かすためには、これらの機能を理解し、適切に使いこなすことが重要だと感じました。Exercisesでは、埋め込みやクロスコンパイル、静的解析など、この章で学んだ機能を実践的に使う課題が用意されていました。実際にコードを書いて試すことで、ツールの使い方や注意点を体験的に学ぶことができました。//go:embed english_rights.txtvar englishRights string//go:embed all:var allRights embed.FSfunc main() {    if len(os.Args) != 2 {        fmt.Println("Please specify a language")        os.Exit(1)    }    language := os.Args[1]    data, err := allRights.ReadFile(language + "_rights.txt")    if err != nil {        fmt.Printf("No UDHR found for language %s\n", language)        os.Exit(1)    }    fmt.Println(string(data))}Goの標準ツールとサードパーティのツールを適切に組み合わせることで、より効率的で高品質なコードを書けるようになります。一方で、ツールを過信せず、その出力を批判的に評価することも大切だと強調されていました。この章ではGoの開発ツールについて網羅的に学ぶことができました。go runやgo installなどの基本的なツールの使い方から、staticcheckやgolangci-lintなどの高度なリンターの活用法、go:embedやgo generateなどの特殊機能まで、Goでの開発に欠かせないツールの数々が丁寧に解説されていました。特に、サードパーティのツールを積極的に活用することの重要性を再認識しました。Goの標準ツールは非常に充実していますが、コミュニティの知恵を結集したサードパーティのツールを併用することで、さらに開発の生産性と品質を高められると感じました。Chapter 12. Concurrency in Go「Chapter 12. Concurrency in Go」を通して、Go言語の並行処理モデルの特徴と使い方、そしてベストプラクティスについて深く理解することができました。この章は、Go言語を使いこなす上で欠かせない重要なトピックを丁寧に解説しており、実践的な知識を身につけるのに最適だと感じました。また、並列処理に関してはブログも書籍もたくさんあるので気になる方がいましたら是非にです。Go言語による並行処理作者:Katherine Cox-BudayオライリージャパンAmazonGo言語の並行処理モデルは、Communicating Sequential Processes（CSP）をベースにしており、その中心的な概念がgoroutineとchannelです。goroutineは、Goランタイムによって管理される軽量のスレッドのようなもので、OS レベルのスレッドよりもはるかに少ないオーバーヘッドで大量に生成・管理できます。一方、channelは、goroutine間でデータを共有するためのパイプのようなもので、型安全でデッドロックを防ぐための仕組みが備わっています。著者は、まず並行処理を使うべきケースについて説明しました。並行処理は、必ずしもプログラムを高速化するわけではなく、IO バウンドなタスクでない限り、オーバーヘッドが大きくなる可能性があると指摘しています。そのため、並行処理を適用する前に、ベンチマークを取って本当にメリットがあるかを確認すべきだと強調していました。次に、goroutineとchannelの基本的な使い方が解説されました。goroutineは、goキーワードを関数呼び出しの前に置くだけで簡単に生成でき、channelはmake関数で作成します。unbuffered channelとbuffered channelの違いや、for-rangeループを使ったchannelの読み取り方法なども丁寧に説明されていました。また、channelを適切にクローズすることの重要性も強調されていました。クローズされたchannelからの読み取りは、その型のゼロ値を返すという特殊な動作を理解しておく必要があります。複数のgoroutineが同じchannelに書き込む場合は、sync.WaitGroupを使ってすべてのgoroutineの終了を待ってからクローズすべきだとのアドバイスもありました。select文は、複数のchannelを扱う際に欠かせない重要な構文です。selectを使えば、複数のchannelを監視し、読み書き可能になったchannelを選択して処理できます。著者は、selectがデッドロックを防ぐ上で重要な役割を果たすことを具体的なコード例で示していました。続いて、並行処理のベストプラクティスとパターンが紹介されました。特に印象的だったのは、APIをconcurrency-freeに保つべきというアドバイスです。並行処理はあくまで実装の詳細であり、ユーザーに不要な複雑さを押し付けるべきではないというのは、納得のいく指摘だと感じました。また、goroutineのリークを防ぐために、必ず終了するようにすべきだという点も重要でした。contextパッケージを使ってgoroutineをキャンセルする方法や、for-selectループから適切に抜ける方法などが具体的に示されていました。バッファ付きchannelの使いどころについても、詳しく解説されていました。バッファ付きchannelは、goroutineの数を制限したり、キューに溜まった処理を制御したりするのに便利です。一方で、不適切に使うとデッドロックを引き起こす可能性もあるため、慎重に検討すべきだと強調されていました。また、バックプレッシャーを実装する方法として、バッファ付きchannelとselect文を組み合わせるアプローチが紹介されていました。これにより、同時実行数を制限しつつ、処理を適切にブロックできるようになります。さらに、select文のcaseを動的にオン・オフする方法として、nil channelを活用するテクニックも面白かったです。クローズしたchannelからの読み込みが、ゼロ値を返し続けてしまう問題を回避できる優れたアイデアだと感じました。一方で、mutexについても適切に使いこなすことの重要性が述べられていました。goroutineとchannelだけでは実現が難しい、共有リソースの保護などでは、mutexが適していると指摘されていました。ただし、mutexの濫用は避けるべきで、可能な限りchannelを使うのがよいとのアドバイスもありました。最後に、これまで学んだ概念を組み合わせて、非同期なパイプラインを実装するサンプルコードが示されていました。goroutine、channel、select、contextを適切に使い分けることで、タイムアウト制御や複数のWeb APIを並行に呼び出す処理を、わずか100行程度の読みやすいコードで実現できることはめちゃくちゃメリットだと思います。練習問題では、goroutineとchannelを使った基本的な並行処理プログラムから、selectやsync.WaitGroupを使ったより複雑な処理まで、幅広い題材が扱われていました。自分で実際にコードを書いて試すことで、並行処理の基本的なパターンが身についたと実感しています。github.comこの章を通して、Go言語の並行処理モデルの優れた設計思想と、それを適切に使いこなすためのベストプラクティスについて深く理解することができました。goroutineとchannelを中心とするシンプルな仕組みの中に、デッドロックを防ぎつつ安全に並行処理を行うための知恵が詰まっていることを実感しました。一方で、並行処理の適用は慎重に検討すべきであり、安易に使うとかえって複雑さを増してしまうことも学びました。並行処理はあくまでツールであり、ボトルネックの特定と適切な設計が何より重要だというのは、肝に銘じるべき教訓だと感じました。特に、現実のシステム開発においては、並行処理とエラーハンドリング、リソース管理などを総合的に考える必要があります。goroutineのリークを防ぎ、適切にリソースを解放する方法や、mutexとchannelの使い分け方など、実践的なスキルを再確認できたのは良かったです。私自身、普段からGoを使った並行処理プログラムを書くことが多いのですが、この章で得た知見を活かして、より堅牢で効率的なコードを書けるようになりたいと思います。特に、contextパッケージを活用したgoroutineのキャンセル処理や、バッファ付きチャネルを使ったバックプレッシャーの実装などは、実際のプロジェクトですぐにでも試してみたいテクニックです。並行処理はGoの最も強力な武器の一つですが、それを適切に使いこなすためには、深い理解と経験が必要不可欠です。この章で学んだ基本的な概念と、数多くのベストプラクティスを、自分の経験として血肉化していくことが、Goのプロフェッショナルとして成長するための鍵になるのだと感じました。Chapter 13. The Standard Library「Chapter 13. The Standard Library」では、Goの標準ライブラリの中でも特に重要なパッケージについて深く掘り下げています。この章を読んで、Goの標準ライブラリがいかにベストプラクティスに基づいて設計されているかを強く実感しました。そこには、他の言語の標準ライブラリにはない優れた設計思想が随所に見られます。印象的だったのは、「io」パッケージの設計です。「io.Reader」と「io.Writer」というシンプルなインターフェースを中心に、様々な入出力処理を抽象化している点は、Goならではの美しい設計だと感じました。この設計のおかげで、ファイルやネットワーク、圧縮、暗号化など、様々な入出力処理を統一的に扱えるようになっています。また、「time」パッケージも非常に使いやすく設計されています。「time.Duration」と「time.Time」という2つの型を中心に、時間関連の処理を直感的に記述できるのは、Goの大きな強みだと思います。特に、モノトニック時間の採用により、リープセカンドなどの影響を受けずに正確な時間計測ができるようになっているのは、システムプログラミングにおいて重要な点だと感じました。「encoding/json」パッケージは、構造体のタグを活用してJSONのエンコーディングとデコーディングを制御できる点が優れています。これにより、JSONのフィールド名と構造体のフィールド名を柔軟にマッピングできるだけでなく、フィールドの省略やデフォルト値の指定なども簡単に行えます。以下のサンプルコードのように、タグを使ってJSONのフィールド名を指定できるのは非常に便利です。type Person struct {    Name string `json:"name"`    Age  int    `json:"age"`}「net/http」パッケージは、Goの標準ライブラリの中でも特に重要なパッケージの1つです。「http.Handler」インターフェースを中心としたシンプルな設計により、高性能で使いやすいHTTPサーバーとクライアントを簡単に構築できます。また、ミドルウェアのパターンを活用することで、ログ出力やエラーハンドリング、認証、圧縮など、様々な機能を柔軟に追加できる点も優れています。「log/slog」パッケージは、2023年にリリースされたGo 1.21で新たに追加された構造化ロギングのためのパッケージです。従来の「log」パッケージの課題を解決し、より使いやすく、パフォーマンスにも優れた設計になっています。以下のように、ログレベルやコンテキスト、属性などを柔軟に指定できるのが特徴です。logger := slog.New(slog.NewTextHandler(os.Stdout))logger.Info("Hello, World!", "name", "Alice", "age", 30)これらの知識を活用して、現在時刻を返すWebサーバーや、ミドルウェアを使ったJSONログ出力、JSONとテキストの切り替えなどを実装する課題が用意されていました。これらの課題に取り組むことで、標準ライブラリの使い方をより深く理解することができました。Goの標準ライブラリがベストプラクティスに基づいて設計されていること、そして後方互換性を尊重しながら進化を続けていることが改めて強調されていました。Goの標準ライブラリは、私たちが日々のプログラミングで参考にすべき優れたお手本だと言えます。個人的な感想としては、Goの標準ライブラリは、シンプルさと実用性のバランスが非常に優れていると感じました。必要十分な機能を提供しながらも、無駄に複雑になることなく、使いやすさを追求しているのが印象的です。特に、インターフェースを活用した抽象化と、具体的な実装の使い分けが絶妙だと思います。また、Goの標準ライブラリは、並行処理やエラーハンドリング、テストなど、現代的なプログラミングに欠かせない要素をしっかりとサポートしているのも大きな特徴だと感じました。これらの機能を標準ライブラリレベルでサポートしているからこそ、Goは大規模なシステム開発に適した言語になっているのだと思います。Chapter 14. The Context「Chapter 14. The Context」は、Go言語プログラミングにおける重要な概念である「コンテキスト」について深く掘り下げた章でした。コンテキストは、リクエストのメタデータを管理し、タイムアウトやキャンセル、値の受け渡しを制御するための強力な仕組みです。この章を通して、コンテキストの適切な使い方とベストプラクティスについて理解を深めることができました。zenn.devGo言語による並行処理にもContext について記載してあるので読んで下さい。learning.oreilly.com著者は、まずコンテキストの基本的な文法と使い方から説明しています。コンテキストは、context.Contextインターフェースを満たす値として表現され、関数の第一引数として明示的に渡すのが慣例です。context.Background関数でルートコンテキストを作成し、そこから子コンテキストを派生させていくのが基本的なパターンだと学びました。HTTPサーバーでコンテキストを使う場合は、http.RequestのContextメソッドとWithContextメソッドを使って、ミドルウェア間でコンテキストを受け渡しするのが適切な方法だと分かりました。ハンドラ関数では、req.Context()でコンテキストを取得し、ビジネスロジックの第一引数として渡すべきだと強調されていました。コンテキストの主な用途の一つが、キャンセル処理だと理解しました。context.WithCancel関数でキャンセル可能なコンテキストを作成し、キャンセル関数を適切にdeferすることで、リソースのリークを防げることが示されていました。Goの標準ライブラリのHTTPクライアントは、コンテキストのキャンセルを尊重して、リクエストを適切に中止してくれるそうです。また、context.WithTimeoutやcontext.WithDeadlineを使えば、コンテキストに時間制限を設定できることも分かりました。これにより、リクエストの処理時間を適切に管理し、サーバーのリソースを公平に配分できるようになります。子コンテキストのタイムアウトは、親コンテキストのタイムアウトに制約されるというルールも重要だと感じました。コンテキストのキャンセル原因を伝えるために、context.WithCancelCauseやcontext.Causeを使う方法も印象的でした。エラーの伝搬と情報の集約に、コンテキストが効果的に活用できることが分かりました。一方で、キャンセル関数の呼び出しを複数回行っても問題ないという点は、意外でした。自作のコードでコンテキストのキャンセルをサポートする場合は、select文でctx.Done()をチェックするパターンと、定期的にcontext.Cause(ctx)をチェックするパターンの2つが紹介されていました。長時間実行される処理では、コンテキストのキャンセルに対応することが重要だと再認識しました。Exercisesでは、これまで学んだコンテキストの知識を活用する問題が用意されていました。ミドルウェアでタイムアウトを設定する課題や、時間制限付きの計算を行う課題、ロギングレベルをコンテキストで制御する課題など、実践的なユースケースが網羅されていたと思います。github.com冒頭でも述べたように、コンテキストはGo言語プログラミングにおける重要な概念です。この章を通して、コンテキストの適切な使い方とベストプラクティスについて体系的に学ぶことができました。特に、キャンセル処理とタイムアウト制御は、サーバーの堅牢性と公平性を確保する上で欠かせない機能だと実感しました。一方で、コンテキストの乱用は、かえってコードの複雑さを増してしまう恐れがあります。コンテキストは、主にリクエストスコープのメタデータを扱うために使うべきで、安易に値の受け渡しに使うのは避けるべきだと強調されていました。この指針は、コンテキストを適切に使いこなす上で重要だと感じました。自作のコードでコンテキストのキャンセルをサポートすることの重要性も再認識できました。特に、select文とctx.Done()を使ったパターンは、Goらしい簡潔で効果的な手法だと感じました。長時間実行される処理では、定期的にコンテキストのキャンセルをチェックすることを習慣づけたいと思います。func longRunningTask(ctx context.Context) error {    for {        select {        case <-ctx.Done():            return ctx.Err()        default:            // Do some work        }    }}この章ではGoのコンテキストについて網羅的かつ実践的に学ぶことができました。コンテキストの基本的な使い方から、キャンセル処理、タイムアウト制御、値の受け渡しまで、幅広いトピックが丁寧に解説されていました。Exercisesで提示された問題は、コンテキストの理解を深め、実際のコードに落とし込む力を養うのに役立つ内容でした。コンテキストは、Goのプログラミングスタイルと哲学を体現する重要な機能だと言えます。明示的なデータの受け渡しを重視しつつ、キャンセルとタイムアウトという横断的な関心事をエレガントに扱える点が、Goらしさを感じさせます。一方で、その柔軟性ゆえに、適切に使いこなすには一定の規律と見識が求められます。Chapter 15. Writing Tests「Chapter 15. Writing Tests」は、Goにおけるテストの書き方と品質向上のためのツールについて詳細に解説している章です。この章を読んで、ユニットテストの書き方、テーブルテストの実行、テストのセットアップとティアダウン、HTTPのスタブ化、ファジングテスト、データ競合の検出など、テストに関する多くの知見を得ることができました。また、テストに関しては他の書籍を読んでも良いかもと思いました。【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazon特に印象に残ったのは、テーブルテストの実行方法です。テーブルテストを使うことで、同じテストロジックに対して様々なデータパターンを適用することができ、コードの可読性と保守性が向上します。また、並行テストの実行方法も非常に興味深かったです。並行テストを適切に実行することで、テストの実行時間を大幅に短縮できます。ただし、共有される可変状態に依存するテストを並行して実行すると、予期しない結果になる可能性があるため注意が必要です。コードカバレッジの計測も重要なトピックの一つでした。go test -coverを使ってカバレッジを計測し、go tool coverでカバレッジ情報を可視化する方法は、テストの網羅性を確認する上で非常に有用です。ただし、100%のコードカバレッジを達成しても、バグが存在する可能性があることに注意が必要です。ファジングテストは、ランダムなデータを生成してコードに入力し、予期しない入力に対する動作を検証する手法です。ファジングテストを行うことで、開発者が想定していなかったようなコーナーケースのバグを発見することができます。また、データ競合の検出には-raceフラグを使用します。これにより、複数のゴルーチンから同時にアクセスされる変数を特定し、適切なロックを設定することができます。サンプルコードとして、sample_code/adderディレクトリにあるaddNumbers関数のテストコードが示されていました。また、sample_code/tableディレクトリではテーブルテストの例が、sample_code/solverディレクトリではスタブを使ったテストの例が示されていました。これらのサンプルコードは、実際のテストコードを書く際の参考になります。Exercisesでは、Simple Web Appプログラムに対してユニットテストを書き、コードカバレッジを計測することが求められていました。また、データ競合を検出して修正し、parser関数に対してファジングテストを実行することも求められていました。これらの演習を通じて、テストに関する知識を実践的に応用することができます。この章で学んだテストとコード品質向上のためのツールについて総括されていました。次の章では、unsafeパッケージ、リフレクション、cgoなど、Goの一般的なルールを破るような機能について探求していくとのことでした。総括すると、この章ではGoにおけるテストの書き方とコード品質向上のためのツールについて網羅的に解説されていました。ユニットテストの書き方、テーブルテストの実行、並行テストの実行、コードカバレッジの計測、ファジングテスト、データ競合の検出など、テストに関する重要なトピックが幅広くカバーされていました。また、サンプルコードや演習問題も充実しており、実践的な知識を身につけることができる内容でした。Chapter 16. Here Be Dragons: Reflect, Unsafe, and Cgo「Chapter 16. Here Be Dragons: Reflect, Unsafe, and Cgo」を通して、Go言語プログラミングにおいて、安全性と規約を一時的に無視してメモリやデータの細かな操作を行う仕組みであるreflect、unsafe、cgoについて深く理解することができました。これらの機能は、Go言語のセキュリティと型安全性を一時的に破ることから、非常に注意深く扱う必要があります。しかし、特定の場面では威力を発揮するため、適切な活用方法を学ぶことが重要だと感じました。reflectreflectは、Go言語の型システムを動的に操作するための強力な仕組みです。コンパイル時には型が特定できない場合、または外部データを動的にマッピングする必要がある場合などに、reflectを使って型の情報を取得したり、値を設定することができます。reflectで扱う主な概念は「型(reflect.Type)」「種類(reflect.Kind)」「値(reflect.Value)」の3つです。reflectを使えば、構造体のフィールドにアクセスしたり構造体を生成できますが、コーディングが冗長になりがちで、正しい操作を行わないとパニックを起こす可能性があります。そのため、適切なエラーハンドリングと注釈を残すことが重要です。特に、型の種類(reflect.Kind)に応じて、呼び出し可能なメソッドが変わるため、種類をしっかり確認する必要があります。type Foo struct {    A int    `myTag:"value"`    B string `myTag:"value2"`}var f Fooft := reflect.TypeOf(f)for i := 0; i < ft.NumField(); i++ {    curField := ft.Field(i)    fmt.Println(curField.Name, curField.Type.Name(),        curField.Tag.Get("myTag"))}上記のサンプルコードは、reflectを使って構造体のタグフィールドにアクセスする方法を示しています。このように、reflectは型情報を動的に取得したり、値を設定・生成したりするのに役立ちますが、過度に使い過ぎるとコードの可読性を下げる恐れがあります。reflectを利用する主なユースケースは、データベースやJSONなどの外部データの読み書き、テンプレートエンジンによるデータのレンダリング、型に依存しないソートアルゴリズムの実装などです。Go言語の標準ライブラリでも、これらの用途でreflectが活用されています。一方、reflectを使うと通常の処理に比べてパフォーマンスが大幅に低下するという課題もあります。サンプルコードのベンチマークでは、reflectを使ったフィルタ処理は通常の場合に比べて50~75倍も遅く、多数のメモリ確保を行うことが分かります。BenchmarkFilterReflectString-8     5870  203962 ns/op  46616 B/op  2219 allocs/opBenchmarkFilterGenericString-8   294355    3920 ns/op  16384 B/op     1 allocs/opBenchmarkFilterString-8          302636    3885 ns/op  16384 B/op     1 allocs/opそのため、必要不可欠な場面でのみreflectを使い、通常の処理ではジェネリクスなどの代替手段を使うべきです。ただし、マーシャリング・アンマーシャリングや動的なメモ化などは、reflectを使わざるを得ない場合もあります。このように、Go言語の規約を一時的に無視する仕組みとして、reflectを適切に使いこなすことが重要だと言えます。unsafeunsafeパッケージは、Go言語の型安全性とメモリ安全性をある程度無視して、低水準のメモリ操作を行う仕組みを提供します。主な使用例は、OSとのシステムコール連携や、バイナリデータの高速なマーシャリング・アンマーシャリングなどです。内部で扱われるデータ型はunsafe.Pointerで、任意のポインタ型やuintptrとの相互キャストが可能です。メモリのレイアウトを調べるためのunsafe.Sizeofとunsafe.Offsetof関数があり、構造体フィールドの並び替えによるメモリ使用量の最適化などに役立ちます。type BoolInt struct {    b bool    i int64}type IntBool struct {    i int64    b bool}fmt.Println(unsafe.Sizeof(BoolInt{}), unsafe.Offsetof(BoolInt{}.b), unsafe.Offsetof(BoolInt{}.i))// Output: 16 0 8 fmt.Println(unsafe.Sizeof(IntBool{}), unsafe.Offsetof(IntBool{}.i), unsafe.Offsetof(IntBool{}.b))// Output: 16 0 8上記のサンプルコードでは、構造体の並び方によってメモリのパディングが変わり、全体のサイズが変化することが分かります。このように、unsafeパッケージを使えば、メモリのレイアウトを細かく制御できます。さらに、unsafeを使えば、バイナリデータをスムーズに構造体へマッピングすることも可能です。func DataFromBytesUnsafe(b [16]byte) Data {    data := (*Data)(unsafe.Pointer(&b))    if isLE {        data.Value = bits.ReverseBytes32(data.Value)    }    return data}このコードは、バイト配列をunsafe.Pointerでキャストし、最終的に構造体へマッピングしています。パフォーマンス的には、unsafeを使ったバイト配列から構造体へのマッピングは、安全な手法に比べて2〜2.5倍程度高速だと言われています。BenchmarkDataFromBytes-8             538443861  2.186 ns/op   0 B/op 0 allocs/opBenchmarkDataFromBytesUnsafe-8      1000000000  1.160 ns/op   0 B/op 0 allocs/opただし、unsafeの濫用は危険を伴うため、必要最小限の使用に留める必要があります。Go言語のセキュリティモデルを部分的に無視する代わりに、そのパフォーマンスメリットを手に入れるかどうかは、用途次第です。通常のプログラミングでは、安全な手法を使うことがベストプラクティスです。また、unsafeを使う際は、ランタイムフラグ -gcflags=-d=checkptrを付けてポインタの不適切な使用をチェックすることが推奨されています。ドキュメントの注意事項にあるとおり、正しく使えば高速で強力なコードを書けますが、間違った使い方をすると簡単にセキュリティホールを作ってしまう可能性もあるため、unsafeの適切な使用には熟達した技術が求められます。cgo最後に、cgoについてですが、これはGo言語とCコードを連携する仕組みです。CコードをC拡張構文のコメント中に直接記述したり、関数の宣言をコメントに記述して外部のCコード中の関数をリンクしたりできます。Go関数をCコードにエクスポートすることも可能です。/*#include <math.h>int add(int a, int b) {    int sum = a + b;    printf("a: %d, b: %d, sum %d\n", a, b, sum);    return sum;}*/import "C"func main() {    sum := C.add(3, 2)    fmt.Println(sum)           // Output: 5    fmt.Println(C.sqrt(100))   // Output: 10}cgoは、OSのシステムコールへアクセスしたり、既存のCライブラリを活用したりするのに便利です。ただし、Go言語がGCで自動メモリ管理しているのに対し、Cコードではメモリ解放を手動で行う必要があるため、ポインタの扱いには注意が必要です。Go側の変数をCコードに渡す際は、cgo.HandleでラップしてCコードに安全に渡す必要があります。p := Person{Name: "Jon", Age: 21}C.in_c(C.uintptr_t(cgo.NewHandle(p)))このように、cgoを使うと、Go言語の安全性とCコードの低レイヤー制御が両立できます。ただし、その実行コストは約40nsと高く、基本的にはパフォーマンス向上のためというよりは、既存のCライブラリ活用のために使われることが多いようです。パフォーマンス向上のためだけにはあまりメリットがない上、ポインタの危険な操作が必要になるため、cgoは「cgo is not Go」と言われています。そのため、自前でCラッピングを書く前に、サードパーティ製のGoラッパーを探すことが推奨されています。また、設計やメモリモデルの違いから、cgoの使用は避けられない場合に限り、それでもできるだけコア部分は安全なGoコードで書くべきだとされています。この章では、Go言語のセキュリティや規約を部分的に無視するreflect、unsafe、cgoについて詳しく学びました。これらの機能は、強力な反面で危険が伴うため、一定の知識と経験が必要とされます。特に、reflectは外部データのマッピングや標準ライブラリの一部の処理に必要不可欠ですが、パフォーマンスの低下が避けられません。unsafeはメモリレイアウトの制御や高速なデータマーシャリングに使えますが、安全性を無視する代わりのメリットが必要です。cgoは既存のCライブラリをラッピングする手段ですが、実行コストが高い上に設計の違いからGoの規約を完全に守ることができません。つまり、これらは例外的な処理を行うための機能であり、通常の処理ではなるべく使わず、代わりにジェネリクスなどの安全な手段を活用するのがベストプラクティスだと言えます。Go言語の利点は、まさにその規約とセキュリティにあるためです。ただし、一方でそれらを無視する機能さえも用意されていることで、Go言語はかえって強力で柔軟な言語になっていると言えるでしょう。Exercisesでは、構造体のバリデーションやメモリレイアウトの最適化、CコードのラッピングなどGoの規約を一時的に無視する練習問題が用意されていました。Wrapping Upでは、Go言語の安全性は基本原則ですが、例外的に規約を無視することで強力で柔軟な機能が提供されていると総括されていました。つまり、これらの高度な機能は「ツール」に過ぎず、適切な使い分けが重要なのです。Go言語は、基本的にはシンプルで規約に従うことで、保守性の高いソフトウェアを作ることを目指しています。一方で、状況次第では規約を一時的に無視して高度な操作を行う必要が出てくる場合もあります。そういった際にこそ、reflect、unsafe、cgoといった高度な機能が役立つのです。これらは、Go言語の最も興味深い部分の1つと言えるでしょう。しかし同時に、これらの機能の濫用はセキュリティホールやバグにつながりかねません。そのため、十分な理解とコントロールが求められます。Go言語のセキュリティやベストプラクティスに反するような例外的な処理は、確実に必要な場面でのみ、そして最小限に留めるべきです。Go言語では、規約に従うことで、強固で長期的に保守しやすいソフトウェアを書くことを目指しています。その一方で、例外的な状況においては、reflectやunsafe、cgoなどの例外的な仕組みを適切に使いこなすスキルも要求されます。つまり、Go言語では一般的なユースケースでは退屈で規約に従うことを推奨しつつ、特殊なケースでは必要最小限の例外を認める、そんな設計思想が貫かれていると言えるのです。今後50年のコンピューティングを支えるソフトウェアを作り上げていく上で、この思想を体現するスキルが求められるでしょう。おわりにここ間違っているとかあればDMください。本書「Learning Go Second Edition」を通して、Go言語プログラミングについて体系的かつ実践的に学ぶことができました。Goのシンプルさと実用性を重視する設計思想、並行処理やエラーハンドリング、テストなどの実践的な要素に言語レベルでサポートされている点が特に印象的でした。一方で、Goのシンプルさは時として制約にもなり得ます。Goの設計思想を理解し、適材適所で機能を使い分けて周知していくことが大事だと思いました。サンプルコードと練習問題を通して、学んだ概念を実際のコードに落とし込み、体験的に理解を更に深めることができました。特に知らなかったことがいくつかあったのと実践的なスキルとして利用したいものがいくつかあったので充分すぎる収穫かと思いました。Goのシンプルさの中に宿る美しさに惹かれ、ベストプラクティスを習慣化し、美しいコードを書けるようになりたいと思いました。並行処理とエラーハンドリングは、Goプログラミングの醍醐味だと感じています。モジュールシステムとテストの重要性についても再認識できました。Goのシンプルで実用的な設計思想を自分の糧として、プログラマとしてのマインドセットを磨いていきたいと思います。**]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[Kubecon EU 2024: Cloud Native AI Day]Reducing Cross-Zone Egress at Spotify with Custom gRPC Load Balancing のご紹介]]></title>
            <link>https://sreake.com/blog/kubecon-eu-2024-cloud-native-ai-dayreducing-cross-zone-egress-at-spotify-with-custom-grpc-load-balancing/</link>
            <guid>https://sreake.com/blog/kubecon-eu-2024-cloud-native-ai-dayreducing-cross-zone-egress-at-spotify-with-custom-grpc-load-balancing/</guid>
            <pubDate>Wed, 19 Jun 2024 01:18:15 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは、Sreake事業部の永瀬滉平です！ 今回はKubeCon EU 2024に参加してきましたので、中でも気になったセッションをピックアップしてご紹介したいと思います。 セッションについて 取り上げるセ […]The post [Kubecon EU 2024: Cloud Native AI Day]Reducing Cross-Zone Egress at Spotify with Custom gRPC Load Balancing のご紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubernetesにおけるCELの記述方法まとめ]]></title>
            <link>https://sreake.com/blog/kubernetes-cel-description/</link>
            <guid>https://sreake.com/blog/kubernetes-cel-description/</guid>
            <pubDate>Wed, 12 Jun 2024 03:33:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Kubernetes 1.30でValidating Admission Policyの機能がGAするなど、開発中の新機能にCELが組み込まれるケースが増えています。今後Kubernetesで使われる機会が増え […]The post KubernetesにおけるCELの記述方法まとめ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのRapid evaluation APIを利用したLLMの評価手法]]></title>
            <link>https://sreake.com/blog/google-cloud-rapid-evaluation-api-verification/</link>
            <guid>https://sreake.com/blog/google-cloud-rapid-evaluation-api-verification/</guid>
            <pubDate>Mon, 10 Jun 2024 09:31:15 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。 本記事では、LLMの評価手法とし […]The post Google CloudのRapid evaluation APIを利用したLLMの評価手法 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud主催パートナー向けイベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」を話しました。]]></title>
            <link>https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb</link>
            <guid>https://zenn.dev/nnaka2992/articles/compare_vector_searches_on_google_clouds_rdb</guid>
            <pubDate>Sun, 09 Jun 2024 22:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2024年6月5日にGoogle Cloudがパートナー向けに開催したデータ関連の非公開イベントで「Google Cloud で利用できるRDBのベクトル検索を徹底解剖！」というLTを話しました。https://speakerdeck.com/nnaka2992/google-cloud-deli-yong-dekirurdbnobekutorujian-suo-woche-di-jie-pou非公開イベントのため録画がなかったり、LT枠だった関係で省略してしまった部分があったりしたためブログでより詳細な説明資料のようなものを書きました。 背景Google Cloudが提供する...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Vertex AI Agent Builderの使い方]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/06/07/171514</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/06/07/171514</guid>
            <pubDate>Fri, 07 Jun 2024 08:15:14 GMT</pubDate>
            <content:encoded><![CDATA[RAG(Retrieval-Augmented Generation)RAG（Retrieval Augmented Generation：検索拡張生成）は、検索機能と生成AIを組み合わせた技術です。従来の生成AIは、学習した情報に基づいてしか回答を生成できませんでしたが、RAGは外部の知識ベースから情報を検索し、生成AIの回答に組み込むことで、より正確で幅広い情報を提供することができます。Google Cloudのマネージドサービスの説明今回のハンズオンで使用するGoogle Cloudのマネージドサービスの説明をします。Cloud StorageGoogle Cloud Storage（GCS）は、Google Cloud 上で動作するオブジェクトストレージサービスです。あらゆる種類のデータを安全かつスケーラブルに保存することができ、データ分析、機械学習、アプリケーション開発など、様々な用途に活用できます。Vertex AIVertex AIは、Google Cloud上で動作する、AIモデルの開発と運用を統合的に支援するプラットフォームです。データサイエンティスト、機械学習エンジニア、開発者など、様々なユーザーが効率的に AIや機械学習(ML) モデルを構築、トレーニング、デプロイ、運用できるよう、機能を提供します。GeminiなどのLLMはVertex AI上で使用できます。Vertex AI Agent BuilderVertex AI Agent Builderは、Google Cloud上で動作する、生成 AI エージェントを簡単に構築、デプロイ、管理できるプラットフォームです。元々はVertex AI Search and Conversationと呼ばれていました。コードを記述することなく、自然言語を使用して、インテリジェントな会話型 AI とプロセス自動化エージェントを作成できます。RAGを簡単に作成でき、今回のハンズオンではRAG作成のために利用します。Google Cloudを用いたRAGハンズオンGoogle CloudはGoogleアカウントがあると、簡単に使い始めることができます。初めて使う場合は$300 相当の無料クレジットが付与されます。Cloud Storageのコンソール画面を開きましょう。画面上側の「作成」を押してください。バケットの名前をつけて、画面をスクロールして、一番下の「作成」のボタンを押してください。「このバケットに対する公開アクセス禁止を適用する」にはデフォルトでチェックマークが入っているかと思います。ここにはチェックマークをつけておくことをおすすめします。「確認」ボタンを押します。バケットができました。RAGに入れるPDFを入手したいと思いますが、私はインターネット上で無料入手できる情報処理推進機構(IPA)のものを10種ダウンロードしました。皆さんはご自身の好きなPDFをお使いください。非機能要件記述とアーキテクチャ記述ガイドhttps://www.ipa.go.jp/archive/digital/iot-en-ci/jyouryuu/hikinou/ps6vr700000077he-att/000005155.pdfプロジェクトマネジメントの見える化https://www.ipa.go.jp/archive/files/000004090.pdf情報処理システム高信頼化教訓活用ガイドブック(ITサービス編)https://www.ipa.go.jp/archive/files/000051041.pdf情報セキュリティ対策ベンチマークから情報セキュリティ監査へhttps://www.ipa.go.jp/archive/files/000011534.pdf経営に活かす IT 投資の最適化 ～ 情報システムを安心して快適に使うために ～https://www.ipa.go.jp/archive/files/000004568.pdf安全なウェブサイト運営にむけてhttps://www.ipa.go.jp/security/todokede/vuln/ug65p90000019gda-att/000089537.pdf初めての情報セキュリティ対策https://www.ipa.go.jp/security/guide/ps6vr70000007pkg-att/09_hazimete_slide.pdf新・5分でできる！情報セキュリティ自社診断https://www.ipa.go.jp/security/guide/sme/ug65p90000019c86-att/000055848.pdfIPA脆弱性対策コンテンツリファレンスhttps://www.ipa.go.jp/security/guide/ssf7ph000000fjhe-att/000051352.pdfECサイト構築・運用セキュリティガイドラインhttps://www.ipa.go.jp/security/guide/vuln/ps6vr7000000acvt-att/000109337.pdfアップロード後、ファイルがあることを確認できます。Agent Builderを使って、RAGを作っていきましょう。Cloud Storageのドキュメントをベクトル化してAgent Builderに蓄えます。コンソール上で簡単にできます。Agent Builderのコンソール画面を開き、左のサイドバーからデータストアを開いてください。「データストアの作成」ボタンを押します。画面下にスクロールして、「Cloud Storage」を選択します。インポートするファイル・フォルダを選択します。先ほど作成したフォルダを選択しましょう。今回はPDFですので、データの種類は「非構造化ドキュメント」を選択したままにしてください。データストアの構成を決めていきましょう。Locationはデフォルトの「global」のままでいきましょう。データストア名を入力します。「作成」ボタンを押してデータストアを構成していきます。データストアが構成できました。作ったデータストアを見ていきましょう。「アクティビティ」タブを開くと、データのインポート状況を確認できます。時間がかかる場合もあります。終わるまで待ちましょう。データのインポートが完了しました。Agent Builderのサイドバーの「アプリ」からアプリを作成していきます。「CREATE APP」を選択します。「検索」を選択します。内容は「汎用」のままでいいです。下にスクロールします。「アプリ名」、「会社名」を入力し、「続行」ボタンを押します。作成したデータストアを選択します。下にスクロールして、「作成」ボタンを押します。アプリが作成できました。サイドバーの「プレビュー」を押しましょう。検索フォームに入力して、検索をしていきましょう。ここで、「システム障害の予防策」と検索すると、関連する順番にPDFを羅列してくれ、検索文に関連するページも表示してくれます。今回はIPAのドキュメントで行いましたが、技術PDFをRAGに入れておくと、調査が捗りそうですね。なお、オライリー書籍をEBookで購入すると、PDF版を入手でき、RAG作成に重宝しそうです。複数人でRAGを使う場合は、著作権侵害にならないよう十分ご注意ください。法人では社内文書をRAGに配置することで、これまでの検索ではすぐに得られなかった情報へのアクセススピードが上がります。社内データの活用はDXの第一歩でもあります。生成AIの活用を機に、DXを進めていきましょう！GeminiGeminiは、Google AIが開発したマルチモーダル生成AIモデルです。2023年12月にBardとして発表され、2024年2月にGeminiへと改名されました。マルチモーダルとは、テキストだけでなく、画像や音声などのデータも扱うこともでき、より創造的で表現力豊かなコンテンツを作成することができます。また、高度な情報検索が可能で、Google検索の検索結果を活用することで、最新の情報や、専門性の高い知識にもアクセスできます。文章生成、言語翻訳、要約、コード生成、画像生成、音声生成など、様々なタスクを実行することができます。プレビュー版のGemini-1.5は100万トークンに対応しています。この記事もGeminiのWeb版を無料で使用して書いています。https://gemini.google.com/app]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[オブザーバビリティ再入門みたいなイベントで登壇しました。再入門だけが創造的な勉強会みたいな主張をした。 #o11y_mackerel]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/06/06/131051</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/06/06/131051</guid>
            <pubDate>Thu, 06 Jun 2024 04:10:51 GMT</pubDate>
            <content:encoded><![CDATA[はじめに先日、taxin_ttさんからダイレクトメッセージで、「オブザーバビリティ再入門」というイベントで登壇し、イベントのテーマが「再入門」ということで、オブザーバビリティについて改めて基本的な概念から説明するようにとの依頼をいただきました。mackerelio.connpass.com「再入門」というテーマを聞いたとき、正直なところ少し悩みました。オブザーバビリティは近年注目を集めているトピックであり、既に多くの人が資料を作って登壇されており参加者も基本的な知識を持っているはずです()。そんな中で、「再入門」として何を話せばよいのか、どのようにアプローチすればよいのか、考えを巡らせました。再読だけが創造的な読書術である (単行本)作者:永田　希筑摩書房Amazonそこで、私は「可観測性とは」「可観測性と監視の違い」「可観測性の導入と抵抗」の3つのトピックを中心に話すことにしました。これらのトピックを通して、オブザーバビリティの基本的な概念や重要性について、わかりやすい言葉で説明することを心がけました。また、非技術者への説明時に再利用しやすいよう、平易な表現を用いています。聴衆の皆さんが、オブザーバビリティについて改めて理解を深め、実践につなげるためのヒントを提供できるよう努めました。なぜなら、言語やコミュニケーションは意図のすべてをそのまま表現できるわけではありません。常に受け取り手によって解釈され、解釈されて初めて意味あるものとして伝わるからです。そのため、この再入門を意味あるものだと感じたのなら、それはあなたが準備できていたからだと言えるでしょう。当日まで概要しか知らなかったのですが、登壇者が尊敬しているまさよしさんで、「メトリクス、ログ、トレースをうまく使い分けて可観測性を高めよう！」というタイトルだったので、その辺の話は避けてもよいと思い、OpenTelemetryという単語を一切使わずにこのような内容になりました。めちゃくちゃに良い資料なので読んでほしいです。「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon登壇資料本資料がどんな資料かというと、 speakerdeck.com可観測性（Observability）について以下のようにまとめている。可観測性とは、システムの外部から観測できる情報に基づいて内部状態を推論・理解する能力のことであり、特にマイクロサービスアーキテクチャでは、複数の信号源からの情報を相関させ、サービスを横断するリクエストを追跡できる可観測性が不可欠である。可観測性の主要なシグナルとしては、メトリクス、ログ、トレースの3つがあり、可観測性と監視の違いは、監視が既知の未知（Known unknow）に対応するのに対し、可観測性は未知の未知（Unknow unknow）に対応する点である。何かを導入する時には、変化への抵抗が伴うことが多く、抵抗の主な要因として、惰性、労力、感情、心理的反発の4つがある。可観測性導入の成功のためには、技術的・人的側面に配慮し、エンジニアや組織全体の心理的抵抗に対処することが重要であり、継続的なコミュニケーションと小さな成功体験で支持を得ることが有効である。可観測性導入は組織的な変革であり、エンジニアリング文化や考え方の変革が必要で、エンジニアの自発的な活用と組織全体の支援が重要である。みたいなことを生成AIを通すと言われたのでそんなことを言われたのでそんな感じの資料です。きょーさんに毎回のようにレビューしていただきました。当日の雰囲気Youtube緊張してアルコールを飲んだ。www.youtube.comXでの投稿まとめまとめを作ってくれる人はいつの時代も偉大である。ありがとうございます。togetter.com参考資料Observability Whitepaperオブザーバビリティ入門：これから始める方への基本コンセプトとツールPractical MonitoringCloud Observability in ActionObservability EngineeringopenobserveObservability with Grafana【2024年度 サイバーエージェント 新卒研修】システム運用の基本と戦略オブザーバビリティ研修実践編オブザーバビリティ入門勘に頼らず原因を⾒つけるためのオブザーバビリティログから始めるオブザーバビリティフロントエンドにおけるObservabilityObservabilityについてOpenTelemetry実践 はじめの一歩分散トレーシングとOpenTelemetryのススメ / Getting started distributed tracing and OpenTelemetry仕様と実装で学ぶOpenTelemetry計測の手間を省きたい！OpenTelemetry に見る"自動計装"のイマPractical MonitoringopenobserveCloud Observability in ActionObservability Engineering「変化を嫌う人」を動かす: 魅力的な提案が受け入れられない4つの理由解像度を上げる 🔬具体と抽象 世界が変わって見える知性のしくみ「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策他者と働く「わかりあえなさ」から始める組織論]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[可観測性ガイダンス]]></title>
            <link>https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu</link>
            <guid>https://speakerdeck.com/nwiizo/ke-guan-ce-xing-kaitansu</guid>
            <pubDate>Tue, 04 Jun 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[可観測性ガイダンスというタイトルで登壇してきました。イベント名: オブザーバビリティ再入門 - 大切さと高め方を知ろう！イベントURL: https://mackerelio.connpass.com/event/316449/# ブログでいくつかの可観測性に関する書籍のまとめを投稿しました。5年後には標準になっている可観測性のこと - Learning Opentelemetry の読書感想文https://syu-m-5151.hatenablog.com/entry/2024/04/16/180511もう一度読むObservability Engineeringhttps://syu-m-5151.hatenablog.com/entry/2024/05/06/090014盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文https://syu-m-5151.hatenablog.com/entry/2024/05/10/121047]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREに求められるスキルと心構え]]></title>
            <link>https://sreake.com/blog/sre-required-skills-and-mindset/</link>
            <guid>https://sreake.com/blog/sre-required-skills-and-mindset/</guid>
            <pubDate>Mon, 03 Jun 2024 01:56:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは、最近の私の人生はキックボクシングとコーディングの2つの活動に極端に偏りつつあります。nwiizoです。一見正反対のようなこの2つの活動ですが、共通する本質があります。それは、頭で考えるだけでなく、実 […]The post SREに求められるスキルと心構え first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fiber v3 を使ったが変更点を確認だけして手癖で解決した]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/05/31/122850</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/05/31/122850</guid>
            <pubDate>Fri, 31 May 2024 03:28:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこの記事では、プログラミング言語のGoとWebフレームワークであるFiber v3を使って、リレーショナルデータベースのPostgreSQLをバックエンドに利用したCRUD (Create, Read, Update, Delete) 操作ができるWeb APIを作成する方法を説明します。本来であれば、Fiber v3の新機能や変更点を活用したかったのですが、十分な調査を行う前に雰囲気で実装を進めてしまったため、本記事ではそれらを採用できておりません。深夜に検証を行っていたこともあり、ベストプラクティスとは言えない部分があることを認識しています。エンジニアとして、新しいバージョンのフレームワークを使う際には、事前に十分な調査を行い、新機能や変更点を理解した上で実装を進めるべきでした。GitHub Copilot とLanguage Server で適当に書いてしまいました。また、コードの品質を保つためには、適切な時間帯に集中して作業を行うことが重要です(これはガチ)。今回の実装では、これらの点が不十分であったことを反省しています。業務では、技術選定や実装方法について、より慎重に検討を行い、品質の高いコードを書くことを心がけたいと思います。読者の皆様におかれましては、本記事の内容を参考にする際には、上記の点にご留意いただければ幸いです。github.comプロジェクトの初期化まず、新しいGoプロジェクトを作成します。mkdir fiber-crud-apicd fiber-crud-apigo mod init github.com/yourusername/fiber-crud-api必要なパッケージのインストール次に、必要なパッケージをインストールします。go get github.com/gofiber/fiber/v3go get github.com/lib/pqデータベースの設定とモデルの定義main.goファイルを作成し、以下のようにデータベースの設定とモデルを定義します。package mainimport (    "database/sql"    "encoding/json"    "fmt"    "log"    "time"    "github.com/gofiber/fiber/v3"    _ "github.com/lib/pq")const (    host     = "db"    port     = 5432    user     = "postgres"    password = "password"    dbname   = "mydb")// Connect to the databasefunc Connect() (*sql.DB, error) {    psqlInfo := fmt.Sprintf("host=%s port=%d user=%s password=%s dbname=%s sslmode=disable", host, port, user, password, dbname)    db, err := sql.Open("postgres", psqlInfo)    if err != nil {        return nil, err    }    return db, nil}// User modeltype User struct {    ID        int       `json:"id"`    Name      string    `json:"name"`    Email     string    `json:"email"`    Password  string    `json:"password"`    CreatedAt time.Time `json:"created_at"`}// Post modeltype Post struct {    ID        int       `json:"id"`    UserID    int       `json:"user_id"`    Title     string    `json:"title"`    Content   string    `json:"content"`    CreatedAt time.Time `json:"created_at"`    UpdatedAt time.Time `json:"updated_at"`}APIエンドポイントの実装続けて、main.goファイルにAPIエンドポイントを実装します。v2 の時には存在していたctx のbodyparserがv3ではなくなっていたので手癖でJSONで返したのですがおそらくBind周りで実装するとよいみたいです(あとから気付きました...)。v2からv3の変更点については以下を参考にしてください。docs.gofiber.iofunc main() {    app := fiber.New()    // データベース接続    db, err := Connect()    if err != nil {        log.Fatal(err)    }    defer db.Close()    // Create User    app.Post("/users", func(c fiber.Ctx) error {        user := new(User)        if err := json.Unmarshal(c.Body(), user); err != nil {            return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{                "error": "Invalid request body",            })        }        // パスワードのハッシュ化やバリデーションを行うことが推奨される        // 簡易実装のため、ここでは省略        // データベースにユーザーを作成        _, err := db.Exec("INSERT INTO users (name, email, password) VALUES ($1, $2, $3)", user.Name, user.Email, user.Password)        if err != nil {            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                "error": "Failed to create user",            })        }        return c.Status(fiber.StatusCreated).JSON(fiber.Map{            "message": "User created",        })    })    // Get User    app.Get("/users/:id", func(c fiber.Ctx) error {        id := c.Params("id")        // データベースからユーザーを取得        row := db.QueryRow("SELECT * FROM users WHERE id = $1", id)        user := new(User)        if err := row.Scan(&user.ID, &user.Name, &user.Email, &user.Password, &user.CreatedAt); err != nil {            if err == sql.ErrNoRows {                return c.Status(fiber.StatusNotFound).JSON(fiber.Map{                    "error": "User not found",                })            }            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                "error": "Failed to get user",            })        }        return c.JSON(user)    })    // Create Post    app.Post("/posts", func(c fiber.Ctx) error {        post := new(Post)        if err := json.Unmarshal(c.Body(), post); err != nil {            return c.Status(fiber.StatusBadRequest).JSON(fiber.Map{                "error": "Invalid request body",            })        }        // データベースに記事を作成        _, err := db.Exec("INSERT INTO posts (user_id, title, content) VALUES ($1, $2, $3)", post.UserID, post.Title, post.Content)        if err != nil {            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                "error": "Failed to create post",            })        }        return c.Status(fiber.StatusCreated).JSON(fiber.Map{            "message": "Post created",        })    })    // Get Post    app.Get("/posts/:id", func(c fiber.Ctx) error {        id := c.Params("id")        // データベースから記事を取得        row := db.QueryRow("SELECT * FROM posts WHERE id = $1", id)        post := new(Post)        if err := row.Scan(&post.ID, &post.UserID, &post.Title, &post.Content, &post.CreatedAt, &post.UpdatedAt); err != nil {            if err == sql.ErrNoRows {                return c.Status(fiber.StatusNotFound).JSON(fiber.Map{                    "error": "Post not found",                })            }            return c.Status(fiber.StatusInternalServerError).JSON(fiber.Map{                "error": "Failed to get post",            })        }        return c.JSON(post)    })    log.Fatal(app.Listen(":3000"))}このコードでは、以下のエンドポイントを実装しています。POST /users: 新しいユーザーを作成します。GET /users/:id: 指定されたIDのユーザーを取得します。POST /posts: 新しい記事を作成します。GET /posts/:id: 指定されたIDの記事を取得します。Dockerfileとdocker-compose.ymlの作成開発環境用のDockerfileとdocker-compose.ymlを作成します。これも簡易的に用意した適当なファイルなので十分に吟味してください。FROM golang:1.22-alpineWORKDIR /appCOPY go.mod go.sum ./RUN go mod downloadCOPY . .RUN go build -o main .CMD ["./main"]version: '3'services:  app:    build: .    ports:      - "3000:3000"    depends_on:      - db  db:    image: postgres    environment:      POSTGRES_USER: postgres      POSTGRES_PASSWORD: password      POSTGRES_DB: mydb    volumes:      - ./init.sql:/docker-entrypoint-initdb.d/init.sqlデータベースの初期化スクリプトinit.sqlファイルを作成し、データベースの初期化スクリプトを記述します。CREATE TABLE users (    id SERIAL PRIMARY KEY,    name VARCHAR(255) NOT NULL,    email VARCHAR(255) UNIQUE NOT NULL,    password VARCHAR(255) NOT NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);CREATE TABLE posts (    id SERIAL PRIMARY KEY,    user_id INTEGER REFERENCES users(id),    title VARCHAR(255) NOT NULL,    content TEXT NOT NULL,    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP);アプリケーションの実行以下のコマンドを実行してアプリケーションを起動します。docker-compose up --buildこれで、GoとFiberを使ってCRUDができるAPIが作成され、PostgreSQLをバックエンドに利用する環境が整いました。APIエンドポイントをテストするために、cURLやPostmanなどのツールを使用してリクエストを送信できます。APIのテストとデータベースの確認アプリケーションを起動した後、CURLを使ってAPIエンドポイントをテストし、PostgreSQLの中身を確認してみましょう。ユーザーの作成と確認まず、新しいユーザーを作成します。curl -X POST -H "Content-Type: application/json" -d '{"name":"John Doe","email":"john@example.com","password":"secret"}' http://localhost:3000/usersレスポンスとして、"User created"が返ってくるはずです。次に、作成したユーザーを確認します。curl http://localhost:3000/users/1レスポンスとして、作成したユーザーの情報がJSON形式で返ってきます。{"id":1,"name":"John Doe","email":"john@example.com","password":"secret","created_at":"2023-04-24T12:34:56Z"}PostgreSQLの中身を確認するために、データベースにログインします。docker-compose exec db psql -U postgres mydbユーザーテーブルの中身を確認します。SELECT * FROM users;作成したユーザーがテーブルに存在することを確認できます。 id |  name   |     email      | password |         created_at----+---------+----------------+----------+----------------------------  1 | John Doe| john@example.com| secret   | 2024-05-30 01:34:56.789012(1 row)記事の作成と確認次に、新しい記事を作成します。curl -X POST -H "Content-Type: application/json" -d '{"user_id":1,"title":"My First Post","content":"Hello, World!"}' http://localhost:3000/postsレスポンスとして、"Post created"が返ってくるはずです。作成した記事を確認します。curl http://localhost:3000/posts/1レスポンスとして、作成した記事の情報がJSON形式で返ってきます。{"id":1,"user_id":1,"title":"My First Post","content":"Hello, World!","created_at":"2023-04-24T12:45:67Z","updated_at":"2023-04-24T12:45:67Z"}再度、PostgreSQLの中身を確認します。SELECT * FROM posts;作成した記事がテーブルに存在することを確認できます。 id | user_id |    title     |    content    |         created_at         |         updated_at----+---------+--------------+---------------+----------------------------+----------------------------  1 |       1 | My First Post| Hello, World! | 2024-05-30 01:45:67.890123 | 2024-05-30 01:45:67.890123(1 row)以上で、APIのテストとデータベースの確認が完了しました。さいごに以上が、GoとFiberを使ってCRUDができるAPIを作成し、PostgreSQLをバックエンドに利用する方法です。実際のアプリケーションでは、エラーハンドリングやバリデーションなどを追加し、より堅牢なAPIを作成することが重要です。また、認証や認可、ページネーション、フィルタリングなどの機能も必要になるでしょう。データベースのマイグレーションツールを使用して、テーブル構造の変更を管理することも忘れずに。本当に手癖でやってみただけです。楽しかったです。この記事を書いている時にはaikoを聴いていたのでプレイリストも共有です。open.spotify.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud SQL for PostgreSQLのベクトル検索を試す]]></title>
            <link>https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search</link>
            <guid>https://zenn.dev/nnaka2992/articles/play_with_cloud_sql_vector_search</guid>
            <pubDate>Sun, 26 May 2024 15:54:14 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Next '24でGoogle Cloudが提供するすべてのマネージドデータベースにベクトル検索の機能が追加されました。[1]今回はそのなかのCloud SQL for PostgreSQLにフォーカスしてベクトル検索機能を試します。 Cloud SQL for PostgreSQL インスタンススペックエディションEnterprisevCPU2RAM8GBストレージタイプSSDZoneasia-northeast1接続パブリックIPを有効化 必要な設定を行うデータベースを作成す...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Geminiはトーク分析ツールに取って代わるか]]></title>
            <link>https://sreake.com/blog/gemini-talk-analysis/</link>
            <guid>https://sreake.com/blog/gemini-talk-analysis/</guid>
            <pubDate>Fri, 24 May 2024 10:28:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 初めまして、Sreake事業部アプリケーション開発支援チームの大美です。 先日、Googleのマルチモーダル生成AIモデル Gemini 1.5 Pro のコンテキストウィンドウが100万→200万トークンにア […]The post Geminiはトーク分析ツールに取って代わるか first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloudのプロンプト比較機能を用いた、言語モデルにおけるプロンプト設計]]></title>
            <link>https://sreake.com/blog/google-cloud-prompt-design/</link>
            <guid>https://sreake.com/blog/google-cloud-prompt-design/</guid>
            <pubDate>Fri, 24 May 2024 09:52:32 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部の井上 秀一です。私はSreake事業部にて、SREや生成AIに関するResearch & Developmentを行っています。 本記事では、Google Clo […]The post Google Cloudのプロンプト比較機能を用いた、言語モデルにおけるプロンプト設計 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes Code Contribution入門]]></title>
            <link>https://speakerdeck.com/bells17/kubernetes-code-contributionru-men</link>
            <guid>https://speakerdeck.com/bells17/kubernetes-code-contributionru-men</guid>
            <pubDate>Tue, 21 May 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Kubernetes Novice Tokyo #32 で登壇したセッションの資料です。https://k8s-novice-jp.connpass.com/event/317561/配信URL:https://www.youtube.com/live/sRLG9ufaZ4M]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Oracle Dataabse 19cの検証環境が欲しいからProxmoxに環境構築する]]></title>
            <link>https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox</link>
            <guid>https://zenn.dev/nnaka2992/articles/install_oracle_19c_to_proxmox</guid>
            <pubDate>Sun, 19 May 2024 14:18:18 GMT</pubDate>
            <content:encoded><![CDATA[概要300年ぶりぐらいに、ローカル環境(非Cloud環境)でホストしたOracle Databaseが欲くなったので、自宅にあるProxmoxへインストールします。 前提Proxmoxにダウンロード済みのOracle Linux 9のイメージを利用する。利用するOracle Databaseは19cとする。検証環境のため本番用途に適した設定ではない。 Proxmox VMを建ち上げる Oracle Database 19cのサーバ要件今回関係あるもののみ抜粋しています。OSOracle Linux 9およびRed Hat互換カーネル: 5.14.0-...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pulumi コマンド を GitHub Actions で実行する]]></title>
            <link>https://zenn.dev/z63d/articles/0d6b3ee4e9a44e</link>
            <guid>https://zenn.dev/z63d/articles/0d6b3ee4e9a44e</guid>
            <pubDate>Sat, 18 May 2024 05:30:31 GMT</pubDate>
            <content:encoded><![CDATA[背景副業で Pulumi を使っています。プロバイダーなどのパッケージのバージョン更新をサボっていたのですが、対応しようと思い Renovate で更新するようにしました。しかし、PR が来た時点では Pulumi の差分が分かりません。ローカルで pulumi preview を実行して差分がないことを毎回確認するのは面倒なので GitHub Actions で pulumi preview を実行して PR のコメントで差分を表示してもらうことにしました。 環境Pulumi CloudPulumi + TypeScriptGoogle Cloud 実装していく...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SLOいつ決めましょう？というタイトルで #第3木曜LT会 に登壇した]]></title>
            <link>https://abnoumaru.com/tech/2024-05-18-third-thursday-lt/</link>
            <guid>https://abnoumaru.com/tech/2024-05-18-third-thursday-lt/</guid>
            <pubDate>Sat, 18 May 2024 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[登壇してきました]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CloudSQL for PostgreSQLのベンチマークと比較して理解するAlloyDBの特徴]]></title>
            <link>https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres</link>
            <guid>https://zenn.dev/nnaka2992/articles/compare_alloydb_and_postgres</guid>
            <pubDate>Fri, 17 May 2024 15:16:13 GMT</pubDate>
            <content:encoded><![CDATA[概要Google Cloudが提供するPostgreSQL互換データベースであるAlloyDBのパフォーマンスをトランザクション用途・分析用途の双方から検証する。今回の検証ではAlloyDBの上限を見定めるのではなく、CloudSQLと比べてどのようなパフォーマンスになるを目的とする。 TL;DR絞り込み条件がインデックスに限定されない場合、AlloyDBのパフォーマンスメリットが特に大きくなる。絞り込み条件がインデックスに限定され、かつデータサイズが小さい場合、CloudSQL for PostgreSQLのコストパフォーマンスが大きくなる。現将・将来のワークロード...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[Kubernetes 1.30] kube-proxy の nftables モード]]></title>
            <link>https://zenn.dev/toversus/articles/dcb888d73f0615</link>
            <guid>https://zenn.dev/toversus/articles/dcb888d73f0615</guid>
            <pubDate>Thu, 16 May 2024 23:43:33 GMT</pubDate>
            <content:encoded><![CDATA[kube-proxyService へのトラフィックをプロキシするコンポーネントのデフォルト実装e.g.) Cluster IP への通信を Pod IP にリダイレクトするEndpointSlice, Service, Node などのオブジェクトの変更を検知して Service を介したトラフィックのルーティングを可能にするContainer Network Interface (CNI) vs kube-proxyCNI が Pod 間で通信できるように Pod IP の払い出しやルーティングをセットアップするPod は一時的なものかつ Pod ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SLOいつ決めましょう？]]></title>
            <link>https://speakerdeck.com/abnoumaru/sloitujue-memasiyou</link>
            <guid>https://speakerdeck.com/abnoumaru/sloitujue-memasiyou</guid>
            <pubDate>Thu, 16 May 2024 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[第3木曜LT会というイベントの「SREどうでしょう」という会でSLOはいつ決めたらよいか？自分なりに考えた結果を発表したLT資料https://metaps.connpass.com/event/313921/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud SQL(MySQL)とSpring Bootの画像検索アプリケーション作成]]></title>
            <link>https://sreake.com/blog/cloudsql-spring-boot-image-search-app/</link>
            <guid>https://sreake.com/blog/cloudsql-spring-boot-image-search-app/</guid>
            <pubDate>Wed, 15 May 2024 00:02:44 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Google Cloud Next ’24 にて Cloud SQL for MySQL にて Embedding データを入れられるようになったというアナウンスが有りました。 https://cl […]The post Cloud SQL(MySQL)とSpring Bootの画像検索アプリケーション作成 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[自動化するならちゃんとエラーを出せ。想定しろ。不安になれ。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/05/11/115518</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/05/11/115518</guid>
            <pubDate>Sat, 11 May 2024 02:55:18 GMT</pubDate>
            <content:encoded><![CDATA[はじめに自動化やツール開発において、通常時に上手くいくのは当たり前です。大切なのは失敗を想定することです。自動化したツールがエラーも出さずに実行結果的にも成功してるので動いていると思っていたら、実は問題が発生していて泣いた経験は、多くの人にあるのではないでしょうか。エラーを出力し、適切に失敗させて、ログに記録することで、問題の早期発見と迅速な対応が可能になります。また、エラーが発生する可能性のある箇所を事前に想定し、適切に処理することで、ツールの信頼性と安定性が向上します。しかし、エラーハンドリングができていても、それだけでは不十分です。優れた自動化ツールは、環境の変化に柔軟に対応できるようにコードが設計されているべきです。また、自動化ツールの完成度を高めるには、エラーハンドリングだけでなく、保守性、拡張性、ユーザビリティなども考慮する必要があります。自動化ツールを開発する際は、常に不安を抱きながらコードを書くことが重要です。「もしこの部分が失敗したらどうなるだろう」「これで本当に大丈夫だろうか」と自問自答しながら、エッジケースを想定し、想定外のエラーが発生した場合の対策を講じておくことが求められます。本記事では、Golang とシェルスクリプトを例に、エラーハンドリングの具体的な方法や、自動化ツール開発における留意点のいくつかについて解説していきます。はじめにで触れた内容の一部については、詳細な説明を割愛していますので、ご了承ください。Golang でのエラーハンドリングGolang には例外機構はありませんが、関数の戻り値として error を返すのが一般的です。以下は、引数のバリデーションをして、想定外ならエラーを返す例です。type MyOption struct {    IsHoge bool    Fuga   int}func f(s string, o MyOption) error {    if !regexp.MustCompile(`^A-\d{4,8}$`).MatchString(s) {        return fmt.Errorf("invalid argument: s must be in format A-\\d{4,8}")    }    if o.IsHoge && o.Fuga == 0 {        return fmt.Errorf("invalid argument: o.Fuga is required if o.IsHoge is true")    }    // 処理本体...    return nil}このように、関数の先頭で引数をバリデーションし、想定外ならエラーを返すようにしています。また、エラーメッセージは fmt.Errorf を使って生成しています。これは、エラーメッセージをフォーマットする際のベストプラクティスです。さらに、エラーが発生した場合は、適切にエラーを処理することが大切です。以下は、エラーをログ出力し、さらに上位の関数に返している例です。func doSomething() error {    err := f("A-1234", MyOption{IsHoge: true, Fuga: 1})    if err != nil {        log.Printf("failed to call f: %v", err)        return fmt.Errorf("failed to do something: %w", err)    }    // 処理続行...    return nil}ここでは、f 関数でエラーが発生した場合、ログ出力をしつつ、fmt.Errorf を使ってエラーをラップして返しています。%w は Go 1.13 から導入された Wrapping Verb で、元のエラーを内包した新しいエラーを生成します。これにより、エラーの因果関係が明確になり、デバッグがしやすくなります。シェルスクリプトでのエラーハンドリングシェルスクリプトでも、コマンドの実行結果を適切にチェックし、エラーを検出することが重要です。以下は、コマンドの実行結果をチェックする一般的なパターンです。some_commandif [ $? -ne 0 ]; then    echo "some_command failed"    exit 1fi$? は直前のコマンドの終了ステータスを表す特殊変数です。0 であれば成功、0 以外であればエラーを表します。また、あるコマンドの実行結果を別のコマンドにパイプで渡す場合、パイプラインの途中でエラーが発生してもシェルスクリプトは中断されません。これを防ぐには、以下のようにします。set -o pipefailsome_command | another_commandif [ $? -ne 0 ]; then    echo "pipeline failed"    exit 1fiset -o pipefail は、パイプラインのいずれかのコマンドが0以外の終了ステータスを返した場合、パイプライン全体の終了ステータスをそのコマンドの終了ステータスにするオプションです。外部リソースのエラーハンドリング自動化ツールでは、外部APIやデータベースへのアクセスが頻繁に行われます。これらの外部リソースは、ネットワークの問題などで必ず失敗する可能性があることを念頭に置く必要があります。Golang では、net/http パッケージを使った HTTP リクエストが一般的です。以下は、タイムアウトを設定し、レスポンスのステータスコードをチェックする例です。client := &http.Client{    Timeout: 10 * time.Second,}resp, err := client.Get("https://3-shake.com/")if err != nil {    return fmt.Errorf("failed to get: %w", err)}defer resp.Body.Close()if resp.StatusCode != http.StatusOK {    return fmt.Errorf("unexpected status code: %d", resp.StatusCode)}// レスポンスの処理...シェルスクリプトでは、curl コマンドがよく使われます。以下は、curl コマンドのエラーをチェックする例です。response=$(curl -s -w "%{http_code}" https://example.com/api/hoge)status_code=$(tail -n1 <<< "$response")  # 最後の行がステータスコードbody=$(sed '$d' <<< "$response")  # 最後の行以外がレスポンスボディif [ $status_code -ne 200 ]; then    echo "unexpected status code: $status_code"    exit 1fi# レスポンスの処理...-s オプションでサイレントモードにし、-w "%{http_code}" でレスポンスのステータスコードを出力しています。デバッグをできるようにするデバッグから逃げてはいけません。問題が発生した際に、どこで何が起きているのかを把握できることは重要です。シェルスクリプトでは、bash -x オプションを使うことでデバッグ出力を有効にできます(他のシェルでも似たようなオプションがある)。このオプションを付けてスクリプトを実行すると、各コマンドが実行される前に、そのコマンドが表示されます。これにより、スクリプトのどの部分が実行されているのか、変数がどのように展開されているのかを確認できます。bash -x ./your_script.shGolang にも同様のデバッグ機能があります。delve というデバッガを使うことで、Golang プログラムのデバッグが可能です。delve を使えば、ブレークポイントを設定してプログラムを停止させ、変数の値を確認したり、ステップ実行したりできます。# delve のインストールgo get -u github.com/go-delve/delve/cmd/dlv# デバッグ実行dlv debug ./your_program.goデバッグ実行中は、break コマンドでブレークポイントを設定し、continue でプログラムを再開、next で次の行に進むなどの操作ができます。これらのデバッグ機能を活用することで、問題の原因をより迅速に特定できるようになります。まとめGolang では、関数の戻り値として error を返し、適切にエラーをハンドリングしよう。シェルスクリプトでは、コマンドの終了ステータスをチェックし、パイプラインのエラーにも対処しよう。外部リソースは必ず失敗すると想定してコードを書こう。 タイムアウトの設定やエラーチェックを忘れずに。自動化は常に不安であり、モニタリングすることを忘れずに。デバッグから逃げるな。個人的に自動化に関してはエッジケースの処理を上手くやっていたりすると「オー」って思うのに問題がないので目立たないので今回は記事を書きました。しっかりと失敗することを想定することで、自動化ツールの信頼性と保守性は大きく向上します。 Golang とシェルスクリプトの両方で、エラーとうまく付き合っていきましょう。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI RAGアプリ開発ハンズオン]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2024/05/10/173352</link>
            <guid>https://shu-kob.hateblo.jp/entry/2024/05/10/173352</guid>
            <pubDate>Fri, 10 May 2024 08:33:52 GMT</pubDate>
            <content:encoded><![CDATA[shu-kob.hateblo.jp↑前回の復習をしていきます。前回参加していない方も大丈夫です。PDFをディレクトリに配置して、取り込む作業が面倒なので、画面からPDFをアップロードできるようにしましょう。chainlit_upload_pdf.pyimport osimport chainlit as clfrom langchain_community.chat_models import ChatOpenAIfrom langchain_community.document_loaders import PyMuPDFLoaderfrom langchain_community.embeddings import OpenAIEmbeddingsfrom langchain.prompts import PromptTemplatefrom langchain.schema import HumanMessagefrom langchain.text_splitter import SpacyTextSplitterfrom langchain_community.vectorstores import Chromaembeddings = OpenAIEmbeddings(  model="text-embedding-ada-002")chat = ChatOpenAI(model="gpt-3.5-turbo")prompt = PromptTemplate(template="""文章を元に質問に答えてください。文章:{document}質問: {query}""", input_variables=["document", "query"])text_splitter = SpacyTextSplitter(chunk_size=300, pipeline="ja_core_news_sm")@cl.on_chat_startasync def on_chat_start():  files = None  while files is None:    files = await cl.AskFileMessage(      max_size_mb=20,      content="PDFを選択してください",      accept=["application/pdf"],      raise_on_timeout=False,    ).send()  file = files[0]  if not os.path.exists("tmp"):    os.mkdir("tmp")    documents = PyMuPDFLoader(file.path).load()  splitted_documents = text_splitter.split_documents(documents)  database = Chroma(    embedding_function=embeddings,    # 今回はpersist_directoryを指定しないことでデータベースの永続化を行わない  )  database.add_documents(splitted_documents)  cl.user_session.set(    "database",    database  )  await cl.Message(content=f"`{file.name}`の読み込みが完了しました。質問を入力してください。").send()@cl.on_messageasync def on_message(input_message):  print("入力されたメッセージ: " + input_message.content)  database = cl.user_session.get("database")  documents = database.similarity_search(input_message.content)  documents_string = ""  for document in documents:    documents_string += f"""  -------------------------  {document.page_content}  """  result = chat([    HumanMessage(content=prompt.format(document=documents_string,     query=input_message.content))  ])  await cl.Message(content=result.content).send()前回の記事に書いた「prepare_db.py」を実行してDBを作っておく必要があります。Chainlitアプリを実行し、PDFをアップロードし、PDFの内容について質問可能chainlit run chainlit_upload_pdf.py -w使ってみたいPDFをアップロードしてみましょうなお、パスワード保護されているファイルは使えないはずIPAが多数のPDFファイルを公開しているので、これらも使ってみましょう。非機能要件記述とアーキテクチャ記述ガイドhttps://www.ipa.go.jp/archive/digital/iot-en-ci/jyouryuu/hikinou/ps6vr700000077he-att/000005155.pdfプロジェクトマネジメントの見える化https://www.ipa.go.jp/archive/files/000004090.pdf情報処理システム高信頼化教訓活用ガイドブック(ITサービス編)https://www.ipa.go.jp/archive/files/000051041.pdf情報セキュリティ対策ベンチマークから情報セキュリティ監査へhttps://www.ipa.go.jp/archive/files/000011534.pdf経営に活かす IT 投資の最適化 ～ 情報システムを安心して快適に使うために ～https://www.ipa.go.jp/archive/files/000004568.pdf安全なウェブサイト運営にむけてhttps://www.ipa.go.jp/security/todokede/vuln/ug65p90000019gda-att/000089537.pdf初めての情報セキュリティ対策https://www.ipa.go.jp/security/guide/ps6vr70000007pkg-att/09_hazimete_slide.pdf新・5分でできる！情報セキュリティ自社診断https://www.ipa.go.jp/security/guide/sme/ug65p90000019c86-att/000055848.pdfIPA脆弱性対策コンテンツリファレンスhttps://www.ipa.go.jp/security/guide/ssf7ph000000fjhe-att/000051352.pdfECサイト構築・運用セキュリティガイドラインhttps://www.ipa.go.jp/security/guide/vuln/ps6vr7000000acvt-att/000109337.pdf最初は「プロジェクトマネジメントの見える化」をアップロードしてみたいと思います。PDFに書かれていることがインプットされているかを確認するために、PDFの中身に関する質問をしてみましょう。なぜ下流工程で問題が顕在化しやすいのでしょうか？下流工程で問題が顕在化しやすい理由は、それまでの工程に起因する品質不良が下流工程に入り込みやすいためです。また、下流工程では問題が露呈しやすく、対応のための時間や手段が限定されているため、問題が早期に発見されても迅速に対処することが難しい状況にあるからです。そのため、下流工程での品質管理や問題解決には特に注意が必要とされています定性的見える化アプローチのチェックシートの使い方を教えてください。定性的見える化アプローチのチェックシートは、プロジェクトマネージャが自己評価を行うためのツールです。上流、中流、下流のそれぞれに対して35、38、40項目が設定されており、自己評価を行う際にそれぞれの項目に対してスコアをつけることで自己チェックを行います。また、専門家チーム（ＰＭＯ）によるヒアリングシートもあり、上流、中流、下流それぞれに対して74、78、85項目が設定されています。専門家の客観的なチェックを受けることで、マネジメントの過不足を把握し、対策を検討することができます。自己評価と専門家の診断の差を認識し、専門家からの対策案を受け取ることで、プロジェクトの見える化を促進することができます。色んな質問をしてみたり、様々なPDFをアップロードしてみましょう。実際に体験してもらったところで、↓RAGなどの技術について過去資料を用いて解説したいと思います。 speakerdeck.com参考文献LangChain完全入門　生成AIアプリケーション開発がはかどる大規模言語モデルの操り方作者:田村 悠インプレスAmazonChatGPT/LangChainによるチャットシステム構築［実践］入門作者:吉田 真吾,大嶋 勇樹技術評論社AmazonGoogle Cloudで学ぶ生成AIアプリ開発入門 ――フロントエンドからバックエンドまでフルスタック開発を実践ハンズオン (Software Design plus)作者:中井 悦司技術評論社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[盲目的に始めないためのオブザーバビリティ実践ガイド - Cloud Observability in Actionの読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2024/05/10/121047</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2024/05/10/121047</guid>
            <pubDate>Fri, 10 May 2024 03:10:47 GMT</pubDate>
            <content:encoded><![CDATA[誕生日エントリー兼読書感想文です。www.amazon.jpはじめにクラウドコンピューティングの普及とマイクロサービスアーキテクチャの台頭により、システムの複雑性が増大しています。そのような中で、オブザーバビリティ(可観測性)の重要性が高まっています。本書「Cloud Observability in Action」は、クラウドネイティブなシステムにおけるオブザーバビリティの概念と実践方法を包括的に解説した一冊です。learning.oreilly.comオブザーバビリティとは、システムの外部から観測できる情報に基づいて、内部の状態を推論し理解する能力のことを指します。本書では、オブザーバビリティを投資対効果の観点から捉え、データの生成から収集、処理、可視化に至るまでのプロセス全体を俯瞰します。OpenTelemetryやPrometheus、Grafana、Loki、Jaegerなどのオープンソースツールを活用し、誰でも実践的な知見を時間以外の費用をかけずに得られるよう工夫されています。著者自身の豊富な経験に基づくベストプラクティスが随所に盛り込まれているのと参考になるURLをめちゃくちゃに共有してくれております、開発者やSREだけでなく、あらゆるクラウドネイティブ関係者にとって有益な内容となっています。単なるツールの使い方の解説にとどまらず、オブザーバビリティを組織文化として定着させるためのヒントも提供されています。本書を通して、オブザーバビリティの本質的な価値とその実現に向けた道筋を学ぶことができるでしょう。得られた知見をどのように活用するかは読者次第ですが、システムと組織の継続的な進化を支える原動力として、オブザーバビリティをバズワードとして盲目的に始めずに目を見開いてオブザーバビリティを捉える視座を得られるはずです。本稿では、各章の要点を丁寧に読み解きながら、私なりの学びと気づきをシェアしていきます。皆様にとっても、オブザーバビリティへの理解を深め、その実践への一歩を踏み出すきっかけとなれば幸いです。Cloud Observability in Action作者:Hausenblas, MichaelManningAmazonこの本の構成本書「Cloud Observability in Action」では、クラウドネイティブなシステムにおけるオブザーバビリティの概念と実践方法が包括的に解説されています。第1章ではエンドツーエンドの例が示され、ソースからエージェント、宛先までの用語が定義されているとともに、可観測性の文脈におけるユースケース、役割、課題について説明されています。第2章ではログ、メトリック、トレースといったさまざまなテレメトリ信号タイプと、それらの使い分け方、収集方法、コストと利点について述べられています。第3章ではテレメトリが生成される信号ソースについて、種類や選択方法、インストルメントコードの扱い方が解説されています。第4章ではOpenTelemetryを中心に、ログルーターからのさまざまなテレメトリエージェントが紹介されています。第5章では、Prometheusなどの時系列データベースやClickHouseなどの列指向データストアを例に、テレメトリ信号のバックエンド宛先について学ぶことができます。第6章では可観測性フロントエンドについて、純粋なフロントエンドとオールインワンの選択方法が説明されています。第7章ではクラウドオペレーションの側面として、異常検知や過去の失敗からの学習、アラート、使用状況、コスト追跡について述べられています。第8章では分散トレースとマイクロサービスの理解・トラブルシューティングへの活用方法が、第9章では継続的なプロファイリングと開発者の生産性ツールを中心に開発者の可観測性について詳解されています。第10章ではサービスレベル目標の設定と消費者満足度の問題への対処方法が、第11章では単一の信号タイプでは解決できない課題と信号相関によるアプローチが取り上げられています。付録ではOpenTelemetry、Prometheus、Jaeger、Grafanaを使用した完全なエンドツーエンドの例が提供されています。Github Repositorygithub.com目次はじめにこの本の構成Github Repository目次1 End-to-end observabilityオブザーバビリティの定義と目的オブザーバビリティのコンポーネント具体例としてのマイクロサービスアプリ "Sock Shop"クラウドネイティブの課題とその解決オブザーバビリティはクラウドネイティブ時代の必須プラクティス2 Signal typesオブザーバビリティの3本柱ログ: 人間が読み解くテキストベースの出力メトリクス: 自動化された監視・分析に役立つ数値指標トレース: マイクロサービスの処理フローを可視化する収集する信号の選定とコスト管理オブザーバビリティを支える3本柱の理解と適切な運用が肝心3 Sourcesクラウドネイティブシステムにおける多様な信号源の理解と活用コンピューティング関連のソースの詳細ストレージ関連のソースの詳細ネットワーク関連のソースの詳細自身のコード関連の詳細4 Agents and instrumentationObservabilityにおけるAgentsとinstrumentationの役割意味論的規約の重要性自動計装と手動計装の使い分けOpenTelemetry collectorの役割と設定OpenTelemetryの柔軟性と拡張性パフォーマンスとリソース効率Observabilityの新しい標準としてのOpenTelemetry自動化と最適化の必要性Observabilityの継続的な改善5 Backend destinationsバックエンドの選択がObservabilityの成功を左右するシグナルタイプごとのバックエンドオプションカーディナリティの課題とカラムナーデータストアポリグロットバックエンドアーキテクチャ制約と誓約6 Frontend destinationsフロントエンドとオールインワンソリューションの役割オープンソースとコマーシャルオファリングの比較ツール選定の考慮事項シングルパネルオブグラスとデータ相関の重要性フロントエンドとオールインワンの選択プロセスObservabilityツールの継続的な評価と改善Observabilityの価値実現に向けて7 Cloud operationsインシデント管理のベストプラクティスアラート設計のポイントと継続的な最適化今後の課題8 Distributed tracing分散トレーシングでクラウドネイティブシステムを徹底的に可視化エンドツーエンドの可視化でシステムをホリスティックに理解分散トレーシングを成功に導く秘訣分散トレーシングの未来組織の分散トレーシングは俺と仲間で育ててる9 Developer observabilityDeveloper observabilityで開発者の生産性を加速するContinuous profilingの技術的側面に迫るプロファイルの保存と分析の課題に挑むあわせて6本にしてみる...10 Observability In ActionSLOでサービスの信頼性を定量化し、顧客満足度を高めるSLOの実装と運用における留意点サービスの継続的な改善の為のSLO11 Signal correlationシグナル相関で複雑なシステムの動作を俯瞰的に理解するOpenTelemetry、Jaeger、Grafanaを使ったメトリクスとトレースの相関シグナル相関の実装における課題と対策将来に向けたシグナル相関の可能性さいごに参考資料1 End-to-end observability本章「1 End-to-end observability」は、クラウドネイティブシステムにおけるオブザーバビリティ(観測可能性)の概念と重要性を詳しく述べています。Observability Engineeringについては読書感想文を書いているので合わせて読んでみてください。syu-m-5151.hatenablog.comオブザーバビリティの定義と目的オブザーバビリティとは、システムから取得できる信号に基づいて、そのシステムの内部状態を継続的に把握し、インサイトを得ることで、システムに影響を与える能力のことです。オブザーバビリティは単に監視(モニタリング)ツールを導入するだけでは不十分です。システムの外側から収集した情報を、そのままダッシュボードなどの可視化ツールに表示するのではなく、行動可能な洞察(アクショナブルなインサイト)を生み出すことが本質的な目的となります。つまり、観測対象のシステムの外側から情報を収集し、分析を行い、それらから具体的なアクション(行動)を引き出すプロセス全体を指します。クラウドネイティブの分散システムでは、システムを構成するコンポーネントが多数に分かれ、ネットワーク経由で相互に通信を行うため、従来のモノリシックなシステムに比べてシステム全体の状態把握が困難になります。このため、オブザーバビリティが非常に重要な役割を果たします。状況を"飛ばず"に把握し、適切な制御を行えるようになることで、以下のようなユースケースに対応できるようになります。コード変更の影響の把握: 新機能の追加やバグ修正によるシステム全体へのインパクト(パフォーマンスへの影響、副作用の発生、リソース使用量の変化など)をモニタリングし、必要な対処を行える。サードパーティ依存関係の監視: 自社のシステムが依存する外部API(決済サービス、ロケーションサービスなど)の可用性、健全性、パフォーマンスを把握し、問題が発生した際の対応を行える。ユーザー体験(UX)の測定: アプリケーションやサービスの応答性、信頼性をユーザーの視点から継続的に測定し、UXの維持・改善につなげられる。システムの健全性とパフォーマンスの追跡: システム全体のアップタイム、応答時間分布、障害の影響範囲(有償ユーザへの影響、無償ユーザへの影響、重要取引先への影響など)を継続的に監視できる。障害の影響範囲(ブラストレディウス)の特定: 障害発生時に、その障害がシステム全体にどの程度影響を与えているのか(ブラストレディウス)を特定できる。さらに根本原因を絞り込み、Kubernetesコントロールプレーン、データプレーン、VMなどの障害発生場所を特定できる。サービスの最適化: サービスのパフォーマンス、リソース使用量、コスト、応答時間などを定量的に測定し、ボトルネックの特定や最適化を行える。開発者生産性の向上: アプリケーションコードのプロファイリングやログ解析などを通じて、パフォーマンスの問題箇所や冗長なコードの特定が可能になり、適切にコード改善を行うことで開発者の生産性を高められる。アクセスとコンプライアンスの監査: 様々なサービスやデータへのアクセス権限を自動的に追跡し、不正アクセスを検知できる。さらに監査証跡を残すことで、規制当局からの検査に備えられる。オブザーバビリティの目的は、上記のようなユースケースに対して、システムの状況をデータドリブンに把握し、適切な対処を迅速に行えるよう支援することにあります。単なるモニタリングツールの導入ではなく、収集した様々な種類の情報から総合的かつ根本的な理解を得て、それに基づいてアクションを起こすことが重要となります。オブザーバビリティのコンポーネントオブザーバビリティを実現するためには、さまざまなコンポーネントが関係してきます。これらのコンポーネントが有機的に連携し、それぞれの役割を果たすことで、オブザーバビリティが実現されます。主なコンポーネントは以下の通りです。システム(System under observation): 観測対象となるクラウドネイティブアプリケーションやプラットフォーム全体信号(Signals): システムから外部に出力される、以下の3種類の情報ログ: アプリケーションの動作履歴をプレーンテキストで記録した情報。エラーメッセージや例外の詳細情報などが含まれる。メトリクス: アプリケーションの運用状況を数値で表した指標。CPU使用率、メモリ使用量、リクエスト処理時間、エラー率などのデータ。トレース: 個々のリクエストがシステムの各コンポーネントを通過する際の、処理フローと時間情報の記録。サービス間の呼び出し関係と、それぞれの処理にかかった時間を特定できる。ソース(Sources): アプリケーションコード、データベース、メッセージキュー、クラウドプロバイダのマネージドサービスなど、信号を生成するコンポーネント。エージェント(Agents): 信号を収集し、前処理やルーティングを行う役割。例えばFluentBitはログのエージェント、OpenTelemetry Collectorはメトリクス/トレースのエージェントとして機能する。宛先(Destinations): ダッシュボード、アラートシステム、長期ストレージ、分析ツールなど、信号を消費し可視化/分析を行う場所。Telemetry: 信号をソースから収集し、エージェントを経由して前処理や分割を行った後、宛先に送信するプロセス全体のこと。fluentbit.io以下の図はこれらのコンポーネント間の関係を視覚化しています。Figure 1.1 Observability overview より引用オブザーバビリティは一方通行のプロセスではなく、フィードバックループを形成しています。例えば、人間がダッシュボードから情報を得て再起動のアクションを取ったり、アプリケーションがメトリクスに基づいて自動スケーリングを行ったりと、収集した信号に基づいてシステムに影響を与えることになります。様々な信号を組み合わせて分析することで、より深いシステムの理解につながり、適切なアクションを起こすことができます。単一の信号からは得られない総合的なインサイトを、信号間の相関によって引き出すことが可能になります。具体例としてのマイクロサービスアプリ "Sock Shop"本章では、Weaveworksが公開しているマイクロサービスアプリケーション"Sock Shop"を具体例に、オブザーバビリティの実践を説明しています。Sock Shopは、Spring Boot、Go kit、Node.jsなど複数の言語・フレームワークを用いて構築された、オンラインストアのデモアプリです。kakakakakku.hatenablog.comDocker コンテナイメージに格納されており、Kubernetes などのコンテナオーケストレーターで実行できます。Figure 1.2 The example microservices app we use for observability exploration より引用本章では、このアプリを実際にKubernetes上で起動し、それぞれのコンポーネントが出力するログやメトリクスの具体例が紹介されています。ログの例(ソース: ordersサービス)Javaで実装されたSpring Bootベースのマイクロサービスから出力されるログが示されています。ログを有効に活用するには、FluentBitなどのエージェントを使ってOpenSearch や CloudWatch などの宛先にルーティングする必要があります。メトリクスの例(ソース: frontendサービス)フロントエンドのNode.jsサービスから出力されるメトリクスがPrometheus形式で示されています。メトリクスを収集するには、Prometheus自身かOpenTelemetry Collectorなどのエージェントが必要です。長期保持のためにはCortexやThanosなどの宛先を用います。このようにSock Shopは、実際にクラウドネイティブなマイクロサービスアプリケーションが出力する様々な信号を確認できる題材として使われています。github.comさらに、トレースについても簡単に触れられており、リクエストの実行フローの可視化や、各サービスの処理時間、ステータスなどを確認できるとされています。オブザーバビリティを実現するには、Jaeger、Zipkin、AWS X-Rayなどのトレーシングツールの導入が必要になります。クラウドネイティブの課題とその解決クラウドネイティブなシステムには、従来のモノリシック構成のシステムとは異なる以下のような課題があり、オブザーバビリティがその解決を助けます。分散システム: コンポーネントが分散し、ネットワーク経由で疎結合に結ばれているため、システム全体を把握することが難しい。モノリシックな構成に比べ、システムの"見えづらさ"が高まる。コンポーネントの場所の重要性: リクエストを処理する各コンポーネントの実行場所(ノード、アベイラビリティーゾーン、リージョンなど)が、パフォーマンスやレイテンシーに大きく影響する。場所情報の重要性が増す。コンポーネントの頻繁な入れ替えと揮発性: マイクロサービスのコンポーネントやKubernetesのPod、Lambda関数バージョンの入れ替えが非常に頻繁に行われ、さらにIPアドレスも動的に変化するなど、システム構成の揮発性が高まる。これらの課題に対して、オブザーバビリティは以下のように貢献します。全ての関連する信号を自動収集し、アクションに結びつける手段を与えるシステムを"飛ばず"に把握し、状況に応じた適切な制御を行えるようになる。ログ、メトリクス、トレースなど複数の信号を収集・分析することで、システムへの深い理解を得られる。信号間の相関により、単一の信号からは得られない総合的な把握が可能になる異なる種類の信号を組み合わせることで、より包括的な視点が得られる。例えばメトリクスの異常からトレースにドリルダウンし、さらにログを確認することで、障害の原因を徹底的に追究できる。オープンスタンダードとオープンソースの採用によりポータビリティが確保され、特定のベンダーやプラットフォームへのロックインを回避できる例えば、OpenTelemetryを用いてアプリケーションに計装を行えば、後からデータ収集の宛先を柔軟に変更可能になる。異なるクラウドプロバイダ間や、オンプレとクラウドをまたいでも同じ方式が適用できる。一方で、オブザーバビリティの導入と運用には以下のようなコストがかかります。計装の開発者の労力アプリケーションコードにロギングやメトリクス、トレーシングの計装を行う必要があり、継続的な労力を要する。信号(ログなど)の保持コスト長期保持が必要なログなどの信号データを保存する、ストレージ費用が発生する。エージェントや計装自体の計算リソースオーバーヘッド信号収集やルーティングを行うエージェントプロセス自体に、一定のCPU/メモリリソースが必要になる。ネットワーク使用量に応じたコスト収集された信号のデータ転送に伴うネットワークトラフィックの費用も考慮しなければならない。これらのコストに見合うだけの投資対効果があるかどうかを、個々の状況において適切に判断する必要があります。効果の測定として、オブザーバビリティツールの導入前後での障害からの平均復旧時間(MTTR)の改善を確認するのが一般的です。その他、開発者のストレス軽減やワークライフバランスの向上など、定性的な効果も期待できます。Return on Investment Driven Observability では、この投資対効果について詳しく議論されています。本書では、教育的な観点から、ログ、メトリクス、トレースといった概念の境界線に沿って解説を進められています。しかし、実際の現場では、これらの概念が混在していることが多いです。プロジェクトやプロダクトが成熟するにつれ、スコープが広がり、概念の切り分けが難しくなるのです。例えば、ログデータの中にメトリクスとして活用できる情報が含まれていたり、トレースデータからログ的な情報を抽出したりすることがあります。また、これらの概念を組み合わせて、より高度な分析や監視を行うこともあるでしょう。本書を活用する際は、このような教育的な側面と実践的な側面のバランスを意識していただければと思いました。概念の境界線を理解することは重要ですが、同時に現場での柔軟な適用も必要不可欠です。本書で得た知識を基礎として、実際のプロジェクトやプロダクトの文脈に合わせて応用していくことが求められます。オブザーバビリティはクラウドネイティブ時代の必須プラクティスオブザーバビリティは、クラウドネイティブな分散システムを効果的に運用する上で不可欠なプラクティスと言えます。システムから出力される様々な信号(ログ、メトリクス、トレース)を収集し、相関させることで、システム全体の状況を多角的に把握し、適切な対処を迅速に行えるようになります。しかしながら、オブザーバビリティの導入と運用には一定のコストがかかります。計装の労力、データ保持コスト、リソースオーバーヘッド、ネットワークトラフィックなどです。これらのコストに見合うだけの効果(MTTRの改善、開発者の生産性向上など)があるかを、個別のユースケースにおいて検討する必要があります。オープンスタンダードとオープンソースのツールを適切に選択・活用することで、特定のベンダーにロックインされるリスクを回避でき、ポータビリティを確保できます。例えばOpenTelemetryはその好例です。オブザーバビリティは、単なるモニタリングツールの導入ではなく、システムへの深い理解を得て、適切なアクションにつなげるための実践的な取り組みです。クラウドネイティブ時代において、ソフトウェアエンジニアやSREが理解しておくべき重要な概念であり、実務で実践していく必要があります。syu-m-5151.hatenablog.com2 Signal typesオブザーバビリティの3本柱クラウドネイティブな分散システムを効率的に監視・運用するためには、ログ、メトリクス、トレースという3つの主要な信号タイプを適切に組み合わせたオブザーバビリティが不可欠です。本章では、それぞれの信号タイプについて詳しく解説されており、その特徴、計装の方法、コスト、利点、オブザーバビリティへの貢献などが丁寧に説明されています。さらに、実際のサンプルアプリケーションを用いた具体例を通して、各信号タイプの収集・可視化方法が示されており、監視システムの構築に役立つ実践的な知見が提供されています。ログ: 人間が読み解くテキストベースの出力ログはアプリケーションの動作履歴やエラー情報などをテキストで記録したものです。開発者がバグの特定を行ったり、SREが障害の原因を追跡する際に、ログの存在は非常に重要です。近年では構造化データ形式(JSONフォーマットなど)を用いたログが主流となり、コンテキスト情報(ラベル)を付与することで検索性や相関性が向上しています。本章ではGoの logrus ライブラリを使って、サンプルアプリケーションに構造化ログの出力機能を追加する例が示されています。github.com出力されたログは FluentBit エージェントによって収集され、 Loki へ転送されます。GrafanaでLokiのデータソースを設定してを、Lokiを使ってログを可視化・探索することができます。grafana.comログには計装のための開発コストや、大量のログデータを保持するためのストレージコストがかかります。しかし、大半の開発者に理解されており、プログラミング言語の標準ライブラリでサポートされているのがログの大きな利点です。保持コストを抑えるには、データの温度(アクセス頻度)に応じて適切な保持期間を設定することが重要です。ホットデータ: 直近のログであり、即座にアクセス可能で高速な検索性が求められる(数日〜数週間程度)ウォームデータ: すぐには必要ないが将来的に参照する可能性のあるログ(数ヶ月〜数年程度)コールドデータ: アクティブには使わないが規制上保持が義務付けられているログ(長期保持用のオブジェクトストレージなどに格納)ログは人間が読み解くことを前提とした信号タイプですが、近年では Promtail のようなエージェントによる構造化ログの収集や、Lokiのようなデータストアでのラベルベース検索が可能になってきました。一方で完全にテキスト検索に頼らず、トレースへの移行を推奨する意見 (https://arxiv.org/abs/2303.13402) もあり、ケースバイケースでの適切な選択が重要になってくるでしょう。grafana.comメトリクス: 自動化された監視・分析に役立つ数値指標メトリクスは定期的にサンプリングされる数値の指標であり、システムやアプリケーションの状態を数値で表します。CPU使用率、メモリ使用量、リクエスト処理時間、エラー率など、ほとんどの監視対象項目はメトリクスとして表現できます。メトリクスの大きな利点は、数値であるがゆえに自動化された監視・分析が可能になることです。本章ではGo製アプリケーションにPrometheus Client Libraryを使ってメトリクスの出力機能を追加し、エラー率のメトリクスを計算するコードが紹介されています。github.comこのアプリから出力されるメトリクスは Prometheus エージェントによって収集され、GrafanaでPrometheusのデータソースを設定して、Prometheusを使ってメトリクスを可視化・分析します。grafana.comメトリクスの計装コストは自動化の恩恵を受けられるケースが多く、比較的低コストです。プログラミング言語の標準ライブラリやミドルウェアによる自動計装の機能が増えてきており、手動での計装コストも限定的です。一方で、指標の種類が増えるとカーディナリティ爆発の問題が発生する可能性があります。例えばユーザーIDをメトリクスのラベルに含めると、大量のユーザーがいる場合に膨大な種類の指標が生成されてしまいます。このようなカーディナリティの高いメトリクスを時系列データベースで保持・検索しようとすると、パフォーマンスが極端に低下する恐れがあります。そのため、収集するメトリクスの種類を限定する、オートプルーニングを行うなど、適切なカーディナリティ管理が重要になります。また、大量のメトリクスデータを長期保持する際には、データ圧縮や集約が必須です。Cortex や Thanos のようなシステムが、スケーラブルなメトリクス長期保存のためのベストプラクティスを提供しています。収集するメトリクスの種類、保持期間、データ形式などを検討する必要があります。メトリクスの主な利用シーンとしては以下が挙げられます。ダッシュボード表示: CPU使用率や処理レイテンシーなどをリアルタイムにモニタリングするアラート発報: メトリクスの閾値超過を検知し、自動的にアラートを通知する自動スケーリング: リクエスト数などのメトリクスに基づいてリソースを動的に拡張/縮小するSLI/SLO監視: サービスレベルインディケータ(SLI)としてのメトリクスを使い、合意された目標水準(SLO)の達成状況をモニタリングするアノマリー検知: 機械学習で正常値の範囲を予測し、異常値を検出するメトリクスはオブザーバビリティを実現する上で中心的な役割を担う信号タイプです。数値指標であるがゆえに自動化が容易であり、リアルタイムな監視だけでなく長期的なトレンド分析や容量計画にも活用できます。トレース: マイクロサービスの処理フローを可視化するトレースは分散システムにおけるリクエストの処理フローを可視化する手段です。マイクロサービスアーキテクチャを採用する上で、そのコンポーネント間の呼び出し関係を把握することは非常に重要です。トレースはリクエストに固有のIDを割り当て、各サービスでの処理時間とステータスを記録することで、そのリクエストの実行フローを可視化します。本章では OpenTelemetry Go ライブラリ を使って、サンプルアプリケーションにトレーシングの機能を追加する例が示されています。github.com生成されたトレースは Jaeger によって収集・可視化されており、GrafanaでJaegerのデータソースを設定して、JaegerのTrace Viewを見ることができます。grafana.comトレースの計装コストは比較的高めですが、マイクロサービス間の呼び出し関係の可視化やボトルネックの特定に役立つため、分散システムを運用する上では非常に重要です。一方で、大量のトレースデータを保持するためのストレージコストや、リクエストへのコンテキスト伝搬によるパフォーマンスオーバーヘッドにも注意が必要です。トレースデータを保存するためのストレージとしては以下のようなアプローチが一般的です。専用のデータストア (ClickHouseなど)NoSQLデータベースを活用 (Cassandra、HBase、Elasticsearchなど)オブジェクトストレージとクエリエンジン (Grafana Tempoなど)各アプローチにはトレードオフがあり、データ量、検索パフォーマンス、コストなどの要件に合わせて適切なものを選択する必要があります。トレースの主な利用シーンは以下のようになります。レイテンシーの特定: リクエスト処理の遅延箇所を特定し、パフォーマンスの最適化を行うデバッグ支援: 本番環境での障害発生時に、該当リクエストのトレースを参照してルート原因を特定するアーキテクチャ可視化: サービスマップやサービス間の呼び出し関係を把握し、アーキテクチャの改善に活かすこのようにトレースは、マイクロサービスアーキテクチャにおける処理フローの可視化を実現する上で非常に重要な役割を担っています。SREやオンコール担当者がインシデント発生時の初動対応を行う際に活用されることも多くなってきています。収集する信号の選定とコスト管理本章の終盤では、オブザーバビリティを実現するために収集すべき信号の選定と、コストコントロールに関する考え方が説明されています。アクションにつながるインサイトを生むか、適切な保持期間が設定できるか、ROI(投資対効果)を考慮する必要があります。具体的な指針は以下の通りです。収集する信号がアクションにつながるインサイトを生み出すか? 単にノイズになるだけの信号は避けるべき信号の保持期間をどう設定するか? タスクや業界の規制に合わせて適切に決めるメトリクスの正常な値範囲(ベースライン)を設定し、異常検知に活用する信号の過剰収集は避け、ROIを意識する 保持するメリットが不明確な信号はコストの無駄収集する全ての信号で一貫したラベル付けを行う 相関性の確保に役立つこのように、オブザーバビリティを実現するためには信号の選別と、収集・保持に伴うコスト管理が重要になってきます。収集しすぎても意味がありませんし、重要な情報が欠落していても目的が果たせません。用途に合わせて 適切な種類の信号を適切な量だけ収集する という観点が欠かせません。オブザーバビリティを支える3本柱の理解と適切な運用が肝心ログ、メトリクス、トレースは、クラウドネイティブな分散システムのオブザーバビリティを実現する上で、それぞれ異なる役割を担う重要な3つの信号タイプです。ログはテキストベースの出力であり、人間が読み解いて状況を把握したりデバッグを行う際に役立ちます。メトリクスは数値の指標であり、自動化された監視・分析や、アラート発報、自動スケーリングなどに適しています。トレースはマイクロサービス間の処理フローを可視化する手段であり、分散システムを運用する上で欠かせません。各信号タイプにはそれぞれ長所と短所があり、3つの信号を組み合わせて収集・活用することで、システム全体の状況を多角的に把握できるようになります。しかし、それぞれに計装コストや保持コスト、リソース消費などのオーバーヘッドがあるため、収集する信号とその収集方法については、ユースケースごとのコストとROIを考慮する必要があります。本章ではサンプルアプリを使った具体例を交えながら、各信号タイプの特徴や計装の方法、Fluentbit、Promtail、Prometheusなどの収集エージェントの利用方法、GrafanaやLoki、Jaegerなどの可視化ツールの活用例が解説されています。これらの知見は監視システムの構築や運用を検討する上で参考になるはずです。ソフトウェアエンジニアやSREは、3つの信号タイプの特性を理解した上で、システムの要件に合わせて最適な組み合わせと収集方法を選択し、効率的なオブザーバビリティの実現を目指す必要があります。 信号の過剰収集に陥らず、ラベル付けの統一や信号間の相関性の確保など、コストを抑えながら有用な情報を得られる適切な運用が何より重要になります。オブザーバビリティの実現には、これら3つの主要な信号タイプを適切に組み合わせた上で、効果的な収集と活用を行うことが不可欠です。各信号タイプには一長一短があり、単独では十分なオブザーバビリティを得ることはできません。ログは人間が読み解くためのテキスト出力ですが、構造化の進展により自動分析の機会も増えてきました。しかしマイクロサービスアーキテクチャにおいては、処理フローの可視化という点でトレースに一部の役割が移行しつつあります。用途に応じてログとトレースを使い分ける必要があります。一方、メトリクスは数値指標のため自動化が容易であり、リアルタイムの監視だけでなく長期的な分析や容量計画にも活用できます。ただし、メトリクスの種類が増えるとカーディナリティ爆発のリスクがあり、適切なカーディナリティ管理が欠かせません。また、大量データの長期保持にはデータ圧縮や集約が必須になります。トレースはマイクロサービス間の処理フローを可視化するため、分散システムの運用では欠かせません。一方で、計装コストが高く、大量データの保持やコンテキスト伝搬によるパフォーマンスオーバーヘッドにも留意が必要です。ストレージの選択では、データ量やパフォーマンス要件、コストを考慮する必要があります。このように、オブザーバビリティを実現するには、3つの信号タイプそれぞれの長所と短所を理解した上で、システムの要件に合わせて最適な組み合わせと収集方法を選択することが肝心です。信号の過剰収集は避け、ラベル付けの統一やコスト管理、信号間の相関性の確保など、効率的な運用が何より重要になります。収集する信号については、以下の点を考慮する必要があるとしています。アクションにつながるインサイトを生み出すか?適切な保持期間が設定できるか?メトリクスの正常値範囲(ベースライン)は設定できるか?ROI(投資対効果)を意識した収集が可能か?信号間で一貫したラベル付けができるか?ソフトウェアエンジニアやSREは、このような点に留意しながら、効率的なオブザーバビリティの実現に努める必要があります。本章で示された具体例は、実際の監視システム構築の参考になるはずです。コストを抑えつつ、有用な情報を効果的に収集・活用できる環境を整備することが求められます。3 Sourcesクラウドネイティブシステムにおける多様な信号源の理解と活用本章「3 Sources」では、クラウドネイティブシステムにおけるオブザーバビリティの実現に欠かせない、様々な信号源(ソース)について詳しく解説されています。コンピューティング、ストレージ、ネットワーク、そして自身のコードに至るまで、各ソースからの信号取得の重要性と注意点が丁寧に説明されており、オブザーバビリティの実践に向けた実用的な知見が提供されています。Figure 3.1 A spectrum of compute, infrastructure, and application level より引用この図はコンピューティングリソースをインフラストラクチャレベル(VM、コンテナなど)とアプリケーションレベル(マイクロサービスやモノリシックアプリなど)に分けて示しています。インフラストラクチャレベルの監視は主に運用者が関与し、アプリケーションレベルの監視は開発者が関与する、といった役割分担が一般的です。しかしながら実際のプロダクション環境では、これら2つのレベルが複合的に組み合わさっていることが多いため、様々なソースからの信号を包括的に収集・相関させる必要があります。Figure 3.2 Signal sources in Kubernetes より引用この図はKubernetesにおけるコントロールプレーンとデータプレーンから出力される様々な信号源を示しています。コントロールプレーンのコンポーネントであれば、主にログとメトリクス、一部でトレースが出力されます。一方のデータプレーンではアプリケーションコンポーネントからログ、メトリクス、トレースが出力されることが一般的です。単一のプロダクト内に多種多様な信号源が存在するため、ホリスティックなオブザーバビリティ対応が求められます。以上の通り、クラウドネイティブな分散システムにはさまざまな種類の信号源が存在し、それぞれ特有の注意点があります。ソフトウェアエンジニアやSREは、これら多様な信号源の存在を理解した上で、用途に応じて適切な手段を選択し、効率的なオブザーバビリティの実現を目指す必要があります。単一の手法に固執するのではなく、必要に応じて収集方法を使い分けながら、ホリスティックな可視化を実現することが肝心です。そのためには本章で解説された信号源に関する深い理解が不可欠だと思います。コンピューティング関連のソースの詳細VMについては、オペレーティングシステムレベルの情報が参照できる点が大きな利点です。本書ではJVMを例に挙げ、JVMはログ、ヒープメモリ使用量、スレッド数など様々なメトリクスを出力することが説明されています。実際のJVM監視ツールとしてはSematextの提供するガイドが紹介されています。JVMは豊富な信号源となり、開発者はこれらのメトリクスを活用してパフォーマンスチューニングやデバッグを行えます。コンテナの場合、コンテナランタイム自体と、コンテナ内で実行されるアプリケーションの両方から情報が出力されます。コンテナランタイムの例としてDockerデーモンが挙げられ、docker logsコマンドでコンテナログを参照できます。また、Dockerコンテナ内のアプリケーションも標準的にログを標準出力に出力するよう12ファクターアプリの設計思想に従います。コンテナランタイムのメトリクス収集には、cAdvisorやTelegrafのDockerプラグインが活用できます。開発者はアプリケーションログを参照し、運用者はコンテナランタイムのメトリクスを監視することで、それぞれの観点からコンテナの状況を把握できます。Kubernetesでは多岐にわたるコンポーネントから様々なシグナルが出力されるため、包括的な理解が重要になります。コントロールプレーンのコンポーネント(APIサーバー、etcd、kubeletなど)からはログ、メトリクス、監査ログ、トレース(APIサーバーのみ)が出力されます。一方のデータプレーンではアプリケーションからのログ、メトリクス、トレースが主な情報源となります。Figure 3.2がKubernetesにおける様々な信号源を示しています。本文中でも触れられているように、Kubernetesではログの取り扱いが分散されており、収集の仕組みを整備する必要があります。アプリケーションログはkubectl logsで一時的に参照できますが、本番環境では永続化が必須です。Fluentbit、Fluentdなどのエージェントを使ってクラウドプロバイダーのログ基盤に転送するのが一般的なパターンです。Kubernetesでは、ログに加えメトリクスとトレースにも注目が集まっています。メトリクスはPrometheus形式で出力されており、kubectl get --raw /metricsで参照できます。一方、トレースはOpenTelemetryを使ってAPIサーバーの動作を追跡できるよう、コミュニティによってサポートが進められています。ストレージ関連のソースの詳細RDBMSでは、パフォーマンスモニタリングにおいてクエリプランナーの動作を理解することが肝心です。PostgreSQLの場合はEXPLAINでプランを確認できますし、各種モニタリングツールでも詳細情報にアクセスできます。例えばpgMonitorなら待機リソースのボトルネックやクエリの履歴なども確認できます。ベンダー製品でも同様の情報を得られます。例えばAWS Redshiftでは、CPU、メモリ、ストレージの使用量など基本的なメトリクスに加え、明示的にスロークエリIDを確認できます。RDBMSではパフォーマンスの観点からクエリプランナーの動作を細かく監視することが重要ですが、NoSQLデータストアではアプローチが異なります。NoSQLデータストアでは、アクセスパターンやストレージレイアウトが重要な監視対象となります。例えば、キャッシュとしても使われるRedisであれば、メモリ使用量のメトリクスが有用です。一方でMongoDB(ドキュメントストア)では、ディスクIOパフォーマンスのメトリクスに注目する必要があります。本書ではElasticsearch(検索エンジン)の事例も紹介されており、背景にあるLuceneのインデックシングプロセスを監視する重要性が説明されています。このようにNoSQLではアクセスパターンに合わせて監視対象を適切に選定することが求められます。RDBMSやNoSQLデータストアのメトリクスを収集する手段としては、PostgreSQL Server ExporterやpgMonitor、クラウドベンダー製品の活用が挙げられています。自社運用の場合はPrometheusと組み合わせるといった方法もあり、より詳細なカスタマイズが可能です。一方でクラウドベンダー製品を利用すれば、運用の手間を大幅に削減できます。RDBMSとNoSQLでは監視の着眼点が異なるため、目的に合わせて適切な手段を選ぶ必要があります。ネットワーク関連のソースの詳細ネットワークデバイスからは大量のログが出力されます。そのためノイズを除去し、価値のある情報だけを抽出することが課題となります。例えばロードバランサーであれば、リクエストの送信元IPやパスに基づいてフィルタリングすると効率的なモニタリングが行えます。AWS ALBの場合は、リクエスト量、アクティブコネクション数、HTTPステータスコードなどのメトリクスが出力されます。ALB自体の稼働状況だけでなく、バックエンドへのトラフィック情報なども確認できるため、アプリケーションの挙動を多角的に監視することが可能です。より高度な運用では、リクエストコンテンツやレスポンスページのレンダリング時間などもモニタリング対象になりうるでしょう。VPNやVPCから得られる情報では、セキュリティモニタリングが主な用途となります。例えばVPC FlowLogsからSSHやRDPアクセスをモニターすれば、不正アクセスの検知に活用できます。そのほか送受信トラフィックのパターン分析を行えば、DDoS攻撃の検知なども可能になります。VPCフローログは全てのIPトラフィックを記録するため、ネットワークの可視化に役立つと同時に、ログ量が膨大になる点にも注意が必要です。用途に応じて適切にフィルタリングする必要があります。ネットワーク関連ソースは大量のノイジーなデータが出力されるため、フィルタリングやラベル付けが重要になります。ALBの場合はデプロイ単位や環境単位でリクエストにラベルを付与することで、効率的なモニタリングが可能となります。また、Kubernetesなどのオーケストレーターを利用する場合は、Ingressリソースなどの抽象化されたネットワーク構成から出力されるシグナルをモニターする必要があります。自身のコード関連の詳細オープンソースのOpenTelemetryは、ログ、メトリクス、トレースの各種信号をベンダーロックインなしに管理できる魅力的なスタンダードです。ただし既存のコードに計装を行うコストがあり、コストとベネフィットのトレードオフを考慮する必要があります。将来の再計装のコストを避けたいのであれば、OpenTelemetryを中心におき、自動計装を最大限活用するのがよいでしょう。一方でCI/CDパイプライン自体も重要な信号源となります。ここからデプロイ進捗や所要時間、テスト結果などのメトリクスが得られます。新しいビルドが発生する度にこれらのメトリクスを監視することで、パフォーマンスの変化やボトルネックを事前に検知できます。将来的にはDigmaやSprkl.devといった専用ツールを使った開発者向けオブザーバビリティも重要になってくるでしょう。特にIDE上でコード変更の影響を可視化したり、プロファイリングデータからボトルネックを特定する機能が期待されています。信号の収集対象として最後に挙げられているのがプロキシソースです。ここでは監視対象外だが監視が必要なコンポーネントに対し、プロキシサーバーを介することで情報収集を実現する方法が説明されています。Prometheusの場合はKafkaやIoTデバイスなど非対応コンポーネントからExporterを使ってメトリクスを収集できます。またPushgatewayではバッチジョブなど一過性のプロセスからもメトリクス収集が可能になります。この他にも、ミドルウェアのDockerネットワークドライバを使えばDockerコンテナからログやメトリクスを抽出できます。あるいはSysdigの機能を活用すれば、アプリケーションレベルからカーネル全体の実行状況を詳細に可視化できるでしょう。特にeBPFを利用したSysdigの監視機能は注目すべき点で、プロセス単位でのリソース消費を正確にトレースすることが可能になります。オブザーバビリティの実現には様々なアプローチが存在します。システムを包括的にオブザーバブルにするには、これらの多様な手段を組み合わせていく必要があります。プロキシソースの活用は強力ですが、各ソースで得られる情報が多すぎるとノイズになりかねません。一方で全くオブザーバブルでない領域が残れば、ブラインドスポットが生まれてしまいます。信号収集の目的とコストを見極め、的を絞って収集・活用を行う工夫が求められます。収集対象の信号は最小限に留め、メタデータの付与や集約を行うといった対策も重要になってくるでしょう。4 Agents and instrumentationObservabilityにおけるAgentsとinstrumentationの役割本章「Agents and instrumentation」は、Observabilityを実現するための重要な要素であるエージェントと計装について詳しく解説しています。著者は、従来のベンダー固有のエージェントやシグナル固有のエージェントと対比させながら、オープンソースの包括的なObservabilityフレームワークであるOpenTelemetryを紹介しています。全然、別件でLearning Opentelemetryの読書感想文を書いていたので合わせて読んでみてください。syu-m-5151.hatenablog.comOpenTelemetryは、仕様、SDK、プロトコル(OTLP)、エージェントから構成される一連のコンポーネントであり、ベンダーに依存せずにログ、メトリクス、トレース、将来的にはプロファイルを収集・処理・取り込むことができます。OpenTelemetryを使えば、シグナルの発生元(リソース属性)とテレメトリシグナル自体の両方について、豊富なメタデータを得ることができます。このメタデータには、各シグナルが生成されたサービス、ホスト、コンテナ、クラウドリソースなどの情報が含まれ、システムの動作を理解し、問題の根本原因を特定する上で非常に重要な役割を果たします。特に、大規模な分散システムでは、各コンポーネントが生成するログ、メトリクス、トレースを関連付けて分析することが不可欠です。OpenTelemetryは、これを可能にする強力なフレームワークであると言えます。OpenTelemetryが提供する豊富なメタデータと、統一された方法でデータを収集・処理する仕組みにより、複雑なシステムの動作を俯瞰的に把握することができます。意味論的規約の重要性また、著者は意味論的規約(semantic conventions)の重要性を指摘しています。OpenTelemetryでは、意味論的規約に基づいてテレメトリデータにメタデータを付与することで、バックエンドでの効果的な相関分析を可能にしています。例えば、トレースデータとログデータに共通の属性を付与しておくことで、特定のリクエストに関連するすべてのログを容易に検索・分析できます。こうした相関分析は、複雑な分散システムの動作を理解し、パフォーマンスの問題や障害の原因を特定する上で欠かせません。opentelemetry.io従来、テレメトリデータの相関分析は、各ベンダーやツールに固有の方法で行われてきました。しかし、OpenTelemetryの意味論的規約により、ベンダーに依存しない形で相関分析を行うことができるようになります。これは、マルチクラウド環境やマイクロサービスアーキテクチャを採用している組織にとって特に大きなメリットとなるでしょう。統一された方法でテレメトリデータを収集・処理できれば、システム全体の可視性が向上し、問題の迅速な特定と解決が可能になります。自動計装と手動計装の使い分け計装に関しては、**アプリケーションのコードを変更せずに自動的にテレメトリを生成する自動計装の重要性が強調されています。 speakerdeck.com**自動計装は、アプリケーションフレームワークやライブラリと連携して、HTTPリクエスト、データベースクエリ、外部サービス呼び出しなどの主要な操作を自動的にトレースします。これにより、開発者はアプリケーションのコードを変更することなく、システムの動作を可視化できます。Figure 4.5 Concept of OpenTelemetry collection (from upstream docs; https://opentelemetry.io/docs/reference/specification/logs/overview/) より引用自動計装は、Observabilityの第一歩として非常に重要な役割を果たします。特に、レガシーなアプリケーションや、コード変更が困難な場合には、自動計装が唯一の選択肢となることもあるでしょう。また、自動計装により得られるデータは、システムのベースラインを把握する上でも役立ちます。ただし、自動計装には限界もあります。アプリケーション固有のビジネスロジックに関連する情報は、自動計装では捕捉できないことが多いのです。そのため、より詳細な分析を行うには、OpenTelemetry SDKを使った手動計装が必要になります。手動計装では、開発者がアプリケーションのコードに直接計装を追加します。これにより、重要なビジネスメトリクスや、アプリケーション固有のイベントを収集することができます。例えば、電子商取引サイトであれば、注文処理の各ステップにおける所要時間や、注文金額などのメトリクスを収集することが考えられます。自動計装と手動計装は、相互に補完する関係にあります。自動計装でシステムの全体像を把握した上で、手動計装でより詳細な情報を収集するのが理想的です。両者を適切に組み合わせることで、システムの可視性を最大限に高めることができるでしょう。OpenTelemetry collectorの役割と設定OpenTelemetry collectorは、エージェントとしての中核的な役割を担っており、あらゆるソースからのテレメトリデータを収集し、フィルタリング、サンプリング、属性の追加などの処理を行った上で、様々なバックエンドシステムに転送します。これにより、OpenTelemetry collectorは、Observabilityデータのハブとして機能し、データの流れを集中管理することができます。OpenTelemetry collectorの設定は、YAMLを使って行います。設定ファイルでは、受信したテレメトリデータをどのように処理し、どの宛先に転送するかを定義します。各シグナルタイプ(メトリクス、トレース、ログ)ごとにパイプラインを設定し、パイプラインの各段階でレシーバー、プロセッサー、エクスポーターを組み合わせて使用します。Figure 4.6 The OpenTelemetry collector and its components より引用この柔軟な設定により、OpenTelemetry collectorは様々な環境に適応できます。例えば、オンプレミスとクラウドが混在する環境では、オンプレミスの既存システムからのデータをOpenTelemetry collectorで収集し、クラウドのバックエンドに転送するといった使い方が可能です。また、複数のバックエンドを併用している場合も、OpenTelemetry collectorを中心とすることで、データの流れを一元管理できます。ただし、OpenTelemetry collectorの設定には注意が必要です。適切なレシーバー、プロセッサー、エクスポーターを選択し、それぞれの設定を最適化しなければなりません。特に、大規模な環境では、データ量が膨大になることがあるため、フィルタリングやサンプリングの設定が重要になります。また、セキュリティの観点から、データの暗号化や認証の設定も欠かせません。著者は、OpenTelemetry collectorの具体的な設定例も提示しています。この例では、サンプルアプリケーション「ho11y」からメトリクスとトレースを収集し、Prometheusをメトリクスのバックエンドに、Jaegerをトレースのバックエンドに使用しています。Figure 4.7 Example OpenTelemetry pipeline for traces and metrics より引用設定ファイルでは、Prometheusレシーバーを使ってPrometheusフォーマットのメトリクスを収集し、OTLPレシーバーを使ってOTLPフォーマットのトレースを収集しています。収集したデータはバッチ処理された後、Prometheusエクスポーターを通じてPrometheusに、Jaegerエクスポーターを通じてJaegerに送信されます。このような設定例を参考にしつつ、自身の環境に合わせてOpenTelemetry collectorの設定を最適化していくことが求められます。設定ファイルのバージョン管理を行い、変更履歴を追跡できるようにしておくことも重要でしょう。また、設定の変更が及ぼす影響を事前にテストし、問題がないことを確認してから本番環境に適用するなど、慎重な運用が必要です。OpenTelemetryの柔軟性と拡張性OpenTelemetryの技術的な側面に目を向けると、その柔軟性と拡張性が際立っています。OpenTelemetryは、ネイティブなOTLPをサポートするだけでなく、Prometheus、Jaeger、Zipkin、Fluentdなど、既存の様々なフォーマットやプロトコルに対応するレシーバーとエクスポーターを提供しています。これにより、既存のシステムからOpenTelemetryへの移行を段階的に進められるほか、複数のバックエンドシステムを並行して利用することもできます。この柔軟性は、OpenTelemetryの大きな強みの一つです。従来のモニタリングツールやObservabilityプラットフォームは、独自のデータフォーマットやプロトコルを使用していることが多く、他のシステムとの連携が困難でした。しかし、OpenTelemetryなら、そうした既存のシステムともスムーズにデータをやり取りできます。これにより、ベンダーロックインを回避しつつ、既存の資産を活かしながら、Observabilityの向上を図ることができるのです。また、OpenTelemetryは、コミュニティ主導で活発に開発が進められているオープンソースプロジェクトです。ユーザーは、OpenTelemetryの機能拡張に自ら貢献することもできます。例えば、新しいレシーバーやエクスポーターを開発し、OpenTelemetryのエコシステムに追加することが可能です。こうしたコミュニティの力によって、OpenTelemetryは今後もさらに発展していくことが期待されます。パフォーマンスとリソース効率パフォーマンスの観点では、OpenTelemetry collectorのスループットとリソース使用量に注意を払う必要があります。大規模な環境では、多数のエージェントが生成する膨大なテレメトリデータを効率的に処理しなければなりません。そのため、collectorのパフォーマンスチューニングが重要になります。例えば、バッチ処理の設定を最適化することで、データ処理のスループットを向上させることができます。一方で、バッチサイズを大きくしすぎると、メモリ使用量が増大するため、適切なバランスを見出す必要があります。また、サンプリングを適用してデータ量を削減することも、パフォーマンス改善に効果的です。ただし、サンプリングによって情報が欠落するリスクがあるため、慎重な設定が求められます。リソース使用量の観点では、メモリ使用量の制御が特に重要です。OpenTelemetry collectorは、受信したデータをメモリ上に保持するため、データ量が増大するとメモリ使用量も増加します。これを放置すると、メモリ不足によってcollectorのパフォーマンスが低下したり、最悪の場合にはOOM (Out of Memory) キルによってプロセスが強制終了したりする可能性があります。こうしたリスクを回避するため、OpenTelemetry collectorにはメモリリミッタープロセッサが用意されています。メモリリミッタープロセッサを使用すると、メモリ使用量が一定のしきい値を超えた場合に、データの受信を一時的に制限したり、古いデータを削除したりすることができます。ただし、データの欠落が許容できないケースでは、十分なメモリリソースを確保する必要があります。また、OpenTelemetry collectorのパフォーマンスは、ホスト環境の影響も受けます。特に、コンテナ環境では、リソース制限の設定によってパフォーマンスが大きく左右されます。適切なCPUとメモリのリソース制限を設定し、必要に応じて縮退運転できるようにしておくことが重要です。パフォーマンスとリソース効率の最適化には、継続的なモニタリングが欠かせません。OpenTelemetry collectorの主要なメトリクス(CPU使用率、メモリ使用量、データ処理のレイテンシなど)を常に監視し、ボトルネックを特定して改善策を講じる必要があります。また、負荷テストを実施して、実際のピーク時の負荷に耐えられるかを確認しておくことも重要です。Observabilityの新しい標準としてのOpenTelemetry本章では、Observabilityの実現に向けて、エージェントと計装が果たす重要な役割が詳細に説明されました。特に、OpenTelemetryは、ベンダーロックインを回避しつつ、多様なテレメトリデータを統一的に扱うことができる画期的なフレームワークです。OpenTelemetryが提供する豊富なメタデータと意味論的規約は、システムの動作を深く理解し、問題の迅速な特定と解決に役立ちます。従来のモニタリングツールやObservabilityプラットフォームは、ベンダー固有のデータフォーマットやAPIを使用していたため、相互運用性に乏しく、複数のツールを併用するのが難しいという問題がありました。しかし、OpenTelemetryは、このような問題を解決し、Observabilityの新しい標準となる可能性を秘めています。OpenTelemetryが広く普及することで、異なるベンダーのツールやサービス間でシームレスにテレメトリデータをやり取りできるようになります。これにより、エンドツーエンドの可視化、ベンダーロックインの回避、既存システムとの統合が容易になるでしょう。また、OpenTelemetryのオープンなエコシステムは、イノベーションを促進し、Observabilityのベストプラクティスの共有を加速させるはずです。自動化と最適化の必要性自動計装と手動計装を適切に組み合わせることで、アプリケーションコードへの変更を最小限に抑えつつ、システムの可視性を高めることができます。自動計装は、Observabilityの基盤を素早く構築するのに役立ちます。一方、手動計装は、ビジネスに特化した重要なメトリクスを収集するのに欠かせません。ただし、計装を実施するだけでは不十分です。収集したテレメトリデータを効果的に活用するには、データのクリーンアップ、集計、相関分析など、一連のデータ処理が必要となります。OpenTelemetry collectorは、こうしたデータ処理を自動化し、最適化する上で重要な役割を果たします。特に、大規模で複雑なシステムでは、膨大なテレメトリデータが生成されるため、データの適切なフィルタリングとサンプリングが不可欠です。OpenTelemetry collectorの柔軟な設定により、環境に合わせたデータ処理を実現できます。また、セキュリティ、パフォーマンス、リソース効率など、運用上の要件を満たすように設定を最適化することも重要です。Observabilityの継続的な改善Observabilityは、一朝一夕で実現できるものではありません。システムの変化に合わせて、Observabilityの仕組みも継続的に改善していく必要があります。OpenTelemetryは、この継続的な改善を支援する強力なプラットフォームです。OpenTelemetryを活用することで、システムの変更に素早く適応できます。新しいサービスやコンポーネントを追加する際に、計装を自動的に適用できます。また、OpenTelemetryの柔軟なアーキテクチャにより、バックエンドのツールやサービスを段階的に入れ替えることも可能です。ただし、OpenTelemetryを効果的に活用するには、組織全体でのコラボレーションが欠かせません。開発者、運用チーム、セキュリティチーム、ビジネス関係者など、様々なステークホルダーが連携し、Observabilityの目標と戦略を共有する必要があります。また、Observabilityのベストプラクティスを継続的に学習し、実践していくことも重要です。5 Backend destinationsバックエンドの選択がObservabilityの成功を左右する本章「Backend destinations」では、Observabilityデータの保存と分析を担うバックエンドの重要性について詳しく解説されています。著者は、適切なバックエンドの選択が、Observabilityの取り組みの成功を大きく左右すると強調しています。opentelemetry.ioバックエンドは、収集されたログ、メトリクス、トレースなどのテレメトリデータを保存し、それらのデータに対するクエリやアラートの実行、ダッシュボードの作成などを可能にする中核的なコンポーネントです。バックエンドの機能性、パフォーマンス、スケーラビリティ、信頼性は、Observabilityシステム全体の有効性に直結します。したがって、自社のニーズや要件に合ったバックエンドを選択することが極めて重要です。著者は、バックエンドの選定において考慮すべき主要な基準として、コスト、オープンスタンダードのサポート、バックプレッシャーへの対応、カーディナリティとクエリのパフォーマンスなどを挙げています。コストの観点では、データの取り込み、保存、クエリに関連する直接的なコストに加えて、エンジニアリングチームのサポート、トレーニング、セキュリティパッチ適用などの間接的なコストも考慮する必要があります。オープンスタンダードのサポートは、ベンダーロックインを回避し、相互運用性を確保するために重要です。OpenTelemetryやOpenMetricsなどの業界標準への対応は、バックエンドの選定において重要な基準となります。バックプレッシャーへの対応は、大量のテレメトリデータを生成するソースからのデータ取り込みを安定的に行うために不可欠です。バックエンドとソース間にキューイングメカニズムを導入することで、バックプレッシャーに起因するデータ欠損や性能低下を防ぐことができます。カーディナリティとクエリのパフォーマンスは、特にメトリクスデータを扱う際の重要な考慮事項です。次元の値が大きく変動するメトリクスは、時系列データベース(TSDB)におけるカーディナリティの爆発を引き起こす可能性があります。カラムナーストレージを採用したClickHouseやDruidなどのデータストアは、高カーディナリティのメトリクスにも対応できます。シグナルタイプごとのバックエンドオプション本章では、ログ、メトリクス、トレースのそれぞれのシグナルタイプに適したバックエンドオプションについて、クラウドプロバイダー、オープンソース、商用の観点から詳しく解説されています。ログのバックエンドでは、Amazon CloudWatch Logs、Azure Monitor Logs、Google Cloud Loggingなどのクラウドプロバイダーのサービスや、Elasticsearch、OpenSearch、Grafana Lokiなどのオープンソースソリューション、Splunk、Instana、Logz.ioなどの商用製品が紹介されています。これらのログバックエンドは、インデックス付きの全文検索、構造化クエリ、アラート、ダッシュボードなどの機能を提供します。ログデータのボリュームが大きい場合や、長期的な保存が必要な場合は、コストとパフォーマンスのバランスを考慮してバックエンドを選択する必要があります。クラウドプロバイダーのサービスは、マネージドな環境で手間のかからない運用が可能ですが、コストが高くなる傾向があります。一方、オープンソースソリューションは、自前での運用が必要ですが、コストを抑えることができます。Figure 5.2 Time series database concept, showing N time series of the mysvc_http_request_total metric より引用メトリクスのバックエンドとしては、時系列データベース(TSDB)が主流です。PrometheusやInfluxDBなどのオープンソースのTSDBに加え、各クラウドプロバイダーのマネージドPrometheusサービスや、M3DB、VictoriaMetricsなどのスケーラブルなソリューションが注目されています。TSDBは、メトリクスデータの効率的な格納と、時間範囲やラベルに基づくクエリを可能にします。PrometheusはKubernetesエコシステムにおける事実上の標準となっており、多くのツールやサービスとの統合が進んでいます。一方、M3DBやVictoriaMetricsは、Prometheusとの互換性を保ちつつ、よりスケーラブルなアーキテクチャを提供します。トレースのバックエンドは、JaegerやZipkinなどのオープンソースプロジェクトが広く採用されている一方で、クラウドプロバイダーやObservabilityベンダーの商用ソリューションも充実しています。ElasticsearchやOpenSearchもトレースのバックエンドとして使用できます。トレースデータは、分散システムにおけるリクエストの流れを可視化し、パフォーマンスのボトルネックや異常を特定するために使用されます。Jaegerは、OpenTelemetryとの緊密な統合により、幅広いプログラミング言語やフレームワークをサポートしています。商用ソリューションは、AIを活用した自動的な異常検知やパフォーマンス最適化の提案など、高度な分析機能を提供します。cloud.google.comカーディナリティの課題とカラムナーデータストア本章では、メトリクスのバックエンドを選択する際の重要な考慮事項として、カーディナリティの問題が取り上げられています。カーディナリティとは、メトリクスの各次元が取り得る値の数を指します。ユーザーIDやセッションIDのように、値が大きく変動する次元を持つメトリクスを扱う場合、TSDBではカーディナリティの爆発が発生し、データの取り込み、保存、クエリのパフォーマンスに深刻な影響を与える可能性があります。この課題に対処するために、著者はカラムナーストレージを採用したデータストアの活用を提案しています。カラムナーストレージは、データを列単位で格納することで、高いデータ圧縮率と優れたクエリパフォーマンスを実現します。Apache Cassandra、Apache Druid、ClickHouse、Snowflakeなどが代表的なカラムナーデータストアとして紹介されています。Figure 5.5 Row-oriented vs. column-oriented storage より引用特に、ClickHouseを使ったログのバックエンドの例では、OpenTelemetry CollectorとClickHouseを組み合わせることで、ログデータをカラムナーフォーマットで効率的に保存し、SQLを使って柔軟にクエリできることが示されています。github.comカラムナーストレージは、高カーディナリティのメトリクスだけでなく、ログやトレースデータの保存と分析にも適しています。ログデータは、多様な構造を持つイベントの集合体であり、カラムナー形式での保存により、クエリのパフォーマンスを大幅に向上させることができます。トレースデータも、スパンのフィールドを列として保存することで、効率的なクエリが可能になります。カラムナーデータストアは、Observabilityデータの長期的な保存と分析において重要な役割を果たします。データレイクとしてのカラムナーストレージに、ログ、メトリクス、トレースを統合することで、包括的な分析と相関関係の発見が可能になります。また、カラムナー形式のデータは、機械学習やデータマイニングのワークロードにも適しており、異常検知やパターン認識などの高度な分析にも活用できます。ポリグロットバックエンドアーキテクチャObservabilityデータの種類や特性に応じて、複数のバックエンドを組み合わせて使用するポリグロットなアプローチも有効です。例えば、ログデータにはElasticsearch、メトリクスデータにはPrometheus、トレースデータにはJaegerを使用するといった構成が考えられます。ポリグロットバックエンドアーキテクチャは、各シグナルタイプに最適化されたバックエンドを選択することで、パフォーマンスとコスト効率を最大化できます。一方で、異なるバックエンド間でのデータの相関分析や一貫性の確保が課題となります。この課題に対処するために、OpenTelemetryなどの共通の収集および転送層を導入することが推奨されます。OpenTelemetryは、ログ、メトリクス、トレースを統一的に扱うことができ、バックエンドの違いを吸収します。また、Grafanaなどの可視化ツールは、複数のバックエンドからデータを取得し、統合されたダッシュボードを提供することができます。ポリグロットバックエンドアーキテクチャの採用には、運用の複雑さと管理コストの増加というトレードオフがあります。バックエンドごとにデータの保存期間やアクセス制御を適切に設定し、モニタリングとアラート設定を行う必要があります。また、バックエンド間のデータ同期や整合性の問題にも注意が必要です。制約と誓約本章で提示された知見を踏まえると、Observabilityにおけるバックエンドの選定は、システムアーキテクチャとデータ管理の両面から慎重に検討すべき重要な意思決定であると言えます。適切なバックエンドの選択は、Observabilityの取り組みの成功を大きく左右します。組織は、自社のユースケースに合ったバックエンドを選択する必要があります。コスト、パフォーマンス、スケーラビリティ、相互運用性など、さまざまな要素を総合的に評価し、長期的な視点に立ってバックエンドの選定を行うべきです。また、バックエンドの特性や制約を深く理解し、データモデルに適したアーキテクチャを採用することが重要です。メトリクスのカーディナリティ問題に代表されるように、バックエンドの選択はデータの特性に大きく依存します。高カーディナリティのメトリクスを扱う場合は、カラムナーストレージの採用を検討すべきです。また、ログやトレースデータの長期的な保存と分析においても、カラムナーデータストアが有力な選択肢となります。ポリグロットバックエンドアーキテクチャは、各シグナルタイプに最適化されたバックエンドを組み合わせることで、パフォーマンスとコスト効率を最大化できる可能性を秘めています。ただし、運用の複雑さと管理コストの増加には十分な注意が必要です。OpenTelemetryなどの共通の収集および転送層を導入し、可視化ツールを活用することで、バックエンド間のデータ統合と相関分析を実現できます。6 Frontend destinationsフロントエンドとオールインワンソリューションの役割本章「Frontend destinations」では、Observabilityデータの可視化と分析を担うフロントエンドとオールインワンソリューションについて詳しく解説されています。フロントエンドは、バックエンドに保存されたObservabilityデータと対話し、ユーザーが様々なグラフィカルおよびテキスト形式でアドホックな質問に答えを見つけるために使用します。一方、オールインワンソリューションは、バックエンドとフロントエンドを一体化したものであり、ベンダーが設計したバックエンドとの組み合わせでのみ使用できます。著者は、フロントエンドとオールインワンソリューションの選択が、Observabilityの取り組みの成功に大きな影響を与えることを強調しています。適切なツールを選択することで、開発者やビジネスステークホルダーに価値を提供し、機能の出荷やバグ修正の加速、本番環境での問題解決時間の短縮、開発者の生産性向上などを実現できます。オープンソースとコマーシャルオファリングの比較本章では、Grafana、Kibana、OpenSearch Dashboardsなどの人気のあるオープンソースフロントエンドや、Jaeger、Zipkin、Apache SkyWalkingなどのオールインワンソリューションについて詳細に説明されています。これらのオープンソースツールは、幅広いバックエンドとの統合、豊富な視覚化オプション、アラート機能などを提供しており、自社のObservabilityソリューションを構築する際の強力な基盤となります。Figure 6.1 An example Grafana data source, showing configuration options より引用GrafanaはPrometheusと、KibanaはElasticsearchと、それぞれ緊密に連携しており、メトリクスとログの可視化において重要な役割を果たしています。一方、JaegerやZipkinは、OpenTelemetryとの統合により、幅広いプログラミング言語やフレームワークをサポートする分散トレーシングソリューションとして広く採用されています。Figure 6.6 Jaeger UI showing all traces for a certain tag (http.status_code=404) より引用また、SigNozやUptraceなど、ClickHouseをバックエンドに使用するオープンソースのオールインワンソリューションも登場しています。これらのツールは、OpenTelemetryを活用してテレメトリデータを収集し、SQLを使ってデータを柔軟にクエリできる点が特徴です。一方、商用ソリューションは、高度な分析機能、AIを活用した異常検知、パフォーマンス最適化の提案など、より豊富な機能を提供します。DatadogやNew Relicなどの有名ベンダーは、自動計装に基づくアウトオブザボックスの機能や、幅広いインテグレーションを備えています。また、Lightstepのようなunified storage layerを持つソリューションは、異なるシグナルタイプを統合的に扱うことができます。ツール選定の考慮事項フロントエンドとオールインワンソリューションの選定においては、以下の点を考慮する必要があります。コスト: フロントエンドのコストは予測可能ですが、オールインワンソリューションではバックエンドのコストも考慮する必要があります。オープンソースを選択する場合は、サポート、パッチ適用、スケーリングなどの運用コストを見積もることが重要です。ベンダーロックインの回避: オープンスタンダード（OpenTelemetryなど）をサポートするオールインワンソリューションは、ベンダーロックインを最小限に抑えつつ、運用負荷を軽減できる優れた選択肢です。オープンソースプロジェクトの健全性: オープンソースツールを選ぶ際は、プロジェクトの背景、ライセンス、コントリビューターの多様性、ドキュメントの品質、Issue対応の速度などを評価することが不可欠です。相関分析のサポート: 複数のシグナルタイプをサポートするツールにおいては、時間ベースの相関分析や、あるシグナルタイプから別のシグナルタイプへのスムーズな移動を可能にする機能が重要です。シングルパネルオブグラスとデータ相関の重要性著者は、Observabilityにおける「シングルパネルオブグラス」の概念について言及しています。これは、ログ、メトリクス、トレースなどの異なるシグナルタイプを単一のインターフェースで統合的に扱うことを指します。シングルパネルオブグラスを実現することで、システムの動作を包括的に把握し、問題の迅速な特定と解決が可能になります。ただし、著者は、シングルパネルオブグラスを絶対的な要件とするのではなく、柔軟なアプローチを取ることを推奨しています。つまり、主要なフロントエンドツールを中心に据えつつ、必要に応じて専門的なツールを組み合わせるのが現実的だと述べています。シングルパネルオブグラスに関連して、データの相関分析が重要な役割を果たします。異なるシグナルタイプ間の関連性を明らかにすることで、複雑なシステムの動作を理解し、パフォーマンスの問題や障害の根本原因を特定できます。著者は、Grafana version 10で導入された相関APIを例に挙げ、変数と変換を使用した相関分析の実現方法を紹介しています。フロントエンドとオールインワンの選択プロセスフロントエンドとオールインワンソリューションの選択において、最初に検討すべきは、「構築か、購入か」の意思決定です。社内でObservabilityプラットフォームを構築することが競争上の優位性につながるのでない限り、できる限りアウトソーシングすることが推奨されます。一方、ベンダーやクラウドプロバイダーへの依存を最小限に抑えたい企業では、オープンソースとオープンスタンダードに基づいたソリューションを構築するのが賢明です。選定プロセスでは、以下の点を評価します。総コストの見積もり（ライセンス料、インフラコスト、運用コストなど）ベンダーロックインのリスクオープンソースプロジェクトの成熟度と持続可能性相関分析を含む主要機能のサポート状況加えて、全てのステークホルダーを巻き込み、要件を明確にすることが肝要です。技術的な側面だけでなく、ビジネス要件や ユーザビリティなども考慮して、最適なソリューションを選択しましょう。Observabilityツールの継続的な評価と改善Observabilityの分野は急速に発展しており、新しいツールやソリューションが次々と登場しています。選択したフロントエンドやオールインワンソリューションが、将来にわたって組織のニーズを満たし続けられるとは限りません。したがって、定期的にツールを評価し、必要に応じて見直しや改善を行うことが重要です。評価の際は、以下の点を考慮します。新しい機能やインテグレーションの追加パフォーマンスとスケーラビリティの向上コミュニティの活発さとサポートの継続性ライセンスやコストモデルの変更また、Observabilityツールの運用においては、以下のような継続的な改善活動が求められます。ダッシュボードやアラートの最適化データ保持期間とコストのバランス調整新しいシグナルソースやデータ型の取り込みユーザートレーニングとドキュメントの整備Observabilityは、単なるツールの導入で完結するものではありません。組織全体でObservabilityの文化を醸成し、継続的な改善を通じて、システムの可視性と運用効率を高めていく必要があります。Observabilityの価値実現に向けて本章では、Observabilityにおけるフロントエンドとオールインワンソリューションの重要性、それらのツールの選定と運用における考慮事項について詳しく解説されました。Observabilityの真の目的は、システムの動作を深く理解し、問題の迅速な特定と解決を可能にすることで、ビジネス価値の実現を支えることにあります。適切なツールを選択し、継続的な改善を積み重ねることで、Observabilityの取り組みを成功に導くことができます。オープンソースとオープンスタンダードを活用しつつ、組織のコンテキストに合ったソリューションを構築することが肝要です。また、ログ、メトリクス、トレースなど、異なるシグナルタイプを相関分析できる機能を備えることで、システムの全体像を俯瞰し、問題の根本原因を特定しやすくなります。フロントエンドとオールインワンソリューションは、Observabilityデータの可視化と分析を通じて、ソフトウェアエンジニアリングとシステム運用に大きな価値をもたらします。本章で得られた知見を活かし、自組織に適したツール戦略を練り上げていきましょう。Observabilityの文化を育み、データドリブンな意思決定を促進することで、ビジネスの俊敏性と回復力を高めることができるはずです。7 Cloud operationsインシデント管理のベストプラクティス本章「Cloud operations」では、クラウドネイティブアプリケーションを円滑に運用するための重要な要素であるインシデント管理、ヘルスモニタリング、アラート、ガバナンス、使用状況の追跡について詳しく解説されています。特に、インシデント管理に関しては、インシデントの検出、処理、そしてインシデントから学ぶことの重要性が強調されています。クラウドネイティブシステムは多数のコンポーネントで構成されており、これらのコンポーネントは相互に依存しています。そのため、ひとつのコンポーネントで問題が発生すると、その影響が全体に波及する可能性があります。こうした複雑なシステムにおいて、エンドユーザーに影響を与える問題が発生した場合、どのコンポーネントが根本原因なのかを特定することは容易ではありません。したがって、システムの外部から継続的にヘルスモニタリングとパフォーマンスモニタリングを行い、期待通りに機能していないことを素早く検知することが不可欠です。モニタリングシステムは、各コンポーネントの主要なメトリクスを収集し、異常値や閾値超過を検出できるように設定する必要があります。これにより、インシデントの兆候をいち早く捉え、影響が拡大する前に対処できます。著者が強調しているのは、インシデントが発生した際には、原因分析よりも問題の解決を優先すべきだということです。つまり、エンドユーザーへの影響を最小限に抑えることが最優先事項であり、そのためには問題の切り分けと適切な対処を迅速に行う必要があります。具体的には、関連するログやメトリクスを確認してシステムの状態を把握し、影響範囲を特定した上で、適切な措置を講じる必要があります。また、ステークホルダーに対しても、状況と対応方針を適宜共有することが重要です。インシデントが収束した後は、再発防止に向けた原因分析が必要です。著者は、非難を伴わないポストモーテム（事後分析）を行うべきだと述べています。ポストモーテムでは、「5 Whys」などの手法を用いて根本原因を掘り下げ、具体的な再発防止策を特定することが重要です。さらに、インシデントの経緯と学びを文書化し、組織内で共有することで、将来のインシデント対応に活かすことができます。インシデント管理のベストプラクティスを確立するためには、以下のような点に留意する必要があります。インシデントの検知と通知の自動化: モニタリングシステムと連動したアラート設定により、インシデントの兆候を早期に検知し、適切な担当者に自動的に通知する。インシデントの優先度付けとエスカレーション: インシデントの影響度に応じて優先度を設定し、適切なタイミングでエスカレーションを行う。コミュニケーションの明確化: インシデント対応の際の連絡体制とコミュニケーションチャネルを予め定義しておく。ランブックとプレイブックの整備: よくあるインシデントへの対処手順をランブック（運用手順書）やプレイブック（対応シナリオ）としてまとめ、迅速かつ的確な対応を可能にする。ポストモーテムの徹底: インシデントの原因究明と再発防止策の特定を徹底的に行い、組織としての学びを促進する。これらのプラクティスを確実に実行できるよう、定期的にインシデント対応の訓練を行うことも重要です。様々なシナリオを想定した机上訓練や、実際にシステムの一部に障害を発生させるカオスエンジニアリングなどを通じて、チームのインシデント対応力を高めていくことができます。アラート設計のポイントと継続的な最適化アラートは、システムの異常を検知し、適切な担当者に通知するための重要な仕組みです。しかし、アラートの設定が不適切だと、大量の無駄なアラートが発生して対応が追いつかなくなったり、逆に重大な問題を見逃してしまったりする恐れがあります。したがって、アラートの設計には細心の注意を払う必要があります。著者は、アラートの設計において、以下のような点が重要だと指摘しています。重要度の設定: インシデントの影響度に応じて、アラートの重要度（critical, warning, infoなど）を適切に設定する。閾値の調整: アラートの閾値を適切に設定し、誤検知や見逃しを最小限に抑える。アラートのグループ化と抑制: 関連するアラートをグループ化し、不要なアラートを抑制することで、アラートのノイズを減らす。エスカレーションパスの明確化: アラートの重要度に応じて、エスカレーション先と連絡方法を明確に定義する。これらの設定を適切に行うことで、重要なアラートを見逃すことなく、迅速に対応できるようになります。本章では、Prometheusを使ったアラートの設定方法が具体的に解説されています。PrometheusではAlertmanagerと呼ばれるコンポーネントが、アラートのグループ化や通知の設定を担当します。Prometheusの設定ファイルでアラートルールを定義し、Alertmanagerの設定ファイルでアラートの通知先やグループ化のルールを指定します。著者が提示した例では、PrometheusのAPIコール数が一定のしきい値を超えた場合にアラートが発報され、Alertmanagerを経由してWebhookに通知が送信されます。アラートルールの定義では、PromQLと呼ばれるクエリ言語を使ってアラート条件を記述します。また、ラベルやアノテーションを使ってアラートの詳細情報を指定できます。Figure 7.2 Prometheus and the Alertmanager より引用Alertmanagerの設定では、アラートのグループ化や通知先の指定、通知メッセージのカスタマイズなどが可能です。たとえば、同じアプリケーションに関連するアラートをまとめたり、アラートの重要度に応じて通知先を変えたりといったことができます。また、抑制ルールを設定することで、特定の条件に一致するアラートを一時的に抑制することもできます。アラートの設計は一度で完璧にはできません。システムの変更に合わせて、継続的にアラートの設定を見直し、最適化していく必要があります。以下のような点に注意しながら、アラートの改善を進めていくことが重要です。アラートの効果の定期的な評価: アラートが期待通りに機能しているか、定期的に評価する。不要なアラートが多い場合は、閾値の調整やアラートルールの見直しを検討する。システム変更へのタイムリーな対応: システムの変更に合わせて、アラートの設定を速やかに更新する。特に、新しい機能のリリース時には、適切なアラートを設定するように心がける。アラートの受信者の最適化: アラートの受信者が適切か定期的にレビューする。担当者の変更やオンコール体制の見直しに合わせて、アラートの通知先を更新する。エスカレーションパスの確認: 重要なアラートが確実にエスカレーションされるよう、エスカレーションパスを定期的にテストする。アラートは、インシデント管理において重要な役割を果たします。適切なアラートの設定は、インシデントの早期検知と迅速な対応を可能にします。しかし、アラートの設計は継続的な改善が必要なプロセスです。システムの変更に合わせてアラートを最適化し、運用チームの負荷を最小限に抑えながら、インシデントを確実に検知できるようにしていくことが求められます。今後の課題本章では、クラウドネイティブアプリケーションの運用において重要となるインシデント管理、ヘルスモニタリング、アラート、ガバナンス、使用状況の追跡について詳しく解説されました。インシデント管理については、インシデントの検知から対応、そしてポストモーテムまでのプロセスを適切に定義し、実行することが重要だと述べられています。特に、インシデント発生時には問題の解決を最優先し、その後に原因分析を行うべきだと強調されています。また、ポストモーテムを通じて、インシデントから学びを得て、再発防止につなげることが重要だと指摘されています。アラートについては、適切な設計と継続的な最適化が必要だと述べられています。アラートの重要度や閾値の設定、アラートのグループ化や抑制、エスカレーションパスの明確化などが、アラートの効果的な運用に欠かせないポイントとして挙げられています。また、Prometheusを使ったアラートの設定方法が、具体的な例を交えて解説されています。ユーザー行動の追跡に関しては、Real User Monitoringを使ったエンドユーザーの行動分析や、CloudTrailなどを使った内部ユーザーのアクション追跡の重要性が指摘されています。これらのデータを活用することで、パフォーマンスの改善やセキュリティ強化、コンプライアンス対応などに役立てることができます。さらに、コスト最適化の重要性についても言及されています。クラウドの利用が拡大する中で、リソースの使用状況を可視化し、無駄な支出を削減することが求められます。AWS Cost and Usage ReportsやKubernetes向けのOpenCostなどのツールを活用することで、コストの最適化を進められると述べられています。クラウドネイティブ時代の運用は、従来のオンプレミス環境とは大きく異なります。インフラストラクチャのプロビジョニングや設定管理の自動化、オブザーバビリティの確保、コストの最適化など、多岐にわたる課題に取り組む必要があります。本章で得られた知見は、これらの課題に立ち向かう上で、重要な指針となるでしょう。ただし、本章で取り上げられたトピックは、クラウドネイティブの運用における一部に過ぎません。たとえば、カオスエンジニアリングによるシステムの回復力向上や、AIOpsの活用による運用の自動化など、本章では触れられていない重要なテーマもあります。また、クラウドネイティブの運用プラクティスは、急速に進化し続けています。新しいツールやサービス、アプローチが次々と登場する中で、運用チームは常に学習と適応が求められます。クラウドネイティブの運用は、単なるシステムの維持ではなく、ビジネスの成功に直結する戦略的な活動です。本章で紹介された手法やツールを活用しつつ、組織の文化や目標に合わせてアプローチをカスタマイズしていくことが重要です。運用の自動化や効率化を進める一方で、チーム内のコラボレーションや、開発チームとのコミュニケーションを強化することも忘れてはなりません。8 Distributed tracing分散トレーシングでクラウドネイティブシステムを徹底的に可視化本書「Observability In Action」の第8章「Distributed tracing」では、分散トレーシングという手法を用いて、クラウドネイティブシステムの複雑な動作を可視化する方法について詳しく解説されています。著者は、モノリシックなアプリケーションではログとメトリクスだけで十分だったのに対し、マイクロサービスアーキテクチャではサービス間の関係性を追跡するために分散トレーシングが欠かせないと指摘しています。分散トレーシングは、個々のリクエストがシステム内の各サービスをどのように通過するかを追跡し、処理のフローと時間情報を記録することで、システム全体の動作を俯瞰的に把握できるようにする技術です。 各サービスはリクエストの処理過程でスパン(span)と呼ばれる情報を生成し、これらのスパンが集まってエンドツーエンドのトレース(trace)を形成します。分散トレーシングツールは、これらのトレースデータを収集、分析、可視化することで、開発者やSREがシステムの動作を理解し、パフォーマンスの問題や障害の原因を特定できるようサポートします。Figure 8.3 A single request path in the app, as a temporal (waterfall) visualization より引用本章では、分散トレーシングの基本概念とユースケースが丁寧に説明されています。トレースやスパンといった基本的な用語の定義から始まり、サンプリングやコンテキスト伝搬など、実践的な話題にも踏み込んでいます。 特に、分散トレーシングが単なるツールの導入ではなく、開発チーム全体で取り組むべき文化的な実践であるという指摘が印象的でした。また、著者自身が開発したサンプルアプリケーションを使って、Jaegerというオープンソースのトレーシングツールでマイクロサービスのトレースを可視化する手順が詳しく解説されています。実際のトレースデータを見ながら、サービスマップやウォーターフォールダイアグラムを使ってシステムの動作を分析する方法を学べるのは、大変有益だと感じました。Figure 8.7 Troubleshooting the demo microservices app: an example failure trace and the span that caused the failure より引用本章の後半では、分散トレーシングを導入・運用する上での実用的なアドバイスが提供されています。 トレースのサンプリング方法の選択、分散トレーシングにかかるコスト（オブザーバビリティ税）の見積もり方、ログやメトリクスとの使い分けなど、実際のプロジェクトで直面しそうな課題に対するヒントが豊富に盛り込まれていました。エンドツーエンドの可視化でシステムをホリスティックに理解分散トレーシングは、複雑化するクラウドネイティブシステムをエンドツーエンドで可視化し、ホリスティック（包括的）に理解するための強力な手法だと言えます。マイクロサービス間の呼び出しフローを追跡することで、システム全体のアーキテクチャを俯瞰でき、パフォーマンスのボトルネックや障害の波及経路を特定しやすくなります。また、各スパンが処理時間や結果のステータスなどの詳細情報を持つため、トレースデータを分析することで、パフォーマンスの最適化や障害対応を効率化できます。一方で、分散トレーシングの導入には一定のコストがかかることも事実です。各サービスにおける計装、トレースデータの収集・保存のためのインフラ、分析・可視化ツールの運用など、様々な側面でコストが発生します。 本章でも指摘されているように、これらのコストに見合うだけの価値が得られるかを見極めることが重要です。分散トレーシングを成功に導く秘訣分散トレーシングをプロジェクトに導入し、その恩恵を最大限に引き出すためには、単にツールを導入するだけでなく、組織文化やプロセスの変革も必要だと感じました。本章から得られた教訓をまとめると、以下のようになります。分散トレーシングをオブザーバビリティ戦略の一環として位置づけるログ、メトリクスと並ぶ重要な柱として、体系的に取り組む開発チーム全体でトレーシングの価値を共有するトレーシングがもたらすメリットを開発者に伝え、活用を促す計装を自動化し、手間を最小限に抑えるOpenTelemetryなどの自動計装を活用するトレースデータを集約し、関連情報と紐付けて分析するトレースIDを軸に、ログやメトリクスと関連づけて分析する可視化ツールを使ってトレースを直感的に理解するJaegerやZipkinなどのツールで、サービスマップやウォーターフォールダイアグラムを活用するコストとベネフィットのバランスを見極める過剰な情報収集は避け、本当に必要なスパンに絞り込む分散トレーシングの未来本章では、分散トレーシングという手法の現状について詳しく解説されていましたが、この分野は現在も活発に発展し続けています。 特に、OpenTelemetryプロジェクトが、ベンダー中立な分散トレーシングのためのオープンスタンダードとして注目を集めています。各言語のSDKやAPIの整備、自動計装の充実など、OpenTelemetryの登場により、分散トレーシングの導入が以前よりも容易になることが期待されます。また、AIOpsやオブザーバビリティプラットフォームとの連携も、分散トレーシングの今後の発展において重要なトピックだと考えられます。トレースデータを機械学習モデルで分析することで、異常検知やパフォーマンス最適化の自動化が進むかもしれません。さらに、ログやメトリクスなど他のオブザーバビリティデータとトレースを統合的に扱うプラットフォームが登場すれば、よりホリスティックなシステム理解が可能になるでしょう。組織の分散トレーシングは俺と仲間で育ててる分散トレーシングは、現代のクラウドネイティブシステムにおいて欠かせないオブザーバビリティ技術の一つです。マイクロサービス間の複雑な相互作用を可視化し、パフォーマンスや信頼性の向上に役立てることができます。本章で得られた知見は、実際のシステム開発・運用の様々な場面で活用できるはずです。一方で、分散トレーシングはシルバーバレットではありません。ツールの導入だけでなく、チーム全体でトレーシングの価値を共有し、データを効果的に活用するための文化やプロセスの変革が求められます。また、トレーシングにかかるコストを適切にコントロールし、投資対効果を見極めることも重要です。分散トレーシングに取り組む際は、本章で紹介された基本概念やベストプラクティスを押さえつつ、自分たちのシステムやチームに合ったやり方を模索していくことが大切だと感じました。オープンスタンダードの採用や、他のオブザーバビリティ実践との連携など、新しい潮流にも注目しながら、システムのエンドツーエンドの可視化を追求していきたいと思います。9 Developer observabilityDeveloper observabilityで開発者の生産性を加速する本書「Observability In Action」の第9章「Developer observability」では、Developer observabilityの概念とその実現方法について詳しく解説されています。著者は、Developer observabilityを「開発者に行動可能なインサイトを提供することで、開発速度の向上、コードのデバッグ、新機能の性能・リソース使用量の理解を可能にするテレメトリシグナルの活用」と定義しています。Efficient Goも書籍として良かったのでオススメです。日本語の「効率的なGo ―データ指向によるGoアプリケーションの性能最適化」もあるので合わせて読んでみてください。learning.oreilly.com従来、開発者は主にコードの作成に注力し、テスト、パッケージング、デプロイ、運用は他の部門が担当するのが一般的でした。しかし、Developer observabilityの登場により、開発者自身がこれらの工程に関与し、迅速なフィードバックループを確立できるようになりました。 これにより、問題の早期発見と修正が可能となり、全体的なコストを削減できます。本章では、Developer observabilityを実現する具体的な手法としてContinuous profiling（継続的プロファイリング）に焦点が当てられています。Continuous profilingを使うことで、開発者はサービスの現在のパフォーマンスとリソース使用量を把握し、コード変更前後の比較が可能になります。これにより、新機能追加によるトレードオフを定量的に評価できるようになります。著者は、Continuous profilingの基盤技術として、pprofフォーマット、Flame graph、eBPFなどを紹介しています。pprofは、Googleが開発したプロファイリングデータの可視化・分析ツールであり、プロファイルをProtocol Buffers形式で表現します。 Flame graphは、プロファイルの呼び出しスタックを視覚的に表現する手法で、eBPFはLinuxカーネルを拡張してプロファイル収集を行う仕組みです。これらの技術を理解することが、Continuous profilingを活用する上で重要だと指摘されています。Figure 9.2 An flame graph using our pprof Go example より引用本章ではまた、Parca、Pixie、Pyroscopeなど、オープンソースのContinuous profilingツールが紹介されています。これらのツールは、pprofフォーマットをサポートし、eBPFを活用してプロファイルを収集します。クラウドプロバイダーや商用ベンダーも、独自のContinuous profiling機能を提供し始めています。 AWS CodeGuru Profiler、Azure Application Insights Profiler、Google Cloud Profilerなどが代表的な例です。Figure 9.3 The eBPF call flow in the Linux kernel at a conceptual level (Source: Brendan Gregg. Licensed under CC BY 4.0) より引用さらに著者は、Continuous profilingをOpenTelemetry collectorの性能分析に活用する具体的な手順を示しています。pprofエクステンションを有効化したOpenTelemetry collectorからプロファイルを収集し、Parcaを使って可視化・分析する一連の流れが丁寧に説明されており、実践的な知見が得られます。Continuous profilingに加えて、本章ではDeveloper productivityツールについても言及されています。これらのツールは、OpenTelemetryを基盤とし、コード変更が性能やリソース使用量に与える影響を開発者に可視化します。Digma、Sprkl、Tracetest、Rookout、Autometricsなどが代表的な例として紹介されています。Digmaは、OpenTelemetryのトレースとメトリクスを分析し、コードレベルのインサイトを提供するIDEプラグインです。 開発者は、コードを編集しながら、パフォーマンス、エラー、使用状況に関するフィードバックを得ることができます。Sprklは、OpenTelemetryを使ってコードをインスツルメントし、コード変更の実行時の振る舞いを探索できるようにします。 コードレベルのトレース、システム内の他のエンティティとの関係、パフォーマンスレポートなどが提供されます。Tracetestは、OpenTelemetryのトレースを利用して、マイクロサービス間の統合テストを構築するためのツールです。 サービス間の呼び出しフローを定義し、期待されるレスポンスとトレースデータに対してアサーションを記述できます。ただし著者は、Developer observabilityツールの採用には注意が必要だと指摘しています。シンボル情報の取り扱い、プロファイルの保存とクエリ、他のテレメトリデータとの相関分析、オープンスタンダードへの準拠など、克服すべき課題が残されています。特に本番環境での利用には、パフォーマンスへの影響を慎重に見極める必要があります。Continuous profilingの技術的側面に迫る本章では、Continuous profilingの基盤となる技術について詳しく解説されていました。特に、pprofフォーマット、Flame graph、eBPFは、Continuous profilingを支える重要な要素として紹介されています。pprofは、Googleが開発したプロファイリングデータの可視化・分析ツールであり、プロファイルをProtocol Buffers形式で表現します。pprofのデータフォーマットは、Continuous profilingツールの多くが採用しており、事実上の標準となりつつあります。著者は、pprofの内部構造を詳解し、protocを使ってpprofファイルをデコードする方法も示しています。これにより、開発者はpprofの仕組みを深く理解し、より効果的にContinuous profilingを活用できるようになります。pprofのデータ構造は、Profileメッセージを中心に構成されています。 Profileメッセージには、サンプルの種類(ValueType)、収集されたサンプル(Sample)、マッピング情報(Mapping)、ロケーション情報(Location)、関数情報(Function)などが含まれます。これらのサブメッセージを組み合わせることで、プロファイリングデータが表現されるのです。Flame graphは、プロファイルの呼び出しスタックを視覚的に表現する手法です。著者は、Flame graphの読み方を丁寧に解説し、slowTask()やquickTask()といった関数の実行時間を色と幅で表現する例を示しています。Flame graphを使いこなすことで、開発者はボトルネックの特定や性能の最適化を直感的に行えるようになります。Flame graphでは、x軸方向に呼び出しスタックが並べられ、y軸方向にスタックの深さが示されます。 各関数の実行時間は、対応する長方形の幅で表現されます。これにより、どの関数がCPU時間を多く消費しているかが一目で分かります。また、呼び出し元と呼び出し先の関係も、スタックの階層構造から読み取ることができます。eBPFは、Linuxカーネルを拡張し、プロファイルの収集を可能にする仕組みです。著者は、eBPFの基本概念とContinuous profilingにおける役割を説明しています。eBPFを活用することで、アプリケーションコードに変更を加えることなく、カーネルレベルでのプロファイリングが実現できます。 ただし、eBPFを本番環境で利用するには、カーネルバージョンや設定に注意が必要だと指摘されています。eBPFプログラムは、カーネル内の特定のイベント（関数の呼び出し、リターン、パケットの受信など）にアタッチされ、イベント発生時に実行されます。これにより、カーネルの動作を詳細に観測し、必要な情報を収集することが可能になります。収集されたデータは、カーネル内のeBPFマップを介してユーザー空間に渡され、分析ツールで処理されます。これらの技術的な説明は、Continuous profilingの仕組みを深く理解する上で欠かせません。pprofやeBPFを適切に活用することで、開発者はアプリケーションの性能を正確に把握し、改善に役立てることができるでしょう。一方で、これらの技術にはそれぞれ固有の制約や課題があることも忘れてはなりません。著者が示唆するように、Continuous profilingを効果的に実践するには、技術的な理解と、トレードオフを見極める判断力の両方が求められます。プロファイルの保存と分析の課題に挑むContinuous profilingを実践する上で、プロファイルデータの保存と分析は大きな課題となります。著者は、列指向のストレージとXOR圧縮という2つのアプローチを紹介しています。列指向のストレージは、プロファイルデータを効率的に保存し、クエリを高速化するために用いられます。著者は、ParcaチームがGo言語で開発したFrostDBを例に挙げ、列指向データベースがプロファイルの保存に適していることを説明しています。FrostDBは、Apache Parquetをストレージフォーマットに、Apache Arrowをクエリエンジンに採用しており、半構造化スキーマをサポートしています。列指向ストレージでは、データが列単位で格納されます。つまり、同じ列に属するデータが連続的に配置されるのです。これにより、特定の列に対するクエリが高速化されます。また、列単位の圧縮が可能となり、ストレージ容量を大幅に削減できます。プロファイルデータは、呼び出しスタックや関数名、タイムスタンプなど、複数の列から構成されるため、列指向ストレージとの親和性が高いと言えます。一方、XOR圧縮は、プロファイルのタイムスタンプを効率的に圧縮するための手法です。著者は、Facebookのエンジニアチームが考案した「Gorilla」アルゴリズムを紹介し、タイムスタンプのデルタ値を符号化することで、ストレージ容量を大幅に削減できると説明しています。XOR圧縮では、連続するタイムスタンプの差分（デルタ）を計算し、そのデルタ値をXOR演算で符号化します。 これにより、タイムスタンプの繰り返しパターンが効果的に圧縮されます。プロファイルデータは、連続的に収集されるため、タイムスタンプの圧縮に適しているのです。XOR圧縮を適用することで、プロファイルの長期的な保存が現実的になります。これらの技術は、大規模なプロファイルデータを扱う上で重要な役割を果たします。列指向ストレージを活用することで、開発者は膨大なプロファイルを効率的に保存し、高速にクエリを実行できるようになります。XOR圧縮は、ストレージコストの削減に貢献し、長期的なプロファイルの保持を可能にします。ただし、著者も指摘するように、プロファイルデータの保存と分析には、まだ多くの課題が残されています。特に、プロファイルに対する表現力豊かなクエリ言語の確立は、喫緊の課題だと言えます。Parcaのラベルベースのクエリ言語やPyroscopeのFlameQLなど、各ツールが独自のアプローチを取っていますが、業界全体で共通の標準が求められています。加えて、プロファイルデータと他のテレメトリデータとの相関分析も、重要な研究テーマです。分散トレースやメトリクスとプロファイルを組み合わせることで、より総合的なパフォーマンス分析が可能になるはずです。しかし、現状では、これらのデータを統合的に扱うための仕組みが十分に確立されているとは言えません。Continuous profilingの本格的な実践には、これらの課題を着実に解決していく必要があります。列指向ストレージやXOR圧縮といった要素技術を活用しつつ、クエリ言語の標準化や、テレメトリデータ間の相関分析手法の確立に取り組むことが求められます。著者が強調するように、オープンスタンダードの採用と、コミュニティ全体での知見の共有が、Continuous profilingの発展に欠かせないのです。あわせて6本にしてみる...本章では、Continuous profilingを支える基盤技術と、その実践に向けた課題について深く掘り下げていました。pprofやFlame graph、eBPFといった要素技術は、Continuous profilingの中核を成すものであり、開発者がその仕組みを理解することは極めて重要です。また、列指向ストレージやXOR圧縮といった手法は、大規模なプロファイルデータを扱う上で欠かせない存在だと言えるでしょう。一方で、クエリ言語の標準化や、テレメトリデータ間の相関分析など、Continuous profilingの実践には克服すべき課題が山積みです。これらの課題に正面から向き合い、地道な改善を積み重ねていくことが、私たち開発者に求められています。オープンスタンダードの採用と、知見の共有。それが、Continuous profiling、ひいてはDeveloper observabilityを発展させるための鍵だと、私は確信しています。 一人一人の開発者が自らの経験を持ち寄り、ベストプラクティスを編み出していく。そのような協調的な取り組みこそが、Developer observabilityの真の力を引き出すのだと思います。Jaeger の作者で OpenTelemetry の共同創始者でもある Yuri Shkuro の TEMPLE: six pillars of telemetry ではObservability をTraces,Events,Metrics,Profiles,Logs,Exceptions で6 本柱としてクラウドネイティブなシステムの観測性に役立つと主張している。このような考えもあることを知っておくと良いかもです。medium.com10 Observability In ActionSLOでサービスの信頼性を定量化し、顧客満足度を高める本書「Observability In Action」の第10章「Service level objectives」では、サービス品質の定量化とその自動化に不可欠なサービスレベル目標（SLO）について詳しく解説されています。著者は、信頼性に関する規制が今後セキュリティと同様に重要になると指摘し、SLOを用いてサービスの信頼性を測定・報告することが、金融、通信、航空などの業界で注目を集めていると述べています。SLOは、サービス提供者と消費者の間で交わされるサービスレベルアグリーメント（SLA）を定量化し、自動化するための重要な手段です。SLAで約束した内容を数値化したものがSLOであり、そのSLOの達成度を実際に測定するための指標がサービスレベルインジケータ（SLI）です。つまり、SLIで測定し、SLOで目標を定め、SLAで契約を交わす、という関係になります。Figure 10.1 Interaction and dependencies between SLAs, SLOs, and SLIs より引用本章では、SLOの対象となるサービスの種類として、同期型、非同期型、特殊型の3つが挙げられています。同期型サービスはリクエスト-レスポンス型のWebサービスや、RPCベースのシステムが該当します。非同期型サービスは、メッセージキューやPub/Subシステムなどが含まれます。特殊型サービスには、バッチジョブ、ストレージ、データベースなどが含まれます。それぞれのサービス特性に応じて、適切なSLIを設定する必要があります。SLIの具体例としては、サービスの可用性、エラー率、レイテンシ、スループットなどが挙げられています。これらの指標をもとに、サービスの品質を定量的に評価し、改善のための目標（SLO）を設定します。例えば、「99.9%の可用性を維持する」「エラー率を0.1%以下に抑える」といったSLOを定めることで、サービス品質の向上を図ることができます。SLOを設定する際は、可用性と速度のバランスを考慮する必要があります。可用性を上げるためには変更を控えめにする必要がありますが、それでは新機能の追加が滞ってしまいます。逆に、変更を頻繁に行えば、可用性が下がるリスクがあります。サービスの特性に応じて、適切なSLOを設定することが重要だと著者は指摘しています。本章ではまた、PrometheusをベースとしたオープンソースのSLOツールであるPyrraとSlothについて詳しく解説されています。これらのツールを使うことで、PrometheusのメトリクスをSLIとして扱い、SLOの達成状況を容易に可視化できます。PyrraはPrometheusのレコーディングルールを生成することでSLOを実装します。ServiceLevelObjectiveリソースを定義すると、それに対応するPrometheusのルールが自動生成されます。一方、SlothはPrometheusのルールグループを生成し、SLIやエラーバジェットの計算を行います。どちらのツールもSLOの実装を大幅に簡略化してくれます。著者はまた、SLOの商用ソリューションについても言及しています。Nobl9、Datadog、Honeycomb、Dynatraceなど、多くのベンダーがSLOの機能を提供し始めていると指摘しています。特にNobl9は、SLOに特化した包括的なソリューションを提供していると紹介されています。最後に著者は、SLOを定義する際にはOpenSLOなどのオープンスタンダードを活用すべきだと強調しています。ベンダーロックインを避け、相互運用性を確保するためにも、オープンな仕様に準拠することが重要だと述べています。SLOの実装と運用における留意点本章では、SLOの実装と運用に関する具体的な留意点についても言及されていました。まず、SLOの設定には、サービスの利用者と提供者の間での合意形成が不可欠です。著者は、営業担当者、プロダクトオーナー、エンジニアリングチームが連携し、サービスの特性に応じた適切なSLOを定義すべきだと述べています。その際、エラーの許容範囲や、SLOの対象期間などを明確にすることが重要です。SLOの達成度を測定するためのSLIの設定も、慎重に行う必要があります。SLIは、サービスの品質を数値化するための指標であり、サービスの種類によって適切なものを選ぶ必要があります。著者は、REDメソッド（Rate、Errors、Duration）など、SLIの選定に関する参考資料を紹介しています。SLOの運用においては、エラーバジェットの管理が鍵を握ります。エラーバジェットとは、SLOを達成するために許容されるエラーの範囲のことです。エラーバジェットを適切に設定し、モニタリングすることで、SLOの違反を未然に防ぐことができます。エラーバジェットの消費速度（バーンレート）を追跡することも、SLOの管理に役立ちます。本章で紹介されたPyrraやSlothなどのSLOツールを活用することで、SLOの実装と運用を大幅に効率化できます。これらのツールは、PrometheusのメトリクスをSLIとして扱い、SLOのモニタリングとアラートの設定を容易にしてくれます。ただし、ツールの選定には注意が必要です。機能、性能、価格などを総合的に評価し、自社のニーズに合ったものを選ぶことが重要です。SLOの導入には、組織文化の変革も欠かせません。サービスの品質を定量的に評価し、継続的に改善していくためには、開発者、運用者、ビジネス関係者が一丸となって取り組む必要があります。SLOを中心とした品質管理のプラクティスを組織全体に浸透させ、データドリブンな意思決定を促進することが求められます。サービスの継続的な改善の為のSLO本章では、サービス品質の定量化と自動化に不可欠なSLOについて、詳細に解説されていました。SLOは、SLAで約束したサービス品質を数値化し、SLIで測定するための重要な手段です。サービスの種類に応じて適切なSLIを選定し、SLOを設定することで、サービスの継続的な改善が可能になります。SLOの実装には、PyrraやSlothなどのオープンソースツールが役立ちます。これらのツールを活用することで、PrometheusのメトリクスをSLIとして扱い、SLOのモニタリングを容易に行えます。一方、Nobl9やDatadogなどの商用ソリューションも、SLOの管理に強力な機能を提供しています。github.comsyu-m-5151.hatenablog.comSLOの運用では、エラーバジェットの管理が鍵を握ります。サービスの品質を維持しつつ、変更を加速するためには、適切なエラーバジェットの設定と消費速度の追跡が欠かせません。また、SLOの導入には組織文化の変革も必要です。サービス品質の定量的な評価と継続的な改善を、組織全体の習慣とすることが重要です。SLOは、単なる技術的な指標ではありません。それは、サービス提供者と消費者の間の信頼関係を築くための重要な手段でもあります。SLOを導入することで、サービスの品質に対する説明責任を果たし、ユーザーの満足度を高めることができるのです。本章を通して、SLOの重要性と実践的な手法について理解を深めることができました。測定できないものは改善できないと言われます。サービスの品質を定量化し、データに基づいて改善を進めていくこと。それがSLOの本質であり、私たちに求められる姿勢だと感じました。皆さんの組織では、SLOをどのように活用されていますか？PyrraやSlothなどのツールの利用経験や、SLOの運用で得られた知見などがあれば、ぜひ共有いただきたいと思います。SLOを通じて、サービスの品質と信頼性を高めていくために、私たちにできることは何でしょうか。サービスの信頼性を定量化し、顧客の期待に応えていく。そのためのアプローチとして、SLOは大きな可能性を秘めています。本章で得られた知見を活かし、SLOの実践を通じて、より信頼性の高いサービスを提供していきたいと思います。11 Signal correlationシグナル相関で複雑なシステムの動作を俯瞰的に理解する本書「Observability In Action」の最終章「Signal correlation」では、複数のオブザーバビリティシグナルを関連付けることで、クラウドネイティブシステムの動作をより深く理解する方法が解説されています。著者は、ログ、メトリクス、トレース、プロファイルといった個々のシグナルだけでは、システムの全体像を把握するのに十分ではないと指摘しています。シグナル相関は、異なるシグナルタイプを結び付けることで、より迅速かつ正確に有用な洞察を得るためのメタデータ主導のプロセスだと定義されています。マイクロサービスアーキテクチャを採用する現代のシステムは、多数のサービスが連携して一つのリクエストを処理します。そのため、障害やパフォーマンスの問題が発生した際に、どのサービスが原因となっているのかを特定するのが難しくなります。シグナル相関は、インシデント対応、根本原因分析、サービスの性能改善など、様々な場面で威力を発揮します。メトリクスからトレースへ、トレースからログへ、といったように、複数のシグナルを行き来しながら、問題の全容を明らかにできるのです。本章では、シグナル相関の基本概念として、相関スタックが紹介されています。これは、計装層、バックエンド層、フロントエンド層から構成され、相関を実現するための階層的な仕組みを表しています。Figure 11.1 The correlation stack より引用計装層では、アプリケーションコードとテレメトリエージェントが、テレメトリデータを生成し、メタデータで enrichment を行います。バックエンド層では、収集されたテレメトリデータがメタデータとともに保存され、相関のためのクエリに応える役割を担います。そして、フロントエンド層で、ユーザーがシグナル間を自在に行き来しながら、システムの動作を探索できるようになります。特に、OpenTelemetryの果たす役割の大きさが強調されています。OpenTelemetryは、セマンティック規約を通じて、リソース属性やシグナル属性といったメタデータを標準化します。これにより、ベンダーに依存しない形で、シグナル間の相関を自動化できるようになります。OpenTelemetryのリソース属性を使えば、Kubernetesのノードや、その上で動作するアプリケーションを一意に識別できます。また、シグナル属性によって、HTTPリクエストやRPCコールなど、個々のシグナルにも豊富なメタデータを付与できるのです。また、著者は相関パスという概念を導入し、あるシグナルタイプから別のシグナルタイプへの遷移を表現しています。Table 11.1 Overview of signal correlations より引用トレースからメトリクスへ、メトリクスからログへ、ログからトレースへ、といったように、様々な組み合わせが考えられます。それぞれの遷移では、関連する情報が引き継がれ、より広い文脈でシステムの動作を理解できるようになります。例えば、トレースからメトリクスへの相関では、トレースが表す分散トランザクションから、レイテンシーや、エラー率などの代表的なメトリクスを導き出せます。逆に、メトリクスからトレースへの相関では、異常な振る舞いを示すメトリクスから、その原因となっているトレースに迫ることができるでしょう。ログとトレースの相関も、非常に有用です。あるサービスのログから、そのサービスが関与するトレースを特定したり、トレースに含まれる各サービスのログを収集したりできます。これにより、分散トランザクションの流れと、各時点で記録されたイベントを突き合わせながら、問題の原因を追跡できるようになります。本章では、このようなシグナル相関の概念を、様々な角度から掘り下げています。相関を実現するためのメタデータの標準化、相関パスの種類と活用方法、OpenTelemetryを中心とするオープンな技術スタックなど、相関に関する重要なポイントが網羅的に解説されていました。OpenTelemetry、Jaeger、Grafanaを使ったメトリクスとトレースの相関本章では、メトリクスとトレースの相関を実現する具体的な方法として、OpenTelemetry、Jaeger、Grafanaを使った例が紹介されています。サンプルアプリケーションは、OpenTelemetryを使って計装され、トレースを生成します。同時に、Prometheus形式のメトリクスにトレースIDを埋め込むことで、エグゼンプラ（exemplars）を実現しています。OpenTelemetryコレクタは、トレースをJaegerに、メトリクスをPrometheusに転送します。コード例を見ると、OpenTelemetryのGoライブラリを使って、メトリクスの各ポイントにトレースIDをラベルとして埋め込んでいます。これがエグゼンプラの肝となる部分です。メトリクスを公開する際には、Prometheusの HTTP ハンドラを使い、レスポンスフォーマットとして OpenMetrics を指定しています。OpenTelemetryコレクタの設定では、Prometheusエクスポータと Jaeger エクスポータを使って、それぞれのバックエンドにデータを送信しています。Prometheusエクスポータでは、enable_open_metrics オプションを有効にすることで、エグゼンプラのサポートが有効になります。実際にエグゼンプラがどのように埋め込まれているかは、curl コマンドで /metrics エンドポイントにアクセスすることで確認できます。traceID というラベルに、トレースIDが格納されているのが分かります。Grafanaのダッシュボードでは、メトリクスのグラフ上に小さな点として表示されるエグゼンプラをクリックすることで、該当するトレースにジャンプできます。これにより、メトリクスの異常を発見した際に、すぐにトレースを確認し、問題の原因を特定できるようになります。Figure 11.2 Screenshot of the Grafana dashboard with exemplars (the small dots at the bottom) for the echo service より引用Figure 11.3 Screenshot of the Jaeger view for the echo service, focusing on the error span representing a 500 responseこのように、オープンソースツールを組み合わせることで、シグナル相関を比較的簡単に実現できることが示されています。各ツールが担う役割を理解し、適切に設定することが重要だと感じました。特に、OpenTelemetryがデータ収集の中心となり、Jaegerがトレースの保存と可視化を、Prometheusがメトリクスの保存と集計を、そしてGrafanaが相関の UI を提供するという、それぞれの得意分野を活かした構成が印象的でした。もちろん、本格的な運用のためには、データ量の増大への対応や、セキュリティの確保など、さらなる検討が必要でしょう。しかし、本章の例は、シグナル相関を実践するための第一歩として、大いに参考になると感じました。シグナル相関の実装における課題と対策本章では、シグナル相関の実装における課題についても言及されています。まず、標準化の欠如が挙げられています。APMやモニタリングツールごとに、シグナルのフォーマットや用語が異なるため、システム間で相関を行うのが難しくなります。これに対しては、OpenTelemetryのような標準化されたフレームワークを採用することが有効だと指摘されています。OpenTelemetryは、ベンダー中立なオープンスタンダードであり、多くのプログラミング言語やフレームワークをサポートしています。これにより、様々なシステムから一貫性のあるテレメトリデータを収集できるようになります。次に、メタデータの不足が課題として挙げられています。相関を実現するには、リソースや環境に関する豊富なメタデータが必要ですが、既存のシステムではそれが十分に提供されていないことが多いのです。特に、レガシーなアプリケーションや、サードパーティのAPIを利用している場合、メタデータの取得が困難を極めることがあります。ここでも、OpenTelemetryのセマンティック規約に従うことで、メタデータの自動付与が可能になります。ただし、完全な自動化は難しく、場合によってはカスタムの計装が必要になるでしょう。シグナルのボリューム、カーディナリティ、サンプリングも、相関の実装を難しくする要因です。大量のデータを処理するために、適切なインデックス設計や集計、フィルタリングが欠かせません。特に、ログデータは非構造化データであるため、関連する情報を抽出するのが一苦労です。また、メトリクスの次元が増えすぎると、カーディナリティ爆発を引き起こし、クエリのパフォーマンスが大幅に低下してしまいます。トレースのサンプリングは、データ量を抑えるための有効な手段ですが、重要なスパンが欠落してしまうリスクもあります。これらの課題に対しては、適切なアーキテクチャの選択と、きめ細かなチューニングが求められます。例えば、ログデータの処理には、Elasticsearchなどの全文検索エンジンや、FluentdやLogstashなどのログ収集基盤が役立ちます。メトリクスのカーディナリティ対策としては、PrometheusのRelabelingやRecordingRuleを活用できるでしょう。トレースのサンプリングでは、重要な操作をあらかじめ識別し、適切なサンプリングレートを設定することが重要です。データのプライバシーとセキュリティの確保も、重要な課題の一つです。法規制やコンプライアンス要件に従って、個人情報を適切にマスキングしたり、データの取り扱いを制限したりする必要があります。特に、SaaSサービスを利用する場合、データの保存場所や、アクセス制御について、慎重に検討しなければなりません。暗号化やアクセスログの監査など、セキュリティ対策も欠かせません。最後に、ユーザーエクスペリエンスの向上が求められます。せっかく相関機能を実装しても、使い勝手が悪ければ活用されません。インサイトを得やすいUIの設計や、エンドツーエンドでの一貫したサポートが重要だと指摘されています。例えば、メトリクスの異常検知から、関連するトレースやログへの seamless なナビゲーションができれば、問題の調査が大幅に効率化できるでしょう。Exploratoryなデータ分析をサポートするためには、データのクエリ性や、ビジュアライゼーションの柔軟性も欠かせません。これらの課題は、一朝一夕には解決できないかもしれません。しかし、シグナル相関の重要性を認識し、地道な改善を積み重ねていくことが大切です。特に、OpenTelemetryを中心とするオープンソースの活用と、コミュニティでの知見共有が、課題の克服に大きく役立つはずです。将来に向けたシグナル相関の可能性本章のエッセンスは、シグナル相関がオブザーバビリティの真価を引き出すための鍵だということだと思います。複雑化するシステムの動作を理解し、問題の迅速な特定と解決を実現するには、複数のシグナルを組み合わせて分析する必要があります。OpenTelemetryを活用することで、ベンダーロックインを回避しつつ、メタデータ主導の自動化された相関が可能になるでしょう。一方で、相関の実装には多くの課題が立ちはだかります。データのボリューム、カーディナリティ、プライバシーなど、技術的にも運用的にも乗り越えるべきハードルは少なくありません。しかし、著者が強調するように、これらの課題に真正面から向き合い、地道な改善を重ねていくことが重要です。シグナル相関は、オブザーバビリティの究極の目標とも言えます。全てのシグナルを横断的に分析し、システム全体の動作を俯瞰的に把握する。そこから得られる洞察は、開発者の生産性向上だけでなく、ビジネス上の意思決定にも大きな価値をもたらすはずです。セキュリティの分野でも、シグナル相関の重要性が増しています。複数のログソースを相関させることで、不正アクセスや情報漏洩の兆候をいち早く検知できます。また、トレースデータとの相関により、脆弱性の原因となるコードを特定することも可能になるでしょう。セキュリティインシデントの防止と、影響範囲の特定に、シグナル相関が大きく貢献する可能性があります。さらに、AIOpsの文脈でも、シグナル相関への期待が高まっています。機械学習やビッグデータ分析と組み合わせることで、システムの異常をリアルタイムに検知し、自動的に対処するような仕組みが実現できるかもしれません。複雑さを増すシステムの運用を、人間の手に頼らずに自動化していくために、シグナル相関が重要な基盤となるはずです。クラウドネイティブ時代のシステムは、ますます分散化・動的化が進んでいくでしょう。コンテナやサーバーレス、マイクロサービスなど、新しいアーキテクチャが次々と登場する中で、オブザーバビリティの重要性はこれまで以上に高まっています。その中で、シグナル相関は、システムの可視性と制御可能性を飛躍的に向上させる、強力な武器になり得ます。本章を通して、シグナル相関の重要性と実践的な手法について理解を深めることができました。OpenTelemetryを中心とするオープンな標準の採用と、コミュニティ全体での知見の共有が、相関技術の発展には欠かせません。課題を一つ一つ克服しながら、より高度な相関の実現を目指していきたいと思います。皆さんの組織では、シグナル相関にどのように取り組まれていますか？OpenTelemetryの活用状況や、相関分析から得られた知見など、ぜひ共有いただければと思います。シグナル相関は、オブザーバビリティ分野における次のブレークスルーになるかもしれません。 複数のシグナルを行き来しながら、システムの本質的な理解に迫っていく。そのためのデータ基盤とスキルを獲得することが、私たちに求められているのではないでしょうか。冒頭でも述べたように、単一のシグナルだけでは、もはやシステムの全容を把握することはできません。ログ、メトリクス、トレース、そしてプロファイル。これらの多様なシグナルを縦横無尽に相関させる力こそが、複雑さに立ち向かうための何よりの武器となるはずです。本書のラストを飾るに相応しい、示唆に富んだ一章でした。ここで得られた学びを胸に、オブザーバビリティのさらなる高みを目指して精進したいと思います。シグナル相関の可能性を追求し、より俊敏で、よりレジリエントなシステムを作り上げていく。それが、私たちソフトウェアエンジニアとSREに託されたミッションなのだと、改めて感じた次第です。さいごに本書「Cloud Observability in Action」を通じて、クラウドネイティブ時代におけるオブザーバビリティの重要性と、その実現に向けた具体的な方法論を学ぶことができ視座を得られました。著者が一貫して訴えかけているのは、オブザーバビリティがツールの導入だけで達成できるものではない、ということです。ログ、メトリクス、トレース、プロファイルなど、様々なシグナルを適切に収集・分析するための技術的な基盤は不可欠ですが、それ以上に重要なのは、オブザーバビリティの文化を組織全体に根付かせ、データドリブンな意思決定を日常的に実践していくことだと説いています。また、オープンスタンダードとオープンソースソフトウェアの活用が強く推奨されています。ベンダーロックインを避け、持続可能なイノベーションを実現するために、OpenTelemetryに代表されるようなオープンな標準や、コミュニティ主導のオープンソースプロジェクトが果たす役割の大きさを再認識させられました。本書の内容を実践するのは容易ではありませんが、その努力は決して無駄にはならないはずです。オブザーバビリティの向上は、システムの信頼性と俊敏性を高めるだけでなく、ビジネスの成功とも直結するからです。本書で得られた知見を咀嚼し、行動に移していくこと。それが、著者のメッセージを真に理解し、オブザーバビリティの価値を自らの組織にもたらすための鍵となるでしょう。クラウドの時代において、オブザーバビリティは「あったら良いもの」ではなく「なくてはならないもの」になりつつあります。本書はその重要性を説き、実践への道筋を示してくれる、頼もしい道しるべだと言えます。みなさん、最後まで読んでくれて本当にありがとうございます。途中で挫折せずに付き合ってくれたことに感謝しています。読者になってくれたら更に感謝です。Xまでフォロワーしてくれたら泣いているかもしれません。参考資料Observability WhitepaperPerformance ReportReturn on Investment Driven ObservabilityIntro to exemplars, which enable Grafana Tempo’s distributed tracing at massive scaleMTBF, MTTR, MTTA, and MTTFDocker daemon configuration overviewContainer Runtime Interface (CRI)github | CrunchyData/pgmonitorLogging in Action - With Fluentd, Kubernetes and moreContextual Logging in Kubernetes 1.24System LogsFluentdFluent BitElastic BeatsLogstashOpenSearch Data Preppersyslog-ngrsyslogGraylogCriblPrometheusCollectdGrafana AgentGraphiteNagiosStatsDTelegrafOpenTelemetryOpenTelemetry Java Auto-InstrumentationOpenTelemetry JavaScriptOpenTelemetry Node SDKOpenTelemetry PythonOpenTelemetry .NET Auto-InstrumentationOpenTelemetry Go InstrumentationCloud Native Observability with OpenTelemetryPractical OpenTelemetryLearning OpenTelemetryAmazon CloudWatch AgentAWS Embedded Metric Format (EMF)AWS CloudWatch Agent OpenTelemetry SupportAWS Distro for OpenTelemetryAzure Monitor Agent (AMA)Azure OpenTelemetry SupportGoogle Cloud Ops AgentVector by DatadogLogstash, Fluentd, Fluent Bit, or Vector ComparisonVector, Fluent Bit, Fluentd Performance BenchmarkingOpenTelemetry Collector Performance | BenchmarksAWS Distro for OpenTelemetry Collector PerformanceOpenTelemetry Collector DashboardOpenSearch Install with DockerKubernetes Control Plane LogsKubernetes Worker Node LogsAWS CloudTrailAmazon CloudWatch LogsAWS Embedded Metric Format (EMF)Azure Monitor LogsGoogle Cloud LoggingElasticsearchOpenSearchApache LuceneElasticsearch in Action, Second EditionGrafana LokiZincObserveSplunkInstanaSolarWindsLogz.ioAmazon CloudWatch MetricsAmazon Managed Service for PrometheusPrometheus Remote WriteAmazon TimestreamAzure Monitor MetricsGoogle Cloud MonitoringGoogle Cloud Managed Service for PrometheusCNCF CortexThanosClymeneGrafana MimirIcingaInfluxDBLinDBM3DBM3DB at FOSDEM 2020Nagios CoreNetdataNightingaleOpenTSDBPromscaleTimescaleDBQuestDBZabbixChronosphereVictoriaMetricsPrometheus Compliance GuideAWS X-RayDistributed Tracing in AzureGoogle Cloud TraceJaegerZipkinGrafana TempoGoogle Cloud Trace OverviewApache CassandraScyllaDBApache DruidApache Druid: overview, running in Kubernetes and monitoring with PrometheusApache PinotReal-time analytics on network flow data with Apache PinotClickHouseAltinity Operator for ClickHouseFrostDBSnowflakeComparison of the Open Source OLAP Systems for Big DataOpenTelemetry Columnar EncodingDesigning Data-Intensive ApplicationsFundamentals of Data ObservabilityOpenTelemetry Fluent Forward ReceiverOpenTelemetry ClickHouse ExporterClickHouse Operations DocsClickHouse Networking ArticleClickCatPrestoDBAmazon RedshiftGoogle BigQueryCNCF Observability & Analysis LandscapeOpenTelemetry Vendor SupportApache KafkaOpenTelemetry Kafka ExporterElastic Common Schema (ECS)LogQLCloudWatch Logs Insights Query SyntaxSyslog Protocol (RFC 5424)Common Log FormatNGINX LoggingGraylog Extended Log Format (GELF)Windows Event Log SchemaCommon Event Format (CEF)Prometheus Query Language (PromQL)Prometheus Exposition FormatOpenMetricsInfluxData FluxGoogle pprofOpenTelemetry Protocol (OTLP)High-Cardinality TSDB BenchmarksGrafanaGrafana Data Sources DocumentationGrafana PluginsGrafana Dashboards DocumentationGrafana Alerting DocumentationAWS Managed GrafanaGrafana CloudKibanaOpenSearch Dashboards DocumentationCNCF JaegerApache SkyWalkingSigNozUptraceDatadogHoneycombNew RelicSplunkDatadog SyntheticsElastic SyntheticsNew Relic SyntheticsAmazon CloudWatch SyntheticsWhen to Alert on What?Anomaly Detection Reddit ThreadShoreline AIOpsAmazon SNSAlertmanager Configuration ExamplePrometheus Alerting RulesAwesome Prometheus AlertsAlertmanager Notification TemplatesCortex | Configuring Notification using Cortex AlertmanagerThanos | Alerting RulesPrometheus: Up & Running, 2nd EditionImproved Alerting With Prometheus and AlertmanagerLife of an Alert TalkGrafana Unified AlertingGrafana Contact PointsGrafana Contact Point TypesAmazon CloudWatch AlarmsAzure Monitor AlertsGoogle Cloud AlertingAWS CloudTrailReal User Monitoring OTEPGoogle AnalyticsAmazon CloudWatch RUMLeadDev An introduction to Real User Monitoring (RUM)Single-Page ApplicationsObservable Frontends OpenTelemetryOpenTelemetry Real User MonitoringAWS Cost and Usage ReportsOpenCostServerless: who’s on call now?All Things Clock, Time and Order in Distributed Systems: Physical Time in Depthhttps://www.w3.org/TR/trace-context/Tracesho11y (pronounced: howl-y)Cloud-Native Observability with OpenTelemetryhttps://httpstatuscodes.org/429/https://opentelemetry.io/docs/collector/deployment/Span Metrics Connectorhttps://keyval.dev/distributed-tracing-2025/Using latency histogramsService MapbubbleupShift-Left: A Developer's Pipe(line) Dream?A Modern Shift-Left Security ApproachGNU gprofDTrace ToolspprofProtocol BuffersIce and Fire: How to read icicle and flame graphshttps://man7.org/linux/man-pages/man2/bpf.2.htmlBPF Performance Tools (book)What Is eBPF?https://www.parca.dev/https://www.parca.dev/docs/parca-agent-language-supporthttps://demo.parca.dev/https://px.dev/https://pyroscope.io/https://demo.pyroscope.io/Continuous profiling now in public preview in Grafana CloudProposal: Adding profiling as a support event typeWhat is Amazon CodeGuru Profiler?Profile production applications in Azure with Application Insights ProfilerProfiling concepts ; Google CloudProfiling and optimization - Dynatrace DocsReal-time profiling for Java using JFR metricsProfiling and optimization - Dynatrace DocsFantastic Symbols and Where to Find Them - Part 1BPF binaries: BTF, CO-RE, and the future of BPF perf toolsInstalling TracetestTrace-based testing cloud-native apps with AWS X-Ray and TracetestMonitoring and Testing Cloud Native APIs with GrafanaProfiles, the Missing Pillar: Continuous Profiling in Practice - InfoQ- BPF Portability and CO-REFrostDBGorilla: A Fast, Scalable, In-Memory Time Series DatabaseTime-series Compression Algorithms ExplainedQuerying ParcaFlameQLLaunchDarkly: Feature Management PlatformAmazon CloudWatch Evidently - Implement Safer Feature Releases and A/B ExperimentsFallacies of Distributed SystemseBay/flow-telemetry: Open source host/network flow collector and exporterDigma: Developer Observability and Continuous FeedbackSprkl: Developer Tool for Continuous Observabilitysprkl-dev/use-sprkl: React hook for Sprkl integrationTracetest: Integration testing platform for cloud-native systemsgoogle/pprof/profile.protoInstalling the protocol compilerBuf: A new way of working with Protocol BuffersProtoman: A GUI for Protobuf filespostmanlabs/postman-app-support: How to encode protobuf in Postman?Flame GraphsDatadog Continuous ProfilerProfilerpedia - Profilers by LanguageDataDog/go-profiler-notes/guideRookout: Debug and Understand Live CodeAutometrics: Observability made simple for developersNew Relic Thread ProfilerProdfiler: Continuous Profiling for Production ApplicationsGranulate Continuous ProfilingBooks For Site Reliability EngineeringThe RED Method: A New Approach to Monitoring Microservices - The New StackGroupGitHub - pyrra-dev/pyrra: Making SLOs with Prometheus manageable, accessible, and easy to use for everyone!Welcome to SLOcademyPyrraSLO-Based Observability For All Kubernetes Cluster Components - Matthias Loibl & Nadine Vehling - YouTubeSloth - SlothCoreDNS availability - SlothNobl9 Reliability Software and Tools to Manage SLOs and MonitoringConcepts in service monitoring  |  Google Cloud Observabilityサービスレベル目標（SLO）SLOs: Service Level Objectives | HoneycombService-level objectives - Dynatrace DocsGet started with New Relic service levelsSLA vs. SLI vs. SLO: Understanding Service Levels | SplunkOpenSLOcommunity/sig-scalability/slos/slos.md at master · kubernetes/community · GitHubThe first Service Level Objective Conference for Site Reliability Engineers Correlating Signals Efficiently in Modern ObservabilitySemantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryResource Semantic Conventions | OpenTelemetryTrace Semantic Conventions | OpenTelemetrygRPCMetrics Semantic Conventions | OpenTelemetryGeneral Logs Attributes | OpenTelemetryResource Semantic Conventions | OpenTelemetryMetrics Semantic Conventions | OpenTelemetryRFC 7231: Hypertext Transfer Protocol (HTTP/1.1): Semantics and ContentTraces | OpenTelemetryApache KafkaEvent Listener - Amazon EventBridge - AWSAWS X-RayIntroduction to exemplarsBuild an observability solution using managed AWS services and the OpenTelemetry standard | AWS Cloud Operations & Migrations BlogOne Observability WorkshopOperationCorrelationTelemetryInitializer Class (Microsoft.ApplicationInsights.Extensibility) - Azure for .NET Developers | Microsoft LearnCorrelate log entries  |  Cloud Logging  |  Google CloudCustom Correlation for Java ApplicationsConfigure Custom Correlation for .NET ApplicationsMetric CorrelationsCorrelate Request Logs With Traces Automatically | Datadog White modal up arrow Icon/worldCorrelating distributed traces of large scale systems | Dynatrace EngineeringAPM Alternative & Platform Comparison | HoneycombCloud ObservabilityCorrelate Logs and TracesConfigure correlation logic with decisionscorrelate - Splunk DocumentationCloud scale correlation and investigation with Cloud SIEM | Sumo LogicBrightTalkData protection - European CommissionTAG OBS Query Standardization WG Charter - Google ドキュメント]]></content:encoded>
        </item>
    </channel>
</rss>