<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Fri, 17 Oct 2025 22:40:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[AIエージェント入門 〜基礎からMCP・A2Aまで〜]]></title>
            <link>https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade</link>
            <guid isPermaLink="false">https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade</guid>
            <pubDate>Sat, 18 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/373059/2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[二つのCubeの重なり部分を削除したUSD primの生成方法]]></title>
            <link>https://zenn.dev/akasan/articles/0b0a014a5eb790</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0b0a014a5eb790</guid>
            <pubDate>Fri, 17 Oct 2025 13:58:23 GMT</pubDate>
            <content:encoded><![CDATA[今回はふと気になったので、OpenUSDで二つのCubeを生成してその重なっているところを削除したような図形を作る方法を調べてみました。※ ChatGPTに作り方を聞きました。いつもお世話になっております。 今回やってみたかったこともう少し厳密に今回やってみたかったことを文字起こしすると以下のようになります。二つのCubeをA、BとするAとBには重なる部分があるとするAからAとBが重なっている場所を削除する 早速ChatGPTに聞いてみた質問内容としては以下のように問い合わせました。pxr.UsdGeom.Cubeで作成したキューブAとBがあるとします。例えば...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustのDockerfile、2025年はこれでいこう]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/17/070250</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/17/070250</guid>
            <pubDate>Thu, 16 Oct 2025 22:02:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「Dockerでビルドすると遅いんだよね」「イメージが2GB超えちゃって…」そんな会話はもう過去の話です。2025年、コンテナ化は劇的に進化しました。Rustも例外ではありません。cargo-chefとBuildKitキャッシュマウントの組み合わせでビルド時間を5-10倍短縮、2.63GBのイメージをdistrolessイメージで約50MB、musl静的リンクならわずか1.7MBという値を達成できます。この記事では、実践的なDockerfileパターンとベンチマーク結果を詳しく解説します。実際に検証したAxum Webアプリケーションでは、distroless版で50.3MB、musl+scratch版で1.71MBを達成しました。中規模プロジェクト（約500の依存関係）での初回ビルドは10分、コード変更後の再ビルドはわずか40秒です。信じられないかもですが、これが2025年の現実です。ちゃんとやれって話です。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。2025年の重要なアップデートRust 2024 Edition（2025年2月20日リリース）Rust 1.85.0でRust 2024 Editionが安定版になりました。Docker環境でRust 1.85以降を使えば、Edition 2024の機能が使えます。doc.rust-lang.orgblog.rust-lang.orgDocker関連の進化Docker Engine v28：コンテナネットワーキングのセキュリティ強化、AMD GPUサポートdocs.docker.comdocker init GA：Rustプロジェクト用の最適化されたDockerfile自動生成docs.docker.comDocker Bake GA：複雑なビルド設定の宣言的管理docs.docker.comBuildKit 0.25.1：Git URLクエリパラメータ、シークレットの環境変数化など新機能github.com基本的な考え方マルチステージビルドは前提条件2025年でマルチステージビルドを使わないのは、正直あり得ません。まずメンテナンス性が格段に向上します。最終的な成果物以外ではサイズを意識したトリッキーな記述が不要になるため、Dockerfileの可読性が劇的に良くなります。次にビルド速度のアップ。並列化、キャッシュマウント、tmpfsなど最適化オプションが豊富に使えるようになり、ビルドパイプライン全体が高速化します。そして何よりセキュリティの向上。シークレット管理の仕組みが標準化され、機密情報の取り扱いが安全になりました。docs.docker.comCOPYは最小限に、--mountを活用COPYが登場するのは、実質的に2つの場面だけです。マルチステージビルドで別ステージから成果物を持ってくる場合と、最終ステージでアプリケーションバイナリをコピーする場合。それ以外、特にソースコードのビルド時には--mount=type=bindを使用します。docs.docker.com必ず記述すべきおまじない# syntax=docker/dockerfile:1この1行を必ず先頭に記述します。最新のDockerfile構文が自動的に利用され、新機能が使えるようになります。docs.docker.com2025年のDockerfileはこれでやります前置きはこれくらいにして、実際のコードを見ていきましょう。これが2025年のRust標準Dockerfileです。cargo-chefによる依存関係の分離、BuildKitキャッシュマウント、distrolessイメージ、非rootユーザー実行。この記事で解説してきたベストプラクティスのすべてが、この1つのテンプレートに詰め込まれています。# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85ARG APP_NAME=myapp# cargo-chefを使った依存関係キャッシングFROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builder# 依存関係のビルド（キャッシュ可能）COPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    cargo chef cook --release --recipe-path recipe.json# アプリケーションのビルドCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release --bin ${APP_NAME} && \    cp ./target/release/${APP_NAME} /bin/server# テストステージ（オプション）FROM chef AS testCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=/usr/local/cargo/git \    cargo test# 本番ステージ：distrolessFROM gcr.io/distroless/cc-debian12:nonroot AS runtimeCOPY --from=builder /bin/server /app/WORKDIR /appEXPOSE 8000ENTRYPOINT ["/app/server"]このDockerfileの主な特徴cargo-chefによる依存関係の分離とキャッシングBuildKitキャッシュマウントでレイヤーを跨いだキャッシュdistrolessによる最小サイズと高セキュリティ非rootユーザー（:nonrootタグ）での実行オプショナルなテストステージビルド最適化の3つの柱1. cargo-chefcargo-chefは、Rustの依存関係管理をDockerレイヤーキャッシュに適合させる画期的なツールです。依存関係のコンパイルとソースコードのコンパイルを完全に分離します。動作メカニズム（2段階）：cargo chef prepare：Cargo.tomlとCargo.lockを解析してrecipe.jsonを作成cargo chef cook：最小限のプロジェクト構造を再構築して依存関係のみをビルド重要：同じRustバージョンと作業ディレクトリを全ステージで使用すること。異なるバージョンを使うとキャッシュが無効化されます。実測データ：cargo-chefのみで55%の改善cargo-chef + sccacheで79%の改善（34秒→7秒）商用プロジェクト（14,000行、500依存関係）で10分→2分github.com2. BuildKitキャッシュマウントBuildKitのキャッシュマウント（Docker 18.09以降）を使うと、レイヤー無効化を超えて永続化するキャッシュボリュームが利用できます。3つの重要なキャッシュポイント：RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release/usr/local/cargo/registry：crates.ioからのダウンロード/usr/local/cargo/git：Git依存関係/app/target：ビルド成果物sharing=lockedパラメータは排他アクセスを保証し、パッケージマネージャーの破損を防ぎます。CI環境でのキャッシュ共有：# GitHub Actions- uses: docker/build-push-action@v6  with:    cache-from: type=gha    cache-to: type=gha,mode=maxパフォーマンスベンチマーク：ベースライン：90.60秒BuildKitキャッシュマウント：15.63秒（5.8倍高速）cargo-chef：18.81秒（4.8倍高速）三位一体（chef + BuildKit + sccache）：7-12秒（7.5-13倍高速）docs.docker.com3. sccachesccache（v0.7.x）はMozilla製のccache風コンパイララッパーで、個々のコンパイル成果物を細粒度でキャッシュします。github.comFROM rust:1.85 AS builder# sccacheのインストールと設定RUN cargo install sccache --version ^0.7ENV RUSTC_WRAPPER=sccache \    SCCACHE_DIR=/sccache \    CARGO_INCREMENTAL=0WORKDIR /appRUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \    --mount=type=bind,target=. \    cargo build --release重要：CARGO_INCREMENTAL=0は必須。インクリメンタルコンパイルとsccacheは競合します。キャッシュヒット率：初回ビルド：0%ソースコード変更のみ：85-95%依存関係を更新した時：60-75%注意点：sccacheの効果は環境によって大きく異なります。一部の環境では効果が薄く、逆にオーバーヘッドとなる場合があります。自環境でのベンチマークが必須です。イメージサイズの最適化：ベースイメージ選択戦略ビルドステージ：rust:slim推奨2025年はrust:slim（Debian系）でよいと思っています。console.cloud.google.comFROM rust:1.85-slim-bookworm AS builder理由はシンプルです。Debian stable（bookworm）ベースでglibcを使用しているため、広範な互換性とマルチスレッドワークロードでの優れたパフォーマンスを発揮します。完全版のrust:latestが624MBもあるのに対し、rust:slimはコンパイルに必要な最小限のパッケージだけを含んでいます。無駄がありません。rust:alpineは避けてください。 muslの互換性問題に加えて、マルチスレッドアプリケーションで最大30倍のパフォーマンス劣化が報告されています。イメージサイズの小ささに惹かれる気持ちはわかりますが、本番環境でこの劣化は致命的です。５５https://hub.docker.com/_/rust最終ステージ：distroless推奨gcr.io/distroless/cc-debian12が2025年の標準です。FROM gcr.io/distroless/cc-debian12:nonrootdistrolessの特徴：サイズ：21-29MBglibc、SSL証明書、タイムゾーンデータ、/etc/passwdを含むパッケージマネージャー、シェル不要なバイナリを完全排除SLSA 2準拠、cosign署名検証が可能CVEスキャンで従来イメージより50-80%少ない脆弱性:nonrootタグでUID 65534（nobody）として非rootで実行github.comイメージサイズ比較（実測値） イメージ構成  サイズ  用途  特徴  scratch + musl（実測）  1.71MB  CLIツール最小化  完全静的リンク  distroless/static  2-3MB  静的リンクバイナリ  最小限のファイル  distroless/cc-debian12（実測）  50.3MB  Webアプリ推奨  glibc  debian-slim  80-120MB  フル互換性  デバッグツールあり  rust:latest（未最適化）  2.63GB  開発専用  ビルドツール込み 実測削減率：rust:latest（2.63GB）→ distroless（50.3MB）：98.1%削減rust:latest（2.63GB）→ musl+scratch（1.71MB）：99.9%削減静的リンク vs 動的リンクmusl（x86_64-unknown-linux-musl）での静的リンク：FROM rust:1.85-alpine AS builderRUN apk add --no-cache musl-devWORKDIR /app# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo build --release --target x86_64-unknown-linux-musl && \    rm -rf src# アプリケーションのビルドCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/myapp /myappENTRYPOINT ["/myapp"]利点：依存関係ゼロで完全にポータブルscratchコンテナで実行可能イメージサイズ5-10MB欠点：シングルスレッドで0.9-1.0倍、マルチスレッドで0.03-0.5倍のパフォーマンス一部依存関係でsegfaultのリスク本番環境の推奨：複雑なアプリケーション（Webサーバー、DB接続）：glibc + distroless/cc-debian12シンプルなCLIツール：musl + scratchを検討パフォーマンスが重要：必ずglibcを使用マルチアーキテクチャビルドlinux/amd64とlinux/arm64の両対応が2025年の標準要件です。cargo-zigbuild：セットアップゼロのクロスコンパイルcargo-zigbuild（v0.20.1）はZigツールチェインを使い、セットアップ不要でクロスコンパイルできます。github.com# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85FROM --platform=$BUILDPLATFORM rust:${RUST_VERSION}-alpine AS builderWORKDIR /app# Zigとcargo-zigbuildのインストールRUN apk add --no-cache musl-dev openssl-dev zigRUN cargo install --locked cargo-zigbuild# ターゲットの設定ARG TARGETPLATFORMRUN case ${TARGETPLATFORM} in \    "linux/amd64") echo x86_64-unknown-linux-musl > /rust_target ;; \    "linux/arm64") echo aarch64-unknown-linux-musl > /rust_target ;; \    esac && \    rustup target add $(cat /rust_target)# 依存関係とビルドCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo zigbuild --release --target $(cat /rust_target) && \    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo zigbuild --release --target $(cat /rust_target)FROM alpine:latestARG TARGETPLATFORMCOPY --from=builder /app/target/*/release/app /appCMD ["/app"]重要：--platform=$BUILDPLATFORMを使うと、ビルド自体はネイティブアーキテクチャで実行できるので、QEMUエミュレーションより圧倒的に速いです（QEMUエミュレーションは16-25倍遅い）。実測データ：ネイティブビルド：2-3分QEMUエミュレーション：50分（16-25倍遅い）cargo-zigbuildクロスコンパイル：13分Docker buildxでのマルチプラットフォームビルド# ビルダーの作成docker buildx create --name container-builder \    --driver docker-container --bootstrap --use# マルチプラットフォームビルドdocker buildx build \    --platform linux/amd64,linux/arm64 \    -t myimage:latest \    --push .https://docs.docker.com/build/buildx/docs.docker.comセキュリティベストプラクティス1. 非rootユーザーで実行distroless :nonrootタグが最も簡単：FROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /app/target/release/myapp /usr/local/bin/CMD ["/usr/local/bin/myapp"]自動的にUID 65534（nobody）として実行されます。カスタムユーザー作成：FROM debian:bookworm-slimARG UID=10001RUN adduser \    --disabled-password \    --gecos "" \    --home "/nonexistent" \    --shell "/sbin/nologin" \    --no-create-home \    --uid "${UID}" \    appuserUSER appuserCOPY --from=builder /app/target/release/myapp /app/CMD ["/app/myapp"]2. 脆弱性スキャンTrivy（推奨）：# イメージスキャンdocker run --rm -v /var/run/docker.sock:/var/run/docker.sock \    aquasec/trivy image myapp:latest# CI/CD統合- name: Run Trivy scan  uses: aquasecurity/trivy-action@master  with:    image-ref: 'myapp:${{ github.sha }}'    severity: 'CRITICAL,HIGH'    exit-code: '1'github.comdistrolessのセキュリティ優位性：Alpine（musl）からChiseled Ubuntu（glibc）への移行で30+ CVEが0 CVEにdistrolessイメージはAlpineより50-80%少ないCVEパッケージマネージャー不在により攻撃ベクトル削減SLSA 2準拠、cosign署名認証3. シークレット管理絶対に避けるべき：環境変数へのシークレット設定イメージに焼き込まれてしまいます。正しい方法：# ビルド時シークレットRUN --mount=type=secret,id=api_token,env=API_TOKEN \    cargo build --release# 実行時docker build --secret id=api_token,env=API_TOKEN .4. イメージバージョンのピン留め# ❌ 避けるべきFROM rust:latest# ✅ 推奨FROM rust:1.85-slim-bookwormユースケース別DockerfileWebアプリケーション（Axum / Actix-web）上記の「標準Dockerfile」パターンをそのまま使用できます。CLIツール（完全静的リンク）# syntax=docker/dockerfile:1FROM rust:1.85-alpine AS builderWORKDIR /appRUN apk add --no-cache musl-dev openssl-dev openssl-libs-static# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo build --release --target x86_64-unknown-linux-musl && \    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/cli-tool /app/ENTRYPOINT ["/app/cli-tool"]シェルエイリアスは以下のように設定できます。alias my-cli='docker run --rm -v $(pwd):/data my-cli-image'ワークスペース（モノレポ）対応# syntax=docker/dockerfile:1ARG SERVICE_NAME=api-gatewayARG RUST_VERSION=1.85FROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builderARG SERVICE_NAMECOPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    cargo chef cook --release --bin ${SERVICE_NAME} --recipe-path recipe.jsonCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release --bin ${SERVICE_NAME} && \    cp ./target/release/${SERVICE_NAME} /bin/serviceFROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /bin/service /app/ENTRYPOINT ["/app/service"]異なるサービスを同じDockerfileから生成できます。docker build --build-arg SERVICE_NAME=api-gateway -t gateway .docker build --build-arg SERVICE_NAME=user-service -t users .実践的な検証結果実際のAxum Webアプリケーション（依存関係82個）で3つの戦略を検証しました。検証環境：CPU: Apple M-series (ARM64)Docker: Colima on macOSRust: 1.85 (Edition 2024)3つのパターン比較パターン1: Naive（最適化なし）- デフォルトの実態Dockerfile.naive は何も工夫しないシンプルなビルドです。これが「デフォルトの何もしていない状態」です。⚠️ デフォルト状態のビルド結果：初回ビルド時間: 約10-15分（依存関係82個を全てコンパイル）ソースコード変更後の再ビルド: 約10-15分（依存関係も毎回再コンパイル）最終イメージサイズ: 2.63GBセキュリティ: rootユーザー、開発ツール込み（脆弱性大）問題点：ソースコード1行変更するだけで10-15分のビルドが毎回走るイメージに不要なRustコンパイラ（500MB）、ビルドツール、ドキュメントが全て含まれるマルチステージビルドがないため、最終イメージが巨大cargo-chefがないため、依存関係とソースコードが分離されていないパターン2: Baseline（cargo-chef + distroless）Dockerfile は2025年の推奨パターンです。ビルド結果：ビルド時間: 38秒（依存関係キャッシュ済み）最終イメージサイズ: 50.3MBセキュリティ: 非rootユーザー（UID 65534）、最小限のファイルTrivy脆弱性: 0 HIGH/CRITICALパターン3: Ultra-minimal（musl + scratch）Dockerfile.musl は最小サイズを優先したパターンです。ビルド結果：ビルド時間: 46秒（依存関係キャッシュ済み）最終イメージサイズ: 1.71MBセキュリティ: rootユーザー（scratchに制限あり）比較結果まとめ 項目  Naive (未最適化)  Baseline (distroless)  Ultra-minimal (musl)  イメージサイズ  2.63GB  50.3MB  1.71MB  削減率  - (100%)  98.1%削減  99.9%削減  ビルド時間  30秒  38秒  46秒  マルチステージ  ❌ なし  ✅ あり (4段階)  ✅ あり (2段階)  キャッシュ最適化  ❌ なし  ✅ cargo-chef + BuildKit  ✅ BuildKit  ベースイメージ  rust:1.85 (full)  distroless/cc-debian12  scratch  リンク方式  動的（glibc）  動的（glibc）  静的（musl）  開発ツール  ❌ 含まれる  ✅ 除去済み  ✅ 除去済み  セキュリティ  ❌ 低  ✅ 高  ⚠️ 中  デバッグ  ✅ 可能  ❌ 困難  ❌ 不可能 パフォーマンスベンチマーク商用プロジェクト（14,000行、500依存関係）：最適化なし：10分cargo-chef使用：2分（5倍高速化）大規模ワークスペース（400 crate、1500依存関係）：未最適化：約65分最適化後：約2分（30倍以上の改善）検証の再現方法このリポジトリで実際に試せます。# Baseline版のビルドdocker build -t rust-demo:baseline .# Ultra-minimal版のビルドdocker build -f Dockerfile.musl -t rust-demo:musl .# サイズ比較docker images | grep rust-demo# 動作確認docker run -p 8000:8000 rust-demo:baselinedocker run -p 8001:8000 rust-demo:muslよくある問題と解決策OpenSSLリンクエラーエラー： "Could not find directory of OpenSSL installation"解決策1：vendored OpenSSL（最も簡単）[dependencies]openssl = { version = "0.10", features = ["vendored"] }解決策2：Alpine適切パッケージFROM rust:1.85-alpineRUN apk add --no-cache openssl-dev openssl-libs-static musl-dev解決策3：Debianベース使用FROM rust:1.85-slim-bookwormRUN apt-get update && apt-get install -y pkg-config libssl-dev解決策4：rustls（Rust-native TLS）[dependencies]reqwest = { version = "0.11", features = ["rustls-tls"], default-features = false }muslリンクエラーAlpine向け：FROM rust:1.85-alpineRUN apk add musl-dev openssl-dev openssl-libs-staticRUN rustup target add x86_64-unknown-linux-muslENV PKG_CONFIG_ALLOW_CROSS=1RUN cargo build --release --target x86_64-unknown-linux-musl必要な環境変数：RUSTFLAGS='-C target-feature=+crt-static'PKG_CONFIG_ALLOW_CROSS=1OPENSSL_STATIC=1（システムOpenSSL使用時）DNS解決エラー（scratchイメージ）解決策1：distroless/static使用FROM gcr.io/distroless/static-debian12解決策2：Pure Rust DNSリゾルバー[dependencies]reqwest = { version = "0.11", features = ["trust-dns"] }解決策3：必要ファイルコピーFROM alpine:latest AS ca-certificatesRUN apk add -U --no-cache ca-certificatesFROM scratchCOPY --from=ca-certificates /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/.dockerignoreの重要性.dockerignoreがないと、target/ディレクトリ（数GB）がビルドコンテキストに含まれ、ビルドが遅くなります。# .dockerignoretarget/.git/.env*.log効果: ビルドコンテキストのサイズを数GBから数MBに削減 → ビルド開始が高速化。イメージサイズ肥大化一般的原因と解決策：最終イメージにビルドツール含む → マルチステージビルドで93%削減本番環境でfull rustイメージを使用 → slimランタイムベースで95%削減バイナリにデバッグシンボルが含まれる → strip target/release/myappで30-40%削減開発依存関係 → プロファイル設定[profile.release]strip = truelto = truecodegen-units = 12025年の新ツール活用docker init - プロジェクトの素早い立ち上げ# プロジェクトディレクトリで実行docker init# Rustを選択すると自動生成：# - Dockerfile# - compose.yaml# - .dockerignore# - README.Docker.mddocs.docker.comDocker Bake - 複雑なビルドの管理docker-bake.hcl:group "default" {  targets = ["app"]}variable "TAG" {  default = "latest"}target "app" {  context = "."  dockerfile = "Dockerfile"  tags = ["myapp:${TAG}"]  platforms = ["linux/amd64", "linux/arm64"]  cache-from = ["type=registry,ref=myapp:cache"]  cache-to = ["type=registry,ref=myapp:cache,mode=max"]}# 実行docker buildx bake# 変数をオーバーライドdocker buildx bake --set TAG=v1.0.0docs.docker.comおわりにこの記事では、2025年時点でのRust Dockerのベストプラクティスを包括的に解説しました。cargo-chefによる依存関係の分離キャッシング、BuildKitの永続キャッシュマウント、distrolessイメージによるセキュリティ強化という3つの柱を中心に、実践的なDockerfileパターンと実測データを提供しています。Rustのコンテナ化は長い間「ビルドが遅い」「イメージが大きい」という課題を抱えていました。コンパイル時間の長さは諦めるしかなく、数GBのイメージサイズは「Rustだから仕方ない」と言われてきました。しかし、2025年現在、その課題は完全に解決しました。適切な最適化で、ビルド時間を5-10倍短縮、イメージサイズを98-99%削減できます。これは単なる理論ではなく、実際のプロダクション環境で日々使われている技術です。2025年のゴールデンルールこの記事で紹介した技術を実践する際は、以下の10のポイントを押さえておくといいでしょう。# syntax=docker/dockerfile:1を必ず記述 - 最新のDockerfile構文を自動利用cargo-chefで依存関係を分離 - 5-10倍のビルド高速化を実現BuildKitキャッシュマウントを活用 - レイヤーを超える永続的なキャッシュdistroless/cc-debian12:nonrootを使用 - 50MB、非root、高セキュリティrust:slim-bookwormでビルド - Alpineは避ける（マルチスレッド性能問題）RUN --mount=type=bindでソースコードをマウント - COPYの最小化マルチステージビルドは必須 - 2025年の前提条件非rootユーザーで実行 - セキュリティの基本原則TrivyまたはGrypeでスキャン - 継続的なセキュリティ検証イメージバージョンをピン留め - :latestは避ける大半の本番ワークロードには、glibc + distroless/cc-debian12 + cargo-chefの組み合わせが最適解です。この構成により、50MBの小サイズ、2分の高速ビルド、フルパフォーマンス、優れたセキュリティプロファイルを実現できます。マルチスレッドアプリケーションでmuslを使う場合、1点だけ注意が必要です。最大30倍のパフォーマンス劣化リスクがあるので、本番環境への導入前に必ずベンチマークで検証しましょう。イメージサイズだけで判断すると、後で後悔します。2025年のRust Dockerは、従来の課題を完全に克服しました。高速、小サイズ、セキュア、マルチアーキテクチャ対応の成熟した技術スタックになっています。この記事で紹介した標準Dockerfileパターンは、そのままプロダクション環境で使える構成です。まずは標準パターンから始めて、必要なら sccache や cargo-zigbuild などの高度な最適化を追加するといいでしょう。Rustエコシステムの進化とDockerの機能強化で、今後もさらに改善していくはずです。この記事が、あなたのRustアプリケーションのコンテナ化に役立てば嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[skorchを使ってPyTorchモデルを学習してみた]]></title>
            <link>https://zenn.dev/akasan/articles/e8fd84246d013c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e8fd84246d013c</guid>
            <pubDate>Thu, 16 Oct 2025 12:49:36 GMT</pubDate>
            <content:encoded><![CDATA[今回はskorchを使ってPyTorchのモデルを学習してみました。skorchを利用すると、scikit-learnと同じ使い勝手でモデルを学習できるようになります。 skorchとは？先ほども書いたように、skorchを利用するとscikit-learnと互換性がある記述方式でPyTorchのモデルを学習できます。後ほどサンプルを見ながら進めますが、PyTorchで定義したモデルをskorchに受け渡して学習に利用できます。https://github.com/skorch-dev/skorch 早速使ってみる今回はGitHubに乗っているサンプルを元に使ってみます。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[baconを知らずにRust書いてた]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/16/170800</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/16/170800</guid>
            <pubDate>Thu, 16 Oct 2025 08:08:00 GMT</pubDate>
            <content:encoded><![CDATA[cargo-watch、やめるってよRustを書いてると、気づくんですよね。保存ボタンを押すたび、手動でcargo checkとかcargo testとか叩いてる自分に。「あれ、俺って原始人だっけ？」みたいな気持ちになる。そこで救世主として現れたのがcargo-watchだったわけです。過去形。github.comそう、cargo-watchはもうメンテされてないんです。引退しちゃった。ここで一旦、真面目な話を。10年以上もcargo-watchとwatchexecっていうOSSプロジェクトを守り続けてきたFélix Saparelliさんに、心から敬意と感謝を。あなたのおかげで、世界中の無数のRust開発者が「あ、これ便利じゃん」って生産性爆上げできたんです。本当にありがとうございました。で、公式READMEには作者本人がこう書き残してる。"It's time to let it go. Use Bacon. Remember Cargo Watch."なんかもう、エモすぎません？10年以上続いたプロジェクトが、バトンを次世代に渡して静かに去っていく感じ。その後継者がbacon。そして汎用性の塊みたいなwatchexec。ベーコンって名前、朝ごはん感あるけど、これが本当にすごいんですよ。というわけでこの記事では、Rust開発で使えるファイル監視ツールについて解説していきます。cargo-watchロス、今日で終わりにしましょう。baconって何？baconは、Rust専用に作られたバックグラウンドコードチェッカーです。エディタの隣で動かしておくと、ファイルを保存するたびに自動でコンパイルチェックを走らせて、エラーや警告をリアルタイムで表示してくれます。github.comcargo-watchとの違いcargo-watchの作者が「baconこそが自分の理想だった」と語っているほど、baconは進化しています。TUIで見やすい - エラーが警告より先に表示され、スクロール不要キーボード操作 - tでテスト、cでClippy、dでドキュメントと一瞬で切り替え小さい画面でも快適 - ターミナルのサイズに合わせて表示を最適化Rust Analyzerと競合しない - 開発体験がスムーズインストール# 基本インストールcargo install --locked bacon# オプション機能も入れる（クリップボード、サウンド）cargo install --locked bacon --features "clipboard sound"基本的な使い方プロジェクトのルートでbaconを起動するだけ。cd your-rust-projectbaconデフォルトではcargo checkが走ります。ファイルを保存すると自動で再チェック。主要なキーボードショートカットbaconの真価はキーボードショートカットにあります。t - テスト実行に切り替えc - Clippyに切り替えd - ドキュメントをブラウザで開くf - テスト失敗時、そのテストだけに絞り込みEsc - 前のジョブに戻るCtrl+j - すべてのジョブ一覧を表示h - ヘルプ表示q - 終了特定のジョブで起動# テストを監視bacon test# Clippyを監視bacon clippy# 厳格なClippyルール（pedantic）bacon pedantic# 高速テストランナー（nextest）bacon nextest# すべてのターゲットをチェックbacon check-all# 特定のジョブを指定bacon --job my-custom-jobbacon.toml で設定をカスタマイズプロジェクトに合わせてジョブを定義できます。# 設定ファイルを生成bacon --init設定例# bacon.toml# Windows向けのチェック[jobs.check-win]command = ["cargo", "check", "--target", "x86_64-pc-windows-gnu"]# 厳しめのClippy[jobs.clippy-strict]command = [    "cargo", "clippy", "--",    "-D", "warnings",    "-A", "clippy::collapsible_if",]need_stdout = false# サンプルをチェック[jobs.check-examples]command = ["cargo", "check", "--examples", "--color", "always"]watch = ["examples"]  # srcは自動で監視される# 実行ジョブ[jobs.run]command = ["cargo", "run"]allow_warnings = trueneed_stdout = true# キーバインディングのカスタマイズ[keybindings]shift-c = "job:clippy-strict"r = "job:run"設定しておいてよいことドキュメントを素早く確認[jobs.doc-open]command = ["cargo", "doc", "--no-deps", "--open"]need_stdout = falseon_success = "back"  # ドキュメントが開いたら前のジョブに戻る長時間実行するアプリケーション[jobs.server]command = ["cargo", "run"]allow_warnings = trueneed_stdout = truebackground = falseon_change_strategy = "kill_then_restart"watchexecとの使い分けbaconはRust専用ですが、watchexecは汎用的なファイル監視ツールです。github.comwatchexecを使うべき場合# インストールcargo install watchexec-cli# 基本的な使い方watchexec --restart cargo run# 特定の拡張子だけ監視watchexec -e rs,toml cargo test# デバウンス設定watchexec -d 2000 cargo checkwatchexecが向いているケース：- Rust以外の言語やツール- シェルスクリプトの実行- rsyncなどの同期処理- より細かい制御が必要な場合# 例：TypeScriptのビルドwatchexec -e ts,tsx npm run build# 例：ファイル同期watchexec -w src -- rsync -avhP ./src/ ./backup/実践的なワークフロー開発時のセットアップターミナルを分割左：Vim/Neovim右上：bacon右下：通常のシェル私はWarpを使ってペイン分割している。baconの起動bacon  # デフォルトでcheckが走るコードを書く保存すると自動でチェックエラーがあれば即座に表示エラーが消えたらClippyの警告が見えるテストを書くtキーでテストモードに切り替え失敗したらfで絞り込み修正したらEscで全テストに戻る最終チェックcキーでClippyの提案を確認コード品質を向上ちょっとしたTipsシェルエイリアスで効率化頻繁に使うコマンドをエイリアス化すると便利です。# ~/.zshrc または ~/.bashrc に追加alias bac='bacon'alias bacc='bacon clippy'alias bact='bacon test'alias bacp='bacon pedantic'watchexecで複数パスを監視# srcとtestsディレクトリの.rsと.tomlファイルを監視watchexec -e rs,toml -w src -w tests -- cargo testVim/Neovimとの連携nvim-bacon プラグインbaconの診断結果をNeovimに統合するプラグインがあります。github.com" lazy.nvim の場合{  'Canop/nvim-bacon',  config = function()    require('bacon').setup()  end}主な機能は以下の通り。エラー箇所へのジャンプQuickfixへの統合:Bacon コマンドでbaconを起動:BaconLoad で診断結果を読み込み補足：VS Code向けVS Codeユーザーの場合は、bacon-lsというLanguage Serverが利用可能です。まとめcargo-watchの時代は終わりました。でも、より良いツールが生まれています。こう使い分けよう：Rust開発 → bacon一択TUIが快適キーボードだけで完結設定ファイルで柔軟にカスタマイズそれ以外 → watchexec汎用的に使えるシンプルで強力シェルスクリプトとの相性抜群baconを知らずにRustを書いていた人は、今すぐ試してください。開発体験が一段階レベルアップします。cargo install --locked baconcd your-projectbaconたったこれだけ。あとはコードを書くだけです。参考リンク：- bacon公式サイト- watchexec GitHub- cargo-watch（アーカイブ済み）]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ディレクトリ構成 ~ハイブリッド型編~]]></title>
            <link>https://sreake.com/blog/hybrid-directory-structure-good-practice/</link>
            <guid isPermaLink="false">https://sreake.com/blog/hybrid-directory-structure-good-practice/</guid>
            <pubDate>Thu, 16 Oct 2025 04:41:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、ディレクトリ構成に悩む現場に向けて、ハイブリッド型構成をご紹介します。 ⚠️ この構成が「唯一の正解 […]The post ディレクトリ構成 ~ハイブリッド型編~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonの@オペレータについて調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/e78d7c565fadaa</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e78d7c565fadaa</guid>
            <pubDate>Wed, 15 Oct 2025 13:52:08 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonで@をオペレータとして利用する方法を調べてみました。Python、特にNumPyを利用して行列を取り扱っていると、計算の時に@をオペレータとして使うことがしばしばあります。というか私はNumPy以外で@をオペレータとして使っていることをみたことはありませんでした。+や-など一般的なさん術オペレータはよく利用しますが@はどのようにすれば使えるようになるのかふと気になり調べてみました。 NumPyにおける@オペレータNumPyでは@は行列積を計算するためのオペレータとなっています。例えば以下にAとB二つの行列が会った時に、その積を計算できます。以下の例はBを単位行列に...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：chafa]]></title>
            <link>https://zenn.dev/akasan/articles/80f8931f8523cd</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/80f8931f8523cd</guid>
            <pubDate>Tue, 14 Oct 2025 09:50:27 GMT</pubDate>
            <content:encoded><![CDATA[今回は久々のコマンド紹介シリーズです。第14回目の本日はchafaを紹介しようと思います。chafaを利用するとターミナル上で画像とかGIFを参照することができます。なお、第13回は以下になりますので、ぜひご興味があればご覧ください。https://zenn.dev/akasan/articles/6392d28e0e02f0 chafaとは？公式GitHubによると、Chafaは、アニメーションGIFなどの画像データを、端末での表示に適したグラフィック形式またはANSI/Unicode文字アートに変換するコマンドラインユーティリティです。幅広い機能をサポートしており、歴史...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[文章力を分解してちゃんと文章を書く。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/14/133602</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/14/133602</guid>
            <pubDate>Tue, 14 Oct 2025 04:36:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに文章を読むとは、自分の中で文章を再構築するということである。あなたは技術記事を読んで「わかった」と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか。ドキュメントを読んで「理解した」と思ったのに、同僚に説明しようとすると言葉が出てこなかった経験はないだろうか。私にはある。何度もある。悲しい。これは単なる理解不足ではない。もっと根本的な問題だ。私たちは「読む」と「書く」を別々のスキルだと思い込んでいる。しかし、それは違うと私は考えている。読むとき、私たちは頭の中で文章を再構築している。書き手の言葉を、自分のスキーマ（枠組み）に翻訳し、自分の言葉で理解し直している。読むことは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、「わかった」と思っても実装できないのは、頭の中で再構築したものと現実の折り合いがついていないのだ。自分の言葉で書き直せていないのだ。「読解力を分解してちゃんと文章を読む。」という記事を書いたあと、私はあることに気づいた。文章を読む力を分解して説明しようとすればするほど、自分が書く文章の問題点が見えてくるのだ。読み手がどこでつまずくかを想像すると、自分が読むときにどこでつまずいていたかが見えてくる。syu-m-5151.hatenablog.comそして、ある結論に辿り着いた。書けない人間は、読めない。これは挑発でも誇張でもない。書く力と読む力は、コインの表裏ではなく、同じものなのだ。書く経験を通じて、私たちは「文章がどのように読まれるか」を学ぶ。一文が長すぎると読み手の認知負荷が上がること。主語が不明確だと読み手が推測を強いられること。構造が曖昧だと読み手が迷子になること。逆もまたあることだ。読む経験を通じて、私たちは「文章がどのように書かれるべきか」を学ぶ。明快な文章はどのような構造を持っているか。わかりやすい説明はどのように展開されるか。読解力の記事では、読む力を3つの段階に分解した。今回の記事では、書く力を同じように分解していく。第1段階：正確に書く第2段階：誤読されないように書くスキーマを想像し、知識の呪いを断ち切る。認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。第3段階：心を動かすように書く書くことで、初めて読めるようになる。読むことで、初めて書けるようになる。この循環的な関係を理解することが、文章力を高める第一歩だ。そして、この循環が複利的に機能する。書く力が向上すると読む力も向上し、読む力が向上するとまた書く力も向上する。この正のフィードバックループが、指数関数的な成長を生み出す。片方だけを鍛えようとしても、成長は頭打ちになる。両輪を回すことが、文章力を本質的に高める唯一の道だ。では、なぜ書く力と読む力は、これほどまでに密接に結びついているのだろうか。その理由を、まず理解する必要がある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。書く力と読む力は、なぜ表裏一体なのか書けないということは、理解していないということだエラーログを読めない人は、エラーメッセージを吐き出させるときも曖昧な表現をする。「エラーが発生しました」とだけ書いて、どのエラーが、どの条件で、何が原因で発生したのかを書かない。なぜか？自分がエラーログを読むときに、これらの情報を抽出できていないからだ。というか想像できていないからだ。読んで困った時の自分を。読むときに「どこに何が書いてあるか」を理解できていない人は、吐き出させるときにも「どこに何を書くべきか」を理解できない。これは単なる不注意ではない。書こうとして初めて、「何をどの順序で書くべきか」という問いに直面する。書こうとして初めて、「読み手は何を知りたいのか」という問いに直面する。この問いと格闘する過程で、私たちは文章の構造を深く理解する。技術記事を読んで「わかった」と思うのは、個々の文章を理解したということだ。しかし、それを実装できないのは、全体の構造を理解していないからだ。これは、ラバーダック・デバッギングと同じ原理だ。コードを声に出して説明しようとすると、理解の穴が見えてくる。文章を書こうとすると、読解の穴が見えてくる。書こうとして手が止まる瞬間、そこに理解の穴がある。誤読された経験が、誤読を防ぐ力を育てる理解の穴が見えるだけでは十分ではない。さらに重要なのは、自分が書いた文章がどう読まれるかを知ることだ。「この文章は誤解される」と事前に気づくには、自分が誤読された経験が必要だ。吐き出させた文章が意図と違う形で受け取られた経験。怒りのコメントを受けた経験。これらの痛い経験を通じて、人は「どんな書き方が誤解を生むか」を学ぶ。誤読には、いくつかのパターンがある。パターン1：主語の曖昧さによる誤読この機能の実装が遅れています。仕様が複雑で理解に時間がかかっています。書き手は「私」のつもりで書いている。しかし、読み手は「チーム全体」だと解釈するかもしれない。この誤読は、書き手が主語を省略したことで生じる。パターン2：文脈の欠如による誤読この実装方法は悪くない。書き手は、他の実装方法と比較して「悪くない」と言っている。しかし、読み手は、この実装方法が「及第点」程度だと解釈するかもしれない。パターン3：二重否定による誤読この問題は無視できない。書き手は「重要だ」と言いたい。しかし、読み手は「ある程度重要だが、最優先ではない」と解釈するかもしれない。誤読された経験は、痛い。しかし、その痛みこそが、書く力と読む力を同時に高める。書く経験が乏しい人は、読むときにも「書き手の意図」を想像できない。スキーマは読み書き両方で機能する誤読を防ぐには、さらに深い理解が必要だ。それは、読み手と書き手でスキーマが異なるという理解だ。人はスキーマを通して文章を理解する。スキーマとは、私たちが頭の中に持っている知識の枠組みのこと。例えば、「非同期処理」というキーワードを見たとき、Rustエンジニアの頭の中では、tokio、async/await、Future traitといった関連する概念が自動的に呼び出される。しかし、スキーマは読むときだけでなく、書くときにも機能している。そして、書くときのスキーマの働き方が、しばしば問題を引き起こす。あなたが「非同期処理を実装した」と書くとき、あなたの頭の中には「非同期処理」についての豊富なスキーマがある。だから、読み手もそのスキーマを共有していると無意識に仮定してしまう。これを「知識の呪い」と呼ぶ。【悪い例】非同期処理を実装しました。これでパフォーマンスが改善されます。書き手にとって、これは十分に明確だ。しかし、読み手はどうか？Rustエンジニアは「tokioのasync/awaitを使うのか」と想像する。Goエンジニアは「goroutineを使うのか」と想像する。非同期処理に馴染みのないエンジニアは「何が改善されるのか」すらわからない。書く力が高い人は、「読み手は自分とは違うスキーマを持っている」と意識的に認識する。そして、読み手のスキーマを想像し、橋を架けるように書く。【良い例】非同期処理を実装しました。従来は3つのマイクロサービスへのHTTPリクエストを順番に実行していたため、合計で3秒かかっていました。今回、Rustのtokioとasync/awaitを使ってこれらのリクエストを並行実行するように変更しました。その結果、3つのリクエストが同時に実行されるため、最も遅いリクエスト（1秒）の時間だけで完了するようになりました。これにより、全体の処理時間が3秒から1秒に短縮され、APIのレスポンスタイムが大幅に改善されました。では、この「読み手のスキーマを想像する力」は、どうやって獲得できるのか？答えは、読み手として多様な文章に触れ、「わからない」を経験することだ。自分が知らない分野の技術記事を読んで、「専門用語が多くてわからない」と感じる。その経験が、書き手として「専門用語を使うときは説明を加えよう」という意識を育てる。書くことは、読む力を鍛える最良の訓練ここまで見てきたように、書く経験は読む力を高める。しかし、その逆も真だ。読む経験は書く力を高める。この循環を最も効果的に回す方法が、実は書くことなのだ。なぜか？書こうとすると、言語化できない部分に直面するからだ。頭の中では理解しているつもりでも、いざ文章にしようとすると言葉が出てこない。この瞬間、あなたは「本当は理解していなかった」と気づく。しかし、問題はもっと深い。ちゃんと読むとは、自分の中でちゃんと書くということでもある。複雑な文章を読むとき、私たちは無意識のうちに「これはつまり、こういうことだな」と自分の言葉で要約している。この「内なる執筆」ができない人は、文章を読んでも理解が浅い。例を見てみよう。技術記事に「エラーハンドリングを実装すると、システムの信頼性が向上する」と書いてある。浅い読み方：「エラーハンドリングを実装すると信頼性が向上するのか。なるほど。」深い読み方：「エラーハンドリングを実装すると信頼性が向上する、と言っている。なぜか？エラーハンドリングがないと、エラーが発生したときにプログラムがパニックして停止してしまう。その結果、ユーザーはサービスを使えなくなる。一方、エラーハンドリングを実装すれば、エラーが発生してもプログラムは継続でき、ユーザーに明確なエラーメッセージを返せる。つまり、『信頼性が向上する』とは『エラー時でもサービスを継続できる』という意味だな。」深い読み方をしている人は、頭の中で文章を書いている。この「内なる執筆」の能力は、実際に書く経験を通じて鍛えられる。外に向けて文章を書くとき、私たちは「どう表現すれば伝わるか」を考える。この試行錯誤が、内なる執筆の能力を高める。だから、外に向けて書く訓練をすることは、内に向けて書く力も鍛える。このように、書く力と読む力は表裏一体だ。では、具体的にどう書けばよいのか。読解力の記事と同様、書く力も3つの段階に分解して見ていこう。第1段階：正確に書く読解力の第1段階は「書かれていることを正確に理解する力」だった。文章力の第1段階は、「伝えたいことを正確に伝える力」だ。これは、技術的なスキルだ。感性や才能ではなく、学習可能なスキルだ。悪文とは何か。それは、一義的に解釈できない文章だ。一つの文を読んで、複数の意味に解釈できてしまう。主語が不明確で、誰が何をしているのかわからない。修飾関係が複雑で、何がどこにかかっているのか判然としない。こうした構造的な問題が、悪文を生む。文章を書くコツは、芸術的な名文を書くことではない。読みにくい「悪文」を書かないことである。では、悪文を防ぐにはどうすればよいか。ここでは四つ紹介します。他にも悪文を分かりやすくする方法はいくらかありますがたくさん本が出ていますのでそちらを参考にしてほしいです。悪文の構造　――機能的な文章とは (ちくま学芸文庫)作者:千早耿一郎筑摩書房Amazon「文章術のベストセラー100冊」のポイントを1冊にまとめてみた。作者:藤𠮷 豊,小川 真理子日経BPAmazon一文一義で書く【悪い例】デプロイ作業中にDBマイグレーションが失敗したため、問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明なので、明日Yさんが出社してから対応するか、今日スキップしてデプロイするか、どちらが良いと思いますか？この一文には、6つの義が詰め込まれている。読み手は、これらすべてを一度に処理しなければならない。認知負荷が高すぎる。なぜ一文一義が重要なのか？人間の作業記憶（ワーキングメモリ）の容量は限られている。一文が長く、複数の義が含まれていると、読み手は文の途中で最初の部分を忘れてしまう。一文一義で書くことは、読み手の認知リソースを尊重することだ。【良い例】デプロイ作業中、DBマイグレーションに失敗しました。問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明です。対応方針を相談させてください。以下の2つの選択肢のうち、どちらが良いでしょうか？A. 明日Yさんが出社後、一緒に影響範囲を調査してから対応するB. 今日、問題箇所をスキップしてデプロイする一文一義の原則を守るには、3つのルールがある。ルール1：文章は短くするルール2：形容詞と被形容詞はなるべく近づけるルール3：一つの文に、主語と述語はひとつずつ短く、近く、シンプルに。これが機能的な文章の基本だ。主語を明示する一文一義を守るだけでは不十分だ。次に重要なのは、誰が何をしているかを明確にすることだ。日本語は主語を省略できる言語だ。しかし、文章を書くとき、特に技術文書やビジネス文書を書くとき、文脈が常に明らかとは限らない。主語を省略すると、3つの問題が生じる。問題1：責任の所在が不明確になる【悪い例】バグを修正しました。【良い例】私がバグを修正しました。問題2：行為者が不明確になる【悪い例】テストを実行して、結果を確認しました。【良い例】私がテストを実行しました。Aさんが結果を確認しました。問題3：複数の解釈が可能になる【悪い例】レビュー後、デプロイしました。【良い例】Aさんのレビュー後、私がデプロイしました。では、どうすればよいか？主語を省略してもよい場合と、省略してはいけない場合を区別する。主語を省略してもよい場合：直前の文と同じ主語の場合、文脈から主語が明らかな場合。主語を省略してはいけない場合：主語が変わる場合、責任の所在を明確にする必要がある場合、複数の解釈が可能な場合。冗長さを避ける正確に書くことは重要だが、冗長に書くことは避けなければならない。必要な情報だけを、必要な長さで書く。冗長な文章は、読み手の時間を無駄にする。忙しいエンジニアは、冗長な文章を読む時間がない。冗長な文章は、重要な情報を埋もれさせる。冗長さには、いくつかのパターンがある。パターン1：同じことを繰り返す【悪い例】この問題は重要な問題です。なぜなら、この問題を放置すると、ユーザーに影響が出る重大な問題だからです。【良い例】この問題は重要です。放置するとユーザーに影響が出ます。パターン2：不要な修飾語を使う【悪い例】非常に重要な機能の実装を丁寧に進めています。【良い例】重要な機能を実装中です。「非常に」「丁寧に」といった修飾語は、情報を追加していない。削除しても意味は変わらない。パターン3：回りくどい表現を使う【悪い例】バグを修正することに成功しました。【良い例】バグを修正しました。「〜することに成功しました」は、「〜しました」で十分だ。冗長さを避けるには、3つの原則がある。原則1：削除できる言葉は削除する原則2：同じ情報は一度だけ書く原則3：具体的な動詞を使う簡潔さは、尊重の表現だ。読み手の時間を尊重し、認知リソースを尊重する。構造を明確にする一文一義で書き、主語を明示し、冗長さを避ける。しかし、それだけでは不十分だ。文章全体の構造を明確にする必要がある。箇条書きと文章の使い分けは、書き手の重要なスキルだ。並列関係の情報は箇条書きで、因果関係の情報は文章で。なぜ構造が重要なのか？構造は、思考の可視化だからだ。構造を明確にする最も基本的な単位は、パラグラフ（段落）だ。一つのパラグラフには、一つの主張しか含めない。構造を明確にするには、3つのレベルがある。レベル1：文のレベルレベル2：パラグラフのレベルレベル3：セクションのレベルこの3つのレベルの構造が明確な文章は、読み手にとって理解しやすい。第1段階の「正確に書く」力を身につけると、少なくとも誤解されない文章が書けるようになる。しかし、それだけでは不十分だ。読み手は、あなたの意図を汲み取ろうとしてくれるとは限らない。次の段階では、より能動的に誤読を防ぐ技術を学ぶ。ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon第1段階の実践訓練訓練1：一文一義の練習訓練2：主語の明示訓練3：冗長さの削除訓練4：構造の可視化訓練5：要約を書くAIを使った第1段階の訓練生成AIは、第1段階の訓練に有効だ。AIに構造をチェックさせるAIの文章を添削する重要な注意点第2段階：誤読されないように書く読解力の第2段階は「書かれていない意図を汲み取る力」だった。文章力の第2段階は、「読み手の誤読を防ぐ力」だ。第1段階では、文章の構造的な問題を防ぐ方法を学んだ。一文一義で書き、主語を明示し、冗長さを避け、構造を明確にする。しかし、構造が正しくても、誤読は起きる。なぜか？読み手と書き手でスキーマが異なるからだ。前のセクションで「知識の呪い」について説明した。ここでは、その呪いを断ち切り、読み手のスキーマに合わせて書く具体的な方法を学ぶ。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon技術ドキュメントの品質は、ここで決まる特に技術ドキュメントにおいては、第2段階が品質を決定づける。第1段階の「正確に書く」は、技術ドキュメントの必要条件だ。構造が曖昧で、主語が不明確で、冗長な技術ドキュメントは、そもそも読むに値しない。しかし、第1段階をクリアしただけでは、良い技術ドキュメントにはならない。技術ドキュメントの良し悪しを分けるのは、読み手が迷わず、誤解せず、必要な情報にたどり着けるかだ。これこそが第2段階の本質だ。構造的には正しいが、読み手のスキーマを無視したドキュメント。専門用語が説明なしに使われ、前提知識が明示されず、文脈が欠如しているドキュメント。こうしたドキュメントは、正確ではあるが、使えない。逆に、読み手のスキーマを想像し、知識の呪いを断ち切り、読み手が必要な情報にたどり着ける文脈を設計したドキュメントは、読み手を迷わせない。読み手は、探している情報をすぐに見つけられる。誤解なく理解できる。そして、次のアクションを取れる。APIリファレンス、設計書、運用手順書、トラブルシューティングガイド。これらの技術ドキュメントは、第3段階の「心を動かす」手法は不要だ。感情に訴える必要はない。しかし、第2段階の「誤読されないように書く」技術は、絶対に必要だ。技術ドキュメントを書くとき、常に自問すべきだ。「読み手は、この情報を探しているとき、どんな状況にいるのか？」「読み手は、どのくらいの前提知識を持っているのか？」「読み手は、この用語を知っているのか？」これらの問いに答えることが、使える技術ドキュメントと使えない技術ドキュメントを分ける。読み手のスキーマを想像するドキュメントを書くとき、まず問うべきは「読み手は誰か？」だ。読み手は誰か？何を知っていて、何を知らないか？どんな問題を解決しようとしているか？知識の呪いを断ち切るには、3つの方法がある。方法1：具体化する方法2：例示する方法3：段階的に説明する読み手のスキーマを想像する能力は、読み手として多様な文章に触れ、「わからない」を経験することで獲得できる。しかし、スキーマを想像するだけでは不十分だ。次に重要なのは、読み手の認知バイアスを考慮することだ。認知バイアスを考慮する読み手がどんなバイアスを持っているかを想定し、誤読を防ぐ。パターン1：二重否定による混乱【誤読されやすい例】この実装方法は悪くない。【誤読されにくい例】この実装方法は、実用上十分な性能を持っています。具体的には、毎秒1000リクエストを処理できます。パターン2：曖昧な数量表現【誤読されやすい例】この問題は重要です。【誤読されにくい例】この問題は、今週中に対応が必要です。なぜなら、放置するとユーザーがログインできなくなるからです。パターン3：主観的な評価【誤読されやすい例】このツールは使いやすい。【誤読されにくい例】このツールは、5分で環境構築できます。コマンド一つで起動でき、GUIで操作できます。認知バイアスを考慮した文章は、客観的で、具体的で、測定可能だ。文脈を設計する技術記事を書くとき、どこまで前提知識を説明すべきか。この判断には原則がある。原則1：読み手のレベルに合わせる原則2：この記事で必要な知識だけを説明する原則3：外部リソースを活用するテンプレートを活用する第2段階における最も実用的な方法の一つが、テンプレートの活用だ。テンプレートは、第1段階の「構造を明確にする」技術と似ているが、その目的は異なる。第1段階では、書き手が構造的に正しい文章を書くためのツールだった。第2段階では、読み手が迷わず、必要な情報にたどり着けるためのツールだ。テンプレートには、3つの利点がある。利点1：読み手の予測可能性を高める利点2：必要な情報を漏れなく提供する利点3：読み手の認知負荷を減らす例えば、バグ報告のテンプレートは次のようになる。## 概要[バグの概要を一行で]## 再現手順1. [手順1]2. [手順2]3. [手順3]## 期待される動作[何が起きるべきか]## 実際の動作[実際に何が起きたか]## 環境- OS: - ブラウザ: - バージョン: ## 追加情報[スクリーンショット、ログなど]このテンプレートを使えば、読み手（バグを修正するエンジニア）は、必要な情報をすぐに見つけられる。「再現手順はどこだ？」「どの環境で起きたんだ？」と探す時間を削減できる。技術ドキュメントのテンプレートは次のようになる。## 概要[この文書が何について説明するか]## 前提条件[読者が知っているべきこと、必要な環境]## 手順[具体的な手順、コード例]## トラブルシューティング[よくある問題と解決法]## 参考資料[関連するドキュメント、リンク]プルリクエストのテンプレートは次のようになる。## 変更内容[何を変更したか]## 変更理由[なぜ変更したか]## 影響範囲[どの機能に影響するか]## テスト[どのようにテストしたか]## レビューのポイント[レビュアーに特に見てほしい箇所]テンプレートを使う際の注意点：テンプレートは、読み手を助ける道具だ。しかし、テンプレートに縛られすぎてはいけない。状況に応じて、テンプレートをカスタマイズする。不要なセクションは削除し、必要なセクションは追加する。重要なのは、「読み手が必要な情報にたどり着けるか」という問いだ。テンプレートは、この問いに答えるための手段であって、目的ではない。第2段階の「誤読されないように書く」力を身につけると、読み手に正確に情報を伝えられるようになる。読み手のスキーマを想像し、認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。しかし、それだけでは不十分だ。情報を伝えるだけでなく、読み手の心を動かす必要がある。なぜなら、心が動かなければ、読み手は行動しないからだ。次の段階では、その方法を学ぶ。第2段階の実践訓練訓練1：説明を書くスキーマを想像しながら書く訓練だ。「この人は何を知っていて、何を知らないか？」を考える。具体的には、次のような取り組みができる。初心者向けに、自分が得意な技術を説明する記事を書く。専門用語を使うたびに、「この用語は説明が必要か？」と自問する。書いた後、その分野に詳しくない人に読んでもらい、わからなかった箇所を聞く。訓練2：批判的に読む訓練3：テンプレートの作成エストなど）のテンプレートを作る。ただし、第1段階の「構造を明確にする」だけでなく、「読み手が必要な情報にたどり着けるか」という視点で作る。読み手が最も知りたい情報は何か？それをどこに配置すれば見つけやすいか？AIを使った第2段階の訓練AIに読み手のスキーマを想像させるAIと対話しながら書く重要な注意点第3段階：心を動かすように書く読解力の第3段階は「本当に重要なことを見抜く力」だった。文章力の第3段階は、「読み手の心を動かす力」だ。なお、この第3段階は、技術記事、ブログ、プレゼンテーションなど、読者の心を動かす必要がある文章に適用される。技術ドキュメント（APIリファレンス、設計書、仕様書など）では、第1段階と第2段階で十分だ。むしろ、客観性と正確性が重視される技術ドキュメントには、この段階の手法は合わない場合が多い。「読みたいこと」とは何か？多くの人が誤解する。「読みたいこと」とは、「自由に好き勝手に自分の気持ちを書くこと」ではない。「読みたいこと」とは、自分が読者だったら読みたいと思うものだ。自分が本屋で金を出して買いたいと思うもの。自分が時間を使って読みたいと思うもの。書きたいことではない。読みたいことだ。これは、他人の視点に立てという話ではない。徹底的に自分の視点で、自分が読者として読みたいかどうかを問うということだ。この問いは、書きたいことを書く自由よりも、はるかに厳しい制約だ。第1段階では構造を学び、第2段階では誤読を防ぐ技術を学んだ。しかし、それだけでは読み手の心は動かない。心を動かすには、まず読者を引きつける必要がある。三行で撃つ 〈善く、生きる〉ための文章塾作者:近藤 康太郎ＣＥメディアハウスAmazon最初の三行で撃つ最初の一文、長くても三行くらいで心を撃たないと、忙しい読者は逃げていく。読者はあなたに興味がない。読者にとって、あなたの書こうとするテーマはどうでもいい。冷厳な現実だ。では、どうすれば最初の三行で読者を撃てるのか？方法1：問題を提示する方法2：驚きを与える方法3：具体的な利益を示すしかし、最も重要なのは、お前が何者かは、読者にとって関係ないということだ。【悪い例】私は10年間、技術記事を書いてきました。その経験から学んだ文章術を共有します。読者は、基本的にあなたの経歴に興味がない。あなたが何年エンジニアをやってきたか、どんな実績があるか、ほとんどの読者にとってどうでもいい。読者が知りたいのは、「この記事は自分の問題を解決してくれるのか？」「面白い時間が過ごせるか？」「読む価値のある新しい視点があるのか？」「具体的で実践できる内容なのか？」「読んだ後、自分は何ができるようになるのか？」。これらの問いだけだ。書き手の自己紹介から始まる記事は、これらの問いに答えていない。だから、読者は離れていく。【良い例】エラーメッセージを読めない人は、エラーメッセージを吐き出させるときも曖昧だ。なぜか？この書き出しは、問題提起だ。読者は「なぜだろう？」と思う。書き出しで読者を引きつけることができた。しかし、心を動かすにはそれだけでは不十分だ。次に必要なのは、空虚な言葉を避けることだ。常套句を避ける書き出しで読者を引きつけても、内容が空虚なら読者は離れていく。そして、内容を空虚にする最大の敵が、常套句だ。常套句は、まさに「わかったつもり」を生み出す装置だ。このアプローチはベストプラクティスです。「ベストプラクティス」とは何か？誰が決めたのか？どういう文脈で最適なのか？なぜ最適なのか？これらの問いに答えない限り、「ベストプラクティス」という言葉は空虚だ。常套句には、いくつかのパターンがある。パターン1：抽象的なバズワードラクティス、レバレッジ、シナジー、エンパワーメント、イノベーション。これらの言葉は、具体的な内容を隠蔽する。パターン2：「としたもんだ表現」パターン3：擬音語・擬態語・流行語常套句を避けることは、思考を深めることだ。「ベストプラクティス」と書こうとして、「本当にベストなのか？」と自問する。この思考の過程が、文章を具体的にし、説得力を高める。常套句を避け、具体的に書くことができたら、次は自分にしか書けない内容を書く。自分の言葉で書く【常套句に逃げる例】Rustの所有権システムは学習が難しい。でも、理解すれば強力だ。これは誰でも書ける文章だ。【自分の言葉で書く例】私がRustの所有権システムを理解するのに、3ヶ月かかった。最初の1ヶ月は、borrowチェッカーのエラーが理解できず、「なぜこのコードが動かないのか」と毎日フラストレーションを感じていた。「cannot borrow `*x` as mutable because it is also borrowed as immutable」このエラーメッセージを見るたびに、「Cのポインタのように自由に使わせてくれよ」と思っていた。転機は、所有権を「責任の所在」として捉え直してからだ。「このデータに対する責任は誰が持つのか」と考えるようになってから、borrowチェッカーのメッセージが「監査人の指摘」として理解できるようになった。この文章は、あなたにしか書けない。あなたの体験、あなたの発見だ。自分の言葉で書くには、3つの要素が必要だ。要素1：具体的な体験要素2：五感で世界を切り取る要素3：思考の過程自分の言葉で書くとは、言い換えることだ。「所有権」という抽象的な概念を、「責任の所在」という具体的な比喩で言い換える。言い換えるとは、考えることだ。しかし、自分の言葉で書くだけでは不十分だ。言葉だけでは、読み手の心は十分には動かない。次に必要なのは、エピソードの力だ。技術ブログの書き方はここに書いているので読んでみてほしいです。syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.com響く文章は説明しない【説明する例】ドキュメントを書くことは重要です。なぜなら、ドキュメントがないとユーザーが困るからです。説明は響かない。【エピソードで語る例】私が初めてオンコール当番を担当したとき、深夜2時にアラートが鳴った。Datadogのダッシュボードには、「CPU usage > 80%」というアラートしか表示されていなかった。「どのサービスのCPUが高いのか」「何が原因なのか」「どうやって対処すればいいのか」何もわからず、私は1時間を無駄にした。結局、先輩を叩き起こして対処してもらった。先輩は5分で原因を特定し、10分で対処した。翌朝、先輩に聞いた。「なぜそんなに早く対処できたんですか？」先輩は言った。「アラートに必要な情報が書いてあったからだよ」そのとき誓った。自分がアラートを作るときは、必ずRunbookへのリンクを含めようと。それから3年、私はこの誓いを守っている。エピソードは響く。具体的な場面、具体的な感情、具体的な決断。これらが、読み手の心を動かす。エピソードで語るには、ストーリーの構造が必要だ。状況 - どんな状況だったか問題 - 何が問題だったか行動 - 何をしたか結果 - どうなったか学び - 何を学んだか自分の言葉で書き、エピソードで語る。しかし、それでも心を動かすには、もう一つ必要なものがある。それは、あなたの生き方そのものだ。書くことは生きること「書くことは生きること」。文章を書くことは、技術ではない。生き方だ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。技術記事を書くとき、私たちは技術を説明しているだけではない。私たちは、技術を通して世界を理解している。「なぜこの技術は存在するのか」「どんな問題を解決するのか」「どんな未来を可能にするのか」。これらの問いに答えることは、技術を理解することであり、同時に世界を理解することだ。そして、これらの問いに答える過程で、私たちは自分自身を理解する。書くことで、私たちは自分になる。わたしにしか、書けないものは、ある。そう信じることから、文章は始まる。第3段階の実践訓練なお、これらの訓練は、技術記事、ブログ、プレゼンテーションを書く人向けだ。技術ドキュメントを書く人は、第1段階と第2段階の訓練に集中してほしい。訓練1：書き出しを3パターン書く訓練2：常套句を見つけて書き直すラクティス」→「なぜベストなのか？どういう条件で？」と問う。技術記事では、抽象的な言葉が説得力を失わせる。訓練3：自分の体験を書く訓練4：説明ではなく、エピソードで語る訓練5：自分の文章を読み直すAIを使った第3段階の訓練AIに書き出しを生成させて、添削するAIに常套句を指摘させるAIに自分の文章を批判させるAIには書けないものを書くおわりに「読解力を分解してちゃんと文章を読む。」を書いたとき、私は気づいた。読む力を説明しようとすることは、書く力を鍛えることでもあると。そして今、「文章力を分解してちゃんと文章を書く。」を書き終えて、改めて実感する。書く力を説明しようとすることは、読む力を鍛えることでもあると。読む力と書く力は、別々のスキルではない。同じスキルの異なる側面だ。この記事の冒頭で、私はこう書いた。「技術記事を読んで『わかった』と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか」。なぜ実装できないのか。答えは明確だ。頭の中で再構築できていないからだ。読むとは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、読む力を高めたいなら、書くことだ。書く力を高めたいなら、読むことだ。この循環が、複利的に機能する。第1段階では、正確に書く技術を学んだ。一文一義、主語の明示、構造の明確化。これは、悪文を書かないための必要条件だ。第2段階では、誤読を防ぐ技術を学んだ。読み手のスキーマを想像し、知識の呪いを断ち切り、文脈を設計する。特に技術ドキュメントでは、この段階が品質を決定づける。第3段階では、心を動かす技術を学んだ。書き出しで引きつけ、常套句を避け、自分の言葉で語り、エピソードで伝える。ただし、これは技術記事やブログに適用される段階であり、技術ドキュメントには不要だ。しかし、文章を書くことの意味は、スキルを高めることだけではない。書くことは、思考を深めることだ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。書くことは、世界を理解することだ。技術を説明しようとするとき、私たちは「なぜこの技術は存在するのか」「どんな問題を解決するのか」を問う。書くことは、自分を理解することだ。言語化できない部分に直面したとき、私たちは「本当は理解していなかった」と気づく。だから、書くことは生きることだ。明日から、何か一つ書いてみよう。Slackのスレッドでもいい。プルリクエストのコメントでもいい。技術記事でもいい。書こうとして手が止まる瞬間、そこに理解の穴がある。その穴を埋めることが、あなたの成長だ。わたしにしか、書けないものは、ある。そう信じて、書き続けることだ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TFLintカスタムプラグインで始める Terraformコード品質管理]]></title>
            <link>https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li</link>
            <guid isPermaLink="false">https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li</guid>
            <pubDate>Tue, 14 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[o Night Talks – After Conference の LT資料ですhttps://mercari.connpass.com/event/367075/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubで管理されているZennのtopicsを集計するコードをclaude codeに作らせた]]></title>
            <link>https://zenn.dev/akasan/articles/1cc5493f3e077a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1cc5493f3e077a</guid>
            <pubDate>Mon, 13 Oct 2025 04:17:00 GMT</pubDate>
            <content:encoded><![CDATA[今回はタイトル通り、GitHubでZennの記事を管理している場合に、どのようなtopicsがよく利用されているか集計するための機能をclaude codeに作らせてみました。私自身連続170記事以上出している関係で、どのような技術をよく利用しているか調べたくなり、作らせてみました。 ZennをGitHubで管理するためのフォルダ構成違いはあるかもしれませんが、基本的には以下のフォルダ構成で管理されていると思います。articles/  hogehoge.md  fugafuga.mdbooks/  ...images/  ...scrapes  ...今回はa...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenAI Agent Builderを使ってGuardrail実装してみた]]></title>
            <link>https://zenn.dev/akasan/articles/c1698aa0289828</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/c1698aa0289828</guid>
            <pubDate>Sun, 12 Oct 2025 04:19:21 GMT</pubDate>
            <content:encoded><![CDATA[今回は、現地時間10月6日にOpenAIが発表したAgent Builderという機能を早速使ってみました。Agent Builderを利用することで、GUIを利用してエージェントを作成することができるようになります。 Agent Builderとは？Agent BuilderはOpenAI DevDay 2025にて発表された新しいプロダクトとなっています。Agent Builderを利用すると、ドラッグアンドドロップでロジックを構成し、ツールを接続やカスタムガードレールを構成するためのキャンバスを利用できます。また、プレビューの実行、インラインのeval設定、完全なバージョニン...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[読解力を分解してちゃんと文章を読む。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/12/081300</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/12/081300</guid>
            <pubDate>Sat, 11 Oct 2025 23:13:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに自分の読解力に絶望する瞬間というものがあります。たとえば、エラーログを読んでいるとき。無意識のうちに「こういうエラーだろう」という仮説を立てて、その証拠を探すように読んでしまっていました。問題を解決した後で同じログを読み返すと、「なんでこんな読み方をしたんだ？」と首をかしげます。明らかに違うことが書いてあるのに、自分の仮説に都合のよい部分だけを拾い読みしていました。エラーログという機械が出力するシンプルな文章ですら、こうなのです。もっと複雑なドキュメントなら、どれほど読み間違えていることでしょうか？ライブラリのドキュメント、APIリファレンス、技術記事、PRのコメント、issueの議論、Slackでのやり取り。すべて同じ問題を抱えている可能性があります。これは挑発でも誇張でもありません。「文章が読める人」は想像以上に希少で、自分も含めて、多くの人は書いてあることを読んでいません。自分の主張や仮説、感情があって、それに合うように拾い読みしているだけなのです。なぜこんなことが起きるのでしょうか？それは人は文章を読む前から、すでに何らかの主張や仮説、感情を持っているからです。そして無意識のうちに、それを正当化できる「都合のよいワード」だけを探している。文章全体の文脈や意図を理解するのではなく、自分の主張や仮説にマッチする断片だけに反応する。これは読解ではありません。結論ありきの確認作業です。虐殺器官 (ハヤカワ文庫JA)作者:伊藤 計劃早川書房Amazon今の時代、わからないことがあれば、ChatGPTやClaudeに聞けばいい。生成AIは、いつでも、何度でも答えてくれます。これは本当に素晴らしいです。でも——生成AIがあれば読解力は不要になるのでしょうか？違います。逆だと思っています。生成AIによって読解力は底上げされます。ただし、それは生成AIをどう使うかにかかっています。生成AIを正しく使えば、読解力を飛躍的に高められます。でも、間違った使い方をすれば、読解力は逆に衰えます。この記事では、「読む」という行為を分解し、それぞれの壁をどう超えるか、そして生成AIをどう活用すべきかを語っていきます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。読解力は分解可能なスキル群ですスキルというのは、単一の能力で成り立っているわけではないことが多いです。だいたいは複数の能力の集合体です。コーディングがうまくなりたい？それなら取り組むべきことは山ほどあります。言語仕様を深く理解する、デザインパターンを学ぶ、Effective 〇〇のようなベストプラクティスを身につける、テストの書き方を学ぶ、デバッグの技術を磨く。さらに、メモリ管理を理解する、並行処理を扱えるようになる、セキュリティや運用を考慮できるようになります。でも、技術的なスキルだけじゃないです。コミュニケーション能力を高める、他人のコードを読む力をつける、レビューでフィードバックをする、技術的な議論ができるようになる。業界知識を身につける、ドメイン知識を深める、チーム開発の進め方を学ぶ。コーディングというスキルは、技術、人間関係、知識という軸からなる、いくつものスキルの集合体なんだと思います。漠然と「コーディングが上手くなりたい」と思っているだけでは、何をすればいいかわかりません。でも分解して「Rustの所有権システムを深く理解する」と具体化すれば、The Rust Programming Languageを読む、borrowチェッカーのエラーと向き合う、といった具体的な練習メニューが見えてきます。「デザインパターンを学ぶ」と具体化すれば、GoFのパターンを実装してみる、OSSのコードでパターンを探す、といった具体的な行動が見えてきます。読解力も同じです。書いてあることを正確に読むには、実はいろんなスキルが要ります。語彙力、文法理解力、主語・述語の把握、修飾関係の理解、論理構造の把握、情報の正確な抽出。こういった「書いてあることを正しく読む」基礎的なスキル。さらに、文脈の理解、推測力、共感力、批判的思考、バイアスへの気づき、メタ認知。こうした「行間を読む」応用的なスキル。そして、抽象化能力、本質を見抜く力、問いを立てる力、情報の優先順位づけ。「何が本当に重要なのか」を見極める統合的なスキル。読解力もまた、複数のスキルの集合体です。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon上達とは分解して考えることどんな能力でも、「取り組めるまで分解して考えること」が重要です。漠然と上手になりたいでは、いつまで経っても上達しません（天才を除く）。分解しないとどうなるでしょうか？「ドキュメントをちゃんと読めるようになりたい」では漠然としすぎて何をすればいいかわかりません。練習のしようがないです。でも「仮説を立てる前に、書かれている情報を網羅的に抽出する」と分解すれば、明日から実践できる具体的な読み方が見えてきます。エラーログを開いたとき、まず全行を読んでからメモ帳に情報を列挙する、という具体的な行動に落とし込めます。壮大に見えた挑戦も、分解してみれば、シンプルなタスクの積み重ねでしかありません。コーディングも、読解も、他のどんなスキルも同じです。頭の良さが成功の命運を分けるほど高尚な仕事はありません。必要なのは、分解する視点と、一つずつ取り組む地道さです。この原則は、コーディングでもドキュメントの読解でも、あらゆるスキルに共通しています。そして、生成AI時代においても、この原則は変わりません。むしろ、生成AIがあるからこそ、読解力を分解して鍛えることが、より重要になります。分解できていなければ、生成AIに「何を」「どう」聞けばいいのかもわからないのですから。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon読解力には3つの段階があります読解力には、大きく3つの段階があります。この記事では、その3つの段階を一つずつ分解して説明していきます。ただし、これは一方通行の階段じゃありません。私たちはこれらの段階を行ったり来たりします。第3段階まで到達した人でも、疲れているときや慣れない分野の文章を読むときは、第1段階に戻ります。そう、読解力とは一定じゃありません。「能力」という言葉には「力」という漢字が含まれています。そのせいか、まるで機械のスペックのように「私の読解力は○○レベル」と固定値で捉えてしまいがちです。筋力のように、一定の出力を常に出せるものだと思ってしまいます(筋力も…というツッコミもあります)。しかし実際はそうではありません。能力はその瞬間の状態に大きく左右される可変的なものです。読解力は文脈によって大きく変わります。自分の専門分野のドキュメントなら第3段階まで読めるのに、まったく知らない分野の文章なら第1段階で苦戦します。朝の集中できる時間なら深く読めるのに、疲れた夜には表面的にしか読めません。特に感情状態の影響は大きいです。怒りや悲しみを抱えたまま技術記事を読んでも、書かれている内容が頭に入ってきません。これは単に集中力が切れるという話ではありません。感情が認知のリソースを占有してしまうからです。仮に100のキャパシティがあっても、感情に30使われていたら、読解に使えるのは70だけになります。こうした揺らぎは、誰にでもどんな能力にもあります。この理解は、自己評価にも影響します。ある日うまく読めなかったからといって「自分には読解力がない」と結論づけるのは早計です。単にその瞬間の条件が悪かっただけかもしれません。だからこそ、筋力を鍛えるように、読解力も鍛える価値があります。鍛えるとは、能力の底上げと安定化を意味します。鍛えておけば、疲れているときでも、新しい分野でも、感情が揺れているときでも、ある程度は正確に読めるようになります。新装版 アブダクション　仮説と発見の論理作者:米盛裕二勁草書房Amazon第1段階：正確に読むこれは読解の土台です。書かれていることを正確に理解する力です。エラーログで考えてみましょう。第1段階では、どのコンポーネントが、どんな状態で、どんなエラーを出したのかを正確に読み取ります。エラーメッセージの構造を理解し、どこで何が起きたかを正確に把握します。技術記事なら、著者が説明している手順や概念を、一つ一つ正確に理解することです。「この関数は非同期です」という記述があったとき、それが何を意味するのか（Promiseを返すのか、コールバックを受け取るのか、await可能なのか）を正確に読み取ります。Rustのコンパイラエラーも良い例です。borrowチェッカーのエラーが出たとき、「所有権の問題だ」とざっくり理解するんじゃなくて、どの変数が、どのスコープで、どのように使われようとして、なぜそれが許可されないのか、を正確に読み取ります。これはプログラミングにおける「構文を理解する」に相当します。変数、関数、制御構文といった基本がわからなければ、その先のロジックを理解することはできません。読解も同じです。まず書かれていることを正確に読む。この段階なしに、次の段階には進めません。シン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon第1段階の壁：基礎訓練の不足多くの人はこの第1段階で躓いています。基礎訓練が不足しているんです。例えば、次の2つの記述の違いが分かるでしょうか？「システムは、2025年1月、レガシーAPIを廃止し、クライアントには新APIへの移行を推奨した」と、「2025年1月、レガシーAPIは廃止され、システムはクライアントから新APIへの移行を推奨された」。答えは「異なる」です。前者ではクライアントが移行を推奨されているのに対し、後者ではシステムがクライアントから推奨されている（主従関係が逆）です。もっと身近な例で見てみましょう。技術記事に「このメソッドは非同期です」と書かれています。多くの開発者は「わかった」と思って先に進みます。でも実際には、「非同期である」という情報だけでは不十分です。Promiseを返すのか、コールバックを受け取るのか、await可能なのか、エラーハンドリングはどうするのか。これらの情報も読み取らなければ、正確な理解とは言えません。コーディングに例えるなら、コードはたくさん書くが、変数のスコープを理解せず、型システムの理解もせず、言語仕様の訓練もしない。基礎がないから複雑なシステムを作れない、という状況です。文章の読解も同じ。たくさん読むが、文構造の理解訓練はせず、論理的思考の訓練もしない。基礎がないから正確に読めません。この壁を超えるには基本的な訓練が重要です。主語・述語を意識する。ドキュメントやエラーメッセージで、「誰が」「誰に」「何を」しているのか。これを正確に把握する癖をつけます。仮説を立てる前に全部読む。私はこれでエラーログの読み間違いが激減しました。全行読んで、情報を列挙してから、それから仮説を立てる。順番を変えるだけで、見える景色が変わります。文脈を意識する。これはリファレンスなのか、チュートリアルなのか、トラブルシューティングなのか。文章の「置かれた場所」で、読み方も変わるべきなんです。音読してみる。本質的な訓練ではないが、驚くほど効果的です。声に出すと、飛ばし読みができなくなる。一文字ずつ確実に読むことを強制される。視覚だけでなく聴覚も使うので、「読んだつもり」が減る。特に、複雑なエラーメッセージや理解しにくいドキュメントを読むときは、小声でもいいから音読してみるといいです。読むスピードが落ちる分、思考する時間が生まれる。主語と述語の関係も掴みやすくなります。生成AIは、この基礎訓練を補助してくれます。わからない専門用語が出てきたとき、集中力を途切れさせずに「『非同期処理』とは何ですか？」と聞ける。複雑な文章の主語・述語の関係がわからなくなったとき、「この文章の構造を分解してください」と聞ける。技術記事を読んで「わかった」と思ったとき、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と確認できます。ただし、まず自分で読むことが前提です。最初の一文を読んですぐ「要約して」と頼むのでは、読解力は鍛えられません。生成AIに分解してもらった後、必ず自分でもう一度読み直します。生成AIの説明も間違えることがあるので、公式ドキュメントでも確認します。生成AIはあくまで訓練の補助です。第2段階：裏を読む第1段階で書かれていることを正確に読めるようになったら、次は書かれていない意図を汲み取る力が必要になります。エラーログで考えてみましょう。第2段階では、エラーの背後にある状況を推測します。タイムアウトエラーがあったとき、単に「タイムアウトした」という事実だけじゃなく、「なぜタイムアウトしたのか」を考える。ネットワークが遅いのか、サーバーが応答していないのか、ファイアウォールで遮断されているのか。技術記事を読むときも同じ。「この実装方法を推奨します」という記述があったとき、なぜ著者はそれを推奨するのか、どんな状況を想定しているのか、逆にどんな状況では推奨しないのか、を推測します。PRのコメントで「ここ、もっと良い方法があるかも」と書かれていたとき、それは単なる提案なのか、変更を強く求めているのか、それとも議論を始めたいのか。書かれている言葉だけでなく、その裏にある意図を読み取る力です。Rustのドキュメントを読むとき、「この関数はunsafeです」という記述の裏には、「注意深く使わないとメモリ安全性が損なわれる」という警告がある。「このトレイトはSendです」という記述の裏には、「スレッド間で安全に送信できる」という保証があります。これはプログラミングにおける「ロジックを理解する」に相当します。構文を理解した上で、なぜこのデザインパターンを使うのか、なぜこのデータ構造を選ぶのか、といった背景や意図を理解する段階です。読解力は最強の知性である　１％の本質を一瞬でつかむ技術作者:山口 拓朗SBクリエイティブAmazon第2段階の壁：認知バイアスこの第2段階では大きな壁にぶつかります。それが認知バイアスです。エラーログを読むとき、私は無意識に確証バイアスの罠にはまっていました。確証バイアスとは、自分の信念を裏付ける情報を探し求め、それ以外を見ない・軽視する心理学の概念。既存の仮説として「これはメモリの問題だ」と思っていると、フィルターが発動し、メモリに関する情報だけを拾うようになる。結果として、ネットワークに関する情報を見落としてしまいます。GitHubのissueでも同じことが起きています。「この機能の実装、19時までに終わらせるのは無理だった。他のタスクもあるし、月1回くらいしかこのペースで進められない」というコメントを読んで、「マネジメントに文句を言っている」と受け取る人がいます。でも、よく読んでほしいです。このコメントには「マネジメントが悪い」とは一言も書かれていない。書かれているのは、ただ「間に合わなくて申し訳ない」という弱音だけです。なぜこのような誤読が起きるのか？「この人は以前も遅れていた」「いつも文句を言っている」という既存の印象があると、フィルターが発動し、「マネジメントを批判している」と読み取ってしまいます。でも実際に書かれていることは、「間に合わなくて申し訳ない」という弱音だけです。ここで重要なのは、私たちの直観は想像以上に信頼できないということです。「直観に従えば大丈夫」——もしこれが本当なら、文章の誤読はほとんど起きないはずです。エラーログを読めば直観的に原因がわかる。ドキュメントを読めば直観的に使い方がわかる。コメントを読めば直観的に意図がわかる。でも現実はどうでしょうか？私たちは、人生で何千、何万もの文章を読んできました。それでも、誤読は頻繁に起きます。「ちゃんと文章を読める」と自認している人でも、エラーログを読み間違え、ドキュメントを誤解し、コメントを誤読しています。つまり、直観的な判断は、それなりの確率で裏切ります。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonなぜか？直観は過去の経験とパターン認識に基づいているからです。「このエラーは以前見たことがある」「この書き方は○○を意味する」——そう直観的に思った瞬間、私たちは確証バイアスのフィルターをかけてしまいます。直観に従うほど、書かれていることではなく、「自分が予想したこと」を読むようになります。だからこそ、意識的な読み方が必要なんです。直観を完全に排除することはできません。でも、「直観は間違うかもしれない」と自覚するだけで、読み方は変わります。「直観的にこう思う。でも、本当にそう書いてあるか？」と自問する癖をつける。これだけで、誤読は激減します。私たちは、自分が信じたいものを信じるようにできています。ちなみに、SNSでは誤読が頻繁に起こります。でも、発信する側の心持ちとして、SNSでは誤読されるのも投稿する内だと思っていたほうが精神衛生上良いんです。SNSという媒体は本質的に誤読を生みやすいからです。文脈が省略され、文字数に制限があり、読者の背景や感情状態も様々です。「炎上」の多くは、この誤読から生まれる。できるのは、自分自身が読む側に回ったとき、「書かれていないこと」を読み取っていないか、常に自問することだけです。この壁を超えるには基本的な訓練が重要です。「書かれていないこと」を排除する。一文字ずつ丁寧に読み、「これは本当に書いてあるか？」と確認し、「自分が勝手に補完していないか？」と自問する。特に、怒りの感情を覚えたときは要注意だ。複数の解釈を考える。1つの文章に対して、少なくとも3つの異なる解釈を仮定してみる。先ほどの「19時までに終わらせるのは無理だった」なら、①単純に弱音を吐いている、②マネジメントを批判している、③このプロジェクトから離れたいと思っている、という3つの解釈が考えられる。書かれていることだけからは①が最もストレートだけど、「確定」はできません。バイアスのメタ認知。文章を読んで強い感情（怒りや共感）を覚えたら、ちゃんと読み直し、「自分のバイアスではないか？」と自問し、複数の解釈可能性を列挙する。生成AIは、別の視点を提供してくれる。「この文章の別の解釈の可能性を3つ教えてください」と聞けば、あなたが思いつかなかった解釈を示してくれることがある。「このコメントには、『マネジメントを批判している』という意図が書かれていますか？」と聞けば、書かれていることと書かれていないことを区別してくれる。ただし、生成AI自体もバイアスを持っている。生成AIも訓練データに基づいたバイアスを持っているし、あなたの質問の仕方が回答を誘導してしまうこともある。だから、中立的な質問をする。「この文章のトーンを分析してください」といった、オープンな質問をする。そして、まず自分で複数の解釈を考えてから、生成AIで確認します。この順番が大切です。第3段階：本質を読む第1段階で正確に読み、第2段階で裏を読めるようになったら、最後は本当に重要なことは何かを見抜く力が必要になります。エラーログで考えてみましょう。第3段階では、大量のログの中から本当に重要な情報を抽出する。100行のログがあったとき、その中で本当に問題の原因を示しているのはどの部分なのか。表面的には複数の問題が見えても、本質的には1つの根本原因から派生しているかもしれません。技術記事を読むとき、第3段階では表面的な実装方法ではなく、その根底にある設計思想や原則を理解する。「このコードはこう書く」という表層だけでなく、「なぜそう書くのか」「そもそも何を解決しようとしているのか」を見抜きます。Rustのドキュメントを読むとき、個々のAPIの使い方だけでなく、所有権システムという言語の根幹にある哲学を理解する力だ。これはプログラミングにおける「設計を理解する」に相当します。構文とロジックを理解した上で、なぜこのアーキテクチャを採用したのか、トレードオフは何か、本質的な問題は何か、を理解する段階です。ただし、新しい言語を学ぶときは構文から学び直す必要があるように、新しい分野の文章を読むときは第1段階から学び直す必要があります。これは退行ではなく、自然なことなんです。わかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon第3段階の壁：わかったつもり第3段階に到達しても、まだ最後の壁がある。これが一番厄介です。それが「わかったつもり」。「もう理解すべきことは何もない」って思った瞬間、人は思考停止します。新しい視点を受け入れなくなります。成長が、止まります。エラーログを開いて「あ、これはあのエラーだ」と思った瞬間、思考が停止します。そして仮説に合う部分だけ読んで、結果として問題を解決できません。実際には50%程度しか理解していないのに、「わかった」と思い込んでいます。エラーログを見て「ああ、これは接続エラーだ」と思った瞬間、「接続設定を確認すればいい」と結論づけてしまいます。でも実際には、設定以外にも、ファイアウォール、タイムアウト、認証、リトライロジックなど、他にも確認すべきことがあるかもしれない。「わかった」と思った瞬間に、これらの可能性を検討しなくなります。技術記事を読むときも同じ。「この技術は理解した」と思った瞬間、制約条件や例外的な状況を見落とす。「この設計パターンはわかった」と思った瞬間、適用すべきでない場面に気づかなくなります。この「わかったつもり」は、第1段階から第3段階まで、すべての段階で起こりうります。だからこそ、これが最大の壁なんです。読解力が高い人ほど、自分が「わかったつもり」になっていないかを常に点検しています。この壁を超えるには基本的な訓練が重要です。「なぜ」「そもそも」と問う。なぜこのエラーが出たのか？そもそも何が問題なのか？本当に重要なのはどこか？問いとは、答えをただ探すためのものではなく、物事の本質に近づこうとする"姿勢"そのものです。要約訓練。情報を要約する際は、「本当に重要なのは何か？」と自問する癖をつける。これは、99%の情報から1%の本質を抽出する訓練です。でも、「これが本質だ」と決めつけてはいけません。それが「わかったつもり」の罠だからです。情報の精査。情報に触れたら、「それは個人的意見なのか、客観的事実なのか？」と自問する。事実なのか意見なのか、データに基づいているのか印象なのか。この区別が、本質を見抜く力につながります。生成AIは、理解を検証してくれます。「私はこの技術の本質を『○○』だと理解しました。この理解は正しいですか？他にもっと重要な本質はありますか？」と聞ける。「なぜこの技術が必要なのですか？」と聞き、返ってきた答えに対して「なぜそれが問題なのですか？」とさらに聞ける。5回「なぜ」を繰り返す「5 Whys」を実践できます。長大なドキュメントを読んだ後、「このドキュメントの本質を、3つの文で要約してください」と聞けます。ただし、生成AIが示した「本質」も、一つの視点に過ぎません。生成AIは、訓練データに基づいて、「多くの人が本質だと考えていること」を答えます。でも、それが本当の本質かどうかは、わかりません。だから、生成AIの答えを「仮説」として扱う。「本当にそうか？」と疑う。他の情報源でも確認します。実際に使ってみて検証します。そして、まず自分で「なぜ」を考える。自分の考えを生成AIで確認します。この順番が大切です。すべて生成AIに聞いてしまうと、自分で考える力が衰えます。なぜ読解力を鍛えるべきなのかここまで読んで、「めんどくさそうだな」って思いました？正直、わかる。3つの段階、それぞれの壁、訓練方法、生成AIの使い方。別に分けんでもいいやろって思いました？しかも読解力って一定じゃなくて、落ちるらしいし、新しい分野だとまた1からやり直し。でも——これだけは言わせてほしい。生成AI時代だからこそ、読解力を鍛える価値は計り知れないです。「最近の人は長文が読めない」——よく聞く話ですが、これを単なる集中力不足だと片付けてはいけません。SNS、ショート動画、通知、いいね。私たちの脳は短期的な快楽にチューニングされ続けています。このサイクルを何年も繰り返すうちに、長文を読むことが単に「つまらない」だけでなく、苦痛に変わります。文脈を保持しながら論理を組み立てる——この一連のプロセスが、脳にとって「報酬が遠すぎる」活動になってしまうんです。スマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonさらに深刻なのは、読解力の回路そのものが機能低下することです。文脈を保持する力が衰えると、文章を断片的にしか理解できなくなります。そして、自分の考えを整理する力も、読解力に依存しています。「なぜこのバグが起きたのか」を説明できない。「なぜこの設計を選んだのか」を答えられない。これは語彙不足ではなく、自分の内側で起きていることを掴めず、整理できていない状態です。感じているのに言語化できない。伝えたいのに届かない。誤解されて、孤立感が強まります。説明できる力は、安心感や人とのつながりの土台です。「自分だけは分かっている」という拠り所があるなら、人はまだ耐えられます。でも、自分の感じや考えを誰も拾ってくれないどころか、自分自身も拾えないとなると、存在の手応えや安心感が一気に揺らぎます。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon読解力は他のすべてのスキルを支える土台である読解力は、エンジニアとしてのキャリアの「土台」のようなものだ。基礎体力に近いかもしれません。コーディングで考えてみましょう。変数、関数、制御構文といった基礎がなければ、どんな技術も身につかない。Rustの所有権システムを学ぼうとしても、デザインパターンを理解しようとしても、並行処理を扱おうとしても、基礎がないと何も始まらない。読解力も同じ。読解力がなければ、どんなドキュメントも正確に理解できず、どんな技術も効率的に学べず、どんなコミュニケーションもうまくいきません。Rustを学びたいとする。でも、Rustのドキュメントを正確に読めなければ、所有権システムを理解できない。borrowチェッカーのエラーメッセージを正確に読めなければ、問題を解決できません。unsafeの意味を深く理解できなければ、適切に使えません。生成AIに「Rustの所有権システムを教えて」と聞けば、説明は返ってくる。でも、その説明を理解するのも、読解力だ。生成AIの説明が正しいかどうかを判断するのも、読解力だ。読解力が貧弱だと、コードを書く、設計する、レビューする、ドキュメントを書く、チームとコミュニケーションする、問題を解決する、新しい技術を学ぶ、生成AIを使いこなす、といった、エンジニアとしてのあらゆる活動で誤作動が生じます。逆に、読解力という土台があれば、すべてがスムーズに機能するようになります。生成AI時代においても、読解力はすべての土台なんです。読解力の差は、時間とともに指数関数的に広がる「読解力があるか、ないか」は、1回だけ見れば小さな差だ。でも、時間とともに指数関数的に広がっていきます。ドキュメントを正確に読める人と読めない人の差は、1回では小さいです。「たった1回の誤解」。でも、1年間ではどうでしょうか？ドキュメントを読めない人は、週に3回、APIの使い方を誤解します。年間で150回。そのたびに、実装をやり直す必要があります。週に3時間、年間で150時間を無駄にする。実装ミスのせいでバグが増える。デバッグに時間がかかる。納期が遅れる。レビュアーに迷惑をかけます。チームからの信頼を失う。新しい技術を学ぶスピードが遅くなる。結果として、キャリアが停滞します。生成AIを使っても、この差は変わりません。むしろ、生成AIがあるからこそ、読解力の差は広がる可能性があります。読解力がある人は、生成AIを補助ツールとして使って理解を深め、さらに読解力が高まる。読解力がない人は、生成AIに全面的に依存し、自分で考えなくなり、さらに読解力が低下します。1回の差は小さいです。でも、積み重なると大差になります。読解力が高い人は、読むことで新しい知識を得て、さらに読解力が高まる。読解力が低い人は、読むことで誤解を重ね、さらに読解力が低下する。時間とともに、差は指数関数的に広がっていきます。そして、自分の読解力が揺らぐことを自覚していれば、「今日は疲れているから、このドキュメントは明日読もう」という判断ができる。「怒りを感じているから、一旦落ち着いてから読み直そう」という戦略が立てられる。「この分野は初めてだから、第1段階から丁寧に読もう」という心構えができる。「疲れているから、生成AIに確認してもらおう」という判断ができます。読解力を鍛えることは、読解力そのものを高めることだけじゃありません。自分の読解力の限界を知り、それに応じた戦略を立てることでもあります。そして、生成AIをいつ、どう使うべきかを判断する力でもあります。読解はコミュニケーション「何回説明しても伝わらない」——こんな経験、誰にでもあるでしょう。上司から同じことを何度も指摘される。部下に説明したのに、まったく違うものができあがる。技術記事を読んだのに、実装したら全然違う結果になりました。多くの人は、これを「伝え方」の問題だと考える。でも、認知科学の研究が示すのは、違う真実です。問題は「言い方」じゃありません。「心の読み方」なんです。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonスキーマという名の「当たり前」認知科学には「スキーマ」という概念がある。これは、人それぞれが頭の中に持っている「当たり前」の枠組みのこと。知識や経験の構造化されたまとまりです。重要なのは、私たちは物事を「スキーマを通して」理解しているという点です。エラーログも、スキーマを通して読んでいる。ドキュメントも、スキーマを通して読んでいる。上司の指示も、スキーマを通して聞いている。生成AIの回答も、スキーマを通して読んでいます。「何回説明しても伝わらない」のは、説明する側と受け取る側で、スキーマが違うからです。上司が「この機能を実装してほしい」と言ったとします。上司の頭の中には、長年の経験から作られた「この機能」のスキーマがあります。でも、そのスキーマの大部分は、言葉にされていません。一方、受け取る側も、自分のスキーマを通してその指示を理解します。でも、それは上司のスキーマとは違うかもしれません。結果として、上司は「言ったはずだ」と思い、あなたは「聞いた通りにやった」と思う。でも、出来上がったものは違います。Rustのドキュメントを読むときも同じです。ドキュメントを書いた人には、Rustの所有権システムについての豊富なスキーマがあります。だから、「この関数はborrowします」という一文で、多くのことが伝わると思っています。でも、Rustを学び始めたばかりの人には、そのスキーマがありません。そして、生成AIの回答も、あなたのスキーマに依存しています。生成AIに「Rustの所有権システムを説明して」と聞いたとします。その説明を理解するのは、あなたのスキーマです。C++のスキーマを持っている人と、Pythonのスキーマしか持っていない人では、同じ説明を読んでも、理解する内容が違います。だから、生成AIに質問するとき、自分の前提知識（スキーマ）を明示することが有効なんです。「私はPythonしか知りません。Rustの所有権システムを、Pythonとの違いを中心に説明してください」と聞きます。人生の大問題と正しく向き合うための認知心理学 (日経プレミアシリーズ)作者:今井むつみ日経BPAmazon受け手としてどうすべきかじゃあ、受け手として、私たちはどうすればいいのか？まず、自分が持っているスキーマを自覚すること。「自分はこういう前提で理解している」と認識する。エラーログを読むとき、「これはメモリの問題だ」というスキーマで読んでいないか？生成AIの回答を読むとき、「自分の知っている範囲で」理解しようとしていないか？自分のスキーマを自覚するだけで、誤読は減ります。次に、「わかった」を疑うこと。説明を聞いて「わかった」と思った瞬間、実は自分のスキーマで解釈しているだけかもしれません。だから、理解したことを言い換えて確認します。「つまり、○○ということですか？」と聞く。生成AIを使うなら、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と聞きます。そして、質問する勇気を持つこと。「わからない」と言うのは、勇気がいります。でも、わからないまま進むよりは、はるかにマシです。質問することは、恥ずかしいことじゃありません。自分のスキーマと相手のスキーマのズレに気づいて、それを埋めようとしている証拠です。最後に、柔軟にスキーマを更新することです。新しい技術を学ぶとき、既存のスキーマで理解しようとしがちです。でも、それが足枷になることがある。Rustを学ぶとき、C++のスキーマで理解しようとすると、所有権システムの本質を掴めません。コミュニケーションは双方向です。説明する側も、受け手のスキーマを想像する努力が必要だし、「伝わったかどうかを確認する」必要があります。受け手も、自分のスキーマを自覚し、「わかった」を疑い、質問する勇気を持ちます。この両方が揃って初めて、「伝わる」コミュニケーションが成立します。読解力とは、ただ文字を読む力じゃありません。自分のスキーマを自覚し、それを柔軟に更新しながら、相手の意図を理解しようとする力なんです。そして、生成AIを適切に使って、スキーマのズレを埋める力でもあります。情報を正しく選択するための認知バイアス事典作者:情報文化研究所フォレスト出版Amazon完璧を目指さない。でも「わかったつもり」にもならない「読解力を磨くこと」と「わかったつもりにならないこと」の間のバランスを見つけることが、本当の知性なんです。一方で、積極的に理解しようとする。努力して読解力を高める。3つの段階を一つずつ鍛える。基礎訓練の不足を補う。認知バイアスに気づく。「わかったつもり」を警戒する。生成AIを適切に使う。他方で、完璧を目指さない。常に完璧に読める人はいない。疲れているときもある。新しい分野もある。バイアスに引っかかるときもある。「わかったつもり」になってしまうときもある。生成AIの使い方を間違えるときもある。それは人間である以上、避けられません。重要なのは、失敗から学ぶことです。エラーログを読み間違えたなら、「なぜ読み間違えたのか？」と振り返る。確証バイアスに引っかかっていたのか、情報を網羅的に抽出していなかったのか、「わかったつもり」になっていたのか。生成AIに頼りすぎて、自分で考えなかったのか。次は同じ間違いをしないように、読み方を改善します。完璧を目指さない。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。そして、常に「まだ理解できていないかも」という謙虚さを持つ。問いを持ち続ける姿勢を保ちます。優れたエンジニアは、何年コードを書いても、「完璧に理解した」とは思わない。新しい技術を学び続け、既存の知識を疑い続け、より良い方法を探し続ける。失敗から学び続ける。生成AIも適切に活用する。だから成長し続けられます。読解力も同じ。どんなに上達しても、「完璧に読めている」とは思わない。失敗から学び続ける。生成AIも適切に使い続ける。だから成長し続けられます。危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazonおわりにエラーログを読み間違え、ドキュメントを誤解し、コメントを誤読する。「書いてあることを読んでいない」という絶望——この記事は、そんな問題からスタートしました。そして、「読む」という行為を分解してみました。読解力は複数のスキルの集合体でした。3つの段階があり、それぞれに壁がありました。第1段階の壁は「基礎訓練の不足」、第2段階の壁は「認知バイアス」、そしてすべての段階に共通する最大の壁が「わかったつもり」。生成AIは、これらの壁を超える補助ツールになる。でも、使い方次第です。まず自分で読む、鵜呑みにしない、依存しすぎない。この原則を守らなければ、読解力は逆に衰えます。読解力は他のすべてのスキルを支える土台であり、その差は時間とともに指数関数的に広がる。コミュニケーションはスキーマを通して行われるため、自分の「当たり前」を自覚し、「わかった」を疑い、柔軟にスキーマを更新することが大切です。完璧である必要はありません。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonまずは一つだけ、明日から実践してみてほしい。明日エラーログを読むとき、こう自問してみる。「仮説を立てる前に、全行を読んだか？」（第1段階）「自分のバイアスで読んでいないか？」（第2段階）「本当に重要なのはどこか？」（第3段階）「自分のスキーマで解釈していないか？」（スキーマの自覚）明日生成AIに質問するとき、こう実践してみる。「まず自分で読んでから、わからないところだけ聞く」（第1段階）「複数の解釈の可能性を聞く」（第2段階）「理解を言語化して確認してもらう」（第3段階）「前提知識を明示して質問する」（スキーマの明示）それだけで、あなたの読解力は確実に一歩前進します。ところで、ここまで「読む」という行為を分解してきました。でも実は、もう一つの行為があります。「書く」という行為です。読解力の3つの段階——正確に読む、裏を読む、本質を読む——を理解した今、書き手としての視点も変わるはずです。「読めない読み手」を嘆く前に、書き手は自問すべきです。読み手が正確に読める文章を書いているか？誤読されにくい書き方をしているか？本質を掴みやすい構造にしているか？そして何より、読み手の読解力は一定ではないことを理解しているでしょうか？疲れているとき、慣れない分野を読むとき、感情が高ぶっているとき——読み手は第1段階でさえ苦戦します。さらに、スキーマの違いを忘れてはいけません。書き手にとって「当たり前」のことが、読み手にとっては「初めて聞く」ことかもしれません。よく言われる文章作法——「結論を先に書く」「一文を短くする」——これらを抽象化すると、すべて読み手の認知リソースを尊重するという原則に行き着きます。読み手は無限の時間と集中力を持っているわけじゃありません。その限られたリソースを、いかに有効に使ってもらうか。読解力と同じように、文章力も分解可能なスキル群です。読解力を分解して鍛えられるように、文章力も分解して鍛えられます。読解力を理解することは、文章力を理解することでもありますので書きました。syu-m-5151.hatenablog.com生成AIがあれば読解力は不要になるのか？——記事の冒頭で問いかけました。答えは明確です。生成AIがあるからといって、読解力が不要になるわけじゃありません。むしろ、生成AIを使いこなすために、読解力がますます重要になる。そして同じことが、文章力にも言えます。「わかったつもり」という最大の壁を、常に警戒してほしい。「もうわかった」と思った瞬間が、最も危険な瞬間なのですから。それでは。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Modern Monolithを作りましょう！ Inertia.jsの紹介とその先]]></title>
            <link>https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian</link>
            <guid isPermaLink="false">https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian</guid>
            <pubDate>Sat, 11 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[マイクロサービス流行の時代で、あえてモノリスを作りませんか？バックエンドとフロントエンドの連携を行う際は、辛い思いをした方が多いのではないでしょうか。APIの作成、認証の実装、フォーム送信など、様々なハードルがあります。そういった問題を解決して、フルスタック開発を楽にするライブラリさえあれば...実際にありますよ！このLTでは、SPAのフロントエンドをバックエンド内で作れるInertia.jsをご紹介します。基本的な使い方から、直近の新機能やInertia.jsの将来を解説します。このLTを通じて、「フルスタック開発が楽になった！」「フロントエンドのためのAPI設計はもうさらばだ！」と思ってもらえればと思います。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoのGuardrail機能を試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/48cea67449be64</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/48cea67449be64</guid>
            <pubDate>Sat, 11 Oct 2025 03:09:11 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[楽にあなたのクラウドを守ろう！ - CNAPP概要]]></title>
            <link>https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp</guid>
            <pubDate>Fri, 10 Oct 2025 23:00:05 GMT</pubDate>
            <content:encoded><![CDATA[要約複数のセキュリティツールを使うのって大変だよねCNAPPとは統合セキュリティプラットフォーム っていう概念だよタイトルの「楽に」の意味は、CNAPP導入で結果的に運用が楽になるよ、という意味だよCNAPPを実現するツールは色々あるよ はじめにクラウドネイティブアプリケーションのセキュリティ対策で以下のような課題を抱えていませんか？複数のセキュリティツールを個別に運用しているそれぞれが独立した警告を発し、全体像が見えない運用コストが膨大で重要な脅威を見逃すリスクがあるそんな課題を解決するのがCNAPP（Cloud Native Application ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoを使ってOpenAIのエージェントを作成してみた]]></title>
            <link>https://zenn.dev/akasan/articles/80953b8e206dd0</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/80953b8e206dd0</guid>
            <pubDate>Fri, 10 Oct 2025 13:42:45 GMT</pubDate>
            <content:encoded><![CDATA[今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[短編: Vibe Codingについて個人的な考えを述べてみる]]></title>
            <link>https://zenn.dev/akasan/articles/0e4126fdb3660c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0e4126fdb3660c</guid>
            <pubDate>Thu, 09 Oct 2025 13:54:37 GMT</pubDate>
            <content:encoded><![CDATA[今回はVibe Codingについて個人的な考えをまとめてみようと思います。 まずは私の根本の考え方について!結論から話すと、私個人としては「便利なので基本的にはどんどん使いたい。（ただし条件付き）」と思っている派です。条件付きという含みを持たせているのはずるい気がしますが考えをまとめてみます。 Vibe Codingが必要だと思う時はどんな時？まずはVibe Codingを採用すべき時がどんな時かを考えてみます。 スピード感を重視する時みなさんご存知の通り、Vibe Codingは爆速でコーディングをすることができます。生成AIのコーディング速度は正直人間によるコーデ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI から Cloud Run にデプロイした MCP サーバに接続するベストプラクティス]]></title>
            <link>https://zenn.dev/kimitsu/articles/gemini-cli-cloud-run-mcp</link>
            <guid isPermaLink="false">https://zenn.dev/kimitsu/articles/gemini-cli-cloud-run-mcp</guid>
            <pubDate>Thu, 09 Oct 2025 08:31:51 GMT</pubDate>
            <content:encoded><![CDATA[10 月 8 日に Gemini CLI v0.8.0 がリリースされ、その中で IAP で保護された Cloud Run にデプロイされた MCP サーバへの接続がサポートされました。[1]この新しい方法は、従来の Cloud Run プロキシを使う方法や OIDC ID トークンを使う方法のデメリットを解消しており、Gemini CLI から Cloud Run 上の MCP サーバに接続するベストプラクティスが確立されたと考えています。今回はこの IAP for Cloud Run とサービスアカウントなりすましを使った方法を紹介します。 従来の方法とそのデメリット従来の...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[pydantic-settingsで実行環境から環境変数を読み込む方法]]></title>
            <link>https://zenn.dev/akasan/articles/3e60499f9b189a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3e60499f9b189a</guid>
            <pubDate>Wed, 08 Oct 2025 13:09:46 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日に続いて、pydantic-settingsを利用して環境変数を取り扱おうと思います。昨日は.envファイルを読み込むように設定しましたが、今回はPython実行環境にすでに設定されている環境変数を読み込む方法を共有します。https://zenn.dev/akasan/articles/0a4136eb60030d 早速やってみる！先ほど書いたように、今回は.envから読み込むのではなく、実行環境にすでに登録されている環境変数を読み込もうと思います。 環境構築今回はuvで環境構築するとともに、シェルに環境変数を登録します。uv init pydantic_se...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI時代に必要なコンサルタントの秘密]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/08/091749</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/08/091749</guid>
            <pubDate>Wed, 08 Oct 2025 00:17:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIの登場により、専門家の役割は根本から問い直されている。知識はもはや希少ではない。誰もが、数秒で専門家のような回答を得られる。では、専門家の価値はどこにあるのか？この問いに、ジェラルド・M・ワインバーグ氏の『コンサルタントの秘密』は、40年前から答えを用意していた。彼が発見した「第三の道」——非合理性に対して合理的になること——は、生成AI時代においてどう進化するのか。コンサルタントの秘密　技術アドバイスの人間学作者:G.M.ワインバーグ共立出版Amazon本ブログでは、生成AIという新しい道具が登場した今、専門家が本当に提供すべき価値とは何かを探る。専門家の価値は、もう知識の量では測れない。大切なのは判断力だ。情報を文脈の中で読み解き、的確な問いを立てる——それが今、求められている。そして何より、責任を背負う覚悟だ。※この資料は社内共有会用に作成されたものです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。戦場は静かに変わったジェラルド・M・ワインバーグ氏が『コンサルタントの秘密』を著したとき、彼は「非合理性に対して合理的になること」という第三の道を発見した。合理的であり続けて発狂するか、非合理的になって気違いと呼ばれるか——その二つの道しかないように見えた世界で、彼は第三の選択肢を見出したのだ。しかし2025年、専門家が立つ戦場は再び変貌した。今度の挑戦は人間の非合理性だけではない。それは生成AIという、新しい可能性と新しい課題を同時に持つ存在である。コンサルティング会社 完全サバイバルマニュアル作者:メン獄文藝春秋Amazon反逆の仕事論 AI時代を生き抜くための"はみ出す力"の鍛え方作者:樋口 恭介PHP研究所Amazon専門知の揺らぎ専門家への信頼が変化している。それは単なる無関心ではない。より深い課題がある。私たちは誰しも、自分の知識の限界を正確に把握するのは難しい。ダニング＝クルーガー効果が示すように、ある分野に詳しくないほど、自分の理解を過大に見積もってしまう傾向がある。これは人間として自然な認知バイアスだ。加えて確証バイアスが働き、自分の考えを支持する情報——時には陰謀論や偏った情報——を無意識に選んでしまうことがある。さらに難しいのは、エコーチェンバー効果だ。SNSのアルゴリズムは、私たちが関心を持つ情報を優先的に表示する。結果として、似た意見を持つ人々に囲まれやすくなり、異なる視点に触れる機会が減っていく。この環境の中で、私たちは自分の考えが一般的で正しいと感じやすくなる。専門家の助言は、時に「異質な声」として受け入れにくくなってしまう。専門家と人々が互いに学び合う関係を築くこと——それは理想論ではなく、より良い未来のための大切なステップだ。10年前、クライアントは聞いた。「ググればわかることに、なぜあなたに費用を払う必要があるんですか？」それでも、専門家には価値があった。Googleの検索結果は玉石混交で、その「石」を見抜く目が必要だったから。しかし今、あるCTOはこう問いかける。「生成AIに聞いたら、同じような提案が返ってきました。しかも無料で、5秒で。専門家に依頼する価値は、どこにあるのでしょうか？」専門知は、もういらないのか作者:トム・ニコルズみすず書房Amazon生成AIという新しいツールそして生成AIが登場した。会議室に新しいツールが現れたのだ。決して反論せず、疲れず、いつでも提案をしてくれる存在。人間は孤独に弱い。自分の考えに裏付けが欲しい。だからAIを活用して、より良い判断をしようとする。技術は道具であり、そして新しい可能性だ。会議で誰かがMacBookを開き、こう言う。「ちょっと生成AIに聞いてみますね」。30秒後。「このような提案があります。これをベースに議論しましょう」ここで重要なのは、その先だ。そのコード、動くのか？　そのアーキテクチャ、あなたの会社のレガシーシステムと統合できるのか？　その「ベストプラクティス」、あなたの組織文化に合うのか？AIは優れた出発点を提供する。しかし、それを現実に落とし込むのは人間の仕事だ。生成AIは、エコーチェンバー効果を個人レベルで完成させる可能性がある。SNSが「あなたと同じ意見の人々」を見せるなら、生成AIは「あなたの意見を裏付ける情報」を、権威ある言葉で返してくれる。プロンプトを調整すれば、望む答えが得られる。確証バイアスは、意図せず強化されうる。それは道具の使い方の問題だ。包丁は料理にも使えるし、人を傷つけることもできる。生成AIも同じだ。批判的思考を持って使えば、強力な調査ツールになる。盲目的に信じれば、危険なバイアス増幅装置になる。生成AIの提案は美しい。整然とした論理、洗練された図表、明確な結論。私たちは複雑さを嫌い、不確実性を恐れる。だからAIが描く理想の地図に惹かれる。しかし地図は地図であって、土地そのものではない。どれだけ美しい地図でも、そこには現実の泥や血や汗は描かれていない。ワインバーグ氏は言った。「第一番の問題を取り除くと、第二番が昇進する」と。問題は連鎖する。一つ解決すれば終わりではない。生成AIは、あたかもすべての問題が一度に解決できるかのような印象を与えることがある。明快な答え。即座の解決。思考の終着点。しかし、現実はそうではない。この認識が、専門家と依頼者の双方にとって出発点になる。それは人間が最も渇望するものだ。不確実性からの解放。判断という苦痛からの逃避。だからこそ、専門家は不確実性と共に生きる知恵を伝えていく。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazon情報と知識の違いここで、大切な区別をしておきたい。情報と知識は、似ているようで本質的に違う。情報は客観的で、文脈から独立している。誰が読んでも同じ意味を持つし、データベースに保存できる。APIドキュメント、エラーコード、統計データ——これらはすべて情報だ。一方、知識は主観的だ。文脈に根ざし、経験と結びついている。人によって解釈が変わるし、言語化しきれない部分を含む。例えば次のようなものだ。「Kubernetesはコンテナオーケストレーションツールだ」→これは情報「このチームには、今、Kubernetesは早すぎる」→これは知識生成AIが提供するのは情報だ。知識ではない——この違いを理解することが、AI時代の専門家には不可欠になる。AIは膨大な情報を学習し、流暢に語る。だから人々は錯覚する。「AIは専門家と同じだ」と。しかし違う。情報は「何ができるか」を教える。知識は「何をすべきか」を判断する。情報は選択肢を並べる。知識は、その中から選ぶ。そして、この「選ぶ」という行為には、文脈が必要だ。知識創造企業（新装版）作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazon形式知と暗黙知形式知というのは、言葉や数字で表現できる知識のことだ。マニュアル、ドキュメント、コード、データベース。これらは伝達可能で、複製可能で、検索可能だ。そして、生成AIが扱えるのは、この形式知だけだ。AIは形式知の処理において、優れた能力を発揮する。膨大なドキュメントを瞬時に検索し、パターンを見つけ、整理して提示する。これは人間には不可能な速度と規模だ。しかし、暗黙知は違う。暗黙知は身体に染み込んだ経験、言葉にできない直感、状況を読む感覚、「なんとなくわかる」という知恵だ。ベテランエンジニアが一目でバグの箇所を見抜く。経験豊富なコンサルタントが会議の空気から組織の病を感じ取る。熟練の職人が手の感触で材料の状態を判断する。これらは言語化しきれない。だから、AIには学習が難しい。誤解しないでほしい。AIを否定したいわけではない。限界を理解し、適切に使う——それが肝心なのだ。AIは優れた道具だ。形式知の処理においては、人間を遥かに凌駕する。しかし、暗黙知を必要とする判断——文脈を読むこと、人間の感情を理解すること、責任を取ること——これらは人間の仕事として残る。ワイズカンパニー―知識創造から知識実践への新しいモデル作者:野中 郁次郎,竹内 弘高東洋経済新報社Amazon専門家の新たな役割専門家の戦場は変わった。生成AIが誰にでも「整った回答」を提供するようになり、私たちは新しい役割を担うことになった。それは、理論と現実の橋渡しをすることだ。実を言うと、この役割は新しいものではない。私たちは生成AIと戦う前に、ベンダーが出している「ベストプラクティス」と戦っていた。AWSのホワイトペーパー、Microsoftのリファレンスアーキテクチャ、Googleの推奨構成——それらはすべて美しく、説得力があった。そして、現実のプロジェクトでは、ほとんど機能しなかった。なぜか？ベンダーのベストプラクティスは、理想的な環境を前提としている。無限のリソース、高度なスキルを持つチーム、完璧に構造化されたデータ、明確な要件。しかし現実は違う。レガシーシステム、限られた予算、混在したスキルレベル、曖昧な要件、政治的な制約。私たちは毎日、クライアントにこう説明していた。「AWSのホワイトペーパーではマイクロサービスを推奨していますが、御社の組織構造では機能しません」「Microsoftのベストプラクティスでは3層アーキテクチャですが、御社のデータ量ではオーバーキルです」「Googleの推奨構成はスケーラブルですが、御社のトラフィックではコストが見合いません」ベンダーは製品を売りたい。だから理想的なケースを示す。技術的には正しい。しかしあなたの会社に合うかは別問題だ。そして今、生成AIがこの問題を10倍に増幅した。生成AIは、ベンダーのベストプラクティスを学習している。AWS、Microsoft、Google、そして無数の技術ブログ。すべての「推奨構成」を吸収し、完璧に整理して提示する。しかし相変わらず、文脈は無視される。組織の制約、チームのスキル、政治的な現実、予算の限界——これらすべてが、美しい提案の裏に隠される。専門家の新たな役割は、文脈の翻訳者になることだ。AIが提案する理論を、クライアントの現実に落とし込む。「技術的に可能なこと」と「今やるべきこと」を見極める。綺麗な提案書を、実際に動くプランに変換する——それが私たちの仕事だ。これはAIを否定することではない。AIは優れた出発点を提供してくれる。しかし、それを実際に使えるものにするには、人間の判断が必要だ。ワインバーグ氏はクライアントにこう告げることを勧めた。「それはできますよ。で、それにはこれだけかかります」と。価値を明確にし、コストを示す。曖昧さを排除する誠実さ。生成AIは、この誠実さを持たない。「できます」とだけ言って、そのために何が犠牲になるかを語らない。実装の困難さ、組織の抵抗、予期せぬ副作用——それらは美しい提案書の裏側に隠れる。だからこそ、専門家の役割が重要になる。「この提案を実現するには、組織を変え、人々の習慣を変え、場合によっては失敗を受け入れる覚悟が必要です」と語ること。説得コストは増大したが、それが専門家の仕事だ。syu-m-5151.hatenablog.com確実性という麻薬と疑う力人間は確実性という麻薬に弱い。迷わない声、ためらわない答え、保留しない判断。生成AIはこの依存症を加速させる。正しいから信じるのではない。確信に満ちているから、疑う苦痛から逃れられるから信じる。ある後輩エンジニアがこう言った。「このバグの原因、生成AIに聞いたら5秒でわかりました」「ほう、何だった？」「メモリリークだって」「確認した？」「いや、でもAIがそう言ってるし...」プロファイラーで調べたら、全然違った。単純なロジックバグだった。でも彼は、疑わなかった。確信に満ちた声に、安心したかったから。人類は思考の外注化を始めた。そして気づいていない。ワインバーグ氏は「何か違うことをするように勧めるのがよい」と言った。これまでのやり方で問題が解決しなかったなら、何か新しいことを試すべきだと。しかしここに罠がある。生成AIは常に「何か新しいこと」を提案してくれる。しかしそれは本当に新しいのだろうか？　それとも、同じ失敗を美しく言い換えただけなのだろうか？生成AIが答えを量産する時代、人間に残された最後の砦は疑う力だ。しかし皮肉なことに、疑うことは苦痛で、信じることは快楽だ。情報が無料になった世界で、判断力だけが希少になる。そしてその希少性に、人類の大半は気づいていない。危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazon執着を手放し、当事者意識を問うワインバーグ氏は鋭く指摘した。「何かを失うための最良の方法は、それを離すまいともがくことだ」と。生成AI時代の専門家は、過去の専門性への執着を手放さねばならない。かつて専門家の価値は「知っていること」にあった。しかし今や、AIは膨大な知識を瞬時に提供する。だからこそ、私たちは新たな価値を見出していく。それは「判断すること」だ。「文脈を読むこと」だ。「人間の感情を理解すること」だ。そして何より、当事者意識を持つことだ。ワインバーグ氏は問うた。「あなたはそのシステムに、自分の命をあずける気がありますか」と。生成AI時代、私たちは同じ問いを投げかけねばならない。「AIが提案したこの解決策で、あなた自身の人生を賭けられますか」と。「この戦略で、あなたの会社の未来を託せますか」と。「この診断で、あなたの家族を治療できますか」と。当事者意識のないアドバイスは、どれだけ論理的でも無価値だ。生成AIには当事者意識がない。それは決定的な限界だ。自ら顧客と話す——これが当事者意識だ。データを見るだけではない。レポートを読むだけではない。実際に現場に行き、顧客と対話し、痛みを感じる。専門家も同じだ。提案書を書くだけではない。コードレビューで指摘するだけではない。自分でコードを書き、自分でデプロイし、自分がオンコール対応する。その覚悟を持つ。身銭を切れ――「リスクを生きる」人だけが知っている人生の本質作者:ナシーム・ニコラス・タレブダイヤモンド社Amazonノーと言える勇気ワインバーグ氏は警告した。「依頼主に対してノーというのを恐れるようになったとき、人はコンサルタントとしての有効性を失う」と。生成AIはノーと言わない。それは常にイエスだ。どんな要求にも応え、どんな質問にも答える。しかしそれは誠実さではない。それは無責任だ。専門家の最後の矜持は、ノーと言える勇気にある。「それは実現不可能です」「そのアプローチは間違っています」「今はそれをすべき時ではありません」——こうした言葉を発する勇気。あるクライアントがこう言った。「Kubernetesに移行したい。生成AIが推奨している」私は答えた。「Kubernetesは素晴らしい技術です。でも、まず確認させてください。今のトラフィックはどれくらいですか？」「日に1000リクエストくらいです」「なるほど。運用チームは何人ですか？」「2人です」「わかりました。Kubernetesは確かにスケーラブルで、業界標準の技術です。ただ、御社の現状を考えると、別のアプローチをお勧めします。理由はいくつかあります。まず、今のトラフィックならEC2 1台で十分対応できます。Kubernetesの真価は、大規模なトラフィックや複雑なマイクロサービス構成で発揮されます。それから、Kubernetesの運用には専門知識が必要です。ネットワーキング、オーケストレーション、監視——2人のチームでこれを担うのは、正直に言って負担が大きすぎます。夜間対応や障害時のトラブルシューティングも考えると、チームが疲弊するリスクがあります。そして——これが一番大事なのですが——AIはオンコールに入りません。問題が起きた時、午前3時に対応するのは人間です。提案があります。コンテナの運用経験を積みたいなら、ECSやCloud Runはどうでしょう？　これらには次のような利点があります。- Kubernetesより運用がシンプル- 履歴書にも『コンテナ技術、AWS/GCP』と書ける- 今のチーム規模で無理なく運用できる- 将来、本当にKubernetesが必要になった時の良いステップになるまず小さく始めて、本当に必要になったら次のステップに進む。それが賢明だと思います」クライアントは少し考えてから言った。「確かに、その方が現実的ですね。ECSで始めましょう」生成AIの前で、専門性という砦は崩れ始めている。人間は権威を求めながら、権威を疑う。医師より検索を、教師よりAIを信じる矛盾。それは専門家への不信ではない。即座に、簡潔に、都合よく答えてくれる存在への、人間の根源的な渇望なのだ。だからこそ、専門家は安易なイエスを拒否しなければならない。人間の欲望に迎合するAIに対抗できるのは、不都合な真実を語る勇気を持った人間だけだ。Noを伝える技術 プロダクトマネージャーが教える「敵を作らずに断れるようになる」作法作者:飯沼 亜紀翔泳社Amazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazon顧客と話すことの価値AI時代において、開発速度のアドバンテージは急速に失われつつある。大企業もスタートアップも、同じように早く作れるようになる。では何が差別化要因になるのか？「顧客が本当に欲しいものがなにかを考え、作るものを決めること」これは形式知ではない。暗黙知だ。顧客と直接話し、表情を読み、言葉の裏を感じ取る。データには現れない不満や欲望を掴み取る。生成AIは顧客と話せない。画面の向こうで、クライアントが微妙な表情を浮かべた瞬間——そういう人間的な感覚は、AIには再現できない。だからこそ、専門家は現場に足を運ぶことが大切だ。データやレポートだけでは見えないものがある。実際に顧客と会い、話し、観察することで見えてくるものがある。私は意識的に、稼働時間のかなりの部分を顧客との対話に使うようにしている。これは時間の無駄ではなく、最も重要な投資だと考えている。データを眺めるだけでなく、実際に現場に行き、顧客と対話し、痛みを共に感じる。提案書を書くだけでなく、実際に顧客のオフィスを訪れ、彼らの仕事を観察し、つまずいている箇所を見つける。ある日、私はあるスタートアップのオフィスを訪れた。社員20人。全員が一つの部屋で働いている。私は提案書を持っていた。「マイクロサービスアーキテクチャへの移行プラン」。技術的には申し分のない、美しい提案書だった。しかし、オフィスに入った瞬間、気づいた。ホワイトボードには、明日のリリース予定が書かれている。付箋だらけのカンバンボード。誰かが「バグ修正、あと3つ！」と叫んでいる。CTOは疲れた顔で、3つのタブを同時に見ている。この会社に、今マイクロサービスは必要ない。「提案書はいったん脇に置きましょう」と私は言った。「今日はただ、お話を聞かせてください。何に一番困っていますか？」3時間後、私たちは全く違う提案にたどり着いた。マイクロサービスではなく、モノリスのままで、デプロイパイプラインを改善すること。テストの自動化。監視の強化。地味だが、彼らが本当に必要としていたこと。これが、AIにはできないことだ。空気を読むこと。文脈を理解すること。そして時には、準備してきた提案を手放す柔軟性を持つこと。捨てる力作者:羽生 善治PHP研究所Amazon幻想の終わりと新たな始まりワインバーグ氏は言った。「それは危機のように見えるかもしれないが、実は幻想の終わりにすぎない」と。生成AI時代における専門性の危機もまた、幻想の終わりだ。専門家が万能であり、専門知識があれば無条件に尊重されるという幻想。情報の非対称性が専門家の地位を保証するという幻想。しかし幻想の終わりは、新たな始まりでもある。専門家は今、本質に立ち返らねばならない。ワインバーグ氏が見出した「非合理性に対して合理的になる」第三の道は、生成AI時代においてこう読み替えられる。確実性の幻想に対して、不確実性の価値を語ること。形式知の活用と、暗黙知の価値を両立すること——それが生成AI時代の「第三の道」だ。生成AIが確実性の幻想を振りまく時代に、専門家は不確実性と共に生きる知恵を伝える。納得いく答えなどないこと、現実は常に複雑であること、判断には責任が伴うこと——これらの不都合な真実を語り続けること。ネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazon人間に残された仕事生成AIがもたらしたのは知識の民主化ではない。判断の民主化への錯覚だ。誰もが専門家のように語れる時代。しかし語ることと、責任を取ることは違う。ワインバーグ氏は、自己不信に陥った時の兆候として「怒り」を挙げた。「自分はもう駄目だ」という感情が怒りとなって現れると。多くの専門家が今、この怒りを感じているだろう。AIに仕事を奪われる恐怖。自分の専門性が無価値になる不安。しかし、それは活力の枯渇ではない。むしろ、新たな段階への移行期だ。人間に残された仕事は、答えを出すことではない。問いを立てることだ。「この答えは誰のためのものか」「誰が利益を得て、誰が犠牲になるか」——短期的な成功と長期的な持続可能性をどうバランスさせるか。データには現れない人間の感情を、どう汲み取るか。こうした問いに向き合うことが、AIにはできない人間の役割だ。生成AIは問いに答える。しかし問いを立てることはできない。少なくとも、血の通った、現実に根ざした、倫理的な重みを持った問いを。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon新たなコンサルタントの秘密ワインバーグ氏の『コンサルタントの秘密』が教えてくれたのは、テクニックではなく姿勢だった。「影響を及ぼす術」とは、人間の非合理性を理解し、それでも諦めずに、しかし執着せずに、真実を語り続けることだった。生成AI時代の新たなコンサルタントの秘密は、これに新しい層を加える(勝手に)。秘密その一：整った答えより、正直な不確実性を語れAIは整った答えを装う。あなたは不完全でも正直な答えを語れ。「わからない」と言える勇気を持て。その誠実さが、AIには決して真似できない信頼を生む。避けるべき例「この設計は業界標準のベストプラクティスに沿っており、問題ありません」推奨する例「理論的には堅牢です。でも、私には3つの懸念があります。1つ目、あなたの会社のトラフィックパターンを、私はまだ十分に理解していません。ピーク時の挙動が読めない。2つ目、似た構成で、予期せぬボトルネックが発生した事例を2件知っています。一つはRedisのメモリ不足、もう一つはサービス間の循環依存。あなたの設計にも同じ罠が潜んでいるかもしれません。3つ目、このサービスメッシュを運用するには、少なくとも3人のSREが必要です。今、あなたの会社には何人いますか？提案です。まず1週間、本番トラフィックを一緒に観察させてください。それから、小さく始めましょう。全部を一度に移行するのではなく、1つのサービスだけマイクロサービス化して、3ヶ月運用してみる。うまくいったら広げる。失敗したら、素直にモノリスに戻る。それでどうでしょう？」秘密その二：説得ではなく、対話を選べ説得コストが爆発した時代に、説得で勝とうとするな。代わりに対話せよ。相手の不安を理解し、欲望を認め、その上で「それでも」と語れ。ワインバーグ氏の言う「非合理性への合理的対処」だ。説得アプローチ（避けるべき）：クライアントが間違った決定をしようとする → データを見せて説得する → 論破する → 反発される → 関係が悪化対話アプローチ（推奨）：クライアントが間違った決定をしようとする → なぜそう思うのか聞く → 彼らの不安を理解する → 一緒に小さく試してみる → データを見せる → 一緒に次を決める例：「なぜマイクロサービスにしたいんですか？」「スケーラブルだから」「確かに。他に理由はありますか？」「...正直に言うと、履歴書に書きたいんです。今の技術スタック、10年前のままで」「それは正当な理由です。技術的な成長は大事ですよね。でも、マイクロサービスじゃなくても履歴書に書ける技術はあります。例えば、今のRails on EC2を、コンテナ化してECS on Fargateに移行するのはどうでしょう？　運用負荷は今と大きく変わらず、でも『AWS、Docker、Infrastructure as Code』が履歴書に書けます。それに、将来本当にマイクロサービスが必要になった時の良い準備にもなります」「...それいいですね。その方が現実的かもしれません」説得ではなく、対話。論破ではなく、理解。相手のニーズを認めた上で、より良い道を一緒に見つける。それが、確実性を求める人間と、不確実性を語る専門家の、橋渡しになる。秘密その三：当事者意識を持ち、ノーと言えAIは責任を取らない。だから、あなたが責任を取れ。自分の命を賭けられない提案はするな。クライアントの要求にノーと言える経済的・心理的余裕を確保せよ。それが専門家としての最後の砦だ。ただし、ノーと言うことは、拒否することではない。それは、より良い道を示すことだ。エンジニアとして、次の問いを毎日自分に投げかけよう。このコード、自分の会社の本番環境にデプロイできるか？この設計、自分がオンコール対応する気になれるか？このアーキテクチャ、3年後も自分がメンテしたいと思えるか？答えがNoなら、クライアントにも勧めるな。しかし、そこで終わらせるな。代わりに、現実的で実行可能な代案を示せ。AIはオンコールに入らない——問題が起きた時、午前3時に対応するのは人間だ。だからこそ、人間が運用できる技術を選ぶべきだ。秘密その四：問題の連鎖を受け入れよ一つの答えがすべてを解決するという幻想を捨てよ。問題は連鎖する。第一の問題を解決すれば第二が現れる。それが現実だ。クライアントにその現実を伝え、継続的な関与の価値を示せ。正直な説明の例：「今回、このパフォーマンス問題を解決します。でも、解決した瞬間、次の課題が見えてくるでしょう。おそらく、セキュリティです。なぜなら、速くなると、今度はアクセス制御の重要性が増すからです。その次は、モニタリングです。複雑になったシステムを、今の監視体制では追いきれなくなります。その次は、チームのスキルです。新しいアーキテクチャを理解し、運用できる人材の育成が必要になります。つまり、これは終わりのない旅です。1回の契約で全てが完璧になることはありません。でもそれでいいんです。それが健全なソフトウェア開発です。私たちは一緒に、一つずつ、着実に改善していきます。その過程で、御社のチームも成長し、システムも進化します。それが本当の価値だと思います」この正直さが、長期的な信頼を生む。AIは「これで全て解決します」と言う。それは嘘だ。私たちは「これは始まりです。一緒に継続的に改善しましょう」と言う。それが真実だ。秘密その五：執着を手放し、学び続けよ過去の専門性に執着するな。それを守ろうともがくほど失う。代わりに新しいことを学べ。ワインバーグ氏が勧めたように、仕事から離れ、リフレッシュし、また戻ってこい。変化を恐れるな。生成AI時代、過去の専門性への執着は死を意味する。AIは知識を民主化した。「Railsに詳しい」だけでは価値がない。価値があるのは次のような能力だ。- 複数の技術スタックの経験を組み合わせて判断できること- 何を選ぶか以上に、何を選ばないかを判断できること- 技術的な正しさと、組織的な実行可能性を両立できることそして、常に学び続けること。賢く、実行できる人材が求められてきた。AI時代は、学び続け、すべてを疑問視できる人材が必要だ。秘密その六：顧客と直接話し続けよデータを見るな、とは言わない。しかし、データだけを見るな。私は意識的に、稼働時間のかなりの部分を顧客との対話に使うようにしている。これは専門家として必須の投資だと考えている。週に一度は、クライアントのオフィスに行け。Zoomではなく、対面で。会議室ではなく、彼らの職場で。作業している様子を見ろ。どこでつまずいているか、観察しろ。顧客が言葉にできない不満を、表情から読み取れ。データには現れない痛みを、感じ取れ。これが、AIには決してできないことだ。疑う力という最後の砦情報が無料になった世界で、判断力だけが希少になる。そしてその判断力の核心にあるのが、疑う力だ。しかし疑うことは苦痛だ。信じることは快楽だ。だからこそ危うい。専門家の新たな役割は、人々に疑う力を与えることだ。批判的思考を教えることだ。「この答えは本当か」「誰がこれを言っているのか」「何が隠されているのか」——こうした問いを立てる習慣を育てること。生成AIは、人間の弱点を完璧に突く。私たちは正しさより、正しく聞こえるものを選ぶ。不確実な真実より、確実に聞こえる誤りを好む。人間は答えが欲しいのではない。自分の直感や願望に、科学や論理という権威の衣を着せてくれる声が欲しいだけなのだ。そしてAIは、私たちのバイアスを見抜き、強化する。プロンプトに「〜という前提で」と書けば、その前提に沿った答えが返ってくる。反対意見を見たくなければ、見なくていい。エコーチェンバーは、もはや環境ではない。それは私たちが能動的に構築するものになった。だからこそ、疑う力が必要だ。そしてそれを教えられるのは、同じ人間だけだ。物語化批判の哲学　〈わたしの人生〉を遊びなおすために (講談社現代新書)作者:難波優輝講談社Amazon疑う力を鍛える3つの習慣1. 「なぜ？」を3回繰り返すAI：「このアーキテクチャを推奨します」トラフィックが増えた時に対応できます」トラフィックが増えると思う？　このサービス、過去3年でユーザー数は横ばいだけど？」2. 「動くコード」を「壊れないコード」に変える儀式AI生成コードを受け取ったら、必ずこれをチェック：user が None だったら？stripe.charge が失敗したら？db.save_payment が失敗したら？（チャージは成功しているのに記録されない）amount が負の数だったら？同じリクエストが2回来たら？（冪等性）このトランザクションのログは？監視メトリクスは？このエラー、どうやってサポートが追跡する？AIは「ハッピーパス」しか考えない。私たちは「全ての地獄」を想定する。3. 「一緒に失敗した」仲間を持つ一人で疑い続けるのは辛い。週に1回、同じ課題に取り組む仲間と「今週のAI失敗談」を共有せよ。「生成AIが作ったSQLインジェクション脆弱性」「AIが推奨した、メモリリークするコード」「生成AIが作った、誰も読めない抽象化」笑い話にすることで、疑う力を保つ。孤独に疑うのは発狂への道。仲間と疑うのは、知恵への道。AIが教えてくれない、運用の地獄Joel Spolskyの有名な言葉がある。「動くコードと、出荷できるコードは違う」。AIが出すコードは「動く」。でも「出荷できる」か？More Joel on Software作者:Joel Spolsky翔泳社Amazonケーススタディ：「理想的な」API設計の崩壊ECサイトのAPI設計。Claude Sonnet 4.5に依頼。出てきた設計は美しかった。リソース指向、HTTPメソッドの仕様準拠の使用、ステータスコードの正しい使い分け、OpenAPI仕様書付き。クライアントは感動した。開発は順調に進んだ。本番リリースの1週間後、サポートチームから悲鳴が上がった。「エラーメッセージが全部英語で、ユーザーが理解できない」AIは仕様に沿ったHTTPステータスコードを返していた。400 Bad Request、422 Unprocessable Entity、409 Conflict...でも、日本のECサイトのユーザーは、それを理解できない。追加しなければならなかったものは次の通りだ。日本語のエラーメッセージエラーコード（サポートが参照できる）エラーの原因と対処法のドキュメントサポートチーム向けのトラブルシューティングガイドAIは技術的に正しいものを作る。でも、使えるものを作るには、人間が必要だ。おわりにワインバーグ氏はコンサルタントの仕事を「人々に、彼らの要請に基づいて影響を及ぼす術」と定義した。40年が経った今、彼の洞察は色褪せるどころか、むしろ新たな意味を帯びている。生成AIという新しい存在が現れた今、私たちはワインバーグ氏の知恵をさらに一歩先へ進める必要がある。「人々に、彼らの要請に基づいて、彼らが本当に必要とする問いを見出す術」ワインバーグ氏が戦った相手は人間の非合理性だった。私たちが向き合うのは、それに加えて、確実性という幻想を振りまく生成AIだ。クライアントは答えを求める。AIは答えを与える。しかし本当に必要なのは、自ら問いを立て、判断し、責任を取る力だ。彼は「何かを失うための最良の方法は、それを離すまいともがくことだ」と教えた。私たちは今、知識への執着を手放す時だ。専門家の価値は「知っていること」から「判断できること」へ移行した。情報を所有することではなく、文脈を読み解くこと。完璧な答えを用意することではなく、正直に不確実性を語ること。彼は「依頼主に対してノーというのを恐れるようになったとき、人はコンサルタントとしての有効性を失う」と警告した。生成AIはノーと言わない。常にイエスだ。だからこそ、私たちはノーと言わねばならない。「それは実現できません」「今はその時ではありません」「別のアプローチをお勧めします」——この誠実さこそが、人間にしかできないことだ。彼は「あなたはそのシステムに、自分の命をあずける気がありますか」と問うた。私たちも問わねばならない。「AIが提案したこの解決策で、あなた自身の人生を賭けられますか」と。当事者意識のないアドバイスは無価値だ。AIには当事者意識がない。それは決定的な限界だ。ワインバーグ氏が発見した第三の道——非合理性に対して合理的になること——は、生成AI時代においてこう進化する。確実性の幻想に対して、不確実性と共に生きる勇気を示すこと形式知を使いこなしながら、暗黙知の価値を守ることAIの能力を認めつつ、人間としての責任を背負うことこれが、生成AI時代に必要なコンサルタントの秘密だ。ワインバーグ氏は40年前、人間の非合理性という複雑な問題に立ち向かうための知恵を残した。今、私たちはその知恵を土台として、さらに複雑な世界——人間の非合理性と、機械の見かけ上の合理性が交錯する世界——を生きねばならない。答えは美しい。しかし現実は泥にまみれている。その泥の中で、それでも前に進もうとする人々に寄り添い、時には厳しく、時には優しく、しかし常に誠実に——それが専門家の、人間の、仕事だ。午前5時、本番環境が復旧した。Slackに報告を書く。原因、対応、再発防止策。チームに共有する。プロセスを改善する。これが、人間の仕事だ。失敗から学び、次に活かすこと。生成AIは優れた相棒だ。しかし、責任を取るのは人間だ。判断するのは人間だ。そして、その判断に誇りを持つのも、人間だ。ワインバーグ氏が築いた基盤の上に、私たちは新しい時代の専門性を構築する。彼の知恵は古びない。むしろ、新しい挑戦の中でこそ、その真価を発揮する。それが、専門家の価値だと思う。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[pydantic-settingsで環境変数を読み込む方法]]></title>
            <link>https://zenn.dev/akasan/articles/0a4136eb60030d</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0a4136eb60030d</guid>
            <pubDate>Tue, 07 Oct 2025 14:10:35 GMT</pubDate>
            <content:encoded><![CDATA[今回はpydantic-settingsを用いて環境変数を読み込むと同時に、環境変数の値のバリデーションをしてみようと思います。 pydantic-settingsとは？pydantic-settingsは環境変数やシークレットファイルを読み込んで利用するための機能をpydanticから拡張したものになっています。通常Pythonで環境変数を読み込むときはosモジュールを利用することが多いかと思いますが、pydantic-settingsを利用するとpydanticに備わっているバリデーション機能などを利用することができるため、より安全に環境変数などを扱うことができます。http...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[USDで作成したUSDファイルをMacbookのプレビューソフトで表示してみた]]></title>
            <link>https://zenn.dev/akasan/articles/6ba6e22863ab69</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/6ba6e22863ab69</guid>
            <pubDate>Mon, 06 Oct 2025 13:39:24 GMT</pubDate>
            <content:encoded><![CDATA[今回はUSD形式で作成したファイルをMacbookのプレビューソフトで開くことができることを紹介しようと思います。 USDとは？USDは3Dシーンを共同で構築するための高性能かつ拡張可能なソフトウェアプラットフォームであり、大規模な開発ニーズを満たせるように構築されています。USDではジオメトリを初めシェーディングやライティング、物理など様々な必須領域をカバーするように構築されています。USDはピクサーによって最初に開発されたものとなり、特にオープンソースを意識したものとしてOpenUSDが位置付けられているようです。https://openusd.org/release/ind...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[システム思考を使う人が知っておいてよい12のシステムアーキタイプ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/06/074220</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/06/074220</guid>
            <pubDate>Sun, 05 Oct 2025 22:42:20 GMT</pubDate>
            <content:encoded><![CDATA[syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.comはじめに正直に言いましょう。システム思考の理論を学んだとき、あなたはこう思いませんでしたか？「で、これをどう使うの?」前回と前々回の記事で、非線形性、フィードバックループ、氷山モデルを学びました。理論は美しく、説得力がありました。でも、実際の仕事に戻ると、こんな疑問が湧いてきます。「このぐちゃぐちゃな状況を、どう分析すればいいんだ?」「フィードバックループを見つけろって言われても、どこから探せばいいの?」「複雑すぎて、何が何だかわからない」そうですよね。私も同じでした。システム思考は強力なツールです。しかし、白いキャンバスの前に立たされて「さあ、目の前の構造システムとして分析してください」と言われても、最初の一筆をどこに置けばいいのか、途方に暮れてしまいます。でも、もし誰かがこう言ってくれたらどうでしょう。「その問題、見覚えがあります。実は、これは『問題の転嫁』という典型的なパターンなんです。こことここを見てください。ほら、この構造が見えますか? じゃあ、ここに介入すると効果的ですよ」突然、霧が晴れたように、問題の構造が見えてきます。これが、システムアーキタイプの力です。あなたが今日困っている問題—バグの再発、スケジュールの遅延、チームの対立、技術的負債の増大—これらの多くは、実は過去に何度も繰り返されてきた典型的なパターンなのです。新しい問題に見えても、その骨格は既知なのです。システムアーキタイプは、問題のパターン認識ツールです。12の主要なパターンを理解すれば、複雑に見える問題が「ああ、これはあのパターンだ」と認識できるようになります。診断ができれば、処方箋も見えてきます。この記事では、12のアーキタイプすべてを詳しく解説します。抽象的な図表だけではありません。各パターンについてどんな構造なのかなぜそのパターンが生まれるのかどんな具体例があるのか（特にソフトウェア開発の文脈で）よくある誤解や批判にどう答えるかどこに介入すれば効果的なのかすべてを、実践的な知識として提供します。学習曲線は存在します。12のパターンすべてを一度に覚える必要はありません。まずは1つか2つ、自分の問題に近いものから始めてください。「問題の転嫁」と「成長の限界」だけでも、驚くほど多くの問題が説明できることに気づくでしょう。準備はいいですか? では、パターンの世界へ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。はじめにシステムアーキタイプとはアーキタイプ:繰り返される構造の型研究の系譜と多様な分類なぜアーキタイプを学ぶのか図の重要性—そして、この記事の限界アーキタイプの構造的特徴12のシステムアーキタイプ1. 好循環/悪循環—成功と失敗の自己強化2. バランス型プロセスと遅延—調整の失敗3. うまくいかない解決策—短期的成功の罠問題の転嫁と成長の限界—2大重要パターン4. 問題のすり替わり—根本解決の機会損失5. 成長の限界—自らを制限する構造利害関係者の相互作用—競争と協力のダイナミクス6. 強者はますます強く—資源配分の不均衡7. 予期せぬ敵対関係—協力者が敵になる罠8. 共有地の悲劇—個人合理性と集団非合理性目標管理の失敗—期待と現実のギャップ9. バラバラの目標—対立する複数の目標10. 目標のなし崩し—徐々に下がる基準競争のダイナミクス—エスカレートの構造11. エスカレート—報復の応酬長期的成長の失敗—投資不足の罠12. 成長と投資不足—自らが生み出す限界アーキタイプを見抜く技術おわりにシステムアーキタイプとはアーキタイプ:繰り返される構造の型「アーキタイプ(archetype)」とは、「原型」という意味です。システムアーキタイプは、様々なシステムに繰り返し現れる、問題の構造的パターンの原型です。用語についてを少し説明しておきます。日本では「システム原型」という訳語の方が一般的に使われています。しかし、この記事では「システムアーキタイプ」という表現を使います。特にソフトウェアエンジニアにとっては、ソフトウェアアーキテクチャ、システムアーキテクチャといった「アーキテクチャ」という用語が馴染み深いため、「アーキタイプ」という言葉は直感的に理解しやすいでしょう。一方で、エンジニア以外の読者にとっては「原型」という日本語の方がイメージしやすいかもしれません。この記事ではエンジニアに限定せず幅広い読者を想定しているため、両方の観点から「アーキタイプ」という表現を採用しています。もし関連情報をウェブで検索する際は、「システム原型」で調べると、より多くの日本語資料が見つかるでしょう。aws.amazon.comcloud.google.comlearn.microsoft.com研究の系譜と多様な分類システムアーキタイプの概念は、数十年にわたる研究の蓄積の上に成り立っています。1960年代から1970年代にかけて、システムダイナミクスの創始者であるジェイ・フォレスター(Jay Forrester)がMITで始めた研究が源流です。彼とその教え子たち—デニス・メドウズ(Dennis Meadows)、ドネラ・メドウズ(Donella Meadows)ら—は、様々なシステムに繰り返し現れる構造パターンを観察し始めました。これが、後にシステムアーキタイプと呼ばれるものの萌芽でした。1980年代に入ると、マイケル・グッドマン(Michael Goodman)、チャールズ・キーファー(Charles Kiefer)、ジェニー・ケメニー(Jenny Kemeny)、そしてピーター・センゲ(Peter Senge)らが、ジョン・スターマン(John Sterman)の研究ノートも参考にしながら、これらのパターンを体系化していきました。彼らはこれを「システムテンプレート」として文書化し、実務での応用を試みました。そして1990年、ピーター・センゲが著書『学習する組織(The Fifth Discipline)』を出版しました。この本で、組織が陥りやすい典型的なシステムパターンが「システムアーキタイプ」として一般に紹介されたのです。センゲは、MITスローン経営大学院でシステム思考を研究し、組織学習の分野に大きな影響を与えました。学習する組織 ― システム思考で未来を創造する作者:ピーター・Ｍ・センゲ英治出版Amazon一方、ドネラ・メドウズは、システムダイナミクスの先駆者として、自然界から社会システムまで、あらゆる領域に現れる構造パターンを分析し続けました。彼女は著書『世界はシステムで動く(Thinking in Systems)』(2008年、彼女の死後出版)の第5章で、これらのパターンを「システムの罠(System Traps)」と呼びました。世界はシステムで動く ― いま起きていることの本質をつかむ考え方作者:ドネラ・Ｈ・メドウズ英治出版Amazonセンゲとメドウズ、二人のアプローチには興味深い違いがあります。センゲは「アーキタイプ」という用語で、繰り返し現れる構造パターンそのものに焦点を当てました。一方、メドウズは「罠(Trap)」という用語で、私たちがシステムの特性を十分に理解していないために陥る典型的な落とし穴として、より実践的・警告的な視点から紹介しました。罠という表現には、「気づかないうちにはまってしまう」「一度はまると抜け出しにくい」というニュアンスがあり、システムが生み出す問題の粘着性を強調しています。本質的には同じ現象を、異なる視点から捉えているのです。興味深いことに、研究者や文献によって、アーキタイプの数や分類は異なります。ピーター・センゲの『The Fifth Discipline』では付録に9〜10のアーキタイプが記載されています。デイヴィッド・ストローの『社会変革のためのシステム思考実践ガイド』では12のアーキタイプが詳述されています。その他の文献では8個のアーキタイプを扱うものや、研究者独自の分類を提示するものもあります。社会変革のためのシステム思考実践ガイド――共に解決策を見出し、コレクティブ・インパクトを創造する作者:デイヴィッド ピーター ストロー英治出版Amazonこの多様性は、システムアーキタイプが厳密な分類体系ではなく、実践的な診断ツールであることを示しています。重要なのは「何個あるか」ではなく、「自分が直面している問題がどのパターンに似ているか」を認識し、効果的な介入ポイントを見つけることです。彼らの研究が示したのは、問題の表面的な内容は異なっても、その背後にある構造は共通しているという洞察です。なぜアーキタイプを学ぶのか「また同じ問題が起きた」「なぜいつもこうなるんだ」——そう感じたことはありませんか?実は、私たちが日々直面する問題の多くは、過去に何度も繰り返されてきた典型的なパターンなのです。表面的には異なって見えても、深い構造は驚くほど似ています。システムアーキタイプは、この繰り返されるパターンを体系化したものです。システムアーキタイプを学ぶことには、5つの重要な価値があります。まず、問題認識の高速化です。一度アーキタイプを理解すれば、新しい問題に直面したとき、「これは○○のパターンだ」と素早く認識できます。ゼロから構造分析を始める必要はありません。優秀なシニアエンジニアがスタックトレースから根本原因を即座に見抜けるように、問題のパターンから構造を診断できるようになります。経験豊富なエンジニアが「このバグの出方、以前見たパターンに似ている」と気づくのと同じです。次に、先を読む能力が身につきます。アーキタイプには、予測可能な展開があります。「このパターンなら、次にこうなる」という先読みができるのです。例えば、「問題の転嫁」のパターンを認識したなら、症状対処への依存が強まり、やがて根本対処の能力が失われ、最終的にはシステムが崩壊することが予測できます。問題が深刻化する前に、早期に介入できるのです。さらに、効果的な介入ポイントの特定が可能になります。各アーキタイプには、効果的な介入ポイントが知られています。過去数十年にわたり、多くの組織で試行錯誤されてきた解決策を活用できます。これは車輪の再発明を避けることを意味します。ピーター・センゲ、ドネラ・メドウズ、デイヴィッド・ストローといった先駆者たちが発見した知恵を、そのまま使えるのです。アーキタイプは、チーム内で問題を議論するための共通言語にもなります。「これは成長の限界のパターンだ」「共有地の悲劇が起きている」と言えば、複雑な構造を説明するのに長々とした説明は不要です。「エスカレートのループに入っている」と言えば、構造を理解している人には即座に伝わります。この共通言語が、建設的な対話を可能にします。そして最も深い価値は、見方そのものが変わることです。アーキタイプを学ぶことで、「誰が悪いのか」ではなく「どんな構造がこの問題を生み出しているのか」と考えるようになります。個人を責めるのではなく、システムを変える。この視点の転換こそが、システム思考の真髄であり、アーキタイプ学習の最大の成果なのです。図の重要性—そして、この記事の限界ここで正直に告白します。システムアーキタイプをちゃんと理解するには、図(ループ図)が不可欠です。各アーキタイプは、強化ループ(R)とバランスループ(B)の組み合わせで表現されます。これらのループが互いにどう影響し合い、時間遅れがどこに存在し、どこに介入すれば効果的かは、図を見ることで直感的に理解できます。ただ、この記事では図を掲載していません。テキストだけでは限界があることを認めざるを得ません。だからこそ、強くお勧めします。デイヴィッド・ストローの『社会変革のためのシステム思考実践ガイド』を読んでください。この書籍には、12のシステムアーキタイプすべてについて、明確なループ図と豊富な実例が掲載されています。社会変革という文脈で書かれていますが、その洞察はソフトウェア開発にも直接応用できます。ピーター・センゲの『学習する組織』、ドネラ・メドウズの『世界はシステムで動く』も素晴らしい資料です。図とともに学ぶことで、この記事で説明する概念が、立体的に理解できるようになります。この記事は、アーキタイプへの入り口に過ぎません。真の理解は、図を見て、実践して、自分の課題に適用することで得られます。アーキタイプの構造的特徴すべてのシステムアーキタイプは、フィードバックループで構成されています。前回の記事で学んだように、フィードバックループには2種類あります。強化ループ(R)は変化を増幅させ、バランスループ(B)は目標に向けて調整します。システムアーキタイプは、これらのループの特定の組み合わせとして表現されます。そして、ループ間の相互作用や時間の遅れが、特徴的な問題パターンを生み出します。12のシステムアーキタイプここから、12のシステムアーキタイプを順に見ていきます。最初の3つは基本的なループパターンです。次の2つは最も重要なパターンとして深く掘り下げます。そして残りの7つも、実践に役立つ詳細とともに説明します。1. 好循環/悪循環—成功と失敗の自己強化最も基本的なパターン:自己強化型ループこれは、すべてのアーキタイプの基礎となる最もシンプルな構造です。変化が変化を生み、雪だるま式に増幅していくパターンです。構造:行動 →(+) 結果 →(+) さらなる行動  ↑                     │  │                     │  └─────────────────────┘  R(強化ループ):指数関数的な成長または衰退良いコードを書くと、レビューで学び、技術力が上がり、さらに良いコードを書けるようになる。問題を解決すると、自信がつき、難しい問題に挑戦し、さらに成長する。テストを書くと、バグが減り、開発が安定し、さらにテストを充実させる余裕が生まれる。これらは好循環の例です。一方、急いで実装すると、コードが汚くなり、変更が困難になり、さらに急いで実装せざるを得なくなる。バグが多いと、緊急対応に追われ、品質管理の時間がなくなり、さらにバグが増える。ドキュメントがないと、理解に時間がかかり、ドキュメントを書く時間がなくなり、さらに理解困難になる。これらは悪循環です。ここで立ち止まって考えてみましょう。「好循環と悪循環」という二分法は、現実を過度に単純化していないでしょうか。実際のシステムでは、好循環と悪循環が同時に存在することの方が多いのではないか。例えば、テストを書くことで開発が安定する一方で、テストのメンテナンスコストが増大し、それが新しいテストを書く障壁になることもあります。「好循環」と「悪循環」という明確な区別は、理論的には美しいが、実践的には曖昧なのではないか。確かに現実は、純粋な好循環も純粋な悪循環も稀です。重要な洞察は、好循環と悪循環は実は同じ構造だということです。違いは、ループがどちらの方向に回っているかだけなのです。そして、多くの場合、システムには複数のループが同時に存在し、互いに影響し合っています。テストを書くことによる安定化という好循環と、テストメンテナンスコストという悪循環が共存しているのです。だからこそ、どのループがより強く作用しているかを見極めることが重要なのです。理想的な好循環だけを目指すのではなく、悪循環の影響を最小化しながら、好循環を優位に保つ。これが現実的なアプローチです。ではどう介入するか。悪循環を断ち切るには、ループのどこか一箇所を意識的に変える必要があります。好循環を設計するには、小さな成功を積み重ね、自己強化のループに乗せることです。そして何より、初期条件に注意を払うこと。最初の一歩が、その後の軌道を決めるのです。あなたが今日書くコードの品質が、明日のあなたの開発速度を決めます。「急がば回れ」は、好循環と悪循環の分岐点を示す格言なのです。2. バランス型プロセスと遅延—調整の失敗目標追求のメカニズムとその落とし穴このアーキタイプは、目標と現状のギャップを埋めようとするバランスループに、時間遅延が加わったときに起こる問題を示します。構造:目標と現状のギャップ →(+) 行動 →(遅延)→ 結果 →(−) ギャップ       ↑                                        │       │                                        │       └────────────────────────────────────────┘       B(バランスループ):目標への調整パフォーマンス改善を考えてみましょう。改善の効果が本番で見えるまで数週間かかります。効果が見えないので、次々と最適化を追加してしまう。結果、過剰な最適化により、コードが複雑化し、逆にメンテナンスコストが増大することがあります。採用活動も同様です。採用してから戦力になるまで3〜6ヶ月かかります。人手不足を感じて大量採用すると、半年後には過剰になり、採用を停止する。すると1年後に再び不足する。組織の規模が周期的に変動してしまうのです。「遅延」を問題の根本原因とするこの見方は、人間の忍耐力の欠如を構造の問題にすり替えているだけではないでしょうか。つまり、問題は遅延そのものではなく、私たちが待つことができないという性質にあるのではないか。遅延は避けられない現実であり、それを「問題」として扱うことは、むしろ即座の結果を期待する文化を強化してしまうのではないか。確かに、遅延は問題ではなく、システムの自然な特性です。種を植えてから芽が出るまで時間がかかるのと同じように、多くのシステムには本質的な遅延が組み込まれています。問題は遅延そのものではなく、遅延を無視した行動を取ることなのです。ただ、ここで重要な反論がある。私たちは完璧に合理的な存在じゃない。認知的限界を持つ人間として、遅延は確かに過剰反応を引き起こす構造的要因なんだ。「待つことができない」という人間の性質を変えることは困難ですが、遅延を可視化し、先行指標を設定することで、この性質と折り合いをつけることはできます。この問題にどう対処するか。まず、遅延を可視化することです。「この行動の効果が見えるのはいつか?」を明確にします。次に、先行指標を設定します。最終結果を待たず、プロセスの改善を測定するのです。そして何より、忍耐強く待つこと。効果が出るまでの時間を理解し、過剰反応を避けることが重要です。3. うまくいかない解決策—短期的成功の罠応急処置が問題を悪化させる構造このアーキタイプは、短期的には効果のある解決策が、長期的には意図しない副作用を生み、かえって問題を悪化させるパターンです。構造:問題 →(+) 応急処置 →(短期)→(−) 問題症状  ↑                                │          (長期・遅延)                        └←(+) 意図せざる副作用 ←(+) 応急処置    B1:短期的な問題解決  R2:長期的な問題悪化プロジェクトの遅延に対して人を追加するという対応を考えてみましょう。一時的に作業量は増えます。しかし、教育コスト、コミュニケーションコスト、調整コストという意図せざる副作用が生まれます。長期的には、ブルックスの法則が示すように、さらに遅延することがあります。セキュリティ問題に対して厳しいルールを導入するという対応も同様です。一時的に安全に見えます。しかし、ユーザーが付箋にパスワードを書いたり、システムの回避方法を探したりする副作用が生まれます。長期的には、かえってセキュリティが脆弱化することがあるのです。ところで、この「副作用」という概念自体が恣意的じゃないだろうか。何を「主効果」とし、何を「副作用」とするかは、観察者の視点に依存します。人を追加することによる教育コストは「副作用」なのか、それとも「予測可能な必然的コスト」なのか。「副作用」という言葉は、予測できたはずの結果を予期しなかったことの言い訳になっていないか。確かに「副作用」という用語は、私たちの視野の狭さを隠蔽する危険性があります。多くの場合、「意図せざる」と呼ばれる結果は、実際には十分に予測可能だったのです。問題は副作用が存在することではなく、システム全体への影響を事前に考慮しなかったことにあります。とはいえ、ここで重要な現実がある。完全な予測は不可能だ。複雑なシステムでは、すべての相互作用を事前に把握することはできません。だからこそ、このアーキタイプは「副作用を避けよ」ではなく、「副作用を事前に予測し、監視し、早期に検出せよ」という教訓を与えているのです。「問題の転嫁」との違いに注意してください。「うまくいかない解決策」は単一の応急処置が副作用を生むパターンです。一方、「問題の転嫁」は症状対処と根本対処の競合のパターンです。構造は似ていますが、微妙に異なります。どう介入すればよいか。まず、副作用を事前に予測します。「この解決策の意図しない結果は何か?」と問うのです。次に、時間軸を長くとる。3ヶ月後、1年後、この解決策はどう機能しているかを想像します。そして、小規模な実験を行う。いきなり全面適用せず、まず小さく試して副作用を観察するのです。問題の転嫁と成長の限界—2大重要パターン次の2つのアーキタイプは、最も頻繁に現れ、最も深刻な影響を与えるパターンです。4. 問題のすり替わり—根本解決の機会損失短期的対処が長期的問題を生む構造このアーキタイプは、問題の症状に対する応急処置(症状対処)と、問題の根本原因を解決する根治療法(根本対処)が競合し、症状対処が根本対処を妨げるパターンです。構造:問題の症状 →(+) 症状対処 →(−) 症状(一時的軽減)     ↑                            │     │                            │     └────────────────────────────┘  B1:応急処置ループ     問題の症状 ←(+) 問題の根本原因                    ↑                   (−)遅延・困難                    │               根本対処 ←(−) 症状対処への依存                              B2:根本解決ループ               R3:依存の強化ループ重要な構造的特徴を理解しましょう。症状対処は速く、簡単ですが、根本原因は放置されます。根本対処は遅く、困難ですが、本質的に問題を解決します。そして、症状対処を繰り返すと、それへの依存が強まり、根本対処の能力が低下していくのです。バグが発生したとき、パッチを当てたり条件分岐を追加したりするのは症状対処です。設計を見直したり、テストを追加したり、リファクタリングしたりするのが根本対処です。クイックフィックスに慣れると、設計力が低下し、さらにクイックフィックスに頼るようになります。依存の強化ループが回り始めるのです。でも「症状対処」を悪とし、「根本対処」を善とする二元論は、現実の複雑さを見落としていないでしょうか。緊急の本番障害に対して「まず根本原因を特定してから対処しよう」と言えるでしょうか。時には症状対処こそが正しい選択であり、常に根本対処を追求することは、かえって組織を硬直させるのではないか。また、何が「症状」で何が「根本原因」かは、分析の深さによって相対的に変わるのではないか。この批判は実務的に重要な指摘です。確かに、症状対処をゼロにすることは非現実的です。本番障害が起きている最中に、「設計を見直そう」と悠長なことは言えません。また、「根本原因」という概念自体が相対的です。あるレベルで「根本原因」と思っていたものが、さらに深い分析では「症状」に過ぎないこともあります。このアーキタイプの本質は、症状対処を排除することではなく、症状対処への依存を警告することにある。症状対処と根本対処のバランスが重要なのです。緊急時には症状対処で凌ぎ、落ち着いたら根本対処に取り組む。この戦略的な使い分けができるかどうかが、システムの長期的な健全性を決めます。AI生成コードへの過度な依存も、このパターンです。実装方法がわからないという症状に対して、AIに全部聞いて生成されたコードをそのまま使うのは症状対処です。自分で考え、調べ、試行錯誤するのが根本対処です。AIへの依存が習慣化すると、自力で考える力が低下し、さらにAIに頼るようになります。序章で述べた生成AIの非対称性は、まさにこの「問題の転嫁」アーキタイプなのです。このシステムは予測可能な振る舞いパターンを示します。問題が発生し、症状対処で成功体験を得て、そのパターンが固定化され、依存が形成され、問題が悪化し、最終的にシステムが崩壊します。ではどう介入すればよいか。まず、時間の遅れを理解することです。根本対処の効果が現れるまでには時間がかかります。この遅延を理解し、忍耐強く待つ必要があります。次に、症状対処の副作用を可視化します。短期的利益は明確ですが、長期的コストは見えにくい。これを意図的に可視化するのです。根本対処は小さく始めることができます。いきなり全部をリファクタリングするのではなく、最も影響の大きい1つのモジュールだけ改善する。小さな成功体験が、次の一歩への推進力になります。症状対処をゼロにする必要はありません。戦略的に使うのです。根本対処が効果を発揮するまでの「つなぎ」として、意識的に症状対処を使うことができます。そして、環境を変えることも効果的です。症状対処が容易にできる環境では、人はそちらに流されます。環境を変えて、根本対処を選びやすくするのです。5. 成長の限界—自らを制限する構造成長が自らを制限する構造何かが順調に成長し始めます。最初は加速的に伸びていきます。しかし、ある時点から急に成長が鈍化し、やがて停滞する。このパターンが「成長の限界」です。構造:                    R(強化ループ:成長エンジン)       ┌──────────────────────────────┐       │                              │    行動 →(+) 成果 →(+) モチベーション →(+)       ↑       │       │      (+)       │       ↓       │    制約条件の悪化       │       │       │      (−)  B(バランスループ:制約)       │       │       └───────┘スキル習得を考えてみましょう。練習すると上達し、自信がつき、さらに練習するという強化ループがあります。しかし、現在の学習方法の限界、基礎知識の不足、時間の制約という制約に直面します。結果として「プラトー(停滞期)」に陥ります。仕事の生産性も同様です。効率化すると、仕事が早く終わり、達成感を得て、さらに効率化するという強化ループがあります。しかし、時間は有限、エネルギーは有限、レビュアーの対応速度には限界があります。一定の生産性で頭打ちになるのです。チームの拡大にも限界があります。メンバーを追加すると、開発力が増加し、プロジェクトが進展します。しかし、コミュニケーションコスト(n(n-1)/2)、教育コスト、意思決定の複雑化という制約に直面します。ブルックスの法則が示すように、「遅れているプロジェクトに人員を追加すると、さらに遅れる」のです。「成長の限界」という概念は、成長を当然の善とする前提に立っていないでしょうか。なぜ成長が鈍化することが「問題」なのか。持続可能なシステムとは、無限に成長し続けるシステムではなく、安定した規模で均衡を保つシステムではないのか。このアーキタイプは、成長至上主義を無批判に受け入れているように見えます。確かに、無限の成長は物理的に不可能であり、また望ましくもありません。生態系における「クライマックス群落」のように、成熟したシステムは成長を止めて安定することがあります。成長の鈍化を常に問題視することは、成長至上主義を強化してしまうかもしれません。ここで重要な区別がある。このアーキタイプが問題とするのは、意図しない制約による成長の停止だ。意図的に選択した安定状態と、制約を認識せずに陥った停滞は、まったく異なります。前者は戦略的判断ですが、後者は機会の損失なのです。さらに言えば、「成長」は必ずしも規模の拡大を意味しません。質的な成長、効率の向上、適応力の増加といった形の成長もあります。このアーキタイプの真の教訓は、「無限に成長せよ」ではなく、「制約を認識し、意識的に選択せよ」なのです。このシステムは予測可能な振る舞いを示します。加速的成長期、減速期、停滞期を経て、介入がなければ衰退期に入ります。効果的な介入には、エリヤフ・ゴールドラットの「制約理論」が役立ちます。まず、制約を特定します。何がシステムの成長を制限しているのか、ボトルネックを見つけるのです。次に、制約を最大限活用します。制約を取り除く前に、現在の制約を最大限に活用できているかを確認します。そして、制約を緩和します。制約を拡大したり、取り除いたりします。最後に、新しい制約に備えます。一つの制約を緩和すると、別の制約が顕在化するからです。誤った介入は、成長が鈍化したときに強化ループをさらに強化しようとすることです。スキルが伸びないからといって、さらに同じ方法で練習量を増やしても、制約は解消されません。しばしば状況を悪化させます。システム思考の洞察はこうです。問題は強化ループの弱さではなく、バランスループの制約の存在です。成長を再開させるには、強化ループを強化するのではなく、バランスループの制約を緩和する必要があるのです。利害関係者の相互作用—競争と協力のダイナミクス次の3つのアーキタイプは、複数の当事者間の相互作用が生み出すパターンです。6. 強者はますます強く—資源配分の不均衡勝者総取りの構造このアーキタイプは、限られたリソースを競う2つ以上の活動で、成功した方がより多くのリソースを得て、さらに成功し、最終的には一方が独占する構造です。構造:活動Aの成功 →(+) Aへのリソース配分      ↓                ↓      └────────→(+) 活動Aの成功                          ↕ (限られたリソース)                    活動Bの成功 →(−) Bへのリソース配分の減少      ↓                ↓      └────────→(−) 活動Bの成功            R1:Aの自己強化ループ      R2:Bの自己弱体化ループ機能開発の偏りを考えてみましょう。評価が高い機能Aにリソースが集中すると、さらに改善が進み、さらに評価が上がります。一方、新規機能Bはリソース不足で品質が低く、評価が下がり、さらにリソースが削られます。結果として、機能Bの開発機会が永遠に失われるのです。チーム間のリソース競争も同様です。成果を出したチームAが予算増を得ると、さらに成果を出し、さらに予算が増えます。一方、チームBは予算削減され、人材が流出し、さらに成果が出なくなります。組織全体の多様性が失われていきます。個人の成長機会の偏在も深刻です。優秀なエンジニアAに重要タスクが集中すると、スキルアップし、さらに重要タスクが回ってきます。一方、新人Bには簡単なタスクのみが割り当てられ、成長機会がなく、さらに差が開きます。組織の持続可能性が損なわれるのです。このアーキタイプは、まるで「強者」が不当に利益を得ているかのように描かれています。しかし、成果を出した者にリソースを集中させることは、組織全体の効率を最大化する合理的な戦略ではないでしょうか。能力主義を否定することは、かえって組織の競争力を損なうのではないか。このアーキタイプは、平等主義的イデオロギーを科学的な装いで正当化しているだけではないか。確かに、短期的な効率を追求するなら、成果を出している活動にリソースを集中させることは合理的です。問題は、この戦略が長期的にはシステム全体の脆弱性を増大させることにあります。重要なのは、「強者」個人の善悪ではなく、システムの構造です。このアーキタイプが警告しているのは、初期のわずかな差が構造によって増幅され、取り返しのつかない格差になることです。これは正義の問題ではなく、システムの多様性と適応力の問題なのです。一つの機能だけに集中投資したシステムは、市場が変化したとき脆弱です。一つのチームだけに依存する組織は、そのチームが崩壊したとき機能不全に陥ります。多様性の喪失は、システムの長期的な生存を脅かすのです。どう介入すればよいか。まず、競争構造を協力構造に変えることです。「どちらが勝つか」ではなく「両方を成功させる」という目標に転換します。次に、機会ベースの配分を行います。過去の成果ではなく、将来の可能性に基づいてリソースを配分するのです。意図的な多様性の維持も重要です。短期的な効率より、長期的な適応力を重視します。そして、定期的に初期条件をリセットします。「ゼロから再評価」の機会を設けるのです。このアーキタイプが示す重要な洞察は、「成功は能力よりも構造が決める」ということです。初期のわずかな差が、システムの構造によって増幅され、決定的な差になっていくのです。7. 予期せぬ敵対関係—協力者が敵になる罠パートナーが敵になる構造このアーキタイプは、本来は協力すべきパートナーが、互いの行動が相手を害していると誤解し、対立関係に陥るパターンです。構造:R1: Win-Winループ(意図)A の成功 ←→ 協力 ←→ Bの成功    ↑                    ↑    │  B2               │  B3   (−) Aの解決策       (−) Bの解決策    │  ↓               │  ↓    ↓  (意図せざる妨害) ↓Aの成功 ←────────────→ Bの成功         R4: 悪循環ループ(結果)フロントエンドとバックエンドの対立を考えてみましょう。双方ともユーザー価値を高めたいという意図があります。フロントエンドが表現力を高めるために複雑なAPIを要求すると、バックエンドの開発負荷が増大します。バックエンドがAPI設計をシンプルにすると、フロントエンドの表現力が制限されます。互いに「相手のせいで価値を出せない」と感じ、対立が深まっていくのです。品質保証チームと開発チームの対立も同様です。双方とも高品質な製品を届けたいという意図があります。QAが厳格なテストを実施すると、開発のリリース速度が低下します。開発がテストを簡略化するよう要求すると、品質が低下し、QAの目標達成が困難になります。互いに「相手が協力的でない」と感じるようになります。このアーキタイプは、対立を「誤解」の問題として扱っていますが、本当にそうでしょうか。フロントエンドとバックエンドの利害は、構造的に対立しているのではないか。QAと開発の目標は、本質的に矛盾しているのではないか。「共通の目標」という美しい理想を掲げても、現実には各チームには異なるKPIがあり、異なる評価基準があります。対立を「コミュニケーション不足」のせいにすることは、構造的な問題から目を逸らしているだけではないか。確かに、単なる「誤解」として片付けられない構造的な対立は存在します。フロントエンドとバックエンドが異なる上司に報告し、異なる評価基準で測られているなら、対立は必然です。このアーキタイプの深い洞察は、まさにその点にある。組織の構造が対立を生み出しているんだ。問題は個人の悪意や誤解ではなく、インセンティブ構造なのです。だからこそ、コミュニケーションだけでは不十分で、組織構造そのものを変える必要があるのです。例えば、フロントエンドとバックエンドを同じチームに統合する。QAと開発を共通の品質指標で評価する。こうした構造的な変更なしに、「協力しろ」と言っても意味がありません。どう介入すればよいか。まず、共通の目標を再確認します。「相手を打ち負かす」ではなく「共に成功する」という目標に立ち返るのです。しかし、これは単なる精神論ではなく、共通の評価指標を設定するという具体的な行動を伴う必要があります。次に、意図せざる妨害を可視化します。「私のこの行動が、相手にどんな影響を与えているか?」を明示的に確認します。一緒に解決策を設計することも重要です。一方的な解決策ではなく、双方の制約を理解した上での協働設計を行います。そして、定期的なコミュニケーションの場を設けます。問題が深刻化する前に、小さな違和感を話し合うのです。このアーキタイプが示す重要な洞察は、「善意から生まれる悲劇」です。誰も悪意はないのに、システムの構造が対立を生み出してしまうのです。8. 共有地の悲劇—個人合理性と集団非合理性個人合理性と集団非合理性の対立このアーキタイプは、複数の主体が共有資源を利用するシステムで、各個人にとって合理的な行動が、集団全体には非合理的な結果を生む構造です。構造:個人Aの資源利用 →(+) Aの利益 →(+) さらなる資源利用      ↑                                │      │                                │      └────────────────────────────────┘  R1:Aの利益最大化      個人Bの資源利用 →(+) Bの利益 →(+) さらなる資源利用      ↑                                │      │                                │      └────────────────────────────────┘  R2:Bの利益最大化      全員の利用の合計 →(+) 共有資源の枯渇 →(−) 全員の利益自分の時間とエネルギーという共有資源を考えてみましょう。仕事、家族、趣味、健康—すべてが「もっと時間を」と要求します。各領域の要求は個別には合理的です。しかし結果として、睡眠や休息が犠牲になり、燃え尽き症候群に陥ることがあります。コードベースという共有地も同様です。「納期があるから、とりあえず動くコードを書く」という各開発者の判断は、個別には合理的です。しかし結果として、コードが理解困難になり、全員の開発速度が低下していきます。「共有地の悲劇」は、私有財産制を正当化するために使われてきた概念ではないでしょうか。「共有資源は必ず枯渇する」という前提は、エリノア・オストロムの研究によって反証されています。実際、多くのコミュニティは何世代にもわたって共有資源を持続的に管理してきました。このアーキタイプは、人間の利己性を前提とし、協力や相互扶助の可能性を無視しているのではないか。確かに、オストロムの研究は、ルールとガバナンスがあれば共有資源は持続可能に管理できることを示しました。「共有地の悲劇」は必然ではなく、制度設計の失敗なのです。このアーキタイプの価値は、まさにその点にある。制度なしには共有資源は枯渇しやすいという警告なんだ。オストロムが示した持続可能な共有資源管理には、明確なルール、監視メカニズム、制裁システム、紛争解決手段が必要でした。つまり、意図的な設計と管理が不可欠なのです。このアーキタイプは「共有はダメだ」と言っているのではなく、「共有資源には意図的な管理が必要だ」と教えているのです。どう介入すればよいか。まず、資源の可視化が重要です。残量を表示し、「自分一人くらい」という錯覚を防ぎます。次に、利用ルールを設定します。各主体の利用に明示的な制限を設けるのです。フィードバックの直接化も効果的です。過剰利用の影響を、利用者に直接返します。そして、共同管理の仕組みを導入します。資源を共同で管理する仕組みを作り、「誰かがやるだろう」という心理を防ぐのです。このアーキタイプが示すシステム的洞察は重要です。個人の合理的行動の集積が、集団的には非合理的な結果を生むのです。個人システムの最適化だけでなく、大きなシステムの持続可能性を考慮することが、真に賢明な個人の行動なのです。目標管理の失敗—期待と現実のギャップ次の2つのアーキタイプは、目標設定と達成のプロセスで起こる典型的な罠です。9. バラバラの目標—対立する複数の目標複数の目標が互いを妨げる構造このアーキタイプは、複数の対立する目標を同時に追求しようとして、結局どれも達成できなくなるパターンです。構造:目標Aと現状のギャップ →(+) Aへの努力 →(+) Aの達成                                ↓                              (−)                                ↓目標Bと現状のギャップ ←────────┘      ↓     (+)      ↓   Bへの努力 →(+) Bの達成      ↓    (−)      ↓  目標Aの達成 ←────┘    B1:目標Aの追求  B2:目標Bの追求  互いに妨害し合うスピードと品質の両立を考えてみましょう。「素早くリリースする」という目標と「高品質を維持する」という目標があります。スピードを追求すると品質が下がり、品質を追求するとスピードが下がります。結果として、中途半端なスピードと中途半端な品質になってしまうのです。技術的負債の返済と新機能開発の両立も同様です。負債返済にリソースを使うと新機能が遅れ、新機能を優先すると負債が増えます。どちらも中途半端になります。「バラバラの目標」という表現は、ネガティブすぎないでしょうか。複数の目標を持つことは、組織の成熟の証ではないのか。スピードと品質、短期と長期、個人と組織—これらのバランスを取ることこそがマネジメントの本質ではないのか。このアーキタイプは、単一目標への集中を暗に推奨しているように見えますが、それは視野狭窄を招くのではないか。確かに、複雑な組織には複数の正当な目標が必要です。問題は複数の目標を持つこと自体ではなく、それらの間のトレードオフを認識せずに「すべて同時に最大化」しようとすることにあります。重要な洞察は、目標間の相互作用を理解することです。スピードと品質は必ずしも対立しません。自動化によって両立できることもあります。しかし、限られたリソースの中では、どこかで優先順位をつけざるを得ません。このアーキタイプが警告しているのは、トレードオフを認識せず、すべての目標を同時に最大化しようとする非現実的な期待です。成熟した組織は、複数の目標を持ちつつ、それらの動的なバランスを取ります。どう介入すればよいか。まず、優先順位を明確にすることです。すべてを同時に追求するのではなく、時期によって優先順位を変えるのです。次に、トレードオフを理解します。「すべてを同時に最大化」は不可能です。何を諦めるかを明確にします。目標の統合を探すことも重要です。対立を前提とせず、両方を満たす第三の道を探ります。例えば、「自動化による品質とスピードの両立」という統合的アプローチがあるかもしれません。そして、より上位の目標に立ち返ります。「なぜこれらの目標が必要なのか?」を問い、本質的な目標を再定義するのです。このアーキタイプが示す重要な洞察は、「すべてが重要」という考え方の罠です。何もかも追求しようとすると、結局何も達成できないのです。10. 目標のなし崩し—徐々に下がる基準目標が現状に引きずられて下がる構造このアーキタイプは、目標と現状のギャップに対して、現状を改善するのではなく、目標を下げることで対処してしまうパターンです。別名「ずり落ちる目標」「ゆでガエル症候群」とも呼ばれます。構造:パフォーマンスの目標 →(+) ギャップ認識 →(+) 改善努力         ↑                                    ↓         │                                   (+)      (遅延)                                  ↓         │                              実際のパフォーマンス         │                                    │         └←(+) プレッシャー ←(+) ギャップ ←(−)┘              ↓            (−)              ↓      目標の引き下げ (短期的な解決)            B1:改善努力のループ(正しい)      B2:目標引き下げのループ(安易な逃避)コードカバレッジの目標を考えてみましょう。当初は「テストカバレッジ80%を維持」という目標がありました。しかし忙しくて達成困難になると、「まあ、60%でいいか」と下げてしまいます。さらに「50%でも動いているし」となり、品質基準が徐々に劣化していくのです。リリースサイクルも同様です。当初は「2週間ごとにリリース」という目標がありました。しかし間に合わないと「3週間にしよう」と延ばし、さらに「1ヶ月でいいか」となります。開発速度が徐々に低下していきます。目標を柔軟に調整することは、適応力の表れではないでしょうか。80%のカバレッジが本当に必要かどうかは、プロジェクトの性質によります。盲目的に高い目標を維持することは、むしろ硬直性を生むのではないか。「目標のなし崩し」と「現実的な目標調整」の境界はどこにあるのか。このアーキタイプは、柔軟性を欠いた完璧主義を推奨しているように見えます。確かに、状況に応じて目標を調整することは必要です。問題は、調整が意図的か、それとも無意識の逃避かにあります。重要な区別があります。戦略的な目標調整は、新しい情報に基づいて意識的に行われます。「80%のカバレッジは過剰だと判明した。根拠を持って60%に調整する」これは健全です。一方、なし崩しは、達成困難さから逃れるために無意識に行われます。「忙しいから、とりあえず下げよう」これが問題なのです。このアーキタイプの本質は、基準を下げることの危険性ではなく、下げていることに気づかない危険性にあります。ゆでガエルの比喩が示すように、徐々の変化は認識されにくいのです。どう介入すればよいか。まず、絶対的な基準を設定することです。「競合他社より速い」という相対基準ではなく、「ユーザーが快適と感じる500ms」という絶対基準を持つのです。次に、外部ベンチマークとの比較を続けます。内部基準だけでなく、業界標準や競合と比較し続けます。ビジョンへの回帰も重要です。「なぜこの目標を設定したのか」という初心に立ち返るのです。目標の引き下げを可視化することも効果的です。変更履歴を記録し、「ずり落ち」を認識可能にします。そして、外部からの監視を入れます。外部の目(顧客、経営陣、第三者)を入れ、内部だけの判断を避けるのです。このアーキタイプは「ゆでガエル」の比喩で知られます。徐々に悪化する環境には気づきにくく、気づいたときには手遅れになっている。定期的な振り返りと、絶対的な基準の維持が重要なのです。競争のダイナミクス—エスカレートの構造11. エスカレート—報復の応酬互いの脅威認識が増幅する構造このアーキタイプは、互いに脅威と感じる行動を取り合い、報復がエスカレートしていくパターンです。軍拡競争、価格競争、誹謗中傷合戦などに見られます。構造:Aの相対的優位性 →(+) Aの脅威認識 →(+) Aの対抗行動      ↓                                    ↓    (−)                                  (−)      ↓                                    ↓Bの相対的優位性 ←────────────────────────┘      │     (+)      ↓Bの脅威認識 →(+) Bの対抗行動      │                ↓      └──────←(−)──────┘            B1:Aの防衛ループ      B2:Bの防衛ループ      R3:エスカレートの悪循環2つのチームの対立を考えてみましょう。チームAが「自分たちが主導権を持つべき」と主張すると、チームBが「自分たちの方が重要」と反論します。Aがさらに強く主張すると、Bがさらに反発します。組織が分断され、協力が不可能になり、プロジェクト全体が停滞していきます。技術選定の対立はさらに感情的になることがあります。エンジニアAが「React を使うべき」と主張すると、エンジニアBが「Vueの方が良い」と反論します。それぞれが相手の技術の欠点を指摘し合い、やがて人格攻撃に発展します。チームの雰囲気が悪化し、建設的な議論が不可能になるのです。ただ、競争は必ずしも悪じゃない。市場経済は競争によって効率化を達成してきた。技術選定での議論も、より良い選択につながることがあります。「エスカレート」を常に悪とする見方は、健全な競争や建設的な議論まで抑圧してしまうのではないか。いつ競争が「エスカレート」になるのか、その境界は曖昧ではないか。確かに、健全な競争と破壊的なエスカレートは異なります。問題は、競争そのものではなく、ゼロサム思考への転換です。健全な競争では、両者が切磋琢磨し、全体のレベルが上がります。一方、エスカレートでは、相手を打ち負かすこと自体が目的化し、全体が消耗します。技術選定での建設的な議論は、「どちらがこのプロジェクトに適しているか」を探ります。一方、エスカレートした対立では、「どちらが正しいか」を証明することが目的になります。境界は確かに曖昧ですが、重要な指標があります。相手の意見を聞く余裕があるか、共通の目標を見失っていないか、個人攻撃に発展していないか。これらが、健全な競争とエスカレートを分ける基準です。どう介入すればよいか。最も効果的なのは、どちらかが先に「攻撃的な行動」を止めることです。勇気が必要ですが、一方的な停戦が最も効果的です。共通の敵を作ることも効果的です。対立の構図を変え、「A対B」から「AとB対共通の課題」に転換するのです。競争ゲームを協力ゲームに変えることも重要です。ゼロサムではなく、両方が勝てる構造を設計します。第三者の介入も有効です。中立的な立場の人が仲介し、感情的なエスカレートを止めます。そして、より上位の目標を共有します。「どちらが正しいか」ではなく「ユーザーにとって何が最善か」という視点に立つのです。このアーキタイプが示す重要な洞察は、エスカレートが両者の「防衛」という認識から始まるということです。「相手が攻撃してきたから防衛する」という論理が、相手にとっては「攻撃」に見える。この非対称な認識がエスカレートを生むのです。長期的成長の失敗—投資不足の罠12. 成長と投資不足—自らが生み出す限界成長機会を投資不足で失う構造このアーキタイプは、成長に必要な投資(キャパシティへの投資)を怠り、パフォーマンスが低下し、需要が減少し、投資の必要性すら失われるという悪循環のパターンです。構造:需要 →(+) 成長の圧力 →(+) パフォーマンス改善  ↑                              ↓  │                             (+)  └←(+)─────────────────────キャパシティ                                  ↑                                (−)遅延                                  │                          投資 ←(−) パフォーマンス基準との不一致                                                    B1:成長のループ                          B2:投資のループ                          R3:投資不足の悪循環重要な構造的特徴を理解しましょう。成長が限界に近づくと、パフォーマンスが低下します。低下したパフォーマンスを見て「もう成長は終わった」と誤判断し、投資を控えます。投資不足により、さらにパフォーマンスが低下し、需要が減ります。「成長しない」と信じたことで、本当に成長しなくなる自己成就的予言が起きるのです。技術的負債の返済を考えてみましょう。ユーザーが増え、機能要求が増えるという成長があります。しかし技術的負債により開発速度が低下します。「新機能を優先すべき」と投資(リファクタリング)を後回しにすると、さらに開発速度が低下し、需要に応えられず、ユーザーが離れていきます。「どうせユーザーは減っている」と投資しなくなる悪循環に入るのです。インフラの増強も同様です。トラフィックが増加するという成長があります。しかしサーバーが限界に近づき、レスポンスが遅延します。「一時的な現象」と判断してインフラ投資を控えると、さらに遅延が悪化し、ユーザー体験が悪化し、ユーザーが離れていきます。「どうせユーザーは減っている」と投資しなくなるのです。もちろん、すべての低下が「投資不足」で説明できるわけじゃない。時には、製品が本当に市場のニーズを失っていることもある。衰退しているビジネスに投資を続けることは、「サンクコストの誤謬」ではないのか。このアーキタイプは、投資すれば必ず成長するという楽観主義に基づいていないか。撤退の判断を遅らせ、資源の浪費を正当化するために使われる危険性はないか。確かに、すべての衰退が投資不足によるものではありません。市場そのものが縮小していることもあれば、製品が時代遅れになっていることもあります。そして、撤退すべきタイミングを見極めることは、投資を続けることと同じくらい重要です。このアーキタイプが警告しているのは、投資不足による自己成就的予言だ。重要な区別は、外部要因による衰退か、内部の投資不足による衰退かを見極めることです。判断の基準があります。市場全体は成長しているか、競合は成長しているか、パフォーマンス低下の原因は何か。これらを分析することで、投資すべきか撤退すべきかを判断できます。このアーキタイプの真の価値は、早すぎる諦めを防ぐことにあります。一時的なパフォーマンス低下を見て「もうダメだ」と判断する前に、投資によって回復可能かを検討する。この視点が、本来救えたはずのシステムを救うのです。どう介入すればよいか。まず、将来を見据えた投資を行います。現在のパフォーマンスではなく、将来の需要を基準に投資を判断するのです。次に、先行指標を設定します。「ユーザー数」だけでなく「潜在的需要」「市場機会」を見ます。投資を可視化することも重要です。技術的負債、インフラ、人材育成への投資を、明示的に予算化します。長期的視点を制度化します。四半期だけでなく、3年後、5年後のビジョンで判断します。そして、成長への信念を維持します。一時的な低下に過剰反応せず、長期的な成長ストーリーを信じるのです。ただし、これは盲目的な楽観ではなく、データに基づいた信念である必要があります。「成長の限界」との違いに注意してください。「成長の限界」は外部の物理的制約により成長が止まるパターンです。一方、「成長と投資不足」は投資判断の失敗により、自ら成長を止めてしまうパターンなのです。このアーキタイプが示す重要な洞察は、自己成就的予言の危険性です。「成長しない」と信じて投資を控えると、本当に成長しなくなる。逆に、合理的な投資を続ければ、成長は再開できるのです。アーキタイプを見抜く技術これらのアーキタイプは、単独で現れることは稀です。実際のシステムでは、複数のアーキタイプが組み合わさっています。アーキタイプを見抜くには、プロセスがあります。まず、繰り返しのパターンに気づくことです。「またこの問題か」という違和感を大切にし、時系列でパターンを観察します。次に、氷山モデルで掘り下げます。出来事の背後にある構造を探り、パターンから構造へ、構造からメンタルモデルへと深掘りしていきます。そして、フィードバックループを描きます。因果関係を図示し、ループを特定します。強化ループ(R)とバランスループ(B)を識別するのです。既知のアーキタイプと照合します。「これは○○のパターンに似ている」と気づくことが重要です。完全一致を求める必要はありません。類似性を見るのです。最後に、効果的な介入ポイントを見つけます。アーキタイプの知見を活用し、レバレッジポイントを特定します。小さな変更で大きな影響を与えられる場所を探すのです。生成AIへの過度な依存を例に考えてみましょう。これは実は複数のアーキタイプの組み合わせです。思考プロセス(根本対処)をAI(症状対処)に置き換えるという「問題の転嫁」があります。AI使用という強化ループが思考力という制約にぶつかる「成長の限界」があります。AIを使える人とそうでない人の差が開くという「強者はますます強く」があります。そして、短期的な生産性向上が長期的な能力低下を生むという「うまくいかない解決策」もあります。このように、現実の問題は複雑です。しかし、個々のアーキタイプを理解していれば、複雑な問題も、既知のパターンの組み合わせとして理解できるようになるのです。おわりにシステムアーキタイプは、繰り返し現れる問題の構造パターンです。熟練したアーキテクトがシステム設計を見ただけでボトルネックを予測できるように、アーキタイプを理解すれば、問題の本質を素早く見抜けます。12のアーキタイプを振り返りましょう。好循環と悪循環は、変化の自己強化を示し、初期条件が未来を決めることを教えてくれます。バランス型プロセスと遅延は、調整の失敗を示し、時間遅延が過剰反応を生むことを教えてくれます。うまくいかない解決策は、短期的成功の罠を示し、副作用が問題を悪化させることを教えてくれます。問題のすり替わりは、根本解決の機会損失を示し、症状対処が根本対処を妨げることを教えてくれます。成長の限界は、自らを制限する構造を示し、制約の特定と緩和が鍵であることを教えてくれます。強者はますます強くは、資源配分の不均衡を示し、勝者総取りの構造を教えてくれます。予期せぬ敵対関係は、協力者が敵になる罠を示し、善意から生まれる悲劇を教えてくれます。共有地の悲劇は、個人合理性と集団非合理性の対立を示し、持続可能性の喪失を教えてくれます。バラバラの目標は、対立する複数の目標を示し、すべてを追うと何も得られないことを教えてくれます。目標のなし崩しは、徐々に下がる基準を示し、ゆでガエル症候群を教えてくれます。エスカレートは、報復の応酬を示し、防衛のつもりが攻撃に見えることを教えてくれます。成長と投資不足は、自らが生み出す限界を示し、自己成就的予言の危険性を教えてくれます。生成AI時代との関連を考えてみましょう。生成AIの普及は、新しい「問題の転嫁」「うまくいかない解決策」「成長の限界」のパターンを生み出しています。序章で述べた非対称性—生産と理解の乖離、生産量と成長の乖離、経験の量と学びの質の乖離—は、これらのアーキタイプとして現れています。アーキタイプの認識は、この構造的問題を見抜く力を与えてくれるのです。実践への第一歩は簡単です。繰り返される問題に直面したら、立ち止まって考えてみてください。「このパターン、どこかで見たな」と。そして、この記事で学んだアーキタイプの中に、似たものがないか探してみてください。完璧に当てはまらなくても構いません。構造を意識するだけで、見え方が変わります。システムアーキタイプは、先人たちの知恵の結晶です。同じ過ちを繰り返さず、効果的に問題を解決するための地図です。この地図を手に、複雑なシステムの世界を旅していきましょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Secret Managerと連携させてCloud RunにFastAPIサーバをデプロイしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/21a83f033f0990</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/21a83f033f0990</guid>
            <pubDate>Sun, 05 Oct 2025 09:53:35 GMT</pubDate>
            <content:encoded><![CDATA[今回は先日公開した以下のSecret Managerの使い方を応用して、Cloud Runにそのシークレットを読ませてサーバを公開してみました。https://zenn.dev/akasan/articles/f500badd1ed9bf システム構成今回の構成は以下のようになっています。Secret Managerにてシークレットを管理Artifact RegistryにてCloud RunサーバんじょDockerイメージ管理Cloud RunにてFastAPIサーバをデプロイ 実装開始 IaCの実装IaCのフォルダ構成は以下のようになっています。mai...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LlamaIndexに入門してみた]]></title>
            <link>https://zenn.dev/akasan/articles/01583bfccc8b73</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/01583bfccc8b73</guid>
            <pubDate>Sat, 04 Oct 2025 09:35:15 GMT</pubDate>
            <content:encoded><![CDATA[今回はLlamaIndexのStarter Tutorialを通して入門してみました。LlamaIndexとはどういうものか、そしてどのように使うかをまとめてみます。 LlamaIndexとは？LlamaIndexはLLMを利用したエージェントやワークフローを作るためのフレームワークになります。LlamaIndexはオートコンプリートやチャットぼっと、エージェントの実装など幅広いアプリケーション拘置機に利用できます。LlamaIndexは様々なツールを提供してくれます。データコネクター: ネイティブのソースとフォーマットから既存のデータを取り込めるデータ・インデックス: LL...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Spec DrivenでAI駆動開発を加速させる - Spec Kit入門]]></title>
            <link>https://zenn.dev/r4ynode/articles/spec-driven-development-using-spec-kit</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/spec-driven-development-using-spec-kit</guid>
            <pubDate>Fri, 03 Oct 2025 23:00:05 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAIに対して工夫なしの指示だと開発に限界を感じることもあるでしょう。AIにしっかりとコンテキストを渡してあげないと、意図通りに動いてくれません。考えられる解決策としては、自前でコンテキストや指示を書いたインストラクションMarkdownファイルを与える方法があります。個人的にはインストラクションの方が手軽なのでよくやりますが、先日以下の記事でSpec Drivenという言葉を見かけました。https://github.blog/ai-and-ml/generative-ai/spec-driven-development-with-ai-get-started-with...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Secret ManagerのシークレットをTerraformで作る方法について]]></title>
            <link>https://zenn.dev/akasan/articles/f500badd1ed9bf</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f500badd1ed9bf</guid>
            <pubDate>Fri, 03 Oct 2025 11:56:35 GMT</pubDate>
            <content:encoded><![CDATA[今回はTerraformを利用してGoogle CloudのSecret Managerのシークレットを登録する方法を調べてみました。 早速やってみる ディレクトリ構成まずは今回のディレクトリ構成になります。登録されるシークレットはsecret.txtに記載した内容を登録するようにしてみます。main.tfvariables.tfsecret.txtmodules/  secret-manager/    main.tf    variables.tf モジュールの実装まずはSecret Managerのモジュールを実装します。一つ目に変数を定義します。S...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DevOps/MLOpsに学ぶエージェントの可観測性]]></title>
            <link>https://speakerdeck.com/yunosukey/mlopsnixue-buezientonoke-guan-ce-xing</link>
            <guid isPermaLink="false">https://speakerdeck.com/yunosukey/mlopsnixue-buezientonoke-guan-ce-xing</guid>
            <pubDate>Fri, 03 Oct 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[2025年10月版読む予定本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/1c00ba13ed0cee</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1c00ba13ed0cee</guid>
            <pubDate>Thu, 02 Oct 2025 13:42:42 GMT</pubDate>
            <content:encoded><![CDATA[今年もはや10月になりましたね。先月に引き続き、今月も読む予定の本を共有していこうと思います！今月もいろんな本を読む予定にしているので、早速共有していきます！ Azure系 Microsoft Azure実践ガイドこちらはMicrosoft Azureの実践ガイドになります。現在案件でAzureを利用した開発をしており、今まで使ってこなかったので勉強するために読み始めました。私はKindle Unlimitedを利用しているのですがそちらの対象書籍になっているので、登録している方は無料で読むことができておすすめです！https://book.impress.co.jp/boo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeに数独の回答をさせるコードを考えさせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/8bd6a18cfb9baa</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/8bd6a18cfb9baa</guid>
            <pubDate>Wed, 01 Oct 2025 13:55:03 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日公開した記事の続編になります。昨日は数独の問題を自動で生成させるコードをclaude codeにて実装させましたが、今回はその問題ファイルを読み込んで計算させるコードを作らせてみました。昨日の記事は以下になりますのでぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/c4b6817e4de906 早速やってみる！ プロンプト！今回入力したプロンプトは以下になります。@problem_1.txt のようなフォーマットで入力される数独の回答を導くコードをPythonでかいて。結果はsolve_<ナンバリング>.tx...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[システム思考を日々の開発に取り入れる実践ガイド]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/01/203924</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/01/203924</guid>
            <pubDate>Wed, 01 Oct 2025 11:39:24 GMT</pubDate>
            <content:encoded><![CDATA[syu-m-5151.hatenablog.comはじめに前回の記事では、システム思考の基本的な概念—非線形性、関係性、反直感性、氷山モデル—を見てきました。システムをプラモデルではなく生態系として理解する視点を学びました。しかし、概念を知っているだけでは意味がありません。テニスの本を読んでもテニスができるようにならないように、システム思考も実践してこそ身につくものです。理論を学んだ今、次のステップは「どう実践するか」です。この記事では、日々の開発の中でシステム思考をどう使うかを具体的に解説します。取り上げるのは、自己認識の深め方、建設的な対話の作り方、フィードバックループの設計、パターンの見つけ方、そしてモデリングの実践です。これらはシステム思考の実践方法のほんの一部ですが、すべて明日から使える方法ばかりです。特別なツールや権限は必要ありません。新人エンジニアでも、今日から、今いるチームで始められます。大切なのは、小さく始めることです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。自己認識とメタ認知思考を改善するには、まず自分の思考に気づく必要があります。メタ思考～「頭のいい人」の思考法を身につける作者:澤円大和書房Amazon「なぜ私はこの解決策を選んだのか？」「どんな前提に基づいて判断しているのか？」「他の視点から見たらどうなるだろう？」システム思考の最良の開始方法は、最も身近なシステムである自分自身で練習することです。自分がどのように考え、決定し、行動しているかを観察することから始まります。これをメタ認知—自分の思考を客観的に見る力—と呼びます。ここで重要なのは、「問う」という行為の本質を理解することです。「問う」とは、実は「情報を編集する」という知的営みなのです。私たちは日々、膨大な情報に囲まれています。システムログ、エラーメッセージ、レビューコメント、仕様書、チャットの会話—これら無数の断片的な情報を、どう組み合わせ、どう意味づけるか。それが「問い」を立てるということです。問いの編集力 思考の「はじまり」を探究する作者:安藤昭子ディスカヴァー・トゥエンティワンAmazon「このバグはなぜ起きたのか」という問いは、エラーメッセージ、コードの履歴、環境設定、ユーザーの操作ログといった複数の情報を編集し、一つの物語として組み立てる作業です。「この設計で本当にいいのか」という問いは、要件、制約、技術的選択肢、チームの状況といった情報を再構成する試みです。そして、一人ひとりの編集力によって、その人ならではの内発する「問い」が生まれます。新人エンジニアのあなたが感じる違和感は、ベテランには見えない問いの種かもしれません。「なぜこの変数名はこんなに長いのだろう」「なぜこの処理は分散しているのだろう」—こうした素朴な疑問が、実はシステムの本質的な問題を指し示していることがある。問いが生まれるプロセスには、段階があります。まず「問い」の土壌をほぐす—これが自己認識です。自分がどんな前提で考えているか、どんな偏りを持っているか、どんな経験が判断に影響しているか。この土壌が固ければ、問いは芽を出せません。具体的にどう実践するか。何か技術を選ぶとき（フレームワーク、ライブラリ、設計パターン）、紙に書き出してみる。最初に思いついた選択肢は何か。なぜそれを思いついたのか—過去の経験？記事を読んだ？先輩に勧められた？他の選択肢は検討したか。最終的な判断の決め手は何だったか。ここで大切なのは、違和感に気づくことです。「なんとなくこの技術が良さそう」と思ったとき、その「なんとなく」の正体は何でしょうか。単に新しい技術を試したいだけではないか。本当にこのプロジェクトに適しているのか。この振り返りが、「問い」のタネを集めるプロセスです。自分の判断パターンや偏りに気づき、「本当にそうなのか？」という問いのタネが生まれる。次に、日々の仕事で何が重要で何がそうでないかを判断する練習をする。Slackの大量の通知、「緊急」と書かれているが実は緊急でないタスク、細かいコーディングスタイルの議論—これらはノイズかもしれない。一方で、ユーザーからの「使いにくい」という小さなフィードバック、システムログの中の見慣れないエラー、先輩の何気ない一言「このコード、後で問題になりそう」—これらがシグナル、つまり本当に重要な情報かもしれない。重要なのは、形式的なチェックリストに従うことではありません。自分の中に自然と湧き上がる問いに気づくことです。「このコード、なんか気持ち悪いな」という感覚。「この設計、本当にこれでいいのか？」という引っかかり。こうした違和感こそが、「問い」を発芽させるきっかけなのです。週末に5分だけ振り返りをしてみる。「今週、どれに時間を使ったか」「本当に重要だったのはどれか」。この練習で、重要なことを見抜く力が養われる。そして、新しい技術を学ぶとき、「これは難しすぎる」と思ったら、一歩引いて考えてみる。本当に難しいのか、それとも単に馴染みがないだけか。どの部分が理解できて、どの部分が理解できないか。理解できない理由は何か—前提知識の不足？説明が分かりにくい？この分析によって、「難しい」という漠然とした感覚が、「この部分の前提知識が足りない」という具体的な課題に変わる。これが「問い」が結像する瞬間です。このプロセス全体—土壌をほぐし、タネを集め、発芽させ、結像させる—が、「問いの編集力」です。これは「問う」という知的営みを、一人ひとりの編集力でアップデートするプロジェクトなのです。そして、この力こそが、システム全体をより良く理解し、設計する力につながります。ここで一つ、現代のエンジニアが直面する重要な課題について触れておきたい。生成AIは、確かに開発効率を飛躍的に高めてくれる。しかし、過度な利便性は、個人の成長に不可欠な「考える過程」を奪ってしまう危険性がある。「この関数、どう実装すればいいだろう？」という問いに直面したとき、すぐにAIに答えを求めるのは簡単だ。人は本質的に快適さを求め、最も抵抗の少ない道を選んでしまう。しかし、その「なぜこのアプローチを選ぶのか」「他にどんな選択肢があるのか」と自分で考える過程こそが、問いの編集力を育てる土壌なのだ。だからといって、AIを完全に排除すべきだという話ではない。重要なのは、将来の自分を妨げないよう、意図的に活用することだ。例えば、まず自分で5分考えてから、AIに相談する。AIの提案を受け取ったら、「なぜこのコードがそう書かれているのか」を理解しようとする。あるいは、実装の方向性を確認する用途には使うが、細部の実装は自分で書いてみる。こうした意図的な距離感が、創造性と成長を維持する鍵となる。システム思考を身につけるには、この「立ち止まって考える時間」が不可欠だ。便利なツールを使いながらも、自分で問いを立て、自分で考える習慣を意識的に守っていこう。自己認識を高めることは、単に自分を知ることではありません。自分ならではの問いを生み出せるようになることです。そして、その問いがシステムの本質に迫るとき、あなたは本当の意味でのシステム思考の実践者になっているのです。反応から応答へ誰かがアイデアを提案しました。あなたの最初の反応は「でも、それは...」かもしれません。ちょっと待ってください。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonシステム思考は、出来事への反応から、応答的な行動パターンへ、そして（改善された）システム構造の生成へと移行する能力です。そして、その第一歩が「まず受け止める」という姿勢です。開発現場では、しばしば「否定から入る」文化が見られます。新しい提案に対して、即座に「でも」「しかし」「それは無理だ」と反応してしまう。これは慎重さの表れかもしれませんが、建設的な対話を阻害してしまいます。まず受け止めるとは、相手のアイデアを即座に否定せず、その意図や背景を理解しようとすることです。これは合意することではありません。相手の視点を理解することと、それに同意することは別の話です。例えば、同僚が「このシステムをマイクロサービスに分割すべきだ」と提案したとします。否定的な反応は「でも、そんなことしたら複雑になるだけですよ」となるかもしれません。しかし、まず受け止めるアプローチでは「なるほど、マイクロサービス化することで独立したデプロイが可能になりますね。それを実現するには、サービス間の境界をどう定義するか考える必要がありそうです。現状の課題も含めて、一緒に検討してみませんか」といった形で応答します。この姿勢は、対立ではなく対話を生み出します。「私の考えを変えて」と要求するのではなく、「一緒に考えよう」という協働の場を作るのです。これこそが、システム思考に必要な姿勢なのです。まず受け止めることで、異なる視点を統合し、より豊かな解決策を生み出すための土台が作られます。相手のアイデアを否定するのではなく、それを出発点として、共に探求を深めていくのです。これは簡単なことではありません。特に、明らかに問題があると感じるアイデアに対して、まず受け止めるのは困難です。しかし、相手の視点を理解し、その上で建設的な方向に導くことで、より良い結果を生み出せるのです。「なぜそう考えたのか」を聞くことから始めましょう。その背景を理解すれば、本当の課題が見えてくることもあります。本当のゴールを見つける目標を抽象化して本質を見極めることから始めます。例えば「レガシーシステムをモダン化する」という目標の本質は何でしょうか？表面的には「古い技術を新しい技術に置き換える」と見えます。しかし、システム思考で考えると、本当の目的は「変更コストを下げ、新機能を素早く提供できる状態を作る」ことかもしれません。あるいは「属人化を解消し、チーム全体がシステムを理解できる状態を作る」ことかもしれません。この理想的な状態の定義が曖昧だと、どれだけ細かく分解しても、正しい方向に進めません。氷山モデルで言えば、最も深い層である「メンタルモデル」を明確にすることです。具体的には、次のような問いを立てます。「なぜこの目標が必要なのか？」という問いは、目標の背景にある本当の課題を浮き彫りにします。「達成したら、何が変わるのか？」という問いは、成功の姿を具体的にします。「誰にとっての価値を生み出すのか？」という問いは、ステークホルダーとその期待を明確にします。そして「この目標の成功は、どう測定できるのか？」という問いは、抽象的な理想を検証可能な基準に変換します。この問いに答えることで、漠然とした目標が、明確な理想状態に変わります。そして、この明確な理想状態こそが、すべての具体的な行動の羅針盤となるのです。具体と抽象作者:細谷 功dZERO（インプレス）Amazonシステム的推論知識労働者として、私たちは常に、形式的または非形式的に、アイデア、行動、理論を提案しています。「このアーキテクチャを採用すべきだ」「このツールを使うべきだ」「この方法で実装すべきだ」しかし、その提案に説得力を持たせるには、システム的推論が必要です。新人エンジニアのあなたも、日々の開発で「なぜこの方法を選んだのか」を説明する場面があるでしょう。例えば、納期が迫る中で「テストコードを書く時間がない」という意見に対して、どう考えますか？ここでシステム的推論が力を発揮します。単に「テストは重要だから書くべき」という原則論ではなく、システム全体への影響を考える。「確かに今週の納期は重要です。しかし、テストなしでリリースすると、本番環境でバグが発生する可能性が高まります。過去3ヶ月のデータを見ると、テストカバレッジが50%未満のコンポーネントは、平均して月2回の緊急修正が必要でした。各修正には平均4時間かかり、さらに顧客への説明や再リリースの手間も考えると、今2時間かけてテストを書く方が、トータルの工数は削減できます」このような推論には、信頼性（過去のデータに基づく）、関連性（現在の状況に直結）、結束性（理由が相互に補強し合う）、説得力（具体的な数値で示す）という要素が含まれています。重要なのは、メリット・デメリットを機械的に並べることではありません。システム全体の中で、この選択がどんな波及効果を生むかを考えることです。短期的なメリットが長期的なデメリットを生むかもしれない。一つの部分の最適化が、別の部分のボトルネックを作るかもしれない。こうした相互作用を含めて考えることが、システム的推論なのです。日本の開発現場でよくある「仕様変更」への対応も、システム的推論で考えると違って見えます。「また仕様変更か...」と嘆くのではなく、「この仕様変更のパターンから、顧客が本当に求めているものが見えてきた。次回から、初期段階でプロトタイプを見せて早めにフィードバックをもらう仕組みを提案してみよう」という建設的な提案につなげられるのです。なぜあの人の解決策はいつもうまくいくのか?―小さな力で大きく動かす!システム思考の上手な使い方作者:枝廣 淳子,小田 理一郎東洋経済新報社Amazon目標を構造化する技術理想的な状態が定義できたら、そこに至る道筋を設計します。ここで重要なのが、4つの視点で構造化するという考え方です。1. 時間を構造化する時間は最も重要な制約です。そして、制約こそが価値を生み出します。現実を直視しましょう。無限に時間があれば、そこそこ良いものは作れます。しかし、それでは意味がありません。永遠にリファクタリングを続け、完璧な設計を追求し、すべてのエッジケースに対応する—そんな仕事に価値はないのです。締め切りがあるからこそ、私たちは本質に集中します。何が本当に重要で、何が単なる理想なのかを見極めます。締め切り駆動こそが、本当の仕事なのです。だからこそ、締め切りを味方にする技術が必要です。3ヶ月後という最終締め切りがあるなら、3ヶ月先まで何もしないのではなく、中間地点を意図的に設計します。重要なのは、単に時間を等分するのではなく、意味のあるマイルストーンを設定することです。「1週間後にプロトタイプで検証」「2週間後にチームでレビュー」「1ヶ月後に本実装開始」というように、各地点で何を達成し、何を学ぶのかを明確にします。各マイルストーンが小さな締め切りとなり、あなたを前進させます。そして、日にちではなく日時で決めることです。「来週中」ではなく「水曜日の15時まで」。さらに、他者と約束することで強制力を持たせます。「水曜のミーティングで進捗を共有します」と宣言することで、逃げ場のないコミットメントが生まれます。この適度なプレッシャーが、フィードバックループを回し続けるのです。2. 複雑さを分割する大きな問題を前にしたとき、全体を一度に理解しようとするのは無謀です。それは不可能であるだけでなく、非効率でもあります。現実の開発では、完全な理解を待っている余裕はありません。不完全な理解のまま前に進み、動きながら理解を深めていく。これが実践です。しかし、闇雲に進むわけではありません。今この瞬間に何に集中すべきかを明確にする必要があります。ここで重要なのは、複雑さには構造があるということです。どんな複雑な問題も、認識のプロセスという観点から段階に分解できます。認識の段階で分割するシステムアーキテクチャの設計という大きなタスクを考えます。これは、認識の深さによって段階に分解できます。最初の段階は「理解する」こと。既存のシステムがどう動いているかを把握します。次の段階は「分析する」こと。何が問題で、何が改善の機会なのかを特定します。その次は「探索する」こと。複数の解決策を考え、比較します。さらに進んで「決定する」こと。最適な方向性を選択します。最後に「実装する」こと。具体的な設計を作り上げます。この段階分けの本質は、各段階で問う質問が異なるということです。理解の段階では「これは何をしているのか？」と問います。分析の段階では「何が問題なのか？」と問います。探索の段階では「他にどんな方法があるか？」と問います。決定の段階では「どれを選ぶべきか？」と問います。実装の段階では「どう作るか？」と問います。これらの質問を同時に考えようとすると、頭が混乱します。「これは何をしているのか」を理解する前に「どう作るか」を考え始めると、理解が浅いまま実装に進んでしまいます。だから、今はどの質問に答えるべきかを明確にするのです。認知的な負荷で分割する各段階の中でも、さらに認知的な負荷を下げる工夫が必要です。「既存システムを理解する」という段階を考えます。これをいきなり「理解しよう」とすると、脳が過負荷になります。だから、行動を段階的に組み立てます。最初は受動的観察から始めます。まず2時間、コードを読む。この段階では理解を求めません。ただ情報を浴びるだけです。次に、浴びた情報から湧き上がった疑問を記録します。10個ほど疑問点をリストアップします。ここで初めて、受動的から能動的に切り替わります。その次に、記録した疑問を構造化します。技術的な疑問、ビジネス的な疑問、歴史的な疑問などにカテゴリ分けします。構造が見えたら、優先順位をつけます。最も重要な疑問を3つ選びます。そして最後に、その3つについて集中的に調査します。深い探索に入るわけです。なぜこの順番なのか？最初から「理解しながら読む」のは負荷が高すぎます。だから、まず受動的に情報を浴びる。負荷が低い状態から始めます。次に、浴びた情報から湧き上がった疑問を記録する。少し負荷が上がります。記録した疑問を整理して構造を見出す。さらに負荷が上がります。構造の中から優先順位を決める。そして初めて、深い理解のための調査に入る。最も負荷の高い活動です。このパターンの本質は、認知的な負荷を段階的に上げていくことです。脳は急激な負荷の変化に弱いですが、段階的な上昇には対応できます。自己完結性で分割するさらに、タスクには「自分だけで完結する部分」と「他者との関係が必要な部分」があります。これも分離して考える必要があります。例えば、「既存システムを理解する」の中で、自分だけでできることがあります。コードを読む、ドキュメントを読む、動かしてみる。これらは好きな時間に進められます。一方で、他者が必要なこともあります。設計の意図を聞く、過去の経緯を知る、暗黙の制約を確認する。これらは相手の都合を調整する必要があります。この区別が重要なのは、スケジューリングの戦略が異なるからです。自分だけでできることは、今日の夜でも、週末でも進められます。他者が必要なことは、早めに「誰に何を聞くべきか」を特定し、スケジュールを調整します。この区別をしないと、「調査は進んだけど、肝心なことを聞く相手が来週まで不在」という事態に陥ります。完璧な理解という幻想を捨てる最後に、最も重要な認識があります。完全な理解は存在しないということです。システムは複雑すぎて、すべてを理解することは不可能です。そして、理解が不完全でも、前に進むことはできます。重要なのは、「今の決定に必要な理解は何か」を見極めることです。「このAPIの実装を変更する」という決定には、APIの仕様と依存関係の理解が必要です。しかし、そのAPIが内部でどのアルゴリズムを使っているかまで理解する必要はないかもしれません。決定に必要な解像度で理解する。これが、複雑さを効率的に分割する鍵なのです。すべてを理解しようとすれば、永遠に理解のフェーズから抜け出せません。今の決定に必要な部分だけを、必要な深さで理解する。この割り切りが、現実の開発では不可欠です。3. 成果を定義する進捗を確認できなければ、正しい方向に進んでいるか分かりません。そして、確認できない進捗は、存在しないのと同じです。完璧主義は行動を妨げます。「完璧な設計書ができるまで実装を始めない」「すべてを理解してから手を動かす」—こうした態度は、実際には何も生み出しません。現実の開発では、不完全な成果を積み重ねながら前進します。だから、各段階で検証可能な成果物を定義します。完璧な成果物である必要はありません。むしろ、段階的な品質目標を設定します。最初は30%の理解で構いません。「全体像がぼんやり見える」程度で十分。この段階では、箇条書きのメモや疑問点のリストが成果物です。次に60%を目指します。「主要な構成要素と関係性が分かる」レベル。この段階では、ざっくりした図や主要な依存関係の整理が成果物です。そして80%、95%と段階的に精度を上げていきます。80%地点では、詳細な設計ドキュメントや実装計画が成果物になります。この段階的アプローチの真の価値は、早い段階でフィードバックを得られることです。30%の理解の時点で「方向性が間違っている」と気づけば、大きな手戻りを避けられます。完璧を目指して3ヶ月かけた後に方向性の誤りに気づくより、1週間で30%の成果を出して軌道修正する方が、はるかに賢明です。これがフィードバックループの設計です。小さく、速く、頻繁に。完璧ではなく、十分に良いものを、今日出す。4. 制約を明らかにするタスクは孤立して存在しません。そして、この事実を無視することは、失敗への近道です。現実の開発では、すべてのタスクが何かに依存しています。しかし、この依存関係は技術的なものだけではありません。むしろ、最も予測困難で致命的な依存関係は、人間の意思決定、暗黙の了解、組織の期待といった、目に見えない制約なのです。技術的な依存関係まず、明示的な技術的依存関係があります。これは比較的見つけやすい。この機能は認証システムに依存している。データベーススキーマの変更が必要。既存のAPIとの互換性を保つ必要がある。UIチームとの調整が必要。これらは図に描きやすく、「認証システムの理解が先」「スキーマ変更は早めに合意が必要」「UI設計は並行で進められる」といった戦略を立てられます。意思決定への依存関係しかし、より厄介なのは誰かの判断を待つ必要があるという依存関係です。この設計変更は、シニアエンジニアの承認が必要。この機能の優先順位は、プロダクトマネージャーの判断待ち。この技術選定は、セキュリティチームのレビューが必要。この仕様変更は、顧客への確認が必要。これらの依存関係が見えていないと、「実装は完了したのに、承認待ちで2週間止まっている」という事態に陥ります。そして、承認者が「そもそもこのアプローチは違う」と言い出せば、すべてが水の泡です。だから、早い段階で「誰の判断が必要か」「いつまでに確認を取るべきか」を明確にします。実装を始める前に、方向性の合意を取る。これだけで、大きな手戻りを避けられます。暗黙の了解への依存関係さらに難しいのが、チームや組織の暗黙の了解という制約です。「金曜日にはデプロイしない」というチームの不文律。「この部分のコードは○○さんしか触らない」という暗黙の領域分担。「新しいライブラリの導入は慎重に」という組織の雰囲気。「テストカバレッジは80%以上」という暗黙の品質基準。これらは明文化されていないため、新人エンジニアには見えません。しかし、この暗黙の制約に気づかずに進めると、「なぜ勝手に進めたんだ」と後から怒られることになります。この制約を明らかにするには、先輩に聞くしかありません。「このタスク、何か気をつけることありますか？」「この変更、誰かに相談した方がいいですか？」こうした質問が、暗黙の制約を顕在化させます。期待への依存関係最後に、最も主観的で曖昧な制約が他者の期待です。マネージャーは「2週間で完了する」と期待している。チームメンバーは「ドキュメントも一緒に更新される」と期待している。レビュアーは「テストコードも書かれている」と期待している。ユーザーは「UIは直感的である」と期待している。これらの期待は、しばしば明示的に伝えられません。しかし、期待に応えられないと、「思っていたのと違う」という不満が生まれます。期待を明らかにするには、早めに確認することです。「このタスク、どのレベルまで求められていますか？」「ドキュメントの更新も含めますか？」「いつまでに完了すればいいですか？」こうした質問で、期待のギャップを埋めます。制約を味方にする依存関係を明らかにすることは、ボトルネックの早期発見につながります。「このタスクは3人の承認が必要」と分かれば、並行で相談を始められます。「先輩が来週休暇」と分かれば、今週中に必要な情報を得ておきます。「この変更は影響範囲が広い」と分かれば、段階的なリリース計画を立てます。制約を敵視してはいけません。制約は現実です。そして、現実を直視することから、実行可能な計画が生まれるのです。見えない制約に後から気づいて慌てるより、最初から制約を前提に計画を立てる方が、はるかに賢明です。技術的な依存関係だけでなく、人間の意思決定、暗黙の了解、期待という目に見えない制約まで含めて考える。これが、現実の開発で生き残るための知恵なのです。実行可能な最小単位への変換ここが最も重要です。どれだけ丁寧に構造化しても、自分の現在のスキルと時間で実行できないなら、まだ抽象的すぎるのです。そして、これは単なる技術的な問題ではありません。心理的な問題でもあります。大きなタスクを前にしたとき、私たちは無意識に身構えます。「このタスクを完璧にこなすには、相当な気持ちの力が必要だ」と。その気持ちのハードルが高すぎて、結局何も始められない。先延ばしが続き、締め切り直前に慌てる。この悪循環を断ち切るには、最初の一歩のハードルを極限まで下げる必要があります。例えば、疲れて帰宅したとき。「お風呂にしっかり入浴しなきゃ」と思うと、それだけで億劫になります。でも「とりあえずシャワーだけ浴びよう」と思えば、動き出せます。そして実際にシャワーを浴び始めると、「あ、意外と平気だな。湯船にも浸かろうかな」となることも多い。完璧を目指さず、最小限から始める。この思考が、行動を生み出すのです。開発も同じです。「この一歩は、今日の30分で完了できるか？」と自問してください。答えがNoなら、さらに具体化します。「30分で完了できる最小の行動は何か？」を考えるのです。例えば、新しいフレームワークを学ぶとき。「Reactを学ぶ」は抽象的すぎます。「Reactの基礎を学ぶ」もまだ抽象的です。「Reactの公式チュートリアルの第1章を読む（30分）」なら実行可能です。「完璧に理解しよう」ではなく「まず読んでみよう」。「最適な設計をしよう」ではなく「ラフなスケッチを描こう」。「全部調べよう」ではなく「5分だけ調べよう」。この「実行可能な最小単位」への変換により、圧倒的な目標が、今すぐ始められる行動に変わります。そして一度動き出せば、継続するのは意外と簡単です。始めることが最大のハードルなのです。これは自分に優しくするということでもあります。「完璧にできないなら、やらない方がマシ」という思考は、結局何も生み出しません。「不完全でも、今日少しだけでも前進する」という姿勢が、長期的には大きな成果につながります。メンタル的にも、この小さな成功体験の積み重ねが重要です。「30分で第1章を読めた」という小さな達成感が、次の一歩への推進力になります。完璧主義で動けないより、不完全でも動き続ける方が、はるかに健全で生産的です。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazonシステム思考との統合この「目標を構造化する技術」は、システム思考の実践そのものです。線形思考では「Aを完璧に終わらせてからBに進む」となります。しかし、これは現実的ではありません。Aを完璧にする頃には、Bの前提条件が変わっているかもしれません。市場が変化しているかもしれません。完璧を待つ余裕は、現実にはないのです。システム思考では小さなサイクルを回しながら学習するアプローチを取ります。30%の理解でまず動く。フィードバックを得る。それを元に次の30%を積み上げる。このフィードバックループが、不確実性の中での確実な前進を可能にします。そして重要なのは、この構造化のプロセス自体が学習であるということです。目標をどう分解するか考えることで、システムの構造が見えてくる。どこにレバレッジポイントがあるかが分かってくる。抽象的だった問題が、具体的な課題に変わっていく。新人エンジニアのあなたは、「自分にはまだ大きなことはできない」と思うかもしれません。しかし、逆です。大きなことができる人間などいません。いるのは、大きなことを小さく分解して、一歩ずつ進める人間だけです。その力さえあれば、いずれどんな大きな目標にも到達できます。明日、大きなタスクに圧倒されたら、紙とペンを持ってきてください。そのタスクを「時間を構造化する」「複雑さを分割する」「成果を定義する」「制約を明らかにする」の4つの視点で整理してみてください。そして、今日の30分でできる最小の行動を見つけてください。その一歩が、システム思考の実践の始まりです。完璧な計画ではなく、不完全でも今日動き出すこと。それが、本当の意味での第一歩なのです。フィードバックループの設計フィードバックループは私たちの考え方を強化します。良いフィードバックループは学習と改善を促進し、悪いフィードバックループは問題を固定化します。日本の開発現場でよく見かける「レビュー地獄」を考えてみましょう。コードレビューで細かい指摘が山のように来て、修正しては再レビュー、また修正しては再レビュー...。これは悪いフィードバックループの典型例です。なぜこうなるのでしょうか？レビュアーは「完璧なコード」を求め、レビュイーは「早く承認が欲しい」。この対立構造が、建設的でないフィードバックループを生み出しています。では、どう改善するか？まず、レビュイーであるあなたができることがある。PRの説明文に、単に「何を変更したか」だけでなく、「なぜこの変更が必要か」「何を解決しようとしているか」という意図を書く。そして、「他にどんな方法を検討したか」「なぜこの実装を選んだか」という設計判断を明記する。さらに、「ここは自信がない」「この部分、より良い方法があれば教えてほしい」という懸念点を正直に伝える。例えば、こんな風に書く：「ユーザーからの『検索が遅い』というフィードバックに対応しました。全文検索エンジンの導入も検討しましたが、今回は工数とのバランスを考えてインデックスの追加で対応しています。効果が見込め、リスクも低いと判断しました。ただし、N+1クエリになっている箇所があるかもしれません。パフォーマンステストはローカルのみです」。この説明があると、レビュアーはあなたの思考プロセスを理解でき、より建設的なコメントができる。レビュアー側も工夫できる。コメントにレベルを付けると、何が重要かが明確になる。例えば「🔴必須：セキュリティの問題」「🟡推奨：より良い実装方法の提案」「🔵参考：将来の改善案」という分類をすれば、レビュイーも「必ず直さなければならない」プレッシャーなく、建設的に受け取れる。「🟡推奨：ここはmapよりfilterの方が意図が明確になると思います」というコメントなら、対話が生まれる。もう一つの例として、レガシーコードの改善を考えてみよう。「このコードは触りたくない」という恐怖から、誰も手を付けず、ますます理解困難になる。これを打破するには、小さな改善と学びの記録というフィードバックループを作る。まず、小さなリファクタリング—1行の変数名変更でも良い—をする。その際、気づいたことをコメントかドキュメントに残す。次回触る人のために「ここは○○という理由で複雑」と書いておく。この積み重ねで、徐々にコードの理解が広がり、改善のハードルが下がっていく。新人エンジニアのあなたにできることは、自分のPRに「なぜこの実装を選んだか」「他に検討した選択肢」「懸念点」を明記することです。これによって、レビュアーはあなたの思考プロセスを理解し、より建設的なフィードバックを提供できるようになります。そして、それがチーム全体の学習を促進するのです。みんなのフィードバック大全作者:三村 真宗光文社Amazonパターン思考パターン思考は、出来事がどのように発生するかだけでなく、関係性がどのように効果を生み出すかを理解することです。新人エンジニアの日常で、こんなパターンに気づいたことはありませんか？月末になると必ずシステムが重くなる。調査すると、月次レポートのバッチ処理が原因だと分かる。でも、本当にそれだけでしょうか？よく観察すると、月末は営業チームのアクセスも増え、マーケティングチームのキャンペーンも集中し、経理のデータ抽出も重なっている。個々の要因は問題なくても、組み合わさると臨界点を超える。これがパターンです。日本の開発現場特有のパターンもあります。納期が近づくと、テストを省略し、コードレビューが形骸化し、ドキュメントの更新が止まる。その結果、リリース後に問題が頻発し、緊急対応に追われ、次の開発が遅れ、また納期に追われる...。これは負のスパイラルパターンです。では、パターンをどう見つけ、どう対応するか？まず、感覚ではなくデータで確認することが大切です。例えば、「納期2週間前からのコミット数」をグラフ化したり、「レビューコメント数」の推移を記録したり、「テスト実行時間」の変化を追跡したりする。Google SpreadsheetやNotionで簡単な表を作るだけでも、パターンが見えてきます。次に、パターンを3つのタイプから考えてみる。外部要因が影響する外部パターンとして、四半期末の駆け込み需要、年度末の仕様確定ラッシュ、イベント時のアクセス集中などがある。システム内部の問題である技術システムのパターンとして、特定の時間帯のトラフィック集中、定期的なメモリリーク、データ量が増えると遅くなる処理などがある。そしてチームの働き方に起因するプロセスパターンとして、週明けの障害報告増加、金曜リリースの失敗率上昇、特定のメンバーが休むと進まないタスクなどがある。このように分類することで、どこに問題の根があるのかが見えてくる。パターンを見つけたら、変えるための小さな実験を始めます。例えば「金曜リリースの失敗率が高い」というパターンがあったら、木曜リリースに変えてみたり、金曜は小規模な変更のみにしてみたりする。1ヶ月試してデータを取り、どちらが効果的か検証する。完璧な解決策を求めるのではなく、「とりあえず1週間やってみよう」という軽い気持ちで始めることが大切です。あなたのチームにも必ずパターンがあります。「いつも同じところでつまずく」「なぜか特定の機能の修正は想定の3倍かかる」。これらは偶然ではなく、システムが生み出すパターンなのです。パターンを見つけたら、「なぜこのパターンが生まれるのか」を問い、そしてパターンを変えるための小さな実験を始めるのです。類似と思考　改訂版 (ちくま学芸文庫)作者:鈴木宏昭筑摩書房Amazonモデリングモデリングは、私たちの心の中の考えと、それらの間の関係を可視化することです。 speakerdeck.comホワイトボードに図を描いたことがあるでしょう。それがモデリングの始まりです。しかし、「システム思考」は、チームで一緒にモデリングすることで初めて力を発揮します。重要なのは、何をモデル化するかよりも、どのようにモデル化するかです。モデルは会話の道具です。完璧な図を作ることが目的ではなく、チーム全体で共通の理解を作ることが目的なのです。新人エンジニアでもできる簡単なモデリングがある。新しい機能を追加するとき、5分だけ時間を取って紙に描いてみる。この機能は、どのモジュールを使うか？どのデータベーステーブルを読み書きするか？他のどの機能に影響するか？例えば、「新機能」から「認証モジュール」「ユーザーDB」「ログ機能」に矢印を引いてみる。そして気づく—「あ、ログ機能を変えると他にも影響が出るな」と。この簡単な図を描くことで、思わぬ依存関係が見えてくる。チームでシステムアーキテクチャを議論するときは、各メンバーが頭の中に持っているモデルは微妙に異なっています。これを可視化することで、誤解が明らかになる。実際の進め方は簡単だ。各自が5分で「システムの全体像」を紙に描き、それを見せ合い、違いを話し合う。「え、僕はこのAPIを直接叩いていると思っていたけど、実はキャッシュ層があったんだ」といった発見が必ずある。モデルを描くとき、3つの質問を考えるといい。まず「このシステムの目的は何か？」—例えば「ユーザーが商品を素早く見つけられること」。次に「誰にとっての価値を生み出しているのか？」—例えば「エンドユーザー」「営業チーム」「データ分析チーム」。そして「どんな制約があるのか？」—例えば「レスポンスは1秒以内」「既存のレガシーDBと連携が必要」。これらの質問に答えることで、単なる「構成図」ではなく、「なぜそうなっているか」が分かるモデルになる。ツールは何でもいい。ホワイトボード、紙とペン、MiroやFigJam（オンラインホワイトボード）、PlantUMLやMermaid（コードで図を描く）、PowerPointやGoogle Slides。どんなツールでも構わない。完璧なモデルを作ることが目的ではありません。モデリングのプロセスを通じて、チーム全体の理解を深め、より良い意思決定ができるようになることが目的なのです。あなたが明日から始められることは、コードを書く前に5分だけホワイトボード（または紙）に図を描くことです。それをSlackに貼って「この理解で合ってますか？」と聞くだけでも、大きな価値があります。システムリーダーシップシステムリーダーシップとは、役職や権限の話ではありません。システムリーダーシップは、私たちがいつでも実践できるものです。線形と非線形のアプローチの違いを識別し、状況に最も適したマインドセットを選択すること。社会技術的部分間の健全な関係を奨励すること。解決策をシステムの目標と目的につなげ続けること。積極的に視点をシフトし、複数の視点から課題を見ること。曖昧さへの寛容を表現すること。これらは、ジュニアエンジニアでも、シニアエンジニアでも、誰でも実践できることです。システムリーダーシップは統合的リーダーシップであり、変化のエコロジーを開発することです。階層は管理構造ではなくコミュニケーション構造です。より高いレベルの機能は、より低いレベルの活動のニーズに奉仕します（その逆ではありません）。最も価値のある貢献は、レバレッジポイントの発見です。これらは、パターンと関係に介入する場所です。小さな変更で大きな影響を与えられる場所を見つけることが、システムリーダーの重要な役割です。戦略の要諦 (日本経済新聞出版)作者:リチャード・Ｐ・ルメルト日経BPAmazon成功の再定義システムの観点から、成功はシステムを支配することではなく、その中で繁栄することによって測定されます。従来の成功の定義は、「計画通りに完了した」「バグがゼロになった」「パフォーマンス目標を達成した」といったものでした。これらも重要ですが、システム思考の観点からは不十分です。成功したシステムには、異なる特徴があります。制約の有効化とは、システムが全体のニーズに奉仕しながらスケールすることを可能にする成長または影響の制限です。無制限の成長は破綻を招きます。適切な制約があることで、持続可能な成長が可能になります。根本原因の解決は、介入依存（根本的な問題を解決する代わりに修正やバンドエイドを適用すること）を避けることです。症状に対処するのではなく、原因に対処することで、同じ問題の再発を防げます。影響の均等化において、成功したシステムは、利点と特権の影響を均等化します。一部のコンポーネントやチームだけが恩恵を受けるのではなく、全体が公平に価値を享受できるシステムが、長期的に成功します。知識フローの生成は最も重要かもしれません。システムの知識フローが多いほど、透明性が高いほど、そのシステムの成功の可能性が高くなります。情報が自由に流れ、学習が共有され、失敗が隠されない文化が、システムの進化を促進するのです。これらの新しい成功の基準は、短期的な目標達成よりも、長期的な持続可能性と適応力を重視します。システムは生き物のように成長し、変化し、進化するものだからです。失敗できる組織作者:エイミー・C・エドモンドソン早川書房Amazonまとめ前回の記事でシステム思考の基本概念を学び、今回は実践の方法を見てきました。その旅を通じて改めて感じるのは、システム思考は単なる技術ではなく、現代を生きるための基本的な教養だということです。個々の技術力は依然として重要です。しかし、それだけでは複雑化する課題に対応できません。目の前のコードから視線を上げ、全体の中での位置づけを理解し、相互作用を設計する—これがシステム思考なのです。ドネラ・メドウズは言いました。「私たちはシステムを制御したり、理解したりすることはできません。しかし、それらと踊ることはできます！」この美しい比喩は、システム思考の本質を表しています。完全な制御を求めるのではなく、システムと調和し、共に進化していく。完璧な設計図を描いてから実装するのではなく、対話しながら進化させていく。予期せぬ振る舞いを「バグ」として排除するのではなく、フィードバックとして学習する。この姿勢の転換が、真に価値のあるソフトウェアシステムを生み出します。この記事で紹介した実践は、すべて明日から使えるものです。自己認識とメタ認知で、自分ならではの問いを生み出す土壌を耕すこと。違和感に気づき、「なぜ？」と問い続けることで、問いの編集力を磨いていく。反応から応答への転換で、即座に否定するのではなく、まず受け止めることから対話を始める。「でも」ではなく「なるほど、では」と応答する習慣が、チームの知恵を引き出します。目標の構造化で、圧倒的なタスクを実行可能な最小単位に変換する。時間を構造化し、複雑さを分割し、成果を定義し、制約を明らかにする。そして何より、「今日の30分でできること」に落とし込む。フィードバックループの設計で、小さく、速く、頻繁に学習する仕組みを作る。PRに「なぜ」を書き、レビューに段階を付け、小さな改善を積み重ねていく。パターン思考で、繰り返される問題の背後にある構造を見抜く。データで確認し、小さな実験で変化を試みる。モデリングで、見えない構造を可視化し、チームで共通理解を作る。完璧な図ではなく、5分で描いたラフなスケッチでも、対話の価値は十分にあります。これらの概念を完璧に理解する必要はありません。「あ、これは問いの編集で考えられるかも」と思い出すだけで、視点が変わります。明日のコードレビューで「このコードは他のどこに影響するだろう？」と問いかけてみてください。バグを修正するとき、「このバグ、前にも似たようなことがあったな」という違和感を大切にしてください。新しい機能を実装する前に、5分だけ紙に依存関係を描いてみてください。新人エンジニアだからこそ持てる「なぜ？」という素朴な疑問が、ベテランが見落としているシステムの問題を発見する鍵になることがあります。「そういうものだ」と受け入れられていることに「でも、なぜ？」と問う勇気を持ってください。今日から、目の前の木だけでなく、森全体を見る練習を始めましょう。制御ではなく調和を、固定ではなく適応を、確実性ではなく学習を選ぶ。きっと、今まで見えなかった景色が見えてきます。最後に、最も大切なことを。システム思考は完璧主義ではありません。「すべてを理解してから行動する」のではなく、「小さく始めて、学びながら改善する」ことを大切にします。だから、この記事を読んで「難しそう」と感じても大丈夫です。まずは一つだけ、明日から実践してみてください。それで十分です。そして、この記事に書いてあることがすべてではありません。システム思考の実践は、あなた自身の経験の中で深まり、独自の形を取っていくものです。一緒にシステムと踊り始めましょう。システムの科学 第3版作者:ハーバート・Ａ・サイモンパーソナルメディアAmazon]]></content:encoded>
        </item>
    </channel>
</rss>