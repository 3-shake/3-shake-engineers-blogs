<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 04 Jul 2023 08:07:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[2023年7月版キャッシュレス生活まとめ]]></title>
            <link>https://pranc1ngpegasus.hatenablog.com/entry/2023/07/04/162557?utm_source=feed</link>
            <guid>https://pranc1ngpegasus.hatenablog.com/entry/2023/07/04/162557?utm_source=feed</guid>
            <pubDate>Tue, 04 Jul 2023 07:25:57 GMT</pubDate>
            <content:encoded><![CDATA[前回からだいぶ変わったので更新。pranc1ngpegasus.hatenablog.com図および下記文章における「夫」は筆者を指す。主なアップデート内容夫が副業として個人事業を開業しましたメインのクレジットカードがプラチナプリファードになりましたSBI証券へのつみたてNISA入金経路がハイブリッド預金経由になりました妻がiDeCoをはじめました2023年に生まれた第二子を追加しましたまとめメインのクレジットカードをプラチナプリファードに変更しました。ポイント還元率が高い加盟店が我が家がよく使う加盟店だったので嬉しいかぎりです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[光に負けルナ~Google Cloudでのマルチリージョンデータベースについて~]]></title>
            <link>https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases</link>
            <guid>https://zenn.dev/nnaka2992/articles/to_beat_light_speed_on_google_cloud_databases</guid>
            <pubDate>Mon, 03 Jul 2023 15:39:08 GMT</pubDate>
            <content:encoded><![CDATA[クラウドを利用する一番のメリットの一つとしてオンデマンドでリソースを調達し、アクセス負荷に応じてスケールイン・アウト出来ることが上げられます。そのため大体のアプリケーションではシングルリージョンまたは隣接するリージョン2~3程度で運用を始めることが多いと思います。(日本の場合asia-northeast-1とasia-northeast-2など)アプリケーションがグローバルに拡大すると、それだけ物理的な距離が広がりユーザ・サーバ間のアクセスにかかる時間が拡大します。例えばユーザ・サーバ共に日本にある場合(沖縄・北海道間約3,000km)、ネットワークによる遅延は片道約15ms以下...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイクに入社しました！]]></title>
            <link>https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2</link>
            <guid>https://bells17.medium.com/3-shake-279ea982b977?source=rss-713cf42ce34d------2</guid>
            <pubDate>Mon, 03 Jul 2023 14:10:50 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[SREの専門家が集まったチームで『SREの探求』の社内輪読会を完遂しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/07/03/094713</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/07/03/094713</guid>
            <pubDate>Mon, 03 Jul 2023 00:47:13 GMT</pubDate>
            <content:encoded><![CDATA[🍡 前回の記事syu-m-5151.hatenablog.com🐶 はじめにこんにちは。株式会社スリーシェイク Sreake 事業部に所属している@nwiizo です。Sreake事業部は技術力が求められる領域で豊富な経験を持つSREの専門家が集まったチームです。事業部にはさまざまな背景を持つSREの専門家が多く在籍してます。しかし、そのSREの専門家達とは案件が一緒にならなかったり、能動的に質問をしなければSREに関する意見や知見を聞けませんでした。SREの探求 ―様々な企業におけるサイトリライアビリティエンジニアリングの導入と実践オライリージャパンAmazonそんな、課題がある中で半年前に各案件で得た知見や経験を各メンバーで出し合える会がもっと(社内で技術共有会はあるため)あると良いと思いました。そこで社内チャットで有志を募り 『輪読会について考える会』を行いました。社内チャットで運営を募ると一瞬で集まったので良い組織だと思いました。※『輪読会の各話』の議事録が見れるTOPページです。🐵 各メンバーの感想と今後のアクションsugoude途中からの参加でしたが、楽しく役立つ輪読会でした。特に16章17章はDBREに関する内容でしたので当事者意識を持って参加し、有意義な時間になりました。個人的には、途中からの参加でしたので、SREの探求を再演してもらえたら嬉しいです。hash_gen選定理由としてみんなSRE本は読んでるだろうという点もあったと思いますが、様々なケースと向き合ってきたSreake事業がある3-shakeだからこそSREの探求を輪読する価値があったと思いました。様々な事例に対して我々の場合はどうやって提案していけばよいかという会話が多かったことが印象に残っています。日々のアウトプットでも技術フォーカスの内容に加えて具体的な経験例を社内に積極的にフィードバックしていくことでこのいい習慣を続けていけたらと思っています。SatohJohn入社してまもなくというのも有り、そこまでSREの用語に対して詳しくなかったため、この本を読むことで、どうしてそれらの用語が必要なのかが深掘りできたきがしました。また、個人的にGoogle CloudのDevOpsの試験を受けることが有り、その際にもこの本での話題が役に立ちました。今後アプリケーション開発にSREの考えを入れられるようにするのに、ちょうどよい粒度だったと感じております。tozastationインターンの方が参加したタイミングだけ出れたのでそのエピソードで...! Sreake 事業部だけでなく、他事業部も巻き込んで開催していたのが素敵だなと思いました。Sreake の仕事を知ってもらうであったり、他事業部にも SRE を取り込んでもらうなどさまざまな意見交換が生まれる場だったじゃないかと思います。インターンの方も声を上げてくれたのがさらに良かったです！次のテーマも応援してます！nnaka2992DBRE兼SRE見習いとしてSRE活動をしている自分にとっては、データベース以外でのSREの取り組みを技術・ヒューマンスキル両方の面から学べる本でした。弊社のような不特定多数の組織に対するSREの導入サポートを行う企業では、それぞれの組織に合わせたSREの適用が必要となります。様々なSRE実践例を扱う本書籍は自分の知見を深める面でも、SREとしての引き出しを増やす面でも素晴らしい書籍でした。今後はあくまでこの書籍はある組織での最適解としてリファレンスしながら、それぞれの組織で最適となるSREの探求を続けられればと思います。とあるメンバーすごい有意義な時間でした。Sreake内で自分は人数も組織も大きな組織でどうやって既存の組織にSREを導入するか？を考えているので、様々なプラクティスを知れたのは良い体験でした。輪読で学んだことをお客様に話すと「なるほど！」と言ってもらえることも多々ありました。🐦 まとめ今回の読書会は、新しい知識共有のコミュニティーを作り上げながら実施しました。毎週1回、定められた時間にオンラインに集まり、担当者が1章ずつ読みまとめ、それについて話し合うのです。そして、その議論の過程をドキュメントに記録し、印象に残った部分をいつでも見返せるように保存しておけます。感想はもちろん、一人一人異なりますが、それぞれが課題や組織に向かって解決策を考えていくのがとても面白かったです。その結果、同じ本を読んでいても、それぞれ異なるアクションを考え出すことができました。このようなコミュニティを活用した議論と輪読により、活発な意見交換をしながら特殊なミームが発生したり楽しく読書を進めることができました。これからも、このスタイルの読書会は続けていく予定です。皆さんも、一緒に働くメンバーと読書会を試してみてはいかがでしょうか？新たな知識共有の体験、その刺激を味わってほしいです。弊社の採用サイトも載せておきますjobs-3-shake.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Copilotでらくらくコードリーディング]]></title>
            <link>https://zenn.dev/nnaka2992/articles/code_reading_with_copilot</link>
            <guid>https://zenn.dev/nnaka2992/articles/code_reading_with_copilot</guid>
            <pubDate>Wed, 28 Jun 2023 14:41:21 GMT</pubDate>
            <content:encoded><![CDATA[GitHub Copilot便利ですね。2021年にTechnical Previewとして発表された時から便利だ便利だと言われていたGitHub Copilotに、2023年の4月末ごろからデビューしました。デビューしたは良いものの最近は仕事ではコーディングよりアーキテクト的な方面でのお仕事が多かったり、個人の時間でもコーディングするよりOSSのコードを読むことのほうが多くコーディングのアシスタントツールとしては使いこなせていません。そのため最近はPostgreSQLのコードを読むときのアシスタントとして利用することが多いです。なのでこの記事ではCopilotでコードリーディン...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud RunのSidecarでJVMのmetricsの取得してみた]]></title>
            <link>https://zenn.dev/satohjohn/articles/25bc5879de7832</link>
            <guid>https://zenn.dev/satohjohn/articles/25bc5879de7832</guid>
            <pubDate>Wed, 28 Jun 2023 12:03:00 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud Runのmetricsをデフォルトで取得している指標(metrics)以外の指標が他に欲しい場合、どうするのが良いのかを考えてみました。ちょうどCloud RunのSidecar機能がでたので、それを使います。他の指標を、ここではJVMのmetricsとします。Cloud Run上のJVMのmetricsが取れて何が嬉しいのかについては、一旦考えません。後にCloud Runの最大起動時間が増えた場合は、意味があるかもしれません。 構成図にすると以下のような感じになります。Cloud RunでSpring Bootアプリケーションを立ち上げClou...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ロクに勉強してこなかったエンジニアが輪読会参加とかPCA受験に向けて勉強とかしてみた話]]></title>
            <link>https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d</link>
            <guid>https://qiita.com/bayobayo0324/items/56f93f50fa0115dc4d6d</guid>
            <pubDate>Tue, 27 Jun 2023 12:31:17 GMT</pubDate>
            <content:encoded><![CDATA[この記事について40歳でフリーランスから転職をきっかけに会社員エンジニアになって、社内のエンジニアの熱意に影響を受けて勉強をはじめてみた中年エンジニアの感想とか気づきとかです。先に結論勉強する…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PagerDutyがたくさん機能追加しているみたいなのでまとめてみた]]></title>
            <link>https://sreake.com/blog/pagerduty-release-updates/</link>
            <guid>https://sreake.com/blog/pagerduty-release-updates/</guid>
            <pubDate>Tue, 27 Jun 2023 06:38:36 GMT</pubDate>
            <content:encoded><![CDATA[はじめに PagerDutyはインシデントの管理、オンコール通知のサービスとして、とても優秀なサービスです。直近も、様々な新機能が出ていますが、旧機能から新機能への移行も同時に行われています。 弊社では、PagerDut […]The post PagerDutyがたくさん機能追加しているみたいなのでまとめてみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraformで実践するAWS IAM Identity Center（AWS Single Sign-On）のユーザー管理戦略]]></title>
            <link>https://qiita.com/yokoo-an209/items/569ac1ba517b076e8cde</link>
            <guid>https://qiita.com/yokoo-an209/items/569ac1ba517b076e8cde</guid>
            <pubDate>Wed, 21 Jun 2023 04:05:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS IAM Identity Center（AWS Single Sign-On）を使用して、ユーザー管理を考えていく上で、Terraformを使用して構成管理を実現しようと思います。作成したコードはgithub上に上がっているので、ご参考ください…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[アプリ開発者のための kubectl 講座]]></title>
            <link>https://zenn.dev/toshikish/articles/6a06017747cbba</link>
            <guid>https://zenn.dev/toshikish/articles/6a06017747cbba</guid>
            <pubDate>Mon, 19 Jun 2023 06:03:18 GMT</pubDate>
            <content:encoded><![CDATA[これは何Kubernetes クラスタ管理者とアプリケーション開発者が分業しているプロジェクトで，開発者が必ずしも Kubernetes に詳しくない場合を想定し，開発時に使いそうな kubectl のコマンドをまとめたものです。クラスタ管理者から開発者にこのドキュメントを適宜改変して渡し，開発者がある程度自立して操作できるようになることで，管理者への問い合わせ負荷を減らすのが狙いです。場合によってはハンズオンで講座を開いてもよいでしょう。 ドキュメント案ここでは Amazon EKS でクラスタを構築する場合の例を示します。別のインフラに構築している場合は適宜書き換え...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[夏に向けて、体もコンテナイメージも減量（軽量化）させよう！]]></title>
            <link>https://qiita.com/yokoo-an209/items/0297808af40c1a74928e</link>
            <guid>https://qiita.com/yokoo-an209/items/0297808af40c1a74928e</guid>
            <pubDate>Mon, 19 Jun 2023 02:46:48 GMT</pubDate>
            <content:encoded><![CDATA[はじめにdockerで構築しているNext.jsのフロントエンドアプリケーションのimageをAmazon ECRにpushしようとしたときに、pushのあまりの遅さにびっくりしたのがことの発端で…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 静的検査ツール比較]]></title>
            <link>https://zenn.dev/tayusa/articles/9829faf765ab67</link>
            <guid>https://zenn.dev/tayusa/articles/9829faf765ab67</guid>
            <pubDate>Thu, 15 Jun 2023 17:00:00 GMT</pubDate>
            <content:encoded><![CDATA[対象tfsectflintKICSCheckovSnyk tfsechttps://github.com/aquasecurity/tfsechttps://aquasecurity.github.io/tfsec/v1.28.1 特徴CI系公式のdocker imageがあるhttps://github.com/aquasecurity/tfsec#use-with-dockerGitHub Actionがあるhttps://github.com/aquasecurity/tfsec-pr-commenter-actionGitH...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[editcap で tcpdump のキャプチャファイルから指定の時間帯を切り出す]]></title>
            <link>https://blog.1q77.com/2023/06/editcap/</link>
            <guid>https://blog.1q77.com/2023/06/editcap/</guid>
            <pubDate>Thu, 15 Jun 2023 14:46:42 GMT</pubDate>
            <content:encoded><![CDATA[ちょっと大きめ (時間範囲の広い) pcap ファイルがあって、wireshark で見るにしてもちょっと大きすぎるなということがありました。 見たい時間帯だけに絞ったファイル]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub の Reusable workflow で working-directory に変数を使う]]></title>
            <link>https://zenn.dev/toshikish/articles/be970407f02098</link>
            <guid>https://zenn.dev/toshikish/articles/be970407f02098</guid>
            <pubDate>Thu, 15 Jun 2023 05:22:24 GMT</pubDate>
            <content:encoded><![CDATA[やりたいことGitHub Actions の reusable workflow で，作業ディレクトリを入力変数で変えたい場合を考えます。on:  workflow_call:    inputs:      workdir:        required: true        type: string うまくいかない方法ワークフロー全体のステップのデフォルト設定 defaults.run.working-directory では，現時点ではコンテキストと式が許可されていません。したがって，入力変数でディレクトリ名を受け取って上記に入れても動作しません。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeconformをGitLab CIに組み込んで、k8sのマニフェストがAPIの仕様に沿うか検査する]]></title>
            <link>https://zenn.dev/tayusa/articles/1aa96e6ceb838a</link>
            <guid>https://zenn.dev/tayusa/articles/1aa96e6ceb838a</guid>
            <pubDate>Sun, 11 Jun 2023 17:19:45 GMT</pubDate>
            <content:encoded><![CDATA[はじめにk8sマニフェストを普段管理していないメンバーがマニフェストのファイルを変更する場面があります。その際のレビューを出来るだけ自動化したくkubeconformを導入しました。 KubeconformマニフェストがAPIの仕様に沿うか検査してくれます。https://github.com/yannh/kubeconform自分でスキーマを用意すればIstio、Argo Rollouts、Argo Workflowsのような外部のAPIも検査できます。 スキーマの生成スキーマの生成はpythonのスクリプトが用意されているので、これをCRDを引数で渡し実行しま...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[plutoをGitLab CIに組み込んで非推奨のk8s apiVersionを検出する]]></title>
            <link>https://zenn.dev/tayusa/articles/79a3f54d8f21bc</link>
            <guid>https://zenn.dev/tayusa/articles/79a3f54d8f21bc</guid>
            <pubDate>Sun, 11 Jun 2023 17:18:13 GMT</pubDate>
            <content:encoded><![CDATA[はじめにk8sのバージョンが上がるとAPIが再編成されたりアップグレードされたりします。新しいAPIが出ると古いAPIは非推奨になり最終的には削除されます。なので、k8sのバージョンアップ時はDeprecated API Migration Guideなどを見て非推奨のapiVersionが使われていないか確認して時には修正する必要があります。https://kubernetes.io/docs/reference/using-api/deprecation-guide/例CronJob の batch/v1beta1 -> batch/v1 plutoplu...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Istio Canary Upgrade by Helm]]></title>
            <link>https://zenn.dev/tayusa/articles/03cf961e2409bd</link>
            <guid>https://zenn.dev/tayusa/articles/03cf961e2409bd</guid>
            <pubDate>Sun, 11 Jun 2023 17:17:37 GMT</pubDate>
            <content:encoded><![CDATA[前提helmfileを利用istioのrevisionTagを利用関係のない設定は省略 Upgradeの前にInstall ディレクトリ構成├── helmfile_istio-base.yaml├── helmfile_istio-ingressgateway.yaml├── helmfile_istiod-1-16-0.yaml└── values    ├── istio-base.yaml    ├── istio-ingressgateway.yaml    └── istiod.yaml helmfile helmfile_isti...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Helmに入門したので、躓いたところを振り返る]]></title>
            <link>https://zenn.dev/tayusa/articles/e9285c6c4c09a1</link>
            <guid>https://zenn.dev/tayusa/articles/e9285c6c4c09a1</guid>
            <pubDate>Sun, 11 Jun 2023 17:16:25 GMT</pubDate>
            <content:encoded><![CDATA[はじめにアプリのマニフェストを管理するのにKustomizeを使っていたのですが、同じようなマニフェストが乱立したので管理を楽にするためにHelmに移行しました。Helmを一から書いたのは初めてだったので、躓いた点をここに残します。 quote関数の進数変換0から始まる数値をquote関数を使って文字列にすると進数変換が起こり想定した値ではなくなる下記のようなtemplateでidとして0000000060のような値を渡すと、8進数として解釈され10進数である48に変換されてしまいます。...id: {{ .id | quote }}...0から始まる数値はtem...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go言語でNetlinkを少し触った話]]></title>
            <link>https://zenn.dev/bells17/articles/netlink-goexample</link>
            <guid>https://zenn.dev/bells17/articles/netlink-goexample</guid>
            <pubDate>Thu, 08 Jun 2023 18:03:10 GMT</pubDate>
            <content:encoded><![CDATA[Go言語でNetlinkを少し触ったのでメモ。具体的にはGo言語でNetlinkというネットワーク関連のライブラリを使ってStatic Routeを設定したりするサンプルを作ったりした。https://github.com/bells17/netlink-gosample Netlinkとは調べた範囲だと、Linuxカーネルのサブシステムの1つで、ルーティングテーブルの管理などのネットワーク関連の設定などを行う際に利用されるもの、という理解をしている。Netlinkは、Linuxカーネルとユーザ空間プロセス間の、またはカーネル内の通信を提供するためのIPC（Inter-pro...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes 1.27 以降のバッチ処理の改善]]></title>
            <link>https://zenn.dev/toversus/articles/d6065bea460871</link>
            <guid>https://zenn.dev/toversus/articles/d6065bea460871</guid>
            <pubDate>Thu, 08 Jun 2023 03:46:32 GMT</pubDate>
            <content:encoded><![CDATA[Kubernetes 1.27 以降で実装済みまたは予定されているバッチ処理の改善に繋がる KEP や Kubernetes のサブプロジェクトの現状を見ていきます。 KEP-3673: Kubelet limit of Parallel Image Pulls!Kubernetes 1.27 時点でアルファ機能です。1.28 でベータを目指していますが、設定はデフォルトで無効化されています。Pod の起動にノードのスケールアウトが必要な場合に、Pod の起動時間の短縮が期待できます。バッチ処理の Pod が一斉に起動するケースで恩恵を受けられそうです。Kubelet は...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[asdf の代わりに rtx を使う]]></title>
            <link>https://blog.1q77.com/2023/06/rtx/</link>
            <guid>https://blog.1q77.com/2023/06/rtx/</guid>
            <pubDate>Wed, 07 Jun 2023 01:25:11 GMT</pubDate>
            <content:encoded><![CDATA[nodeenv とか rbenv とか tfenv とか XXenv がそれぞれ .xxx-version というファイルにそのディレクトリ配下で使用する software の version を指定するという仕様があり、それらをまとめてやってくれる asdf というツールが登場]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[お前のパケットはもう死んでいる。TCPに死亡フラグを実装してみた]]></title>
            <link>https://zenn.dev/satoken/articles/golang-rfc9401</link>
            <guid>https://zenn.dev/satoken/articles/golang-rfc9401</guid>
            <pubDate>Wed, 07 Jun 2023 00:32:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめにプロトコルの仕様などIETFが発行しているRFCにはジョークRFCというものが存在しています。伝書鳩でIP通信するとか、コーヒーポットを制御するなどが有名です。鳥類キャリアによるIPHyper Text Coffee Pot Control Protocol (HTCPCP/1.0) 日本語訳今年そんなジョークRFCに、TCPに死亡フラグを実装するというRFC9401が追加されました。The Addition of the Death (DTH) Flag to TCP 日本語訳この記事ではこのTCPに死亡フラグを実装するというRFC9401を真面目に実装してみ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenAI API を利用して Terraform から構成図っぽい Mermaid を出力してくれるコマンドを作った話]]></title>
            <link>https://sreake.com/blog/mermaid-with-openai-api/</link>
            <guid>https://sreake.com/blog/mermaid-with-openai-api/</guid>
            <pubDate>Tue, 06 Jun 2023 02:44:12 GMT</pubDate>
            <content:encoded><![CDATA[前段 Sreake事業部の橋本です。 ChatGPTで話題のOpenAIのモデルは、現在画像の取り扱いはまだ発展途上です。文章から画像を作るAPIや画像入力が検討されていますが、システム運用にクリティカルに使えそうになる […]The post OpenAI API を利用して Terraform から構成図っぽい Mermaid を出力してくれるコマンドを作った話 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Redis公式のGoクライアントライブラリrueidisを試してみた]]></title>
            <link>https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2</link>
            <guid>https://qiita.com/bayobayo0324/items/8ac3e27eef360a316ad2</guid>
            <pubDate>Wed, 31 May 2023 12:02:25 GMT</pubDate>
            <content:encoded><![CDATA[This 記事 is 何？Twitterぼんやり見てたらRedis公式のGo用クライアントライブラリが出てたとかで、自身のプロジェクトにどの程度簡単に入れられるのかなーと思い試してみました。公式…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 1.5 で既存リソースからの HCL 生成ができるようになるので試してみる]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-generate-config</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-generate-config</guid>
            <pubDate>Mon, 29 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Terraform 1.5 のベータ版がリリースされています。https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta1https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta2Terraform 1.5 で追加される機能の中には以下のようなものが含まれています。import ブロックterraform plan の -generate-config-out オプションTerraform では手作業などで作成済みの既存リソースも ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OLAPデータベースを支える技術]]></title>
            <link>https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database</link>
            <guid>https://zenn.dev/nnaka2992/articles/technics_behind_analytical_database</guid>
            <pubDate>Thu, 25 May 2023 00:02:49 GMT</pubDate>
            <content:encoded><![CDATA[今年に入ってからCarnegie Mellon UniversityのAdvanced Database SystemsでReading Assignmentとして出ている論文リストで必須とされているものや講義資料を読みました。https://nnaka2992.hatenablog.com/archive/category/論文この記事では紹介されていた論文やAdvanced Database Systemsの講義資料・動画を振り替えることで、BigQueryやRedShift、Snowflakeといった最新の分析用データベースがどのように優れたパフォーマンスを実現しているかを考え...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes の運用効率化を ChatGPT-4 で実現する 障害対応編]]></title>
            <link>https://sreake.com/blog/kubernetes-operation-with-chatgpt4/</link>
            <guid>https://sreake.com/blog/kubernetes-operation-with-chatgpt4/</guid>
            <pubDate>Mon, 22 May 2023 23:46:38 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上秀一です。 Sreake事業部はSRE関連技術に強みを持つエンジニアによるコンサルテーションサービスを提供する事業部であり、私たちもSRE技術の調査と研究 […]The post Kubernetes の運用効率化を ChatGPT-4 で実現する 障害対応編 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform 1.5 で追加される import ブロックの使い方]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/tf-import-block</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/tf-import-block</guid>
            <pubDate>Mon, 22 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[先日 Terraform v1.5.0-beta1 がリリースされました。https://github.com/hashicorp/terraform/releases/tag/v1.5.0-beta1NEW FEATURES を眺めてみると、どうやら import ブロックというものが追加されているみたいです。今までは既存のリソースを Terraform の管理下に追加するためには terraform import コマンドを使用して 1 つ 1 つ import する必要がありました。import ブロックを使用することでリソースの import を宣言的に実行することができ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform Modules で再利用できるので最高ではないでしょうか？]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/05/19/154346</guid>
            <pubDate>Fri, 19 May 2023 06:43:46 GMT</pubDate>
            <content:encoded><![CDATA[概要ModuleはTerraformの複数のリソースをまとめて再利用可能な単位として扱うことができます。Moduleを使うことで複雑なリソース構成を抽象化し、システムの構造の把握やリソース構成の再利用が可能になり、読みやすさや可読性が向上し、修正箇所が単一になるなどのメリットがあります。ただし、理解には初期コストが必要です。Moduleの設計では、1つの機能を持つように小さくシンプルに保つことが重要で、それが難しい場合は大抵複雑と言えます。また、公式のModuleを利用することで、自身で定義やドキュメントの整備、メンテナンスの手間を省きつつ、プロジェクトを超えて共通認識として扱えるため、Module理解のコストが減ります。しかし、どのタイミングでModuleに組み込むかの正解は、個々のプロジェクトの特性や開発チームの状況により大いに変わるでしょう。絶えず試行錯誤を繰り返しながら個々のプロジェクトごとに最適な解を見つけることが求められます。このブログではそれらの話の前にTerraform Modulesについて利用方法をまとめてみました。概要Module を利用するmoduleの使い方moduleの入力ローカルをうまく利用するmoduleの出力module を使ったときの失敗についてバージョン状態の差分は可能な限り小さくすべきアップグレードは自動されるべきファイルパスインラインブロックいい感じのデフォルトの変数最後に参考Module を利用するシステムを構築するにあたって開発、検証、本番環境をそれぞれ用意することが多いですが、Terraformを環境ごと（例：開発環境、ステージング環境、本番環境）にシンプルなWebサーバーの構成を例にしてModuleを使わないときと使ったときの構成を比較してみましょう。Terraform Configuration|--- Development Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Staging Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)|--- Production Environment|   |--- VM Instances (Web servers)|   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|   |--- Load Balancer (Balance traffic among VM instances)|   |--- Storage Bucket (Store static content)この構成では、 環境毎にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されていて環境間で異なるリソース設定を利用します。一方、moduleを使用した場合の構成は以下のようになります。Terraform Configuration|--- modules|   |--- user_service_cluster|       |--- main.tf|       |   |--- VM Instances (Web servers)|       |   |--- Firewall Rules (Allow HTTP/HTTPS traffic to the web servers)|       |   |--- Load Balancer (Balance traffic among VM instances)|       |   |--- Storage Bucket (Store static content)|       |--- variables.tf|       |--- output.tf|--- Development Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)|--- Staging Environment|   |--- User-Service-Cluster Module (source: ../modules/user_service_cluster)|--- Production Environment|   |--- User-Service-Cluster  Module (source: ../modules/user_service_cluster)この構成では、 user_service_cluster moduleのmain.tfファイル内にVM Instances 、Firewall Rules 、 Load Balancer 、Storage Bucket などのリソースが定義されています。各環境はこのuser_service_clustermoduleを参照しており、環境間で共通のリソース設定を再利用します。これによって再利用性、可読性が上がり維持管理性を高める事ができると思います。moduleの使い方Terraformの moduleは、リソース設定の再利用可能な部品で、コードの抽象化と組織化をサポートします。 moduleは一つ以上のリソースを定義し、それらをまとめて管理することができます。 moduleを使用するためには、 moduleブロックをmain.tf（またはその他の.tfファイル）に追加し、そこでmoduleのソースと任意の入力変数を指定します。以下に、user_service_cluster moduleを使用するための基本的なmodule ブロックの例を示します。module "user_service_cluster" {  source = "../modules/user_service_cluster"  instance_type  = "n1-standard-1"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = "HTTP"    port     = 80  }  bucket_name = "dev-bucket"}source属性にmoduleのソースコードが存在するパスを指定しています。そして、user_service_cluster moduleが定義する各入力変数を設定しています。moduleは、そのソース内でvariableブロックを使用して入力変数を定義します。これらの入力変数は、moduleの使用者が値を提供することでmoduleの振る舞いをカスタマイズできます。また、moduleはoutputブロックを使用して出力値を定義します。出力値は、moduleの内部リソースの属性をmoduleの外部に公開するために使用されます。これにより、他のリソースやmoduleがmoduleから生成されるリソースを参照することが可能になります。module化はTerraformのコードベースを組織化し、再利用可能なコードを作成するための重要な手段です。これにより、一貫性が保たれ、メンテナンスが容易になり、エラーの可能性も低減します。moduleの入力Terraformのmoduleは再利用可能なコードブロックで、入力変数（input variables）を使用してカスタマイズできます。これらの入力変数は、moduleブロックで設定します。以下に、user_service_cluster moduleで使用する入力変数の例を示します。まず、module自体のvariables.tfファイルには以下のように入力変数を定義しますvariable "instance_type" {  description = "The type of instance to start"  type        = string  default     = "n1-standard-1"}variable "instance_count" {  description = "Number of instances to create"  type        = number  default     = 1}variable "firewall_rules" {  description = "Firewall rules for instances"  type        = map(any)  default     = {}}variable "load_balancer_config" {  description = "Configuration for load balancer"  type        = map(any)  default     = {}}variable "bucket_name" {  description = "Name of the storage bucket"  type        = string  default     = "default-bucket"}そして、このmodule を呼び出す際に、具体的な値を設定します：module "user_service_cluster" {  source = "../modules/user_service_cluster"  instance_type  = "n1-standard-1"  instance_count = 3  firewall_rules = {    allow_http  = true    allow_https = true  }  load_balancer_config = {    protocol = "HTTP"    port     = 80  }  bucket_name = "dev-bucket"}上記の例では、user_service_cluster moduleはsourceで指定されたソースからロードされ、instance_type、instance_count、firewall_rules、load_balancer_config、bucket_nameという入力変数を設定しています。module に入力変数を提供することで、module の動作をカスタマイズし、異なる環境や条件で再利用することが可能になります。ローカルをうまく利用するTerraformのlocalsブロックを使用すると、再利用可能な内部変数をmodule内で定義することができます。localsはmodule内で共有され、module外からは参照できません。以下に、user_service_cluster module のlocalsの例を示します。この例では、HTTPポート、任意のポート、任意のプロトコル、TCPプロトコル、そして全てのIPアドレスをローカル変数として定義しています。locals {  http_port    = 80  any_port     = 0  any_protocol = "-1"  tcp_protocol = "tcp"  all_ips      = ["0.0.0.0/0"]}ローカル変数はlocal.<NAME>の形式で参照します。以下のリソース定義では、ロードバランサーリスナーとセキュリティグループの設定にローカル変数を使用しています。resource "google_compute_instance" "http" {  name         = "web-instance"  machine_type = "n1-standard-1"  network_interface {    network = "default"    access_config {      // Assign an ephemeral IP to the instance    }  }    // Other configuration...}resource "google_compute_firewall" "default" {  name    = "default-firewall"  network = "default"  allow {    protocol = local.tcp_protocol    ports    = [local.http_port]  }  source_ranges = local.all_ips}上記の例では、ロードバランサーリスナーとセキュリティグループでlocalsブロックに定義したローカル変数を参照しています。local.http_port、local.tcp_protocol、local.all_ipsを各リソースブロックで参照することで、コードがDRYに保たれ、より読みやすく、メンテナンスがしやすくなります。localsブロックを使用することで、コードの冗長性を減らし、module全体の一貫性を保つことができます。また、ローカル変数を使用することで、moduleの一部で使用する変数をmodule全体で共有することが可能になります。moduleの出力Terraformのmoduleは、出力変数（outputs）を提供できます。出力変数はmoduleの値を外部に公開するための手段で、moduleを使用しているコードからアクセスできます。また、Terraformがapplyコマンドを実行した後にこれらの値を表示することもできます。以下に、user_service_cluster moduleの出力変数の例を示します。この例では、output.tf にクラスタのURLとインスタンスのIDを出力しています。output "cluster_url" {  description = "The URL of the load balancer for the cluster"  value       = "http://${google_compute_global_address.default.address}"}output "instance_ids" {  description = "The IDs of the instances in the cluster"  value       = google_compute_instance.default.*.id}これらの出力をmodule の使用側でアクセスするためには、moduleの名前と出力の名前を組み合わせて参照します。output "user_service_cluster_url" {  description = "The URL of the load balancer for the user service cluster"  value       = module.user_service_cluster.cluster_url}output "user_service_cluster_instance_ids" {  description = "The IDs of the instances in the user service cluster"  value       = module.user_service_cluster.instance_ids}このようにして、moduleの出力変数を使用することで、moduleの内部データをmodule外部に公開し、他のTerraformコードがそのデータを参照できるようにします。出力変数はmodule間の情報共有を可能にし、moduleの再利用性を向上させます。Terraformはファイル名に特別な意味を持たせません。すなわち、variables.tfやoutputs.tfという名前は慣習にすぎないので、入力変数と出力変数を1つのファイルにまとめることも技術的には可能です。module を使ったときの失敗についてmodule を作る時に注意する点について実際にハマったことをベースに3つ紹介します。バージョンModuleのバージョンが異なると意図しない挙動やエラーが引き起こされる可能性があるので、バージョンを固定し実行環境を統一しましょう。Providerやパッケージにしても同じでバージョンを指定して再利用性を高めろ！！！状態の差分は可能な限り小さくすべきいつでもアップグレードを状態差分なしで行うことはできません。依存するリソースの変更やセキュリティ問題ができるだけ早くパッチを適用する必要があるなど、破壊的な変更を導入する必要がある場合があります。その場合、コストをどのように減らすかについて考える必要があります。状態の差分が少なければ、アップグレードのコストは少なくなります。破壊的な変更を導入するときは、それを文書化できるCHANGELOGやユーザーガイドを通じてユーザーに伝える必要がありますアップグレードは自動されるべきアップグレードは長期的に開発されるソフトウェアの最も重要なタスクの一つです。ただし、一般的に使用され、広く使用されているTerraform Moduleの場合、これは大きな問題でもあります。また、Moduleを頻繁に更新する場合、自動アップデートの機能を準備する必要があります。ユーザーにアップグレードを依頼しても、通常、彼らはより重要なタスクを行うためにそれを行うことはありません。そのため、代わりに、彼らのためにPRを作成します。PRがTerraformの差分がない場合に自動的にマージされるメカニズムを持っています。これと後方互換性の維持の組み合わせにより、最新バージョンのModuleを使用するユーザーの率を増やすことができますファイルパスTerraformのtemplatefile関数を使用する際、ファイルパスは絶対パスではなく相対パスを使用する必要があります。しかし、これはどのパスに対して相対的なのでしょうか？デフォルトでは、Terraformはパスを現在の作業ディレクトリに対して相対的に解釈します。そのため、terraform applyを実行しているディレクトリと同じディレクトリにTerraform設定ファイルがある場合、これはうまく動作します。しかし、別のフォルダに定義されたmodule内でtemplatefileを使用する場合、これは問題となります。この問題を解決するためには、path.moduleなどのパス参照を使用します。これを使用すると、module自体に対する相対パスが得られます。インラインブロックTerraformリソースの一部の設定は、インラインブロックか別のリソースとして定義することができます。インラインブロックとは、リソース内で設定する引数のことで、次の形式を持っています。resource "xxx" "yyy" {  <NAME> {    [CONFIG...]  }}ここでNAMEはインラインブロックの名前（例えば、ingress）、CONFIGはそのインラインブロックに特有の一つ以上の引数（例えば、from_portやto_port）です。しかし、インラインブロックと別のリソースを混在して使用すると、Terraformの設計上、設定が衝突し互いに上書きされてエラーが発生します。したがって、どちらか一方を使用する必要があります。moduleを作成する際には、別のリソースを使用することを常に推奨します。これらの注意点を理解しておくことで、Terraformのmoduleをより効果的に利用することができます。いい感じのデフォルトの変数完全にカスタマイズできるModuleには魅力がないです。Moduleの変数には、80％のユーザーをカバーするスマートデフォルト値を持つべきです。ただし、同時に、通常のユーザーとは異なる方法でModuleを使用するパワーユーザーのための設定も用意するべきです。変数を変更したときに何が起こるかは、ユーザーにとって明白で予測可能でなければなりません。この設定は適切に設計され、安易に浅いインターフェースを持つべきではありません最後にmoduleを活用することで、インフラストラクチャの再利用性と効率性が大幅に向上します。開発者は証明済み、テスト済み、文書化済みのインフラストラクチャの一部を再利用できるようになるため、迅速かつ確実にシステムを構築できます。例えば、マイクロサービスのデプロイメントを定義するmoduleを作成し、各チームが数行のコードで自身のマイクロサービスを管理できるようにすることが可能です。しかし、このようなmoduleを複数のチームで活用するためには、module内のTerraformコードは柔軟性と設定可能性が必要です。異なるチームや状況に応じて、ロードバランサーなしの単一インスタンスやロードバランサー付きの複数インスタンスといった、さまざまなデプロイメント要件を満たすことができます。Terraformの柔軟な構文を活用することで、より多機能なmoduleを設計し、インフラストラクチャの構築を一層楽しく効果的に行うことができます。また、どれぐらいの規模からmodule化するのかなど迷う場面が多いと思いますがこの辺は経験としか言えずにみんな雰囲気でやっているなぁって思いました。このブログが伸びたらもっと実装に基づいた話をしていこうと思います。ちなみにベストプラクティスなんかは俺にはわからない。自分を信じても…信頼に足る仲間を信じても…誰にもわからない…今の構成が一番変更しやすくて誇れるものならそれが正解なんだとおもう。実践Terraform　AWSにおけるシステム設計とベストプラクティス (技術の泉シリーズ（NextPublishing）)作者:野村 友規インプレスR&DAmazon参考Terraform: Up & Running; Writing Infrastructure As CodeDeveloper/Terraform/Configuration Language/Modulesterraform-module/terraform-module-blueprinthttps://registry.terraform.io/namespaces/terraform-aws-moduleshttps://registry.terraform.io/namespaces/terraform-google-modulesHashiCorp LearnModule Creation - Recommended PatternAWSとTerraformで学ぶプロダクションレディなKubernetes 技術の泉シリーズ (技術の泉シリーズ（NextPublishing）)]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLab トラブル事例紹介]]></title>
            <link>https://sreake.com/blog/gitlab-trouble-case-study/</link>
            <guid>https://sreake.com/blog/gitlab-trouble-case-study/</guid>
            <pubDate>Tue, 16 May 2023 02:23:30 GMT</pubDate>
            <content:encoded><![CDATA[本ドキュメントでは、トラブルシューティングの事例を取り上げ、それぞれのトラブルの原因調査の流れと判明した原因、解決方法について記載します。 また、トラブルシューティングを円滑に進められるように心がけていることをご紹介しま […]The post GitLab トラブル事例紹介 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Go で GitHub CLI 拡張機能を作る]]></title>
            <link>https://zenn.dev/kou_pg_0131/articles/gh-cli-extension-in-go</link>
            <guid>https://zenn.dev/kou_pg_0131/articles/gh-cli-extension-in-go</guid>
            <pubDate>Mon, 15 May 2023 09:00:00 GMT</pubDate>
            <content:encoded><![CDATA[先日 gh-grass という Go 製の GitHub CLI 拡張機能を開発してみたのですが、意外と簡単にできたので手順のメモです。gh-grass については次の記事をご参照ください。https://zenn.dev/kou_pg_0131/articles/gh-grass-introduction 拡張機能を作成する!GitHub CLI がインストールされている必要があります。GitHub CLI のインストール方法については GitHub CLI 公式リポジトリの README をご参照ください。まずは gh extension create を次のように...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[現在のDremelの実装を解説した論文を読みました ]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/2023/05/15/111420</link>
            <guid>https://nnaka2992.hatenablog.com/entry/2023/05/15/111420</guid>
            <pubDate>Mon, 15 May 2023 02:14:20 GMT</pubDate>
            <content:encoded><![CDATA[この記事の趣旨2020年に発表されたBigQueryの元となったGoogle内で利用されている分析向けデータベースであるDremelの実装を解説した論文を読みました。Dremel: A Decade of Interactive SQL Analysis at Web Scale著者についてSergey Melnik, Andrey Gubarev, Jing Jing Long, Geoffrey Romer, Shiva Shivakumar, Matt Tolton,Theo Vassilakisら2010年のDremel発表論文の著者らと、Hossein Ahmadi, Dan Delorey, Slava Min, Mosha Pasumansky, Jeff ShuteらGoogleで分析ワークロードと分散処理に関わる著者らによる論文。概要BigQueryの元となったGoogleのDremelの10年間を振り替えってアーキテクチャについて説明した論文。Dremelは現代のクラウドネイティブ分析ツールで一般的になっている、計算リソースとストレージの分解、カラムナストレージ、in situデータ分析などを統合した最初のツールである。手法SQLの採用Googleでは殆どのデータはBigTableなどNoSQLデータベースで管理されていたため、SQLを用いないデータアクセスが主流であった。しかしトランザクション型ビッグデータシステムにおける、SQLの採用に共ないDremelでもSQLを採用した。ストレージの分離メモリの分離MapReduceのシャッフルのボトルネックを回避するためにDisaggregated Memory Shuffle Systemを採用した。In situデータ分析への対応DBMSへのデータロードを必要としないデータ分析のことで、DremelではGFSに移行するときにGoogle内で共有のストレージフォーマットを使用することでGoogle内のデータに対応した。加えてGoogle Cloud StorageやGoogle Drive、MySQL、BigTableなどからのデータ取得もフェデレーションとして対応した。サーバレスアーキテクチャフォールトトレラントリスタート、仮想スケジューリングユニットによりマルチテナントかつオンデマンドなリソースを提供可能とし、低価格な利用を可能とした。現在ではサーバレスアーキテクチャを進化させ、集中型スケジューリングやShuffle Persistent Layer、柔軟なDAG実行、動的クエリ実行などを実装することでより優れたサーバレスアーキテクチャを実現した。ネストデータにおけるカラムナストレージ[[32])]Figure 5Figure 6Figure 7クエリレイテンシの最小化インタラクティブな実行のレイテンシは大きくなる。それを解決するためにDremelではスタンバイサーバプール、マルチレベル実行ツリー、列指向スキーマ表現、CPUとIO負荷のバランス調整、ファイルオペレーションの再利用、保証されたキャパシティ、適合的なクエリスケーリングにより実現している。作業時間read27:5027:50author32:024:12summary68:5026:48]]></content:encoded>
        </item>
    </channel>
</rss>