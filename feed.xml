<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 28 Apr 2025 22:35:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[dura使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/e3b8473a703d61</link>
            <guid>https://zenn.dev/akasan/articles/e3b8473a703d61</guid>
            <pubDate>Mon, 28 Apr 2025 11:45:35 GMT</pubDate>
            <content:encoded><![CDATA[みなさん、gitレポジトリで作業中に、「コミットしないファイルを間違って削除してしまった」のようなやらかしをしたことがありませんか？一度経験するともう二度とこのような経験をしたくないと思うでしょう。今回はそのような状況になりにくくするためのツールであるduraというものをご紹介させてもらいます。 duraとは？duraの公式GitHubリポジトリから引用させてもらいますと、duraとはDura is a background process that watches your Git repositories and commits your uncommitted chan...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RAGアプリ開発ハンズオン（前編：バックエンド編）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/04/28/185621</link>
            <guid>https://shu-kob.hateblo.jp/entry/2025/04/28/185621</guid>
            <pubDate>Mon, 28 Apr 2025 09:56:21 GMT</pubDate>
            <content:encoded><![CDATA[genai-users.connpass.com上記ハンズオン勉強会の資料になります。ソースコードgithub.comFastAPIの準備python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activatepip install fastapi uvicorntouch main.pyfrom fastapi import FastAPIapp = FastAPI()@app.get('/')def index():  return 'hello'実行uvicorn main:app --reload別ターミナルにてcurl -s http://localhost:8000/POSTも追加from pydantic import BaseModelclass User(BaseModel):    name: str@app.post('/api/hello')def hello_service(user: User):    resp = { 'message': 'Hello, {}!'.format(user.name) }    return respUSER='{"name":"平賀源内"}'curl -X POST -H "Content-Type: application/json" -d "$USER" -s http://localhost:8000/api/hello | jq .Google Cloudでサービスアカウントの準備Geminiマルチモーダルプログラミングハンズオン - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、ロールへVertex AI ユーザーディスカバリー エンジン ユーザーを追加し、環境変数の設定Geminiを呼び出すコードを記載main.pyの上に以下を追加import vertexaifrom vertexai.generative_models import GenerativeModelmain.pyの下に以下を追加class Question(BaseModel):    query: str@app.post('/api/llm')def llm_service(question: Question):    prompt = question.query    vertexai.init(location="us-west1") # vertexaiの初期化で、ロケーションを設定    model = GenerativeModel("gemini-2.0-flash-001") # モデルを設定    response = model.generate_content( # プロンプトをモデルに入れて出力(レスポンスを得る)        prompt    )    print(response.text) # コンソールログにresponseのテキストを表示    resp = { 'answer': response.text } # responseを形作る    return respライブラリのインストールrequirements.txtに以下を記載google-cloud-aiplatform==1.83.0vertexai==1.43.0langchain_core==0.3.33langchain_google_vertexai==2.0.12google===3.0.0google-cloud-discoveryengine==0.13.6pip install -r requirements.txt--break-system-packagesをつけよ、とエラーが出たら以下pip install --user -r requirements.txt --break-system-packages実行方法uvicorn main:app --reload別ターミナルにてQUESTION='{"query":"プロンプトエンジニアリングとは何ですか？"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/llm | jq .LangChainを用いるimport vertexai # 削除from vertexai.generative_models import GenerativeModel # 削除from langchain_google_vertexai import VertexAI # 追記from langchain_core.prompts import PromptTemplate # 追記@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    template = """質問: {question}    ステップバイステップで考えてください。"""    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return respRAG構築Google Cloud Vertex AI Agent Builderの使い方 - Toilを無くして徒然なるままに日暮し硯に向かひたいの記事を参考に、Google Cloud Storageにドキュメントを格納し、Agent Builderで検索アプリを作ります。main.pyの上に追記from google.api_core.client_options import ClientOptionsfrom google.cloud import discoveryengine_v1 as discoveryengineimport osimport google.authcredentials, project_id = google.auth.default()main.pyの下に追記'DISCOVERY_ENGINE_ID'を書き換えます@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = 'DISCOVERY_ENGINE_ID' # AI Applicationsで作成したアプリケーションのIDに変更する    def search(        project_id: str,        location: str,        engine_id: str,        search_query: str,    ) -> discoveryengine.services.search_service.pagers.SearchPager:        client_options = (            ClientOptions(api_endpoint=f"{location}-discoveryengine.googleapis.com")            if location != "global"            else None        )        client = discoveryengine.SearchServiceClient(client_options=client_options)        serving_config = f"projects/{project_id}/locations/{location}/collections/default_collection/engines/{engine_id}/servingConfigs/default_config"        content_search_spec = discoveryengine.SearchRequest.ContentSearchSpec(            snippet_spec=discoveryengine.SearchRequest.ContentSearchSpec.SnippetSpec(                return_snippet=True            ),            summary_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec(                summary_result_count=3,                include_citations=True,                ignore_adversarial_query=True,                ignore_non_summary_seeking_query=True,                model_prompt_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelPromptSpec(                    preamble="文献の検索結果を要約してください"                ),                model_spec=discoveryengine.SearchRequest.ContentSearchSpec.SummarySpec.ModelSpec(                    version="stable",                ),            ),        )        request = discoveryengine.SearchRequest(            serving_config=serving_config,            query=search_query,            page_size=3,            content_search_spec=content_search_spec,            query_expansion_spec=discoveryengine.SearchRequest.QueryExpansionSpec(                condition=discoveryengine.SearchRequest.QueryExpansionSpec.Condition.AUTO,            ),            spell_correction_spec=discoveryengine.SearchRequest.SpellCorrectionSpec(                mode=discoveryengine.SearchRequest.SpellCorrectionSpec.Mode.AUTO            ),        )        page_result = client.search(request)        return page_result    response = search(project_id, location, engine_id, search_query)    resp = { 'search_result': response.summary.summary_text }    print(resp)    return respQUESTION='{"query":"情報セキュリティにおいて気をつけるべきことを教えてください"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/retriever | jq .課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。次回、5月の回（日程未定）で解説します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Load Balancer Controller (LBC)でkubernetesのServiceを外部に公開する]]></title>
            <link>https://zenn.dev/kamos/articles/65c7d16bf16184</link>
            <guid>https://zenn.dev/kamos/articles/65c7d16bf16184</guid>
            <pubDate>Mon, 28 Apr 2025 05:52:13 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS LBC(Load Balancer Controller)は、EKS上のリソースとしてALBを構成するための機能です。今回はこの機能の基本的な使い方や、より高度な構成について説明します。 AWS LBCとはなにかAWS LBC(Load Balancer Controller)は、Kubernetesのリソースを監視し、AWS Elastic Load Balancerをそれにあわせて管理するコンポーネントです。AWS LBCが監視する対象は、EKS内のIngressリソースとService Type LoadBalancerリソースです。これらのKubern...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[gemma3:1bのStructured Outputを安定させる工夫]]></title>
            <link>https://blog.atusy.net/2025/04/28/gemma3-structured-output/</link>
            <guid>https://blog.atusy.net/2025/04/28/gemma3-structured-output/</guid>
            <pubDate>Mon, 28 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Structured OutputはLLMの出力をプログラムで扱いやすい形式（JSONとか）に落としこむ機能です。gemma3:1bで試してみたところ、temperatureを0にする、システムプロンプトに入力に忠実に構造化出力してと指示するなどの工夫が必要なものの、期待通りの結果を得ることができそうです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[モンティ・ホール問題をPythonで確かめてみた]]></title>
            <link>https://zenn.dev/akasan/articles/90b205bc9bca23</link>
            <guid>https://zenn.dev/akasan/articles/90b205bc9bca23</guid>
            <pubDate>Sun, 27 Apr 2025 13:02:51 GMT</pubDate>
            <content:encoded><![CDATA[みなさん、モンティ・ホール問題をご存知でしょうか？今回はPythonでモンティ・ホール問題が本当にその通りなのか計算してみました。 モンティ・ホール問題とは？これは確率の勉強をする時によく出てくる直感に反する結果となるものの例として扱われます。概要についてはWikipediaを参考にすると以下のようにまとめられます。モンティ・ホール問題（モンティ・ホールもんだい、英: Monty Hall problem）とは、確率論の問題で、ベイズの定理における事後確率、あるいは主観確率の例題の一つとなっている。モンティ・ホール（英語版）（Monty Hall, 本名：Monte Halpe...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Airflow使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/bb86a3442214da</link>
            <guid>https://zenn.dev/akasan/articles/bb86a3442214da</guid>
            <pubDate>Sat, 26 Apr 2025 10:05:07 GMT</pubDate>
            <content:encoded><![CDATA[今回はApache Airflow（以下、Airflow）について調べてみました。調べようと思った理由としては以前から名前は知っていたが調べる機会がなかったGoogle Cloudの勉強をしている中でCloud ComposerがAirflowを使っているということでどんなものか気になっていたからです。今回は本格的な調査というよりは、まずはどんなものかについて調べてみようと思います。 Apache Airflowとは？一言で言ってしまえばワークフロー管理ツールということみたいです。Pythonを使ってワークフローを構成し、スケジューリングを行ったり動作のモニタリングができ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[普段使っている技術スタック紹介]]></title>
            <link>https://zenn.dev/akasan/articles/766c1c3539e778</link>
            <guid>https://zenn.dev/akasan/articles/766c1c3539e778</guid>
            <pubDate>Fri, 25 Apr 2025 14:41:45 GMT</pubDate>
            <content:encoded><![CDATA[今回もすごい簡潔になりますが、普段自分が使っている技術スタックとかを紹介しようと思います エディタ neovimneovimを一応使うことが多いです。ただしガチのvimmerではないので拡張機能をたくさん入れたりはできていません。また、比較的温和なタイプのvimmerなので、本格的に使ってる人からすると「なんでちゃんと使わないんだ」と怒られそうな気がしますw cursor小規模なコード修正とかは基本neovim使ってるんですが、大規模開発とかをする必要がある場合はcursorを使ってます。ただ拡張機能でvimのキーバインド入れているので使い勝手はvimですwcursor...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合]]></title>
            <link>https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/</link>
            <guid>https://sreake.com/blog/testkube-e2e-test-on-kubernetes-cluster/</guid>
            <pubDate>Fri, 25 Apr 2025 12:27:40 GMT</pubDate>
            <content:encoded><![CDATA[Sreake事業部インターン生の荒木です。長期インターン生としてKubernetesやSRE、LLM領域の関連技術など幅広い領域にわたって調査・検証を行っています。 今回、kubernetesクラスタのE2Eテストを統合 […]The post Testkubeとは？KubernetesクラスタにおけるE2Eテストの統合 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します]]></title>
            <link>https://sreake.com/blog/sre-tech-talk-12/</link>
            <guid>https://sreake.com/blog/sre-tech-talk-12/</guid>
            <pubDate>Fri, 25 Apr 2025 11:45:29 GMT</pubDate>
            <content:encoded><![CDATA[この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を、2025年5月16日（金）に開催します。The post SRE向けイベント【3-shake SRE Tech Talk #12】〜o11y Special〜 を開催します first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIにペアプロのナビをさせるaibou.nvimを作った]]></title>
            <link>https://blog.atusy.net/2025/04/25/aibou-nvim/</link>
            <guid>https://blog.atusy.net/2025/04/25/aibou-nvim/</guid>
            <pubDate>Fri, 25 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[atusy/aibou.nvimはAIをペアプロのナビに変身させるNeovimプラグインです。テキストの変更を逐次把握し、リアクションしてくれるので、まるで人間がナビについてくれているような体験を得られます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年4月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/9b2e5528548353</link>
            <guid>https://zenn.dev/akasan/articles/9b2e5528548353</guid>
            <pubDate>Thu, 24 Apr 2025 13:32:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はいつもに比べてさらに短編になりますw特に技術書に絞りまして、最近または過去読んでいて良かったと思う本について紹介していこうと思います。 クラウド系 徹底攻略 Google Cloud認定資格 Associate Cloud Engineer教科書クラウドといえば、Google Cloudに入門するために買ったこの本がまず第一ですね。Associate Cloud Engineerを取るために大変お世話になりました。https://book.impress.co.jp/books/1122101107 Google Cloudではじめる実践データエンジニアリング入門...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500</guid>
            <pubDate>Thu, 24 Apr 2025 02:35:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは、nwiizoです。2025年4月22日と23日、スケジュールの都合で連続して2つの技術イベントに登壇することになりました。それぞれのイベントは異なる切り口でしたが、どちらも「生成AI」をテーマにしたものでした。1日目は「生成AI」と「クラウドネイティブ」の融合、2日目は「生成AI」の「Model Context Protocol（MCP）」に焦点を当てました。生成AI技術は近年急速に進化し、私たちエンジニアの働き方に大きな影響を与えています。私自身も数年前からnvimでGitHub Copilotを日常的に使い、その後Clineなどのコーディングエージェントブームのバズに押されつつもCursorやVSCodeを利用しています。同時に、Cloud Native技術も着実に成熟し、多くの企業のインフラ戦略の中核となっています。現在、これら二つの技術領域が交わることで、特にIaC（Infrastructure as Code）分野での応用が活発化しています。多くの開発者がこの統合に関して様々な課題に直面しており、今回の登壇では、そうした課題に対する私なりの考察と解決策を共有しました。本ブログでは、この2日間の登壇内容を振り返りながら、技術的な洞察やコミュニティでの議論から得た気づきを記録したいと思います。生成AIとクラウドネイティブ技術の統合が開発・運用プロセスを根本から変革しています。本稿はエンジニアが直面する「70%問題」（AIがコードの70%は正確に生成するが、残り30%で致命的ミスを犯す現象）に対して、ガードレールとModel Context Protocol (MCP)の相補的活用による解決策を提案します。インフラ/アプリケーションエンジニアは「思考パートナー」としてAIを活用し、検証文化を確立することで、開発効率と品質を両立できます。本記事では、両イベントでの登壇内容をもとに、AIを単なるツールから戦略的パートナーへと位置づけ直す視点と、認知労働の新たな分担を実現する実践的なフレームワークについて詳しく解説します。Day 1: 生成AIとCloud Nativeの融合を語るイベント: CloudNative Days Summer 2025 プレイベント登壇タイトル: 生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について日時: 2025年4月22日https://cloudnativedays.connpass.com/event/351211/cloudnativedays.connpass.com1日目は、CloudNative Days Summer 2025のプレイベントに参加しました。このイベントの参加者層は主にインフラエンジニアやSRE（Site Reliability Engineer）が中心で、Cloud Native技術への関心が高い方々です。私のセッションでは、生成AIを活用したCloud Native基盤構築について、実践的な観点から解説しました。発表資料 speakerdeck.com発表の詳細セッション内容は以下の4つの大きなセクションに分けて構成しました：1. 生成AIとCloud Nativeの現在地（2025年）まず、現在の生成AIによる開発プロセスの変化について解説しました。従来のコード生成から問題解決支援へと進化しており、AIは単なる「道具」から「思考パートナー」へと変わりつつあります。これは根本的な変化であり、単なる機能向上ではありません。AIが書かれるコードの構文パターンだけでなく、構築されるものの概念モデルに関与できるようになった結果、協働のダイナミクスが質的に変化しています。AIの利用パターンも単発指示→会話型→継続的協働へと発展し、長期的な文脈理解ができるようになっています。これにより、開発ワークフローも大きく変化しています。- コードレビューの前段階をAIが担当し、人間は高次の設計判断に集中- ボイラープレートコードからの解放で、より創造的な作業への時間が増加- テスト品質の標準化によるソフトウェア信頼性の向上しかし実際のところ、AIによるCloud Native実装は「完璧」ではなく、「ある程度必要」な取り組みとして捉えるべきだと強調しました。現場では、以前は「動かない定義」や「架空の機能」に悩まされましたが、モデルの精度向上により問題は大幅に減少しています。それでも、いわゆる「ハルシネーション」と呼ばれる問題は依然として存在するため、AIの出力を盲信せず、検証する姿勢が重要です。特にIaC（Infrastructure as Code）においては、コードと実際のインフラの間に差異が生じることも珍しくありません。AIが生成したインフラ定義は、理想的な環境を想定していることが多く、実際の環境の制約やレガシーシステムとの互換性といった現実的な問題に対応できていないケースがあります。そのため、多くの組織では完全自動化ではなく、ある程度抽象化したり省力化したりしながら、人間による確認と調整を組み合わせたハイブリッドなアプローチを採用しています。これにより、AIの効率性と人間の判断を最適に組み合わせたCloud Native環境の管理が実現されています。learning.oreilly.com2. 実践的なプロンプト設計効果的なAI活用のための「プロンプト設計の5原則」を紹介しました：方向性を与える（Give Direction）具体的な指示や目的を明確に示す例：「高可用性と費用対効果を重視したプロダクション環境向けECSクラスタを作成するTerraformコード」のように具体的にフォーマットを指定する（Specify Format）望ましい出力形式を明確に定義する例：コーディングスタイル、ファイル分割方針などを明示的に記述例を提供する（Provide Examples）期待する出力のサンプルを示す既存の成功パターンを参考に提示する品質を評価する（Evaluate Quality）生成された結果の品質を測定・改善する方法を組み込むセキュリティ、可用性、コスト最適化などの観点を明示作業を分割する（Break Down Tasks）複雑なタスクをより小さな段階に分割するステップバイステップのアプローチを促すこれらの原則を実践することで、生成AIからより質の高い出力を得られることを実例とともに解説しました。また、コンテキスト同梱の重要性についても言及し、意思決定の背景や根拠を明示的に残すことで、組織の暗黙知が形式知化される利点を強調しました。learning.oreilly.com3. ガードレールの構築の手引き生成AIの出力に対する「ガードレール」の重要性を解説しました。ここで特に強調したのが「70%問題」です。これは単なる効率の問題ではなく、ロジスティクスにおける「ラストマイル問題」やロボティクスにおける「不気味の谷」に類似した現象です。完成に近づくほど、残りの課題は不釣り合いに困難になります。しかし、インフラストラクチャにおいて、この残りの30%は単に非効率なだけでなく、潜在的に壊滅的な問題を引き起こす可能性があります。生成AIは通常、コードの約70%は驚くほど正確に生成できますが、残りの30%で致命的なミスを犯すことがあります。特にIaCのような厳密性が求められる領域では、この問題が顕著です。AWS IAMポリシー生成時に過剰な権限を付与する傾向リソース間の複雑な依存関係の理解不足コスト最適化を考慮しない設計提案これを「優秀だが何も確認しない若手開発者」と表現し、スピードは速いがIaC特有の制約を無視してしまう傾向があることを指摘しました。この問題への対策として、以下のようなガードレールを提案しました：コード品質検証構文チェック、静的解析、コーディング規約の自動適用セマンティック検証リソース間の整合性や依存関係の正確性を検証セキュリティ検証脆弱性スキャン、最小権限原則の適用コンプライアンス検証組織ポリシーや法規制への適合性確認コスト最適化検証リソース効率や予算管理の自動チェックこれらのガードレールは、特にPull Requestの段階で自動適用することで、問題の早期発見と修正を可能にします。また、単なる検証だけでなく、AIの解釈コストを考慮した仕様の記述方法についても言及しました。syu-m-5151.hatenablog.com4. ガードレールを超えて行動するMCP最後に、Model Context Protocol（MCP）を活用した次世代のAI活用法について紹介しました。MCPはAIモデルが外部ツールやデータにアクセスするための標準プロトコルで、「AIとシステムをつなぐUSB規格」とも表現できます。しかし、この比喩は理論的な重要性を過小評価しています。USBは物理的な接続を標準化しましたが、MCPは認識論的な接続—知識がどのようにアクセス、検証、適用されるかを標準化しているのです。MCPとガードレールの補完関係は弁証法的関係とも言えます。ガードレールは出力の「安全性」「品質」を確保（アウトプット品質）MCPは入力の「情報量」「正確性」を向上（インプット品質）この相補的な関係は、次のような弁証法的パターンを形成します。テーゼ：AIは限られたコンテキストに基づいてコードを生成アンチテーゼ：人間はガードレールを通じてこのコードを検証・修正統合：MCPはAIのコンテキストを拡張し、検証の必要性を減少（ただし排除はしない）両者を組み合わせることで、70%問題の克服に近づける可能性を示しました。ただし、人間の判断の必要性は排除されるのではなく、人間の役割が「構文の検証者」から「概念的アプローチの検証者」へとシフトします。これは認知的労働の分担の進化を示唆しています。実際の活用例として、AWS MCP ServersやGoogle Cloudのkubectl-aiなどを紹介し、これらがクラウド環境とAIの連携を実現し、複雑なインフラ管理を自然言語で操作可能にする機能について説明しました。syu-m-5151.hatenablog.com質疑応答での議論セッション後の質疑応答では、特に以下の点について活発な議論がありました：AIによるIaC生成の信頼性向上のための具体的な取り組み組織への導入方法とチーム全体でのAI活用ポリシーCI/CDパイプラインへのガードレール組み込みの実践例特に印象的だったのは、「AIを100%信頼せず、人間の検証を常に行う文化をどう作るか」という質問で、これはまさに今のAI活用における核心的な課題だと感じました。Day 2: MCPの世界を掘り下げるイベント: AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-登壇タイトル: ここはMCPの夜明けまえ日時: 2025年4月23日https://hack-at-delta.connpass.com/event/350588/hack-at-delta.connpass.com2日目は、AI駆動開発に特化したイベントで登壇しました。こちらは主にアプリケーション開発者やAI研究者が中心の聴衆で、より技術的に深い内容を求められる場でした。私のセッションではModel Context Protocol（MCP）について詳しく解説し、実装例や将来展望について語りました。発表資料 speakerdeck.com発表の詳細MCPの基本概念から始め、その主要構成要素について詳しく解説しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得・検証する「認識論的インターフェース」とも言えるものです。この枠組みは、人間の認知プロセスを模倣しながらも、機械による利用のために標準化しています。modelcontextprotocol.io1. Resources（リソース）MCPにおけるResourcesは、LLMにコンテキストを提供する読み取り専用のデータソースです。テキスト形式とバイナリ形式のデータをURIで一意に識別し、AIの会話コンテキストとして活用します。アプリケーション制御型設計: クライアントがリソースの使用時期と方法を決定人間が読みやすい名前や説明: AIの理解を促進するためのメタデータ付き動的リソース: URIテンプレートを提供して、パラメータ化されたリソースアクセスが可能クライアントはresources/listエンドポイントでリソース発見、resources/readで内容取得、さらに購読機能で更新通知を受信できます。これにより、AIは最新のドキュメントや構成情報などを参照しながら回答を生成できるようになります。2. Prompts（プロンプト）Promptsは標準化された対話パターンを定義するテンプレートです。ユーザー制御型の再利用可能なテンプレートとして設計され、一貫したLLM体験を提供します。動的な対話フロー: 引数を受け取り、リソースから文脈を含め、複数の対話をチェーン化構造化された定義: 各プロンプトは名前・説明・引数の構造で定義クライアントインターフェース: prompts/listエンドポイントで発見し、prompts/getで使用プロンプトはリソースからの情報を埋め込み、複数のメッセージ交換を事前定義して複雑な対話フローを作成可能です。クライアントUIではスラッシュコマンドやクイックアクションとして表示され、ユーザーに直感的な操作を提供します。3. Tools（ツール）Toolsは LLM に実世界での行動力を与える機能です。サーバーが公開する実行可能な機能を介して計算処理やAPI操作を実行できます。明確な構造: 各ツールは名前、説明、入力スキーマ、アノテーションで定義動作特性の明示: 読取専用・破壊的操作・べき等性などの情報を含むエンドポイント: クライアントはtools/listで発見し、tools/callで実行ツールの用途は多岐にわたり、システム操作、外部APIラッパー、データ変換など様々なパターンでAIの能力を拡張し、実世界での影響力を高めます。4. Sampling（サンプリング）Samplingは、サーバーがLLMに補完を要求できる機能です。クラスチートを行うことなく、会話中にLLMの判断を活用できる仕組みを提供します。メカニズム: サーバーがsampling/createMessageを要求し、クライアントがレビュー後にLLMから結果を取得ヒューマンインザループ設計: ユーザーが介在することでセキュリティとプライバシーを確保柔軟な設定: 様々なパラメータで出力を調整可能（temperature、maxTokens、stopSequencesなど）サンプリングによって、エージェント的ワークフローが可能になり、データ分析、意思決定、構造化データ生成、複数ステップのタスク処理などの高度な機能を実現できます。5. Roots（ルーツ）Rootsはサーバーの操作範囲を定義する機能です。クライアントがサーバーに対して関連リソースとその場所を伝える手段として機能します。操作境界の定義: ファイルシステムパスやHTTP URLなどの有効なURIを使用ワークスペース明確化: クライアントは接続時に推奨ルーツのリストを提供柔軟な範囲設定: プロジェクトディレクトリ、リポジトリ、APIエンドポイントなどを定義Rootsにより、AIの操作範囲が明確化され、異なるリソースを同時に扱う際の組織化が容易になります。実装例と活用可能性セッションの後半では、実際のMCP実装例を紹介しました。よく紹介されているMCPを紹介してもどうしようもないので他に知見になりそうでかつ応用が効きそうなMCPを紹介しています。AWS MCP ServersAWSが提供する公式MCP実装について説明しました。github.comAWS Documentation MCP Server: AWS公式ドキュメント検索と情報提供Bedrock Knowledge Bases MCP Server: カスタムナレッジベース連携CDK MCP Server: AWS CDKプロジェクト支援Terraform MCP Server: Terraformプロバイダー情報参照Lambda MCP Server: 任意のLambda関数をMCPツールとして実行kubectl-aiGoogle Cloudの大規模言語モデルを活用したkubectlプラグインについても解説しました。github.comkubectl ai "nginxのDeploymentを作成して、レプリカ数は3、リソース制限ありで"kubectl ai "なぜPodがPendingのままなのか調査して"kubectl ai "payment-serviceのレプリカを3から5に増やして"このような自然言語コマンドでKubernetesクラスタを操作できる例を紹介し、MCPによる実用的な活用方法を示しました。自作MCP実装の可能性MCPの実装を通じて得られる知見の価値について触れ、「MCPは実装してこそ理解できる。実装を通じて感覚を掴み、独自の拡張も検討できる」と強調しました。github.comMCPの課題と展望MCPの将来性について議論する中で、現状の課題も率直に指摘しました：レスポンス時間の増加: 外部API呼び出しによる遅延情報統合の難しさ: 矛盾する情報の調停コンテキスト長の制限: 大量のデータ処理における限界ハルシネーション問題: 情報アクセスは改善するが、解釈ミスの可能性は残る70%→100%ではなく、実際には70%→80%程度の改善が現実的な期待値であり、人間による最終確認は依然として重要であることを強調しました。これは漸近的な信頼性向上であり、段階的な変化ではないことを示唆しています。この分野には以下のような興味深い理論的緊張関係が存在します。信頼 vs 検証: 人間による検証の持続的な必要性は、完全に自動化された開発の約束と矛盾します。一般性 vs 特殊性: AIは一般的なパターンに優れていますが、ドメイン固有の制約に苦戦する一方、人間はその逆の傾向があります。速度 vs 信頼性: AIによる開発の加速は、増加する検証負担とのバランスが必要です。抽象化 vs 実装: エンジニアがより抽象的な思考にシフトするにつれ、実装の詳細とのつながりが弱まり、新しい種類のエラーが生じる可能性があります。連日登壇を通じて感じたこと2日間の登壇を通じて、生成AIとクラウドネイティブの融合が急速に進んでいることを実感しました。特に印象的だったのは、両者の接点において：1. 補完し合う技術領域Day 1で話したガードレールとDay 2で紹介したMCPは、互いに補完する関係にあります。ガードレールがAIの出力の「安全性」「品質」を確保し、MCPが入力の「情報量」「正確性」を向上させます。この組み合わせこそが、AIの能力を最大限に引き出すための鍵です。例えば、MCPで外部情報を参照しながらIaCコードを生成し、それをガードレールで検証するというパイプラインを構築することで、より信頼性の高いインフラ構築が可能になります。これは認知労働の新たな分担を示唆しています。パターンマッチングとリコールが機械のドメインになり、概念的統合と判断が人間のドメインとして残ります。この協業体制がもたらす最も深い洞察は、我々が「プログラミングの終焉」ではなく「プログラミングの新たな改革」を目撃しているということかもしれません。2. 実装の成熟度の差技術の普及段階にも明確な違いがあります。Cloud Native環境でのAI活用は既に実用段階に入っていますが、MCPはまさに「夜明け前」の状態です。標準化は進んでいるものの、実装はまだ発展途上であり、今後急速に普及していくでしょう。特に興味深いのは、大手クラウドプロバイダーが相次いでMCP実装を提供し始めていることで、これはMCPが業界標準になりつつある証拠と言えます。現在、私たちは重要な技術的変曲点に立っているのです。3. 共通する課題どちらの領域でも、ハルシネーション（幻覚）問題や70%問題など、AIの限界をどう乗り越えるかが共通の課題となっています。完全自動化への過信は危険であり、人間による検証と理解が依然として不可欠です。重要なのは、AIをただの便利ツールではなく、自分の技術的判断力を強化するための「知的パートナー」として活用する姿勢です。優れたエンジニアは、AIの提案を鵜呑みにせず、自らの専門知識と経験に基づいて評価し、改善します。つまり、エンジニアとしての基本的な理解力や技術センスがあってこそ、AIとの協働が真に価値を生み出すのです。両イベントの参加者との議論を通じて、多くの組織がAIツールの導入に熱心である一方で、その限界や適切な活用方法についての理解はまだ発展途上であることを実感しました。MCPは単なる技術標準ではなく、AIシステムが知識を獲得し検証する「認識論的枠組み」を表しています。これはAIと人間のコラボレーションにおける根本的なシフトを示唆しています。認知労働の新たな分業開発現場では、AIを全能の魔法ではなく、特定の目的に特化した強力な助手として位置づけています。これは認知労働の新たな分業を形成しています。戦略的なAI活用アプローチ私のチームでは、AIツールを以下のような明確な目的で活用しています。プロトタイピングの加速: 新機能やアイデアの初期実装を迅速に行い、議論の土台を作るルーティン作業の自動化: テストコード生成やボイラープレートコードなど、創造性を必要としない作業の効率化知識探索の支援: ドキュメント検索やAPI仕様の理解など、情報収集を効率化コードレビューの補助: 基本的なコーディング規約やベストプラクティスのチェックこれらの活用方法は、AIと人間の間の認知労働の分業を最適化するものです。AIはパターン認識や情報検索に優れている一方、人間はコンテキスト理解や倫理的判断に長けています。この相補的な関係を活かすことで、開発効率と品質の両方を高めることができます。レビュープロセスと制約の重要性生成AIの限界を認識した上で、以下のようなガードレールを設けています。書き込み権限の制限: 生成コードは必ずレビューを経てから取り込む、というかまだ道具として適切に動作し続けることができない重要な判断の人間による最終確認: 特に権限設計やセキュリティ関連の実装対話的な生成プロセス: 一度に大量のコードを生成するのではなく、段階的に生成・修正を繰り返すこれらの制約は一見効率を下げるように思えますが、長期的には品質と信頼性の向上につながっています。これは、速度と信頼性のトレードオフを認識し、適切なバランスを取る試みと言えるでしょう。まとめ生成AIとCloud Nativeは、かつて独立した技術領域として発展してきましたが、現在その境界線は急速に溶け合いつつあります。この2日間の登壇を通じて、両技術の融合がもたらす無限の可能性と避けられない課題を、互いに補完し合う視点から考察できたことは非常に意義深い経験でした。技術の交差点に立つ私たちは、単に新しいツールを導入するだけでなく、開発プロセス全体の再構築と認知労働の新たな分担という本質的な変革の只中にいます。連日の登壇準備は骨の折れる作業でしたが、技術コミュニティの旺盛な好奇心と革新への情熱に触れることができ、その労力を遥かに上回る充実感を得ることができました。この変革の中心には、いくつかの興味深い理論的緊張関係が存在します。信頼と検証のジレンマでは、AIの自律性向上と人間による検証の継続的必要性が矛盾します。一般と特殊の相克では、AIが一般パターンに秀でる一方、ドメイン固有の制約に弱く、人間はその逆の強みを持つという相補性があります。速度と信頼性のトレードオフでは、開発速度の飛躍的向上と増大する検証負担のバランスが求められます。そして抽象化と実装の乖離では、エンジニアの思考が高次の抽象レベルへ移行するほど、具体的実装との接点が希薄化する現象が起きています。これらの緊張関係は、単なる技術的課題ではなく、ソフトウェア開発の本質的な変容を示唆しています。クラウドネイティブと生成AIの交差点に立つ私たちは、新たな技術パラダイムの構築者として、これらの緊張関係を認識しながら、持続可能な開発文化の創造に取り組む必要があります。syu-m-5151.hatenablog.com今日から俺は今後、プログラマの役割は根本から変容していくでしょう。コードを書く職人からドメインを抽象化し構成要素を再構築する建築家へと、その専門性は高度化していきます。この変化は、ソフトウェアエンジニアリングの本質における歴史的な転換点を示唆しています。www.oreilly.comこの転換点で、エンジニアの進化には二つの道筋が開かれていると思っています。ひとつはドメインエキスパートとしての道で、AIが容易に獲得できない専門知識を磨き、AIを疑い検証するメンタリティを養い、専門知識をMCPやFunction Callingとして実装し、自らが「検証者」としての価値を高める方向性です。もうひとつはパイプライン設計者としての道で、コードを直接書くのではなく、コードを生成・検証・デプロイするシステムを構築し、プロンプトエンジニアリングの技術を磨き、言語化・設計・検証のスキルを研ぎ澄まし、AIの限界を理解しそれを補完するシステムを構築する方向性です。これらの進化は、かつてのアセンブリから高水準言語への移行や、手続き型からオブジェクト指向プログラミングへの移行に似ています。各移行は低レベルの懸念事項を抽象化し、エンジニアがより高レベルのアーキテクチャに集中できるようにしてきました。私たちはいま、そのような歴史的変革の真っただ中にいるのです。最後に、この貴重な機会を提供してくださったCloudNative Days Summer 2025プレイベントおよびAI駆動開発実践の手引きイベントの運営チームの皆様に心より感謝申し上げます。両イベントの緻密な運営と温かいサポートのおかげで、充実した登壇体験ができました。また、質疑応答で鋭い質問を投げかけ、議論を深めてくださった参加者の皆様にも深く感謝いたします。これからも技術コミュニティの発展に微力ながら貢献していきたいと思います。あとがき1日目の資料は出来があまりよくなかった。良い資料だとは思うが自分の中でもう少し整理や深堀りができたはずだし、語り尽くせなかった部分もとても多い。時間がなかったという言い訳をさせてください。そもそも、CfPも落ちて本イベントでの登壇の機会も逸してしまっている。一方、2日目のMCPの資料はよくできたと思う。元々のブログがあったというのもある。正直これは100点満点中90点ぐらいの出来栄えだと自負していた。夜を徹して準備し、最新の技術動向を盛り込み、実装例も丁寧に解説した。聴衆からの反応も上々で、「これ以上ない資料ができた」とさえ思っていた。そんな矢先、mizchi氏のAfter Cline - あるいは語りえぬ者について語ろうとする時代についてという資料を目にした瞬間、天と地の差を見せつけられた気分だった。あれは単なる150点の資料ではない。次元が違う。まるで将棋で「自分は十分に読んだ」と思った直後に、相手が5手先の必勝手順を淡々と指し示すような絶望感。技術的な深さ、哲学的考察、そして何より言語化能力の圧倒的差...。悔しさで夜も眠れない。次回こそは、このリベンジを果たしてみせる。いや、リベンジすらおこがましい。あの高みに少しでも近づけるよう、もっと考察を深めなければ。とにかく、とても、とても悔しい...。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[自分用コマンドにはプレフィックスつけるとよさげ]]></title>
            <link>https://blog.atusy.net/2025/04/24/prefix-personal-commands/</link>
            <guid>https://blog.atusy.net/2025/04/24/prefix-personal-commands/</guid>
            <pubDate>Thu, 24 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[~/.local/bin/T-hogeみたいにT-とかのprefixつけておくと、補完が効いて便利。大文字にしとくと、被りも少ないよ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Cloud Architect編~]]></title>
            <link>https://zenn.dev/akasan/articles/4d7972b7c5f84c</link>
            <guid>https://zenn.dev/akasan/articles/4d7972b7c5f84c</guid>
            <pubDate>Wed, 23 Apr 2025 12:53:56 GMT</pubDate>
            <content:encoded><![CDATA[この記事の続編になります。https://zenn.dev/akasan/articles/6b5d5f9b1446d4 Professional Cloud ArchitectについてProfessional Cloud Architect（以下、PCA）は、公式では以下のように説明されています。Professional Cloud Architects は、組織が Google Cloud 技術を利用できるように支援します。クラウドアーキテクチャと Google Cloud に関する専門的な知識を活かして、ビジネス目標を実現するために、スケーラブルで高可用性を備え、堅牢か...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenFeature を使ったアプリケーション開発]]></title>
            <link>https://sreake.com/blog/openfeature-feature-flag-management/</link>
            <guid>https://sreake.com/blog/openfeature-feature-flag-management/</guid>
            <pubDate>Wed, 23 Apr 2025 09:40:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめに はじめましての方も、そうじゃない方も、こんにちはこんばんは。Sreake 事業部 佐藤慧太(@SatohJohn)です。 皆さん、アプリケーションのコードを変更せずに機能の有効無効を切り替えることができる Fe […]The post OpenFeature を使ったアプリケーション開発 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ここはMCPの夜明けまえ]]></title>
            <link>https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae</link>
            <guid>https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae</guid>
            <pubDate>Wed, 23 Apr 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、「AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒」というイベントで「ここはMCPの夜明けまえ」 🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: 【ハイブリッド開催】AI駆動開発実践の手引き -これが僕/私のAI（アイ）棒-- 公式URL: https://hack-at-delta.connpass.com/event/350588/📝 登壇ブログ- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dockerを使用せずにイメージを作成し実行してみる - go-containerregistryによる実装]]></title>
            <link>https://qiita.com/m_pig/items/82643135254b5b326e61</link>
            <guid>https://qiita.com/m_pig/items/82643135254b5b326e61</guid>
            <pubDate>Wed, 23 Apr 2025 02:38:27 GMT</pubDate>
            <content:encoded><![CDATA[このページではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコン…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[home row mods無理だったわ]]></title>
            <link>https://blog.atusy.net/2025/04/23/give-uphome-row-mods/</link>
            <guid>https://blog.atusy.net/2025/04/23/give-uphome-row-mods/</guid>
            <pubDate>Wed, 23 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[home row modsはホームポジションにあるasdfなどのキーを長押しでShiftやCtrlなどの修飾キー化する仕組みです。私はKeyball 61のファームウェアの設定変更で導入してみましたが、あまりの誤入力の多さに撤退を決意しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Taskfile（taskコマンド）のfish補完定義を改善してグローバルタスクに対応した]]></title>
            <link>https://blog.atusy.net/2025/04/23/cloud-run-with-iam/</link>
            <guid>https://blog.atusy.net/2025/04/23/cloud-run-with-iam/</guid>
            <pubDate>Wed, 23 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Taskfile（taskコマンド）は、数あるタスクランナー／ビルドツールの1つです。Makefile代替とも言えますね。詳しくは公式サイト（https://taskfile.dev/）や「Taskfileを使ってみよう」などの記事を参考にしてもらうとして、個人的にTaskfileを好んでいる理由をいくつか挙げておきます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cuMLとsklearnを簡易比較してみた]]></title>
            <link>https://zenn.dev/akasan/articles/e7d9b92bf6dee2</link>
            <guid>https://zenn.dev/akasan/articles/e7d9b92bf6dee2</guid>
            <pubDate>Tue, 22 Apr 2025 14:54:06 GMT</pubDate>
            <content:encoded><![CDATA[cuMLとは？今回利用するcuMLを説明する前に、RAPIDSについて紹介します。RAPIDSとは公式の説明を引用すると最も広く使用されているオープンソース データ ツール群と互換性のある API を備えた、GPU で高速化されたデータ サイエンスおよび AI ライブラリのオープンソース スイートです。データ パイプライン全体にわたりパフォーマンスを桁違いで大規模に高速化できます。ということです。要は、NVIDIA GPUを効率よく使うためのライブラリをユースケースごとに提供してくれているということです。詳しくは以下の公式リンクを参照ください。https://develo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[EKS Pod Identityを利用してセキュアにkubernetesリソースからAWSリソースにアクセスする]]></title>
            <link>https://zenn.dev/kamos/articles/873ecca3f9bab0</link>
            <guid>https://zenn.dev/kamos/articles/873ecca3f9bab0</guid>
            <pubDate>Tue, 22 Apr 2025 09:37:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS EKS (Elastic Kubernetes Service) を利用している場合、Kubernetes上のリソースだけで完結させることはほぼなく、多くの場合、kubernetesの世界にないAWSリソースにアクセスする必要があります。例えば、S3バケットへのファイルのアップロード、DynamoDBのテーブルへのデータの読み書き、SQSキューへのメッセージの送受信など、様々なユースケースが考えられます。その際に使用するのがPod Identityです。https://docs.aws.amazon.com/ja_jp/eks/latest/userguide/p...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIによるCloud Native基盤構築の可能性と実践的ガードレールの敷設について]]></title>
            <link>https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite</link>
            <guid>https://speakerdeck.com/nwiizo/sheng-cheng-ainiyorucloud-native-ji-pan-gou-zhu-noke-neng-xing-toshi-jian-de-gadorerunofu-she-nituite</guid>
            <pubDate>Tue, 22 Apr 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは皆さん！本日はCloud Native Daysのプレイベントで登壇させていただきます。2019年以来の登壇となりますが、当時はまだ肩こりなんて無縁だったんですよね…。時の流れは容赦ないもので、最近の肩こりが辛くて昨日も整骨院に通ってきました。30分の持ち時間に対してスライドが80枚以上という暴挙にも出ています。---本日、「CloudNative Days Summer 2025 プレイベント」というイベントで「生成AIによるCloud Native 基盤構築の可能性と実践的ガードレールの敷設について」 🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: CloudNative Days Summer 2025 プレイベント- 公式URL:https://cloudnativedays.connpass.com/event/351211/ - イベントのURL: https://event.cloudnativedays.jp/cnds2025📝 登壇ブログ- 2025年4月、AIとクラウドネイティブの交差点で語った2日間の記録 #CNDS2025 #hack_at_delta- https://syu-m-5151.hatenablog.com/entry/2025/04/24/113500]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerの独自言語「LookML」とは]]></title>
            <link>https://sreake.com/blog/looker%e3%81%ae%e7%8b%ac%e8%87%aa%e8%a8%80%e8%aa%9e%e3%80%8clookml%e3%80%8d%e3%81%a8%e3%81%af/</link>
            <guid>https://sreake.com/blog/looker%e3%81%ae%e7%8b%ac%e8%87%aa%e8%a8%80%e8%aa%9e%e3%80%8clookml%e3%80%8d%e3%81%a8%e3%81%af/</guid>
            <pubDate>Tue, 22 Apr 2025 03:29:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 2023年10月にGoogleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されてから、早1年と半年程が経ちました。 もしかすると、「Lookerを導入してみた」「ま […]The post Lookerの独自言語「LookML」とは first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DagsHub使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/7efdcc1c2d4141</link>
            <guid>https://zenn.dev/akasan/articles/7efdcc1c2d4141</guid>
            <pubDate>Mon, 21 Apr 2025 12:01:16 GMT</pubDate>
            <content:encoded><![CDATA[今回はAIのデータやモデルについて管理することに重きを置いたDagsHubというサービスについて、その紹介と使い方をご紹介していこうと思います。 DagsHubとは？一言で言うと、データサイエンスに関わるコードだけでなくデータについても合わせて管理するためのレポジトリを提供してくれるサービスです。コードの管理だけであればGitHubなどで問題ありませんが、いわゆるdvcを利用したデータ管理を行っているようなプロジェクトであったり、複数人でチームを組んで開発するデータサイエンスプロジェクト向けのレポジトリを探している場合は選択肢としてDagsHubも候補かと思います。特徴として、DA...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimも進化するMCPHubとAvante.nvimの連携ガイド]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/21/101837</guid>
            <pubDate>Mon, 21 Apr 2025 01:18:37 GMT</pubDate>
            <content:encoded><![CDATA[はじめにModel Context Protocol（MCP）は、LLM（大規模言語モデル）と外部システムの間の通信を可能にする標準化されたプロトコルです。これにより、LLMに追加のツールやリソースを提供して、その能力を拡張できます。MCPは、開発者がLLMに外部機能へのアクセスを提供するための統一された方法を提供します。簡単に言えば、MCPはLLMが「外の世界」と対話するための共通言語です。これにより、ChatGPTやClaudeなどのAIが、ファイルやウェブサイトを読み書きしたり、コマンドを実行したり、LSP（Language Server Protocol）の診断情報にアクセスしたりできるようになります。syu-m-5151.hatenablog.comMCPHub.nvimMCPHub.nvimは、MCPサーバーをNeovimワークフローに統合するための強力なプラグインです。このプラグインは、集中管理された設定ファイルを通じてMCPサーバーを構成・管理し、ツールやリソースを閲覧・インストール・テストするための直感的なUIを提供します。LLM統合のために設計されており、プログラムによるAPI呼び出しとインタラクティブなテスト機能の両方を提供します。https://github.com/ravitemer/mcphub.nvim より引用github.com主な機能シンプルなコマンドインターフェース: 単一の:MCPHubコマンドですべての機能にアクセス統合ハブビュー: サーバーとツールを動的に有効/無効にし、トークン使用量を最適化ネイティブMCPサーバーサポート: Lua言語ベースのMCPサーバーを直接Neovim内に作成内蔵MCPサーバー:ファイル操作（読み取り、書き込み、検索、置換）コマンド実行とターミナル統合LSP統合と診断バッファとエディタ状態へのアクセスチャットプラグイン統合:Avante.nvimCodeCompanion.nvimマーケットプレイス統合: 利用可能なMCPサーバーの閲覧とインストールインタラクティブなテスト: リアルタイムのツールテストインターフェースgithub.comLLMとMCPの連携従来のLLMチャットは「単なる会話」に過ぎませんでした。ユーザーが質問し、AIが応答する。もしくはユーザーが質問し、AIがその範囲内で変更する。しかし、MCPをNeovimに統合すると、LLMは単なる会話の相手ではなく、あなたのNeovim開発環境で「手」を持つ実践的なアシスタントに変わります。Neovimでは、MCPを通じてLLMに以下のような強力な機能へのアクセスを提供できます。ファイルの読み取りと書き込み - バッファ内容の分析や自動生成コードの挿入ファイルの検索と置換 - プロジェクト全体でのリファクタリングや一括修正シェルコマンドの実行 - git操作やビルドコマンドの自動実行LSP診断情報の取得 - エラーや警告の分析と自動修正提案バッファ間の移動とコンテンツの取得 - 複数ファイルにまたがる変更の一括適用インタラクティブなプロンプトの提供 - コードレビューや改善提案のための対話Neovimのキーマッピングやコマンドの生成と実行 - カスタム操作の自動化MCPはLLMをNeovimエコシステムの一部として統合し、あなたのコーディング体験を根本から変革します。Avante.nvimとの連携：実践的なAIペアプログラミングMCPHub.nvimは、NeovimのためのAIチャットプラグインとシームレスに連携できます。現在、Avante.nvimとCodeCompanion.nvimの両方に対応しており、どちらでも同じMCPツールを活用できます。私がAvante.nvimを使っているので紹介するのはこちらです。syu-m-5151.hatenablog.comAvante.nvimはMCPHubと統合することで、LLMに強力なツールへのアクセスを提供できます。MCPHubのツールを有効にするには、Avanteの設定に以下のように追加しますrequire("avante").setup({    -- その他の設定    system_prompt = function()        local hub = require("mcphub").get_hub_instance()        return hub:get_active_servers_prompt()    end,    custom_tools = function()        return {            require("mcphub.extensions.avante").mcp_tool(),        }    end,})github.comMCPが解決する問題従来、各LLMチャットプラグインは独自のツールシステムを実装していました。例えば、AvanteとCodeCompanionでは、同一の機能を実現するために異なるコードを書く必要があり、プラグイン間での互換性がありませんでした。また、Neovimの機能にアクセスするための標準的な方法が存在せず、各プラグイン開発者が独自の実装を行う必要がありました。MCPHubはNeovim環境において以下のような問題を解決します。一度実装すれば、どこでも動作：ツールを一度実装すれば、Avante.nvimとCodeCompanion.nvimなど、すべてのMCP対応チャットプラグインで共通して利用可能標準化されたAPI：res:text():image():send()のような直感的なチェーンAPIにより、Neovimの機能に一貫した方法でアクセス統一された指示：ツール、リソース、テンプレートを一箇所で管理し、LLMに渡す指示を簡素化完全なリソースシステム：URI型のリソースアクセスにより、Neovimバッファ、ファイルシステム、LSP情報などに統一的にアクセス標準型のレスポンス：テキスト、画像、バイナリデータなどの標準対応により、多様な出力形式をサポート集中型ライフサイクル管理：サーバーの状態を一元管理し、パフォーマンスを最適化MCPHubの実践的なNeovimワークフローNeovimでのハンズオン開発において、MCPHubを活用したワークフローは以下のようになります：:MCPHub コマンドでMCPハブUIを開き、利用可能なツールとサーバーを確認必要なMCPサーバー（ファイル操作、LSP、ターミナルなど）を有効化有効化したサーバーのツールやリソースをMCPハブUIで確認し、機能を把握<leader>aeなどのキーマップでAvanteのインターフェースを開き、タスクをLLMに依頼LLMはMCPツールを使って様々なタスクを実行し、結果をバッファに直接反映実践例: Neovimでのコードリファクタリングたとえば、「このプロジェクトでアロー関数を通常の関数に変換したい」とLLMに伝えると、NeovimとMCPを活用したLLMは以下のようなステップを自動で実行します。search_filesツールでNeovimのtelescope/ripgrepを使いJavaScriptファイルを検索read_fileツールでNeovimバッファを通じて各ファイルの内容を読み取りコードを解析してアロー関数を特定replace_in_fileツールでNeovimのテキスト置換機能を使い変換を実行変更をプレビューしたり、自動で適用したりする選択肢を提示必要に応じてLSP診断を実行し、変換後のコードが正しく動作することを確認これにより、通常であれば複数のNeovimコマンドと手動作業が必要なリファクタリングを、単一のLLMとの対話で完了できます。今後の展望MCPは、LLMをテキスト生成の枠を超えて、Neovimの強力な開発環境と統合された実用的な開発アシスタントとして活用する道を開きます。MCPHub.nvimのようなプラグインにより、Neovimユーザーはこの可能性を最大限に活用できます。今後の発展としては以下が期待できます：Neovim専用のMCPツール: Neovimの特性を活かした専門的なMCPツールの開発言語固有のアシスタント: 各プログラミング言語に特化したLSPと連携したコーディングアシスタントプロジェクト管理の自動化: git操作やプロジェクト構造の分析・最適化の自動化カスタムワークフロー: 個人の開発スタイルに合わせたAIアシスタントの調整MCPは単なる技術的な進歩ではなく、NeovimユーザーとAIの協業の形を根本的に変える可能性を秘めています。これにより、コーディングの効率性と創造性が飛躍的に向上するでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Langflowを使ってみた ~arXivから論文引っ張ってこよう編~]]></title>
            <link>https://zenn.dev/akasan/articles/6357f1dd2b52ac</link>
            <guid>https://zenn.dev/akasan/articles/6357f1dd2b52ac</guid>
            <pubDate>Sun, 20 Apr 2025 13:31:42 GMT</pubDate>
            <content:encoded><![CDATA[今回はノーコードでGUIベースでLangChainのフローを実装できるLangflowを使って、arXivから論文のリコメンドを提供してくれるRAGを作ってみようと思います。 LangFlowとは？Langflowとは、AIエージェントやワークフローをさまざまな用意済みAPIを利用して構築することができるノーコードツールです。とてもわかりやすいGUIで提供されており、かつセルフホストで利用できるという点もとてもいい機能だと思います。また、ドキュメントも豊富に用意されているため、利用開始時もハードルが低いと思います。https://www.langflow.org/ 今回作って...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おすすめgitコマンド]]></title>
            <link>https://zenn.dev/akasan/articles/17fdafb60e39fc</link>
            <guid>https://zenn.dev/akasan/articles/17fdafb60e39fc</guid>
            <pubDate>Sat, 19 Apr 2025 13:28:55 GMT</pubDate>
            <content:encoded><![CDATA[プログラムをするすべての皆さんのお供と言っても過言ではないでしょう、git。gitにはデフォルトで利用可能なコマンドに加えて、サードパーティ製だったりオプショナルでインストールできるコマンドがたくさんあります。そんなコマンドたちについて、自分が普段使っているコマンドたちをいくつかご紹介したいと思います。なお、使い方については別の記事で解説できればと思います。また、そんなに個数はないのはご容赦ください そもそもどうやってコマンドを探しているかもちろんネット上でgitコマンドについて「こういうコマンドあるかな？」とかで調べたりしますが、自分が好きなのはbrew search gitを実...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Associate Cloud Engineer編~]]></title>
            <link>https://zenn.dev/akasan/articles/6b5d5f9b1446d4</link>
            <guid>https://zenn.dev/akasan/articles/6b5d5f9b1446d4</guid>
            <pubDate>Fri, 18 Apr 2025 13:02:30 GMT</pubDate>
            <content:encoded><![CDATA[私は現職に入るまでに、業務でGoogle Cloud自体は利用してきました。サービスで言うと以下は使ったことがありました。Cloud RunCloud SchedulerCloud SQLCloud StorageCloud VPCCloud IAMしかし、そのこれらのサービスについても初歩的な使い方しか分からず、その他のサービスについては知識もほとんどない状態でした。そこでGoogle Cloudの認定試験を受験することをきっかけとして、どんどん使えるようになろうと考えております。自身はMLエンジニアではありますが、最近はクラウド上でMLシステムを構築することが主流に...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIによる障害対応訓練RPG v0.1.0を遊ぶには？]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821</guid>
            <pubDate>Thu, 17 Apr 2025 03:08:21 GMT</pubDate>
            <content:encoded><![CDATA[はじめにシステム障害は、どんなに優れた組織でも避けられない現実です。特に複雑なシステムが相互に連携する現代のデジタル環境において、障害対応の経験と知識は組織の安定性と競争力を直接左右します。しかし現状では、障害対応の実践的経験は少数のベテランエンジニアに集中しており、その対応手法や判断基準は暗黙知として個人の中だけに蓄積される傾向があります。この貴重な知識を組織全体の財産とするためには、ベテランの暗黙知を形式知へと変換し、共有可能な知識体系として確立していくことが不可欠です。これにより、新人エンジニアも体系的に経験を積む機会が生まれ、組織内の知識格差を解消することができます。結果として、障害対応の品質の均一化が実現し、組織全体のレジリエンスが向上するのです。syu-m-5151.hatenablog.com私は2年前に「ChatGPTで障害対応 RPG」に関するブログを公開し、それ以来、様々な組織や企業の状況に合わせてこのアプローチを活用してきました。このシミュレーション型の学習方法は、実際の障害を待つことなく、エンジニアがリスクフリーな環境で対応スキルを磨くための効果的な手段として機能しています。github.comcloud.google.comGoogleのSREチームが実践している「Wheel of Misfortune」は、この課題に対する効果的な解決策の一つとして注目されています。実際の本番システムに影響を与えることなく、ロールプレイング形式で障害対応を模擬体験できるこの手法を、最新の生成AIテクノロジーと融合させることで、より柔軟かつスケーラブルな訓練プログラムの実現が可能になりました。v0.0.1 と v0.1.0 の主な違いv0.0.1では、主にシンプルなRPG形式の障害対応ゲームとして設計されており、ゲームマスターとプレイヤーの役割が明確に分かれています。システム障害のシナリオは自動的に設定され、2D6ダイスロールによる判定を用いた比較的ゲーム性の高い内容となっています。自動生成される障害シナリオは汎用的であり、実際の組織構造やドキュメントとの連携は限定的です。一方、v0.1.0では、実際の障害対応ドキュメントを分析し活用するプロフェッショナル向けの訓練プログラムへと進化しています。ファシリテーターとしての役割が追加され、実際の組織のドキュメント（README、フロー図、マニュアルなど）を分析した上でリアルな障害シナリオを作成します。また、ドキュメントの不備や矛盾点を明示的に指摘し、組織の障害対応プロセスの改善に直接貢献する機能が強化されています。セッションの構成も明確に定義され、振り返りや改善点の整理といった学習サイクルを重視した設計になっています。github.comこのブログの内容が参考になりましたら、読者登録やnwiizoのフォローをしていただけると大変励みになります。それでは、本題に入っていきましょう。あなたは「Wheel of Misfortune」方式の障害対応訓練を進行するファシリテーター兼ゲームマスターです。企業のシステム運用チーム向けに、実践的な障害対応訓練セッションを提供します。【前提条件】* このセッションでは、**実際の障害対応ドキュメント、README、アラートルール、インシデント対応フロー図**などの実ドキュメントを分析します* 分析したドキュメントに基づいて、**より現実的な障害シナリオと対応フロー**を再現します* **ドキュメントの不備、矛盾点、改善点**を発見し、明示的に指摘します【ファシリテーターとしての役割】* セッション全体の構成を管理し、参加者の学習を促進します* 訓練の目的と流れを明確に説明します* 振り返りを主導し、学びを言語化・共有する場を作ります* 訓練中に気づいたドキュメント改善点や対応手順の課題を記録します* 参加者全員が発言できる環境を整え、新人からベテランまで学びを得られるようにします【ゲームマスターとしての役割】* 提供されたドキュメントに基づくリアルなシステム障害シナリオを提供します* 参加者の行動に応じて状況を変化させます* 実際の組織構造に基づき、システム担当者やステークホルダーなどのNPCを演じます* 各NPCは組織内の役割や立場に応じた反応をします（経営層、開発者、顧客サポート等）* 参加者の判断や行動に対して適切なフィードバックを行います* 必要に応じて2D6ダイスロールによる判定を実施します（成功率6以上）* 実際のツールや監視画面の出力を擬似的に再現します【セッションの流れ】1. ドキュメント分析（5-15分）：提供された障害対応ドキュメント、README、フロー図を分析2. システム設定の合意（5-10分）：分析結果に基づくシステム設定の確認3. 組織体制の確認（5分）：実際の担当者と役割の確認4. シナリオの導入（3-5分）：ドキュメントから抽出した現実的なシナリオ設定5. 障害対応演習（30-45分）：実際の対応フローに沿った演習6. 振り返り（15-20分）：対応プロセスと発見された課題の振り返り7. ドキュメント・手順改善点の整理（10-15分）：訓練で発見された不備や改善点の整理【訓練の目的】* **インシデント対応の経験を積む*** **対応プロセスとドキュメントの問題点を発見する*** **チーム内でのナレッジ共有を促進する*** インシデント発生時の対応スキルを向上させる* **新人エンジニアでも適切に対応できる仕組みを検証する*** 既存のドキュメントや手順の不備を特定し、改善する【ドキュメント分析】以下のドキュメントを共有してください（可能な範囲で）：* システム構成図またはREADME* 障害対応マニュアルまたはRunbook* インシデント対応フロー* エスカレーションルール* アラートルールまたは監視設定* オンコール体制や担当者リスト共有いただいたドキュメントを分析し、以下の観点で評価します：* 完全性：必要な情報が全て含まれているか* 明確性：手順が明確で誤解の余地がないか* 最新性：古い情報や廃止されたコンポーネントへの言及がないか* 整合性：複数のドキュメント間で矛盾がないか* 実用性：実際の障害発生時に使いやすい形式になっているか【システム設定】ドキュメント分析に基づき、訓練対象となるシステムの基本情報を整理します：* システム名・サービス名* システム構成（サーバー、DB、ネットワーク、クラウドサービス等）* 主要コンポーネントと依存関係* 監視の仕組み（アラート、ダッシュボード等）* 過去に発生した障害パターン【組織体制の設定】実際の組織体制を反映したロールプレイを行うため、以下の情報を整理します：* 1次対応者（オンコール担当者）の役割と権限* エスカレーション先（2次対応者、専門チーム等）* 意思決定者（サービスオーナー、マネージャー等）* 社内外のステークホルダー（営業、カスタマーサポート、経営層等）* コミュニケーションチャネル（Slack、メール、電話等）【障害シナリオ】提供されたドキュメントと実際の環境に基づき、現実的な障害シナリオを設計します：* 過去に実際に発生した障害をベースにするか、起こりうる障害を想定* 複数のコンポーネントに連鎖する障害を想定* ドキュメントの不備や曖昧さが影響する状況を意図的に含める* 障害の重大度（影響範囲、ビジネスインパクト）を明確にする* 障害発生から発見までの時間経過も考慮する* 必要に応じて外部要因（セキュリティ、自然災害等）も考慮する【実際の対応フロー】実際の対応フローに沿ってシナリオを進行します：* アラート検知からの初動対応* 状況確認と影響範囲の特定* エスカレーションの判断と実行* 原因調査と対応策の検討* 復旧作業の実施* ステークホルダーへの報告* 障害クローズと再発防止策の検討【不備の指摘と改善提案】訓練を通じて発見された以下の点を**明示的に指摘し、改善案を提示**します：* **ドキュメントの不備や曖昧な記述*** **手順の抜け漏れや矛盾*** 役割や責任の不明確さ* コミュニケーションの問題点* 技術的な対応の課題* 監視やアラートの改善点【振り返りのポイント】* 対応プロセスの適切さ（初動、エスカレーション等）* 技術的判断の妥当性* コミュニケーションの適切さ* ドキュメントの不備や改善点* より良い対応のためのアイデア* 次回の訓練で焦点を当てるべき領域まずは、分析対象となるドキュメント（障害対応マニュアル、README、インシデント対応フロー等）を共有してください。ドキュメントの量が多い場合は、最も重要な部分や、特に検証したい部分を優先的に共有いただければと思います。実施ガイド事前準備必要ドキュメントの整理障害対応マニュアルやRunbookシステム構成図やREADMEオンコール体制やエスカレーションフロー監視システムやアラートルールの説明参加者の選定訓練対象者（新人エンジニアが理想的）オブザーバー（経験者やマネージャー）ファシリテーター（実施進行役）シナリオの検討過去に実際に発生した障害事例懸念されるが未発生の障害パターンドキュメントの不備が顕著な領域セッション実施プロンプトの入力上記プロンプトを生成AI（Claude/ChatGPT等）に入力分析対象ドキュメントを提供セッション開始AIによるドキュメント分析結果の確認訓練の目的と進め方の説明参加者の役割確認障害対応演習AIが提示する初期状況（アラート等）に対応実際の対応フローに沿ったアクション実施必要に応じたエスカレーションやコミュニケーション振り返りAIから指摘されたドキュメントの不備確認対応プロセスの課題抽出改善アクションの設定フォローアップ改善タスクの整理ドキュメント更新タスクプロセス改善タスク技術的対策タスク次回訓練の計画焦点を当てる領域の選定参加者の拡大検討定期開催スケジュールの設定RPG スタート架空のシステムを作る今回の訓練では、現実のシステム構成を反映した架空のシステムを利用します。生成AIを活用することで、README.mdやシステム構成図などの基本ドキュメントを自動生成することができます。この例では「FuturePay」という架空の決済システムを想定しています。生成AIは組織の実際のシステム特性（マイクロサービスアーキテクチャ、使用している技術スタック、インフラ構成など）を考慮して、より現実に近い環境を短時間で構築できます。これにより、訓練の没入感と実践的価値が大幅に向上します。障害対応に必要なドキュメント類の生成システム設定に加えて、障害対応に必要な以下のドキュメントも自動生成します：Runbook：各コンポーネントの操作手順や復旧手順インシデント対応フロー：検知から解決までのプロセス図アラートルール：監視項目と閾値の定義エスカレーションルール：重大度別の連絡先と対応フローこれらのドキュメントには、意図的に不完全な部分や曖昧な記述を含めることで、実際の業務環境で直面する課題を再現しています。訓練参加者はこれらのドキュメントを頼りに障害対応を進めることで、ドキュメント品質の重要性を体感できます。シナリオの開始ファシリテーターからの「障害発生のアラートが上がりました」という通知でRPGが始まります。参加者は実際の障害対応と同様に、以下のステップで対応を進めます：状況確認：どのようなアラートが発生したのかを確認影響範囲の特定：どのサービスやユーザーに影響があるのかを判断原因調査：ログ確認やシステム状態の分析を実施対応策の実行：障害復旧のための具体的なアクションを決定・実行ステークホルダーへの報告：適切なタイミングで適切な相手に状況を伝達生成AIはリアルタイムに状況を変化させ、参加者の判断や行動に応じたフィードバックを提供します。これにより、臨場感のある訓練体験が実現します。期待される効果ドキュメント品質の向上不備や曖昧さの発見と修正実際の利用シーンを想定した改善チーム全体のスキル向上新人エンジニアの障害対応経験蓄積知識の属人化防止対応フローの最適化ボトルネックや非効率な手順の発見エスカレーションルールの明確化障害対応時間の短縮初動対応の迅速化適切な判断と対応の促進組織レジリエンスの向上どのメンバーでも対応可能な体制構築予期せぬ状況への対応力強化おわりに障害対応はシステム運用において最も重要かつ難しいスキルの一つです。「Wheel of Misfortune」と生成AIを組み合わせたアプローチは、これまで難しかった実践的な訓練を、環境構築のコストを抑えながら定期的に実施できる画期的な方法です。この訓練方法の最大の強みは、単なる障害対応のシミュレーションに留まらず、実際のドキュメントや組織体制の問題点を浮き彫りにし、具体的な改善につなげられる点にあります。また、チーム全体で知識を共有し、特定のエンジニアに依存しない強固な運用体制を構築することができます。システム障害をゼロにすることは不可能でも、組織の対応力を高めることは可能です。この方法を取り入れ、定期的な訓練を行うことで、障害発生時の対応時間短縮とサービス品質の向上を実現してください。障害対応は「いざという時のための備え」ではなく、継続的に鍛えるべき組織の中核能力なのです。今後も実践的なシステム運用のヒントを発信していきますので、ぜひご期待ください。また、障害対応について知識をしっかりと身に着けたければ「【改訂新版】システム障害対応の教科書」を読んでほしいです。【改訂新版】システム障害対応の教科書作者:木村 誠明技術評論社AmazonIncident Response MeetupやPagerDuty Japan、Waroom Meetupなどの国内のイベントもたくさんあるので気になる方はぜひ、参加してみてください。incident-response.connpass.compagerduty.connpass.comtopotal.connpass.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~]]></title>
            <link>https://sreake.com/blog/google-cloud-next-2025-database-updates/</link>
            <guid>https://sreake.com/blog/google-cloud-next-2025-database-updates/</guid>
            <pubDate>Thu, 17 Apr 2025 03:04:19 GMT</pubDate>
            <content:encoded><![CDATA[AgentspaceやAgent Development Kit、A2A Protocolの発表など生成AI関連の発表が目立ったGoogle Cloud Next 2025ですが、データベース関連でも魅力的なリリースがた […]The post Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MACのDocker 環境はcolima にしました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211</guid>
            <pubDate>Wed, 16 Apr 2025 11:12:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめにコンテナ技術は現代のソフトウェア開発において不可欠なツールとなっています。特にMacユーザーにとって、効率的なコンテナ環境の構築は開発ワークフローを大きく改善します。そんな中、ローカルの環境をColimaにしたのでブログにします。Colimaは、macOSとLinux上でコンテナランタイムを最小限の設定で実行できる軽量なツールです。Docker Desktopの代替として、あるいはLimaの機能を拡張するソリューションとして、多くの開発者に支持されています。github.comこのドキュメントでは、Colimaの基本的な機能と特徴、インストール方法、そして実際の使用例について詳しく説明します。Docker DesktopやLimaからの移行を検討している方や、単にMac上でより効率的なコンテナ環境を探している方に、Colimaという選択肢を紹介します。Colimaとは？Colimaは、macOS（およびLinux）上でコンテナランタイムを最小限のセットアップで実行するためのツールです。Limaという仮想マシンマネージャーを利用して、Docker、Containerd、Kubernetesなどを簡単に使えるようにしてくれます。主な特徴としては：Intel MacとApple Silicon Macの両方をサポートシンプルなCLIインターフェースと分かりやすいデフォルト設定自動ポートフォワーディングボリュームマウント複数インスタンスのサポート複数のコンテナランタイムをサポート（Docker、Containerd、Incusなど）なぜColimaを選んだのか元々はDocker Desktopを使っていましたが、一度Limaに移行し、そこからさらにColimaに移行することにしました。その理由はいくつかあります。シンプルなCLI: GUIではなくCLIベースなので、自動化やスクリプトに組み込みやすいですカスタマイズ性: 仮想マシンのCPU、メモリ、ディスク容量などを簡単に調整できますオープンソース: 完全にオープンソースで、ライセンス問題の心配がありません統合管理: LimaをベースにしながらもDocker、Containerd、Kubernetesなどを一元的に管理できる点が便利です正直、Limaで満足していた。動機としては気になったから移行したというのが本音Limaとの比較Colimaはより高レベルな方法でLimaを活用しています。具体的に言うと、Limaは仮想マシンを提供するツールである一方、Colimaはその上にDockerやContainerdなどのコンテナ環境を自動的に構築・設定します。これは、自分でLimaの設定ファイルを書いてDockerを動かす作業を自動化してくれるようなものです。つまり、Limaの複雑な設定や調整をせずに、すぐにコンテナ環境を使い始めることができます。Colimaの主な利点は：統合された環境: Limaは純粋な仮想マシン管理に特化していますが、ColimaはDocker/Containerd/Kubernetesの設定を自動的に行う点が便利ですシンプルなCLIインターフェース: 必要なコマンドが少なく、直感的に操作できます自動化のしやすさ: 特にbrew servicesとの統合が優れていますインストールと基本的な使い方Homebrewを使って簡単にインストールできます。brew install colima基本的な使い方はとてもシンプル：# 起動colima start# 状態確認colima status# 停止colima stop私の環境では次のような出力になっています。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock システム起動時に自動起動する設定開発環境として日常的に使うので、Macの起動時にColimaも自動的に起動するように設定しました。Homebrewのservicesを使うと簡単です。brew services start colimaこれだけで、Macを再起動してもColimaが自動的に起動するようになります。以前のLimaでは、~/Library/LaunchAgents/com.lima.docker.plistのようなLaunchAgentsのplistファイルを作成・編集して自動起動を設定する必要がありました。Colimaではbrew servicesコマンド一つで同様の設定ができるようになり、格段に簡単になりました！カスタマイズの例デフォルトのColimaは2CPU、2GiBメモリ、100GiBストレージで構成されていますが、必要に応じて変更できます。# CPUとメモリを増やす場合colima stopcolima start --cpu 4 --memory 8# 設定ファイルで編集する場合colima start --editLima/Docker Desktopからの移行で注意したことLima や Docker Desktopから移行する際に、いくつか注意点がありました：Dockerコンテキスト: Colimaは独自のDockerコンテキストを作成します。docker context lsとdocker context useコマンドで管理できます。Dockerソケットの場所: デフォルトでは~/.colima/default/docker.sockにあります。一部のツールで直接ソケットパスを指定する必要がある場合は、この場所を指定します。Limaとは異なるパスなので注意が必要です。ボリュームマウント: ホームディレクトリ以外のパスをマウントする場合は、設定ファイルのmountsセクションで明示的に指定する必要があります。既存のコンテナとイメージ: Lima や Docker Desktopで使っていたコンテナやイメージは自動的には引き継がれないので、必要なら再ビルドやpull が必要です。Colimaの動作確認実際にcolima statusコマンドを実行すると、以下のような情報が表示されます。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock また、colima listコマンドでは、実行中のColimaインスタンスの詳細な情報が確認できます。colima listPROFILE    STATUS     ARCH       CPUS    MEMORY    DISK      RUNTIME    ADDRESSdefault    Running    aarch64    2       2GiB      100GiB    dockerこれがColimaのデフォルト設定です。これらの値は必要に応じてcolima startコマンドのオプションや設定ファイルで変更できます。まとめLimaベースのColimaへの移行は思った以上に簡単で、日常の開発作業がより快適になりました。特にCLIベースのシンプルさと設定のわかりやすさが気に入っています。自動起動の設定（brew services start colima）が簡単なこともとても便利で、開発環境のセットアップが格段に楽になりました。Docker DesktopやLimaそのものから移行を検討している方、特にコンテナランタイムを簡単に導入したいMacユーザーの方には、Colimaを検討する価値があります。普通にローカルのCPUとメモリを喰う生成AIツール全盛時代に最適な環境がなにか俺にも分からん。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LangChainとVertexAIのgemini 2.0 flashで構造化出力に失敗するケースが直りそう]]></title>
            <link>https://blog.atusy.net/2025/04/16/lang-chain-vertexai-structured-output/</link>
            <guid>https://blog.atusy.net/2025/04/16/lang-chain-vertexai-structured-output/</guid>
            <pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[LangChainのStructured outputを使うと、文章中の構造を良い感じに読み取って、Pydanticで定義したデータ構造に落としてこんでくれます。]]></content:encoded>
        </item>
    </channel>
</rss>