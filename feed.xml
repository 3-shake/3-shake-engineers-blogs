<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 27 May 2025 22:35:29 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Nix Meetup #3 大阪に参加した]]></title>
            <link>https://blog.atusy.net/2025/05/28/nix-meetup-3-in-osaka/</link>
            <guid>https://blog.atusy.net/2025/05/28/nix-meetup-3-in-osaka/</guid>
            <pubDate>Wed, 28 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Nix meetup #3 大阪が2025-05-24に開催されました。技術への愛溢れた濃いい話がいっぱいできてよかったです。いっぱい聞けて、じゃなくてできてってところがまた素敵。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：thefuck]]></title>
            <link>https://zenn.dev/akasan/articles/fff0cfa9beadbc</link>
            <guid>https://zenn.dev/akasan/articles/fff0cfa9beadbc</guid>
            <pubDate>Tue, 27 May 2025 11:22:06 GMT</pubDate>
            <content:encoded><![CDATA[今回から、私が普段使ってるコマンドを紹介していくシリーズを始めたいと思います。記念すべき第一回は、thefuckというコマンドを紹介します。名前だけ見るとなかなかにパンチが効いたものですが、スター数も多いコマンドですので、ぜひ興味がある方はみてください。※ 本記事を書くにあたり、果たしてこの文字を入力して良いのか迷いましたが、①あくまでコマンド紹介であること、②他の記事で4文字が入っている記事も結構ありそうだったので採用しました thefuckとは？一言で言ってしまうと、コマンド入力をミスした時に、本来実行したかったコマンドを想定して出してくれるコマンドになります。例えば...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇]]></title>
            <link>https://sreake.com/blog/developer-productivity-conference-2025/</link>
            <guid>https://sreake.com/blog/developer-productivity-conference-2025/</guid>
            <pubDate>Tue, 27 May 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 7月3日（木）4日（金）に開催される「開発生産性Conference 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[alphaXivを使って論文要約してみた]]></title>
            <link>https://zenn.dev/akasan/articles/feaca6271b5f0c</link>
            <guid>https://zenn.dev/akasan/articles/feaca6271b5f0c</guid>
            <pubDate>Mon, 26 May 2025 13:01:26 GMT</pubDate>
            <content:encoded><![CDATA[今回は、先日Xにて見つけたalphaXivというものを使って、arXiv上の論文を要約する方法を調べてみました。 alphaXivとは？alphaXivとは、arXiv上にアップロードされている論文を要約できるサービスです。自分の指定した論文を要約できるだけでなく、コミュニティを作成・参加したりおすすめの論文を一覧に出してもらったりと、様々なことを実施できます。また、なんと言っても一番の特徴が、要約に利用されるLLMに関して料金がかからないところです。記事執筆時点ではaplhaXivで利用されるLLMについて無料で使えており、このサービスが無料で使えるのが不思議ですw。http...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RAGアプリ開発ハンズオン（後編：フロントエンド編）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/05/26/185645</link>
            <guid>https://shu-kob.hateblo.jp/entry/2025/05/26/185645</guid>
            <pubDate>Mon, 26 May 2025 09:56:45 GMT</pubDate>
            <content:encoded><![CDATA[genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    template = """質問: {question}    ステップバイステップで考えてください。"""    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp↓@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    context_resp = retriever_service(question)    context = context_resp['search_result']    print(context)    template = """質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    """    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question, "context": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = 'DISCOVERY_ENGINE_ID'↓@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = os.environ['DISCOVERY_ENGINE_ID']動作確認QUESTION='{"query":"情報セキュリティにおいて気をつけるべきことを教えてください"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob · Pull Request #4 · shu-kob/rag-app-handson · GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    <main className="flex items-center justify-center pt-16 pb-4">      <div className="flex-1 flex flex-col items-center gap-16 min-h-0">        <div>          <div>            <label htmlFor="message">メッセージ</label>          </div>          <div>            <textarea              id="message"              rows={4}              cols={50}              style={{                padding: "0.5rem",                border: "1px solid #ccc",                outline: "none",                boxShadow: "none",              }}            />          </div>          <div>            <button              type="button"              style={{                border: "1px solid #ccc",                padding: "0.5rem 1rem",              }}            >              送信            </button>          </div>        </div>      </div>    </main>  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from "react";export function Welcome() {  const [input, setInput] = useState("");  const onSend = () => {    console.log(input)  }  return (    <main className="flex items-center justify-center pt-16 pb-4">      <div className="flex-1 flex flex-col items-center gap-16 min-h-0">        <div>          <div>            <label htmlFor="message">メッセージ</label>          </div>          <div>            <textarea              id="message"              rows={4}              cols={50}              style={{                padding: "0.5rem",                border: "1px solid #ccc",                outline: "none",                boxShadow: "none",              }}              value={input}              onChange={(e) => setInput(e.target.value)}            />          </div>          <div>            <button              type="button"              style={{                border: "1px solid #ccc",                padding: "0.5rem 1rem",              }}              onClick={onSend}            >              送信            </button>          </div>        </div>      </div>    </main>  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=["*"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=["*"],  # すべてのメソッドを許可    allow_headers=["*"],  # すべてのヘッダーを許可    expose_headers=["*"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () => {    fetch("http://localhost:8000/api/llm", {      method: "POST",      headers: {        "Content-Type": "application/json",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob · Pull Request #6 · shu-kob/rag-app-handson · GitHub]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Agent Engine のカスタムテンプレートでセッション機能付きチャットボットを作る]]></title>
            <link>https://zenn.dev/kimitsu/articles/agent-angine-custom-agent</link>
            <guid>https://zenn.dev/kimitsu/articles/agent-angine-custom-agent</guid>
            <pubDate>Mon, 26 May 2025 07:02:31 GMT</pubDate>
            <content:encoded><![CDATA[Vertex AI Agent Engine は AI エージェントを構築・デプロイするための Google Cloud のマネージドサービスです。[1]以下のフレームワークに対してはテンプレートが用意されており、簡単にデプロイすることができます。Agent Development KitLangChainLangGraphAG2LlamaIndexまた上記に挙げられていないフレームワークについても、カスタムテンプレートを作成することでデプロイすることができます。今回はカスタムテンプレートを用いて、セッション機能付きの AI チャットボットを実装してみます。なお本記...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TerragruntでTerraformをいい感じに管理する]]></title>
            <link>https://zenn.dev/kojake_300/articles/9b008349fa8310</link>
            <guid>https://zenn.dev/kojake_300/articles/9b008349fa8310</guid>
            <pubDate>Sun, 25 May 2025 14:05:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに皆さんはTerraformをどのような管理していますか？最近では、Google Cloudがベストプラクティス[1]を公開していたり、FUTURE社が設計ガイドライン[2]を提供していたりと、Terrafromの設計・開発ガイドラインは成熟して来ているのではないでしょうか。それでも、何となくもっと良い管理の方法はないかなあ？ と思ったことはありませんか。そんなTerraform Loverに送る、Terragruntというツールを紹介します。 Terraformの課題基本的なTerraformのディレクトリ構成を以下に示します。AWSリソースを管理することを想定と...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年5月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/b37d1767115ee0</link>
            <guid>https://zenn.dev/akasan/articles/b37d1767115ee0</guid>
            <pubDate>Sun, 25 May 2025 11:52:17 GMT</pubDate>
            <content:encoded><![CDATA[5月も終わりに近づいてきました。そこで、先月に続いて、今月読んでいた本を紹介しようと思います。4月版はこちらになりますので、ご興味があればぜひ参照してください！https://zenn.dev/akasan/articles/9b2e5528548353 クラウド系 Google Cloudではじめる実践データエンジニアリング入門こちらは先月も載せていた本ですが、改めて載せています。その理由としてですが、5月にProfessional Data Engineerを受験しまして、その勉強にとてもよく立ちました。PDEではBigQueryをはじめデータレイク・データウェアハウスの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【思考実験】バイブコーディング(Vibe coding)と多腕バンディット問題 - 選択の最適化と報酬の探索]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646</guid>
            <pubDate>Sun, 25 May 2025 05:36:46 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIが普及して、プログラミングの世界に「バイブコーディング（Vibe Coding）」という面白い言葉が生まれています。なんとなくの感覚や「バイブ(雰囲気)」に頼りながら、AIとやり取りしてコードを作るこの方法は、従来のプログラミングとは全く違うアプローチです。www.gitpod.iolearning.oreilly.com一方で、確率論の世界には「多腕バンディット問題」という古典的な問題があります。限られた時間の中で、どの選択肢が一番良い結果をくれるか分からない状況で、どうやって最良の選択をするか—という問題です。この二つ、一見全く関係なさそうですが、よく観察してみると驚くほど似ています。私たちがAIに色々なプロンプトを試している行動は、実は多腕バンディット問題を解いているのと同じようなことをしているのです。本稿では、この意外な共通点を深く探りながら、日常的なバイブコーディングの中に隠れている、洗練された認知メカニズムの正体に迫ってみたいと思います。注：筆者は多腕バンディット問題の専門家ではないため、解釈に誤りがある可能性があります。あくまで思考実験として読んでいただければと思います。バイブコーディングという新しい認知活動バイブコーディングをしている時、私たちは無意識に以下のようなことをしています：「こういう書き方でプロンプトを書いてみよう」「前回これでうまくいったから、今回も同じパターンでやってみよう」「なんか今日は調子悪いな、違うアプローチを試してみるか」「この例を見せた方が良いコードが出そうだ」興味深いのは、これらの行動が極めて自然に、まるで本能のように現れることです。特別な訓練を受けたわけでもないのに、多くの人が似たような試行錯誤のパターンを示します。www.businessinsider.com多腕バンディット問題多腕バンディット問題を簡単に説明すると：状況： カジノに複数のスロットマシンがあります。それぞれ当たりやすさが違いますが、どれが一番当たりやすいかは分かりません。目標： 限られた時間で、できるだけ多くの当たりを出したい。ジレンマ： 新しいマシンを試して情報を集める（探索）べきか、今まで当たりが多かったマシンをずっと使う（活用）べきか？この「探索と活用のトレードオフ」は、実は生物の進化から人間の日常生活まで、あらゆる場面に現れる根本的な意思決定パターンです。新しいレストランを試すか、お気に入りの店に行くか。新しい本を読むか、好きな作家の作品を読み返すか。私たちは常にこのジレンマと向き合っています。バンディット問題の理論とアルゴリズム (機械学習プロフェッショナルシリーズ)作者:本多淳也,中村篤祥講談社Amazonバイブコーディングをほぼスロットマシンなので...バイブコーディングを多腕バンディット問題として見たとき、その対応関係は驚くほど明確です。「スロットマシン」= プロンプトのパターン「詳しく説明してからコードを書いて」「具体例を示してから実装して」「ステップバイステップで教えて」「エラーハンドリングも含めて書いて」「当たり」= 期待する品質のコードが生成される「探索と活用のジレンマ」= 新しいプロンプト戦略を試すか、慣れ親しんだ方法を使うかしかも、この対応関係は表面的なものではありません。行動パターンの時間的変化、学習曲線、意思決定の心理的メカニズムまで、驚くほど一致しているのです。学習段階の自然な進化初心者期：無制限探索の混沌プログラミングを始めたばかりの人がAIを使う時は、まさに「片っ端から試してみる」状態です。成功率は低いものの、各プロンプトパターンがどれくらい有効かを肌感覚で学習しています。これは多腕バンディット問題における「純粋探索フェーズ」に相当します。中級者期：偏った活用の安定ある程度経験を積むと、「この書き方はいつもうまくいく」という黄金パターンを発見し、それに依存するようになります。これは効率的ですが、より良い戦略を見逃すリスクもはらんでいます。多腕バンディット問題で言う「早期収束の罠」です。上級者期：動的バランスの芸術経験豊富な人は、状況に応じて探索と活用のバランスを直感的に調整します。新しいモデルが出れば探索モードに戻り、安定したタスクでは効率的なパターンを活用します。これは最も洗練された多腕バンディット戦略と言えるでしょう。この自然な進化過程は、特別な理論を学ばなくても、人間が本能的に最適化アルゴリズムを身につけることを示しています。コンテキストによる戦略の分化興味深いことに、プログラミング言語やAIモデルが変わると、最適なプロンプト戦略も変化します。Pythonでうまくいくアプローチが、C++では効果的でない。GPT-4で成功した方法が、Claude では通用しない。これは多腕バンディット問題における「コンテキスト付きバンディット」の典型例です。同じ「腕」（プロンプトパターン）でも、文脈によって期待報酬が変わるのです。熟練したエンジニアは、この文脈の切り替えを無意識に行います。言語を変えると同時に、プロンプト戦略も自動的に調整される。これは、人間の適応的学習能力の驚くべき柔軟性を物語っています。「報酬」の多次元性と測定の難しさバイブコーディングにおける「報酬」は、多腕バンディット問題の古典的な設定よりもはるかに複雑です。即座に測定できる報酬コンパイルが通る期待した動作をする実行時間が短い長期的な報酬コードの可読性保守のしやすさチーム開発での再利用性主観的な報酬「美しい」コード学習になるコード創意工夫のあるコードこの多次元的な報酬構造が、バイブコーディングを単純な最適化問題以上の、芸術的な活動にしているのかもしれません。自動テストが変革する「報酬関数」ここで自動テストの存在が、バイブコーディングの性質を根本的に変えることに注目したいと思います。テストがない状況では、報酬の測定は主観的で曖昧です。「なんとなく動いているから良いコード」という判断は、多腕バンディット問題で言う「ノイズの多い報酬シグナル」です。一方、自動テストがある場合、報酬は明確で客観的になります。「全テストが通る」は0か1かの明確な成功指標です。これにより、どのプロンプト戦略が本当に効果的かを正確に学習できるようになります。この変化は単なる測定精度の向上以上の意味を持ちます。報酬関数の明確化により、学習アルゴリズムそのものが高度化するのです。syu-m-5151.hatenablog.comプロンプトエンジニアリングという「期待値制御」プロンプトエンジニアリングを多腕バンディット問題の視点で見ると、これは「各腕の期待報酬を高める技術」と解釈できます。曖昧なプロンプト「ログイン機能を作って」は、期待報酬の分散が大きい「腕」です。うまくいく時もあれば、全く期待外れの結果になることもある。一方、詳細で構造化されたプロンプトは、期待報酬の平均値を高め、分散を小さくします。これは多腕バンディット問題において、明らかに優位な「腕」です。興味深いのは、多くの人がプロンプトエンジニアリングの重要性を、理論を知らずとも実感していることです。これは、人間が直感的に「期待値と分散の最適化」を理解していることを示唆しています。チーム協働における「集合知のバンディット」個人でのバイブコーディングから、チームでの協働に視点を移すと、さらに興味深い現象が見えてきます。複数のエンジニアが異なる「腕」を並行して探索し、成果を共有する。これは「協調型バンディット」と呼ばれる高度な問題設定です。全員が同じ試行錯誤を繰り返す無駄を避け、チーム全体として効率的に最適解に近づいていきます。「このプロンプトパターンが効果的だった」「このアプローチは避けた方がいい」こうした情報共有は、個人の学習速度を遥かに超える集合的な最適化を可能にします。人間が本能的に行う知識共有行動が、実は数学的に最適な協調戦略だったのです。AIモデル進化への適応：非定常環境での生存戦略AIモデルの頻繁なアップデートは、バイブコーディングに非定常性という新たな次元を加えます。昨日まで最適だった戦略が、新しいモデルでは全く効果がない。これは生物の進化圧にも似た、動的な環境変化です。この変化に対して、経験豊富なエンジニアは見事な適応を見せます。新しいモデルが出ると、自動的に「探索モード」に切り替わる。過去の成功体験にとらわれず、新たな最適解を求めて試行錯誤を始める。この柔軟性は、多腕バンディット問題の理論が想定する以上の高度な適応能力です。環境の変化を察知し、学習戦略そのものを動的に調整する—これは人間の認知能力の真骨頂と言えるでしょう。「バイブ」の正体：統計的直感の結晶「バイブ」や「勘」と呼ばれる現象の正体を、多腕バンディット問題の枠組みで考えてみると、驚くべき洞察が得られます。経験豊富なエンジニアが「なんとなくこのアプローチが良さそう」と感じる時、それは過去の膨大な試行錯誤から蓄積された統計的パターンの内在化です。意識的には覚えていない微細な成功・失敗の記憶が、直感的判断として表面化している。これは、Thompson Samplingという高度なアルゴリズムと本質的に同じメカニズムです。過去の経験から各戦略の成功確率分布を学習し、その分布に基づいて確率的に選択を行う。完全に論理的でもなく、完全にランダムでもない、絶妙なバランスの意思決定です。「バイブ」は非科学的なものどころか、むしろ最先端の確率的アルゴリズムを人間が自然に実装している証拠なのです。中毒性の数学的説明バイブコーディングに多くの人が「ハマる」理由も、多腕バンディット問題の枠組みで説明できます。新しいプロンプトを試すたびに得られる「うまくいくかもしれない」という期待感。実際に良いコードが生成された時の達成感。これらは、不確実性の中で最適解を探索する過程で得られる本能的な報酬です。人間の脳は、探索と活用のバランスを取る活動に対して、進化的に報酬を与えるよう設計されています。バイブコーディングがこの古い報酬系を刺激するからこそ、多くの人が夢中になるのでしょう。なぜこの類似性が存在するのかここで根本的な問いに向き合ってみましょう。なぜバイブコーディングと多腕バンディット問題は、これほどまでに似ているのでしょうか？一つの仮説は、人間の学習と意思決定の根底にある共通のメカニズムです。不確実な環境で最適な選択を見つけるという課題は、人類が何十万年もの間直面してきた生存問題でした。どの狩場が豊富な獲物をもたらすか。どの植物が安全で栄養価が高いか。多腕バンディット問題は、この根本的な生存戦略を数学的に抽象化したものです。そして、バイブコーディングは、この古い学習メカニズムが新しい技術的環境で発現したものなのかもしれません。イプシロン-グリーディ戦略としての日常多くのエンジニアが無意識に実践している行動パターンを詳しく観察すると、「イプシロン-グリーディ戦略」との類似性が見えてきます：大部分の時間（90%）: 今まで最も成功率の高かった方法を使う（活用）少しの時間（10%）: 新しい方法を試してみる（探索）「いつものパターンでやってみよう。あ、でもたまには違うアプローチも試してみるか」この何気ない意思決定が、実は数学的に洗練された最適化戦略だというのは、驚くべき発見です。UCB的思考の高次元化より洗練された判断をする人は、UCB（Upper Confidence Bound）アルゴリズムに似た思考を示します：「このプロンプトは過去に良い結果を出したけど、まだ試行回数が少ないから、もう少し試してみる価値がある」これは、平均的な成功率だけでなく、「不確実性」も考慮した意思決定です。試行回数が少ない選択肢に対して「まだ可能性がある」という判断を下す。この高次な推論を、多くの人が自然に行っているのです。認知バイアスとしての「過度な活用」一方で、バイブコーディングには多腕バンディット問題と同様の落とし穴もあります。早期収束の罠: 最初に見つけた成功パターンに固執し、より良い方法を探索しなくなる。確証バイアス: 自分のお気に入りの方法がうまくいった事例ばかりを記憶し、失敗例を忘れてしまう。環境変化への適応遅れ: 新しいAIモデルが出ても、古い戦略に固執し続ける。これらの認知バイアスは、多腕バンディット問題における「準最適解への収束」と本質的に同じ現象です。人間の学習メカニズムの限界が、両方の文脈で同様に現れているのです。思考実験から見えてくることこの思考実験から得られる洞察を、整理してみましょう。第一に、私たちが日常的に行っている「試行錯誤」は思っているより合理的だということです。「なんとなく」でプロンプトを選んでいるように見えて、実は過去の経験から学習した効率的な戦略を使っているのです。第二に、自動テストやプロンプトエンジニアリングが効果的な理由が、多腕バンディット問題の観点から説明できることです。これは単なる「ベストプラクティス」ではなく、学習効率を上げる合理的な手法だったのです。第三に、チームでのAI活用が個人より効果的な理由も明確になります。みんなで情報共有することで、効率的に最適解を見つけられる。これは感覚的に分かっていたことですが、理論的な裏付けがあったということです。エンジニアとしての実感実際にバイブコーディングをしている身として、この類似性には「なるほど、そういうことか」という納得感があります。新しいプロジェクトを始める時の「色々試してみる」段階、ある程度慣れてきて「いつものパターン」を使うようになる段階、そして新しいAIモデルが出ると再び「探索モード」に戻る段階。この流れは、多くのエンジニアが体験していることでしょう。特に興味深いのは、「なんか今日は調子悪いな」と感じて戦略を変える時の判断です。これも、実は環境の変化を察知した合理的な適応行動だった可能性があります。おわりにこの思考実験の面白さは、日頃「感覚的」だと思っていた行動に、実は理論的な構造があったという発見にあります。「バイブ」と呼んでいた直感は、決してランダムな当て推量ではありませんでした。それは、過去の大量の試行錯誤から学習した、効率的な意思決定メカニズムのように思えます。私たちがAIに向かって何気なくプロンプトを打っている時、実は無意識のうちに確率的な最適化を行っている。理論を知らなくても、効果的な学習戦略を実践している。この発見は、バイブコーディングをただの「なんとなくのコーディング」から、理論に裏打ちされた合理的なアプローチとして捉え直すきっかけを与えてくれます。最終的に、この思考実験が示しているのは、私たちエンジニアが思っているより賢く、効率的に学習し、適応しているということです。それは決して特別なことではなく、人間が持つ自然な学習能力の現れなのかもしれません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache jcloudsとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/c4783b7b825847</link>
            <guid>https://zenn.dev/akasan/articles/c4783b7b825847</guid>
            <pubDate>Sat, 24 May 2025 10:30:19 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache jclouds。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache jcloudsとは？公式サイトによると、Java向けのマルチクラウドツールキットクラウド特有の機能を完全に利用しつつ、クラウドを横断した...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud の生成 AI オブザーバビリティ機能まとめ]]></title>
            <link>https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y</link>
            <guid>https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y</guid>
            <pubDate>Sat, 24 May 2025 09:01:25 GMT</pubDate>
            <content:encoded><![CDATA[生成 AI アプリケーションにおけるオブザーバビリティの必要性ここ数年の生成 AI 技術の発展に伴い、RAG や AI エージェントなど生成 AI のアプリケーションへの応用が進んでいます。一方で生成 AI アプリケーションを本番利用していくにあたっては以下のような課題があります。確率的な挙動モデルの出力生成にかかる時間トークンに対する課金額外部サービス呼び出し（RAG であれば検索サービス、AI エージェントであればツール）実行経路（ワークフロー型エージェントの場合）モデルの更新、プロンプトの更新これらの課題に対し、生成 AI アプリケーションにおいて...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cursorの@Symbolsについて調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/6e1770944b3a1e</link>
            <guid>https://zenn.dev/akasan/articles/6e1770944b3a1e</guid>
            <pubDate>Fri, 23 May 2025 13:55:25 GMT</pubDate>
            <content:encoded><![CDATA[今回はCursorの機能である@Symbolsについて、公式ドキュメントの内容をまとめてみます。 @Symbolsとは？Cursorにはチャットを利用したコーディングアシスト機能がありますが、その機能についてどのようにコードやファイル、ドキュメントなどのコンテキストを参照するかということを制御するために@Symbolsというものがあります。https://docs.cursor.com/context/@-symbols/overviewCmd + Kなどで表示できるチャットボックスでは、一般的には例えば〜の計算をするための関数を実装してのような指示を投げたりするかと思いますが...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonを利用してPub/Subトピックを扱ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/471883f3a9495f</link>
            <guid>https://zenn.dev/akasan/articles/471883f3a9495f</guid>
            <pubDate>Thu, 22 May 2025 12:00:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonを利用して、Google CloudのPub/Subを利用してみました。認定資格の勉強中にももちろん出てきますし、以前実施したGCSとDataflowの連携においてもPub/Subを利用しました。Pub/SubはGoogle Cloudのサービスの中でも特に重要な要素の一つだと思いますが、直接利用したことがなかったので、PythonのSDKを利用して実際に使ってみました。https://zenn.dev/akasan/articles/e17a1867408c53 実際に使ってみる今回は、公式のこちらのドキュメントに従ってチュートリアルをしてみようと思います！...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Portalsとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/344ee65cfc92fb</link>
            <guid>https://zenn.dev/akasan/articles/344ee65cfc92fb</guid>
            <pubDate>Wed, 21 May 2025 12:09:04 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Portalsとは何かについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Portalsとは？公式サイトを見ると、Apache Portalsとは以下のようなもののようです。ロバスト...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[これから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752</guid>
            <pubDate>Wed, 21 May 2025 03:27:52 GMT</pubDate>
            <content:encoded><![CDATA[この記事で得られる3つのポイント「つぶしが効く」エンジニアになる: 表面的な技術習得ではなく、根本原理の深い理解と問題解決能力が長期的な市場価値を創出するAI時代の新たな役割: テクノロジーと人間の強みを組み合わせ、AIとの効果的な協働を設計・実現できる「アーキテクト」としての視点計画的偶発性の活用: 不確実性を受け入れ、専門性と横断性のバランス、継続的学習、そして「偶然を必然に変える」姿勢の重要性はじめにみなさん、こんにちは！本日はアカリクの就職ラウンジイベント＠会津大学に来ていただき、ありがとうございます。「AI時代に市場価値を高めるキャリア戦略」というテーマでお話しさせていただきます。口頭で補足しながらいろいろやっていきます。よろしくお願いします。acaric.jp現役エンジニアとして日々AIの進化と自身のキャリアパスに向き合う中で、私が得た気づきや思考を皆さんと共有できればと思います。なお、本発表では何冊かの書籍を紹介していますが、必ずしも読む必要もないです。興味があればでよいです。購入する必要も余計にありません。図書館での閲覧や貸出サービスを活用していただければと思います。疑問があればこの場でもDMでも聞いていただければと思います。完全に別件で20代のキャリア形成を振り返ったブログ記事も紹介しますので、同じ道を歩む方々の参考になれば幸いです。syu-m-5151.hatenablog.com会津大学の皆さんは、日本有数のコンピュータサイエンス教育を受けている最中ですね。私がコンピュータサイエンスを学んでいた頃と比べると、周りの環境は一変しています。ほんの10数年前、私が学生だったころには「AIがコードを書く」というのはまだSFの世界の話でした。「そんな日が来るのかな〜」なんて友達と冗談半分で話していたのに、気づけばそれが当たり前になっている。2020年の「アップロード ～デジタルなあの世へようこそ」（死後デジタル世界へアップロードされた主人公を描くSFコメディ）には、AIによるコード支援の形でペアプロのような描写がありましたが、今や私たちの現実はそれを遥かに超えています。ja.wikipedia.org2025年の今、生成AIはもはや「選択肢」ではなく「前提」です。私の職場でも、多くのエンジニアがCline、Cursor、RooといったAIコーディングアシスタントを日常的に活用しています。「人間がコードを書く」という、これまでエンジニアの核心的業務だと思われていた部分が急速に変化しつつあります。zenn.devこの変化に直面して、皆さんはこんな疑問を持っているかもしれませんね：「プログラミング言語やアルゴリズムを学ぶ意味は、これからどこにあるんだろう？」「AIがコードを書く時代に、エンジニアとして私は何をすればいいんだろう？」実は、私も同じような疑問を感じながら日々仕事をしています。でも、この変化は単なる脅威ではなく、新たな可能性も開いてくれると思うんです。AIの登場によって、私たちエンジニアの役割も進化していくのかもしれません。www.oreilly.com今日の講演では、プログラミングの基礎知識の重要性はもちろん、それに加えて「文脈に応じた適切な問いの立て方」や「AIとの効果的な協働方法」など、これからのエンジニアに求められるスキルについて考えていきたいと思います。本日は、実際の現場での経験や試行錯誤から学んだことをもとに、具体的で実践的なお話ができればと思っています。皆さんはAIと共に成長する世代のエンジニアです。これは確かに挑戦ですが、同時に新しい可能性にも満ちています。それでは、まずは将来価値のあるエンジニア像から考えていきましょう。この記事で得られる3つのポイントはじめに1. 「つぶしが効く」エンジニアになるために深い理解の価値なぜ専門家ほどAIを使いこなせるのか理解の範囲がツール活用の上限を決める原理原則は腐らない知識になるAI時代における深い理解の実践的意味実践のためのアドバイス2. 技術を点ではなくて線で見極める目を養う技術の進化と本質的価値長期的に価値を持つスキルの見極め方実践のためのアドバイス3. 技術革新と不平等の歴史から学ぶ歴史に見る技術革命と不平等AI革命の文脈で考えるエンジニアの責任と可能性4. そして、エンジニアになるユーザーに寄り添うエンジニアになる技術に寄り添うエンジニアになる自分に寄り添うエンジニアになる量をこなすことの本質的価値ちゃんと、エンジニアになる5. 計画的偶発性理論とAI時代のキャリア戦略計画的偶発性理論とは計画的偶発性を生み出す5つの行動特性1. 好奇心（Curiosity）2. 持続性（Persistence）3. 楽観性（Optimism）4. 柔軟性（Flexibility）5. 冒険心（Risk Taking）計画的偶発性理論に基づくキャリアの基礎構築専門性と横断性のバランス実践的な問題解決経験人間同士のコミュニケーション能力明日からの具体的なアクションAIツールの実験と比較日記を通じた言語化能力の向上コミュニティへの参加と知識の還元不確実性を受け入れ、偶然を活かす姿勢おわりにこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はてなブログに投稿しましたこれから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学 - じゃあ、おうちで学べる  https://t.co/cUS6z4nBmt#はてなブログ— nwiizo (@nwiizo) 2025年5月21日   1. 「つぶしが効く」エンジニアになるために皆さん、エンジニアとして長く活躍するために最も重要なことは何でしょうか？それは「つぶしが効く」エンジニアになることです。つまり、どんな環境でも、どんな技術変化が起きても適応できる基盤を持つことが重要です。「つぶしが効く」エンジニアになるには、標準化された技術スタックの習得だけでは不十分です。 技術の深層に潜り、なぜそう設計されているのかを理解し、他社や他プロジェクトでも応用できる原理原則を掴むことが重要です。表面的な技術習得より、深い洞察を積み重ねることこそが差別化につながります。エンジニアとしての私自身の経験から言えることですが、本当にキャリアの長期的な安定性をもたらすのは、特定のプログラミング言語やフレームワークの知識ではなく、「なぜそのように設計されているのか」という根本的な理解です。例えば、10年前にモバイルアプリ開発で流行していたフレームワークの多くは今や使われていませんが、その基盤となるアーキテクチャパターンや並行処理の原則は今でも変わらず価値を持っています。もし、Webのバックエンドエンジニアとして就職がしたいと思っているなら「データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理」などを読むとよいのではないでしょうか？ちょうど、来年ぐらいに第2版もリリースされることですし、learning.oreilly.com若いうちからやっておいた方がよく、失ってから「なぜ誰も教えてくれなかったのか」と後悔することが多い健康管理。これはAI時代においても最も必要なものの一つです。そして見落とされがちですが、「つぶしが効く」エンジニアキャリアの持続可能性において身体的・精神的健康の維持は極めて重要です。 デスクワークが中心のエンジニアは運動不足になりがちで、長時間のコーディングや深夜の障害対応などで睡眠リズムが乱れやすい職業です。健康管理は本当に大切なことです。理想的には、週に3回程度の有酸素運動と軽い筋トレを習慣化することをお勧めします。特にデスクワークによる姿勢の悪化を防ぐために、背中や体幹の筋肉を鍛えることは効果的です。また、1時間に一度は立ち上がって5分程度ストレッチするだけでも違います。最近では多くのエンジニアが導入している昇降式デスクも検討する価値があるでしょう。精神面では、定期的な休息とメンタルリフレッシュの時間確保が重要です。技術の進化が早いIT業界では常に学び続ける必要がありますが、それだけに燃え尽き症候群のリスクも高いです。趣味や運動など、コーディング以外の活動に意識的に時間を割くことで、長期的には創造性や問題解決能力も向上します。運動脳作者:アンデシュ・ハンセンAmazon深い理解の価値なぜ専門家ほどAIを使いこなせるのか現在のLLMはプログラミング教師としてはもはや人間より性能が上だと言えるでしょう。膨大なコードベースから学習したLLMは、何千もの言語やフレームワークについての知識を持ち、無限の忍耐力で初心者の質問に答えることができます。そして次の世代のLLMは今の世代よりさらに優秀になることが予想されます。このような状況で、多くの人が「AIがコードを書いてくれるなら、私たちエンジニアは何をすればいいの？」と疑問に思います。しかし、興味深い現象が起きています。AIツールを最も効果的に使いこなしているのは、すでにその分野に深い知識を持つエンジニアたちなのです。これは「生成AIが何でもやってくれる」という主張と矛盾しているように思えますが、実は理にかなっています。深い理解を持つエンジニアは、AIの提案を適切に評価し、改善点を見つけ、より良い解決策へと導くことができるからです。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon理解の範囲がツール活用の上限を決めるここで重要な原則があります。「自分の認知を超えるものは活用できない」ということです。例えば、プログラミングの基本概念を理解していない人がAIに「効率的なアルゴリズムを書いて」と頼んでも、生成されたコードが本当に効率的かどうかを判断できません。データベース設計の原則を知らない人が「スケーラブルなデータモデルを設計して」と指示しても、結果の質を評価する基準がないのです。現場の視点から言えば、AIが生成したコードを無批判に受け入れた結果、既にいくつかの重大なパフォーマンス問題やセキュリティホールを生み出してしまう例を何度も目にしてきました。反対に、基礎をしっかり理解しているエンジニアは、AIの提案を適切に評価し、時には「ここはこうした方がいい」と修正を加えることができます。ファンタジア(吹替版)ミッキーマウスAmazon原理原則は腐らない知識になるなぜAIの時代にも深い理解が重要なのでしょうか。その答えは、コードの「良い」「悪い」を決めるのは、AIでも人間の主観でもなく、そのコードが負う責任だからです。責任の評価: その責任の重さと範囲を正確に評価できるのは、システムの基盤となる原理を深く理解している人だけです影響範囲の見極め: AIが提案する解決策の影響範囲と限界を見極め、より適切な方向性を示せるのは、システム設計の原則と実世界での影響を理解している人だけです統合と責任: AIが生成した出力を実際の問題解決に統合し、その結果に責任を持てるのは、全体的なアーキテクチャを理解しているエンジニアだけですプログラミング言語やツールは変わっても、基本的な原則や設計パターンは何十年も変わりません。アルゴリズム、データ構造、分散システム、データベース設計などの基礎的な知識は、AIの時代になってもその価値が色あせることはありません。むしろ、AIが成熟するほど、ソフトウェアの量は爆発的に増えます。その基盤となる原理原則を理解している人の価値は高まるのです。syu-m-5151.hatenablog.comAI時代における深い理解の実践的意味結局のところ、AIをパートナーとして活用し、その出力を批判的に評価し、改良できる能力こそが、これからのエンジニアに求められる真の価値なのです。これは次のような実践を意味します：AIとの対話における質問力: 適切な問いを立て、AIから価値ある回答を引き出す能力出力の評価眼: AIが生成したコードやアイデアの品質を見極める判断力改善と統合: AIの提案を実際のプロジェクトに適用し、必要に応じて改善する技術力責任ある実装: 最終的な成果物に対して技術的責任を負える専門性AIが発展すればするほど、私たち自身も成長し続ける必要があります。AIと効果的に協働するための使い方は、自分自身の学びと経験に基づいて考え、発展させていくものなのです。これからのエンジニアは、AIを単なる「便利なツール」として使うのではなく、深い理解に基づいた「創造的なパートナーシップ」を築いていく必要があるでしょう。そのパートナーシップの質を決めるのは、結局のところ、私たち人間が持つ基礎的理解の深さなのです。 speakerdeck.com実践のためのアドバイスでは、大学生の皆さんが「つぶしが効く」エンジニアになるために、具体的に何をすべきでしょうか？基礎を徹底的に学ぶ：授業で教わるアルゴリズムとデータ構造を丸暗記ではなく、本質的に理解する講義だけでなく、自分で実装してみることで理解を深めるコンピュータサイエンスの基礎科目を軽視せず、しっかり身につけるOSの仕組みやメモリ管理などのローレベルな動作原理も抽象化に頼らず理解する「なぜ」を常に問う：新しい技術やツールに出会ったとき、「なぜこれが存在するのか」を考える課題やレポートに取り組む際、「これはなぜこの方法で解くのか」を自問自答するAIがコードを生成したときも、「なぜこのような実装になるのか」を考察する「どうやって」の前に「なぜ」を問うことで、表面的な理解を超える多様な経験を積む：授業の課題だけでなく、サークル活動やハッカソンなど異なる環境での開発を経験するチームプロジェクトに積極的に参加し、異なる役割を経験してみるコンテストや学外の活動にも挑戦して視野を広げる可能であれば異なる規模のプロジェクト（小規模な個人プロジェクトから大規模なチーム開発まで）を経験するいいやつになる：技術力だけでなく、チームの中で信頼される人間性を育む知識やスキルを惜しみなく共有し、他者の成長を支援する批判するだけでなく建設的なフィードバックを心がける自分の間違いを素直に認め、修正できる謙虚さを持つ技術的な決断において倫理的な側面も考慮できる視点を養う一時的な効率より長期的な関係構築を重視する姿勢を持つ「つぶしが効く」エンジニアは、特定の技術やツールに依存しません。彼らは根本的な問題解決能力と適応力を持ち、どんな状況でも価値を生み出せるのです。皆さんも大学時代から、そのような柔軟性と深い理解を育てていきましょう。『コンサル一年目が学ぶこと ― 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選』は、論理的思考・プレゼン・タイムマネジメントなど30の汎用スキルを「話す技術／思考術／デスクワーク術／ビジネスマインド」の４カテゴリに整理し、AIでは置き換えにくい問題解決プロセスを基礎から鍛えてくれる。コンサル一年目が学ぶこと 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選作者:大石哲之ディスカヴァー・トゥエンティワンAmazon『コンサルティング会社 完全サバイバルマニュアル』は、アナリストからマネージャーまでに潜む罠と突破口を３部構成で描き、クライアント合意形成やチーム動員術など"人間関係の摩擦"を乗り越える実践策を開示し、苛烈な業界で残業せず成果を出すための暗黙知を授ける。コンサルティング会社　完全サバイバルマニュアル (文春e-book)作者:メン獄文藝春秋Amazon『シン・ロジカルシンキング』は、問い（Q）→仮説（A）→示唆（D）→結論（I）のQADIサイクルで〈発見〉と〈論証〉を往復し、生成AI時代にこそ差別化源となる"問う力"と独創的洞察の生み出し方を提示する。基礎体力を底上げする一冊、苛烈な現場を生き抜く一冊、思考をアップデートする一冊——この３冊を通読すれば、ビジネスパーソンはAIが代替できない知的生産プロセスを多角的に武装できる。シン・ロジカルシンキング作者:望月安迪ディスカヴァー・トゥエンティワンAmazon生成AIの時代には、単にコードを書く技術だけでは「AIに任せた方が早いもしくは安い(易い)」と思われてしまう危険性があります。これは新卒のみなさんだけではなく中堅やベテランエンジニアも同様にです。AI時代を生き抜くには、技術スキルだけでなく、問題の本質を見抜く力、ビジネス感覚、そして人間関係の機微を読む力を意識的に磨くことが不可欠で、これらのスキルを身につけることで、技術力と人間力を兼ね備えた「AIより人間に任せたい」「〇〇といっしょに働きたい」と思われるエンジニアになれるのです。www.slideshare.netバカと無知―人間、この不都合な生きもの―（新潮新書） 言ってはいけない作者:橘玲新潮社Amazon2. 技術を点ではなくて線で見極める目を養うAIやテクノロジーの進化が加速する中、多くの学生や若手エンジニアはこの変化について行こうと焦っています。「最新技術を習得しないと就職で不利になるのでは？」「他の人に遅れを取るのでは？」という不安も理解できます。しかし、最先端の技術を追いかけることだけに集中すると、むしろ長期的な成長を妨げる可能性があります。皆さんには、「技術を点ではなくて線で見極める目」を養ってほしいと思います。syu-m-5151.hatenablog.com技術の進化と本質的価値技術の進化に振り回されず、本質を見極めることがエンジニアの価値です。 最新技術への焦りは不要で、顧客価値を軸に選択すべきです。「流行りの技術を使っていない」ことへの不安より、「なぜその技術が必要か」を問い続けることが、長期的に価値あるエンジニアになる道筋です。ハラリが「NEXUS 情報の人類史」で指摘しているように、人類の進化はつねに「情報ネットワーク」と密接に関わってきました。そして今、私たちは人類史上初めて「人間ならざる知能」の時代に突入しています。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon技術者として重要なのは、この歴史的文脈の中で自分たちの立ち位置を理解することです。私たちは単なる「コード生産者」ではなく、情報の流れ方そのものを設計する重要な役割を担っています。特にAIモデルが日々進化する中で、「どのような情報をどのように処理し、どのような形で人間に提示するか」という選択は、社会に大きな影響を与えます。「新しい技術に追いつかなければ」という焦りはエンジニアなら誰しも感じるものです。しかし、重要なのは技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。長期的に価値を持つスキルの見極め方技術の世界は常に変化していますが、すべての変化が同じ重要性を持つわけではありません。「新しい技術に追いつかなければ」という焦りに駆られる前に、次の3つの質問を自分に問いかけてみてください：この技術は一時的なトレンドか、根本的な変化か？このフレームワークの流行り廃りは一時的なトレンドか？バージョン管理システムの普及は根本的な変化か？クラウドインフラの普及やコンテナ技術の標準化は根本的な変化の原因は？この技術は問題解決の新しい方法を提供しているのか？単に既存の解決策を少し改良したものかまったく新しいアプローチを可能にするものか解決できる問題の範囲を根本的に拡大するものかこの技術の基礎となる原理は何か？表面的な実装詳細を超えて、根底にある考え方は何かその原理は他の文脈でも適用可能かその原理が解決している根本的な問題は何かこれらの質問に答えることで、目の前の技術が「追いかける価値があるもの」なのか、それとも「様子を見るべきもの」なのかを判断する力が養われます。重要なのは、技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。また、個人ですべての技術動向を追うのは現実的ではありません。信頼できる技術ブログや専門家の意見、実際に手を動かしている現場のエンジニアの知見を参考にしながら、情報収集の効率化を図ることも重要です。そこで、今のXは少々使いづらいのでControl Panel for Twitterなどのプラグインを利用すると良いユーザー体験が生まれるのでオススメです。システム設計の現場では、「賢い」デザインと「単純」なデザインの選択に直面することがよくあります。経験から言えることですが、長期的に価値を持つのは後者です。いくら「賢く」見える技術ソリューションでも、あまりに複雑で他者が理解しにくいものは、長期的にはメンテナンスコストが高くなり、チームの足かせになります。「単純さ」を追求することこそ、実は高度な技術力の現れなのです。 speakerdeck.com実践のためのアドバイスでは大学生の皆さんは、どうすれば技術の本質を見極める目を養えるのでしょうか？「なぜ」を5回問う：新しい技術に出会ったら、連続して「なぜ」を問いかけましょう。例えば：なぜDockerが人気なのか？ → 環境の一貫性を提供するからなぜ環境の一貫性が重要か？ → 開発と本番環境の差異を最小化するためなぜ環境差異の最小化が必要か？ → デプロイの信頼性向上のためなぜデプロイの信頼性が重要か？ → 継続的なサービス提供のためなぜ継続的なサービス提供が求められるか？ → デジタルサービスの常時稼働が期待されるからこの連鎖的な問いかけで、技術の表層から社会的・経済的な本質へと掘り下げられます。古典的で嫌う人もいますが一定の価値はあると思います。技術の歴史を学ぶ：デカルトは「困難を分割せよ」と言い、ビル・ゲイツは「問題を切り分けろ」と言った。この思想はコンピュータサイエンスの基盤ですが、実は問題の分解法こそが難所です。歴史的変遷を学ぶことで、なぜ現在の解法が選ばれたのか、試行錯誤のプロセスも含めて理解でき、「創造の追体験」という知的興奮を得られます。プログラミング言語の進化やプロトコル設計の歴史を知ることで、表層的な知識を超えた洞察が得られるでしょう。知的多様性と創造的衝突を求める：技術の価値は多様な視点がぶつかる場で鮮明になります。同じ技術でも、バックエンド、フロントエンド、デザイン、マネジメントの観点で評価が異なります。計算機科学だけでなく、心理学や経営学など異分野からの視点が予想外の気づきをもたらすことも。研究室やサークルでの議論から始め、カンファレンスやオンラインコミュニティへと視野を広げ、「異質な他者」との対話を通じて技術の多面性を理解しましょう。コードを「読む」文化を身につける：優れたミュージシャンが名曲を聴き込むように、良いエンジニアは質の高いコードを読み込みます。GitHubの時代は「巨人の肩」への前例のないアクセスを提供しています。LinuxカーネルやPostgreSQLなど様々な成熟度のプロジェクトから生きた知恵を吸収しましょう。コミットメッセージや設計ドキュメントを読むことで、技術選択の背景にある思考プロセスも理解できます。「読む」という行為は「書く」能力を飛躍的に高める最も効率的な投資です。技術の本質を見極める目を持つことは、AI時代のエンジニアにとって最も価値ある資質です。流行りに惑わされず「なぜ」を問い続けることで、変化する環境でも揺るがない判断軸を持てるようになるでしょう。3. 技術革新と不平等の歴史から学ぶ技術の本質を見極める視点をさらに深めるために、ここで少し歴史的な視点から考えてみましょう。技術革新は本当に社会を良くするのでしょうか？その恩恵は誰に届くのでしょうか？2024年のノーベル経済学賞受賞者ダロン・アセモグルとサイモン・ジョンソンも「技術革新と不平等の1000年史」で重要な警鐘を鳴らしています。彼らの研究によれば、技術革新は自動的に社会全体の富や幸福をもたらすわけではありません。むしろ歴史は、技術革命の果実が一部の人々に集中し、不平等を拡大させてきた事例で満ちています。技術の恩恵が広く社会に行き渡るかどうかは、技術そのものではなく、その「ビジョン」と「設計された分配システム」に依存するのです。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon歴史に見る技術革命と不平等人類の歴史を振り返ると、多くの技術革命は必ずしも万人に恩恵をもたらしてきませんでした。農業革命は食料生産を増加させましたが、その恩恵は主に土地を所有するエリート層に集中し、多くの人々はかえって過酷な労働を強いられました。情報の視点で見れば、これは「中央集権的な情報管理」の始まりでもありました。少数の支配者が情報を独占することで、多数の人々を統制する仕組みが生まれたのです。産業革命の初期段階では、工場労働者の生活水準は実際に悪化しました。機械化による生産性向上の恩恵は工場主に集中し、労働者は危険で過酷な環境で働かされました。情報の観点では、「標準化された情報」と「階層的な情報の流れ」が特徴的でした。コンピュータ革命でさえ、デジタル格差と所得格差の拡大をもたらしました。プログラミングのスキルを持つ人々と持たない人々の間に新たな分断が生まれ、技術の発展が必ずしも平等な社会をもたらさなかったのです。ハラリは「情報が多いほど真実に近づける」という素朴な前提が実は誤りであることを指摘しています。同じ情報インフラが科学を発展させる一方で、魔女狩りのような集団ヒステリーを引き起こすこともあるのです。決定的な分かれ道となるのは、「間違いを前提に互いに補正できる仕組みがあるかどうか」なのです。カルトのことば　なぜ人は魅了され、狂信してしまうのか作者:アマンダ・モンテル,青木音白揚社AmazonAI革命の文脈で考える私たちが今経験しているAI革命も、同様の歴史的パターンを繰り返す可能性があります。AIが生み出す生産性向上の恩恵は、AIを所有・制御する企業や個人に集中するかもしれません。また、AIを効果的に活用できるスキルを持つ人々と持たない人々の間に新たな格差が生まれる可能性もあります。エンジニアとして私たちは、技術が社会に与える影響に対して無関心ではいられません。私たちが設計するシステムが、意図せず不平等を拡大したり、一部の人々を排除したりする可能性を常に意識する必要があります。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店AmazonLLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発作者:John Berryman,Albert Ziegler,服部 佑樹（翻訳）,佐藤 直生（翻訳）オーム社Amazonエンジニアの責任と可能性歴史は決定論的ではありません。私たちには選択肢があります。エンジニアとして、技術の恩恵がより広く社会に行き渡るような設計や実装を意識的に選ぶことができます。具体的には：アクセシビリティを考慮した設計：すべての人がテクノロジーの恩恵を受けられるよう、多様なユーザーのニーズを考慮する倫理的な視点を持つ：開発するシステムが社会に与える可能性のある影響を常に考えるオープンな技術の推進：知識や技術へのアクセスを広げるオープンソースやオープン教育の取り組みに参加する多様性のある開発チーム：様々な背景や視点を持つ人々が開発に参加することで、より包括的な技術を生み出す技術史を学ぶことは、未来を形作るために不可欠です。私たちは過去の過ちを繰り返さないよう、意識的に行動することができます。AI時代のエンジニアとして、技術の社会的影響を理解し、より公正で包括的な未来に貢献する責任があるのです。デジタルの皇帝たち――プラットフォームが国家を超えるとき作者:ヴィリ・レードンヴィルタみすず書房Amazon4. そして、エンジニアになるここまで、技術的な深さと歴史的視点について話してきましたが、次に「人間的な側面」に目を向けていきましょう。AI時代において価値あるエンジニアとなるために必要な、「ユーザー」「技術」「自分自身」との3つの関係性について考えていきます。ユーザーに寄り添うエンジニアになる技術に精通することはエンジニアにとって重要ですが、それだけでは十分ではありません。価値のあるエンジニアとなるためには、自分の作るものが最終的に誰に届き、どのような影響を与えるのかを常に意識する必要があります。エラーログの向こうに人がいることを忘れるな。0.01%の障害も、誰かの人生を大きく狂わせる可能性があります。 数字だけで判断せず、実際にサービスを触り、ユーザー体験を自分の目で確かめるエンジニアこそが、信頼性の高いシステムを作れるのです。例えば私の経験からですが、あるサービスで「99.9%の可用性」というメトリクスに満足していたチームがありました。しかし、実際にユーザーとして使ってみると、残りの0.1%の障害が、ユーザーが最も重要なタイミング（プレゼンの直前や商談中など）に発生していることが分かりました。統計的には小さな数字でも、ユーザーにとっては致命的な問題になり得るのです。エンジニアの世界では、しばしば数字やメトリクスで成功を測ります。「99.9%の可用性」「平均応答時間50ms」「エラー率0.01%」といった具合です。これらの数字は確かに重要ですが、その裏側にある人間の体験を見失ってはいけません。技術的な指標だけでなく、「この機能が失敗したとき、ユーザーはどう感じるか」「彼らの人生にどんな影響を与えるか」を常に考えることが、価値のあるシステムを作る鍵となります。エンジニアとして成長するために最も効果的な方法の一つは、自分が作ったシステムを実際のユーザーとして使ってみることです。これは「ドッグフーディング」とも呼ばれますが、単なる形式的なテストではなく、ユーザーの立場に立つことを意味します。この体験を通して、技術的な視点だけでは見えてこなかった問題点や改善の機会に気づくことができるでしょう。技術に寄り添うエンジニアになるエンジニアとして価値を発揮するためには、技術そのものを深く理解し、技術の特性や進化の方向性に寄り添う姿勢も重要です。技術に寄り添うとは、単に最新技術を追いかけることではなく、各技術の本質や適切な使いどころを見極める目を持つことです。技術を目的化せず、手段として適切に選択できるエンジニアが良い価値を生み出せます。 データベースの負荷問題も、技術的な最適化、アーキテクチャの再設計、あるいはビジネス要件の見直しなど、複数の視点から最適な解決策を見つけられる柔軟性が重要です。技術に寄り添うエンジニアは、次のような特徴を持っています：技術の「なぜ」を理解している：特定の技術がなぜ生まれたのか、どのような問題を解決するために設計されたのかを理解しています。この理解があるからこそ、適切な場面で適切な技術を選択できるのです。技術の限界を認識している：どんな優れた技術にも限界があることを知っています。「この技術では解決できない問題は何か」を理解しているからこそ、過剰な期待や誤った適用を避けることができます。技術間の関係性を把握している：個々の技術を孤立して見るのではなく、技術エコシステム全体の中での位置づけを理解しています。これにより、相互運用性の問題や将来的な拡張性を考慮した設計が可能になります。技術の進化の方向性を予測できる：過去の技術進化のパターンを理解し、将来の方向性を予測する目を持っています。これにより、一時的なトレンドに振り回されず、長期的な視点で技術選択ができます。技術に寄り添うためには、幅広い知識と経験が必要です。異なる専門領域の知識を組み合わせ、多角的な視点で問題を捉える能力が重要になります：フロントエンドとバックエンドの両方の視点から考えるインフラストラクチャとアプリケーション開発の関係性を理解するセキュリティとユーザビリティのバランスを考慮するパフォーマンスと保守性のトレードオフを意識するAIの時代においては、「人間とAIの協働」という新たな視点も必要です。AIツールの特性を理解し、人間の創造性と判断力を活かしながら、AIの処理能力と効率性を組み合わせていく視点が重要になるでしょう。技術に寄り添うエンジニアになるには、一朝一夕ではなく日々の小さな習慣の積み重ねが鍵です。毎日15分の技術調査、週一回のコード見直し、月一冊の技術書など、小さくても継続的な取り組みが深い理解を育みます。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon200万人の「挫折」と「成功」のデータからわかった 継続する技術作者:戸田大介ディスカヴァー・トゥエンティワンAmazonAI時代では特に、新しいツールを定期的に試し、結果を記録する習慣が重要です。理解のプロセスは螺旋状に進みます。この道のりには挫折もありますが、小さな習慣を粘り強く続けることで、技術に対して誠実なエンジニアへと成長できるのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon自分に寄り添うエンジニアになる技術の急速な進化と複雑化が進む中、エンジニアとして長く活躍し続けるためには、「自分自身に寄り添う」姿勢も欠かせません。これは単に自己満足や自己中心的になることではなく、自分の学習プロセス、強み・弱み、成長の方向性を理解し、持続可能なキャリアを構築することを意味します。元オリンピック選手で「熟達論」で知られる為末大氏は、熟達を単なる技術の向上ではなく、「技能と自分」を一体として捉え、人間という総体を高めていくプロセスだと説明しています。このアプローチはAI時代のエンジニア育成においても極めて示唆に富んでいます。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon為末氏による熟達の5段階を見ていきましょう：遊(ゆう) - 探索と実験: すべての学びは「遊び」から始まります。好奇心に導かれ、新しい言語やフレームワーク、AIツールと自由に戯れる段階です。ここでの自由な探索が長期的な学習のエネルギー源となります。型(かた) - 基本を身につける: 基本的な動きや思考パターンを繰り返し練習し、無意識にできるようになる段階です。AIがコード生成を担う時代でも、この「型」の理解なしにAIの出力を評価・改善することはできません。観(かん) - 深い理解: 対象を部分に分解し、その関係性と構造を深く理解する段階です。コードが「動く」だけでなく、「なぜそう動くのか」を考察し、見えない部分まで想像できるようになります。心(しん) - 本質の把握: 細部にとらわれず全体のバランスを保ち、本質的な部分を直感的に見抜ける段階です。AIとのコラボレーションにおいても、本質的な方向性を見失いません。空(くう) - 創造的境地: 既存の枠組みを超え、純粋に目的や価値の創造に集中できる境地です。AI時代においてこそ、この創造的な「空」の境地が人間の価値となります。重要なのは、熟達のプロセスが一直線ではなく螺旋状に進むということです。新しい技術やAIモデルに出会うたびに、再び「遊」の段階から始まり、徐々に「型」「観」「心」へと進んでいきます。この螺旋的な成長過程を理解し、受け入れることで、変化の激しいAI時代においても心理的な安定を保ちながら成長し続けることができるのです。自分に寄り添うエンジニアになるための具体的なアプローチとしては：自分の学習スタイルを理解する：人によって効果的な学習方法は異なります。読書、実践、教えること、議論など、自分にとって最も効果的な学習方法を見つけ、意識的に活用しましょう。自分のエネルギー源を知る：何に取り組むとエネルギーが湧いてくるか、逆に何をするとエネルギーを消耗するかを理解しましょう。持続可能なキャリアのためには、エネルギーを与えてくれる活動と消費する活動のバランスが重要です。適切な休息と内省の時間を確保する：常に新しい技術を追いかけ続けるのではなく、学んだことを内省し、自分のものにするための時間も大切です。定期的な休息や趣味の時間も、長期的な創造性と生産性のために不可欠です。自分の強みと弱みを正直に評価する：すべてを完璧にこなそうとするのではなく、自分の強みを活かし、弱みは補完するアプローチを考えましょう。チームやコミュニティの中で、互いの強みを活かし合う関係を構築することも重要です。量をこなすことの本質的価値ここまで「寄り添う」という質的な側面について語ってきましたが、エンジニアとして成長する上で避けて通れない真実があります。それは「質は量から生まれる」ということです。AI時代になって「もうコードを大量に書く必要はない」と考える人もいるかもしれません。しかし、これは大きな誤解です。AIを効果的に使いこなせる人は、例外なく膨大な量のコードを書いてきた人たちです。なぜなら、量をこなすことで初めて得られる「暗黙知」があるからです。為末氏の熟達論でも触れたように、成長は螺旋状に進みます。量をこなすことで質が向上し、質の向上によってより高度な量をこなせるようになるという好循環が生まれます。最初の1000時間は基礎的なコーディングスキルの習得に費やされるかもしれません。次の1000時間では、より複雑な問題解決に挑戦できるようになります。そして次の1000時間では、AIと協働しながら、以前は想像もできなかった規模のプロジェクトに取り組めるようになるでしょう。「とにかく手を動かせ」という古からのアドバイスは、AI時代においても色褪せることはありません。むしろ、AIという強力なパートナーを得た今こそ、かつてない速度で量を積むことができる絶好の機会なのです。ちゃんと、エンジニアになるこれまで述べてきた「ユーザーに寄り添う」「技術に寄り添う」「自分に寄り添う」という3つの姿勢を総合して、初めて「ちゃんとしたエンジニア」になれるのではないでしょうか。では、実際にどのようにすれば、これらの要素を日々の実践に落とし込んでいけるのでしょうか？自分の作ったものを実際に使う習慣をつける：自分が開発したシステムやアプリケーションを、定期的に実際のユーザーとして使ってみましょう。理想的には、業務外の時間や異なる環境で使うことで、新たな視点が得られます。「ユーザーに寄り添う」姿勢を具体化する第一歩です。異なる専門性を持つ人々との協働を積極的に求める：デザイナー、プロダクトマネージャー、マーケター、ビジネス部門の人々など、多様な背景を持つ人々との協働プロジェクトに参加しましょう。これにより、多角的な視点で問題を捉える力が養われ、「技術に寄り添う」視野の広さが育まれます。AIとの「遊び」の時間を確保する：AIツールを業務だけでなく、創造的な探索のために使う時間を意識的に確保しましょう。例えば、週に1時間だけ「AIとの実験タイム」を設け、新しい使い方や可能性を探求するのも良いでしょう。為末氏の言う「遊」の段階を大切にすることで、AIとの共創の可能性が広がります。振り返りとフィードバックを習慣化する：プロジェクトやタスクの終了後に、「何がうまくいったか」「何が改善できるか」「どんな学びがあったか」を振り返る時間を持ちましょう。また、同僚や顧客からのフィードバックを積極的に求め、それを次の成長につなげましょう。これは「自分に寄り添う」ための重要な習慣です。「技術以外の本」を読む習慣をつける：技術書だけでなく、デザイン、心理学、ビジネス、哲学など様々な分野の本を読むことで、多角的な思考が育まれます。これらの知識は、技術的な問題に対しても新たな視点をもたらすことがあります。「ちゃんとしたエンジニア」とは、単に技術が優れているだけでなく、その技術を通じて人々の生活や仕事をより良くする価値を生み出せる人です。そのためには、技術的なスキルだけでなく、ユーザーへの共感力、技術の本質を見極める洞察力、そして自分自身の成長プロセスを理解する内省力が必要です。AI時代のエンジニアとして、これらの要素をバランスよく発展させることで、単なる「コードを書く人」を超えた、価値あるエンジニアへと成長することができるでしょう。技術の進化がどれほど加速しても、最終的に価値を生み出すのは人間です。その原点を忘れずに、日々の実践を積み重ねていきましょう。エンジニアとしての総合的な成長を目指す方には、技術的スキルだけでなく人生全体のマネジメントや自己投資の方法を網羅的に解説した『ソフトスキル：ソフトウェア開発者の人生マニュアル』と、プログラミングの技術的側面に加えてプロフェッショナルとしての心構えや実践的知恵を提供する古典的名著『達人プログラマー：熟達に向けたあなたの旅』の2冊をぜひお読みいただきたいと思います。前者は「自分に寄り添う」姿勢を育み長期的なキャリア構築の指針となり、後者は「技術に寄り添う」ための具体的なプラクティスが豊富で、両書を通じてAI時代においても普遍的な価値を持つエンジニアリングの本質と、バランスの取れた成長への道筋を学ぶことができるでしょう。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon5. 計画的偶発性理論とAI時代のキャリア戦略ここまで「つぶしが効くエンジニア」「技術の本質を見極める目」「エンジニアとしての在り方」について話してきました。では、AIの急速な進化という大きな変化の中で、皆さんは具体的にどのようなキャリア戦略を持ち、どのような選択をすればよいのでしょうか？「AIに代替されない職業を選ぶべきか」「これから伸びる分野はどこか」という問いに明確な答えを出すことは困難です。その代わりに、不確実性の高い時代におけるキャリア構築の考え方として、「計画的偶発性理論」（Planned Happenstance Theory）をご紹介します。この理論を理解した上で、大学時代の選択と明日からの具体的なアクションについて考えていきましょう。計画的偶発性理論とは計画的偶発性理論は、スタンフォード大学の心理学者ジョン・D・クランボルツ教授が1999年に提唱したキャリア発達理論です。この理論によれば、個人のキャリアの約8割は、本人が予想していなかった偶然の出来事によって方向づけられるとされています。クランボルツ教授は、成功したビジネスパーソンのキャリアを調査した結果、多くの人のターニングポイントが「計画されたもの」ではなく「偶然の出来事」だったことを発見しました。しかし重要なのは、その「偶然」をただ待つのではなく、偶然を活かすための準備と行動が必要だということです。この理論がAI時代において特に重要なのは、テクノロジーの進化があまりに速く、将来どのような職種が残るか、どのようなスキルが求められるかを正確に予測することがほぼ不可能だからです。例えば、数年前には「AIプロンプトエンジニア」という職業は存在していませんでした。現在から見たら過去のトレードオフが分からないので、分かったような顔して「これが正解だった」と言う人はあとから来ていろいろ語りますが、だいたい運で勝っている人も多いです。技術の歴史を振り返ると、「明らかに正しい選択だった」と思えることでも、当時は複数の選択肢の中からの賭けだったことが少なくありません。計画的偶発性を生み出す5つの行動特性クランボルツ教授によれば、計画的偶発性を生み出すには5つの重要な行動特性があるとされています：1. 好奇心（Curiosity）好奇心とは、新しい知識や経験に対して積極的に探求する姿勢です。AIツールやモデルに対する好奇心は、その可能性と限界を見極める上で重要です。「これは何ができるのだろう？」と試してみる姿勢が、未知の可能性を開拓します。学生のうちからできること：講義で紹介された技術を授業以外でも試してみる新しいAIツールが登場したら、すぐに実験してみる「こんなことはできないだろう」と決めつけず、実際に試してみる姿勢を持つ2. 持続性（Persistence）持続性は、困難や障害に直面しても諦めず、目標に向かって努力し続ける能力です。AIツールは万能ではなく、期待通りの結果が得られないことも多々あります。そんなとき、一度や二度の失敗で諦めず、異なるアプローチを試みる持続力が重要です。学生のうちからできること：課題で壁にぶつかったとき、別のアプローチを試みる習慣をつけるAIとの協働でうまくいかない場合も、プロンプトや方法を変えて複数回試す失敗した試みも記録に残し、何が学べたかを振り返る3. 楽観性（Optimism）楽観性は、将来に対する前向きな見方と、成功の可能性を信じる姿勢です。技術変革期には、「AIに仕事を奪われる」といった不安や悲観的な見方が広がりがちです。しかし、歴史が示すように、新技術は常に新たな職種や専門性を生み出してきました。AIを脅威ではなく、可能性を拡張するパートナーとして前向きに捉えることが重要です。学生のうちからできること：技術の変化を「危機」ではなく「機会」として捉える視点を養う失敗やミスを「学びの機会」として前向きに受け止める習慣をつける週に一度、自分の小さな成功や進歩を書き出してみる未来について友人と前向きな対話をする時間を定期的に持つ4. 柔軟性（Flexibility）柔軟性は、変化する状況や予期せぬ出来事に適応する能力です。AI技術は日々進化し、その可能性と制約も常に変化しています。特定のツールや方法論に固執せず、状況に応じて最適なアプローチを柔軟に選択する能力が重要になります。学生のうちからできること：複数のプログラミング言語やフレームワークに触れる「これが唯一の正解」という思考を避け、複数の解法を探る習慣をつける計画変更を余儀なくされたとき、それを学びの機会と捉える姿勢を持つ異なる文化や背景を持つ人々との交流を通じて多様な視点を学ぶコンフォートゾーンを意識的に離れる小さな挑戦を定期的に行う5. 冒険心（Risk Taking）冒険心とは、不確実性や失敗の可能性があっても、新しいことに挑戦する勇気です。AI技術の最前線は常に変化しており、確立された「正解」が存在しないことも多いです。誰も試したことのない方法やアプローチに挑戦する冒険心が、イノベーションを生み出します。学生のうちからできること：ハッカソンやコンテストなど、短期間で新しいことに挑戦する機会に参加する未知の技術領域のプロジェクトにあえて挑戦してみる「失敗しても構わない」と考えられる安全な環境で、リスクを取る経験を積む自分のアイデアを公の場で発表する機会を積極的に求める「ちょっと無理かも」と思うようなプロジェクトや役割に手を挙げてみる計画的偶発性理論に基づくキャリアの基礎構築キャリアとは何でしょうか？「キャリア」の語源はラテン語の「carrus（車輪の付いた乗り物）」に由来し、後にイタリア語（carriera）、フランス語（carriere）となり、レールコース（通り道）を意味するようになりました。つまり、キャリアとは車輪の通った跡（轍・わだち）を意味しています。語源としてはそうですが実際もそうでこれは前もって計画できるものではなく、進んだ後に振り返って初めて見えるものなのです。誰かが「成功したキャリア」を語るとき、それは無数の選択肢と偶然の中から結果的に選び取った一本の道を後付けで説明しているにすぎません。特に現代のように技術革新と不確実性が加速する時代では、10年後、20年後の働き方を正確に予測することはほぼ不可能です。「偶然を必然に変えるのは、あなた自身の行動と姿勢なのです」計画的偶発性理論が教えてくれるのは、予測不能な未来に対して完璧な計画を立てるのではなく、偶然の出会いや機会を活かせるよう準備し、自分だけの独自の轍を刻んでいく姿勢の重要性です。就活生が見る労働の世界はいろんな人達が作った虚構の上に成り立っているので仕事選びや仕事で馬鹿を見ないために読んでおくのありかと思います。NINE LIES ABOUT WORK 仕事に関する9つの嘘は、私たちが当然と受け入れている職場の「常識」が実は神話に過ぎないことを鋭く指摘します。「どの会社で働くかが大事」「リーダーシップというものがある」といった広く信じられている前提を覆し、実際のデータと研究に基づいて職場の真実を明らかにしています。特に就職活動中の方や、キャリアの岐路に立つエンジニアにとって、この本は組織や仕事の本質を見抜く目を養い、自分が本当に活躍できる環境を見極める力を与えてくれるでしょう。NINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon専門性と横断性のバランスAI時代においても、深い専門性の価値は決して減じません。むしろ、ChatGPTのような汎用AIが「浅く広い」知識を提供できるようになるほど、特定分野における「深く狭い」専門知識の希少性は増していきます。しかし同時に、複数の領域を横断する能力も重要です。ここでのポイントは「浅く広く」ではなく「深く狭い専門性を複数持つ」というアプローチです。T型人材（1つの分野で深い専門性+広い一般知識）からπ型人材（複数の分野での深い専門性）へのシフトが、AI時代には価値を発揮します。これから10年、20年と生成AIはますます賢くなっていくでしょう。多くの領域で、AIに「優れる」ことは非常に難しくなります。しかし、「異なる」ことは常に可能です。AI時代のキャリア戦略として大切なのは、「優れる」よりも「異なる」ことを目指すアプローチです。「異なる」とは、独自の視点、独自の問い、独自の関心領域を持つことです。これは必ずしも仕事や学問の組み合わせだけではありません。あなたのユニークな趣味、特異な経験、異文化での生活体験など、あなただけの「異なる」要素がキャリアの差別化につながることもあります。将棋や囲碁が好きな人は、その戦略思考がシステム設計に活きるかもしれません。山登りが趣味の人は、「少しずつ高みを目指す」という考え方がソフトウェア開発に応用できるかもしれません。重要なのは、自分が本当に情熱を持てる「異なる」要素を見つけ、それを技術と組み合わせる方法を探ることです。AIは多くのタスクで人間を超えるかもしれませんが、あなただけの独自の視点と問いは、AIにはない価値を生み出す源泉となるでしょう。実践的な問題解決経験AIがコードを生成できる時代において、「Todoアプリを作りました」といった基本的な実装経験の差別化価値は相対的に低下します。代わりに、「具体的な問題を解決した」という経験が価値を持ちます：特定の地域や集団の課題をテクノロジーで解決するプロジェクト既存ソリューションの特定の制限や課題を克服する独自アプローチニッチな領域の特殊なニーズに対応するツールの開発採用面接で最も印象に残るのは「こういう課題があって、このアプローチを試したがうまくいかなかった。そこでこの解決策を考え、実装した結果、こうなった」と問題解決のプロセス全体を説明できる学生です。人間同士のコミュニケーション能力AI時代こそ、人間同士のコミュニケーション能力が重要になります。特に技術的な内容を非技術者に分かりやすく伝える能力は、AIと人間の橋渡しをする上で不可欠です。技術ブログの執筆、プレゼンテーションの機会の獲得、異なる背景の人々との協働などを通じて、この能力を磨きましょう。明日からの具体的なアクション計画的偶発性理論に基づくなら、重要なのは「偶然の機会に気づき、活かすための行動」です。不確実性が高まる時代だからこそ、以下のような具体的なアクションを通じて、偶然を必然に変える力を養いましょう。AIツールの実験と比較様々なAIコーディングツールを使い倒してみることから始めましょう。これは単なるお遊びではなく、AIの本質と限界を理解するための重要な実験です。GitHub Copilot、Cline、Cursor、など、様々なツールを同じタスクに適用し、それぞれの得意・不得意を体系的に記録してみましょう。これだけ変化が激しい世界で人生を賭けるのはリスクすぎる。「AI比較実験ノート」をつけることで、ただ使うだけでは得られない洞察を得ることができます。重要なのは、AIを「答えをくれる先生」ではなく「一緒に問題を解決するパートナー」として位置づけることです。プロンプトを工夫し、AIの提案を批判的に評価し、改善を求め、最終的には自分で最適化するというサイクルを通じて、効果的な協働方法を見つけていきましょう。自分で手を動かしてない人のいうことはあまり信用しなくてよいです。読んでいない本について堂々と語る方法 (ちくま学芸文庫 ハ 46-1)作者:ピエール・バイヤール筑摩書房AmazonAfter Cline - あるいは語りえぬ者について語ろうとする時代について · GitHubzenn.dev日記を通じた言語化能力の向上TikTokやYouTubeを見る時間の一部を、日記を書く時間に変えてみましょう。たった5分でも構いません。現代の娯楽は文字どおり１分１秒を奪い合うレベルにまで特化していて、長い時間をじっくりかけて楽しむ娯楽は、かれらの目まぐるしい日々の暮らしのなかでそのポジションを急激に失いつつあります。そんな中で、日記を書くことには、多くの利点があります。言語化能力の向上: 自分の考えや経験を言葉にする習慣がつくことで、コミュニケーション能力が自然と高まります。自己認識の深化: 日々の出来事や感情を振り返ることで、自分自身の思考パターンや価値観に気づくことができます。前向きな思考の促進: 特に「今日学んだこと」「今日感謝したいこと」などポジティブな視点を含めた日記は、心理的な健康にも良い影響を与えます。アイデアの整理と発見: 断片的な思考を書き出すことで、新たな関連性やアイデアに気づくことがあります。日記のテーマとしては、「今日学んだ技術のこと」「気になる技術トレンド」「解決した問題とその過程」など、技術に関連したものでも構いませんし、「今日感じた感情」「未来の自分への手紙」など、より個人的なものでも良いでしょう。重要なのは継続することです。スマートフォンのリマインダーを設定したり、就寝前の習慣にするなど、自分に合った方法で習慣化してみてください。スマホ脳（新潮新書） 『スマホ脳』シリーズ作者:アンデシュ・ハンセン新潮社Amazonコミュニティへの参加と知識の還元技術の学習や成長は、一人で行うよりもコミュニティの中で行う方が効果的です。AIツールを活用しながらプログラミングやプロジェクト開発に取り組む仲間と定期的に経験を共有する場を作りましょう。また、学ぶだけでなく、自分の知識や発見を積極的にコミュニティに還元することも重要です。AIツールの活用で得た知見をブログに投稿したり、学内勉強会で発表したりすることで、自分の理解が深まり、新たな視点を得ることができます。不確実性を受け入れ、偶然を活かす姿勢この理論は、「明確なキャリアプランを持つな」と言っているわけではありません。むしろ、計画に固執しすぎず、予期せぬ出来事に柔軟に対応できる準備をしておくことの重要性を教えてくれます。現代のように技術革新のスピードが加速し、不確実性が高まっている時代には、10年後の働き方を正確に予測することはほぼ不可能です。そんな中で「これが絶対の正解」と信じて一つの道に固執するよりも、様々な可能性に目を向け、偶然の機会を活かせるよう自分を準備しておくことが賢明でしょう。「偶然は準備された心にのみ微笑む」という言葉があるように、偶然の出会いや機会を価値あるものに変えるのは、あなた自身の行動と姿勢なのです。AI時代のキャリアにおいては、「これが正解」という単一の道筋はないでしょう。むしろ、好奇心を持って多様な可能性に目を向け、変化に柔軟に対応できる力を養うことが、長期的な市場価値を高める最も確かな戦略かもしれません。完璧を求めすぎないことも重要です。提案した活動のすべてを同時に実行する必要はありません。自分の興味や強みに基づいて、できることから始めましょう。失敗を恐れず、様々なことに挑戦し、可能性を広げることこそが、予測不可能なAI時代に対応するための最良の準備となるでしょう。結局のところ、この話の落としどころは極めて凡庸な結論に帰着します。不確実性を受け入れ、偶然を活かす姿勢といっても、最終的には「自分が選んだ選択肢を正解にするしかない」という単純な事実に行き着くのです。これは特別な知恵でもなんでもない当たり前の話かもしれません。しかし、この凡庸な事実こそが、急速に変化するAI時代において最も実践的な知恵なのかもしれません。どんなに理論を語っても、どんなに戦略を練っても、最後は自分の選んだ道を誠実に歩み、その選択に意味を見出し、自らの手で「正解」に変えていく努力以外に道はないのです。おわりにここまで様々な観点からAI時代のエンジニアキャリアについてお話ししてきましたが、最後に少し本音をお伝えしたいと思います。実は、この講演のタイトル「AI時代に市場価値を高めるキャリア戦略」を見たとき、少し困ってしまいました。このような強いタイトルのもとで講演するには、あまりにも重い責任を感じたからです。「市場価値を高める」などと言えるほど、私自身が確固たる答えを持っているわけではないですし、AIの進化は日々予測を覆しています。しかし、このタイトルが私自身への挑戦状となり、真剣に考える機会となりました。率直に申し上げて、私自身もAIの急速な進化には戸惑いを感じています。現役エンジニアとして、これまで時間をかけて身につけたスキルの一部が、あっという間にAIで代替されていく現実は、正直なところ不安を覚えます。しかし、こうした変化の波に対しては、抵抗するよりも乗る方が賢明でしょう。私たちエンジニアは、望むと望まざるとにかかわらず、この技術革新の最前線に立っています。ただ、この状況をむしろポジティブな視点で捉えることも可能です。今日お話した計画的偶発性理論は、私自身のキャリアを振り返った時に非常に納得感があります。実際、私のキャリアも「計画通り」には進まず、予想外の出会いや偶然の機会が、振り返ってみれば重要なターニングポイントになっていました。例えば、趣味で始めたオープンソース活動が、思いがけず重要な仕事の機会につながったり、一見無関係に思えた副業プロジェクトでの経験が、後の大型プロジェクトで決定的な価値を持ったりしました。このような「計画できない幸運」は、実はキャリア形成の重要な要素ではないかと考えています。最近の経験から、AIツールを積極的に活用することで興味深い発見がありました。当初は「自分の仕事が奪われる」という懸念を抱いていましたが、実際には単調な作業から解放され、より創造的な領域に集中できるようになったのです。コーディングの基礎的な部分や定型的なタスクをAIに委託することで、システム設計や問題の本質的な解決により多くの時間と思考を割けるようになりました。これは決して悪い変化ではないと感じています。今、大学生の皆さんは、AIと共に成長する先駆的な世代です。困難も多いでしょうが、それだけ新しい可能性に満ちた時代でもあります。皆さんが構築するエンジニアとしてのキャリアは、私たち世代のものとは大きく異なるかもしれませんが、それはより創造的で多様な可能性を秘めていると確信しています。皆さんのキャリアが、AIとの創造的な協働を通じて、より充実したものになることを心から願っています。本日はありがとうございました。最後になりますが、今お話したような「AIと共に成長するエンジニア」を私たちの会社でも募集しています。本日の内容に共感いただけた方は、ぜひよろしくお願いします。jobs-3-shake.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[vim-jp ラジオ #41聞いた - モバイルDevOpsエンニジアのgiginetさん登場！]]></title>
            <link>https://blog.atusy.net/2025/05/21/vim-jp-radio-giginet/</link>
            <guid>https://blog.atusy.net/2025/05/21/vim-jp-radio-giginet/</guid>
            <pubDate>Wed, 21 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[最近ちっともvim-jp ラジオをきけてなかった。特段理由らしい理由はないのだけれど、強いていうならYAMORIのビートボックスがよすぎてYoutubeあさったり、TENDREのライブに行ったり、耳は音楽を聴くのに忙しかったのかも。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[モンティ・ホール問題をGoでも実装してみた。]]></title>
            <link>https://zenn.dev/akasan/articles/25ce5919322134</link>
            <guid>https://zenn.dev/akasan/articles/25ce5919322134</guid>
            <pubDate>Tue, 20 May 2025 11:58:52 GMT</pubDate>
            <content:encoded><![CDATA[今回は、以前Pythonでモンティ・ホール問題を実装した記事を出したのですが、Goの勉強も兼ねて今回はGoでの実装を試してみました。モンティ・ホール問題って何？という方やPythonでの実装が気になる方はぜひこちらを参照ください。https://zenn.dev/akasan/articles/90b205bc9bca23 それでは早速実装していく プロジェクト初期化今回もこちらの記事のようにmiseを使ってプロジェクトを初期化していきます。https://zenn.dev/akasan/articles/7ef47bf9cd599bmise use go@1.24.3...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pod Resource動的リサイズの検証]]></title>
            <link>https://sreake.com/blog/kubernetes-pod-resource-dynamic-resize/</link>
            <guid>https://sreake.com/blog/kubernetes-pod-resource-dynamic-resize/</guid>
            <pubDate>Tue, 20 May 2025 08:38:25 GMT</pubDate>
            <content:encoded><![CDATA[Kubernetesでは、アプリケーションの可用性や運用効率を高めるため、リソース変更時のダウンタイムを極力抑える取り組みが進んでいます。従来、CPU やメモリのリソースを変更する際には、Pod の再作成やコンテナ再起動 […]The post Pod Resource動的リサイズの検証 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gonum Plotを使ってGoでプロットを作ってみる]]></title>
            <link>https://zenn.dev/akasan/articles/7ef47bf9cd599b</link>
            <guid>https://zenn.dev/akasan/articles/7ef47bf9cd599b</guid>
            <pubDate>Mon, 19 May 2025 14:25:47 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoでプロットグラフを作れるGonum Plotを使ってみようと思います。 Gonum Plotとは？Gonum Plotはcode.google.com/p/plotinumの新しい公式フォークとのことです。Goを利用してプロットのビルド・描画ができるAPIを提供しており、現時点ではまだ変動しており仕様が変更される可能性があるとのことです。詳しくは以下の公式ドキュメントを参照ください。https://pkg.go.dev/gonum.org/v1/plot#section-readme 実際に使ってみる インストールまず検証環境を作成します。今回はmiseを使っ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ブログ記事評価プロンプト (0.0-5.0)を作成しました。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/19/100659</guid>
            <pubDate>Mon, 19 May 2025 01:06:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめにある日のこと、私はブログを書いていました。ブログをレビューしたり、修正したり。そんな日々の中で、ふと思ったのです。「あれ？自分が書いたブログ記事、本当に役に立っているのかな？」と。皆さんも一度は感じたことがあるのではないでしょうか。せっかく時間をかけて書いた記事が、実は的外れだったかもしれない、という不安。「もっとこうすればよかった」という後悔。あるいは「この記事、本当に価値があるのか」という疑問。そんな思いを抱えながら、私はあることに気づきました。ブログ記事を評価する明確な基準がないということに。プログラミングにはコードレビューがあり、デザインにはクリティークがあります。でも、技術ブログには？そこで考えました。もしブログ記事を客観的に評価できるプロンプトがあれば、多少なり自分の記事をより良くするヒントになるのではないか、と。単なる「良い/悪い」ではなく、複数の観点から数値化して評価できれば、改善点が明確になります。Writing for Developers: Blogs that get read (English Edition)作者:Sarna, Piotr,Dunlop, CynthiaManningAmazon本日は、そんな「ブログ記事評価プロンプト」の作り方と使い方についてご紹介します。このプロンプトは、私が以前書いた「3年目までに身につけたい技術ブログの書き方」と「防御力の高い技術ブログを書こう」の内容をベースに、記事の質を多角的に評価できるよう設計しています。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめになぜブログ記事を評価する必要があるのかフィードバックの少なさという現実自己評価の盲点継続的な改善のために5つの評価観点とその意味防御力：批判に耐える文章の力思考整理力：混沌から秩序を生む力実践応用性：読んですぐ行動できる情報構成と読みやすさ：情報の消化しやすさコミュニケーション力：人間味のある伝え方ブログ記事評価プロンプトの使い方評価の手順自己評価として使う場合成長の記録として使う場合評価プロンプトを評価するバランスの取れた総合力読者を中心に据えた視点進化し続ける生き物としてのブログブログ記事評価プロンプト全文ブログ評価プロンプトの限界と注意点AIによる評価の限界評価基準のカスタマイズ評価を絶対視しないおわりになぜブログ記事を評価する必要があるのかフィードバックの少なさという現実技術ブログを書いていて感じるのは、直接的なフィードバックの少なさです。コードならPRレビューで指摘を受けますが、ブログはほとんどの場合、反応がないまま時間が経ちます。実際、私の経験では1000人に読まれた記事でも、コメントをくれるのはせいぜい数人。「参考になりました」と言ってくれる人がわずかにいて、大多数は何も言わず、たまに批判的なコメントが来る程度です。こういった状況では、自分の記事が本当に役立っているのか、どう改善すべきなのか判断するのが難しくなります。自己評価の盲点自分で書いた記事を自分で評価するのは、想像以上に難しいものです。「こんなにわかりやすく書いたのに、なぜ伝わらないんだろう」と思うことはありませんか？それは私たちが自分の知識や前提条件を無意識に読者にも期待してしまうからです。「これくらい知っているだろう」「これは説明不要だろう」という判断が、実は大きな誤解を生んでいることも少なくありません。継続的な改善のためにブログを書き続けるモチベーションを維持するには、自分の成長を実感することが重要です。評価基準があれば、「前回より良くなった」と客観的に感じられるようになります。数値化された評価は、「前回は実践応用性が3.2だったけど、今回は4.0に上がった！」といった具体的な進歩を認識させてくれます。これは小さな達成感を生み、次の記事への原動力になるのです。5つの評価観点とその意味ブログ記事を評価する際、単一の基準ではなく複数の視点から見ることが重要です。以下の5つの観点は、私が過去の記事で大切だと感じてきた要素を反映しています。これらをバランスよく考慮することで、より立体的に記事の質を捉えることができます。防御力：批判に耐える文章の力防御力とは、批判や反論に対してどれだけ耐性のある記事になっているかを評価する観点です。前回の「防御力の高い技術ブログを書こう」でも詳しく解説しましたが、特に重要なのは次の要素です：主観的表現と限定的な主張：「これが正しい方法だ」ではなく「私の経験では〜」と限定することコンテキストと限界の明示：「この方法はXXの環境で、YYの制約がある場合に有効です」と条件を明確にすること実体験と具体例の活用：抽象的な主張ではなく具体的な体験を共有すること根拠と出典の明示：主張の裏付けとなる情報源を示すこと誠実さの表現：自分の不確かさや知識の限界を率直に認め、「まだ完全には理解していない」「今後調査が必要」といった点を隠さないこと防御力が高い記事は「これは間違っている！」という批判を受けにくくなり、建設的な対話を生み出しやすくなります。特に誠実さを示すことで、読者は筆者を信頼し、共に学び合う関係を築けるのです。syu-m-5151.hatenablog.com思考整理力：混沌から秩序を生む力思考整理力とは、複雑な概念や情報をどれだけ論理的に整理して伝えられているかという観点です。優れた技術ブログは、単なる情報の羅列ではありません。著者の試行錯誤の過程、思考の変遷を透明に示すことで、読者は表面的な結論だけでなく、その背景にある考え方まで学ぶことができます。具体的には以下のような要素が重要です：問題提起→コンテキスト→探求の旅→発見と学び→次のステップという明確な流れ「最初は〜と考えたが、〜という課題に直面し、最終的に〜という結論に至った」という思考プロセスの共有失敗したアプローチも含めた試行錯誤の過程の可視化思考整理力が高い記事は、読者に「なるほど、こういう考え方をすればいいのか」という気づきを与えます。実践応用性：読んですぐ行動できる情報実践応用性とは、記事の情報が読者の実際の行動や実践にどれだけ役立つかという観点です。「なるほど、理解できた」と「よし、これで自分でもできる」は大きく異なります。実践応用性の高い記事は、読者が具体的な行動に移せる情報が豊富に含まれています。以前紹介した技術ブログの種類でいえば、「学習ログ」「バグハント記事」「環境構築ガイド」「学んだ教訓記事」などは特に実践応用性を重視したものです。実践応用性を高める要素としては：具体的な手順やステップバイステップの指示つまずきやすいポイントへの対応策失敗例とその解決策読者が自分の状況に応用できる情報の提供実践応用性が高い記事は、読者のお気に入りブックマークやメモに残りやすくなります。構成と読みやすさ：情報の消化しやすさ構成と読みやすさとは、記事の構造、文体、視覚的要素が読者の理解をどれだけ促進するかという観点です。いくら良い内容でも、長い文章の塊では読者は疲れてしまいます。適切な構成と視覚的な工夫は、読者の理解と集中力を大きく助けます。具体的には：冒頭の3行で読者の興味を引く導入適切な見出し階層による内容の整理短い段落(3-5行程度)、箇条書き、強調表示の効果的な使用図や視覚的要素による複雑な概念の明確化具体例と全体像の交互の提示読者に余韻と思考の広がりを残す結び構成と読みやすさが高い記事は、読者がストレスなく最後まで読み切れる記事になります。コミュニケーション力：人間味のある伝え方コミュニケーション力とは、記事が読者と共感的につながり、技術情報を人間味を持って伝えているかという観点です。技術情報は往々にして無機質で冷たい印象を与えがちですが、その背後には常に人間の試行錯誤や感情があります。それらを含めて伝えることで、読者との距離が縮まります。コミュニケーション力を高める要素としては：読み手の感情を大切にする表現個人の経験として共有する姿勢主観的な表現を心がける好きなものを中心に語るポジティブさ批判を柔らかく伝える工夫読者の立場に立った情報提供コミュニケーション力が高い記事は、読者に「この人の次の記事も読みたい」と思わせる力を持ちます。ブログ記事評価プロンプトの使い方では、実際にこのプロンプトを使って記事を評価する方法を見ていきましょう。評価の手順記事全体を通読する：まずは全体を通して読み、初期印象を得ます。各基準で評点をつける：5つの観点それぞれに0.0～5.0の範囲で評点をつけます（小数点第一位まで、例: 4.3）。具体的な所見を記述する：各基準について良い点と改善点の両方を含めた所見を記述します。総合評価を計算する：5つの観点の平均値を算出して総合評価とします。総評と改善提案をまとめる：記事全体についての総評と、優先的に改善すべき点を具体的に提案します。自己評価として使う場合自分の記事を客観的に見直すツールとしても有効です：記事を書き終えた後、少し時間を置いてから（できれば1日以上）再度読み返します。各評価基準を念頭に置きながら、自分の記事を評価します。特に低い評点がついた観点について、改善方法を考えます。成長の記録として使う場合時間をかけて記事を書き続けると、確実に上達していきます。その成長を可視化するツールとしても使えます：過去に書いた記事と最近書いた記事を同じプロンプトで評価します。各観点の点数の変化を比較し、自分がどの領域で成長したかを確認します。まだ点数が低い観点を次回の記事で意識的に改善します。評価プロンプトを評価するこのプロンプトを作成する過程で、改めて「良いブログとは何か」を考えさせられました。5つの観点から見えてくる良いブログの特徴をまとめてみましょう。syu-m-5151.hatenablog.comバランスの取れた総合力興味深いのは、5つの観点がお互いに補完し合う関係にあることです。例えば：防御力を高めるためには、コンテキストと限界を明示する必要がありますが、これは思考整理力にも関わります。実践応用性を高めるには、読者が実行しやすいよう構成と読みやすさが重要です。コミュニケーション力を高めるには、著者自身の思考整理力が前提となります。つまり、真に優れた記事とは、どれか一つの観点だけが突出しているものではなく、全ての観点でバランス良く高い評価を得られるものだと言えるでしょう。読者を中心に据えた視点5つの観点に共通するのは、常に読者の立場から考えるという姿勢です。防御力は「読者の多様な立場や状況を尊重する」こと思考整理力は「読者が著者の考えを追体験できる」こと実践応用性は「読者が実際に行動に移せる」こと構成と読みやすさは「読者の理解と集中力を助ける」ことコミュニケーション力は「読者と共感的につながる」ことこれは、良いブログが「自分のための記録」と「他者のための情報」の絶妙なバランスの上に成り立っていることを示しています。進化し続ける生き物としてのブログ評価プロンプトは「完璧な記事」を目指すためのものではなく、記事の強みと弱みを知り、継続的に改善していくための道具です。前回の記事でも書いたように、「完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しい」のです。評価の目的は完璧を目指すことではなく、80%の完成度で公開しながらも、次はもう少し良くするための指針を得ることにあります。ブログ記事評価プロンプト全文以下が、実際に使用できるブログ記事評価プロンプトの全文です。コピーして自由にお使いください。こちらでも、公開しておきます。blog_evaluation_prompt_5criteria.md · GitHub# ブログ記事評価プロンプト (0.0-5.0)あなたはブログ記事を評価する専門家です。以下の5つの観点から記事を0.0～5.0の範囲で評価し、詳細なフィードバックを提供してください。## 評価基準### 防御力 (0.0-5.0)記事が批判や反論に対してどれだけ耐性を持っているかを評価します。**5.0**: 完璧な防御力。主観的表現と限定的な主張を適切に用い、コンテキストと限界を明示し、実体験と具体例が豊富で根拠と出典が明確。批判を先取りする構成で異なる立場への配慮が行き届いている。見出しと結論が余地を残す形で表現されており、事実と解釈の違いを明確に認識している。自分の不確かさや知識の限界を誠実に認め、読者との信頼関係を構築している。**4.0**: 高い防御力。主観的表現を用い、コンテキストを示し、具体例と根拠を提示している。批判への一定の対応と異なる視点への配慮がある。自分のバイアスをある程度認識し、誠実さを示す表現が見られる。**3.0**: 標準的な防御力。部分的に主観や限界を示しているが、一部に断言的な表現や根拠不足がある。批判への対応が限定的で、特定の立場からの視点に偏る傾向がある。誠実さの表現が限られている。**2.0**: 弱い防御力。断言的な表現が多く、コンテキストや限界の明示が不足。具体例や根拠が少なく、批判への対応がほとんどない。一方的な視点で書かれ、自分の不確かさを認める表現がほとんどない。**1.0**: 非常に弱い防御力。断言と一般化が目立ち、コンテキストや根拠がほぼない。批判や異なる視点への考慮がなく、バイアスを認識していない。誠実さに欠け、権威的な印象を与える。**0.0**: 防御力がない。完全に断言的で一般化された主張のみ。コンテキスト、根拠、実例がなく、批判への対応策がまったくない。不誠実な印象を与える表現が含まれている。### 思考整理力 (0.0-5.0)記事が著者の思考プロセスを整理し、知識を構造化して伝えているかを評価します。**5.0**: 卓越した思考整理力。複雑な概念が「問題提起→コンテキスト→探求の旅→発見と学び→次のステップ」という明確な流れで整理されている。著者の試行錯誤のプロセスが透明に示され、「最初は〜と考えたが、〜という課題に直面し、最終的に〜という結論に至った」という思考の変遷が丁寧に記述されている。**4.0**: 優れた思考整理力。概念が論理的に整理され、思考プロセスの大部分が示されている。問題から解決策までの道筋が明確で、読者は著者の思考をたどることができる。**3.0**: 標準的な思考整理力。基本的な論理構造はあるが、思考プロセスの一部が省略されている。結論は示されているが、そこに至る過程の説明が不十分な箇所がある。**2.0**: 弱い思考整理力。論理の飛躍が多く、思考プロセスがほとんど示されていない。結論だけが述べられ、そこに至る思考の道筋が不明瞭。**1.0**: 非常に弱い思考整理力。断片的な考えが並べられているだけで、論理的なつながりがほとんどない。著者の思考プロセスが見えない。**0.0**: 思考整理力がない。無関係な情報の羅列に近く、何を伝えようとしているのか把握できない。### 実践応用性 (0.0-5.0)記事の情報が読者の実際の行動や実践にどれだけ役立つかを評価します。**5.0**: 非常に高い実践応用性。「学習ログ」「バグハント記事」「環境構築ガイド」「学んだ教訓記事」などの要素を含み、具体的な手順、失敗例とその解決策、つまずきやすいポイントへの対応策を提供している。読者はこの記事だけで実際に行動を起こせる十分な情報と具体的ステップを得られる。**4.0**: 高い実践応用性。具体的な例や実践的なアドバイスが豊富で、読者が自分の状況に応用できる情報が含まれている。行動のきっかけとなる要素が明確に示されている。**3.0**: 標準的な実践応用性。基本的な実践情報は提供されているが、具体例やステップバイステップの指示が限定的。読者は追加情報を探す必要がある。**2.0**: 低い実践応用性。情報は含まれているが抽象的で、実際の場面での応用方法が示されていない。「何をすべきか」は書かれているが「どうすべきか」の説明が不足。**1.0**: 非常に低い実践応用性。情報が断片的で実践に結びつけるのが困難。具体的な行動指針がほぼない。**0.0**: 実践応用性がない。読者が実際に行動に移せる情報がまったくない、または誤った実践指針が含まれている。### 構成と読みやすさ (0.0-5.0)記事の構造、文体、視覚的要素が読者の理解と共感をどれだけ促進するかを評価します。**5.0**: 卓越した構成と読みやすさ。冒頭の3行で読者の興味を引き、適切な見出し階層で内容が整理されている。短い段落(3-5行程度)、箇条書き、強調表示が効果的に使われ、長いコードブロックには適切な説明が付随している。図や視覚的要素が複雑な概念を明確化し、具体例と全体像が交互に示されている。結びは読者に余韻と思考の広がりを残している。**4.0**: 優れた構成と読みやすさ。明確な構造があり、視覚的要素も効果的に使用されている。段落が適切に分割され、重要ポイントが強調されている。読者が内容を容易に把握できる。**3.0**: 標準的な構成と読みやすさ。基本的な構造はあるが、一部に長い段落や複雑な説明がある。視覚的要素の活用が限定的で、読みやすさを向上させる工夫が不足している。**2.0**: 弱い構成と読みやすさ。構造が不明確で、長い段落や複雑な文が多い。視覚的要素がほとんどなく、読者がついていくのが困難。**1.0**: 非常に弱い構成と読みやすさ。一貫した構造がなく、文章が冗長で複雑。視覚的サポートがなく、読者は内容を理解するのに大きな労力を要する。**0.0**: 構成と読みやすさがない。無秩序な情報の羅列で、読者が内容を把握するのがほぼ不可能。### コミュニケーション力 (0.0-5.0)記事が読者と共感的につながり、技術情報を人間味を持って伝えているかを評価します。**5.0**: 優れたコミュニケーション力。読み手の感情を大切にし、個人の経験として共有し、主観的な表現を心がけている。好きなものを中心に語り、ポジティブな内容を強調し、批判を柔らかく伝える工夫がある。読者の立場に立った情報提供と、共感を呼ぶ語り口で、技術情報に人間味を加えている。**4.0**: 良好なコミュニケーション力。読者への配慮が見られ、個人的な経験や感想が適切に織り込まれている。技術情報が親しみやすい形で提示され、読者との対話を意識した書き方がされている。**3.0**: 標準的なコミュニケーション力。基本的な情報は伝わるが、読者との共感的なつながりが限定的。技術情報が淡々と伝えられ、人間味のある表現が少ない。**2.0**: 弱いコミュニケーション力。読者への配慮が不足し、一方的な情報提供に終始している。技術的には正確でも、読者の感情や状況への理解が欠けている。**1.0**: 非常に弱いコミュニケーション力。読者の存在をほとんど意識していない書き方で、共感や対話の要素がない。単なる情報の羅列に近い。**0.0**: コミュニケーション力がない。読者を無視した、または読者に対して無配慮な内容。技術情報が冷淡で機械的に提示されている。## 評価手順1. 記事全体を通読し、各評価基準における初期印象を得る2. 各基準について0.0～5.0の範囲で評点をつける（小数点第一位まで、例: 4.3）3. 各基準についての具体的な所見を述べる（良い点と改善点の両方を含める）4. 総合評価として、各基準の評点の平均値を計算する5. 記事全体についての総評と主な改善提案をまとめる## 評価レポート形式# [記事タイトル] 評価レポート## 総合評価: [平均点]/5.0### 防御力: [点数]/5.0[具体的な所見と例]### 思考整理力: [点数]/5.0[具体的な所見と例]### 実践応用性: [点数]/5.0[具体的な所見と例]### 構成と読みやすさ: [点数]/5.0[具体的な所見と例]### コミュニケーション力: [点数]/5.0[具体的な所見と例]## 総評[全体的な感想と主な強み]## 改善提案[優先的に改善すべき点とその具体的な方法]## 評価の姿勢* 批判ではなく建設的なフィードバックを心がける* 著者の経験レベルや記事の目的を考慮して評価する* 良い点を明確に指摘し、改善点は具体的な提案と共に述べる* 「防御力の高い」コミュニケーションを実践する（批判的す```ぎず、個人の経験としての意見を述べる）* 記事の「学び続ける姿勢」や「思考の過程」としての価値も評価する* 「完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しい」という謙虚さを持ち、80%の完成度でも価値があることを認識するブログ評価プロンプトの限界と注意点この評価プロンプトは便利なツールですが、もちろん限界もあります。使用する際は以下の点に注意しましょう。AIによる評価の限界AIモデルは文章を「理解」しているわけではなく、ある種の基準に基づいて評価しています。そのため：専門的な正確さを完全に判断できない場合があります記事の文化的・社会的コンテキストを十分に考慮できないこともAIの学習データによるバイアスが評価に影響する可能性があります特に技術的な正確性については、専門家によるレビューに勝るものはありません。評価基準のカスタマイズこの評価プロンプトは技術ブログを念頭に作成していますが、あなたの書く記事のタイプや目的に合わせてカスタマイズすることをお勧めします。例えば：チュートリアル記事なら「正確性」や「再現性」の観点を追加哲学的な考察記事なら「思考の深さ」や「問いの質」の観点を追加製品レビュー記事なら「公平性」や「比較の妥当性」の観点を追加評価を絶対視しないどんなに優れた評価基準でも、それはあくまで参考にすべきものであり、絶対的な判断基準ではありません。前回の記事でも触れたように、「過剰な期待が否定の感情を生み出します」。評価が低かったからといって落ち込むのではなく、「どうすれば次はもっと良くなるか」という前向きな視点で捉えることが大切です。おわりに「ブログ記事評価プロンプト」を作成してみて、改めて感じたのは、「良い記事を書く」ということの多面性です。防御力、思考整理力、実践応用性、読みやすさ、コミュニケーション力—これらや他の要素のバランスを取りながら、読者にとって価値ある情報を提供することの難しさと奥深さを実感しました。そして同時に、完璧を目指すことの罠も見えてきました。全ての観点で5.0を取るような記事を書こうとすると、おそらく公開に至る前に挫折してしまうでしょう。しかも絶対的に「良い記事」なんてものはないんですよね。誰かにとって素晴らしい記事でも、別の誰かにとっては「何言ってるかわからない」記事かもしれません。というか別に誰からも見られない記事かもしれません。大切なのは、80%の完成度で公開する勇気と、次はもう少し良くしようという向上心と予定調和からどこかはみ出そうとするバランスです。このプロンプトは完璧を求めるためのものではなく、自分の強みと弱みを知り、少しずつ成長していくための道具として使ってください。なので、修正して使ってもらって問題ないです。書き続けることこそが、最高の学びです。一つひとつの記事が完璧でなくても、書き続けることで確実に上達していきます。このプロンプトが、あなたのブログ執筆の旅の、小さくても役立つ道しるべとなれば幸いです。このプロンプトはあくまで私の考える評価基準であり、個人や会社によって必要な評価観点は当然変わってきます。技術系スタートアップならば「技術的正確性」をより重視するかもしれませんし、マーケティング部門では「読者の行動喚起力」が重要になるでしょう。個人ブログなら「自分らしさ」や「個性の表現」という観点も加えたいかもしれません。ぜひ皆さんの状況や目的に合わせて、このプロンプトを修正・拡張・カスタマイズしてください。「うちの組織では、この観点の方が重要だ」「この基準は自分の文脈では意味がない」といった具合に、それぞれのニーズに合わせた評価プロンプトに育てていってください。最後に、このプロンプトは誰でも使ってくれという気持ちで公開しています。使ってみて改善点があれば、ぜひ教えてください。あなたの視点で改良を加え、さらに良いツールに育てていただければと思います。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—それがブログの本当の姿だと私は思っています。このプロンプトが、あなたの書く喜びと成長の一助となることを願っています。余談ですが「LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発」はとても参考になる良い本だったのでオススメです。LLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発作者:John Berryman,Albert Ziegler,服部 佑樹（翻訳）,佐藤 直生（翻訳）オーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[miseを使い始めた]]></title>
            <link>https://zenn.dev/akasan/articles/2aa8031a03871c</link>
            <guid>https://zenn.dev/akasan/articles/2aa8031a03871c</guid>
            <pubDate>Sun, 18 May 2025 02:41:55 GMT</pubDate>
            <content:encoded><![CDATA[今回はmiseを使い始めたので、インストール方法など自分の備忘録を兼ねてまとめてみようと思います。 miseとは？まず、miseとは何かというと、公式GitHubから拝借するとasdfのように、nodeやPython、cmakeやterraform、その他数百もの開発ツールを管理するdirenvのように、異なったプロジェクトディレクトリに関して環境変数を管理できるmakeのように、ビルドやプロジェクトのテストのためにタスクを管理できる要は開発環境を整えるツールなんだなという認識をしてます。最近ではPythonではuvなどが利用されていますが、そのような形でツールを簡単に...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Data Engineer編~]]></title>
            <link>https://zenn.dev/akasan/articles/e2416e40a90499</link>
            <guid>https://zenn.dev/akasan/articles/e2416e40a90499</guid>
            <pubDate>Sat, 17 May 2025 06:01:17 GMT</pubDate>
            <content:encoded><![CDATA[この記事の続編になります。https://zenn.dev/akasan/articles/4d7972b7c5f84c Professional Data EngineerについてProfessional Data Engineer（以下、PDE）は、公式では以下のように説明されています。Professional Data Engineer は、データを収集、変換、公開することで、データを有効で価値のあるものにします。ビジネス要件と規制要件を満たすために、プロダクトやサービスを評価し、選択します。Professional Data Engineer は、堅牢なデータ処理シス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[React Tokyo LT大会「ストリームの実装」]]></title>
            <link>https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang</link>
            <guid>https://speakerdeck.com/shukob/react-tokyo-ltda-hui-sutorimunoshi-zhuang</guid>
            <pubDate>Sat, 17 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年5月17日React Tokyo LT大会にて、生成AIアプリケーションなどでよく使う「ストリーム実装」について話しました。https://react-tokyo.connpass.com/event/350715/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LangflowとNotion連携について　〜コンテンツ生成編〜]]></title>
            <link>https://zenn.dev/akasan/articles/9acb1ed5fa3dc0</link>
            <guid>https://zenn.dev/akasan/articles/9acb1ed5fa3dc0</guid>
            <pubDate>Fri, 16 May 2025 13:30:15 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Langflowを利用して、Notionのページ内にコンテンツを生成させる方法についてまとめてみようと思います。Langflowの使い方については以前以下の記事で解説していますので併せてご覧ください。https://zenn.dev/akasan/articles/6357f1dd2b52ac 早速使ってみる 環境の立ち上げ今回も以前と同様に、公式が提供しているdockerを利用します。簡単な起動方法は以下になります。公式GitHubのレポジトリをcloneするdocker_exampleフォルダに移動するdocker compose upを実行する...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのAI Agent関連のサービス紹介]]></title>
            <link>https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie</link>
            <guid>https://speakerdeck.com/shukob/google-cloudnoai-agentguan-lian-nosabisushao-jie</guid>
            <pubDate>Fri, 16 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://3-shake.connpass.com/event/351861/3-shake SRE Tech Talk #12 にて、Google CloudのAI Agent関連のサービス紹介を行いました・Vertex AI Agent Builder・Agent Garden・Agent Engine・Vertex AI Search・Agentspaceなど]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/15/230818</guid>
            <pubDate>Thu, 15 May 2025 14:08:18 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「新規プロジェクトに参画したら、アプリケーションがRustで書かれていた...」このような経験をされた方も多いのではないでしょうか。もしくは今後あるかもしれません。特に、オブザーバビリティの実装を担当することになったインフラエンジニアにとって、Rustは馴染みの薄い言語かもしれません。このガイドは、インフラエンジニアとしての経験は豊富だが、Rustの経験が少ないインフラエンジニアのために書かれています。既存のRustアプリケーションにログ、メトリクス、トレーシングを実装する方法を、Rustの前提知識を必要とせずに理解できるよう解説します。前提知識が不要なだけで都度学習はしてもらいます。想定読者オブザーバビリティの実装経験があるPython、Java、Goなどでの実装経験はあるRustは初めて触れる、もしくは経験が浅い既存のRustアプリケーションにオブザーバビリティを実装する必要があるこのガイドで得られることRustアプリケーションの基本的な構造の理解オブザーバビリティ実装に必要なRustの最小限の知識実装手順とコード例トラブルシューティングのポイントまず、典型的なRustのWebアプリケーションの構造を見ていきましょう。Rustの基本的な概念アトリビュート（#[...]）Rustでは#[...]という記法をアトリビュート（属性）と呼びます。これはコードに対して追加の情報や機能を付与する特別な構文です。アトリビュートを使用することで、コンパイラへの指示や機能の自動実装が可能になります。これは他の言語では以下のように表現されるものに相当します。Java: アノテーション（@SomeAnnotation）Python: デコレータ（@decorator）TypeScript: デコレータ（@decorator）参考: The Rust Reference - Attributes主なアトリビュートの例：// 自動的に特定の機能を実装する#[derive(Debug)]  // println!("{:?}", obj)でデバッグ出力を可能にする                  // 例: println!("{:?}", user); // User { id: 1, name: "John" }#[derive(Clone)]  // オブジェクトのクローン（複製）を可能にする                  // 例: let user2 = user.clone();#[derive(Serialize, Deserialize)]  // JSONとの相互変換を可能にする                  // 例: let json = serde_json::to_string(&user)?;                  // let user: User = serde_json::from_str(&json)?;// 関数やモジュールの属性を指定する#[test]  // テスト関数であることを示す         // 例: cargo testでテストとして実行される#[actix_web::main]  // actix-webのメイン関数であることを示す                    // 非同期ランタイムの設定を自動的に行うアトリビュートが実際に何をしているのかを具体例で見てみます。// #[derive(Debug)]がない場合struct User {    id: u32,    name: String,}let user = User { id: 1, name: "John".to_string() };println!("{:?}", user);  // コンパイルエラー！// #[derive(Debug)]がある場合#[derive(Debug)]struct User {    id: u32,    name: String,}let user = User { id: 1, name: "John".to_string() };println!("{:?}", user);  // User { id: 1, name: "John" } と出力されるアトリビュートを使用することで、以下のようなメリットが得られます。ボイラープレートコードの削減標準的な機能の自動実装コンパイル時の動作制御フレームワークとの統合Rust By Example - AttributesRust Derive マクロのドキュメント構造体（struct）とパターンマッチング（match）Rustの構造体は、他の言語のクラスに相当します。また、パターンマッチングは他言語のswitch文に似ていますが、より強力です。// match式の例match result {    Some(value) => println!("値が存在します: {}", value),    None => println!("値が存在しません"),}参考: The Rust Programming Language - Pattern Matchingエンドポイントの戻り値型-> impl Responderこれは「Responderトレイトをimplementsする何らかの型」を返すことを意味します。雑に言うとJavaのインターフェースやTypeScriptの型に似た概念です。参考: Actix Web - Responder traitMutexを使用したデータの共有users: Mutex<HashMap<u32, User>>Mutexは「相互排除（Mutual Exclusion）」の略で、複数のスレッドから安全にデータにアクセスするための機構です。参考: Rust Standard Library - MutexPath引数の取得id: web::Path<u32>URLのパスパラメータを型安全に取得します。例：/users/123の123部分。参考: Actix Web - Path ExtractorWebアプリケーションの簡易な実装それでは、簡易なRustのWebアプリケーションの構造を見てみましょう。// src/main.rs - 既存のWebアプリケーションuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;// Rustでは構造体の定義に#[derive(...)]という形式で機能を追加します// SerializeとDeserializeは、JSONとの相互変換を可能にします#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}// AppStateは、アプリケーション全体で共有する状態を定義します// Mutexは、複数のスレッドから安全にデータを変更するために使用しますstruct AppState {    users: Mutex<HashMap<u32, User>>,    user_counter: Mutex<u32>,}// エンドポイントの実装async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;        HttpResponse::Created().json(new_user)}async fn get_user(    state: web::Data<AppState>,    id: web::Path<u32>) -> impl Responder {    let users = state.users.lock().unwrap();        match users.get(&id.into_inner()) {        Some(user) => HttpResponse::Ok().json(user),        None => HttpResponse::NotFound().finish()    }}#[actix_web::main]async fn main() -> std::io::Result<()> {    // アプリケーションの状態を初期化    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    HttpServer::new(move || {        App::new()            .app_data(app_state.clone())            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}参考:Actix Web DocumentationSerde JSON DocumentationRust Standard Library - HashMapAPIの使用例# ヘルスチェックcurl http://localhost:8080/health# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0この基本的な実装を理解することで、次のステップであるオブザーバビリティの実装がより理解しやすくなります。Rustの重要な概念（インフラエンジニアが知っておくべきこと）依存関係の管理RustではCargo.tomlファイルで依存関係を管理しますnpmのpackage.jsonやrequirements.txtに相当します[dependencies]name = "version"  # 基本的な依存name = { version = "version", features = ["feature1", "feature2"] }  # 機能を指定モジュールとパスuseキーワードでモジュールをインポートしますmodキーワードで新しいモジュールを定義します// src/logging.rs などの新しいファイルを作成した場合mod logging;  // main.rsでこのように宣言use crate::logging::setup_logger;  // 関数を使用する際はこのように指定エラーハンドリングRustではResult<T, E>型でエラーハンドリングを行います?演算子でエラーを上位に伝播させます// エラーハンドリングの例fn function() -> Result<(), Box<dyn Error>> {    let result = something_that_might_fail()?;  // エラーが発生したら即座にReturnします    Ok(())}オブザーバビリティの実装この辺はぜひもう一度読んでほしいです。syu-m-5151.hatenablog.com依存関係の追加まず、Cargo.tomlに必要な依存関係を追加します。[dependencies]# 既存の依存関係actix-web = "4.4"serde = { version = "1.0", features = ["derive"] }serde_json = "1.0"# オブザーバビリティ関連の依存関係を追加tracing = "0.1"tracing-subscriber = { version = "0.3", features = ["env-filter"] }tracing-actix-web = "0.7"prometheus = "0.13"lazy_static = "1.4"opentelemetry = { version = "0.21", features = ["rt-tokio"] }opentelemetry-otlp = "0.14"tracing-opentelemetry = "0.22"モジュール構造の作成オブザーバビリティ関連のコードを整理するために、以下のような構造を作成します。// src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::setup_metrics;pub use tracing::setup_tracing;ログの実装今度、別でRust のロギングのライブラリの比較をしたいです⋯。moriyoshi.hatenablog.comwww.forcia.comライブラリが云々よりも実際にちゃんと設計するのも大切ですよね。qiita.com// src/observability/logging.rsuse tracing::{info, warn, error, Level};use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("{}=info", env!("CARGO_PKG_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}// ログマクロの使用例// info!("メッセージ");// error!("エラー: {}", err);メトリクスの実装// src/observability/metrics.rsuse prometheus::{Registry, Counter, IntCounter, opts};use lazy_static::lazy_static;// メトリクスの定義lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();    pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        "http_requests_total",        "Total number of HTTP requests"    ).unwrap();    pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!("user_operations_total", "Total number of user operations")            .const_label("service", "user-api")    ).unwrap();}pub fn setup_metrics() -> Result<(), Box<dyn std::error::Error>> {    // メトリクスの登録    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}// Prometheusメトリクスエンドポイント用のハンドラpub async fn metrics_handler() -> impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(&REGISTRY.gather(), &mut buffer).unwrap();        HttpResponse::Ok()        .content_type("text/plain")        .body(buffer)}トレーシングの実装気になればこちらも読んでもらいたいです。syu-m-5151.hatenablog.com// src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -> Result<(), Box<dyn std::error::Error>> {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var("OTLP_ENDPOINT")                        .unwrap_or_else(|_| "http://localhost:4317".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new("service.name", "user-api"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    // トレーシングの初期化    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}既存のエンドポイントへの統合// 修正後のcreate_user関数#[tracing::instrument(name = "create_user", skip(state, user_data))]async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    // メトリクスのインクリメント    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    // ログの出力    info!(        user_name = %user_data.name,        user_email = %user_data.email,        "Creating new user"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, "User created successfully");        HttpResponse::Created().json(new_user)}メインアプリケーションの更新#[actix_web::main]async fn main() -> std::io::Result<()> {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect("Failed to setup metrics");    setup_tracing().expect("Failed to setup tracing");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!("Starting server at http://localhost:8080");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route("/metrics", web::get().to(metrics_handler))            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}3. 動作確認アプリケーションの起動# 開発モードで実行cargo run# 本番モードで実行（最適化あり）cargo run --releaseAPIのテスト# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsログの確認# 環境変数でログレベルを設定RUST_LOG=debug cargo run4. トラブルシューティング一般的な問題と解決方法コンパイルエラー依存関係のバージョンの不一致cargo update  # 依存関係を更新ランタイムエラーOpenTelemetryエンドポイントに接続できない# エンドポイントの確認OTLP_ENDPOINT=http://localhost:4317 cargo runメトリクスが表示されないPrometheusレジストリの確認// メトリクスが正しく登録されているか確認println!("Registered metrics: {:?}", REGISTRY.gather());5. 本番環境への展開環境変数の設定# 必要な環境変数export RUST_LOG=infoexport OTLP_ENDPOINT=http://otel-collector:4317export SERVICE_NAME=user-apiDockerファイルの例FROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-app /usr/local/bin/CMD ["my-app"]6.Rustオブザーバビリティ実装の最終成果物ディレクトリ構造my-rust-api/├── Cargo.toml├── Dockerfile├── .env└── src/    ├── main.rs    └── observability/        ├── mod.rs        ├── logging.rs        ├── metrics.rs        └── tracing.rs各ファイルの実装Cargo.toml[package]name = "my-rust-api"version = "0.1.0"edition = "2021"[dependencies]actix-web = "4.4"serde = { version = "1.0", features = ["derive"] }serde_json = "1.0"tokio = { version = "1.0", features = ["full"] }tracing = "0.1"tracing-subscriber = { version = "0.3", features = ["env-filter"] }tracing-actix-web = "0.7"prometheus = "0.13"lazy_static = "1.4"opentelemetry = { version = "0.21", features = ["rt-tokio"] }opentelemetry-otlp = "0.14"tracing-opentelemetry = "0.22"src/main.rsuse actix_web::{web, App, HttpResponse, HttpServer, Responder};use serde::{Deserialize, Serialize};use std::sync::Mutex;use std::collections::HashMap;use tracing::info;mod observability;use observability::{setup_logging, setup_metrics, setup_tracing, metrics_handler};#[derive(Serialize, Deserialize, Clone)]struct User {    id: u32,    name: String,    email: String,}struct AppState {    users: Mutex<HashMap<u32, User>>,    user_counter: Mutex<u32>,}#[tracing::instrument(name = "create_user", skip(state, user_data))]async fn create_user(    state: web::Data<AppState>,    user_data: web::Json<User>) -> impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    use crate::observability::metrics::USER_OPERATIONS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    USER_OPERATIONS_TOTAL.inc();    info!(        user_name = %user_data.name,        user_email = %user_data.email,        "Creating new user"    );    let mut user_counter = state.user_counter.lock().unwrap();    let mut users = state.users.lock().unwrap();        let new_user = User {        id: *user_counter,        name: user_data.name.clone(),        email: user_data.email.clone(),    };        users.insert(*user_counter, new_user.clone());    *user_counter += 1;    info!(user_id = new_user.id, "User created successfully");    HttpResponse::Created().json(new_user)}#[tracing::instrument(name = "get_user", skip(state))]async fn get_user(    state: web::Data<AppState>,    id: web::Path<u32>) -> impl Responder {    use crate::observability::metrics::HTTP_REQUESTS_TOTAL;    HTTP_REQUESTS_TOTAL.inc();    let users = state.users.lock().unwrap();        match users.get(&id.into_inner()) {        Some(user) => {            info!(user_id = user.id, "User found");            HttpResponse::Ok().json(user)        },        None => {            info!(user_id = %id, "User not found");            HttpResponse::NotFound().finish()        }    }}#[actix_web::main]async fn main() -> std::io::Result<()> {    // オブザーバビリティの初期化    setup_logging();    setup_metrics().expect("Failed to setup metrics");    setup_tracing().expect("Failed to setup tracing");    let app_state = web::Data::new(AppState {        users: Mutex::new(HashMap::new()),        user_counter: Mutex::new(0),    });    info!("Starting server at http://localhost:8080");    HttpServer::new(move || {        App::new()            .wrap(tracing_actix_web::TracingLogger::default())            .app_data(app_state.clone())            .route("/metrics", web::get().to(metrics_handler))            .route("/users", web::post().to(create_user))            .route("/users/{id}", web::get().to(get_user))    })    .bind("127.0.0.1:8080")?    .run()    .await}src/observability/mod.rsmod logging;mod metrics;mod tracing;pub use logging::setup_logging;pub use metrics::{setup_metrics, metrics_handler};pub use tracing::setup_tracing;pub(crate) use metrics::HTTP_REQUESTS_TOTAL;pub(crate) use metrics::USER_OPERATIONS_TOTAL;4. src/observability/logging.rsuse tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};pub fn setup_logging() {    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("{}=info", env!("CARGO_PKG_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();}src/observability/metrics.rsuse actix_web::{HttpResponse, Responder};use prometheus::{Registry, IntCounter, opts};use lazy_static::lazy_static;lazy_static! {    pub static ref REGISTRY: Registry = Registry::new();        pub static ref HTTP_REQUESTS_TOTAL: IntCounter = IntCounter::new(        "http_requests_total",        "Total number of HTTP requests"    ).unwrap();        pub static ref USER_OPERATIONS_TOTAL: IntCounter = IntCounter::with_opts(        opts!("user_operations_total", "Total number of user operations")            .const_label("service", "user-api")    ).unwrap();}pub fn setup_metrics() -> Result<(), Box<dyn std::error::Error>> {    REGISTRY.register(Box::new(HTTP_REQUESTS_TOTAL.clone()))?;    REGISTRY.register(Box::new(USER_OPERATIONS_TOTAL.clone()))?;    Ok(())}pub async fn metrics_handler() -> impl Responder {    let mut buffer = vec![];    let encoder = prometheus::TextEncoder::new();    encoder.encode(&REGISTRY.gather(), &mut buffer).unwrap();        HttpResponse::Ok()        .content_type("text/plain")        .body(buffer)}src/observability/tracing.rsuse opentelemetry::sdk::Resource;use opentelemetry::KeyValue;use opentelemetry_otlp::WithExportConfig;pub fn setup_tracing() -> Result<(), Box<dyn std::error::Error>> {    let tracer = opentelemetry_otlp::new_pipeline()        .tracing()        .with_exporter(            opentelemetry_otlp::new_exporter()                .tonic()                .with_endpoint(                    std::env::var("OTLP_ENDPOINT")                        .unwrap_or_else(|_| "http://localhost:4317".to_string())                ),        )        .with_trace_config(            opentelemetry::sdk::trace::config()                .with_resource(Resource::new(vec![                    KeyValue::new("service.name", "user-api"),                ]))        )        .install_batch(opentelemetry::runtime::Tokio)?;    opentelemetry::global::set_tracer_provider(tracer);        Ok(())}.envRUST_LOG=infoOTLP_ENDPOINT=http://localhost:4317SERVICE_NAME=user-apiDockerfileFROM rust:1.70 as builderWORKDIR /usr/src/appCOPY . .RUN cargo build --releaseFROM debian:buster-slimCOPY --from=builder /usr/src/app/target/release/my-rust-api /usr/local/bin/COPY .env /usr/local/bin/WORKDIR /usr/local/binCMD ["my-rust-api"]動作確認方法アプリケーションの起動:cargo runAPIのテスト:# ユーザーの作成curl -X POST http://localhost:8080/users \  -H "Content-Type: application/json" \  -d '{"name": "John Doe", "email": "john@example.com"}'# ユーザーの取得curl http://localhost:8080/users/0# メトリクスの確認curl http://localhost:8080/metricsこの実装により、以下のオブザーバビリティ機能が利用可能になります。ログ出力：構造化ログが標準出力に出力されますメトリクス：/metricsエンドポイントでPrometheus形式のメトリクスが取得可能トレーシング：OpenTelemetryを通じて分散トレーシングが可能各機能は環境変数を通じて設定可能で、本番環境での運用に対応しています。7. 参考リンクRust公式ドキュメントActix-Web ガイドZero To Production In RustRust Web Programming - Third EditionOpenTelemetry RustPrometheus Rust Clienttracing クレートRustを使った社内用Webアプリの開発・運用を持続させるために、素材メーカーが学んだことまとめこのガイドでは、Rustの経験が浅いインフラエンジニアを対象に、既存のRustアプリケーションにオブザーバビリティを実装する方法を解説しました。アトリビュートやトレイトといったRustの基本的な概念から始め、オブザーバビリティ実装に必要な最小限の知識を説明しました。Cargoを使用した依存関係の管理方法や、モジュール構造の基本についても触れることで、Rustの開発環境への理解を深めることができたと思います。実装面では、ログ出力にtracing、メトリクスにprometheus、分散トレーシングにOpenTelemetryを採用し、それぞれを個別のモジュールとして整理された形で実装する方法を示しました。これにより、構造化ログによる効率的なログ管理や、Prometheusと互換性のあるメトリクスエンドポイント、そしてOpenTelemetryによる分散トレーシングといった実用的な機能を実現することができました。このガイドを通じて、Rustの詳細な知識がなくても、実用的なオブザーバビリティ機能を実装できることを示すことができました。Cargoのパッケージは複雑怪奇なので注意してほしいです。オブザーバビリティの実装は、アプリケーションの健全性監視と問題解決に不可欠です。このガイドが、Rustでのオブザーバビリティ実装に取り組むインフラエンジニアの一助となれば幸いです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[clickを使ってPythonのコマンドライン引数をきれいにしよう！]]></title>
            <link>https://zenn.dev/akasan/articles/034598cbd096e2</link>
            <guid>https://zenn.dev/akasan/articles/034598cbd096e2</guid>
            <pubDate>Thu, 15 May 2025 13:08:26 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Pythonできれいなコマンドラインインターフェースを実装できるclickについて紹介してみようと思います。 clickとは？clickとはPythonできれいなコマンドラインインターフェースを実装するためのライブラリです。その名前はCommand Line Interface Creation Kitの頭文字をとったようです。レポジトリは以下になります。https://github.com/pallets/clickclickはコマンドラインツールを素早く実装できることに注力しており、従来のsysやargparseを利用したものと比べて格段に実装難易度が下がっていると...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[学ぶ・つながる・挑戦する ~ 大学から始めるセキュリティの学び~/security_learning]]></title>
            <link>https://speakerdeck.com/moz_sec_/security-learning</link>
            <guid>https://speakerdeck.com/moz_sec_/security-learning</guid>
            <pubDate>Thu, 15 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年5月15日に行われたランチタイムトークで登壇した資料です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[転職したらMCPサーバーだった件]]></title>
            <link>https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian</link>
            <guid>https://speakerdeck.com/nwiizo/zhuan-zhi-sitaramcpsabadatutajian</guid>
            <pubDate>Thu, 15 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、Forkwell さんに悪ふざけに付き合ってもらってイベントやりました。ありがとうございます。「転職したらMCPサーバーだった件」 🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: 転職したらMCPサーバーだった件- 公式URL: https://forkwell.connpass.com/event/354289/- ハッシュタグ: https://x.com/search?q=%23Forkwell_MCP&f=live- 参考資料①: https://speakerdeck.com/nwiizo/kokohamcpnoye-ming-kemae- 参考資料②: https://syu-m-5151.hatenablog.com/entry/2025/03/09/020057- 参考資料③: https://speakerdeck.com/superbrothers/that-time-i-changed-jobs-as-a-kubernetes]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIエージェントのオブザーバビリティについて]]></title>
            <link>https://speakerdeck.com/yunosukey/aiezientonoobuzababiriteinituite</link>
            <guid>https://speakerdeck.com/yunosukey/aiezientonoobuzababiriteinituite</guid>
            <pubDate>Thu, 15 May 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』]]></title>
            <link>https://sreake.com/blog/introduction-long-context-llms-meet-rag/</link>
            <guid>https://sreake.com/blog/introduction-long-context-llms-meet-rag/</guid>
            <pubDate>Thu, 15 May 2025 01:01:02 GMT</pubDate>
            <content:encoded><![CDATA[RAG（Retrieval Augmented Generation）は、LLM（Large Language Model：大規模言語モデル）が知らない情報を外部から与えてあげることで、LLMの知識を拡張する手法です。R […]The post 論文紹介『長文コンテキストLLMとRAGの連携：RAGにおける長文入力の課題克服』 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Guacamoleとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/6af98c0cd8fcff</link>
            <guid>https://zenn.dev/akasan/articles/6af98c0cd8fcff</guid>
            <pubDate>Wed, 14 May 2025 10:50:43 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Guacamoleとは何かについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Guacamoleとは？公式サイトを見ると、Apache Guacamole is a clientle...]]></content:encoded>
        </item>
    </channel>
</rss>