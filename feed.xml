<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 04 Nov 2025 07:40:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[garakを用いてGeminiの脆弱性スキャンをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/f7adda4b70a138</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f7adda4b70a138</guid>
            <pubDate>Mon, 03 Nov 2025 08:31:26 GMT</pubDate>
            <content:encoded><![CDATA[今回はgarakを用いてGeminiの脆弱性スキャンをしてみました。garakは様々なLLMに対する脆弱性スキャンのための機能を提供していますが、執筆時点ではまだGeminiの対応はできていないようでした。しかし、garakにはREST API形式でLLMと接続してスキャンをする機能があり、今回はそれを利用してGeminiのスキャンをしてみました。garakについては過去に紹介していますので、合わせて以下の記事もご覧ください。https://zenn.dev/akasan/articles/34756e48c4f870なお、今回の実装をするにあたり、garakの公式ドキュメントと合わ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、部屋を掃除しろ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/11/03/020316</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/11/03/020316</guid>
            <pubDate>Sun, 02 Nov 2025 17:03:16 GMT</pubDate>
            <content:encoded><![CDATA[はじめにどれだけ技術を学んでも、どれだけ正しいプロセスを知っていても、燃え尽きてしまったら意味がない。才能ある若者たちが最初は誰よりも速く理解して、誰よりも多くのコードを書いていたのに、数ヶ月後には姿を見せなくなる。「疲れた」と言って離れていく。逆に、最初は遅くても数年経った今も黙々と学び続けている人たちがいる。彼らに共通しているのは、自分を大切に扱う習慣を持っていることだった。ちゃんと眠る。ちゃんと食べる。ちゃんと休む。そしてちゃんと掃除する。その中でも最も基本的な実践が、掃除だ。在宅勤務を始めて六年目のある朝、ふと自分の部屋を見回した。今、部屋は比較的綺麗だ。床に物は落ちていない。デスクの上も整理されている。技術書も本棚に並んでいる。窓を開けて空気を入れ替える習慣もついた。カーテンも開いていて、部屋の中は明るい。30歳のエンジニア、独身。在宅勤務という働き方は自由をくれたはずなのに、気づけば自分は4畳半の部屋の中で完結した生活を送っている。仕事もする。プログラミングもする。読書もする。ブログも書く。趣味もある。孤独は嫌いではない。むしろ好きだ。一人で考える時間、一人でコードを書く時間、一人で本を読む時間。誰にも邪魔されず、自分のペースで物事に向き合える時間。これは孤独であって、寂しさではない。寂しいと孤独は別物だ。孤独は選べるが、寂しさは選べない。でも私生活がぐちゃぐちゃになってしまうと、自分のプライベートも引きずられて悪くなる。掃除をしなくなる。自炊をしなくなる。身だしなみが雑になる。運動をしなくなる。風呂に入らなくなる。これらが崩れ始めると、部屋は散らかり、仕事も集中できなくなり、趣味も楽しめなくなり、選んだはずの孤独が、望まない寂しさに変わっていく。掃除は、精神の指標になる。部屋を見れば、今の自分の精神状態が分かる。乱れている時は心も乱れている。整っている時は心も整っている。結局、最も重要なのは燃え尽きずに続けることで、そのために必要なのは自分を大切に扱うことで、その最も基本的な実践が掃除なのではないか。この記事は、そんな仮説を自分自身で検証するために書いている。掃除とは何か。なぜ自分は掃除ができなくなるのか。そして掃除することで何が変わるのか。表面的な整理整頓の話ではなく、もっと根本的な、自分をどう扱うかという話だ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。掃除できない理由は全て言い訳だ「忙しいから掃除できない」。でも本当にそうか？毎日Twitterを見て、YouTubeのショート動画を延々と見ている。気づけば一時間、二時間が過ぎている。つまり、時間がないのではない。掃除を優先していないだけだ。「疲れているから」という言い訳もある。でも実は、散らかった部屋で過ごしていることが疲れの原因かもしれない。視界の隅に常にゴミや散らかったものが入ってきて、それが無意識のストレスになっている。朝起きたときにすでに憂鬱で、仕事を始める前からエネルギーが削がれている。だから疲れる。そして疲れているから掃除しない。この悪循環。「どうせすぐ散らかるから」という諦めもある。以前掃除したけど三日後には元通りだった。でもなぜか。綺麗にした後、何も仕組みを変えていなかったからだ。服を脱いだら床に置く習慣、ゴミが出たらデスクに置く習慣、本を読んだら床に積む習慣。掃除をしたというより、一時的に物を移動させただけだった。これらの言い訳を並べてみて気づく。どれも本質的な理由ではない。本当の理由はもっと深いところにある。「どうせ自分なんか」という、言葉にならない諦めが。部屋を整えることが心を整えるよく「部屋の乱れは心の乱れ」と言われる。でもこの言葉は因果関係が逆だ。「部屋の乱れが心を乱す」のだ。そしてもっと正確に言えば「部屋を整えることが心を整える」。心という曖昧なものを直接コントロールすることは難しい。でも部屋という物理的な空間は、手を動かせば変えられる。服をハンガーにかける。ゴミを捨てる。床を拭く。これらは全て、具体的で、実行可能で、結果が目に見える行動だ。そしてこれらの行動が、不思議なことに心に作用する。綺麗な部屋で目覚めると、一日の始まりが違う。整理されたデスクで仕事をすると、思考がクリアになる。物が少ない空間にいると、頭の中も軽くなる。部屋を整えることは、心を整えるための、最も具体的で確実な方法なのだ。掃除は自分への態度を訓練する修行だ掃除は単に「清潔にする」ための行動だと思われがちだ。でも実は、もっと深い意味を持っている。自分をどう扱うかを、身体に教えている訓練なのだ。掃除とは、「自分の空間を整える力が自分にある」と確認することだ。散らかった部屋を見て「どうせ自分には無理だ」と諦めるのではなく、一つずつ片付けていく。床に落ちている服を拾う。ゴミを捨てる。デスクを拭く。この行為を通じて「自分には変える力がある」と身体で理解する。これは掃除だけではない。自炊なら「自分のために手を動かす価値がある」と身体が覚えること。身だしなみを整えるのは「私は丁寧に扱っていい存在だ」と身体に教えること。運動することは「自分の身体に投資する価値がある」と確認すること。風呂に入ることは「私は清潔でいていい存在だ」と身体に教えること。しかし、その中でも掃除は最も基本的で、最も効果が目に見えやすい実践だ。「どうせ自分なんか」と思って放っておく時間が続くと、それらの行為がどうしても億劫に感じて、身体は「私は放っておかれて当然なんだ」と学んでしまう。逆に言えば、少しずつでも、適当でも、掃除をしていくことで、「自分は守られていい」「手をかけられていい」と身体が再び信じ始める。これは精神論ではない。実際に起きることだ。部屋を掃除した日の夜、なぜか少しだけ自己肯定感が上がる。掃除は、自分への態度を訓練する修行なのだ。放置のサイクルと手入れのサイクル放置のサイクル朝起きる。部屋が汚い。気分が重い。でも掃除する気力がない。「今日は忙しいから」と自分に言い訳をする。朝食も作らない。シャワーも浴びない。適当な服を着る。仕事を始める。集中できない。視界の隅にゴミが見える。気が散る。効率が落ちる。疲れる。夜になる。もっと疲れている。掃除なんてできない。自炊もめんどくさい。風呂に入るのもめんどくさい。運動なんてもってのほか。「明日やろう」と思う。眠る。次の日も同じ。部屋は昨日より汚い。服がもう一枚増えている。ゴミがもう一つ増えている。気分はもっと重い。でも何もする気力はもっとない。そしてまた「明日やろう」と思う。一週間後、すべてが荒れ果てている。部屋は散らかり、床はほとんど見えない。デスクは物で埋まっている。空気は淀んでいる。そして自分の気持ちも荒れ果てている。「もうどこから手をつけていいか分からない」という諦めが支配している。毎日、放置という行動を通じて、「お前は放っておかれて当然だ」というメッセージを自分自身に送り続けている。手入れのサイクル朝起きる。部屋が綺麗。気持ちがいい。窓を開ける。空気を入れ替える。ベッドを整える。たった一分の作業だが、これだけで一日の始まりが違う。シャワーを浴びる。髪を整える。清潔な服を着る。朝食を作る。簡単なものでいい。温かいご飯。身体が目覚める。仕事を始める。デスクが綺麗だから集中できる。必要なものがすぐ見つかる。思考がクリア。コードがスムーズに書ける。効率が上がる。気持ちがいい。昼休み、食器をすぐ洗う。軽く散歩する。身体を動かす。夜、仕事を終える。運動する日もある。しない日も軽くストレッチする。夕食を作る。自分のために作った温かいご飯。シャワーを浴びる。床に落ちているものを片付ける。ゴミを捨てる。読んだ本を本棚に戻す。合計十分。でもこの十分が、明日の自分を助ける。身体は学習する。「私は手をかけられる存在だ」と。「私の空間は整っていていい」と。「私は価値がある」と。行動が、その人の存在の意味を決める。言葉ではなく、行動が。毎日の小さな選択が、自分をどう扱うかを決めている。規律という美学部屋が散らかっている時の自分は、不思議なことに、あらゆる面が乱れている。時間管理も散らかる。締切ギリギリになって慌てる。生活のあらゆる面は繋がっていて、一つの領域での乱れは、他の領域にも波及する。逆に、部屋を整えている時期の自分は、あらゆる面が整っている。朝、決まった時間に起きられる。約束を守れる。締切を守れる。自分との約束も守れる。そしてこの規律が、自分という存在に秩序をもたらす。美しさとは、日々の規律ある行動から生まれる副産物なのではないか。一つ一つの動作に美を宿すこと。服を畳むときに丁寧に畳む。食器を洗うときに丁寧に洗う。掃除をするときに隅々まで拭く。これらの「めんどくさい」行為が、実は自分を美しくしている。誰も見ていない。在宅勤務だから誰にも会わない。だから適当でいい。そう思って過ごしていると、その「適当さ」が身体に染み込んでいく。でも逆に、誰も見ていなくても、自分のために丁寧に生きる。その選択が、自分を美しくする。掃除は「修行」として捉えるべき実践なのだ。小さく始めるという勇気ある日、決意した。「今日から毎日掃除をする」と。でも夜には忘れていた。三日目には諦めていた。「やっぱり自分には無理だ」と。問題は、始め方が大きすぎたことだ。「毎日掃除をする」というのは、実は途方もなく大きな変化だ。でもある時、試しに小さく始めてみた。「朝起きたら、ベッドを整える。それだけ」。これなら一分もかからない。簡単すぎる。でもこれを続けた。一週間、二週間、一ヶ月。気づけば習慣になっていた。そして不思議なことに、ベッドを整える習慣ができると、他のことも少しずつやりたくなってきた。「どうせベッドを整えるなら、カーテンも開けよう」「どうせカーテンを開けるなら、窓も開けよう」「どうせ窓を開けるなら、ゴミも捨てよう」。小さな一歩が、次の一歩を呼ぶ。完璧を求めて何もしないより、不完全でも小さく始める方が、ずっと前に進める。一日五分の掃除と、週に一回の大掃除、どちらが効果的か。前者だ。なぜなら習慣になるから。小さく始めることは、実は最も大きな勇気を必要とする。なぜなら、小さすぎて効果がないように感じるから。「たったこれだけで意味があるのか」という疑念と戦わなければならない。でも意味はある。確実にある。身体は小さな変化を記憶する。そして小さな変化の積み重ねが、大きな変化になる。おわりにこの記事を書きながら、自分の部屋を見回している。今、部屋は比較的綺麗だ。床に物はほとんど落ちていない。デスクの上も整理されている。窓を開けて空気を入れ替える習慣もついた。これらの小さな習慣が、気持ちを支えている。仕事にも集中できる。コードを書くのも、ブログを書くのも、本を読むのも楽しい。掃除は、精神の指標になる。今、部屋が比較的綺麗なのは、今の精神状態が比較的安定しているということだ。でも油断すると、すぐに乱れる。だから毎日少しずつ手をかけ続ける。才能があっても燃え尽きたら意味がない。理解が速くても続かなければ意味がない。結局、長く続けた人が、最も遠くまで行く。そして長く続けるために必要なのは、派手なスキルでも高度な知識でもなく、自分を丁寧に扱う日々の習慣だ。掃除は単なる家事ではない。自分への態度を訓練する修行であり、自分という存在をどう扱うかを身体に教える実践だ。そして何より、燃え尽きないための、最も基本的な自己防衛の手段なのだ。在宅勤務で過ごす30歳の自分にとって、掃除は生き延びるための技術になった。孤独は好きだ。一人で考える時間、一人でコードを書く時間、一人で本を読む時間。誰にも邪魔されない自由。でもその孤独を愛するためには、まず自分の空間を整える必要があった。部屋を整えることで、心を整える。空間に秩序をもたらすことで、人生に秩序をもたらす。そして集中して仕事ができる。コードが書ける。ブログが書ける。本が読める。選んだ孤独を、寂しさに侵食されずに生きられる。自分を大切にするということ。それは掃除をすること、自炊をすること、身だしなみを整えること、運動をすること、風呂に入ること。これらすべてが大切だ。でもその第一歩が、掃除なのだ。「どうせ自分なんか」という声が聞こえたら、まず床に落ちている服を一枚拾う。ゴミを一つ捨てる。デスクを一度拭く。たったそれだけでいい。その小さな行動が、「自分は手をかけられていい」というメッセージを、自分自身に送る。そして身体がそれを覚える。少しずつ、少しずつ、「自分は大切にされていい存在だ」と信じ始める。完璧を目指す必要はない。毎日完璧に掃除する必要もない。ただ、少しずつでも、適当でも、自分に手をかけ続けること。それが掃除の本質であり、同時に自分を整えることの本質であり、そして燃え尽きずに続けるための、最も確実な方法なのだ。技術は大切だ。知識も大切だ。仕事も大切だ。プログラミングも大切だ。読書も大切だ。ブログも大切だ。趣味も大切だ。孤独を愛することも大切だ。でも最も大切なのは、自分を大切にすることだ。そしてその第一歩が、自分の部屋を掃除することなのかもしれない。おい、部屋を掃除しろ。それは命令ではなく、自分自身への、静かな呼びかけだ。長く続けるために。燃え尽きないために。そして、自分を大切にするために。利他・ケア・傷の倫理学作者:近内悠太晶文社Amazonカウンセリングとは何か　変化するということ (講談社現代新書)作者:東畑開人講談社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NVIDIA Brev上でGPUインスタンスを立ち上げる方法]]></title>
            <link>https://zenn.dev/akasan/articles/686e4b3ef0b8ff</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/686e4b3ef0b8ff</guid>
            <pubDate>Sun, 02 Nov 2025 07:52:43 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIA Brev（以下、Brev）を利用してGPUインスタンスを立ち上げる方法をご紹介します。ディープラーニングモデルの開発をはじめ、様々な用途でGPUインスタンスを利用したい場合があるかと思います。そのような場合に取りうる選択肢の一つとして、Brevを利用することができ、その利用方法を紹介できればと思います。 NVIDIA Brevとは？NVIDIA Brevは、一般的なクラウドプラットフォーム上のNVIDIA GPUインスタンスへの効率的なアクセスをはじめとして自動環境セットアップ、柔軟な展開オプションを提供し、開発者がすぐに実験を開始できるようにしてくれるサービス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[garakでLLMの脆弱性スキャンをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/34756e48c4f870</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/34756e48c4f870</guid>
            <pubDate>Sat, 01 Nov 2025 07:54:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAがOSSとして提供しているgarakを用いて、LLMの脆弱性スキャンを試してみたので共有します。 garakとは？garakは生成AIに対するレッドチーミングおよびアセスメントのためのツールです。garakを利用すると、LLMが望ましくない方法で失敗させられるかどうかを検証し、ハルシネーションを初めジェイルブレイクなど多くの脆弱性を探知することができます。garakのドキュメントを確認すると、以下の特徴があるとのことです。LLMセキュリティへのフォーカス：主にLLMセキュリティに焦点を当ててており、他のツールが一般的な機械学習セキュリティやアプリセキュリティ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[言葉にしない限り、『なんか』は永遠に巨大な壁であり続ける]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/11/01/120027</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/11/01/120027</guid>
            <pubDate>Sat, 01 Nov 2025 03:00:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめにワークショップが始まる三十分前、会場の隅で、一人の若者がノートPCの画面を凝視していた。ブラウザには二十を超えるタブが開かれている。Dockerの公式ドキュメント、Kubernetesの公式リファレンス、Qiita、Zenn、個人ブログ。静かな会場に響くのは、マウスホイールを回す音だけで、彼は次から次へとタブを切り替えながら、何かを探すように、あるいは何かから逃げるように、ドキュメントを読み続けていた。読んでいた、という言葉はきっと正確ではなくて、目で文字を追っているだけで、その言葉が本当に頭の中に入っているかどうかは、おそらく彼自身にも分からなかったのだろうし、分からないことに気づかないふりをしていたのかもしれないし、あるいは気づいていたけれど認めたくなかったのかもしれない。「準備しておかないと」ぽつりと呟いた声は、誰に向けられたものでもなかった。会場には他にも何人か早めに来ている参加者がいたけれど、彼らに向けた言葉でもなく、講師である僕に向けた言葉でもなく、けれど僕には分かった、あの言葉は自分自身への言い訳で、読み続けている限り「まだ始めていない」という事実から目を逸らせて、手元にあるyamlファイルを開くことも、Dockerfileを書き始めることもなく、ただスクロールを繰り返していれば、準備という名の猶予期間はどこまでも続いていくような気がして、その錯覚こそが彼を動けなくしているのだと、その姿を見ながら僕は思った。彼は、昔の僕だ。気づけば開始時刻になっていた。けれど彼の画面に立ち上がったコンテナは一つもなくて、代わりにあったのは無数に開かれたタブと、そして不思議なことに「今日は勉強した」という、根拠はどこにもないのにどこか心地よい、温かくて柔らかい達成感だけだった。手は動かしていないのに、頭は働かせた気がして、何も作っていないのに、何かを学んだ気がして、この感覚はとても甘くて危険で、僕も何度もこの甘い罠に捕まってきたから分かる。僕も石橋を叩いて渡るタイプで、新しい技術を学ぶときはまず本を買って安心する。「準備してから」「もう少し理解してから」「完璧になってから」、その言葉は、とても合理的に聞こえる、誰も反論できない、自分自身も反論できない、だから安心してその言葉に逃げ込むことができる。でも、ある時気づいてしまった。「まだ準備が足りない」と思って読み続けるうちに、何時間も、何日も経っていて、僕は実際には何一つ手を動かしていなかったことに。本当は、もっと早く気づいていたのかもしれない。けれど気づかないふりをして、気づきたくなくて、「準備」という名の停滞を「努力」だと自分に言い聞かせていた。「明日からやろう」という言葉の背後で何が起きているのか、本人は意外と気づいていない。いや、もしかしたら気づいているのかもしれないけれど、気づかないふりをしているのかもしれないし、気づいていることに気づかないふりをしているのかもしれない。このポストは動けない人の構造を解剖し、そこから抜け出すための実践について書いたもので、三年間ワークショップで自分や多くの若手エンジニアと向き合う中で見えてきたことがある。動けない理由は一見バラバラに見える、けれどこれらの言葉を一つ一つ丁寧に剥いでいくと、驚くほど似た構造が現れる。恥への恐怖、完璧主義、そして「才能がない」という誰も反論できない便利な逃げ道。面白いことに、これらの根底には共通するものがあって、それは「なんとなく不安」「どうも気が進まない」「なんか怖い」という、この「なんか」という輪郭を持たない曖昧な言葉で、僕らはこの「なんか」という便利な言葉の中に、言葉にしたくない、言葉にするのが怖い、言葉にしてしまったら向き合わなければならなくなる、そういう感情を全部押し込めて蓋をしている。この「なんか」を言葉にしない限り、恐怖は形を持たない。形を持たない恐怖は霧のように僕らの思考を覆って、じわじわと、気づかないうちに、判断力を奪い続ける。ここで一つ断っておきたいのは、僕の「なんか」とあなたの「なんか」は、きっと少し違うということで、僕が恐れているものとあなたが恐れているものは同じではないかもしれないし、僕が「恥」だと感じるものとあなたが「恥」だと感じるものは、同じ言葉を使っていても中身は違うのかもしれない。けれど、それでも共通しているのは、その「なんか」を言葉にしないまま放置していることで、言葉にしない限り、それが何であれ、形を持たないまま僕らの中で勝手に膨らんでいくということだ。だから本人も周りもなかなか気づかないまま、「準備している」「慎重なだけ」「向いていないのかも」という、どこか優しげに聞こえて、誰も否定できない言葉の裏側で、実は何ヶ月も何年も同じ場所に立ち止まっていて、立ち止まっていることにすら気づかないまま時間だけが過ぎていく。さらに現代という時代が、この自己欺瞞を加速させている。生成AIに聞けばそれっぽい答えがすぐ返ってきて「理解した気」になれるし、スマホを開けば無限に刺激があって「ちょっと休憩」が気づけば一時間になる。立ち止まっている自分を見て見ぬふりをするための道具が、これほど揃っている時代はない。けれど同時に、この構造を理解すれば抜け出す方法も見えてくる。言語化すること、小さく始めること、遊ぶこと、不完全でも動くこと。これらは全て才能ではなく訓練可能な技術で、動けない理由を言語化できれば、動くための方法も見えてくる。「なんか不安」と思ったとき、立ち止まって「何が不安なのか」と問いかけるようになった。その答えを、怖くても、恥ずかしくても、認めたくなくても、言葉にするようになった。そうすると不思議なことに動けるようになって、言葉にしてしまえば思ったより大したことなかったりして、「こんなことで止まっていたのか」と拍子抜けするほどで、でも、言葉にしない限り、その「こんなこと」は永遠に巨大な壁であり続ける。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。三つの声いろんな彼というか昔の僕から動けない理由を聞くと、大きく三つのパターンに分かれる。正確には、休憩時間や終了後に雑談をしていて「今日はどうだった？」と聞くと、こんな答えが返ってくる。「失敗したくない」という声がある。ワークショップである学生が「エラーが出たら、どうしていいか分からなくなるんです」と言った。その時は「エラーメッセージを読むといいよ」とアドバイスして終わったのだが、後になって考えた。彼が本当に恐れていたのはエラーそのものだったのだろうか。よく思い返してみると、彼は他の参加者を横目で見ていて「みんな進んでる」とも言っていた。つまり、エラーが出たときにそれを解決できない自分が露呈するのが怖かったのではないか。「このエラーの意味が分からない」「基礎的な知識が足りない」と認めることは、自分の無知を他者に見せることになる。他の参加者は解決できているかもしれないし、講師は当然知っている。その中で自分だけが分からない。失敗への恐怖は、実は無知の露呈への恐怖なのかもしれない。エラーそのものは怖くないが、エラーを通じて自分の能力の限界が可視化されることが怖い。だからエラーが出る前に完璧に準備しようとしてドキュメントを読み漁るが、どれだけ読んでも「完璧」には到達しない。そして永遠に始められない。「もっと良い方法があるはず」という声もある。別の学生は「このやり方で合っているのか分からなくて」と言った。その時の彼の画面を覗き込むと、Dockerfileが半分書きかけのまま止まっていた。「どうしたの？」と聞くと「ベストプラクティスを調べてて」と言い、ブラウザには10個以上のタブが開いていた。終わった後、もう少し話を聞いてみた。「何が一番困った？」「うーん、正解が分からなくて」。その「正解」という言葉が引っかかった。プログラミングに唯一の正解なんてあるだろうか。後で考えてみると、彼が求めていたのは「正解」ではなく「間違っていないという保証」だったのかもしれない。Dockerfileを書き始めて一行書いては止まり、「これは本当にベストプラクティスなのか」とブラウザに戻って「Docker ベストプラクティス」で検索する。いくつかの記事を読むと別のやり方が紹介されていて「どっちが正しいんだろう」とまた別の記事を読み、さらに別のやり方を見つける。最適解を求めるほど選択肢は増え、決断は遠のく。でもよく考えてみると、おかしなことを言っている。「最適解」は実際にやってみないと分からず、プロジェクトの要件やチームの習熟度、運用の制約といった文脈によって「最適」は変わる。にもかかわらず文脈なしで「最適解」を求めている。これは実は決断を先延ばしにするための言い訳なのかもしれない。なぜ決断を先延ばしにするのか。おそらく決断には責任が伴うからだ。「これで行く」と決めた瞬間、それが間違っていたときの責任を負うことになる。でも「まだ調べている」段階なら責任は発生せず、間違える可能性もなく、評価されることもない。完璧主義は行動の質の問題ではなく、存在の先延ばしの問題なのかもしれない。「周りの目が気になって」という声は、終わった後の雑談で最も正直に語られた。「質問すると『こんなことも知らないのか』と思われそうで」という学生は、ワークショップ中に何度もつまずいていて画面を見れば分かるのだが、質問もせず隣の人に聞くこともせずに、ただ黙って画面を見つめていた。「どうして質問しなかったの？」と聞くと、「みんな分かってそうな雰囲気で、自分だけ分かってないって思われたくなくて」と言った。でも実際には、後で他の参加者に聞いてみると同じところでつまずいていた人が何人もいたのだが、誰も質問しなかった。みんな同じことを思っていた。恥という感情の不思議なところは、実際の他者の反応ではなく想像上の他者の視線に縛られることだ。「こう思われるかもしれない」という想像がその行動を止めるが、その想像が現実と一致しているかは確かめられない。なぜなら行動していないから。三つの声の正体失敗したくない、もっと良い方法があるはず、周りの目が気になる。学生たちから聞いたこれらの言葉を一人になってから反芻していた。一見バラバラに見えるこれらの理由だが、丁寧に分解していくと共通した構造が見えてくる気がした。すべて恥への恐怖に行き着くのではないか。「失敗したくない」は無知を露呈したくない、つまり恥をかきたくないということであり、「もっと良い方法があるはず」は間違った選択の責任を負いたくない、つまりこれも恥の回避だ。「周りの目が気になる」はそのものズバリ、他者の視線という恥の源泉である。そしてさらに抽象化すると、三つの根源的な恐怖に還元される気がした。恥をかきたくない、損をしたくない、嫌われたくない。でも面白いことに、これらを具体的に言葉にした瞬間、その恐怖は不思議なほど小さく見える。「エラーメッセージの意味が分からないのが怖い」と言葉にすればそれは解決可能な課題になるし、「ベストプラクティスを知らないのが不安」と認めれば「じゃあまず動くものを作って後で改善しよう」という選択肢が見える。「質問して笑われるのが怖い」と明確にすれば、「実際に笑う人がいるのか？ いたとしてその人の評価を気にする必要があるのか？」と問い直せる。具体的に言葉にした瞬間、恐怖は相対化される。でも多くの人はこの言語化の一歩手前で止まっている。いくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon「なんか」の正体「なんとなく不安で」「どうも気が進まなくて」「なんか怖くて」。この「なんか」という言葉が問題だ。「なんか」で済ませている限り恐怖は輪郭を持たない。輪郭を持たない恐怖は無限の可能性として脅威を放ち続け、それは霧のように思考空間を覆って判断力を奪う。逆に言えば、恐怖を明瞭に言語化すればそれは相対化可能な「ひとつの感情」へと縮小する。言葉は混沌に秩序を与える。でも、なぜ人は言語化を避けるのか。試しに自分が動けない理由を紙に書き出してみるといい。「なぜこのタスクに取り掛かれないのか」を具体的に書き始めると手が止まる。なぜか。言語化とは「嫌な自分」と正面から向き合う行為だから。曖昧なままなら自己欺瞞の余地が残り、「本気出せばできる」「時間がないだけ」「環境が悪いだけ」とそう思い込んでいられる。でも一度言葉にしてしまえばもはや逃げ場はない。「基礎的なことを理解していない」と書けばそれは事実として目の前に現れ、「エラーメッセージを読み飛ばしている」と認めればその怠慢は言い逃れできなくなり、「質問する勇気がない」と言葉にすれば自分の臆病さと向き合わざるを得ない。だから人は言語化を避ける。でもこの回避こそが停滞を生み出す。言葉にできない感情は実体以上に巨大化し、漠然とした不安のまま放置すればそれはどんどん大きくなっていく。「なんとなく怖い」が「とても怖い」になり「絶対に無理」になる。未言語化の不安は輪郭を持たないがゆえに肥大化し、行動を麻痺させる。このポストは動けない人の構造を解剖しそこから抜け出すための実践について書いたものだ。抽象的な話に聞こえるかもしれないが、これは極めて実践的な話だ。なぜなら動けない理由を言語化できれば動くための方法も見えてくるからだ。ワークショップでドキュメントを読み漁る若者を見ながら、自分もかつてそうだったことを思い出す。そして今も新しい技術に触れるとき同じパターンに陥りそうになる。でも一つだけ変わったことがある。「なんか不安」と思ったとき立ち止まって「何が不安なのか」と問いかけるようになった。その答えを言葉にするようになった。そうすると不思議なことに動けるようになる。「なんか」の正体を一緒に言葉にしてみよう。人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazonなぜこんなに変わりたいのに行動ができないのか動けない理由を剥いていくとワークショップの後、参加者たちと話していて気づいたことがある。動けない理由は人それぞれ違う言葉で語られるが、その言葉を一つ一つ剥いでいくと意外なほど似た構造が現れる。「失敗したくない」と言った学生に「何が失敗なの？」と聞いてみた。「エラーが出ることです」。「エラーが出ると何が困るの？」「解決できないからです」。「解決できないと何が困るの？」と重ねて聞くと、彼は少し黙って小さな声で言った。「他の人にできないやつだと思われるのが嫌なんです」。ああそうか。エラーが怖いのではなかった。自分で認めるのも嫌だけど、エラーを解決できない自分が他者に見られることが怖かったのだ。「もっと良い方法があるはず」と言った学生には「今のやり方の何が問題なの？」と聞いた。「うーん、間違ってるかもしれないから」。「間違ってると何が困るの？」「後で直すのが大変だから」。「本当にそれだけ？」と聞くと、彼も少し考えてこう言った。「間違ったやり方を選んだって知られたくないです」。ここでも他者の視線が出てきた。試しに動けない理由を「○○が怖い」という形に言い換えてみると、面白いことにだいたい三つに集約される。恥をかくのが怖い、損をするのが怖い、嫌われるのが怖い。これらを観察しているとある構造に気づく。すべての中心に「他者の視線」がある。恥は他者がいて初めて成立し、損も他者との比較で生まれ、嫌われるもそのものズバリ他者との関係だ。動けない理由を突き詰めていくと、思考の主語が「自分」ではなく「他人」になっている。恥という不思議な感情恥を恐れて動けないとき自分の思考を観察してみるといい。面白いことに気づく。思考の主語が「他人」になっている。「自分がどうしたいか」ではなく「他人にどう見られるか」、「これは面白いか」ではなく「これは評価されるか」と、判断基準の中心にいつの間にか他者の視線が居座っている。ワークショップでこんなことがあった。ある学生が自分で考えた実装方法を試そうとしていたが、途中で手を止めて「これ間違ってるかもしれない」と言ってブラウザでベストプラクティスを検索し始めた。「さっきの方法試してみたら？」と声をかけると、「でももし間違ってたら恥ずかしいです」と言った。誰に対して？よく考えてみるとおかしな話だ。ワークショップは学ぶ場所で間違えるために来ているのに、彼は間違えることを恥だと感じていた。恥という感情は本質的に社会的なものだ。一人で山に籠もって生きているなら恥という感情は存在せず、恥は他者の視線があって初めて成立する。だから恥を避けようとすればするほど自分の判断基準は外部に移っていく。「自分はこれを試してみたい」ではなく「これは他者に評価されるか」、「自分はこれが面白い」ではなく「これは正しいと思われるか」となる。これは「外部評価への依存」というきわめて脆弱な存在様式だ。なぜ脆弱なのか。他者の評価はコントロールできないからだ。どれだけ頑張っても他者がどう評価するかは分からず、評価を気にすればするほどその不確実性に振り回される。さらに皮肉なことに恥を避けようとしてもっと深刻な状態に陥る。「失敗」という一時的な出来事を避けようとして「停滞」という持続的な状態に陥る。一瞬の恥を避けるために何ヶ月も何年も同じ場所に立ち止まる。でもこの事実に気づくのはいつも後になってからだ。停滞している最中は自分が停滞していることにすら気づかず、「準備している」「勉強している」「タイミングを見計らっている」とそう言い聞かせながら過ごす。恥を避けることに内的エネルギーを費やすほど自己の内側は空洞化していく。他者の評価を内面化し自分で自分を監視する。自己評価の基準が外部にあるときそこにはもう自己は存在しない。「完璧」という呪い「完璧に準備してから始める」という言葉は合理的に聞こえるが、ワークショップでこの言葉を聞くたびある疑問が浮かぶ。「完璧」って何だろう。ある学生はワークショップ開始前に2時間ドキュメントを読んでいて「準備したい」と言っていたが、実際にコンテナを立ち上げることはなかった。「どこまで準備したら始められそう？」と聞くと「全部理解してから」と言った。全部。でも「全部」って何だろう。Dockerの全ての機能を理解する？ Kubernetesの全てのコンポーネントを理解する？ そんなことは実務で何年も使っているエンジニアでも無理だ。つまり「完璧に準備してから始める」は実質的に「決して始めない」と同義だ。よく考えてみるとおかしなことを言っている。完璧に準備するとは何か。すべてを理解してから始めるということだが、すべてを理解するには実際にやってみるしかなく、やってみないと分からないことは必ずある。ドキュメントに「Podは一つ以上のコンテナを含む」と書いてあれば読めば理解できるが、実際にyamlを書いてkubectl applyしてエラーが出てそのエラーメッセージと格闘して、初めて本当に理解できる。理論的な理解と体験的な理解は違う。「完璧に準備してから」と言う人は実は理論的な理解だけで完璧になれると思っているが、それは不可能だ。体験なしに理解は完成しない。では、なぜ人は「完璧に準備してから」と言うのか。これは行動の質の問題ではなく存在の先延ばしの問題だ。不完全な自分を世界に晒すことへの恐怖、評価されることへの恐怖、そしてその根底にはやはり恥がある。完璧主義は恥への防衛機制として機能し、「準備不足だから失敗した」という言い訳をあらかじめ用意しておく。決して完成しないものは決して評価されず、評価されなければ恥もかかない。求めるほど遠のくという逆説がここにある。完璧を求めるから行動できず、行動しないから経験が積めず、経験がないから完璧からは遠のき、そしてさらに完璧を求める。この悪循環。ワークショップである学生が最後に「結局何も完成しませんでした」と言った。でも彼は多くのことを学んだはずだ。エラーメッセージの読み方、yamlの書き方、kubectlのコマンド。不完全でも多くのことを試した。「完成しなかったけど学んだことはたくさんあったんじゃない？」と言うと少し考えて「そうですね。でも完成させたかったです」と言った。完璧主義者が見落としているのは小さな一歩の価値だ。不完全でも動いた一歩と完璧を求めて動かなかったゼロ。どちらが自分を前に進めるか。答えは明白なのになぜか後者を選んでしまう。不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon言葉にできない不安の正体「なんとなく不安で」「どうも気が進まなくて」「なんか怖くて」という言葉を休憩時間によく聞く。「どうして手を動かさないの？」と聞くと「なんとなく」と返ってくる。この「なんか」「なんとなく」という言葉が実は重要な意味を持っている。試しに「なんとなく不安」と言った学生に「何が不安なの？」と聞いてみた。「うーん、なんか」。「例えば？」「分からないです」。言葉にできない。でもこれは語彙力の問題ではなく言語化を避けているという選択の問題だ。なぜそう思うか。別の機会に同じ学生にもう一度少し角度を変えて聞いてみた。「もし今コンテナを立ち上げようとしたら何が起きると思う？」すると意外なほど具体的な答えが返ってきた。「エラーが出ると思います。そのエラーの意味が分からなくてどうしていいか分からなくなって時間ばかりかかって結局できなくて周りの人に遅れて」。ああ言葉にできるじゃないか。彼は自分の不安を言語化できないのではなく、言語化したくなかっただけだ。なぜか。言葉にできない感情は実体以上に巨大化する。「なんとなく不安」のままならその不安の正体は確定しないが、「エラーの意味が分からないのが怖い」と言葉にした瞬間それは具体的な課題になってしまい、具体的な課題になればそれに対処しなければならなくなる。言語化とは「嫌な自分」と正面から向き合う行為だから。「エラーメッセージの意味が分からない」と認めることは自分の知識不足を認めることであり、「基礎が理解できていない」と言葉にすることは自分の勉強不足を認めることであり、「質問する勇気がない」と明確にすることは自分の臆病さを認めることだ。曖昧なままなら自己欺瞞の余地が残り、「本気出せばできる」「時間がないだけ」「環境が悪いだけ」とそう思い込んでいられるが、一度言葉にしてしまえばもはや逃げ場はない。だから人は言語化を避ける。でもこの回避こそが停滞を生み出す。輪郭を持たない恐怖は無限の可能性として脅威を放ち続ける。それは霧のように思考空間を覆って判断力を奪い、「なんとなく怖い」が「とても怖い」になり「絶対に無理」になる。未言語化の不安は輪郭を持たないがゆえに肥大化し行動を麻痺させる。逆に言えば恐怖を明瞭に言語化すればそれは相対化可能な「ひとつの感情」へと縮小する。「エラーメッセージの意味が分からないのが怖い」と言葉にした瞬間それは解決可能な具体的課題になる。言葉は混沌に秩序を与える。言葉を持つことは自由を獲得することに等しい。言語化は自己認識の解像度を上げる行為であり、内面の混沌を構造化し恐怖を名指すことで相対化する力。それが言語化の力だ。「無理」の構造 ―この世の理不尽さを可視化する作者:細谷 功dZEROAmazon「才能」という最も便利な逃げ道そして最後にすべてを覆い隠す魔法の言葉がある。「才能がない」。ワークショップの最後ある学生が「自分には向いていないかもしれません」と言った。「どうしてそう思うの？」と聞くと「他の人より理解が遅いから」と言った。でも観察していて気づいたことがある。彼は理解が遅いのではなく理解しようとしていなかったのだ。エラーメッセージが出てもちゃんと読んでいなかった。「Expected type X, but got type Y」と明確に書いてあるのに「type X」という文字列だけを拾って、期待される型と実際の型が違うという関係性を読み取っていなかった。ドキュメントを「読んでいる」と言いながら実際には流し読みしていて、主語と述語を把握せず「誰が」「誰に」「何を」しているのかという基本的な構造を理解しないまま「なんとなく」で進めようとしていた。仮説を一つずつ潰すのではなく「ネットワークの問題かもしれない」「データベースの問題かもしれない」と複数の仮説を同時に追いかけてどれも中途半端に確認していた。これは才能の問題ではなくプロセスの問題だ。エラーメッセージをちゃんと読む、仮説を一つずつ潰す、主語と述語を把握する。誰でもできることだ。でもこの「小さなこと」を飛ばしているから「理解が遅い」ように見える。そしてこの事実から目を逸らすために「才能」という言葉を使う。「才能がない」という言葉は根深い自己欺瞞であり最も便利な逃避だ。なぜなら才能という言葉を使った瞬間、人は変化の可能性を放棄できるからだ。「才能がないからできない」は「努力してもどうせ無理」と同義で、成長のための努力そのものが無意味に思える。そして才能という言葉はすべてを覆い隠す。恥への恐怖を覆い隠し完璧主義を正当化し言語化を避ける。基礎プロセスを飛ばしていることも努力を怠っていることもすべて「才能」という一言で片付けられる。才能という言葉を使った瞬間思考は停止する。でも観察していると分かる。「才能がある」ように見える人も実は同じプロセスを踏んでいる。エラーメッセージをちゃんと読み仮説を一つずつ潰し主語と述語を把握している。ただそれだけだ。違いはそのプロセスを意識的に実践しているかどうかであり、それは訓練可能だ。前のポストで書いたように技術力は経験の蓄積とセンスから成り立ち、そしてどちらも訓練可能だ。センスとは突き詰めれば「何に注目するか」という習慣と「それを面白がれるか」という姿勢だ。でも「才能」という言葉を使えばこうした具体的な分析も具体的な対策もすべて放棄できる。恥への恐怖、完璧主義、言語化の欠如。そのすべてを「才能」という一言で説明する。これが動けない人が抱える最後の砦だ。HIDDEN POTENTIAL 可能性の科学――あなたの限界は、まだ先にある (三笠書房　電子書籍)作者:アダム・グラント三笠書房Amazon動くための小さな一歩言葉にしてみるという勇気まず自分の恐怖を具体的に正直に言語化してみる。ワークショップの終わりにこんな提案をしてみた。「今日動けなかった理由を紙に書いてみて」。最初は戸惑った顔をしていた参加者たちだが何人かが書き始めた。ある学生が書いたのは「エラーが出たときに解決方法が分からなくて周りに遅れるのが嫌だった」という文章だった。書き終わって彼はその紙をじっと見ていて「あれこんなことだったのか」と言った。言葉にした瞬間不思議なことが起きる。恐怖が相対化され「ああこんなことで止まっていたのか」という気づきから「じゃあどうすればいいか」という具体的な対策が見えてくる。「エラーが出たときに解決方法が分からない」なら「じゃあエラーメッセージの読み方を学ぼう」となり、「周りに遅れるのが嫌」なら「でもこれは学ぶ場所だ。遅れても構わない」となる。抽象的な不安は具体的な課題へと変換され、具体的な課題は具体的な対策で解決できる。「恥をかきたくない」だけではまだ抽象的だ。もう一歩踏み込んで「このコードをレビューに出したら基礎的な部分の知識不足を指摘されるのが怖い」とここまで具体的にする。すると「じゃあ基礎的な部分を先に学べばいい」という対策が見え、「レビュー前に自分でチェックリストを作ればいい」という方法が浮かび、「そもそも指摘されることは学びのチャンスだ」という視点が得られる。言語化は勇気の技術であり嫌な自分と向き合う技術だが、その一歩がすべてを変える。さみしい夜にはペンを持て作者:古賀史健ポプラ社Amazon現代人が失ったものただ言語化を阻むものは個人の内側だけにあるわけではなく、現代という時代そのものが言語化を難しくしている。ワークショップの休憩時間、参加者たちの多くがスマホを見てTwitterやInstagramをスクロールしLINEに返信しYouTubeのショート動画を見る。私たちは今インスタントで断片的な刺激に取り巻かれている。即座の返信、短い動画、分かりやすい解説とスマホを持つことで即時的な満足にいつでもアクセスでき、「消化しきれなさ」「難しさ」「モヤモヤ」といった時間もコストもかかるものは避けられるようになった。技術ドキュメントを読むことはまさにこの「モヤモヤ」との戦いだ。Kubernetesの公式ドキュメントを開いても一読してすぐに理解できるものではなく、分からない用語が出てきてそれを調べるとさらに分からない概念が出てくる。読み返し実際に試しエラーが出てまた読み返す。この時間のかかるプロセスがインスタント化した感覚に慣れた私たちには耐えがたい。だからすぐに生成AIに「KubernetesのServiceとは何ですか？要約して」と聞く。確かに分かりやすい説明が返ってきてスッキリする。でもその過程で失われるものがある。モヤモヤした状態を抱えたまま読み続け試し続けることでしか到達できない深い理解。断片的な知識ではなく体系的な理解。これは要約では得られない。ある学生がワークショップで「生成AIで調べたんですけど実際にやってみるとうまくいかなくて」と言った。よく見ると生成AIの説明を鵜呑みにしてその背後にある前提条件を理解していなかった。「この設定はこういう環境を前提としています」という部分を読み飛ばしていた。生成AIは便利なツールだが使い方を間違えると理解の機会を奪う。同時にスマホによる常時接続は孤独を奪った。ワークショップ中少し難しい課題に取り組んでいるときすぐにスマホに手が伸びて「ちょっと休憩」と言ってTwitterを開く。退屈に耐えきれず何か刺激を求めてスマホをいじる。一人でドキュメントと向き合う時間一つのことに没頭する孤立。このシンプルな行為が驚くほど難しくなっている。でも言語化には孤独が必要で、自分の内側と向き合うには外部の刺激から離れる必要がある。そしてもう一つ、ネガティブ・ケイパビリティの欠如だ。これは「結論づけずモヤモヤした状態で留めておく能力」のことで、把握しきれない謎をそのまま抱えておく力だ。新しい技術を学ぶときすぐに「わかった」と思いたくなるが実際にはわかっていないことだらけで、この不確実性に耐える力が現代人には欠けている。ワークショップでこんなことを言う学生がいた。「全部理解してから次に進みたいんです」。でも「全部理解する」なんて不可能だ。理解は何度も行ったり来たりしながら螺旋を描くように深まっていく。最初は30%の理解、実際に使ってみて50%、エラーと格闘して70%、また別の文脈で使って80%。理解は一度で完成しない。でもこのモヤモヤした状態に耐えられずすぐに「分かった」と結論づけたいために生成AIに「簡潔に説明して」と頼む。簡潔な説明は確かに分かりやすいが、その分かりやすさは複雑さを削ぎ落とした結果で、削ぎ落とされた部分にこそ本質が隠れていることもある。学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon生成AIという新たな逃避ChatGPTやClaudeの登場は学習の風景を変えそして新しい逃避の道を開いた。停滞のパターンはこうだ。エラーが出て生成AIに「このエラーどう直す？」と聞き答えが返ってコピペして動いて「解決！」となる。これは答えは得られるが理解は得られず、次に同じエラーに遭遇したときまた同じことを繰り返す。ワークショップで何度も同じパターンを見た。学生がエラーに遭遇してすぐに生成AIに聞き答えをコピペし次のエラーでまた聞きまたコピペする。三回目に同じようなエラーが出たとき彼は気づいていなくて「あれさっきも似たようなエラーが出たな」という記憶がない。なぜか。自分で考えていないからだ。エラーメッセージを読んでいない。なぜそのエラーが出たのか理解しようとしていない。答えは得られるが学びは得られない。混乱したときすぐに生成AIに頼ると不快感と向き合う機会が失われる。でもこの不快感こそが深い理解への道なのに。成長のパターンはこうだ。まず自分で理解しようとしてエラーメッセージを読みドキュメントを読み仮説を立てて試す。それでも分からなかったら自分なりの理解をまとめる。その上で生成AIに「私はこう理解したが合ってる？」と質問する。先に自分で考えて生成AIは「答えを教える」のではなく「理解を確認する」役割にする。あるいは「このエラーが出た。なぜこのエラーが出るのか仕組みから説明して。直し方は教えなくていい」と聞いて表面的な解決策ではなく根本的な理解を得る。ワークショップでこの方法を試した学生がいた。最初は時間がかかったが、三回目に似たようなエラーが出たとき彼は自分で解決できて「ああこれはあの時と同じパターンだ」と言った。理解があれば応用が効く。生成AIとの付き合い方には四つの落とし穴がある。一つ目は思考の外部化で考えるべきことを全て生成AIに任せてしまうこと。二つ目は流暢性の錯覚で、生成AIの説明は分かりやすいが自分でコードを書こうとすると書けず「分かった気」になっているだけ。三つ目は最適な難易度を見失い自分の理解レベルに合わない質問をしてしまい、基礎を理解していないのに応用的な質問をする。四つ目は不快感から逃げることで、混乱したときモヤモヤしたときすぐに頼ってしまうがその不快感こそが成長の証なのに。重要なのは自分の頭で考え手を動かし不快感と向き合うことで、これは生成AIがなかった時代もある時代も変わらない真実だ。そしてこれも才能の問題ではなく習慣の問題だ。生成AI「戦力化」の教科書作者:松本 勇気日経BPAmazon遊ぶことから始まる恥を恐れ完璧を求め言語化から逃げる。この三つが絡み合って人を動けなくする。一つの答えは遊ぶことだ。ワークショップでこんな提案をしてみた。「次の30分何も見ずにとりあえず動かしてみて」。「えっドキュメント見なくていいんですか？」と驚く学生たちに「いいよ。適当にやってみて。エラーが出ても気にしない。とにかく何か動かしてみる」と答えた。最初は戸惑っていたが徐々に表情が変わってきて「あこれ動いた」「このオプション何だろう」「試してみよう」となった。遊びには「正解」がないから失敗を恐れる必要がない。評価されることもなくただ面白いからやり好奇心のままに試す。この心理的な自由が試行錯誤を促進する。30分後何人かの学生が予想外のものを作っていた。「Nginxのコンテナを3つ立ち上げてそれぞれ違うページを表示させてみました」。ドキュメント通りではないが動いていて彼は楽しそうだった。「どうやって作ったの？」と聞くと「分からないままとりあえず書いてみたら動いたんです」と言った。この「なんとなく」が実は重要なのだ。理論を学ぶ前に体験を通じた直感的理解が生まれる。後に理論を学ぶとき「あああの時の『なんとなく』はこういうことだったのか」と腑に落ちる。プログラミングを学び始めた頃を思い出してほしい。「とりあえず動かしてみよう」と思ってよくわからないままコードを書いた経験はないだろうか。エラーが出て何が悪いのかわからないが、いろいろいじっているうちになんとなく動いた。遊びは内発的動機を育てる。「やらなければならない」ではなく「やりたい」という動機で、これは強制では生まれない。自分で選んで自分のペースで面白いと思うことをやる過程で内発的動機が育つ。失敗への耐性も生まれる。遊んでいるとき失敗は「失敗」ではなくただの「結果」だ。「あこうするとこうなるんだ」という発見と次は別の方法を試してみようという好奇心。多くの人は学びを始めるときいきなり「正しいやり方」を覚えようとして教科書を読みチュートリアルを見る。でもこれは実は難しい。なぜなら「なぜその型が重要なのか」がわからないまま形だけを真似ようとするから。型の意味を理解するにはその型がない状態を経験する必要がある。だからまず遊ぶ。制約なく好奇心のままに試して失敗を恐れず楽しむ。ここで少し逆説的なことを言いたい。特に若い時期には根拠がなくても自分を信じることが重要だ。「これが本当に正しい道なのか」「自分に向いているのか」。そんな冷静な自己分析ばかりしていると一歩も踏み出せなくなる。時には根拠のない自信を持って盲信的に突き進むことも必要だ。「Kubernetesなんて簡単だろう」というある意味で無知ゆえの大胆さ。この「若気の至り」とも言える姿勢が最初の一歩を踏み出させてくれる。ワークショップで最も早く理解した学生に「なんでそんなに迷わず進めるの？」と聞いてみた。彼は少し考えて「分からないけどとりあえずやってみたら分かるかなって」と言った。根拠のない自信だがその自信が彼を動かした。実際に動いた結果本当に理解した。その盲信的な姿勢がいつか本当の自信に変わり、根拠のない自信が実績という根拠を伴った自信になる。気づけば最初は「嘘」だった「自分はできる」という言葉が本当になっている。完璧主義を捨ててまず遊ぶ。型を学ぶのはその後でいい。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon小さく、完璧でなくても、動く停滞と努力の違いを理解することも重要だ。ワークショップである学生がKubernetesのServiceの概念に数日苦しんでいて、彼は毎日同じドキュメントを読み返していた。「努力している」と本人は言ったが彼は前に進んでいなかった。よく話を聞くと彼はそもそもネットワークの基礎を理解していなかった。IPアドレスとは何かポートとは何かDNSがどう動くのか。こうした土台がないままKubernetesの抽象的な概念を理解しようとしていた。難しい問題に直面したとき人は二つの道を選ぶ。一つは理解できないまま同じ説明を何度も読み返し同じ場所でぐるぐると回り続けること。もう一つは「何が分からないのか」を見極めてまずそこから順番に理解していくこと。前者を停滞と呼び後者を努力と呼ぶ。停滞している人はしばしば自分が努力していると思っている。長時間向き合い何度も試している。でも実際には前提となる知識が欠けたまま同じところで足踏みを繰り返しているだけ。「Serviceが分からない」と言っていた学生に「じゃあまずネットワークの基礎から学ぼう」と提案すると最初は不満そうで「それは遠回りじゃないですか」と言った。でも基礎から学び始めて3日後彼は突然Serviceを理解して「ああそういうことか！」と言った。本当の意味での努力とは今の自分が理解できるところから始めること。Kubernetesが難しいならまずネットワークの基礎から。ネットワークが難しいならまず自分のPCで2つのプログラムを通信させることから。この段階を踏んだ学び方こそが努力の本質だ。学習には三つのゾーンがある。コンフォートゾーンはすでに理解していることを繰り返す状態で簡単すぎて新しい学びがない。パニックゾーンは現在の理解からかけ離れていて難しすぎて何から手をつければいいかわからない。学習ゾーンは少し難しいが頑張れば手が届き既存の知識を応用すればなんとか理解できる。「才能がない」と感じているとき実はパニックゾーンに突っ込んでいるだけかもしれない。基礎を理解していないのに応用に挑戦し前提知識がないのに高度な概念を理解しようとする。当たり前だがこれは無理だ。才能の問題ではなく順序の問題だ。不快感を恐れないことも重要だ。学習において最も反直感的な真実の一つはある種の困難は実は学習を改善するということだ。同じチュートリアルの再読、すでに動くコードの微調整、すぐに答えを探すこと。これらは確かに楽だが長期的な学習効果は低い。なぜか。脳は情報を取り出すのに苦労すること自体でその情報への神経経路を強化するからだ。簡単すぎる復習ではこの「取り出す苦労」が発生せず記憶が強化されない。効果的な方法は少し忘れかけたタイミングで復習すること。概念を学び1日空けて何も見ずに説明しようとし思い出せない部分を確認する。難しく忘れかけていて思い出すのに苦労するがこの苦労こそが記憶を強化する。新しい概念を学ぶとき混乱は不快で「もう無理だ」と思う。でもこの不快感こそが成長の証なのだ。脳が新しい構造を構築しようとしている証で既存の理解の枠組みが崩れ新しい理解が生まれつつある証だ。この不快な状態を抱えたまま学び続け逃げずに向き合う。ある日突然繋がる。その瞬間の爽快感はすべての苦労を報いてくれる。「快適ならやり方が間違っている」という言葉がある。本当の成長は常にコンフォートゾーンの外側で起きる。最後にエラーメッセージをちゃんと読み仮説を一つずつ潰し主語と述語を把握する。こうした小さなこと。ワークショップの最後にある学生が「エラーメッセージちゃんと読んだらちゃんと書いてありました」と言った。当たり前のことだがこの当たり前のことができていない人は驚くほど多い。めんどくさいと感じるかもしれないがこの「めんどくさい」基礎作業を飛ばすから結果的に何倍も時間がかかってしまう。才能があるように見える人はこれらを実践しているだけで意識的か無意識的に。これらは訓練可能だ。小さく始める。不完全でも動く。その積み重ねだけだ。エンジニアという仕事には一つの大きな救いがある。それは手を動かしている間才能への不安が消えるということだ。「自分には才能がない」という悩みは頭の中でぐるぐる回り始めるとどんどん大きくなるが「これを作りたい」と思って実装を始めた瞬間その悩みはどこかに消える。目の前にあるのは具体的な問題だけだ。エラーが出て調べて解決してまた詰まってまた調べる。この「詰まる→調べる→解決する」のサイクルを回すこと自体が静かに自信を育てていく。理解の速さには個人差がありこれは残酷な現実だが、人生という長い時間軸で見たときこの速さの差は思ったほど大きくない。むしろ一歩ずつでも前に進み続けた人と途中で立ち止まってしまった人の差の方がはるかに大きい。時間は誰にも平等だ。その時間を「理解できない問題の前での空回り」に使うか「今理解できることから順に積み上げていく前進」に使うか。この選択が長期的には想像もできないほどの差を生む。ぐちゃぐちゃ考える暇があったら手を動かす。才能について悩む時間を1行でも多くコードを書く時間に変え、理想の自分について考える時間を作りたいものを作る時間に変える。その積み重ねが気づけば「成長」と呼ばれるものになっている。心理的安全性　最強の教科書作者:ピョートル・フェリクス・グジバチ東洋経済新報社Amazonおわりにワークショップで出会った学生の一人が最近こんなメッセージを送ってきた。「ちゃんと読むようになったら解決が早くなりました」。彼は以前「才能がない」と言っていたが実際にはエラーメッセージを読み飛ばしていただけだった。その事実を言語化し意識的に「ちゃんと読む」ようにした。それだけで解決速度は変わった。些細なことだがその些細なことに気づくまで私は何年もかかった。このポストで繰り返し述べてきたように動けない理由は言葉にしてしまえば驚くほど小さい。恥を恐れていて完璧を求めすぎていて「なんか不安」を「なんか」のまま放置していて、そして「才能がない」という誰も反論できない理由で全てから逃げていた。言葉にした瞬間それらは「対処可能な課題」に変わる。でも言葉にするまでが驚くほど難しい。なぜなら嫌な自分と向き合わなければならないから。ワークショップを三年続けて一つ確信したことがある。最初は速かったのに途中で離れていった人たちがいて最初は遅かったのに黙々と続けている人たちがいる。三年後後者の方が圧倒的に前に進んでいる。「才能」という言葉を使った瞬間思考は停止する。でも「エラーメッセージを読み飛ばしている」と言語化した瞬間「じゃあちゃんと読めばいい」という対策が見える。そのシンプルな事実に気づくかどうか。それだけの差が長い時間をかけて想像もできないほど大きな差になる。syu-m-5151.hatenablog.com未熟な自分がワークショップを始めて三年。今でも不安はあり「自分なんかが教えていいのか」と思うこともある。でも若手と一緒に作業する中で気づいた。彼らが必要としているのは全てを知り尽くした完璧な指導者ではない。「才能」という便利な言葉で可能性を閉ざさず「じゃあどうすればいいか」を一緒に考える誰かだ。そしてそれは自分自身に対しても同じだと思っている。「読んでいる自分は頑張っている気がする」という謎の達成感に私たちはいつまで浸っているのだろうか。本当に必要なのは手を動かすこと。小さく完璧でなくてもでも確実に前に進むこと。言葉にしない限り「なんか」は永遠に巨大な壁であり続けるが、言葉にしてしまえば思ったより大したことなかったりする。その一歩を踏み出すかどうか。結局それだけの話だ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[splitコマンドでファイルを分割する方法について]]></title>
            <link>https://zenn.dev/akasan/articles/a7d35ab880e1f8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/a7d35ab880e1f8</guid>
            <pubDate>Fri, 31 Oct 2025 12:47:15 GMT</pubDate>
            <content:encoded><![CDATA[今回はファイルを分割するためのsplitコマンドについて調べてみました。行数が多いファイルを分割する方法を調べていたら組み込みのコマンドとして存在していたので調べてみました。 splitコマンドの使い方それでは早速splitコマンドを使ってみます。 検証用データの作成今回はテストように100万行あるデータを作成してみました。Pythonでパパッと作りました。with open("original.txt", "w") as f:    for i in range(1_000_000):        f.write(f"{i}\n")これを実行すると、0から99,9...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Observability Conference Tokyo 2025に参加してきました！]]></title>
            <link>https://sreake.com/blog/o11y-con-tokyo-2025/</link>
            <guid isPermaLink="false">https://sreake.com/blog/o11y-con-tokyo-2025/</guid>
            <pubDate>Fri, 31 Oct 2025 09:21:45 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 3-shakeで マーケティング・ブランディングを行なっている永瀬です。 2025/10/27に Observability Conference Tokyo 2025 が開催されましてスリーシェイクもスポンサ […]The post Observability Conference Tokyo 2025に参加してきました！ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[近すぎず、遠すぎず - コードの結合度とちょうどいい距離の測り方]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/31/125256</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/31/125256</guid>
            <pubDate>Fri, 31 Oct 2025 03:52:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに人間関係が数値化できればなぁって思ったこともありますか？僕はあります。「この人とは、ちょうどいい距離感だな」とか、「もうちょっと親しくなりたいけど、近づきすぎると息苦しいかもしれない」とか。そういう、言葉にしづらい感覚を、もし数字で表せたら——なんて。コードを書いているとき、似たようなことを考える。「このモジュールとあのモジュール、近すぎるな」と思う瞬間がある。あるいは逆に、「これ、もっと近くにあった方がいいんじゃないか」と。モジュール同士の距離感。誰もが一度は悩んだことがあるはずだ。近すぎても、遠すぎてもいけない。でも、「ちょうどいい」って、どういうことだろう。バグを修正したときのことだ。直接的には関係ないはずの、別の場所が壊れる。そんな経験、ないだろうか。それは、見えない糸が張り巡らされている証拠だ。データの持ち方への暗黙の依存。前提条件。実行順序。そういう、目に見えにくい結合が、コードのあちこちに潜んでいる。大切なのは、結合をゼロにすることじゃない。そんなことは、できない。むしろ、適切にバランスさせることだ。人間関係と同じように。Vlad Khononov が書いた「Balancing Coupling in Software Design」という本がある。この本は、結合度を測るための、実践的なフレームワークを提供している。結合の強さ、距離、そして変更の頻度——この3つの軸。これで測る。バランスを評価する。この本が教えてくれることがある。機能は線形に増える。でも、複雑さは指数関数的に膨れ上がる。そして、僕たち人間には認知的な限界がある。だから、複雑さに対処するには、システムの形を変えるしかない。そのための道具が、結合なのだ。この記事では、その概念を Rust プロジェクトに適用してみる。実際に測定して、分析できるツールを作る。コードの「ちょうどいい距離感」を数値化し、可視化する。そんな試みである。Balancing Couplingの核心概念ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazon3つの次元で結合度を測るすごく端的に話すとKhononov のフレームワークは、結合度を 3 つの軸で評価する。1. Integration Strength（統合強度）コンポーネント間で共有される知識の量。次の 4 つのレベルに分類される。Intrusive Coupling（侵入的結合）- 内部実装の詳細に依存Functional Coupling（機能的結合）- 共有された責任による依存Model Coupling（モデル結合）- ビジネスドメインモデルの共有Contract Coupling（契約結合）- インターフェース/トレイトによる抽象化下に行くほど結合が弱く、望ましい。2. Distance（距離）依存関係がどれだけ離れているかを測る。同じ関数内同じモジュール内異なるモジュール異なるクレート異なるサービス（マイクロサービスの場合）距離が遠いほど、変更のコストが高くなる。3. Volatility（変動性）コンポーネントの変更頻度を示す。Core Subdomain（コアサブドメイン）- 高頻度で変更Supporting Subdomain（サポートサブドメイン）- 中程度の変更Generic Subdomain（汎用サブドメイン）- 低頻度の変更バランスの公式これらを組み合わせた「バランスの方程式」は、概念的には次のように表現できる。BALANCE = (STRENGTH XOR DISTANCE) OR NOT VOLATILITY概念の解釈MODULARITY = STRENGTH XOR DISTANCE強い結合なら距離を近く（局所性を保つ）弱い結合なら距離を遠くても良い（疎結合）この 2 つのパターンが理想的BALANCE = MODULARITY OR NOT VOLATILITYモジュラーである、または変動性が低い（安定している）どちらかの条件を満たせばバランスが取れている数値計算への変換実装では、論理演算を数値計算に変換する。XOR - 両極端（強×近、弱×遠）の和として計算OR - 最大値（max）として計算NOT - 補数（1.0 - x）として計算ここで押さえておきたいのは、結合をゼロにするのが目的ではないということ。適切にバランスさせることが肝心で、コンテキストに応じて最適な形を選ぶ必要がある。Connascence（共依存性）結合度をさらに細かく分析するには、Meilir Page-Jones が提唱した「Connascence」の概念が役立つ。Static Connascence（静的共依存性）コンパイル時に検出可能なもの。Connascence of Name（CoN）- 名前への依存Connascence of Type（CoT）- 型への依存Connascence of Meaning（CoM）- 値の意味への依存Connascence of Position（CoP）- パラメータ順序への依存Connascence of Algorithm（CoA）- アルゴリズムへの依存Dynamic Connascence（動的共依存性）実行時に検出されるもの。Connascence of Execution（CoE）- 実行順序への依存Connascence of Timing（CoT）- タイミングへの依存Connascence of Value（CoV）- 値の同期的変更への依存Connascence of Identity（CoI）- 同一インスタンスへの依存動的共依存性は、最も弱いものでも、最も強い静的共依存性よりも強い結合を意味する。Rustにおける既存ツール1. cargo-modulesモジュール構造と依存関係を可視化できる。https://crates.io/crates/cargo-modulescrates.ioインストール:cargo install cargo-modules使い方:# モジュール構造をツリー表示cargo modules structure# モジュール間の依存関係をグラフ表示cargo modules dependencies# 循環依存の検出cargo modules dependencies --acyclic# 孤立したファイルの検出cargo modules orphans特徴:モジュール階層の視覚化循環依存の検出（リファクタリングの重要な手がかり）未使用ファイルの発見GraphViz と連携可能2. rust-code-analysisMozilla が開発した、多言語対応のコードメトリクス計測ツール。github.comインストール:cargo install rust-code-analysis-cli使い方:# 単一ファイルの分析rust-code-analysis-cli --metrics -p src/main.rs# プロジェクト全体の分析rust-code-analysis-cli --metrics -p ./src# JSON形式で出力rust-code-analysis-cli --metrics -O json -o metrics.json -p ./src計測可能なメトリクスCC (Cyclomatic Complexity) - 循環的複雑度COGNITIVE - 認知的複雑度HALSTEAD - Halstead メトリクス（Bugs, Difficulty, Effort, Volume 等）LOC 系 - SLOC、PLOC、LLOC 等NOM - メソッド数NARGS - 引数の数NEXITS - 出口の数WMC - クラスごとの循環的複雑度の合計Rust コードの複雑度を他言語と比較する研究でも使用されており、信頼性が高い。3. cargo treeCargo 組み込みの依存関係ツリー表示コマンド。doc.rust-lang.org使い方:# 依存関係ツリーの表示cargo tree# 深さを制限cargo tree --depth 1# 特定のパッケージを除外cargo tree --prune serde# 重複する依存関係を表示cargo tree --duplicates# リバース依存関係（何がこのクレートに依存しているか）cargo tree --invert <package-name>4. その他の有用なツールcargo-deps - GraphViz DOT ファイルを生成cargo-depgraph - 視覚的な依存関係グラフtokei - コード統計（行数、言語別集計）cargo-deny - 依存関係のポリシー検証Balanced Couplingを測定するカスタムツールの実装既存ツールは有用だが、Khononov のモデルを直接適用するには限界がある。特に、Integration Strength の分類、Dynamic Connascence の検出、Git 履歴との連携、Balance Score の計算といった機能が不足している。これらを測定するため、カスタムツールを実装していこう。基本的なアプローチ必要な依存関係を Cargo.toml に追加します。[dependencies]syn = { version = "2.0", features = ["full", "visit"] }quote = "1.0"walkdir = "2.4"thiserror = "2.0"実装例です。use syn::{visit::Visit, ItemFn, ItemImpl};/// 結合度メトリクスを保持する構造体////// Integration Strength、Distance、Connascenceの3つの次元を測定#[derive(Debug, Default, Clone)]pub struct CouplingMetrics {    // Integration Strength    pub intrusive_count: usize,    pub functional_count: usize,    pub model_count: usize,    pub contract_count: usize,    // Distance    pub same_module: usize,    pub cross_module: usize,    pub cross_crate: usize,    // Connascence    pub name_coupling: Vec<String>,    pub type_coupling: Vec<String>,    pub position_coupling: Vec<String>,}/// ASTを訪問して結合度を分析するアナライザー#[derive(Debug)]pub struct CouplingAnalyzer {    pub metrics: CouplingMetrics,    pub current_module: String,}impl CouplingAnalyzer {    /// 新しいアナライザーを作成    ///    /// # Arguments    /// * `module_name` - 分析対象のモジュール名    fn new(module_name: String) -> Self {        Self {            metrics: CouplingMetrics::default(),            current_module: module_name,        }    }    /// 関数シグネチャを分析してConnascence of Positionを検出    ///    /// # Arguments    /// * `sig` - 分析対象の関数シグネチャ    fn analyze_function_signature(&mut self, sig: &syn::Signature) {        // 引数の数をチェック（Connascence of Position）        if sig.inputs.len() > 3 {            self.metrics.position_coupling.push(                format!("Function {} has {} parameters",                    sig.ident, sig.inputs.len())            );        }    }    /// 2つのモジュールパス間の距離を計算    ///    /// # Arguments    /// * `from_path` - 開始パス (例: "crate::module::submodule")    /// * `to_path` - 終了パス    ///    /// # Returns    /// モジュール階層における段数（距離）    fn calculate_distance(&self, from_path: &str, to_path: &str) -> usize {        let from_parts: Vec<&str> = from_path.split("::").collect();        let to_parts: Vec<&str> = to_path.split("::").collect();        // 共通の祖先を見つける        let common = from_parts.iter()            .zip(to_parts.iter())            .take_while(|(a, b)| a == b)            .count();        (from_parts.len() - common) + (to_parts.len() - common)    }}impl<'ast> Visit<'ast> for CouplingAnalyzer {    /// 関数定義を訪問    fn visit_item_fn(&mut self, node: &'ast ItemFn) {        // 関数定義を分析        self.analyze_function_signature(&node.sig);        syn::visit::visit_item_fn(self, node);    }    /// implブロックを訪問してContract/Intrusive Couplingを検出    fn visit_item_impl(&mut self, node: &'ast ItemImpl) {        // トレイト実装を分析（Contract Coupling）        if node.trait_.is_some() {            self.metrics.contract_count += 1;        } else {            // 具象型への直接実装（Intrusive Coupling）            self.metrics.intrusive_count += 1;        }        syn::visit::visit_item_impl(self, node);    }}Volatility（変動性）の測定Git の履歴から変更頻度を分析します。use std::process::Command;use std::collections::HashMap;use thiserror::Error;/// Volatility分析のエラー型#[derive(Error, Debug)]pub enum VolatilityError {    #[error("Git command failed: {0}")]    GitCommandFailed(String),    #[error("Failed to parse Git output: {0}")]    ParseError(String),    #[error("IO error: {0}")]    Io(#[from] std::io::Error),    #[error("UTF-8 conversion error: {0}")]    Utf8Error(#[from] std::string::FromUtf8Error),}/// ファイルの変更頻度を分析するアナライザー////// Git履歴を解析して各ファイルの変動性を評価#[derive(Debug, Default, Clone)]pub struct VolatilityAnalyzer {    file_changes: HashMap<String, usize>,}/// 変動性のレベル#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]pub enum VolatilityLevel {    /// 低変動性（汎用サブドメイン）    Low,    /// 中変動性（サポートサブドメイン）    Medium,    /// 高変動性（コアサブドメイン）    High,}impl VolatilityAnalyzer {    /// 新しいアナライザーを作成    fn new() -> Self {        Self::default()    }    /// Git履歴を解析して変更頻度を収集    ///    /// # Arguments    /// * `months` - 過去何ヶ月分の履歴を分析するか    ///    /// # Returns    /// 成功時は `Ok(())`、Git コマンド実行失敗時はエラー    ///    /// # Errors    /// - Git コマンドが失敗した場合    /// - 出力のパースに失敗した場合    ///    /// # Example    /// ```    /// let mut analyzer = VolatilityAnalyzer::new();    /// analyzer.analyze_git_history(6)?; // 過去6ヶ月を分析    /// ```    pub fn analyze_git_history(&mut self, months: usize) -> Result<(), VolatilityError> {        let output = Command::new("git")            .args([                "log",                "--pretty=format:",                "--name-only",                &format!("--since={} months ago", months)            ])            .output()?;        // Git コマンドが失敗した場合のチェック        if !output.status.success() {            let stderr = String::from_utf8_lossy(&output.stderr);            return Err(VolatilityError::GitCommandFailed(stderr.to_string()));        }        let files = String::from_utf8(output.stdout)?;        for file in files.lines().filter(|l| !l.is_empty()) {            *self.file_changes.entry(file.to_string())                .or_insert(0) += 1;        }        Ok(())    }    /// ファイルの変動性レベルを分類    ///    /// # Arguments    /// * `file` - 分類対象のファイルパス    ///    /// # Returns    /// 変動性レベル（Low/Medium/High）    fn classify_volatility(&self, file: &str) -> VolatilityLevel {        let changes = self.file_changes.get(file).copied().unwrap_or(0);        match changes {            0..=2 => VolatilityLevel::Low,            3..=10 => VolatilityLevel::Medium,            _ => VolatilityLevel::High,        }    }    /// 最も変更頻度の高いファイルを取得    ///    /// # Arguments    /// * `n` - 取得する上位ファイル数    ///    /// # Returns    /// (ファイルパス, 変更回数) のタプルのベクター    fn top_volatile_files(&self, n: usize) -> Vec<(&str, usize)> {        let mut files: Vec<_> = self.file_changes            .iter()            .map(|(file, &count)| (file.as_str(), count))            .collect();        files.sort_by(|a, b| b.1.cmp(&a.1));        files.truncate(n);        files    }}バランススコアの計算/// Balancing Couplingのスコアを計算////// Khononovのモデルに基づき、Strength、Distance、Volatilityの/// 3次元からバランススコアを算出#[derive(Debug, Clone)]struct BalancedCouplingScore {    /// 結合の強さ: 0.0 (弱い) から 1.0 (強い)    strength: f64,    /// 距離: 0.0 (近い) から 1.0 (遠い)    distance: f64,    /// 変動性: 0.0 (安定) から 1.0 (頻繁に変更)    volatility: f64,}impl BalancedCouplingScore {    /// 新しいスコアを作成    ///    /// # Arguments    /// * `strength` - 結合の強さ (0.0-1.0)    /// * `distance` - 距離 (0.0-1.0)    /// * `volatility` - 変動性 (0.0-1.0)    ///    /// # Panics    /// 各値が 0.0-1.0 の範囲外の場合にパニック    fn new(strength: f64, distance: f64, volatility: f64) -> Self {        assert!((0.0..=1.0).contains(&strength), "strength must be 0.0-1.0");        assert!((0.0..=1.0).contains(&distance), "distance must be 0.0-1.0");        assert!((0.0..=1.0).contains(&volatility), "volatility must be 0.0-1.0");        Self {            strength,            distance,            volatility,        }    }    /// モジュラリティを計算    ///    /// # Formula    /// MODULARITY = STRENGTH XOR DISTANCE (論理的な意味での排他的論理和)    ///    /// 理想的な状態：    /// - 強い結合なら距離が近い (strength が高く distance が低い)    /// - 弱い結合なら距離が遠くても良い (strength が低く distance が高い)    ///    /// # Returns    /// モジュラリティスコア (0.0-1.0、高いほど良い)    fn calculate_modularity(&self) -> f64 {        // 強い結合 × 近い距離 = 良い（局所性が高い）        let ideal_close = self.strength * (1.0 - self.distance);        // 弱い結合 × 遠い距離 = 良い（疎結合が保たれている）        let ideal_far = (1.0 - self.strength) * self.distance;        ideal_close + ideal_far    }    /// バランススコアを計算    ///    /// # Formula    /// BALANCE = MODULARITY OR (NOT VOLATILITY) (論理的な意味での論理和)    ///    /// バランスが取れている状態：    /// - モジュラーである、または    /// - 変動性が低い（安定している）    ///    /// # Returns    /// バランススコア (0.0-1.0、高いほど良い)    fn calculate_balance(&self) -> f64 {        let modularity = self.calculate_modularity();        let stability = 1.0 - self.volatility;        // 論理和の近似：max を使用        modularity.max(stability)    }    /// 結合の問題点を識別    ///    /// # Returns    /// 検出された問題のリスト    fn identify_issues(&self) -> Vec<CouplingIssue> {        let mut issues = Vec::new();        // パターン1: グローバル複雑性        // 強い結合 + 遠い距離 = 変更の調整コストが高い        if self.strength > 0.7 && self.distance > 0.7 {            issues.push(CouplingIssue {                severity: IssueSeverity::High,                description: "Strong coupling over long distance increases global complexity"                    .to_string(),                recommendation: "Consider moving coupled components closer or reducing coupling strength"                    .to_string(),            });        }        // パターン2: ローカル複雑性        // 弱い結合 + 近い距離 = 不要な抽象化の可能性        if self.strength < 0.3 && self.distance < 0.3 {            issues.push(CouplingIssue {                severity: IssueSeverity::Medium,                description: "Weak coupling at close distance may indicate unnecessary indirection"                    .to_string(),                recommendation: "Consider consolidating components or increasing distance"                    .to_string(),            });        }        // パターン3: カスケード変更リスク        // 強い結合 + 高変動性 = 変更が広範囲に波及        if self.strength > 0.7 && self.volatility > 0.7 {            issues.push(CouplingIssue {                severity: IssueSeverity::Critical,                description: "Strong coupling with volatile component creates cascading change risk"                    .to_string(),                recommendation: "Isolate volatile components or reduce coupling strength"                    .to_string(),            });        }        // パターン4: 低モジュラリティ        let modularity = self.calculate_modularity();        if modularity < 0.4 {            issues.push(CouplingIssue {                severity: IssueSeverity::Medium,                description: format!("Low modularity score: {:.2}", modularity),                recommendation: "Review coupling strength and distance relationship"                    .to_string(),            });        }        issues    }}/// 結合に関する問題#[derive(Debug, Clone)]struct CouplingIssue {    severity: IssueSeverity,    description: String,    recommendation: String,}/// 問題の重要度#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]enum IssueSeverity {    Low,    Medium,    High,    Critical,}実践的な使用例プロジェクト全体の分析必要な依存関係を追加します。[dependencies]syn = { version = "2.0", features = ["full", "visit"] }walkdir = "2.4"実装例です。use walkdir::WalkDir;use std::path::Path;use std::ffi::OsStr;use std::fs;/// プロジェクト全体のメトリクスを保持#[derive(Debug, Default)]struct ProjectMetrics {    measurements: Vec<CouplingMeasurement>,    file_count: usize,    module_count: usize,}/// 結合度の測定結果#[derive(Debug)]struct CouplingMeasurement {    from_module: String,    to_module: String,    strength: f64,    distance: f64,    volatility: f64,}/// プロジェクト全体を分析////// # Arguments/// * `project_path` - プロジェクトのルートパス////// # Returns/// プロジェクトメトリクス、またはエラー////// # Example/// ```/// let metrics = analyze_project("./src")?;/// println!("Total files analyzed: {}", metrics.file_count);/// ```fn analyze_project(project_path: &str) -> Result<ProjectMetrics, Box<dyn std::error::Error>> {    let mut project_metrics = ProjectMetrics::default();    // 1. 構造的な依存関係を分析    for entry in WalkDir::new(project_path)        .follow_links(true)        .into_iter()        .filter_map(|e| e.ok())    {        let path = entry.path();        // Rustファイルのみを処理        if path.extension() == Some(OsStr::new("rs")) {            analyze_rust_file(path, &mut project_metrics)?;        }    }    // 2. Git履歴から変動性を分析    let mut volatility = VolatilityAnalyzer::new();    volatility.analyze_git_history(6)?;    // 3. バランススコアを計算    calculate_balance_scores(&mut project_metrics, &volatility);    Ok(project_metrics)}/// 個別のRustファイルを分析////// # Arguments/// * `path` - ファイルパス/// * `project_metrics` - プロジェクトメトリクスの可変参照fn analyze_rust_file(    path: &Path,    project_metrics: &mut ProjectMetrics,) -> Result<(), Box<dyn std::error::Error>> {    let content = fs::read_to_string(path)?;    let syntax = syn::parse_file(&content)?;    let module_name = path        .to_string_lossy()        .replace('/', "::")        .replace(".rs", "");    let mut analyzer = CouplingAnalyzer::new(module_name);    analyzer.visit_file(&syntax);    project_metrics.file_count += 1;    project_metrics.module_count += 1;    Ok(())}/// バランススコアを計算してプロジェクトメトリクスに追加////// # Arguments/// * `metrics` - プロジェクトメトリクスの可変参照/// * `volatility` - 変動性アナライザーの参照fn calculate_balance_scores(    metrics: &mut ProjectMetrics,    volatility: &VolatilityAnalyzer,) {    for measurement in &metrics.measurements {        let score = BalancedCouplingScore::new(            measurement.strength,            measurement.distance,            measurement.volatility,        );        let issues = score.identify_issues();        if !issues.is_empty() {            eprintln!(                "Issues found in coupling from {} to {}:",                measurement.from_module, measurement.to_module            );            for issue in issues {                eprintln!("  [{:?}] {}", issue.severity, issue.description);            }        }    }}レポート生成use std::io::{self, Write};/// Markdownフォーマットでレポートを生成////// # Arguments/// * `metrics` - プロジェクトメトリクス/// * `writer` - 出力先 (stdout、ファイルなど)////// # Example/// ```/// let metrics = analyze_project("./src")?;/// generate_report(&metrics, &mut std::io::stdout())?;/// ```fn generate_report<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, "# Coupling Analysis Report\n")?;    // サマリーセクション    write_summary(metrics, writer)?;    // 統合強度の分布    write_strength_distribution(metrics, writer)?;    // 問題の検出    write_issues(metrics, writer)?;    // 変動性分析    write_volatility_analysis(metrics, writer)?;    Ok(())}/// サマリーセクションを出力fn write_summary<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, "## Summary\n")?;    writeln!(writer, "- **Total Files**: {}", metrics.file_count)?;    writeln!(writer, "- **Total Modules**: {}", metrics.module_count)?;    writeln!(        writer,        "- **Total Couplings**: {}\n",        metrics.measurements.len()    )?;    Ok(())}/// Integration Strengthの分布を出力fn write_strength_distribution<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, "## Integration Strength Distribution\n")?;    let total = metrics.measurements.len() as f64;    let contract = metrics        .measurements        .iter()        .filter(|m| m.strength <= 0.25)        .count();    let model = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.25 && m.strength <= 0.50)        .count();    let functional = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.50 && m.strength <= 0.75)        .count();    let intrusive = metrics        .measurements        .iter()        .filter(|m| m.strength > 0.75)        .count();    writeln!(        writer,        "- **Contract Coupling** (weakest): {} ({:.1}%)",        contract,        (contract as f64 / total) * 100.0    )?;    writeln!(        writer,        "- **Model Coupling**: {} ({:.1}%)",        model,        (model as f64 / total) * 100.0    )?;    writeln!(        writer,        "- **Functional Coupling**: {} ({:.1}%)",        functional,        (functional as f64 / total) * 100.0    )?;    writeln!(        writer,        "- **Intrusive Coupling** (strongest): {} ({:.1}%)\n",        intrusive,        (intrusive as f64 / total) * 100.0    )?;    Ok(())}/// 検出された問題を出力fn write_issues<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, "## Detected Issues\n")?;    let mut has_issues = false;    for measurement in &metrics.measurements {        let score = BalancedCouplingScore::new(            measurement.strength,            measurement.distance,            measurement.volatility,        );        let issues = score.identify_issues();        if !issues.is_empty() {            has_issues = true;            writeln!(                writer,                "### {} → {}\n",                measurement.from_module, measurement.to_module            )?;            for issue in issues {                writeln!(writer, "**{:?}**: {}", issue.severity, issue.description)?;                writeln!(writer, "- *Recommendation*: {}\n", issue.recommendation)?;            }        }    }    if !has_issues {        writeln!(writer, "No significant coupling issues detected.\n")?;    }    Ok(())}/// 変動性分析を出力fn write_volatility_analysis<W: Write>(    metrics: &ProjectMetrics,    writer: &mut W,) -> io::Result<()> {    writeln!(writer, "## High Volatility Analysis\n")?;    // 高変動性のファイルを抽出    let high_volatility: Vec<_> = metrics        .measurements        .iter()        .filter(|m| m.volatility > 0.7)        .collect();    if high_volatility.is_empty() {        writeln!(writer, "No high volatility modules detected.\n")?;    } else {        writeln!(writer, "Modules with high change frequency:\n")?;        for measurement in high_volatility {            writeln!(                writer,                "- `{}` (volatility: {:.2})",                measurement.from_module, measurement.volatility            )?;        }        writeln!(writer)?;    }    Ok(())}実践的なガイドライン結合度を改善するためのパターン1. 強い結合が必要な場合は距離を近くする頻繁に一緒に変更される機能は、同じモジュール内に配置するべきだ。// Good: 密接に関連する機能を同じモジュールに配置mod user_profile {    pub struct User { /* ... */ }    pub struct UserProfile { /* ... */ }    // Userと常に一緒に使われる    impl User {        pub fn get_profile(&self) -> &UserProfile { /* ... */ }    }}DDD 的に言えば、同じ Bounded Context 内の概念は同じモジュールに配置する。2. 弱い結合なら距離を遠くしても良いインターフェース（trait）を通じた疎結合なら、別クレートに分けても問題ない。// core/src/lib.rs - インターフェース定義pub trait NotificationService {    fn send(&self, message: &str) -> Result<(), Error>;}// adapters/email/src/lib.rs - 実装は別クレートuse core::NotificationService;pub struct EmailService;impl NotificationService for EmailService {    fn send(&self, message: &str) -> Result<(), Error> { /* ... */ }}3. 高変動性のコードは低結合に保つビジネスロジック（Core Subdomain）は頻繁に変更される。他への影響を最小化するため、低結合に保つ必要がある。// Strategy Patternで変動性を隔離pub trait PricingStrategy {    fn calculate(&self, base_price: f64) -> f64;}pub struct StandardPricing;impl PricingStrategy for StandardPricing {    fn calculate(&self, base_price: f64) -> f64 {        base_price // ビジネスルールの変更がここに限定される    }}pub struct Order {    pricing: Box<dyn PricingStrategy>, // Dependency Injection}4. Connascenceを意識したリファクタリングパターン1: Position → Name// Before: Connascence of Position（悪い例）fn create_user(name: String, email: String, age: u32, country: String) -> User {    // 引数の順序に依存}// After: Connascence of Name（良い例）struct UserBuilder {    name: String,    email: String,    age: u32,    country: String,}impl UserBuilder {    fn name(mut self, name: String) -> Self {        self.name = name;        self    }    // 他のフィールドも同様}パターン2: Meaning → Name// Before: Connascence of Meaning（悪い例）if status == 1 { /* active */ }else if status == 2 { /* inactive */ }// After: Connascence of Name（良い例）#[derive(Debug, Clone, Copy, PartialEq, Eq)]enum UserStatus {    Active,    Inactive,    Suspended,}if status == UserStatus::Active { /* ... */ }おわりにVlad Khononov の「Balancing Coupling」フレームワークが教えてくれるのは、単なる「強い/弱い」という二元論を超えた結合度の見方だ。結合の強さ、距離、変動性——この3つの軸で測定することで、より細かい粒度での分析が可能になる。この調査を通じて明らかになったのは、Rust エコシステムには部分的に役立つツールは存在するものの、Balancing Coupling の概念を完全に体現するツールはまだ存在しないということだった。cargo-modules、rust-code-analysis、cargo tree といった既存ツールは、それぞれが異なる視点からコードを照らし出してくれる。しかし、Integration Strength の分類、Dynamic Connascence の検出、変動性の分析、そしてバランススコアの計算——これらを統合的に扱うには、カスタム実装が必要だ。そこで、本記事で紹介した設計をベースに、実際に動作するツールを作成していく。 syn クレートによる AST 解析、Git 履歴からの変動性測定、そして Khononov のフレームワークに基づくバランス評価——これらを組み合わせた実用的なツールだ。コードの「ちょうどいい距離感」を数値化し、可視化することで、リファクタリングの指針となることを目指す。ここで忘れてはいけないのは、結合をゼロにするのが目的ではないということだ。人間関係と同じように、コードにも「適切な距離感」がある。密接に関連する機能は、むしろ強く結合すべきだ。無理に引き離せば、かえって複雑になる。定期的な測定と分析により、過度な抽象化を避けつつ、柔軟で進化可能な設計を維持していこう。コードの「ちょうどいい距離感」は、測定することで初めて見えてくる。ネットワーク・エフェクト 事業とプロダクトに欠かせない強力で重要なフレームワーク作者:アンドリュー・チェン日経BPAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini Enterprise（旧Google Agentspace）を活用する]]></title>
            <link>https://sreake.com/blog/get-started-with-gemini-enterprise/</link>
            <guid isPermaLink="false">https://sreake.com/blog/get-started-with-gemini-enterprise/</guid>
            <pubDate>Fri, 31 Oct 2025 01:22:38 GMT</pubDate>
            <content:encoded><![CDATA[Gemini Enterprise（旧Google Agentspace）の概要 2025/10/10まではGoogle Agentspaceと呼ばれていたGoogle AIアシスタントサービスのサービス名称変更が行われ […]The post Gemini Enterprise（旧Google Agentspace）を活用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説]]></title>
            <link>https://sreake.com/blog/learn-about-snowflake-role-based-access-control/</link>
            <guid isPermaLink="false">https://sreake.com/blog/learn-about-snowflake-role-based-access-control/</guid>
            <pubDate>Fri, 31 Oct 2025 01:21:49 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Snowflakeでデータ分析基盤を構築するうえで、最も重要な要素の一つがロール管理です。これはデータガバナンスの活動の第一歩の位置付けでもあり、さらにはある程度成熟された基盤の状態からロールを再設計するコスト […]The post 【初心者向け】Snowflakeロールベースアクセス制御（RBAC）解説 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Run FunctionsにTerraformを使ってデプロイしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/d94c8407a99c90</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/d94c8407a99c90</guid>
            <pubDate>Thu, 30 Oct 2025 12:39:31 GMT</pubDate>
            <content:encoded><![CDATA[今回はTerraformを利用してCloud Run Functionsにサービスをデプロイしてみました。 構築するアーキテクチャ今回構築するアーキテクチャは以下のようになっています。Cloud Storageでは提供するアプリケーションのソースコードをZIPファイルで格納し、Cloud Run FunctionsではCloud Storageからソースコードを参照した上でサービスを展開します。 早速構築 Pythonアプリケーションの実装今回は呼び出すとHello World!と返すエンドポイントの提供を目指します。そのような仕組みを実現するために必要なファイルは以下...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[構造的類似性を捉える技術 - similarity-rsで学ぶAST-basedコード解析の実装]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/30/203342</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/30/203342</guid>
            <pubDate>Thu, 30 Oct 2025 11:33:42 GMT</pubDate>
            <content:encoded><![CDATA[github.comはじめにコードベースが大きくなるにつれて、似たようなコードが散らばっていることに気づく瞬間がある。「あれ、これ前にも書いたような...」そう思いながらコードを眺めるのだけれど、変数名が微妙に違っていたり、処理の順序が少しずれていたりして、結局は共通化できないまま放置してしまう。そんな経験は、プログラマなら誰しも一度や二度ではないはずだ。そして、生成AI時代の今、この問題はさらに深刻になっている。AIがコードを生成してくれるのは便利だけれど、同じような処理を少しずつ違う形で何度も生成してしまうことがある。人間が書いたコードなら「ああ、これは前に書いたやつだ」と気づけるのに、AIが生成したコードは一見して判別がつかない。気づけばコードベースは「似て非なるコード」で溢れかえり、保守性は急速に失われていく。生成AI時代だからこそ、コードの構造的な類似性を見抜く技術が、これまで以上に必要とされているのだ。私は、結合度を測って適切にリファクタリングを促すツールを開発したいと考えていた。そのヒントを探していたときに出会ったのが、@mizchiさんのsimilarityプロジェクトだった。このプロジェクトの中でも特に、Rustへの実装であるsimilarity-rsの仕組みに惹かれ、その内部構造を詳しく調査することにした。この記事は、そこで得られた発見の記録である。syu-m-5151.hatenablog.com実際の使用例は以下です。# インストール（Cargo経由）cargo install similarity-rs# プロジェクトルートで実行similarity-rs .# より詳細なオプションを確認similarity-rs -h# AI によって修正させる場合Run `similarity-rs .` to detect semantic code similarities. Execute this command, analyze the duplicate code patterns, and create a refactoring plan. Check `similarity-rs -h` for detailed options.実行すると、以下のように重複コードを検出します。Duplicates in src/utils.rs:────────────────────────────────────────────────────────────src/utils.rs:10 | L10-15 similar-function: calculateSumsrc/utils.rs:20 | L20-25 similar-function: addNumbersSimilarity: 85.00%, Priority: 8.5 (lines: 10)これがどうやって実現されているのか、その内部実装を紐解いていきます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。similarity-rsとは何か？similarity-rs は、similarity の中の Rust プロジェクトのコード重複を検出する CLI ツールです。ただし、単純なテキストマッチングではありません。抽象構文木（AST）を使った構造的な比較により、変数名が違っても本質的に同じ処理をしている関数を見つけ出せます。例えば、以下の 2 つの関数は変数名が違いますが、similarity-rs は「これらは似ている」と判断できます。fn calculate_total(items: Vec<i32>) -> i32 {    let mut sum = 0;    for item in items {        sum += item;    }    sum}fn add_numbers(values: Vec<i32>) -> i32 {    let mut result = 0;    for value in values {        result += value;    }    result}テキストベースの diff ツールなら「全然違う」と判断する場合でも、similarity-rs は「構造が同じ」と判定できます。技術スタックの全体像similarity-rs の核となる技術は 2 つです。tree-sitter - Rust コードを解析して AST を生成APTED (All Path Tree Edit Distance) - 2 つの AST の距離を計算この 2 つを組み合わせることで、「コードの意味的な類似度」を数値化しています。なぜtree-sitterなのか？tree-sitter は、GitHub が開発した高速でインクリメンタルなパーサーです。rustc の手書きパーサーと比べると初回パースは 2-3 倍遅いですが、以下の利点があります。インクリメンタルパース: コードの一部が変更されたとき、変更部分だけ再パースできる堅牢性: 構文エラーがあっても部分的にパースを続行できる多言語対応: 同じインターフェースで複数の言語に対応実測値は次のとおりです。2157行のRustファイル（約64KB）のパース時間：- 初回: 約6.48ms- インクリメンタル更新: 1ms未満- スループット: 約9908 bytes/ms初回パースで約 6.48ms、インクリメンタル更新では 1ms 未満という実測値が得られています。ASTベース比較の仕組みStep 1: コードをASTに変換するまず、Rust コードを tree-sitter でパースします。use tree_sitter::{Parser, Language};let mut parser = Parser::new();parser.set_language(&tree_sitter_rust::LANGUAGE.into())    .expect("Error loading Rust grammar");let source_code = "fn test() { println!(\"hello\"); }";let tree = parser.parse(source_code, None).unwrap();生成される AST は、以下の階層構造になります。source_file└── function_item    ├── fn (keyword)    ├── identifier: "test"    ├── parameters    └── block        └── macro_invocation            └── ...Step 2: 関数を抽出するAST から関数定義を抽出します。この時、以下のような工夫がされています。fn extract_functions(tree: &Tree, source: &str) -> Vec<Function> {    let mut functions = Vec::new();    let root = tree.root_node();        fn visit_node(node: Node, source: &str, functions: &mut Vec<Function>) {        match node.kind() {            "function_item" => {                // テスト関数は除外                if !is_test_function(&node, source) {                    functions.push(Function::from_node(node, source));                }            }            "impl_item" => {                // implブロック内のメソッドも処理                for child in node.children() {                    if child.kind() == "function_item" {                        if !is_test_function(&child, source) {                            functions.push(Function::from_node(child, source));                        }                    }                }            }            _ => {                // 再帰的に子ノードを探索                for child in node.children() {                    visit_node(child, source, functions);                }            }        }    }        visit_node(root, source, &mut functions);    functions}注目すべき点として、テスト関数は自動的に除外されます。以下の 3 つの方法で検出します。#[test] 属性がついている関数test_ で始まる関数名（Rust の慣習）#[cfg(test)] モジュール内の関数これにより、本番コードの重複だけに集中できます。Step 3: 木構造の編集距離（TSED）を計算するここが最も興味深い部分です。2 つの AST がどれだけ「似ているか」を測定するために、Tree Edit Distance（木構造の編集距離）を使用します。木構造の編集距離とは？木構造を別の木構造へ変換する際に必要な「編集操作の最小回数」です。編集操作は 3 種類あります。Insert（挿入）: ノードを追加Delete（削除）: ノードを削除Rename（名前変更）: ノードのラベルを変更例を示します。Tree 1:          Tree 2:   A                A  / \              / \ B   C            B   D編集操作：1. C を D に Rename編集距離 = 1APTEDアルゴリズムsimilarity-rs は、APTED (All Path Tree Edit Distance) アルゴリズムを使用しています。これは 2015-2016 年に Pawlik と Augsten が発表したアルゴリズムで、以下の特徴があります。最適な分解戦略: 木を最も効率的に分解して計算動的計画法: 部分問題の結果をメモ化して再利用時間計算量: O(n·m) - 理論的に最適実装の概要は以下のとおりです。fn calculate_similarity(tree1: &TreeNode, tree2: &TreeNode, options: &TSEDOptions) -> f64 {    // APTEDで編集距離を計算    let edit_distance = compute_edit_distance(tree1, tree2);        // 正規化：類似度スコア（0.0〜1.0）に変換    let max_nodes = max(tree1.node_count(), tree2.node_count());    let base_similarity = 1.0 - (edit_distance as f64 / max_nodes as f64);        // サイズ差ペナルティを適用（オプション）    if !options.no_size_penalty {        let size_ratio = min_size as f64 / max_size as f64;        base_similarity * size_ratio    } else {        base_similarity    }}重要な発見として、ACL 2024 の研究論文（Song et al.）によると、以下の重みが最適とされています。Insert: 0.8Delete: 1.0Rename: 1.0この重みは実験によって導き出されたもので、48 以上のプログラミング言語で有効性が実証されています。ただし、similarity-rsの現在のデフォルト実装では異なる設定が使用されています。Rename: 0.3（デフォルト）Delete: 1.0Insert: 1.0研究論文で推奨される最適値とは異なりますが、--rename-costオプションで調整可能です。パフォーマンス最適化の技術1. Rayonによる並列処理similarity-rs の最大の強みの 1 つが、Rayon を使った並列処理です。use rayon::prelude::*;// ファイルを並列処理files.par_iter()    .flat_map(|file| extract_functions(file))    .collect()// 関数比較も並列化functions.par_iter()    .enumerate()    .flat_map(|(i, func1)| {        functions[i+1..].par_iter()            .map(|func2| compare_functions(func1, func2))    })    .filter(|similarity| similarity.score > threshold)    .collect()Rayon の優れた特徴は次のとおりです。ワークスティーリング: CPU コア間で自動的に負荷分散データ競合フリー: Rust の型システムが保証（Send + Syncトレイト）ゼロ同期オーバーヘッド: データ共有が不要な場合線形スケーラビリティ: CPU コア数に応じてほぼ線形に高速化実際のベンチマークでは、中規模ファイルで逐次処理比16倍の高速化が確認されています。2. ブルームフィルタによる事前フィルタリングTypeScript 版（similarity-ts）で先行実装され、Rust 版でも部分的にサポートされています。高速化に大きく貢献するテクニックです。struct AstFingerprint {    bloom_filter: BloomFilter,           // 確率的集合メンバーシップ    node_types: HashSet<NodeKind>,    signature: u64,                      // ハッシュベース署名}fn quick_reject(&self, func1: &FunctionDef, func2: &FunctionDef) -> bool {    let intersection = self.bloom_filter        .estimate_intersection(&func1.fingerprint, &func2.fingerprint);        let estimated_similarity = intersection / max(func1.size, func2.size);    estimated_similarity < self.min_similarity_threshold}この手法による効果は次のとおりです。比較回数を 70-90%削減偽陽性率 1%未満TypeScript 版で約 4 倍の高速化を実現明らかに違う関数ペアを高価な TSED 計算の前に除外できるため、全体の処理時間が 70-90%削減されます。Rust 版での実装状況は次のとおりです。crates/core/src/ast_fingerprint.rsにブルームフィルタの基礎実装が存在--no-fastオプションでブルームフィルタを無効化可能TypeScript 版ほど最適化されていないが、将来的な改善が期待される3. メモリ最適化の工夫Rust の所有権システムとゼロコスト抽象化を活かした最適化がいくつも施されています。ライフタイム注釈によるゼロコピーの例を示します。pub struct FunctionComparison<'a> {    func1: &'a FunctionDefinition,    func2: &'a FunctionDefinition,    similarity: f64,}データをクローンせず、参照を渡すだけで済みます。イテレータチェーンによる変換の例を示します。let similar_pairs: Vec<_> = functions.iter()    .enumerate()    .flat_map(|(i, f1)| {        functions.iter()            .skip(i + 1)            .filter_map(|f2| {                let sim = calculate_similarity(f1, f2);                (sim > threshold).then_some((f1, f2, sim))            })    })    .collect();この書き方の利点は次のとおりです。イテレータチェーンはタイトなループにコンパイルされる中間値のヒープアロケーションが発生しない遅延評価により、collectされるまで計算しない実際の使い方と出力フォーマット基本的な使い方# カレントディレクトリを解析similarity-rs .# 類似度の閾値を指定（デフォルト: 0.85）similarity-rs . --threshold 0.9# テスト関数をスキップsimilarity-rs . --skip-test# ファイル間の比較も有効化similarity-rs . --cross-file# コードスニペットを出力に含めるsimilarity-rs . --print# 最小トークン数を指定（小さい関数を除外）similarity-rs . --min-tokens 50出力の読み方Duplicates in src/utils.rs:────────────────────────────────────────────────────────────src/utils.rs:10 | L10-15 similar-function: calculateSumsrc/utils.rs:20 | L20-25 similar-function: addNumbersSimilarity: 85.00%, Priority: 8.5 (lines: 10)────────────────────────────────────────────────────────────src/utils.rs:30 | L30-40 similar-function: processDatasrc/handlers.rs:50 | L50-60 similar-function: handleRequestSimilarity: 92.00%, Priority: 11.5 (lines: 12)Priority は次の計算式で求められます: 行数 × 類似度スコアこれにより、影響度の高い重複（長くて似ている）を優先的に見つけられます。VSCode 互換の出力フォーマットを採用しており、ターミナルからファイル名をクリックすることで該当箇所に直接ジャンプできます。処理フローの全体像similarity-rs がどのように動作するのか、全体の流れを説明します。1. ファイル検索   └─> ディレクトリを再帰的にスキャンして.rsファイルを検索   2. パース段階   └─> 各ファイルに対して:       ├─> tree-sitterがソースをASTにパース       └─> ASTから関数ノードを抽出       3. フィルタリング段階   └─> 各関数に対して:       ├─> 最小行数/トークン数をチェック       ├─> テスト関数かチェック（--skip-test有効時）       └─> 合格すれば候補プールに追加       4. 特徴抽出（高速モード）   └─> ブルームフィルタ用のAST特徴を抽出   └─> 各関数のブルームフィルタを構築   5. 候補ペア生成   └─> 比較する関数ペアを生成       ├─> 同一ファイル内ペア（デフォルト）       └─> ファイル間ペア（--cross-file時）       6. ブルームフィルタ事前フィルタリング   └─> ブルームフィルタで高速チェック   └─> 明らかに異なるペアを除外   7. TSED計算   └─> 残りのペアに対して:       ├─> APTEDで木編集距離を計算       ├─> サイズペナルティを適用（有効時）       └─> 類似度スコアに正規化       8. 閾値フィルタリング   └─> 類似度 >= 閾値のペアを保持   9. 出力生成   └─> 結果をフォーマット（JSONまたは人間可読）   └─> --printフラグ時はコードスニペットを含むTypeScript版（similarity-ts）との比較mizchi さんのプロジェクトには、TypeScript 版も存在します。各実装の特徴を比較します。アーキテクチャの違い 側面  similarity-ts  similarity-rs  パーサー  oxc-parser（Rust製）  tree-sitter-rust  メモリ管理  アリーナアロケーション  標準ヒープ  高速モード  ブルームフィルタ完全実装  部分的実装  型チェック  実験的サポート  実験的サポート（--experimental-types） パフォーマンス比較実際のベンチマーク結果に基づく比較を示します。similarity-rs（Rust 版）の利点は次のとおりです。中規模ファイルで約 16 倍高速（ネイティブコードの効率性）メモリ使用量が一定（Rc による参照カウント）大規模ファイルでも安定動作（TypeScript は OOM エラー発生）ネイティブ Rust コード（FFI オーバーヘッドなし）Rust 固有機能（#[test]属性の検出など）similarity-ts（TypeScript 版）の利点は次のとおりです。小規模ファイルではやや高速（0.74x、プロセス起動オーバーヘッドなし）ブルームフィルタ高速モードで約 4 倍高速化oxc-parser による高速パース（swc より 3 倍高速）アリーナアロケーションによるキャッシュ局所性向上JavaScript エコシステムとの統合が容易言語固有機能similarity-ts の機能は次のとおりです。型類似度検出クラス比較サポートデコレータサポートsimilarity-rs の機能は次のとおりです。implブロック解析テスト関数フィルタリングトレイト実装検出研究基盤と理論的背景similarity-rs の背後には、しっかりとした研究基盤があります。TSED研究論文（Song et al., ACL 2024）この研究では、48 以上のプログラミング言語で TSED の有効性が実証されました。BLEU および Jaccard 類似度と 0.6-0.8 の相関実行一致に関して意味論的メトリクスより高精度最適重み: Insert=0.8、Delete=1.0、Rename=1.0APTEDアルゴリズム（Pawlik & Augsten, 2015-2016）木編集距離の堅牢な実装を提供し、メモリ使用量を抑制最適な分解戦略により O(n·m) の時間計算量で動作以前のアルゴリズム（RTED、Demaine など）を凌駕学術的にも裏付けられた手法を使っている点は信頼性が高いです。実用例：リファクタリング計画の立て方実際の使用方法とリファクタリングへの活用方法を説明します。Step 1: 重複コードを検出similarity-rs . --threshold 0.85 --skip-test > duplicates.txtStep 2: 優先度の高い重複を確認出力の Priority スコアを見て、影響の大きい重複から着手します。Priority: 11.5 (lines: 12, similarity: 92%)Step 3: リファクタリング方針を決定検出された重複コードを見て、以下を判断します。共通化できる場合共通関数として抽出部分的に共通化できる場合共通部分を関数として抽出差分をパラメータ化偶然の重複である場合本質的に異なる処理なので、そのままStep 4: 継続的なモニタリングCI/CD パイプラインに組み込んで、新しい重複が生まれないか監視します。# .github/workflows/code-quality.yml- name: Check code duplication  run: |    similarity-rs . --threshold 0.85 --skip-test    if [ $? -ne 0 ]; then      echo "Warning: Code duplication detected"      # Slackに通知するなど    fi制限事項と今後の展望現在の制限公式ドキュメントにも明記されていますが、similarity-rs は実験段階です。プロダクション環境での検証が不十分ブルームフィルタが部分的実装（similarity-ts ほど最適化されていない）マクロヘビーなコードには制限があるrustc パーサーより 2-3 倍遅い（初回パース時）既知の問題（KNOWN_ISSUES.md より）は次のとおりです。Enum similarity detection: 構造的に同一の Enum でも約 43%の類似度しか検出されない原因: Enum の variant 名が value として扱われ、rename_cost パラメータで適切に処理されない回避策: Enum 比較時は閾値を 0.4-0.5 に下げるStruct similarity detection: 正常に動作（90%以上の類似度を検出）similarity-rsから学んだことsimilarity-rs を深掘りした結果、このツールから多くの重要な学びを得ることができました。まず最も印象的だったのは、ASTベース解析の威力です。従来のテキストベースの類似度検出では、表面的な文字列の一致に頼るため、変数名やコメントの違いによって本質的に同じコードを見逃してしまうことがありました。しかし、AST ベースのアプローチでは構造的な類似性を捉えることができます。変数名が異なっていても、処理のロジックや制御構造が同じであれば、それを的確に検出できる点は非常に強力です。次に感銘を受けたのは、Rust の型システムが可能にする最適化です。Rust の所有権システムは、メモリ安全性をコンパイル時に保証します。さらに、ゼロコスト抽象化により、高レベルな記述をしながらも実行時のオーバーヘッドを最小限に抑えられます。加えて、充実した並行処理プリミティブにより、マルチスレッド処理を安全に記述できます。これらの特性を組み合わせることで、安全性とパフォーマンスを両立したツールの実装が実現されています。また、実装の随所に見られる実用的な最適化の積み重ねも注目に値します。ブルームフィルタによる事前フィルタリングで不要な比較を削減し、Rayon を活用した並列処理で処理速度を向上させています。さらに、テスト関数の自動除外や最小トークン数によるフィルタリングなど、実際の開発現場で役立つ工夫が随所に施されています。このような小さな最適化の積み重ねが、理論だけでなく実用的なツールを作り上げる鍵となることを実感しました。最後に、このツールはACL 2024の論文をベースにした実装である点も重要です。学術研究で提案されたアイデアを、実際に動作するソフトウェアとして具現化しており、理論と実践の橋渡しをしている好例と言えます。研究成果を実装に落とし込む過程で、どのような工夫や最適化が必要になるのかを学ぶことができました。おわりに冒頭で述べた「結合度を測って適切にリファクタリングを促すツール」について、similarity-rs から学んだアプローチを応用できます。AST ベースの解析で構造的な類似性を捉える並列処理で大規模コードベースにも対応優先度スコアでリファクタリングの優先順位を示すCI/CD 統合で継続的にコード品質を監視similarity-rs の実装を理解したことで、自分が作りたいツールの具体的なイメージが明確になりました。GitHub リポジトリで実装の詳細を確認できます。コードは読みやすく構成されているため、Rust の学習にも適した教材です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon参考文献mizchi/similarity - GitHubZenn記事：TypeScript/Rustで高速なコード類似度検出ツールを作るtree-sitter - Official DocumentationRayon - Data Parallelism in Rust]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Trayce, a Raycast Extension for Tokyo AI Hackathon 2025]]></title>
            <link>https://speakerdeck.com/ota1022/trayce-a-raycast-extension-tokyo-ai-hackathon-2025</link>
            <guid isPermaLink="false">https://speakerdeck.com/ota1022/trayce-a-raycast-extension-tokyo-ai-hackathon-2025</guid>
            <pubDate>Thu, 30 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[The pitch deck for a Raycast extension called Trayce, created at the Tokyo AI Hackathon.https://raycast.connpass.com/event/369928/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonのlistとsetでの値の含み判定の所要時間について]]></title>
            <link>https://zenn.dev/akasan/articles/b9e7806e438f8f</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b9e7806e438f8f</guid>
            <pubDate>Wed, 29 Oct 2025 11:40:49 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonのlistとsetでデータが含まれているかどうかを判定するためのロジックの所要時間の差について調べてみました。Pythonの仕様として、単純にデータを列挙しておきたいだけの場合にlistを利用せずsetを利用する方が良い場合もあり個人的に気をつけていましたが、以下の記事をみて実際にlistとsetでどれくらい差が出るかを調べてみようと思いました。今回は値の一覧に特定の値が含まれているかを判定するのにかかる時間を調べてみました。https://medium.com/the-pythonworld/stop-using-if-x-in-list-heres-the-fas...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：NumPyやpandasデータをRay Dataで取り込む]]></title>
            <link>https://zenn.dev/akasan/articles/db0b5b634d453d</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/db0b5b634d453d</guid>
            <pubDate>Tue, 28 Oct 2025 14:21:11 GMT</pubDate>
            <content:encoded><![CDATA[今回はRay Dataを利用して、NumPyとpandasのデータを読み込む方法をまとめます。 早速試してみる内容はこちらを参考にしています。https://docs.ray.io/en/latest/data/loading-data.html#loading-data-from-other-libraries 環境構築uvを利用して以下のように構築します。uv init ray_data_numpy_pandas -p 3.12cd ray_data_numpy_pandasuv add "ray[data]" numpy pandas NumPyからデータを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ソフトウェアエンジニアにおける才能という幻想、あるいは成長を阻む最大の敵について]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/28/113009</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/28/113009</guid>
            <pubDate>Tue, 28 Oct 2025 02:30:09 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「才能がない」と言われたことがあるでしょうか。それとも、友人や知り合いと自分を比べて、自分で自分にそう言い聞かせたことがあるでしょうか。学生の頃からエンジニアを志してきた私は、コンテストで優秀な成績を残す人たちを目の当たりにしてきました。大手IT企業に入社し、優秀な同期と出会いました。勉強会やカンファレンスに足を運び、そこで出会った人たちの軌跡を追ってきました。華々しくスタートアップを立ち上げた人、革新的なプロダクトを生み出した人、OSSコミュニティで名を馳せる人。一方で、いつの間にか表舞台から姿を消した人もいます。これらがごく一部の狭い世界でしかないことも、自覚しています。そして今、インターンシップやワークショップで若手エンジニアと接する機会が増えました。3年ほど前に始めたこの活動──正直に言うと、自分が未熟なまま始めてしまったという不安は、今でもどこかにあります。彼らと一緒に作業する中で、「才能がない」と自己評価する学生やインターン生に出会うことがよくあります。彼らは真剣な表情で「自分には向いていないかもしれません」と告げます。コードを書くのが遅い。エラーの意味が理解できない。他の人は簡単にできることが、自分には難しい──そう語る彼らの目には、諦めと不安が混じっています。私はその度に、ある問いを投げかけます。「才能って、何だと思う?」「君には才能がある」とも「才能なんて関係ない」とも言わず、まず考えてもらう。しかし大抵の場合、明確な答えは返ってきません。実は、私もかつて、才能という言葉に深く囚われていました。コンテスト会場で、企業の開発フロアで、勉強会の懇親会で、私は何度も「天才」と呼ばれるエンジニアたちに出会いました。彼らは難解なアルゴリズムを一瞬で理解し、複雑なバグを数分で特定し、誰も思いつかないような解決策を次々と生み出していました。そして私は何度も思いました。「自分には才能がない」と。しかし、多くの「一流」と呼ばれる人々と接し、彼らの日常を観察し、そして時には彼らが立ち止まる瞬間や、消えていく瞬間も目撃する中で、ある重要な事実に気づきました。才能という言葉は、実は成長を阻む最大の敵なのかもしれない。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。技術力という幻想才能について語る前に、まずソフトウェアエンジニアリングにおける「技術力」とは何かを整理しておく必要があります。我々の文脈では、才能という言葉はこの技術力と結びつけて語られることが多いためです。技術力という言葉の曖昧さ私たちは「技術力が高い」「技術力が低い」という言葉を安易に使いがちです。しかし、その実態は何でしょうか。率直に言えば、ソフトウェアエンジニアの「技術力」と呼ばれるものの多くは、実は「ちょっと詳しい」「似たようなトラブルを経験している」「これとこれを組み合わせれば行けそう」という程度のものです。私が使ってきた「エンジニアリング」という言葉にも、工学的な要素はあまり含まれていませんでした。正しくは「テクニック」──つまり、実践的な技術や方法論の集積です。特別なスキルというよりは、日々の積み重ねで身につく経験知なのです。では、技術力とは何なのか。私の観察では、それは大きく二つの軸に分解できます。一つは「経験の蓄積」、もう一つは「洞察力としてのセンス」です。センスは知識からはじまる作者:水野学朝日新聞出版Amazon第一の軸：経験の蓄積技術力の第一の要素は、経験の蓄積です。これは、しばしば「同じ失敗を繰り返さない力」として評価されます。具体的には、こういうことです。あるエラーに遭遇したとき、以前に似たようなエラーを見たことがあれば、解決は早くなります。データベースのデッドロック、非同期処理のタイミング問題、キャッシュの不整合──こうした問題は、一度経験していれば「ああ、これか」と気づけます。これは確かに価値のある能力です。経験豊富なエンジニアが重宝されるのは、このためです。しかし、これを「才能」と呼ぶのは適切でしょうか。違います。これは単に時間をかけて様々な問題に向き合った結果であり、誰でも積み重ねられるものです。早く始めた人、多く失敗した人が、より多くの経験を持っているだけです。具体と抽象作者:細谷 功dZERO（インプレス）Amazon第二の軸：洞察力としてのセンス技術力のもう一つの要素、それが「センス」です。音楽をやっている人たちの中で「あいつは耳が良い」と評価される能力があります。単に楽器を弾く技術だけでなく、音のバランス、リズムの微妙なズレ、和音の響き方──こうした細部を感じ取る力のことです。ソフトウェアエンジニアリングにも、これに似たものがあります。コードを見たとき、「このコード、何か変だな」と直感的に感じる。実行する前から「ここでバグが出そう」と予感する。設計図を見て「この構造は将来的に問題になる」と察知する。これが、エンジニアにおける「センス」です。重要なのは、これは単なる経験の蓄積とは質的に異なるということです。同じ年数働いていても、このセンスを持つ人と持たない人がいます。では、このセンスとは何なのでしょうか。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazonセンスの正体──三つの具体的な現れ方センスは抽象的な概念に聞こえますが、実は具体的に分解できます。私の観察では、センスは主に三つの形で現れます。1. 細部への注目力センスのあるエンジニアは、コード全体の機能だけでなく、細部のリズムやバランスに気づきます。例えば、関数の長さのバランス。あるファイルに25行の関数と5行の関数が混在しているとき、「なぜこの差があるのか」と気づきます。命名の一貫性。ある場所ではgetUserDataと書き、別の場所ではfetchUserと書いているとき、その揺らぎに違和感を覚えます。これらは動作に直接影響しないこともあります。でも、コードの「匂い」として現れます。そして、この匂いに気づけるかどうかが、センスの有無を分けます。ルールズ・オブ・プログラミング ―より良いコードを書くための21のルール作者:Chris Zimmermanオーム社Amazon2. 構造の美しさへの感受性センスのあるエンジニアは、「美しいコード」と「醜いコード」を区別できます。そして最も重要なのは、なぜ美しいと感じるのか、その理由を言語化できることです。「この関数は単一責任原則を守っているから美しい」「この命名は意図が明確に伝わるから良い」「この抽象化は読みやすさと柔軟性を両立しているから綺麗」単に「良い」「悪い」と感じるだけでなく、その判断の根拠を意識できる。これがセンスです。そして、この言語化能力が、他者にも伝えられる知見へと昇華されます。Good Code, Bad Code ～持続可能な開発のためのソフトウェアエンジニア的思考作者:Tom Long秀和システムAmazon改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazon3. 問題の本質を見抜く力最も価値が高いのは、表面的な問題の背後にある本質的な問題を見抜く力です。例えば、バグが報告されたとします。表面的には「nullポインタ例外」かもしれません。しかし、センスのあるエンジニアは、その背後に「状態管理の設計が不適切」という本質的な問題があることに気づきます。エラーログを見て、「このエラーが頻発しているということは、そもそもこの処理フローに問題がある」と洞察します。パフォーマンスの問題を見て、「これは単にクエリの最適化の問題ではなく、データモデルの設計から見直すべき」と判断します。この「一歩踏み込んで問題を捉える力」こそが、経験を超えたセンスの核心です。ライト、ついてますか　問題発見の人間学作者:ドナルド・C・ゴース,ジェラルド・M・ワインバーグ共立出版Amazonセンスは訓練できるのかここまで読んで、「じゃあセンスは才能じゃないか」と思うかもしれません。違います。センスも訓練できます。なぜなら、センスとは突き詰めれば「何に注目するか」という習慣と、「それを面白がれるか」という姿勢だからです。どちらも意識的に育てることができます。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon訓練法1：意識的な観察の習慣最初は意識的に練習します。コードレビューをするとき、ただ「動くか動かないか」だけでなく、以下の点に注目してみます。関数の長さのバランスは適切か命名に一貫性はあるか、揺らぎは意図的か抽象度の上下動に違和感はないかコメントの密度は適切か変数のスコープの範囲は適切か最初は面倒です。でも、こうした細部に意識的に注目する習慣を続けていると、やがて自然と細部が目に入るようになります。これがセンスを磨くということです。訓練法2：本質を掴む読み方優れたエンジニアのコードを読むとき、ただ写経するのではなく、その背後にある思考を読み取ろうとします。なぜこの構造を選んだのかなぜこの命名にしたのかなぜこの順序で処理しているのかなぜこの部分だけ抽象化したのかそして、そこから本質的な要素を抽出し、自分のコードに応用する。この「本質を掴む」プロセスを繰り返すことで、表面的なパターンの暗記を超えた理解が生まれます。訓練法3：面白がる回路を作る最も重要なのは、問題を面白がる姿勢を育てることです。センスのあるエンジニアは、エラーや問題を「厄介だ」ではなく「興味深い」と捉えています。この姿勢は、選択できるものです。最初は意識的に「これは面白い」と自分に言い聞かせます。「このバグ、再現条件が複雑で面白い」「このエラーメッセージ、何を伝えようとしているのか興味深い」「この設計の問題、どう解決すべきか考えるのが楽しい」こうした「面白がる回路」を作ることが、センスを磨く本質です。すると徐々に、本当に面白く感じられるようになってきます。そして、面白がれるようになると、自然と深く考えるようになり、結果としてセンスが磨かれます。技術力もセンスも、どちらも成長可能結局のところ、技術力を構成する二つの軸──経験の蓄積とセンスという洞察力──は、どちらも成長可能な能力です。経験は、時間をかけて多くの問題に向き合うことで自然と積み重なります。失敗を恐れず、様々なことに挑戦することで、経験値は増えていきます。センスは、意識的な訓練によって磨かれます。細部に注目し、本質を掴もうとし、問題を面白がることで、徐々に洞察力が深まっていきます。どちらも「才能」という固定的な能力ではありません。時間と意識的な努力によって育てられるスキルなのです。「あの人は技術力がある」と言われる人は、単に先に始めて多くの経験を積んだか、意識的にセンスを磨く習慣を持っているか、あるいはその両方です。そして、その両方とも、今からでも始められます。才能という名の逃避「才能がない」という言葉は、一見すると謙虚に聞こえます。しかし実のところ、これは危険な自己欺瞞です。なぜなら、才能という言葉を使った瞬間、私たちは変化の可能性を放棄してしまうからです。「才能がないからできない」は、「努力してもどうせ無理」と同義です。そして一度この思考に陥ると、成長のための努力そのものが無意味に思えてきます。私自身、新人時代にこの罠に嵌っていました。新しい技術概念と格闘していた頃、何度もこう思いました。「自分にはこの考え方を理解する才能がないのだろう」と。そしてその思考は、学習を放棄する口実となりました。難しいドキュメントを読むことを避け、エラーメッセージと真剣に向き合うことから逃げました。でも、ある時気づきました。私が「才能がない」と諦めていた領域で活躍している先輩たちも、実は最初から理解していたわけではありませんでした。彼らは単に、私が避けていた苦痛と向き合い続けていただけだったのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon性格と人格才能を考える上で、重要な区別があります。それは性格と人格の違いです。性格とは、通常の日にどう反応するか──つまり、私たちの自然な傾向や気質のことを指します。一方で人格とは、困難な日にどう振る舞うか──つまり、意図的に選択される態度や行動のことです。この区別は、才能という概念を理解する上でとても重要です。私たちはよく、性格と人格を混同してしまいます。「私は物覚えが悪い」「集中力がない」「創造性がない」──これらは一見すると先天的な限界のように聞こえます。しかし実際には、これらの多くは人格、つまり訓練可能な能力の領域なのです。例えば、「集中力がない」と自己評価する人の多くは、実は集中する環境や方法を知らないだけかもしれません。スマートフォンの通知をオフにし、作業を25分単位に区切り、定期的に休憩を取る──こうした具体的な方法を実践することで、「集中力」は劇的に向上します。重要なのは、こうした能力を「才能」ではなく「性格スキル」として捉え直すことです。才能は固定的で変えられないものですが、スキルは練習によって向上させることができます。この視点の転換が、成長への扉を開くのです。世界一やさしい「才能」の見つけ方　一生ものの自信が手に入る自己理解メソッド作者:八木 仁平KADOKAWAAmazon不快感という成長の証才能という幻想から抜け出すために、もう一つ重要な認識があります。それは、学習における不快感の本質的な役割です。「快適に学べる」というのは、実は矛盾した概念かもしれません。スキルを真に習得するまで快適にはなれないのですが、習得する前の練習は必然的に不快だからです。そして人は、その不快感を避けようとします。これが、多くの人が成長の途中で挫折する根本的な理由です。Docker最適化の学習を例に取りましょう。BuildKitのキャッシュ戦略を理解しようとするとき、最初はかなり混乱します。レイヤーの仕組み、マウントの種類、キャッシュの無効化条件──これらの概念は最初、全く繋がらない断片として現れます。この混乱は不快です。だから多くの人は、「とりあえず動けばいい」と表面的な理解で妥協します。しかし、この不快感こそが成長の証なのです。脳が新しい構造を構築しようとしている証。既存の理解の枠組みが崩れ、新しい理解が生まれつつある証です。この不快感から逃げずに、むしろそれを「成長が起きている」というサインとして受け入れられるかどうか──それが、習得できる人とできない人を分ける分岐点になります。「快適なら、やり方が間違っている」という言葉があります。この言葉は、学習の本質を突いています。本当の成長は、常にコンフォートゾーンの外側で起きるのです。ネガティブ・ケイパビリティ　答えの出ない事態に耐える力 (朝日選書)作者:帚木　蓬生朝日新聞出版Amazon才能がないと言う前にインターンシップやワークショップで若手と一緒に作業をしていて気づいたことがあります。「才能がない」と自己評価する人の多くが、実は才能の問題ではなく、もっと基礎的なプロセスを飛ばしているだけだということです。syu-m-5151.hatenablog.comドキュメントを読んでいない「自分には向いていない」と言う学生がいました。コードがうまく動かないし、エラーが理解できないと。しかし彼は、エラーメッセージを実際には読み飛ばしていたのです。エラーメッセージには「Expected type X, but got type Y」と明確に書いてあります。しかし「type X」という文字列だけを拾って、期待される型と実際の型が違うという関係性を読み取っていませんでした。これは彼だけの問題ではありません。ドキュメントを「読んでいるつもり」でも、実際には自分の仮説に都合のよい部分だけを拾い読みしている人は驚くほど多いのです。APIのリファレンスに「このメソッドは非同期です」と書いてあっても、Promiseを返すのか、コールバックを受け取るのか、await可能なのか──書かれているはずの詳細を読んでいません。仮説を一つずつ潰していない別の学生は「バグが見つからない」と何時間も格闘していました。しかし彼は、複数の仮説を同時に追いかけて、どれも中途半端に確認していたのです。「ネットワークの問題かもしれない」と言いながらネットワークのログを確認せず、「データベースの問題かもしれない」と言いながらクエリを確認しない。問題解決には、仮説を一つずつ潰していくプロセスが必要です。この地道なプロセスを飛ばして、「なんとなく」で進めようとするから、何時間経っても解決しないのです。仮説行動――マップ・ループ・リープで学びを最大化し、大胆な未来を実現する作者:馬田隆明英治出版Amazon主語と述語を把握していない技術文書を読むとき、主語と述語の関係を曖昧にしたまま読み進めている人は非常に多いのです。「誰が」「誰に」「何を」しているのか──この基本的な構造を把握しないまま、「なんとなく」で理解したつもりになっています。小さなことの積み重ねエラーメッセージをちゃんと読む。仮説を一つずつ潰す。主語と述語を把握する。誰でもできることです。しかし、この「小さなこと」の積み重ねが、「才能がある」ように見える人と「才能がない」と思い込む人を分けています。才能があるように見える人は、これらの基礎的なプロセスを、意識的か無意識的に実践しています。これらは訓練可能です。才能ではありません。最初は意識的にやる必要があります。めんどくさいと感じるかもしれません。でも、この「めんどくさい」基礎作業を飛ばすから、結果的に何倍も時間がかかってしまうのです。なぜ、ちゃんと読めないのか「ちゃんと読むことによる成功体験」が積めていない──これが、根本的な問題かもしれません。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonインスタント化と「モヤモヤ」への耐性の喪失私たちは今、インスタントで断片的な刺激に取り巻かれています。YouTubeのレコメンド、TikTokの短い動画、LINEスタンプ──一定のリズムで繰り返されるインスタントで分かりやすい感覚やコミュニケーションが蔓延しています。スマホを持つことで、即時的な満足にいつでもアクセスできる状態にあり、「消化しきれなさ」「難しさ」「モヤモヤ」といった時間もコストもかかるものは人気がなくなっています。技術ドキュメントを読むことは、まさにこの「モヤモヤ」との戦いです。一読してすぐに理解できるものではありません。何度も読み返し、実際に試し、エラーに出会い、また読み返す。この時間のかかるプロセスが、インスタント化した感覚に慣れた私たちには耐えがたいのです。新しい技術を学ぶとき、最初は「モヤモヤ」します。でも、このモヤモヤした状態を抱えたまま、読み続け、試し続けることでしか、深い理解には到達できません。ChatGPTやClaudeに「要約して」と頼んでしまう。確かに、それでスッキリはします。でも、その過程で失われるものがあります。孤独と孤立の喪失スマホによる常時接続の世界では、何か一つのことに取り組み、一つのことに没頭する＜孤立＞が喪失しています。反射的なコミュニケーションを積み重ねるということは、相手の人格や心理状態を想像しないコミュニケーションです。同時に、退屈に耐えきれず、何か刺激やコミュニケーションを求めてスマホをいじってしまい、自分一人で時間を過ごす＜孤独＞も失われかけています。スマホ時代に必要なのは孤独と孤立であり、それらがあってこそ、自分を浸している感覚に耳を澄ませ、刺激的な経験と折り合いをつけることができます。技術ドキュメントを読むことは、まさにこの「孤立」を必要とします。一人で、ドキュメントと向き合う時間。このシンプルな行為が、現代では驚くほど難しくなっています。ネガティブ・ケイパビリティの欠如ネガティブ・ケイパビリティとは、「結論づけず、モヤモヤした状態で留めておく能力」です。把握しきれない謎をそのまま抱えておくことで、そこから新しい何かをどこまでも汲み取ろうとする姿勢のことです。これは、他者の経験を理解したり、技術を学んだりするときに必要です。謎を安易に「自分のわかる範囲」に回収しない能力と言えます。新しい技術を学ぶとき、すぐに「わかった」と思いたくなります。でも実際には、わかっていないことだらけです。このモヤモヤした状態を抱えたまま、読み続け、試し続ける。この能力が、現代人には欠けているのかもしれません。自己啓発の罠と他者の想像力悩みや困難を抱えている人は、「自分の直観に従って判断しろ」「自分の情熱に従え」というメッセージに心を揺さぶられます。しかし、このアプローチには内なる声は一つであり、その声こそ自分を然るべき一つの進路へと導いてくれるはずという前提があります。他者の想像力は、「ノイズ」としてラベリングされてしまいます。私たちは、一枚岩のような存在ではありません。自分の内側にはいくつもの声が発せられています。「他者に見られる自分」も自分の重要な構成要素となるので、他者はノイズどころか、自分を豊かに育てるものです。「才能がない」という言葉も、実はこの自己啓発の罠と表裏一体です。「才能がないから無理」は自己責任の裏返しです。でも実際には、他者の想像力を借りること、ドキュメントを丁寧に読むこと、先輩に質問することは、ノイズではなく成長の糧なのです。「自分の頭で考える」の代わりに、「他人の頭で考える」「他者の想像力を自分に取り入れる」ことが大切です。才能ではなく、学び方の問題「才能がある」と見なされる人々を注意深く見ると、彼らの多くは特別な能力を持っているわけではありません。彼らは効果的な学び方を知っているだけなのです。例えば、指摘と助言の違いを理解している人は、より速く成長します。「このコードのどこが悪いですか?」は指摘を求める質問で、過去の実績に焦点を当て、しばしば批判的な応答を引き出します。一方で「このコードをより保守性の高いものにするにはどうアプローチすべきでしょうか?」は助言を求める質問で、未来に焦点を当て、建設的な提案を引き出します。この小さな違いが、学びの質を大きく変えます。才能があるように見える人は、こうした学び方の技術を実践しています。彼らは「分からない」と素直に認め、「教えてください」と謙虚に頼み、そして得られた助言を素直に実践します。これは才能ではなく、態度の問題なのです。学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon後退も成長のプロセスの一部才能という概念を手放すと、もう一つ重要な認識が生まれます。それは、成長が必ずしも直線的ではないということです。私たちは、成長を一方向的な進歩として捉えがちです。しかし実際の成長は、螺旋を描くように進んでいきます。前進し、停滞し、時には後退し、そしてまた前進します。この後退期を「才能がない証拠」として捉えるか、「成長のための再編成」として捉えるかで、その後の軌道は大きく変わります。技術を学ぶ過程でも、この現象は頻繁に起きます。新しいフレームワークを学び始めた当初は順調に進みます。しかし、ある程度理解が深まると、突然全てが分からなくなる瞬間が来ます。これは実は、表面的な理解から深い理解へと移行する兆候なのです。しかし多くの人は、この瞬間を「やはり自分には才能がない」と解釈し、学習を放棄してしまいます。人は前進するために時に立ち止まり、後退し、そしてまた前進した先には以前よりも大きく飛躍しています。このプロセスを理解することで、停滞期や後退期を前向きに捉え直すことができます。それは失敗ではなく、次の飛躍のための準備期間なのです。手を動かすことの救いエンジニアという仕事には、一つの大きな救いがあります。それは、手を動かしている間、才能への不安が消えるということです。「自分には才能がない」という悩みは、頭の中でぐるぐる回り始めると、どんどん大きくなります。でも「これを作りたい」と思って実装を始めた瞬間、その悩みはどこかに消えます。目の前にあるのは、具体的な問題だけです。エラーが出る。調べる。解決する。また詰まる。また調べる。この「詰まる→調べる→解決する」のサイクルを回すこと自体が、静かに自信を育てていきます。最初は1つのエラーに1時間かかったのが、30分になり、10分になる。その変化を実感するとき、「成長している」という手応えが得られます。理想ではなく、作りたいものを追う重要なのは、「優秀なエンジニアになりたい」という抽象的な目標ではなく、「このアプリを作りたい」「この機能を実装したい」という具体的な目標に向かって手を動かすことです。完璧主義に陥る人は、結果に過度な完成度を求めるあまり、小さな一歩を踏み出せません。「理想的なアーキテクチャを設計してから始めよう」「全ての技術を理解してから作ろう」──そう考えて、結局何も始められない。でも実際には、小さく作って、動かして、直して、また作る。このサイクルを回すことでしか、良いものは生まれません。一つのエラーを解決する。一つの機能を実装する。一つのテストを通す。この小さな積み上げが、気づけば大きなものになっています。綿密な計画よりも、不完全でも動く一歩の方が、はるかに価値があります。あえて視野を狭めろここで、少し逆説的なことを言います。特に若い時期には、根拠がなくても、自分を信じることが重要です。「才能という幻想」を批判してきたこの記事で、矛盾するように聞こえるかもしれません。しかし、「自分には才能がある」という固定的な思い込みと、「自分はできるようになる」という成長への信頼は、全く別物です。若いうちは、視野をあえて狭めることも必要です。「これが本当に正しい道なのか」「自分に向いているのか」──そんな冷静な自己分析ばかりしていると、一歩も踏み出せなくなります。時には、根拠のない自信を持って、盲信的に突き進むことも必要です。「プログラミングなんて簡単だろう」という、ある意味で無知ゆえの大胆さ。この「若気の至り」とも言える姿勢が、最初の一歩を踏み出させてくれます。その盲信的な姿勢が、いつか本当の自信に変わります。根拠のない自信が、実績という根拠を伴った自信になります。そして気づけば、最初は「嘘」だった「自分はできる」という言葉が、本当になっているのです。問題を面白がる力もう一つ、見落とされがちな視点があります。それは、学びにおける遊び心です。才能があるように見える人は、実はこの遊び心を持っています。彼らは学びを苦痛として捉えるのではなく、謎解きとして楽しんでいます。新しいバグに出会えば「面白い現象だ」と興味を持ち、理解できない概念に出会えば「理解できたら面白そうだ」と好奇心を抱きます。この姿勢は、才能ではなく選択です。同じ状況を「苦痛」として捉えるか「挑戦」として捉えるか──その選択が、長期的な成長の軌道を決めます。そして、この選択は意識的に訓練できます。義務として学ぶのではなく、探究心を持って取り組むとき、人は最も成長します。ぐちゃぐちゃ考える暇があったら才能があるかどうかなんて、作っているときには関係ありません。目の前のエラーメッセージは、あなたが才能があるかどうかなんて気にしていません。ただ、解決策を求めているだけです。ドキュメントを読む。エラーメッセージをちゃんと読む。仮説を立てて検証する。うまくいかなければ別の方法を試す。これらは全て、才能ではなく、プロセスです。コンテストで優秀な成績を残した人たちも、結局は同じことをしています。彼らが特別なのではありません。ただ、このプロセスを高速で回せるようになっただけです。そして、その高速化は、繰り返しによってしか得られません。自分が未熟だと不安に思いながらインターンシップを始めた私が、3年経って確信していることがあります。それは、手を動かし続けた人は、必ず前に進んでいるということです。才能について悩む時間を、1行でも多くコードを書く時間に変える。理想の自分について考える時間を、作りたいものを作る時間に変える。その積み重ねが、気づけば「成長」と呼ばれるものになっています。才能という言葉を使わないここまで読んで、一つの結論に至るかもしれません。それは、才能という言葉を使わないことの重要性です。「才能がある」「才能がない」──この二元論は、成長の可能性を見えなくしてしまいます。代わりに、より具体的で建設的な言葉を使うべきです。「まだ学んでいない」「まだ練習が足りない」「まだ自分に合った学び方に出会っていない」──こうした表現は、現在の状態を固定的なものではなく、変化可能なものとして捉えさせます。インターン生に技術を教える際も、この視点の転換を意識しています。「才能がない」という言葉を聞いたら、必ず問い返します。「具体的に、何が難しいと感じている?」と。すると、「才能」という曖昧な概念ではなく、具体的な課題が見えてきます。そして具体的な課題は、具体的な対策で解決できます。「あなたには向いていないかも」ではなく、「どういう環境や説明の仕方なら理解できるだろうか」と考えます。この視点の転換が、教育者として最も重要な態度なのかもしれません。では、才能という言葉を使わないとしたら、何を語るべきなのでしょうか。それは、成長のメカニズムそのものです。どうすれば効果的に学べるか。どうすれば困難に直面しても諦めずに続けられるか。どうすれば自分の可能性を最大限に引き出せるか──こうした実践的な問いに答えることが、才能という幻想よりもはるかに価値があります。これは抽象的な話ではありません。とても実践的な話です。毎朝同じ時間に起きる習慣。集中できる環境を整える工夫。失敗から学ぶための振り返りの時間。他者から助言を求める勇気──これらは全て、トレーニング可能なスキルです。そして、これらのスキルの蓄積が、才能と呼ばれるものの正体なのかもしれません。HIDDEN POTENTIAL 可能性の科学――あなたの限界は、まだ先にある (三笠書房　電子書籍)作者:アダム・グラント三笠書房Amazon時間という最も公平な資源才能という概念に対して、時間は最も公平な資源です。どんな人にも、1日は24時間しかありません。もちろん、その24時間をどう使えるかは、環境によって大きく異なります。しかし、与えられた時間の中で、何を選択するか──その選択の積み重ねが、最終的な差を生みます。才能がある人とない人の違いは、実は時間の使い方の違いなのかもしれません。才能があるように見える人は、学習に多くの時間を投資しています。しかしそれは、単純に勉強時間が長いという意味ではありません。むしろ、質の高い時間の使い方を知っているということです。例えば、同じ1時間でも、受動的にチュートリアルを見るのと、能動的に問題を解こうとするのでは、学びの質が全く異なります。同じエラーに出会っても、すぐに答えを探すのと、まず自分で考えてみるのでは、理解の深さが変わります。時間という公平な資源を、どう使うか。これは才能ではなく、戦略の問題です。そして戦略は、学ぶことができます。あっという間に人は死ぬから　「時間を食べつくすモンスター」の正体と倒し方作者:佐藤 舞（サトマイ）KADOKAWAAmazon停滞と努力の違い時間の使い方について語るとき、見落とされがちな重要な区別があります。それは、停滞と努力の違いです。Kubernetesのワークショップで、あるインターン生がServiceの概念に数日苦しんでいました。彼は毎日、同じドキュメントを読み返していました。「努力している」と本人は言いました。でも、彼は前に進んでいませんでした。よく話を聞くと、彼はそもそもネットワークの基礎を理解していませんでした。IPアドレスとは何か、ポートとは何か、DNSがどう動くのか──こうした土台がないまま、Kubernetesの抽象的な概念を理解しようとしていたのです。難しい問題に直面したとき、人は二つの道を選びます。一つは、理解できないまま同じ説明を何度も読み返し、同じ場所でぐるぐると回り続けること。もう一つは、「何が分からないのか」を見極めて、まずそこから順番に理解していくこと。前者を停滞と呼び、後者を努力と呼びます。停滞している人は、しばしば自分が努力していると思っています。長時間向き合っている。何度も試している。でも実際には、前提となる知識が欠けたまま、同じところで足踏みを繰り返しているだけなのです。本当の意味での努力とは、今の自分が理解できるところから始めることです。Kubernetesが難しいなら、まずネットワークの基礎から。ネットワークが難しいなら、まず自分のPCで2つのプログラムを通信させることから。この段階を踏んだ学び方こそが、努力の本質です。理解の速さには個人差があります。これは残酷な現実です。でも、人生という長い時間軸で見たとき、この速さの差は思ったほど大きくありません。むしろ、一歩ずつでも前に進み続けた人と、途中で立ち止まってしまった人の差の方が、はるかに大きいのです。時間は誰にも平等です。でも、その時間を「理解できない問題の前での空回り」に使うか、「今理解できることから順に積み上げていく前進」に使うか──この選択が、長期的には想像もできないほどの差を生みます。だから、ゆっくり急いでください。今日から始めて、でも焦らず、着実に。目の前の問題が難しすぎるなら、何が前提として必要かを見極めて、より基礎的なところから。その地道な積み重ねこそが、あなたを想像もしなかった場所へと連れて行ってくれます。超一流になるのは才能か努力か？ (文春e-book)作者:アンダース・エリクソン,ロバート・プール文藝春秋Amazonどうしようもなく満たされない性質についてここまで「才能という言葉を使わないこと」を言ってきましたが、最後に一つだけ、もしエンジニアに才能というものがあるとすれば何か、という問いに答えたいと思います。それは、どうしようもなく満たされない性質です。知りたいと思う。理解したいと思う。作りたいと思う。解決したいと思う。そして、その過程を楽しめる。それをしてないと、ちゃんと生きていけない。そういう性質。これは祝福でもあり、同時に呪いでもあります。なぜなら、これらの能力はコントロールできないことが多いからです。夜中の3時に突然コードのことを考え始める。休日なのに技術ドキュメントを読んでしまう。趣味と仕事の境界が曖昧になる。多くの不都合を抱えています。だから、あまり気にしなくて良いのです。才能と能力が一致しているのは、かなり稀です。「満たされなさ」を持っていても、それが必ずしも成果に結びつくわけではありません。逆に、その「満たされなさ」を持たずとも、優れたエンジニアになることは十分に可能です。自分に才能があるのかないのか。何者かになれる人となれない人の違いは何なのか。その境目はありません。「才能がある」とか「天才だ」というのは、原因ではなく結果に対して付けられる評価です。何かを成し遂げた後で、周りが「あの人には才能があったんだ」と言うだけです。始める前から、自分に才能があるかどうかなんて、誰にも分かりません。そして、それを気にする必要もありません。重要なのは、今、目の前にあることに取り組むかどうか。その選択だけです。ご冗談でしょう、ファインマンさん（上） (岩波現代文庫)作者:Ｒ．Ｐ．ファインマン岩波書店Amazonご冗談でしょう、ファインマンさん（下） (岩波現代文庫)作者:Ｒ．Ｐ．ファインマン岩波書店Amazonおわりに様々な場所で、様々な「才能」を目撃してきました。コンテスト会場、企業のオフィス、勉強会、ワークショップ──華々しく成功した人も、静かに立ち去った人も、黙々と歩き続けている人も。私が伝えたかったのは「才能なんて存在しない」という単純なメッセージではありません。「才能という言葉を使うことで、私たちは何を見失っているのか」ということです。才能という言葉は便利です。でも、その便利さと引き換えに、私たちは変化の可能性を、成長の余地を、自分と他者の可能性を信じる力を手放しています。「才能がない」という言葉を、もし今、心の中で繰り返しているのなら──それは本当は違うかもしれません。エラーメッセージを、ちゃんと読んでいないだけかもしれません。仮説を、一つずつ潰していないだけかもしれません。インスタントな答えを求めて、モヤモヤと向き合っていないだけかもしれません。まだ、自分に合った学び方に出会っていないだけかもしれません。小さなことです。でも、その小さなことを飛ばしているから、「才能がない」と思い込んでしまう。コンテストで輝いていた同期が、燃え尽きていることがあります。勉強会で熱心だった後輩が、姿を見せなくなることがあります。一方で、当時は目立たなかった誰かが、誰も予想しなかった場所で花を咲かせていることもあります。スタート地点の優劣など、長い人生においてはほとんど意味をなさない──20代を通じて、私はそう学びました。あなたの可能性は、スタート地点では測れません。どれだけ伸びたか、どれだけ学んだか、どれだけ変化したか──それこそが、本当の意味での能力です。才能という幻想を手放したとき、初めて見えてくる景色があります。それは、不完全な今の自分を受け入れ、それでも前に進み続けることの静かな勇気です。未熟な自分がインターンシップを始めて3年。今でも不安はあります。でも、若手と一緒に作業する中で気づきました。彼らが必要としているのは、全てを知り尽くした指導者ではありません。共に悩み、共に考え、そして「才能」という言葉で可能性を閉ざさない、そんな誰かです。この記事を通じて、私自身もまた、自分に言い聞かせています。才能があるかどうかなんて、後になってから誰かが決めることです。大切なのは、今、目の前にあることに手を動かし続けること。その積み重ねだけです。最後に、私自身のことを少しだけ。私にはいくつかの目標があります。世界的に有名なOSSを作って、海外で見知らぬ人にコーヒーを奢ってもらいたいです。書籍をコンスタントに出して、いつか道端でサインを求められたいです。週刊プレイボーイに連載を載せて、毎週誰から指摘されても反論ができるようにグラビア雑誌を買うことです。できるかどうかは分かりません。才能があるかどうかも分かりません。でも、文章を書き続けています。コードを書き続けています。なぜなら、それが私にとって「満たされなさ」を満たす行為だからです。そして、その過程を楽しんでいるからです。あなたにも、そんな「満たされなさ」があるなら。それに向かって、ただ手を動かし続けてください。それが才能かどうかなんて、後になってから誰かが決めることです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[今更ながらadkを使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/637c35253400e7</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/637c35253400e7</guid>
            <pubDate>Mon, 27 Oct 2025 12:50:38 GMT</pubDate>
            <content:encoded><![CDATA[今回はadkを使ってみました。すでに提供が開始されてからかなり日数が立っていますが使っていなかったことに気づきまして、今回Qucikstartを試してみました（エージェントを実装できる方法が他に色々ありすぎて漏れていましたw）。 adkとは？adkとはAgent Development Kitの省略であり、エージェントを開発・デプロイするためのフレームワークになります。GeminiやGoogleのエコシステムに最適化されてはいますが利用するモデルについてはそれ以外のものも利用でき、他のフレームワークと互換性があるものとなっています。利用用途としてはadkをつかってエージェントをくみ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[技術力に優劣はある(「技術力に優劣はない」を読んで)]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/27/134629</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/27/134629</guid>
            <pubDate>Mon, 27 Oct 2025 04:46:29 GMT</pubDate>
            <content:encoded><![CDATA[sizu.meはじめに先日、「技術力に優劣はない（技育などに参加している学生に向けて）」という記事を読みました。技育に参加する学生たちへの励ましのメッセージで、技術との向き合い方の多様性を認め、コミュニケーション力の重要性を説き、相互リスペクトの大切さを訴える、とても温かい内容でした。この記事は、あの記事の対象読者ではない私が、横から口を出すような形になってしまうことを承知で書いています。 元の記事の主張——技術の感受性には段階があること、ジュニアにはコミュニケーションが大事なこと、べき論に揺さぶられないこと、どの段階にいてもキャリアは作れること——これらは本質的に正しいと思います。ただ、私はこう思います。それでもなお、技術力という軸においては、やはり優劣が存在し、それが中長期的なキャリアに大きな影響を与えます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきましょう。技術との向き合い方元の記事では、技術への向き合い方を3段階に分けていました。この分類は本質を捉えていると思います。技術を道具として使う人技術を理解する人技術を創る人この分類自体はとても良いのですが、私はこれをポケモンの進化のような段階的なものとは捉えていません。むしろ、これらは固定的な段階ではなく、状況や分野によってシームレスに行き来するものだと感じています。例えば、Reactについては深い理解があり、新しいパターンを生み出せる人でも、機械学習の分野では既存のライブラリを使うだけかもしれません。人は常に3つの状態を往復しています。新しい分野に挑戦すれば「道具として使う」状態に戻りますし、経験を積めば「理解する」状態に移行し、さらに探求すれば「創る」状態に到達します。それぞれの状態の中には優劣は存在するここで重要なのは、これら3つの状態は確かに流動的ですが、それぞれの状態の中には明確に優劣が存在するということです。「道具として使う」中には優劣があります。 同じ「道具として使う」状態でも、ドキュメントを読んで適切に活用できる人と、エラーが出たらすぐに諦めてしまう人では、生産性に大きな差があります。基本的な概念を理解しながら使っている人と、ほぼブラックボックスとして使っている人では、応用力が全く異なります。そして今、生成AIを効果的に活用できる人とそうでない人では、学習速度に圧倒的な差が生まれています。エラーメッセージをAIに投げて適切な解決策を引き出せる人と、ただコピペして満足する人では、問題解決能力が変わってきます。「理解する」中には優劣があります。 内部実装を読んで理解している人と、公式ドキュメントレベルの理解に留まっている人では、問題解決能力に差があります。パフォーマンスの特性やエッジケースまで把握している人と、基本的な使い方だけ知っている人では、設計の質が変わってきます。ここでも生成AIの活用法に差が出ます。複雑なコードベースの理解を加速するためにAIを使える人と、単に「これ何してるの？」と聞くだけの人では、深い理解への到達速度が違います。技術的な仮説を立て、AIに検証させながら学びを深められる人は、独学だけの人より効率的に専門性を高められます。「創る」中には優劣があります。 既存のものを少し改良したレベルと、まったく新しいパラダイムを生み出すレベルでは、技術的なインパクトが桁違いです。自分のプロジェクトで使える小さなライブラリを作る人と、業界全体に影響を与えるOSSを開発する人では、その影響力は比較になりません。そして今、生成AIを創造のパートナーとして使いこなせる人とそうでない人では、アウトプットの質と量に大きな差が生まれています。アイデアの壁打ち相手としてAIを使い、設計の初期段階を加速できる人。実装の定型部分をAIに任せ、本質的な設計に集中できる人。こういった使い方ができる人は、同じ時間でより高度なものを創り出せます。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon向き合い方の違いを優劣として捉えがちしかし、学生や若いソフトウェアエンジニアは、この向き合い方の違いを、ソフトウェアエンジニアとしての優劣として捉えがちだという側面があります。「自分は道具として使っているだけだから、ダメなエンジニアだ」「あの人は技術を創っているから、自分よりずっと上だ」こういった思考に陥りやすいです。それが過度な自己否定につながったり、逆に、ある分野で「創る」状態に到達したことで慢心したりします。しかし、向き合い方は分野によって変わります。誰もが全ての技術について「創る」状態にいるわけではありません。そして、「道具として使う」状態であることが、必ずしも劣っているわけではありません。重要なのは、どの状態にいるかではなく、その状態の中でどのレベルにいるか、そして複数の領域でどう組み合わせているかです。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon能力ではなく衝動や偏愛人を「道具として使う」状態から「理解する」状態へ、さらには「創る」状態へと突き動かすものは、おそらくは計画的なキャリアデザインではありません。むしろ、それは衝動や偏愛に近いものだと思います。あるいは、そうした衝動を自然と抱けるような環境に身を置けるかどうかです。「なぜかこのエラーメッセージが気になる」「この実装がどうなっているのか知りたくて仕方がない」「この技術で何かを作りたいという衝動が止まらない」——こういった、理屈では説明しきれない偏愛が、人を技術の深みへと引き込んでいきます。そして、周囲に技術を深く追求する人たちがいる環境は、そうした衝動を自然と育んでくれます。人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazonそれでもなお、市場価値の差は存在するしかし、この3つの状態の間には、やはり市場価値の差が存在します。そして、どの状態に長く留まっているか、その状態の中でどのレベルにいるかが、中長期的なキャリアに大きな影響を与えます。「道具として使う」状態に留まり続けることのリスクは、年齢を重ねるほど大きくなります。表面的な理解しかないエンジニアは、年齢を重ねると「代替可能な人材」になっていきます。若手の方が給与が安く、学習意欲も高いです。同じ「道具として使う」状態であれば、企業が選ぶのは若手です。一方、主要な技術領域で「理解する」状態に到達できれば、市場価値は変わります。そして、いくつかの領域で「創る」状態に到達している人は、さらに大きな影響力を持ちます。さらに、同じ「理解する」状態でも、そのレベルの高さによって市場価値は大きく変わってきます。この差を「優劣ではない、違いだ」と言えるでしょうか？ 市場は明確に評価しています。ジュニアに技術力は求められていない？元の記事は「ジュニアに技術力は求められていない」と述べていました。確かに、新卒や入社1〜2年目であれば、それは正しいです。しかし、これを「技術力を磨かなくてもいい理由」にしてはいけません。「ITエンジニアの転職学」では年収600万円を超えるには、以下のような能力で「自立レベル」への到達が求められます。設計力/実装力：アーキテクチャ設計、コーディング、技術選定など専門性の深さと広さ：特定領域の深い知識と、周辺技術の幅広い理解推進力・プロジェクト貢献：プロジェクトを前に進める力、スケジュール管理組織貢献：チームビルディング、メンバー育成、採用への貢献事業・顧客貢献：ビジネス価値への理解、顧客課題の解決情報発信・プレゼンス：技術ブログ、登壇、OSS活動などこのレベルに到達するのは、通常は入社3〜5年目だと言われています。つまり、「ジュニアには技術力は求められていない」というのは、せいぜい20代半ばまでの話です。それを過ぎても設計力/実装力や専門性が低いままだと、キャリアは確実に行き詰まります。ITエンジニアの転職学 2万人の選択から見えた、後悔しないキャリア戦略 (KS科学一般書)作者:赤川 朗講談社Amazonコミュニケーション力と技術力は対立しない元の記事では、技術の勉強をしている人とそうでない人が対比され、後者は「別の有意義なことをしている」と書かれていました。確かに、ゲームをしたり、友達と飲みに行ったりする時間は人生において大切です。キャリアは短距離走ではなく、中長距離走です。 燃え尽きないことが重要であり、適度な息抜きや趣味の時間は必要です。しかし、それは「技術を学ばない理由」にはなりません。 むしろ、中長距離だからこそ、地道な積み重ねが最終的に大きな差を生みます。1年、3年、5年と継続的に学び続けることで、技術力は確実に向上します。なぜなら、優秀なエンジニアは、技術力もコミュニケーション力も両方高いからです。これは対立するものではなく、掛け算で効いてくるものです。私が見てきた優秀なエンジニアたちは、例外なく以下の特徴を持っていました。設計力/実装力が高い（主要技術について「理解する」以上の状態）コミュニケーション力も高いビジネス理解力がある学習意欲が高い「技術力がないから、コミュニケーション力で勝負する」というのは、戦略ではなく妥協です。本当に市場価値を高めたいなら、先ほど挙げた6つの能力を、バランス良く磨く必要があります。syu-m-5151.hatenablog.comキャリアの中盤で見えてくる分岐点20代のうちは、技術力の差はそれほど致命的ではません。コミュニケーション力や調整力でカバーできるし、「これから成長すればいい」という期待値もあります。しかし、キャリアの中盤になると、市場が求めるレベルは急激に上がります。技術的な意思決定ができることチームをリードできることアーキテクチャ設計ができること若手を育成できることこれらはすべて、高い技術力を前提としています。 コミュニケーション力だけでは、技術的な意思決定はできません。表面的な理解では、アーキテクチャ設計はできません。自分が技術を深く理解していなければ、若手を育成することもできません。早期のマインド切り替えと継続的な努力「追いつけない」ではなく「只々積み上げる」元の記事には、圧倒的なテックリードを見て「自分が3に行けることはないと実感した」という記述があった。この気持ちはよくわかります。圧倒的な技術力を持つ人を目の当たりにしたとき、「自分には無理だ」と感じる瞬間は、多くのエンジニアが経験することです。しかし、そのテックリードもまた、努力の積み重ねでそこに到達しているということを忘れてはいけません。彼らは最初から「創る」状態にいたわけではません。膨大な時間をかけて技術を学び、無数のエラーと格闘し、何度も失敗を繰り返し、そして徐々に深い理解を獲得していった。「あの人は天才だから」と片付けてしまうのは、その人が積み重ねてきた努力を見ないことになります。そして、自分自身の成長の可能性を閉ざすことにもなります。その積み重ねを軽く見てはいけません。確かに、技術に対する偏愛や衝動の強さは人それぞれです。しかし、それでもなお、努力で到達できる範囲は思っているより広いです。 毎日1時間でもいいです、技術書を読みましょう。個人プロジェクトに取り組みましょう。エラーメッセージと真剣に向き合いましょう。こういった地道な積み重ねが、1年後、3年後、5年後の自分を作ります。技術力が高いエンジニアは、キャリアの中盤以降も選択肢が広がり続けます。一方、主要技術について表面的な理解に留まっているエンジニアは、選択肢が狭まっていきます。これが、早期に技術力を磨くことの重要性です。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonやる気は行動の後からついてくる「技術を学ばなければ」と頭では理解していても、なかなか実行に移せません。モチベーションが湧かません。やる気が出ません。こういった悩みを抱えている人は多い。しかし、ここで重要な真実があります。やる気を出すには、やるしかません。多くの人は「やる気が出たら始めよう」と考える。しかし、これは因果が逆です。やる気は行動の前に現れるものではなく、行動の後からついてくるものです。心理学の研究でも明らかになっているが、人間の脳は「行動を始めてから」やる気を出すようにできています。作業興奮という現象です。まずは5分だけコードを書いてみる。1ページだけ技術書を読んでみる。すると、脳が活性化し、自然と続けたくなります。「理想的な環境が整ったら」「十分な時間ができたら」「気分が乗ったら」——こういった条件を待っていても、その日は永遠に来ません。理想的な状態を待つのではなく、不完全なままでも始めることです。毎日30分でいいです。週末の2時間でいいです。小さく始めて、継続しましょう。それが1ヶ月、3ヶ月、1年と続けば、気づいたときには大きな差になっています。「やる気が出ないから動けない」のではなく、「動かないからやる気が出ない」のです。だから、やる気を出すには、やるしかありません。 今この瞬間から、小さな一歩を踏み出しましょう。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon学生のうちに気づけるなら私が最も伝えたいのは、早期にマインドを切り替え、只々研鑽を積み重ねることの重要性だ。早く気づけば気づくほど、リカバリーは容易になります。学生なら今が絶好のタイミングです。時間はたっぷりあります。大学の授業だけでなく、個人プロジェクト、OSS、インターン——自分に合った形で技術と向き合いましょう。一時の成功も失敗も、長い人生の中では泡のようなものです。 今日のコンテストでの勝利も、明日の挫折も、それ自体は大した意味を持たません。重要なのは、そこから何を学び、次にどう活かすかです。そして、本当のトップレベルを見に行こう。 自分より優秀な人たちがいる環境に飛び込み、「ボコボコにされる」経験をしましょう。それは屈辱的かもしれないが、それこそが成長のチャンスです。ただし、一度の挫折で諦めないでほしいです。 圧倒的な実力差を見せつけられても、それは終わりではありません。自分の現在地を知る機会です。そこから、只々積み上げていけばいいです。社会人になってから気づいても遅くはない20代であっても、キャリアの中盤であっても、「技術力を磨かなければ」と気づいた時点から始めれば、必ず変わります。ただし、学生時代より難易度は上がります。家庭があるかもしれません。体力も落ちているかもしれません。それでも、今から本気で取り組めば、道は開けます。業務時間外の勉強を習慣化しましょう。技術書を読みましょう。個人プロジェクトを作りましょう。2〜3年本気で取り組めば、主要技術について表面的な理解から深い理解へと確実に移行できます。そうなれば、市場価値は大きく変わります。気づいた時点が、あなたにとっての「今」です。過去を悔やむより、今から只々積み上げていきましょう。キャリア戦略の選択肢エンジニアとして生きていく上で、大きく分けて2つの戦略があります。選択肢1: 技術のスペシャリストを目指す本気で技術を磨き、技術者として高い評価を得られるエンジニアになります。これは楽な道ではません。業務時間外も勉強し、常に新しい技術にキャッチアップし、OSSにコントリビュートし、深夜までコードを書きます。しかし、その努力は報われる。キャリアの中盤で選択肢が広がり、技術者としての充実感を得られます。市場価値も高く、転職の選択肢も豊富です。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazon選択肢2: 技術とビジネスのバランス型を目指す設計力/実装力は一定レベルに抑え、組織貢献や事業・顧客貢献で価値を出す。プロダクトマネージャーやエンジニアリングマネージャーを目指す道です。これも立派な戦略です。しかし、技術の基礎理解は必須です。 表面的な理解だけで「マネジメントに進む」というのは、逃げに過ぎません。マネージャーやPMになっても、技術を深く理解していなければ、チームから信頼されず、技術的な制約や可能性を踏まえた意思決定もできません。どちらを選ぶにせよ、技術力に優劣があることを認め、自分の現在地を正確に把握することが、全ての出発点です。 そして、気づいた時点から、只々積み上げていくことが大切です。エンジニアのためのマネジメントキャリアパス ―テックリードからCTOまでマネジメントスキル向上ガイド作者:Camille FournierオライリージャパンAmazon一つの物差しで人を測るなここまで技術力の重要性を語ってきたが、同時に伝えておきたいことがあります。学生時代から社会人の初期にかけて、私はカンファレンスやイベントで、相手の技術的な知識を試すような会話をしていました。わざと難しい質問を投げかけて、相手が答えられないのを見て優越感に浸る。今振り返ると、最低です。当時の私は、技術力の有無だけで人間の優劣を測っていました。学生のギーク層にありがちな行動だが、自分がイキれる相手を見つけて、マウントを取るのは確かに気持ちがいい。でも、それは恥ずべき行為です。他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazonただし、逆の極端も問題だと思っています。世の中には「技術力なんてどうでもいい、面白い人間かどうかが全て」という価値観もあります。確かに、人間的な魅力は重要です。でも、それを唯一の評価軸にして「技術バカは使えない」「コミュ力こそ全て」と言い切るのも、結局は別の物差しで人を測っているだけです。技術力で人を測るのも、コミュ力で人を測るのも、面白さで人を測るのも、本質的には同じ過ちです。この記事で私は「技術力の優劣を直視せよ」と書いてきた。市場価値という文脈では、技術力の差は厳然として存在します。それを無視してキャリアを語ることはできません。しかし、それはあくまで市場価値という一つの軸での話です。 技術力が高いからといって人として偉いわけではません。逆に、技術力が低いからといって人として劣っているわけでもません。イベントで出会った人が、あなたより技術的な知識が少ないように見えても、その人にはその人の文脈があります。学びの途中かもしれません。別の分野のエキスパートかもしれません。技術以外の部分で圧倒的な価値を生み出している人かもしれません。大切なのは、相手の文脈を読み取って会話できることです。 自分の得意な物差しだけで人を評価し、優越感に浸るのは、いくら専門性が高くても人として未熟です。技術力を磨くことと、人として成熟することは、まったく別の話なのだから。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonおわりに長々と書いてきたが、最後にもう一度、元の記事への敬意を示したい。元の記事は、学生たちを励まし、多様性を尊重し、相互リスペクトを訴える、とても温かい内容でした。その優しさと配慮は、本当に素晴らしいと思います。私はこの記事で「技術力に優劣はある」と主張してきた。それは市場価値やキャリアという観点では事実です。しかし同時に、技術力で人間の価値を測ってはいけません。技術力が高いことと、人として成熟していることは別物です。むしろ、技術力があるからこそ、謙虚さとリスペクトを忘れてはいけません。「優劣はない」という優しい言葉に安住せず、現実を直視してほしいです。そして、今のうちに本気で技術を学んでほしいです。キャリアは中長距離走です。 今なら、まだ間に合います。ただし、技術を学ぶ過程で、決して人を見下してはいけません。相手の文脈を理解し、リスペクトを持ってコミュニケーションを取りましょう。それができて初めて、優秀なエンジニアと言えるのだと思います。Googleのソフトウェアエンジニアリング ―持続可能なプログラミングを支える技術、文化、プロセスオライリージャパンAmazonこの記事は、元の記事の筆者や読者を否定する意図はありません。対象読者ではない私が横から口を出すような形になってしまい申し訳ありませんが、学生時代の自分に伝えたかったこと、そして過去の自分を反省する気持ちを込めて書きました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：sshm]]></title>
            <link>https://zenn.dev/akasan/articles/6d97f52cccfeef</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/6d97f52cccfeef</guid>
            <pubDate>Sun, 26 Oct 2025 10:19:23 GMT</pubDate>
            <content:encoded><![CDATA[コマンド紹介シリーズ第15回目の本日はsshmを紹介しようと思います。sshmを利用するとsshの設定に関してTUIインターフェースで操作できます。なお、第14回は以下になりますので、ぜひご興味があればご覧ください。https://zenn.dev/akasan/articles/80f8931f8523cd sshmとは？公式GitHubによると、sshmは、SSHホストの管理と接続方法を変革する美しいコマンドラインツールです。Go言語で構築され、直感的なTUIインターフェースを備えているため、SSH接続管理が簡単かつ快適になります。とのことで、SSHホストをTUIで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Astro で Standard ML のシンタクスハイライト]]></title>
            <link>https://silasol.la/posts/2025-10-26-02_astro-sml/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2025-10-26-02_astro-sml/</guid>
            <pubDate>Sun, 26 Oct 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[デフォルトでハイライトされない言語を TextMate を用いた拡張で認識させます．]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Ray Dataへの入門 ~quickstart~]]></title>
            <link>https://zenn.dev/akasan/articles/3cdf0bd79a898a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3cdf0bd79a898a</guid>
            <pubDate>Sat, 25 Oct 2025 12:05:51 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayでデータを取り扱うためのRay Dataについて、Quickstartを通して入門してみました。 Ray Dataとは？Ray Dataは、Ray上に構築されたMLとAIワークロードのためのスケーラブルなデータ処理ライブラリです。 バッチ推論やデータ前処理、MLトレーニングのためのインジェストなど、AIワークロードを表現するための柔軟で高性能なAPIを提供してくれます。他の分散データシステムとは異なり、Ray Dataはストリーミング実行を特徴としており、大規模なデータセットを効率的に処理し、CPUとGPUの両方のワークロードで高い利用率を維持します。Ray Data...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[30歳を迎えたMLエンジニアが今後の計画を考えてみた]]></title>
            <link>https://zenn.dev/akasan/articles/35d7eeebb7a84c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/35d7eeebb7a84c</guid>
            <pubDate>Fri, 24 Oct 2025 13:09:25 GMT</pubDate>
            <content:encoded><![CDATA[本日筆者は30歳を迎えまして、人生のある意味節目なので今後のプランを考えてみました。 まずは20代を振り返る 何をやってきたか22際から新卒エンジニアとして働き始めて8年程度でしょうか、色々な業務をこなしてきました。ざっと上げただけでもこんな感じですかね。ソフトウェア開発OCRを利用した業務効率化ソフトウェアの改修データ分析ソフトウェアの設計・開発プログラミング効率化のためのソフトウェア開発異常検知モデルの結果や設定をするためのWebアプリケーションの実装ロボット制御開発経路計画立案システムの構築ロボットの制御ソフトウェア開発ロボット制御のための回路...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[anyenvやasdfに代わる？miseで始める開発環境管理]]></title>
            <link>https://sreake.com/blog/mise-development-env-management/</link>
            <guid isPermaLink="false">https://sreake.com/blog/mise-development-env-management/</guid>
            <pubDate>Fri, 24 Oct 2025 12:34:35 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 開発環境の構築において「このプロジェクトは Node.js 16 系だけど、別の案件は 18 系じゃないと動かない」といった状況に遭遇することは少なくありません。 プロジェクトごとに異なる言語やツールのバージョ […]The post anyenvやasdfに代わる？miseで始める開発環境管理 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NeMo Guardrailsを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/0b825a53e78e06</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0b825a53e78e06</guid>
            <pubDate>Thu, 23 Oct 2025 14:18:27 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAが提供するNeMo Guardrailsを利用してみました。NeMo Guardrailsを利用することでプログラムを用いてガードレール機能を導入することができます。 NeMo Guardrailsとは？こちらの解説によると、NeMo Guardrails はプログラム可能なガードレールを LLM ベースの対話システムに簡単に追加するための OSS です。NeMo Guardrails を使用する事で、簡単なコンフィグレーションの作成と Python によるコーディングのみで、信頼性のある、安全でセキュアな LLM 対話システムの構築を簡単に行う事ができます。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI でセキュアで堅牢な開発をするためのプラクティス集]]></title>
            <link>https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli</link>
            <guid isPermaLink="false">https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli</guid>
            <pubDate>Thu, 23 Oct 2025 01:52:31 GMT</pubDate>
            <content:encoded><![CDATA[先日、クラウドネイティブ × Gemini CLIというイベントで『Gemini CLI でもセキュアで堅牢な開発をしたい！』というタイトルで登壇させていただきました。時間都合で端折ってしまった部分が多かったため、本記事で行間を埋めつつ最新の状況をお伝えします。登壇の内容は全て記載するため、イベントに参加されなかった方も読んでいただければと思います。 はじめに本記事は Gemini CLI を個人レベルではなく企業やチームとして使いたい方を対象とします。そのため、Gemini CLI の基本的な部分（例えばどのようにインストールするか、settings.jsonとは何か、基本...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DecisionTree分類器の構造を可視化してみる]]></title>
            <link>https://zenn.dev/akasan/articles/dc29b37ec0d998</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/dc29b37ec0d998</guid>
            <pubDate>Wed, 22 Oct 2025 13:31:10 GMT</pubDate>
            <content:encoded><![CDATA[今回はscikit-learnのDecisionTree分類器の学習結果を可視化する方法をまとめてみます。 DecisionTree分類器とは？DecisionTree分類器は決定木を利用した分類器です。構造としては二分木で、各ノードで何かしらの条件により入力データが2つに分割されます。その分割を複数段階適用することでクラス分類をすると言うものになります。DecisionTree分類器については以下をご参照ください。https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifi...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[build.nvidia.comからgpt-oss-120bを使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/1bb37e8ad6de59</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1bb37e8ad6de59</guid>
            <pubDate>Tue, 21 Oct 2025 13:38:50 GMT</pubDate>
            <content:encoded><![CDATA[今回はbuild.nvidia.comで利用できるgpt-oss-120bを利用してみました。 build.nvidia.comとは？build.nvidia.comはNVIDIAが提供しているNIMのAPIを試せる環境となっています。NIMとは公式ページにて以下のように説明されています。NVIDIA NIM™ は、クラウド、データセンター、ワークステーション、エッジなど、あらゆる NVIDIA アクセラレーテッド インフラストラクチャに最新の AI モデルを迅速にデプロイできるように、最適化された事前構築済みの推論マイクロサービスを提供します。要はマイクロサービスとして様...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LogisticRegressionの重みを可視化してみる]]></title>
            <link>https://zenn.dev/akasan/articles/f3ec2f94a385b3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f3ec2f94a385b3</guid>
            <pubDate>Mon, 20 Oct 2025 14:11:09 GMT</pubDate>
            <content:encoded><![CDATA[今回はLogisticRegressionの回帰係数を可視化して各特徴量の分類に対する寄与度を可視化してみました。 検証内容今回はscikit-learn上で利用できるirisデータを使います。irisは多クラス（３クラス）データであり特徴量は4つあります。LogisticRegressionを学習させ、その回帰係数を可視化してみます。 早速実装する 環境構築まずは必要なライブラリをインストールします。uv init iris_logistic_regression -p 3.12cd iris_logistic_regressionuv add scikit-le...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLIでもセキュアで堅牢な開発をしたい！]]></title>
            <link>https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai</link>
            <guid isPermaLink="false">https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai</guid>
            <pubDate>Sun, 19 Oct 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[imbalanced-learnを利用してアンダー/オーバーサンプリングを実施してみた]]></title>
            <link>https://zenn.dev/akasan/articles/7a148787cb3be8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/7a148787cb3be8</guid>
            <pubDate>Sun, 19 Oct 2025 03:34:17 GMT</pubDate>
            <content:encoded><![CDATA[今回はimbalanced-learnを利用してデータセットの偏りを調整する方法を試してみました。機械学習ではデータの分布がとても重要であり、偏ったデータ分布は好ましくない場合が多いです。そのような場合にデータの偏りを補正するためのライブラリとしてimbalanced-learnがあり、今回はそれを利用してみました。 データの偏りとは？文字通りですが、データに偏りがある状態をいいます。例えばある病気について、診察対象の人が病気に罹患しているかしていないかをまとめたデータセットがあったとします。仮にその病気に罹患している人が極めて少数の場合、このデータセットは大半が罹患していない人...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions の Job から WireGuard で VPN アクセス]]></title>
            <link>https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6</link>
            <guid isPermaLink="false">https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6</guid>
            <pubDate>Sat, 18 Oct 2025 09:09:27 GMT</pubDate>
            <content:encoded><![CDATA[背景GitHub Actions の Job で家のネットワークにアクセスさせたいことがあり、いったんは Squid を認証付きで publilc に公開するというのをやっていたのですが、やっぱり嬉しくないのでどうしたものかと思っていたのですが WireGuard が使...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-chefがRustのDockerビルドを高速化する話]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/18/163911</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/18/163911</guid>
            <pubDate>Sat, 18 Oct 2025 07:39:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の記事では、Rust の Docker イメージサイズを 98%削減する方法を解説しました。その中で最も重要な役割を果たしているのが cargo-chef です。この記事では、cargo-chef の仕組みと動作原理を深く掘り下げていきます。syu-m-5151.hatenablog.comcargo-chef は、Docker のレイヤーキャッシングと Cargo のビルドモデルの根本的な不整合を解決し、Rust プロジェクトのDockerビルドを5倍高速化します。Luca Palmieri が「Zero to Production In Rust」のために作成したこのツールは、ソースコード変更のたびに 20 分以上かかっていたリビルドを、依存関係をアプリケーションコードから分離してキャッシュし、2〜3 分のビルドに変えました。www.zero2prod.comcargo-chef は依存関係情報のみを捉えた「レシピ」を作成し、ソースコードが変更されても有効なままの別レイヤーで高コストな依存関係のコンパイルをキャッシュできます。約 500 の依存関係を持つ商用コードベースでは、ビルド時間が約 10 分から約 2 分に短縮され、CI/CD の速度とインシデント対応時間に直接影響を与えます。github.comRustのDockerビルドにおける根本的な問題Docker のレイヤーキャッシングは、各命令(RUN、COPY、ADD)に対してレイヤーを作成します。いずれかのレイヤーが変更されると、そのレイヤーとそれ以降のすべてのレイヤーが無効化されます。標準的な Rust Dockerfile は重大な問題に直面します: 依存関係のマニフェストとソースコードの両方を一緒にコピーする必要があるため、ソースの変更があるとビルドキャッシュ全体が無効になってしまうのです。問題のあるパターン:FROM rust:1.75WORKDIR /appCOPY . .              # マニフェストとソースを一緒にコピーRUN cargo build       # 変更のたびにすべてを再ビルドPython の pip install -r requirements.txt や Node の npm install とは異なり、Cargoには依存関係のみをビルドするネイティブな方法がありません。cargo build コマンドは、依存関係とソースのコンパイルを統一された操作として扱います。cargo build --only-deps のようなフラグは存在しません。このアーキテクチャ上の制限により、他の言語では美しく機能する標準的な Docker パターンが、Rust では壊滅的に失敗してしまいます。影響は開発ワークフロー全体に波及します。すべてのコード変更—たった 1 文字の修正でさえ—数百の依存関係の完全な再コンパイルを引き起こします。2〜4 コアの CI システムでは、ビルドが 30 分を超えることがあります。これにより、デプロイ速度、インシデント対応時間、開発者の反復サイクルに厳しい下限が生まれます。本番環境のインシデントで緊急パッチが必要な場合、その 20 分のビルドが 20 分のダウンタイムになります。Rustのビルドが特に問題になる理由Rust のコンパイルモデルは、コンパイル時間の速度よりも実行時パフォーマンスを優先します。リリースビルド(--release)は、中規模のプロジェクトで 15〜20 分かかる広範な LLVM 最適化パスを実行します。ジェネリクス、トレイト特殊化、単相化の多用により、依存関係は各使用パターンに対して相当量のコードをコンパイルします。非同期エコシステム(tokio、actix-web、tonic)はこれを悪化させます—これらのクレートは単純なアプリケーションでもコンパイルが重いのです。インクリメンタルコンパイルは存在しますが、リリースビルドではデフォルトで無効になっており、外部依存関係には役立ちません。Docker の本番ビルドは常に --release プロファイルを使用するため、遅いコンパイルパスを避けられません。依存関係のコンパイルは通常、総ビルド時間の 80〜90%を消費しますが、これらの依存関係はアプリケーションコードに比べてほとんど変更されません。この逆転した関係—最も遅い部分が最も変更されない—こそが、cargo-chef が活用するポイントです。アーキテクチャプロジェクト構造:src/main.rs - コマンドパースを含む CLI エントリポイントsrc/lib.rs - ライブラリエントリポイントsrc/recipe.rs - レシピ生成、依存関係ビルド、クッキングロジックsrc/skeleton.rs - プロジェクトスケルトンの作成とダミーファイル生成cargo-chef のアーキテクチャは 2 つの抽象化を中心としています: RecipeとSkeleton。Recipe はシリアライズ可能なコンテナで、Skeleton は実際のマニフェストデータとロックファイルを含みます。これらの構造により、コアワークフローが可能になります: 分析 → シリアライズ → 再構築 → ビルド。レシピコンセプトと動作原理「レシピ」は、ソースコードなしで依存関係をビルドするために必要な最小限の情報を捉えたJSONファイル(recipe.json)です。これは Python の requirements.txt と同じ目的を果たしますが、Rust のより複雑なプロジェクト構造に対応しています。レシピの内容:プロジェクト全体のすべての Cargo.toml ファイルとその相対パスCargo.lock ファイル(存在する場合)、正確な依存関係バージョンのためすべてのバイナリとライブラリの明示的な宣言—正規の場所(src/main.rs、src/lib.rs)にあるものでもスケルトン再構築のためのプロジェクト構造メタデータpub struct Recipe {    pub skeleton: Skeleton,}pub struct Skeleton {    manifests: Vec<Manifest>,    lock_file: Option<String>,}この構造は人間が読める JSON にシリアライズされ、レシピはデバッグ可能で検査可能です。明示的なターゲット宣言により、Cargo が通常ファイルの場所からターゲットを推測する場合でも、信頼性の高いキャッシュが保証されます。動作原理と内部メカニズムcargo-chef は、マルチステージビルドで連携する 2 つのコマンドを提供します:1. cargo chef prepare --recipe-path recipe.jsonこのコマンドは次のように現在のプロジェクトを分析します。ベースパスからディレクトリを再帰的にトラバース相対パスを保持してすべての Cargo.toml ファイルを収集依存関係バージョンロックのために Cargo.lock を読み取りSkeleton データ構造を作成マニフェスト内の明示的なターゲット宣言を確保recipe.json にシリアライズprepare コマンドは高速(通常 1 秒未満)です。ファイル構造を分析して TOML をパースするだけで、コンパイルは行わないためです。2. cargo chef cook --release --recipe-path recipe.jsonこのコマンドは次のように再構築とビルドを行います。recipe.json を Skeleton に逆シリアライズskeleton.build_minimum_project() を呼び出してディレクトリ構造を再作成すべての Cargo.toml ファイルを相対パスに書き込みCargo.lock をディスクに書き込みすべてのターゲット(main.rs、lib.rs、build.rs)に対してダミーソースファイルを作成指定されたフラグで cargo build を実行skeleton.remove_compiled_dummies() 経由でコンパイル済みダミーアーティファクトを削除ダミーファイルトリック: cargo-chef は次のように最小限の有効な Rust ファイルを作成します。// ダミーのmain.rsfn main() {}// ダミーのlib.rs// (空または最小限)これらは Cargo がコンパイル可能なプロジェクトを要求する条件を満たしますが、実際のロジックは含まれていません。その後、Cargo は通常通りすべての依存関係を解決してコンパイルし、キャッシュされたアーティファクトを生成します。ダミーアーティファクトは後でクリーンアップされ、外部依存関係のコンパイル結果のみが残ります。重要な技術的制約: cook とその後の build コマンドは、同じ作業ディレクトリから実行すべきです。これは、target/debug/deps 内の Cargo の *.d ファイルにターゲットディレクトリへの絶対パスが含まれているためです。ディレクトリを移動するとキャッシュの利用が壊れます。これは cargo-chef の制限ではなく、cargo-chef が尊重する Cargo の動作です。Docker統合とマルチステージビルドcargo-chef は、Docker のマルチステージビルド機能用に特別に設計されています。標準的なパターンは 3 つのステージを使用します:標準的な3ステージパターン:FROM lukemathwalker/cargo-chef:latest-rust-1 AS chefWORKDIR /app# ステージ1: Planner - レシピを生成FROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.json# ステージ2: Builder - 依存関係をキャッシュFROM chef AS builderCOPY --from=planner /app/recipe.json recipe.jsonRUN cargo chef cook --release --recipe-path recipe.json# ↑ このレイヤーは依存関係が変更されるまでキャッシュされる# 次にソースをコピーしてアプリケーションをビルドCOPY . .RUN cargo build --release --bin app# ステージ3: Runtime - 最小限の本番イメージFROM debian:bookworm-slim AS runtimeWORKDIR /appCOPY --from=builder /app/target/release/app /usr/local/binENTRYPOINT ["/usr/local/bin/app"]キャッシングの仕組み:各 Docker ステージは独立したキャッシングを維持します。ステージは COPY --from 文を通じてのみやり取りします。この分離が cargo-chef の効果の鍵です。planner ステージの COPY . . は planner キャッシュを無効化(ただしこれは高速)Planner はフルソースツリーから recipe.json を生成Builder ステージは COPY --from=planner 経由で recipe.json のみを受け取るrecipe.jsonのチェックサムが変更されていない限り、builderの依存関係レイヤーはキャッシュされたままCargo.toml または Cargo.lock が変更された場合にのみ recipe.json が変更されるソースコードの変更は recipe.json に影響しないため、依存関係レイヤーはキャッシュされたままキャッシュ無効化ロジック:ソースコード変更 → plannerステージ無効化                → recipe.json変更なし                → builderの依存関係レイヤーキャッシュ済み ✓                → アプリケーションビルドのみ実行依存関係変更    → plannerステージ無効化                → recipe.json変更                → builderの依存関係レイヤー無効化 ✗                → フルリビルド必要これはインセンティブを完璧に整合させます: 高コストな操作(依存関係コンパイル)は、そうあるべき時(依存関係が変更されていない時)にキャッシュされ、高速な操作(ソースコンパイル)は期待通り毎回の変更で実行されます。ビルドプロセスの統合とサポート機能cargo-chef は標準的な Cargo ワークフローとシームレスに統合し、ビルドカスタマイズの全範囲をサポートします:ビルドコマンド:build(デフォルト)check(--check フラグ経由)clippyzigbuildサポートされるオプション:プロファイル選択: --release、--debug、カスタム --profile機能: --features、--no-default-features、--all-featuresターゲット: --target、--target-dir(ファーストクラスのクロスコンパイルサポート)ターゲットタイプ: --benches、--tests、--examples、--all-targets、--bins、--binワークスペース: --workspace、--package、--manifest-pathCargo フラグ: --offline、--frozen、--locked、--verbose、--timingsツールチェーンオーバーライド: cargo +nightly chef cookワークスペースサポートは自動です。cargo-chef はワークスペース内のすべてのクレートを検出し、正しく処理します。ファイルやクレートが移動しても、cargo-chef は自動的に適応します—Dockerfile の変更は不要です。これは、プロジェクト構造をハードコードする手動アプローチに対する大きな利点です。ビルド済みDockerイメージは Docker Hub の lukemathwalker/cargo-chef で利用可能で、柔軟なタグ付けができます。latest-rust-1.75.0(特定の Rust バージョンの最新 cargo-chef)0.1.72-rust-latest(最新の Rust の特定 cargo-chef)Alpine バリアント: latest-rust-1.70.0-alpine3.18バージョンの一貫性: すべてのステージで同一のRustバージョンを使用すべきです。バージョンの不一致は、異なるコンパイラバージョンが異なるアーティファクトを生成するため、キャッシングを無効化します。主要機能と実用的なユースケース主なユースケース:1. CI/CDパイプラインの最適化 - 標準的なユースケースです。すべてのコード変更が CI で Docker ビルドをトリガーします。cargo-chef なしでは、各ビルドが 500 以上のすべての依存関係を再コンパイルします(10〜20 分)。cargo-chef があれば、変更されていない依存関係はキャッシュされ、ビルドは 2〜3 分に短縮されます。これは次のような点に直接影響します。デプロイ速度(機能をより速くリリース)インシデント対応(本番環境をより速くパッチ)開発者体験(PR へのより速いフィードバック)インフラコスト(消費される CPU 分の削減)2. マルチステージビルド - ビルド環境とランタイム環境を分離。ビルダーステージは完全な Rust ツールチェーン(800MB 以上)を含み、ランタイムステージは最小イメージ(25〜50MB)を使用します。cargo-chef は、高コストなビルダーステージをキャッシュ状態に保つことで、このパターンを実用的にします。3. ワークスペース/モノレポプロジェクト - 依存関係を共有する複数のバイナリとライブラリを自動的に処理します。手動アプローチはワークスペースで破綻します; cargo-chef は透過的に処理します。4. クロスコンパイル - --target フラグ経由でファーストクラスサポート。例: Alpine Linux デプロイのために x86_64-unknown-linux-musl バイナリを CI でビルド。ターゲット指定は依存関係キャッシング中に尊重されます。高度な最適化戦略:sccacheとの組み合わせ:FROM rust:1.75 AS baseRUN cargo install --locked cargo-chef sccacheENV RUSTC_WRAPPER=sccache SCCACHE_DIR=/sccache# ... plannerステージ ...FROM base AS builderRUN --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \    cargo chef cook --release --recipe-path recipe.jsonこの組み合わせは2層のキャッシングを提供します。cargo-chef: 粗粒度(依存関係レイヤー全体)sccache: 細粒度(個々のコンパイルアーティファクト)1 つの依存関係が変更された場合、cargo-chef はすべてを再ビルドしますが、sccache は個々のクレートコンパイルをキャッシュします。変更された依存関係のみが実際に再コンパイルされます。BuildKitキャッシュマウント:RUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=/usr/local/cargo/git \    cargo chef cook --release --recipe-path recipe.jsonこれは cargo レジストリ自体をキャッシュし、再ダウンロードを回避します。sccache および cargo-chef と組み合わせることで、Rust Docker ビルドの現在のベストプラクティスとなります。重要な制限と考慮事項作業ディレクトリの制約 - cargo cook と cargo build は、Cargo の *.d ファイル内の絶対パスのため、同じディレクトリから実行すべきです。これは Docker では煩わしくありませんが、認識すべきです。ローカルパス依存関係 - プロジェクト外の依存関係(path = "../other-crate" で指定)は、変更されていなくてもゼロから再ビルドされます。これは、タイムスタンプベースのフィンガープリントに関連する Cargo の制限(issue #2644)です。コピーするとタイムスタンプが変更され、フィンガープリントが無効になります。ローカル開発には不向き - cargo-chef はコンテナビルド専用に設計されています。既存のコードベースでローカルに実行すると、ファイルが上書きされる可能性があります。このツールは、ターミナル環境で実行される場合の安全警告を含みます。ワークスペースの動作 - cargo chef cook はデフォルトですべてのワークスペースメンバーをビルドします。1 つのサービスのみが必要な大規模ワークスペースの場合、これによりビルド時間が増加する可能性があります。回避策には、ターゲットビルドフラグまたはサービスごとの個別の Dockerfile が含まれます。最適なユースケース - cargo-chef は以下に最大の利益を提供します。中規模から大規模プロジェクト(500 以上の依存関係)安定した依存関係ツリー(まれに変更)頻繁なデプロイ(CI/CD 環境)共有ビルドインフラを持つチーム環境非常に小規模なプロジェクト(少数の依存関係)の場合、オーバーヘッドが利益を上回る可能性があります。設計パターンとアーキテクチャの決定注目すべき技術的決定:JSONレシピ形式 - バイナリ形式ではなく JSON を使用し、レシピは人間が読めてデバッグ可能です。recipe.json を検査して、cargo-chef が何を抽出したかを正確に確認できます。明示的なターゲット宣言 - 正規の場所にある場合でも、すべてのターゲットを明示的に宣言するように Cargo.toml を変更します。これにより、キャッシュ無効化全体で Cargo がそれらを確実に認識します。マニフェスト操作 - 手動パースではなく、ワークスペース構造へのプログラマティックアクセスに cargo_metadata クレートを使用します。これにより Cargo の進化に伴う堅牢性が提供されます。TOML順序保持 - preserve_order 機能を持つ TOML を使用して、シリアライゼーションを通じたラウンドトリップ時にマニフェスト構造の整合性を維持します。安全機能 - atty クレートを使用したターミナル検出。対話的に実行された場合の警告メッセージ。ローカル環境での偶発的なファイル上書きを防ぐために、明示的なユーザー確認が必要です。採用された設計パターン:ビルダーパターン(Recipe/Skeleton 構築)コマンドパターン(CommandArg enum)ファサードパターン(複雑さを隠すシンプルな 2 コマンドインターフェース)テンプレートメソッドパターン(build_dependencies オーケストレーション)おわりにcargo-chef は、Cargo 自体が提供しない依存関係とソースコンパイルの分離を作成することで、Rust 特有の Docker レイヤーキャッシング問題を解決します。このツールの優雅さはシンプルさにあります: 依存関係管理を再発明するのではなく、Cargo が最も得意とすることを可能にする最小限の有効なプロジェクト構造を作成し、Docker のレイヤーキャッシングメカニズムと完璧に整合します。必須のベストプラクティス:すべての Docker ステージで同一の Rust バージョンを使用cook と build 間で一貫した作業ディレクトリを維持レジストリキャッシング用の BuildKit キャッシュマウントと組み合わせる細粒度のコンパイルキャッシング用に sccache を追加最小限のランタイムイメージを持つマルチステージビルドを使用.dockerignore でビルドコンテキストを最小化cargo-chefを使用すべき場合:中規模から大規模の Rust プロジェクトCI/CD Docker ビルド安定した依存関係ツリーを持つプロジェクト高速な反復サイクルを必要とするチーム迅速なインシデント対応を必要とする本番デプロイ。cargo-chef は、Docker 経由で Rust アプリケーションをデプロイするチームにとって不可欠なツールに成熟しており、より良い開発者体験、より速いデプロイ、削減されたインフラコストに直接変換される測定可能なパフォーマンス改善を提供します。]]></content:encoded>
        </item>
    </channel>
</rss>