<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sun, 26 Oct 2025 22:40:50 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：sshm]]></title>
            <link>https://zenn.dev/akasan/articles/6d97f52cccfeef</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/6d97f52cccfeef</guid>
            <pubDate>Sun, 26 Oct 2025 10:19:23 GMT</pubDate>
            <content:encoded><![CDATA[コマンド紹介シリーズ第15回目の本日はsshmを紹介しようと思います。sshmを利用するとsshの設定に関してTUIインターフェースで操作できます。なお、第14回は以下になりますので、ぜひご興味があればご覧ください。https://zenn.dev/akasan/articles/80f8931f8523cd sshmとは？公式GitHubによると、sshmは、SSHホストの管理と接続方法を変革する美しいコマンドラインツールです。Go言語で構築され、直感的なTUIインターフェースを備えているため、SSH接続管理が簡単かつ快適になります。とのことで、SSHホストをTUIで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Ray Dataへの入門 ~quickstart~]]></title>
            <link>https://zenn.dev/akasan/articles/3cdf0bd79a898a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3cdf0bd79a898a</guid>
            <pubDate>Sat, 25 Oct 2025 12:05:51 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayでデータを取り扱うためのRay Dataについて、Quickstartを通して入門してみました。 Ray Dataとは？Ray Dataは、Ray上に構築されたMLとAIワークロードのためのスケーラブルなデータ処理ライブラリです。 バッチ推論やデータ前処理、MLトレーニングのためのインジェストなど、AIワークロードを表現するための柔軟で高性能なAPIを提供してくれます。他の分散データシステムとは異なり、Ray Dataはストリーミング実行を特徴としており、大規模なデータセットを効率的に処理し、CPUとGPUの両方のワークロードで高い利用率を維持します。Ray Data...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[30歳を迎えたMLエンジニアが今後の計画を考えてみた]]></title>
            <link>https://zenn.dev/akasan/articles/35d7eeebb7a84c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/35d7eeebb7a84c</guid>
            <pubDate>Fri, 24 Oct 2025 13:09:25 GMT</pubDate>
            <content:encoded><![CDATA[本日筆者は30歳を迎えまして、人生のある意味節目なので今後のプランを考えてみました。 まずは20代を振り返る 何をやってきたか22際から新卒エンジニアとして働き始めて8年程度でしょうか、色々な業務をこなしてきました。ざっと上げただけでもこんな感じですかね。ソフトウェア開発OCRを利用した業務効率化ソフトウェアの改修データ分析ソフトウェアの設計・開発プログラミング効率化のためのソフトウェア開発異常検知モデルの結果や設定をするためのWebアプリケーションの実装ロボット制御開発経路計画立案システムの構築ロボットの制御ソフトウェア開発ロボット制御のための回路...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[anyenvやasdfに代わる？miseで始める開発環境管理]]></title>
            <link>https://sreake.com/blog/mise-development-env-management/</link>
            <guid isPermaLink="false">https://sreake.com/blog/mise-development-env-management/</guid>
            <pubDate>Fri, 24 Oct 2025 12:34:35 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 開発環境の構築において「このプロジェクトは Node.js 16 系だけど、別の案件は 18 系じゃないと動かない」といった状況に遭遇することは少なくありません。 プロジェクトごとに異なる言語やツールのバージョ […]The post anyenvやasdfに代わる？miseで始める開発環境管理 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NeMo Guardrailsを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/0b825a53e78e06</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0b825a53e78e06</guid>
            <pubDate>Thu, 23 Oct 2025 14:18:27 GMT</pubDate>
            <content:encoded><![CDATA[今回はNVIDIAが提供するNeMo Guardrailsを利用してみました。NeMo Guardrailsを利用することでプログラムを用いてガードレール機能を導入することができます。 NeMo Guardrailsとは？こちらの解説によると、NeMo Guardrails はプログラム可能なガードレールを LLM ベースの対話システムに簡単に追加するための OSS です。NeMo Guardrails を使用する事で、簡単なコンフィグレーションの作成と Python によるコーディングのみで、信頼性のある、安全でセキュアな LLM 対話システムの構築を簡単に行う事ができます。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI でセキュアで堅牢な開発をするためのプラクティス集]]></title>
            <link>https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli</link>
            <guid isPermaLink="false">https://zenn.dev/kimitsu/articles/secure-and-robust-development-with-gemini-cli</guid>
            <pubDate>Thu, 23 Oct 2025 01:52:31 GMT</pubDate>
            <content:encoded><![CDATA[先日、クラウドネイティブ × Gemini CLIというイベントで『Gemini CLI でもセキュアで堅牢な開発をしたい！』というタイトルで登壇させていただきました。時間都合で端折ってしまった部分が多かったため、本記事で行間を埋めつつ最新の状況をお伝えします。登壇の内容は全て記載するため、イベントに参加されなかった方も読んでいただければと思います。 はじめに本記事は Gemini CLI を個人レベルではなく企業やチームとして使いたい方を対象とします。そのため、Gemini CLI の基本的な部分（例えばどのようにインストールするか、settings.jsonとは何か、基本...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DecisionTree分類器の構造を可視化してみる]]></title>
            <link>https://zenn.dev/akasan/articles/dc29b37ec0d998</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/dc29b37ec0d998</guid>
            <pubDate>Wed, 22 Oct 2025 13:31:10 GMT</pubDate>
            <content:encoded><![CDATA[今回はscikit-learnのDecisionTree分類器の学習結果を可視化する方法をまとめてみます。 DecisionTree分類器とは？DecisionTree分類器は決定木を利用した分類器です。構造としては二分木で、各ノードで何かしらの条件により入力データが2つに分割されます。その分割を複数段階適用することでクラス分類をすると言うものになります。DecisionTree分類器については以下をご参照ください。https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifi...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[build.nvidia.comからgpt-oss-120bを使ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/1bb37e8ad6de59</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1bb37e8ad6de59</guid>
            <pubDate>Tue, 21 Oct 2025 13:38:50 GMT</pubDate>
            <content:encoded><![CDATA[今回はbuild.nvidia.comで利用できるgpt-oss-120bを利用してみました。 build.nvidia.comとは？build.nvidia.comはNVIDIAが提供しているNIMのAPIを試せる環境となっています。NIMとは公式ページにて以下のように説明されています。NVIDIA NIM™ は、クラウド、データセンター、ワークステーション、エッジなど、あらゆる NVIDIA アクセラレーテッド インフラストラクチャに最新の AI モデルを迅速にデプロイできるように、最適化された事前構築済みの推論マイクロサービスを提供します。要はマイクロサービスとして様...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LogisticRegressionの重みを可視化してみる]]></title>
            <link>https://zenn.dev/akasan/articles/f3ec2f94a385b3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f3ec2f94a385b3</guid>
            <pubDate>Mon, 20 Oct 2025 14:11:09 GMT</pubDate>
            <content:encoded><![CDATA[今回はLogisticRegressionの回帰係数を可視化して各特徴量の分類に対する寄与度を可視化してみました。 検証内容今回はscikit-learn上で利用できるirisデータを使います。irisは多クラス（３クラス）データであり特徴量は4つあります。LogisticRegressionを学習させ、その回帰係数を可視化してみます。 早速実装する 環境構築まずは必要なライブラリをインストールします。uv init iris_logistic_regression -p 3.12cd iris_logistic_regressionuv add scikit-le...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLIでもセキュアで堅牢な開発をしたい！]]></title>
            <link>https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai</link>
            <guid isPermaLink="false">https://speakerdeck.com/yunosukey/gemini-clidemosekiyuadejian-lao-nakai-fa-wositai</guid>
            <pubDate>Sun, 19 Oct 2025 04:00:00 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[imbalanced-learnを利用してアンダー/オーバーサンプリングを実施してみた]]></title>
            <link>https://zenn.dev/akasan/articles/7a148787cb3be8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/7a148787cb3be8</guid>
            <pubDate>Sun, 19 Oct 2025 03:34:17 GMT</pubDate>
            <content:encoded><![CDATA[今回はimbalanced-learnを利用してデータセットの偏りを調整する方法を試してみました。機械学習ではデータの分布がとても重要であり、偏ったデータ分布は好ましくない場合が多いです。そのような場合にデータの偏りを補正するためのライブラリとしてimbalanced-learnがあり、今回はそれを利用してみました。 データの偏りとは？文字通りですが、データに偏りがある状態をいいます。例えばある病気について、診察対象の人が病気に罹患しているかしていないかをまとめたデータセットがあったとします。仮にその病気に罹患している人が極めて少数の場合、このデータセットは大半が罹患していない人...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions の Job から WireGuard で VPN アクセス]]></title>
            <link>https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6</link>
            <guid isPermaLink="false">https://qiita.com/yteraoka/items/eef62dc05aa96fbed3b6</guid>
            <pubDate>Sat, 18 Oct 2025 09:09:27 GMT</pubDate>
            <content:encoded><![CDATA[背景GitHub Actions の Job で家のネットワークにアクセスさせたいことがあり、いったんは Squid を認証付きで publilc に公開するというのをやっていたのですが、やっぱり嬉しくないのでどうしたものかと思っていたのですが WireGuard が使...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-chefがRustのDockerビルドを高速化する話]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/18/163911</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/18/163911</guid>
            <pubDate>Sat, 18 Oct 2025 07:39:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の記事では、Rust の Docker イメージサイズを 98%削減する方法を解説しました。その中で最も重要な役割を果たしているのが cargo-chef です。この記事では、cargo-chef の仕組みと動作原理を深く掘り下げていきます。syu-m-5151.hatenablog.comcargo-chef は、Docker のレイヤーキャッシングと Cargo のビルドモデルの根本的な不整合を解決し、Rust プロジェクトのDockerビルドを5倍高速化します。Luca Palmieri が「Zero to Production In Rust」のために作成したこのツールは、ソースコード変更のたびに 20 分以上かかっていたリビルドを、依存関係をアプリケーションコードから分離してキャッシュし、2〜3 分のビルドに変えました。www.zero2prod.comcargo-chef は依存関係情報のみを捉えた「レシピ」を作成し、ソースコードが変更されても有効なままの別レイヤーで高コストな依存関係のコンパイルをキャッシュできます。約 500 の依存関係を持つ商用コードベースでは、ビルド時間が約 10 分から約 2 分に短縮され、CI/CD の速度とインシデント対応時間に直接影響を与えます。github.comRustのDockerビルドにおける根本的な問題Docker のレイヤーキャッシングは、各命令(RUN、COPY、ADD)に対してレイヤーを作成します。いずれかのレイヤーが変更されると、そのレイヤーとそれ以降のすべてのレイヤーが無効化されます。標準的な Rust Dockerfile は重大な問題に直面します: 依存関係のマニフェストとソースコードの両方を一緒にコピーする必要があるため、ソースの変更があるとビルドキャッシュ全体が無効になってしまうのです。問題のあるパターン:FROM rust:1.75WORKDIR /appCOPY . .              # マニフェストとソースを一緒にコピーRUN cargo build       # 変更のたびにすべてを再ビルドPython の pip install -r requirements.txt や Node の npm install とは異なり、Cargoには依存関係のみをビルドするネイティブな方法がありません。cargo build コマンドは、依存関係とソースのコンパイルを統一された操作として扱います。cargo build --only-deps のようなフラグは存在しません。このアーキテクチャ上の制限により、他の言語では美しく機能する標準的な Docker パターンが、Rust では壊滅的に失敗してしまいます。影響は開発ワークフロー全体に波及します。すべてのコード変更—たった 1 文字の修正でさえ—数百の依存関係の完全な再コンパイルを引き起こします。2〜4 コアの CI システムでは、ビルドが 30 分を超えることがあります。これにより、デプロイ速度、インシデント対応時間、開発者の反復サイクルに厳しい下限が生まれます。本番環境のインシデントで緊急パッチが必要な場合、その 20 分のビルドが 20 分のダウンタイムになります。Rustのビルドが特に問題になる理由Rust のコンパイルモデルは、コンパイル時間の速度よりも実行時パフォーマンスを優先します。リリースビルド(--release)は、中規模のプロジェクトで 15〜20 分かかる広範な LLVM 最適化パスを実行します。ジェネリクス、トレイト特殊化、単相化の多用により、依存関係は各使用パターンに対して相当量のコードをコンパイルします。非同期エコシステム(tokio、actix-web、tonic)はこれを悪化させます—これらのクレートは単純なアプリケーションでもコンパイルが重いのです。インクリメンタルコンパイルは存在しますが、リリースビルドではデフォルトで無効になっており、外部依存関係には役立ちません。Docker の本番ビルドは常に --release プロファイルを使用するため、遅いコンパイルパスを避けられません。依存関係のコンパイルは通常、総ビルド時間の 80〜90%を消費しますが、これらの依存関係はアプリケーションコードに比べてほとんど変更されません。この逆転した関係—最も遅い部分が最も変更されない—こそが、cargo-chef が活用するポイントです。アーキテクチャプロジェクト構造:src/main.rs - コマンドパースを含む CLI エントリポイントsrc/lib.rs - ライブラリエントリポイントsrc/recipe.rs - レシピ生成、依存関係ビルド、クッキングロジックsrc/skeleton.rs - プロジェクトスケルトンの作成とダミーファイル生成cargo-chef のアーキテクチャは 2 つの抽象化を中心としています: RecipeとSkeleton。Recipe はシリアライズ可能なコンテナで、Skeleton は実際のマニフェストデータとロックファイルを含みます。これらの構造により、コアワークフローが可能になります: 分析 → シリアライズ → 再構築 → ビルド。レシピコンセプトと動作原理「レシピ」は、ソースコードなしで依存関係をビルドするために必要な最小限の情報を捉えたJSONファイル(recipe.json)です。これは Python の requirements.txt と同じ目的を果たしますが、Rust のより複雑なプロジェクト構造に対応しています。レシピの内容:プロジェクト全体のすべての Cargo.toml ファイルとその相対パスCargo.lock ファイル(存在する場合)、正確な依存関係バージョンのためすべてのバイナリとライブラリの明示的な宣言—正規の場所(src/main.rs、src/lib.rs)にあるものでもスケルトン再構築のためのプロジェクト構造メタデータpub struct Recipe {    pub skeleton: Skeleton,}pub struct Skeleton {    manifests: Vec<Manifest>,    lock_file: Option<String>,}この構造は人間が読める JSON にシリアライズされ、レシピはデバッグ可能で検査可能です。明示的なターゲット宣言により、Cargo が通常ファイルの場所からターゲットを推測する場合でも、信頼性の高いキャッシュが保証されます。動作原理と内部メカニズムcargo-chef は、マルチステージビルドで連携する 2 つのコマンドを提供します:1. cargo chef prepare --recipe-path recipe.jsonこのコマンドは次のように現在のプロジェクトを分析します。ベースパスからディレクトリを再帰的にトラバース相対パスを保持してすべての Cargo.toml ファイルを収集依存関係バージョンロックのために Cargo.lock を読み取りSkeleton データ構造を作成マニフェスト内の明示的なターゲット宣言を確保recipe.json にシリアライズprepare コマンドは高速(通常 1 秒未満)です。ファイル構造を分析して TOML をパースするだけで、コンパイルは行わないためです。2. cargo chef cook --release --recipe-path recipe.jsonこのコマンドは次のように再構築とビルドを行います。recipe.json を Skeleton に逆シリアライズskeleton.build_minimum_project() を呼び出してディレクトリ構造を再作成すべての Cargo.toml ファイルを相対パスに書き込みCargo.lock をディスクに書き込みすべてのターゲット(main.rs、lib.rs、build.rs)に対してダミーソースファイルを作成指定されたフラグで cargo build を実行skeleton.remove_compiled_dummies() 経由でコンパイル済みダミーアーティファクトを削除ダミーファイルトリック: cargo-chef は次のように最小限の有効な Rust ファイルを作成します。// ダミーのmain.rsfn main() {}// ダミーのlib.rs// (空または最小限)これらは Cargo がコンパイル可能なプロジェクトを要求する条件を満たしますが、実際のロジックは含まれていません。その後、Cargo は通常通りすべての依存関係を解決してコンパイルし、キャッシュされたアーティファクトを生成します。ダミーアーティファクトは後でクリーンアップされ、外部依存関係のコンパイル結果のみが残ります。重要な技術的制約: cook とその後の build コマンドは、同じ作業ディレクトリから実行すべきです。これは、target/debug/deps 内の Cargo の *.d ファイルにターゲットディレクトリへの絶対パスが含まれているためです。ディレクトリを移動するとキャッシュの利用が壊れます。これは cargo-chef の制限ではなく、cargo-chef が尊重する Cargo の動作です。Docker統合とマルチステージビルドcargo-chef は、Docker のマルチステージビルド機能用に特別に設計されています。標準的なパターンは 3 つのステージを使用します:標準的な3ステージパターン:FROM lukemathwalker/cargo-chef:latest-rust-1 AS chefWORKDIR /app# ステージ1: Planner - レシピを生成FROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.json# ステージ2: Builder - 依存関係をキャッシュFROM chef AS builderCOPY --from=planner /app/recipe.json recipe.jsonRUN cargo chef cook --release --recipe-path recipe.json# ↑ このレイヤーは依存関係が変更されるまでキャッシュされる# 次にソースをコピーしてアプリケーションをビルドCOPY . .RUN cargo build --release --bin app# ステージ3: Runtime - 最小限の本番イメージFROM debian:bookworm-slim AS runtimeWORKDIR /appCOPY --from=builder /app/target/release/app /usr/local/binENTRYPOINT ["/usr/local/bin/app"]キャッシングの仕組み:各 Docker ステージは独立したキャッシングを維持します。ステージは COPY --from 文を通じてのみやり取りします。この分離が cargo-chef の効果の鍵です。planner ステージの COPY . . は planner キャッシュを無効化(ただしこれは高速)Planner はフルソースツリーから recipe.json を生成Builder ステージは COPY --from=planner 経由で recipe.json のみを受け取るrecipe.jsonのチェックサムが変更されていない限り、builderの依存関係レイヤーはキャッシュされたままCargo.toml または Cargo.lock が変更された場合にのみ recipe.json が変更されるソースコードの変更は recipe.json に影響しないため、依存関係レイヤーはキャッシュされたままキャッシュ無効化ロジック:ソースコード変更 → plannerステージ無効化                → recipe.json変更なし                → builderの依存関係レイヤーキャッシュ済み ✓                → アプリケーションビルドのみ実行依存関係変更    → plannerステージ無効化                → recipe.json変更                → builderの依存関係レイヤー無効化 ✗                → フルリビルド必要これはインセンティブを完璧に整合させます: 高コストな操作(依存関係コンパイル)は、そうあるべき時(依存関係が変更されていない時)にキャッシュされ、高速な操作(ソースコンパイル)は期待通り毎回の変更で実行されます。ビルドプロセスの統合とサポート機能cargo-chef は標準的な Cargo ワークフローとシームレスに統合し、ビルドカスタマイズの全範囲をサポートします:ビルドコマンド:build(デフォルト)check(--check フラグ経由)clippyzigbuildサポートされるオプション:プロファイル選択: --release、--debug、カスタム --profile機能: --features、--no-default-features、--all-featuresターゲット: --target、--target-dir(ファーストクラスのクロスコンパイルサポート)ターゲットタイプ: --benches、--tests、--examples、--all-targets、--bins、--binワークスペース: --workspace、--package、--manifest-pathCargo フラグ: --offline、--frozen、--locked、--verbose、--timingsツールチェーンオーバーライド: cargo +nightly chef cookワークスペースサポートは自動です。cargo-chef はワークスペース内のすべてのクレートを検出し、正しく処理します。ファイルやクレートが移動しても、cargo-chef は自動的に適応します—Dockerfile の変更は不要です。これは、プロジェクト構造をハードコードする手動アプローチに対する大きな利点です。ビルド済みDockerイメージは Docker Hub の lukemathwalker/cargo-chef で利用可能で、柔軟なタグ付けができます。latest-rust-1.75.0(特定の Rust バージョンの最新 cargo-chef)0.1.72-rust-latest(最新の Rust の特定 cargo-chef)Alpine バリアント: latest-rust-1.70.0-alpine3.18バージョンの一貫性: すべてのステージで同一のRustバージョンを使用すべきです。バージョンの不一致は、異なるコンパイラバージョンが異なるアーティファクトを生成するため、キャッシングを無効化します。主要機能と実用的なユースケース主なユースケース:1. CI/CDパイプラインの最適化 - 標準的なユースケースです。すべてのコード変更が CI で Docker ビルドをトリガーします。cargo-chef なしでは、各ビルドが 500 以上のすべての依存関係を再コンパイルします(10〜20 分)。cargo-chef があれば、変更されていない依存関係はキャッシュされ、ビルドは 2〜3 分に短縮されます。これは次のような点に直接影響します。デプロイ速度(機能をより速くリリース)インシデント対応(本番環境をより速くパッチ)開発者体験(PR へのより速いフィードバック)インフラコスト(消費される CPU 分の削減)2. マルチステージビルド - ビルド環境とランタイム環境を分離。ビルダーステージは完全な Rust ツールチェーン(800MB 以上)を含み、ランタイムステージは最小イメージ(25〜50MB)を使用します。cargo-chef は、高コストなビルダーステージをキャッシュ状態に保つことで、このパターンを実用的にします。3. ワークスペース/モノレポプロジェクト - 依存関係を共有する複数のバイナリとライブラリを自動的に処理します。手動アプローチはワークスペースで破綻します; cargo-chef は透過的に処理します。4. クロスコンパイル - --target フラグ経由でファーストクラスサポート。例: Alpine Linux デプロイのために x86_64-unknown-linux-musl バイナリを CI でビルド。ターゲット指定は依存関係キャッシング中に尊重されます。高度な最適化戦略:sccacheとの組み合わせ:FROM rust:1.75 AS baseRUN cargo install --locked cargo-chef sccacheENV RUSTC_WRAPPER=sccache SCCACHE_DIR=/sccache# ... plannerステージ ...FROM base AS builderRUN --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \    cargo chef cook --release --recipe-path recipe.jsonこの組み合わせは2層のキャッシングを提供します。cargo-chef: 粗粒度(依存関係レイヤー全体)sccache: 細粒度(個々のコンパイルアーティファクト)1 つの依存関係が変更された場合、cargo-chef はすべてを再ビルドしますが、sccache は個々のクレートコンパイルをキャッシュします。変更された依存関係のみが実際に再コンパイルされます。BuildKitキャッシュマウント:RUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=/usr/local/cargo/git \    cargo chef cook --release --recipe-path recipe.jsonこれは cargo レジストリ自体をキャッシュし、再ダウンロードを回避します。sccache および cargo-chef と組み合わせることで、Rust Docker ビルドの現在のベストプラクティスとなります。重要な制限と考慮事項作業ディレクトリの制約 - cargo cook と cargo build は、Cargo の *.d ファイル内の絶対パスのため、同じディレクトリから実行すべきです。これは Docker では煩わしくありませんが、認識すべきです。ローカルパス依存関係 - プロジェクト外の依存関係(path = "../other-crate" で指定)は、変更されていなくてもゼロから再ビルドされます。これは、タイムスタンプベースのフィンガープリントに関連する Cargo の制限(issue #2644)です。コピーするとタイムスタンプが変更され、フィンガープリントが無効になります。ローカル開発には不向き - cargo-chef はコンテナビルド専用に設計されています。既存のコードベースでローカルに実行すると、ファイルが上書きされる可能性があります。このツールは、ターミナル環境で実行される場合の安全警告を含みます。ワークスペースの動作 - cargo chef cook はデフォルトですべてのワークスペースメンバーをビルドします。1 つのサービスのみが必要な大規模ワークスペースの場合、これによりビルド時間が増加する可能性があります。回避策には、ターゲットビルドフラグまたはサービスごとの個別の Dockerfile が含まれます。最適なユースケース - cargo-chef は以下に最大の利益を提供します。中規模から大規模プロジェクト(500 以上の依存関係)安定した依存関係ツリー(まれに変更)頻繁なデプロイ(CI/CD 環境)共有ビルドインフラを持つチーム環境非常に小規模なプロジェクト(少数の依存関係)の場合、オーバーヘッドが利益を上回る可能性があります。設計パターンとアーキテクチャの決定注目すべき技術的決定:JSONレシピ形式 - バイナリ形式ではなく JSON を使用し、レシピは人間が読めてデバッグ可能です。recipe.json を検査して、cargo-chef が何を抽出したかを正確に確認できます。明示的なターゲット宣言 - 正規の場所にある場合でも、すべてのターゲットを明示的に宣言するように Cargo.toml を変更します。これにより、キャッシュ無効化全体で Cargo がそれらを確実に認識します。マニフェスト操作 - 手動パースではなく、ワークスペース構造へのプログラマティックアクセスに cargo_metadata クレートを使用します。これにより Cargo の進化に伴う堅牢性が提供されます。TOML順序保持 - preserve_order 機能を持つ TOML を使用して、シリアライゼーションを通じたラウンドトリップ時にマニフェスト構造の整合性を維持します。安全機能 - atty クレートを使用したターミナル検出。対話的に実行された場合の警告メッセージ。ローカル環境での偶発的なファイル上書きを防ぐために、明示的なユーザー確認が必要です。採用された設計パターン:ビルダーパターン(Recipe/Skeleton 構築)コマンドパターン(CommandArg enum)ファサードパターン(複雑さを隠すシンプルな 2 コマンドインターフェース)テンプレートメソッドパターン(build_dependencies オーケストレーション)おわりにcargo-chef は、Cargo 自体が提供しない依存関係とソースコンパイルの分離を作成することで、Rust 特有の Docker レイヤーキャッシング問題を解決します。このツールの優雅さはシンプルさにあります: 依存関係管理を再発明するのではなく、Cargo が最も得意とすることを可能にする最小限の有効なプロジェクト構造を作成し、Docker のレイヤーキャッシングメカニズムと完璧に整合します。必須のベストプラクティス:すべての Docker ステージで同一の Rust バージョンを使用cook と build 間で一貫した作業ディレクトリを維持レジストリキャッシング用の BuildKit キャッシュマウントと組み合わせる細粒度のコンパイルキャッシング用に sccache を追加最小限のランタイムイメージを持つマルチステージビルドを使用.dockerignore でビルドコンテキストを最小化cargo-chefを使用すべき場合:中規模から大規模の Rust プロジェクトCI/CD Docker ビルド安定した依存関係ツリーを持つプロジェクト高速な反復サイクルを必要とするチーム迅速なインシデント対応を必要とする本番デプロイ。cargo-chef は、Docker 経由で Rust アプリケーションをデプロイするチームにとって不可欠なツールに成熟しており、より良い開発者体験、より速いデプロイ、削減されたインフラコストに直接変換される測定可能なパフォーマンス改善を提供します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[glomを使ってdictのネストを取り扱ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/1d839a9083627c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1d839a9083627c</guid>
            <pubDate>Sat, 18 Oct 2025 06:23:24 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonのライブラリであるglomを使ってみました。glomを利用するとネストされたdictを扱う際にいくつもキーにアクセスするためにカッコを使わなくても簡単にアクセスできるようになります。ちなみに、なぜこのライブラリを知ったかというと以下の記事が気になって読んでいると出てきたので調べてみた次第です。ぜひ以下の記事もご覧ください。https://medium.com/@abdur.rahman12/the-python-toolbelt-12-tiny-libraries-that-solve-big-problems-9a6be9309e43 glomとは？glom...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIエージェント入門 〜基礎からMCP・A2Aまで〜]]></title>
            <link>https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade</link>
            <guid isPermaLink="false">https://speakerdeck.com/shukob/aiezientoru-men-ji-chu-karamcpa2amade</guid>
            <pubDate>Sat, 18 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/373059/2025年10月18日、オープンソースカンファレンス2025 Online/Fallで発表した資料です。今話題となっている「AIエージェント」について、要素技術となる生成AIを用いてどのように自律的に動作するのか基礎を説明した後、AIが外部のツールやデータにアクセスするためのオープンプロトコルであるMCP（Model Context Protocol）や、複数のエージェントによる分業と連携を可能にするオープンプロトコルA2A（Agent-to-Agent）について解説しました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[英語4文字のセキュリティ用語あれこれ説明できる？ - SBOM/SAST/DAST...]]></title>
            <link>https://zenn.dev/r4ynode/articles/security-english-words</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/security-english-words</guid>
            <pubDate>Sat, 18 Oct 2025 03:00:01 GMT</pubDate>
            <content:encoded><![CDATA[セキュリティの話になると、謎の4文字くらいの英語が羅列しているのを見たことありません？それらのセキュリティ用語を説明できますか？私はできません多すぎて分からなくなるので少し整理します。!内容は概要程度です。機能面についても利用するソフトウェアやベンダーに依存するため参考程度に。 早見表用語一言解説SBOMソフトウェア部品表。構成要素を一覧化する。SCAOSSやライブラリの脆弱性・ライセンス管理。ASTアプリの脆弱性を検出するセキュリティテスト。SASTソースコードを静的解析して脆弱性検出。DAST実行中アプリに攻撃して...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[二つのCubeの重なり部分を削除したUSD primの生成方法]]></title>
            <link>https://zenn.dev/akasan/articles/0b0a014a5eb790</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/0b0a014a5eb790</guid>
            <pubDate>Fri, 17 Oct 2025 13:58:23 GMT</pubDate>
            <content:encoded><![CDATA[今回はふと気になったので、OpenUSDで二つのCubeを生成してその重なっているところを削除したような図形を作る方法を調べてみました。※ ChatGPTに作り方を聞きました。いつもお世話になっております。 今回やってみたかったこともう少し厳密に今回やってみたかったことを文字起こしすると以下のようになります。二つのCubeをA、BとするAとBには重なる部分があるとするAからAとBが重なっている場所を削除する 早速ChatGPTに聞いてみた質問内容としては以下のように問い合わせました。pxr.UsdGeom.Cubeで作成したキューブAとBがあるとします。例えば...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RustのDockerfile、2025年はこれでいこう]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/17/070250</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/17/070250</guid>
            <pubDate>Thu, 16 Oct 2025 22:02:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「Dockerでビルドすると遅いんだよね」「イメージが2GB超えちゃって…」そんな会話はもう過去の話です。2025年、コンテナ化は劇的に進化しました。Rustも例外ではありません。cargo-chefとBuildKitキャッシュマウントの組み合わせでビルド時間を5-10倍短縮、2.63GBのイメージをdistrolessイメージで約50MB、musl静的リンクならわずか1.7MBという値を達成できます。この記事では、実践的なDockerfileパターンとベンチマーク結果を詳しく解説します。実際に検証したAxum Webアプリケーションでは、distroless版で50.3MB、musl+scratch版で1.71MBを達成しました。中規模プロジェクト（約500の依存関係）での初回ビルドは10分、コード変更後の再ビルドはわずか40秒です。信じられないかもですが、これが2025年の現実です。ちゃんとやれって話です。あと皆さんのDockerfileも教えて欲しいです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。2025年の重要なアップデートRust 2024 Edition（2025年2月20日リリース）Rust 1.85.0でRust 2024 Editionが安定版になりました。Docker環境でRust 1.85以降を使えば、Edition 2024の機能が使えます。doc.rust-lang.orgblog.rust-lang.orgDocker関連の進化Docker Engine v28：コンテナネットワーキングのセキュリティ強化、AMD GPUサポートdocs.docker.comdocker init GA：Rustプロジェクト用の最適化されたDockerfile自動生成docs.docker.comDocker Bake GA：複雑なビルド設定の宣言的管理docs.docker.comBuildKit 0.25.1：Git URLクエリパラメータ、シークレットの環境変数化など新機能github.com基本的な考え方マルチステージビルドは前提条件2025年でマルチステージビルドを使わないのは、正直あり得ません。まずメンテナンス性が格段に向上します。最終的な成果物以外ではサイズを意識したトリッキーな記述が不要になるため、Dockerfileの可読性が劇的に良くなります。次にビルド速度のアップ。並列化、キャッシュマウント、tmpfsなど最適化オプションが豊富に使えるようになり、ビルドパイプライン全体が高速化します。そして何よりセキュリティの向上。シークレット管理の仕組みが標準化され、機密情報の取り扱いが安全になりました。docs.docker.comCOPYは最小限に、--mountを活用COPYが登場するのは、実質的に2つの場面だけです。マルチステージビルドで別ステージから成果物を持ってくる場合と、最終ステージでアプリケーションバイナリをコピーする場合。それ以外、特にソースコードのビルド時には--mount=type=bindを使用します。docs.docker.com必ず記述すべきおまじない# syntax=docker/dockerfile:1この1行を必ず先頭に記述します。最新のDockerfile構文が自動的に利用され、新機能が使えるようになります。docs.docker.com2025年のDockerfileはこれでやります前置きはこれくらいにして、実際のコードを見ていきましょう。これが2025年のRust標準Dockerfileです。cargo-chefによる依存関係の分離、BuildKitキャッシュマウント、distrolessイメージ、非rootユーザー実行。この記事で解説してきたベストプラクティスのすべてが、この1つのテンプレートに詰め込まれています。# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85ARG APP_NAME=myapp# cargo-chefを使った依存関係キャッシングFROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builder# 依存関係のビルド（キャッシュ可能）COPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    cargo chef cook --release --recipe-path recipe.json# アプリケーションのビルドCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release --bin ${APP_NAME} && \    cp ./target/release/${APP_NAME} /bin/server# テストステージ（オプション）FROM chef AS testCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=/usr/local/cargo/git \    cargo test# 本番ステージ：distrolessFROM gcr.io/distroless/cc-debian12:nonroot AS runtimeCOPY --from=builder /bin/server /app/WORKDIR /appEXPOSE 8000ENTRYPOINT ["/app/server"]このDockerfileの主な特徴cargo-chefによる依存関係の分離とキャッシングBuildKitキャッシュマウントでレイヤーを跨いだキャッシュdistrolessによる最小サイズと高セキュリティ非rootユーザー（:nonrootタグ）での実行オプショナルなテストステージビルド最適化の3つの柱1. cargo-chefcargo-chefは、Rustの依存関係管理をDockerレイヤーキャッシュに適合させる画期的なツールです。依存関係のコンパイルとソースコードのコンパイルを完全に分離します。動作メカニズム（2段階）：cargo chef prepare：Cargo.tomlとCargo.lockを解析してrecipe.jsonを作成cargo chef cook：最小限のプロジェクト構造を再構築して依存関係のみをビルド重要：同じRustバージョンと作業ディレクトリを全ステージで使用すること。異なるバージョンを使うとキャッシュが無効化されます。実測データ：cargo-chefのみで55%の改善cargo-chef + sccacheで79%の改善（34秒→7秒）商用プロジェクト（14,000行、500依存関係）で10分→2分github.com2. BuildKitキャッシュマウントBuildKitのキャッシュマウント（Docker 18.09以降）を使うと、レイヤー無効化を超えて永続化するキャッシュボリュームが利用できます。3つの重要なキャッシュポイント：RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release/usr/local/cargo/registry：crates.ioからのダウンロード/usr/local/cargo/git：Git依存関係/app/target：ビルド成果物sharing=lockedパラメータは排他アクセスを保証し、パッケージマネージャーの破損を防ぎます。CI環境でのキャッシュ共有：# GitHub Actions- uses: docker/build-push-action@v6  with:    cache-from: type=gha    cache-to: type=gha,mode=maxパフォーマンスベンチマーク：ベースライン：90.60秒BuildKitキャッシュマウント：15.63秒（5.8倍高速）cargo-chef：18.81秒（4.8倍高速）三位一体（chef + BuildKit + sccache）：7-12秒（7.5-13倍高速）docs.docker.com3. sccachesccache（v0.7.x）はMozilla製のccache風コンパイララッパーで、個々のコンパイル成果物を細粒度でキャッシュします。github.comFROM rust:1.85 AS builder# sccacheのインストールと設定RUN cargo install sccache --version ^0.7ENV RUSTC_WRAPPER=sccache \    SCCACHE_DIR=/sccache \    CARGO_INCREMENTAL=0WORKDIR /appRUN --mount=type=cache,target=/usr/local/cargo/registry \    --mount=type=cache,target=$SCCACHE_DIR,sharing=locked \    --mount=type=bind,target=. \    cargo build --release重要：CARGO_INCREMENTAL=0は必須。インクリメンタルコンパイルとsccacheは競合します。キャッシュヒット率：初回ビルド：0%ソースコード変更のみ：85-95%依存関係を更新した時：60-75%注意点：sccacheの効果は環境によって大きく異なります。一部の環境では効果が薄く、逆にオーバーヘッドとなる場合があります。自環境でのベンチマークが必須です。イメージサイズの最適化：ベースイメージ選択戦略ビルドステージ：rust:slim推奨2025年はrust:slim（Debian系）でよいと思っています。console.cloud.google.comFROM rust:1.85-slim-bookworm AS builder理由はシンプルです。Debian stable（bookworm）ベースでglibcを使用しているため、広範な互換性とマルチスレッドワークロードでの優れたパフォーマンスを発揮します。完全版のrust:latestが624MBもあるのに対し、rust:slimはコンパイルに必要な最小限のパッケージだけを含んでいます。無駄がありません。rust:alpineは避けてください。 muslの互換性問題に加えて、マルチスレッドアプリケーションで最大30倍のパフォーマンス劣化が報告されています。イメージサイズの小ささに惹かれる気持ちはわかりますが、本番環境でこの劣化は致命的です。https://hub.docker.com/_/rust最終ステージ：distroless推奨gcr.io/distroless/cc-debian12が2025年の標準です。FROM gcr.io/distroless/cc-debian12:nonrootdistrolessの特徴：サイズ：21-29MBglibc、SSL証明書、タイムゾーンデータ、/etc/passwdを含むパッケージマネージャー、シェル不要なバイナリを完全排除SLSA 2準拠、cosign署名検証が可能CVEスキャンで従来イメージより50-80%少ない脆弱性:nonrootタグでUID 65534（nobody）として非rootで実行github.comイメージサイズ比較（実測値） イメージ構成  サイズ  用途  特徴  scratch + musl（実測）  1.71MB  CLIツール最小化  完全静的リンク  distroless/static  2-3MB  静的リンクバイナリ  最小限のファイル  distroless/cc-debian12（実測）  50.3MB  Webアプリ推奨  glibc  debian-slim  80-120MB  フル互換性  デバッグツールあり  rust:latest（未最適化）  2.63GB  開発専用  ビルドツール込み 実測削減率：rust:latest（2.63GB）→ distroless（50.3MB）：98.1%削減rust:latest（2.63GB）→ musl+scratch（1.71MB）：99.9%削減静的リンク vs 動的リンクmusl（x86_64-unknown-linux-musl）での静的リンク：FROM rust:1.85-alpine AS builderRUN apk add --no-cache musl-devWORKDIR /app# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo build --release --target x86_64-unknown-linux-musl && \    rm -rf src# アプリケーションのビルドCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/myapp /myappENTRYPOINT ["/myapp"]利点：依存関係ゼロで完全にポータブルscratchコンテナで実行可能イメージサイズ5-10MB欠点：シングルスレッドで0.9-1.0倍、マルチスレッドで0.03-0.5倍のパフォーマンス一部依存関係でsegfaultのリスク本番環境の推奨：複雑なアプリケーション（Webサーバー、DB接続）：glibc + distroless/cc-debian12シンプルなCLIツール：musl + scratchを検討パフォーマンスが重要：必ずglibcを使用マルチアーキテクチャビルドlinux/amd64とlinux/arm64の両対応が2025年の標準要件です。cargo-zigbuild：セットアップゼロのクロスコンパイルcargo-zigbuild（v0.20.1）はZigツールチェインを使い、セットアップ不要でクロスコンパイルできます。github.com# syntax=docker/dockerfile:1ARG RUST_VERSION=1.85FROM --platform=$BUILDPLATFORM rust:${RUST_VERSION}-alpine AS builderWORKDIR /app# Zigとcargo-zigbuildのインストールRUN apk add --no-cache musl-dev openssl-dev zigRUN cargo install --locked cargo-zigbuild# ターゲットの設定ARG TARGETPLATFORMRUN case ${TARGETPLATFORM} in \    "linux/amd64") echo x86_64-unknown-linux-musl > /rust_target ;; \    "linux/arm64") echo aarch64-unknown-linux-musl > /rust_target ;; \    esac && \    rustup target add $(cat /rust_target)# 依存関係とビルドCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo zigbuild --release --target $(cat /rust_target) && \    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo zigbuild --release --target $(cat /rust_target)FROM alpine:latestARG TARGETPLATFORMCOPY --from=builder /app/target/*/release/app /appCMD ["/app"]重要：--platform=$BUILDPLATFORMを使うと、ビルド自体はネイティブアーキテクチャで実行できるので、QEMUエミュレーションより圧倒的に速いです（QEMUエミュレーションは16-25倍遅い）。実測データ：ネイティブビルド：2-3分QEMUエミュレーション：50分（16-25倍遅い）cargo-zigbuildクロスコンパイル：13分Docker buildxでのマルチプラットフォームビルド# ビルダーの作成docker buildx create --name container-builder \    --driver docker-container --bootstrap --use# マルチプラットフォームビルドdocker buildx build \    --platform linux/amd64,linux/arm64 \    -t myimage:latest \    --push .https://docs.docker.com/build/buildx/docs.docker.comセキュリティベストプラクティス1. 非rootユーザーで実行distroless :nonrootタグが最も簡単：FROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /app/target/release/myapp /usr/local/bin/CMD ["/usr/local/bin/myapp"]自動的にUID 65534（nobody）として実行されます。カスタムユーザー作成：FROM debian:bookworm-slimARG UID=10001RUN adduser \    --disabled-password \    --gecos "" \    --home "/nonexistent" \    --shell "/sbin/nologin" \    --no-create-home \    --uid "${UID}" \    appuserUSER appuserCOPY --from=builder /app/target/release/myapp /app/CMD ["/app/myapp"]2. 脆弱性スキャンTrivy（推奨）：# イメージスキャンdocker run --rm -v /var/run/docker.sock:/var/run/docker.sock \    aquasec/trivy image myapp:latest# CI/CD統合- name: Run Trivy scan  uses: aquasecurity/trivy-action@master  with:    image-ref: 'myapp:${{ github.sha }}'    severity: 'CRITICAL,HIGH'    exit-code: '1'github.comdistrolessのセキュリティ優位性：Alpine（musl）からChiseled Ubuntu（glibc）への移行で30+ CVEが0 CVEにdistrolessイメージはAlpineより50-80%少ないCVEパッケージマネージャー不在により攻撃ベクトル削減SLSA 2準拠、cosign署名認証3. シークレット管理絶対に避けるべき：環境変数へのシークレット設定イメージに焼き込まれてしまいます。正しい方法：# ビルド時シークレットRUN --mount=type=secret,id=api_token,env=API_TOKEN \    cargo build --release# 実行時docker build --secret id=api_token,env=API_TOKEN .4. イメージバージョンのピン留め# ❌ 避けるべきFROM rust:latest# ✅ 推奨FROM rust:1.85-slim-bookwormユースケース別DockerfileWebアプリケーション（Axum / Actix-web）上記の「標準Dockerfile」パターンをそのまま使用できます。CLIツール（完全静的リンク）# syntax=docker/dockerfile:1FROM rust:1.85-alpine AS builderWORKDIR /appRUN apk add --no-cache musl-dev openssl-dev openssl-libs-static# 依存関係のキャッシュCOPY Cargo.toml Cargo.lock ./RUN --mount=type=cache,target=/usr/local/cargo/registry \    mkdir src && echo "fn main() {}" > src/main.rs && \    cargo build --release --target x86_64-unknown-linux-musl && \    rm -rf srcCOPY src ./srcRUN --mount=type=cache,target=/usr/local/cargo/registry \    cargo build --release --target x86_64-unknown-linux-muslFROM scratchCOPY --from=builder /app/target/x86_64-unknown-linux-musl/release/cli-tool /app/ENTRYPOINT ["/app/cli-tool"]シェルエイリアスは以下のように設定できます。alias my-cli='docker run --rm -v $(pwd):/data my-cli-image'ワークスペース（モノレポ）対応# syntax=docker/dockerfile:1ARG SERVICE_NAME=api-gatewayARG RUST_VERSION=1.85FROM lukemathwalker/cargo-chef:latest-rust-${RUST_VERSION} AS chefWORKDIR /appFROM chef AS plannerCOPY . .RUN cargo chef prepare --recipe-path recipe.jsonFROM chef AS builderARG SERVICE_NAMECOPY --from=planner /app/recipe.json recipe.jsonRUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/usr/local/cargo/git,sharing=locked \    cargo chef cook --release --bin ${SERVICE_NAME} --recipe-path recipe.jsonCOPY . .RUN --mount=type=cache,target=/usr/local/cargo/registry,sharing=locked \    --mount=type=cache,target=/app/target,sharing=locked \    cargo build --release --bin ${SERVICE_NAME} && \    cp ./target/release/${SERVICE_NAME} /bin/serviceFROM gcr.io/distroless/cc-debian12:nonrootCOPY --from=builder /bin/service /app/ENTRYPOINT ["/app/service"]異なるサービスを同じDockerfileから生成できます。docker build --build-arg SERVICE_NAME=api-gateway -t gateway .docker build --build-arg SERVICE_NAME=user-service -t users .実践的な検証結果実際のAxum Webアプリケーション（依存関係82個）で3つの戦略を検証しました。検証環境：CPU: Apple M-series (ARM64)Docker: Colima on macOSRust: 1.85 (Edition 2024)3つのパターン比較パターン1: Naive（最適化なし）- デフォルトの実態Dockerfile.naive は何も工夫しないシンプルなビルドです。これが「デフォルトの何もしていない状態」です。⚠️ デフォルト状態のビルド結果初回ビルド時間: 約10-15分（依存関係82個を全てコンパイル）ソースコード変更後の再ビルド: 約10-15分（依存関係も毎回再コンパイル）最終イメージサイズ: 2.63GBセキュリティ: rootユーザー、開発ツール込み（脆弱性大）問題点：ソースコード1行変更するだけで10-15分のビルドが毎回走るイメージに不要なRustコンパイラ（500MB）、ビルドツール、ドキュメントが全て含まれるマルチステージビルドがないため、最終イメージが巨大cargo-chefがないため、依存関係とソースコードが分離されていないパターン2: Baseline（cargo-chef + distroless）Dockerfile は2025年の推奨パターンです。ビルド結果ビルド時間: 38秒（依存関係キャッシュ済み）最終イメージサイズ: 50.3MBセキュリティ: 非rootユーザー（UID 65534）、最小限のファイルTrivy脆弱性: 0 HIGH/CRITICALパターン3: Ultra-minimal（musl + scratch）Dockerfile.musl は最小サイズを優先したパターンです。ビルド結果ビルド時間: 46秒（依存関係キャッシュ済み）最終イメージサイズ: 1.71MBセキュリティ: rootユーザー（scratchに制限あり）比較結果まとめ 項目  Naive (未最適化)  Baseline (distroless)  Ultra-minimal (musl)  イメージサイズ  2.63GB  50.3MB  1.71MB  削減率  - (100%)  98.1%削減  99.9%削減  ビルド時間  30秒  38秒  46秒  マルチステージ  ❌ なし  ✅ あり (4段階)  ✅ あり (2段階)  キャッシュ最適化  ❌ なし  ✅ cargo-chef + BuildKit  ✅ BuildKit  ベースイメージ  rust:1.85 (full)  distroless/cc-debian12  scratch  リンク方式  動的（glibc）  動的（glibc）  静的（musl）  開発ツール  ❌ 含まれる  ✅ 除去済み  ✅ 除去済み  セキュリティ  ❌ 低  ✅ 高  ⚠️ 中  デバッグ  ✅ 可能  ❌ 困難  ❌ 不可能 パフォーマンスベンチマーク商用プロジェクト（14,000行、500依存関係）：最適化なし：10分cargo-chef使用：2分（5倍高速化）大規模ワークスペース（400 crate、1500依存関係）：未最適化：約65分最適化後：約2分（30倍以上の改善）検証の再現方法このリポジトリで実際に試せます。# Baseline版のビルドdocker build -t rust-demo:baseline .# Ultra-minimal版のビルドdocker build -f Dockerfile.musl -t rust-demo:musl .# サイズ比較docker images | grep rust-demo# 動作確認docker run -p 8000:8000 rust-demo:baselinedocker run -p 8001:8000 rust-demo:muslよくある問題と解決策OpenSSLリンクエラーエラー： "Could not find directory of OpenSSL installation"解決策1：vendored OpenSSL（最も簡単）[dependencies]openssl = { version = "0.10", features = ["vendored"] }解決策2：Alpine適切パッケージFROM rust:1.85-alpineRUN apk add --no-cache openssl-dev openssl-libs-static musl-dev解決策3：Debianベース使用FROM rust:1.85-slim-bookwormRUN apt-get update && apt-get install -y pkg-config libssl-dev解決策4：rustls（Rust-native TLS）[dependencies]reqwest = { version = "0.11", features = ["rustls-tls"], default-features = false }muslリンクエラーAlpine向け：FROM rust:1.85-alpineRUN apk add musl-dev openssl-dev openssl-libs-staticRUN rustup target add x86_64-unknown-linux-muslENV PKG_CONFIG_ALLOW_CROSS=1RUN cargo build --release --target x86_64-unknown-linux-musl必要な環境変数：RUSTFLAGS='-C target-feature=+crt-static'PKG_CONFIG_ALLOW_CROSS=1OPENSSL_STATIC=1（システムOpenSSL使用時）DNS解決エラー（scratchイメージ）解決策1：distroless/static使用FROM gcr.io/distroless/static-debian12解決策2：Pure Rust DNSリゾルバー[dependencies]reqwest = { version = "0.11", features = ["trust-dns"] }解決策3：必要ファイルコピーFROM alpine:latest AS ca-certificatesRUN apk add -U --no-cache ca-certificatesFROM scratchCOPY --from=ca-certificates /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/.dockerignoreの重要性.dockerignoreがないと、target/ディレクトリ（数GB）がビルドコンテキストに含まれ、ビルドが遅くなります。# .dockerignoretarget/.git/.env*.log効果: ビルドコンテキストのサイズを数GBから数MBに削減 → ビルド開始が高速化。イメージサイズ肥大化一般的原因と解決策：最終イメージにビルドツール含む → マルチステージビルドで93%削減本番環境でfull rustイメージを使用 → slimランタイムベースで95%削減バイナリにデバッグシンボルが含まれる → strip target/release/myappで30-40%削減開発依存関係 → プロファイル設定[profile.release]strip = truelto = truecodegen-units = 12025年の新ツール活用docker init - プロジェクトの素早い立ち上げ# プロジェクトディレクトリで実行docker init# Rustを選択すると自動生成：# - Dockerfile# - compose.yaml# - .dockerignore# - README.Docker.mddocs.docker.comDocker Bake - 複雑なビルドの管理docker-bake.hcl:group "default" {  targets = ["app"]}variable "TAG" {  default = "latest"}target "app" {  context = "."  dockerfile = "Dockerfile"  tags = ["myapp:${TAG}"]  platforms = ["linux/amd64", "linux/arm64"]  cache-from = ["type=registry,ref=myapp:cache"]  cache-to = ["type=registry,ref=myapp:cache,mode=max"]}# 実行docker buildx bake# 変数をオーバーライドdocker buildx bake --set TAG=v1.0.0docs.docker.comおわりにこの記事では、2025年時点でのRust Dockerのベストプラクティスを包括的に解説しました。cargo-chefによる依存関係の分離キャッシング、BuildKitの永続キャッシュマウント、distrolessイメージによるセキュリティ強化という3つの柱を中心に、実践的なDockerfileパターンと実測データを提供しています。Rustのコンテナ化は長い間「ビルドが遅い」「イメージが大きい」という課題を抱えていました。コンパイル時間の長さは諦めるしかなく、数GBのイメージサイズは「Rustだから仕方ない」と言われてきました。しかし、2025年現在、その課題は完全に解決しました。適切な最適化で、ビルド時間を5-10倍短縮、イメージサイズを98-99%削減できます。これは単なる理論ではなく、実際のプロダクション環境で日々使われている技術です。2025年のゴールデンルールこの記事で紹介した技術を実践する際は、以下の10のポイントを押さえておくといいでしょう。# syntax=docker/dockerfile:1を必ず記述 - 最新のDockerfile構文を自動利用cargo-chefで依存関係を分離 - 5-10倍のビルド高速化を実現BuildKitキャッシュマウントを活用 - レイヤーを超える永続的なキャッシュdistroless/cc-debian12:nonrootを使用 - 50MB、非root、高セキュリティrust:slim-bookwormでビルド - Alpineは避ける（マルチスレッド性能問題）RUN --mount=type=bindでソースコードをマウント - COPYの最小化マルチステージビルドは必須 - 2025年の前提条件非rootユーザーで実行 - セキュリティの基本原則TrivyまたはGrypeでスキャン - 継続的なセキュリティ検証イメージバージョンをピン留め - :latestは避ける大半の本番ワークロードには、glibc + distroless/cc-debian12 + cargo-chefの組み合わせが最適解です。この構成により、50MBの小サイズ、2分の高速ビルド、フルパフォーマンス、優れたセキュリティプロファイルを実現できます。マルチスレッドアプリケーションでmuslを使う場合、1点だけ注意が必要です。最大30倍のパフォーマンス劣化リスクがあるので、本番環境への導入前に必ずベンチマークで検証しましょう。イメージサイズだけで判断すると、後で後悔します。2025年のRust Dockerは、従来の課題を完全に克服しました。高速、小サイズ、セキュア、マルチアーキテクチャ対応の成熟した技術スタックになっています。この記事で紹介した標準Dockerfileパターンは、そのままプロダクション環境で使える構成です。まずは標準パターンから始めて、必要なら sccache や cargo-zigbuild などの高度な最適化を追加するといいでしょう。Rustエコシステムの進化とDockerの機能強化で、今後もさらに改善していくはずです。この記事が、あなたのRustアプリケーションのコンテナ化に役立てば嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[skorchを使ってPyTorchモデルを学習してみた]]></title>
            <link>https://zenn.dev/akasan/articles/e8fd84246d013c</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e8fd84246d013c</guid>
            <pubDate>Thu, 16 Oct 2025 12:49:36 GMT</pubDate>
            <content:encoded><![CDATA[今回はskorchを使ってPyTorchのモデルを学習してみました。skorchを利用すると、scikit-learnと同じ使い勝手でモデルを学習できるようになります。 skorchとは？先ほども書いたように、skorchを利用するとscikit-learnと互換性がある記述方式でPyTorchのモデルを学習できます。後ほどサンプルを見ながら進めますが、PyTorchで定義したモデルをskorchに受け渡して学習に利用できます。https://github.com/skorch-dev/skorch 早速使ってみる今回はGitHubに乗っているサンプルを元に使ってみます。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[baconを知らずにRust書いてた]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/16/170800</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/16/170800</guid>
            <pubDate>Thu, 16 Oct 2025 08:08:00 GMT</pubDate>
            <content:encoded><![CDATA[cargo-watch、やめるってよRustを書いてると、気づくんですよね。保存ボタンを押すたび、手動でcargo checkとかcargo testとか叩いてる自分に。「あれ、俺って原始人だっけ？」みたいな気持ちになる。そこで救世主として現れたのがcargo-watchだったわけです。過去形。github.comそう、cargo-watchはもうメンテされてないんです。引退しちゃった。ここで一旦、真面目な話を。10年以上もcargo-watchとwatchexecっていうOSSプロジェクトを守り続けてきたFélix Saparelliさんに、心から敬意と感謝を。あなたのおかげで、世界中の無数のRust開発者が「あ、これ便利じゃん」って生産性爆上げできたんです。本当にありがとうございました。で、公式READMEには作者本人がこう書き残してる。"It's time to let it go. Use Bacon. Remember Cargo Watch."なんかもう、エモすぎません？10年以上続いたプロジェクトが、バトンを次世代に渡して静かに去っていく感じ。その後継者がbacon。そして汎用性の塊みたいなwatchexec。ベーコンって名前、朝ごはん感あるけど、これが本当にすごいんですよ。というわけでこの記事では、Rust開発で使えるファイル監視ツールについて解説していきます。cargo-watchロス、今日で終わりにしましょう。baconって何？baconは、Rust専用に作られたバックグラウンドコードチェッカーです。エディタの隣で動かしておくと、ファイルを保存するたびに自動でコンパイルチェックを走らせて、エラーや警告をリアルタイムで表示してくれます。github.comcargo-watchとの違いcargo-watchの作者が「baconこそが自分の理想だった」と語っているほど、baconは進化しています。TUIで見やすい - エラーが警告より先に表示され、スクロール不要キーボード操作 - tでテスト、cでClippy、dでドキュメントと一瞬で切り替え小さい画面でも快適 - ターミナルのサイズに合わせて表示を最適化Rust Analyzerと競合しない - 開発体験がスムーズインストール# 基本インストールcargo install --locked bacon# オプション機能も入れる（クリップボード、サウンド）cargo install --locked bacon --features "clipboard sound"基本的な使い方プロジェクトのルートでbaconを起動するだけ。cd your-rust-projectbaconデフォルトではcargo checkが走ります。ファイルを保存すると自動で再チェック。主要なキーボードショートカットbaconの真価はキーボードショートカットにあります。t - テスト実行に切り替えc - Clippyに切り替えd - ドキュメントをブラウザで開くf - テスト失敗時、そのテストだけに絞り込みEsc - 前のジョブに戻るCtrl+j - すべてのジョブ一覧を表示h - ヘルプ表示q - 終了特定のジョブで起動# テストを監視bacon test# Clippyを監視bacon clippy# 厳格なClippyルール（pedantic）bacon pedantic# 高速テストランナー（nextest）bacon nextest# すべてのターゲットをチェックbacon check-all# 特定のジョブを指定bacon --job my-custom-jobbacon.toml で設定をカスタマイズプロジェクトに合わせてジョブを定義できます。# 設定ファイルを生成bacon --init設定例# bacon.toml# Windows向けのチェック[jobs.check-win]command = ["cargo", "check", "--target", "x86_64-pc-windows-gnu"]# 厳しめのClippy[jobs.clippy-strict]command = [    "cargo", "clippy", "--",    "-D", "warnings",    "-A", "clippy::collapsible_if",]need_stdout = false# サンプルをチェック[jobs.check-examples]command = ["cargo", "check", "--examples", "--color", "always"]watch = ["examples"]  # srcは自動で監視される# 実行ジョブ[jobs.run]command = ["cargo", "run"]allow_warnings = trueneed_stdout = true# キーバインディングのカスタマイズ[keybindings]shift-c = "job:clippy-strict"r = "job:run"設定しておいてよいことドキュメントを素早く確認[jobs.doc-open]command = ["cargo", "doc", "--no-deps", "--open"]need_stdout = falseon_success = "back"  # ドキュメントが開いたら前のジョブに戻る長時間実行するアプリケーション[jobs.server]command = ["cargo", "run"]allow_warnings = trueneed_stdout = truebackground = falseon_change_strategy = "kill_then_restart"watchexecとの使い分けbaconはRust専用ですが、watchexecは汎用的なファイル監視ツールです。github.comwatchexecを使うべき場合# インストールcargo install watchexec-cli# 基本的な使い方watchexec --restart cargo run# 特定の拡張子だけ監視watchexec -e rs,toml cargo test# デバウンス設定watchexec -d 2000 cargo checkwatchexecが向いているケース：- Rust以外の言語やツール- シェルスクリプトの実行- rsyncなどの同期処理- より細かい制御が必要な場合# 例：TypeScriptのビルドwatchexec -e ts,tsx npm run build# 例：ファイル同期watchexec -w src -- rsync -avhP ./src/ ./backup/実践的なワークフロー開発時のセットアップターミナルを分割左：Vim/Neovim右上：bacon右下：通常のシェル私はWarpを使ってペイン分割している。baconの起動bacon  # デフォルトでcheckが走るコードを書く保存すると自動でチェックエラーがあれば即座に表示エラーが消えたらClippyの警告が見えるテストを書くtキーでテストモードに切り替え失敗したらfで絞り込み修正したらEscで全テストに戻る最終チェックcキーでClippyの提案を確認コード品質を向上ちょっとしたTipsシェルエイリアスで効率化頻繁に使うコマンドをエイリアス化すると便利です。# ~/.zshrc または ~/.bashrc に追加alias bac='bacon'alias bacc='bacon clippy'alias bact='bacon test'alias bacp='bacon pedantic'watchexecで複数パスを監視# srcとtestsディレクトリの.rsと.tomlファイルを監視watchexec -e rs,toml -w src -w tests -- cargo testVim/Neovimとの連携nvim-bacon プラグインbaconの診断結果をNeovimに統合するプラグインがあります。github.com" lazy.nvim の場合{  'Canop/nvim-bacon',  config = function()    require('bacon').setup()  end}主な機能は以下の通り。エラー箇所へのジャンプQuickfixへの統合:Bacon コマンドでbaconを起動:BaconLoad で診断結果を読み込み補足：VS Code向けVS Codeユーザーの場合は、bacon-lsというLanguage Serverが利用可能です。まとめcargo-watchの時代は終わりました。でも、より良いツールが生まれています。こう使い分けよう：Rust開発 → bacon一択TUIが快適キーボードだけで完結設定ファイルで柔軟にカスタマイズそれ以外 → watchexec汎用的に使えるシンプルで強力シェルスクリプトとの相性抜群baconを知らずにRustを書いていた人は、今すぐ試してください。開発体験が一段階レベルアップします。cargo install --locked baconcd your-projectbaconたったこれだけ。あとはコードを書くだけです。参考リンク：- bacon公式サイト- watchexec GitHub- cargo-watch（アーカイブ済み）]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ディレクトリ構成 ~ハイブリッド型編~]]></title>
            <link>https://sreake.com/blog/hybrid-directory-structure-good-practice/</link>
            <guid isPermaLink="false">https://sreake.com/blog/hybrid-directory-structure-good-practice/</guid>
            <pubDate>Thu, 16 Oct 2025 04:41:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、ディレクトリ構成に悩む現場に向けて、ハイブリッド型構成をご紹介します。 ⚠️ この構成が「唯一の正解 […]The post ディレクトリ構成 ~ハイブリッド型編~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonの@オペレータについて調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/e78d7c565fadaa</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/e78d7c565fadaa</guid>
            <pubDate>Wed, 15 Oct 2025 13:52:08 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonで@をオペレータとして利用する方法を調べてみました。Python、特にNumPyを利用して行列を取り扱っていると、計算の時に@をオペレータとして使うことがしばしばあります。というか私はNumPy以外で@をオペレータとして使っていることをみたことはありませんでした。+や-など一般的なさん術オペレータはよく利用しますが@はどのようにすれば使えるようになるのかふと気になり調べてみました。 NumPyにおける@オペレータNumPyでは@は行列積を計算するためのオペレータとなっています。例えば以下にAとB二つの行列が会った時に、その積を計算できます。以下の例はBを単位行列に...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：chafa]]></title>
            <link>https://zenn.dev/akasan/articles/80f8931f8523cd</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/80f8931f8523cd</guid>
            <pubDate>Tue, 14 Oct 2025 09:50:27 GMT</pubDate>
            <content:encoded><![CDATA[今回は久々のコマンド紹介シリーズです。第14回目の本日はchafaを紹介しようと思います。chafaを利用するとターミナル上で画像とかGIFを参照することができます。なお、第13回は以下になりますので、ぜひご興味があればご覧ください。https://zenn.dev/akasan/articles/6392d28e0e02f0 chafaとは？公式GitHubによると、Chafaは、アニメーションGIFなどの画像データを、端末での表示に適したグラフィック形式またはANSI/Unicode文字アートに変換するコマンドラインユーティリティです。幅広い機能をサポートしており、歴史...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[文章力を分解してちゃんと文章を書く。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/14/133602</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/14/133602</guid>
            <pubDate>Tue, 14 Oct 2025 04:36:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに文章を読むとは、自分の中で文章を再構築するということである。あなたは技術記事を読んで「わかった」と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか。ドキュメントを読んで「理解した」と思ったのに、同僚に説明しようとすると言葉が出てこなかった経験はないだろうか。私にはある。何度もある。悲しい。これは単なる理解不足ではない。もっと根本的な問題だ。私たちは「読む」と「書く」を別々のスキルだと思い込んでいる。しかし、それは違うと私は考えている。読むとき、私たちは頭の中で文章を再構築している。書き手の言葉を、自分のスキーマ（枠組み）に翻訳し、自分の言葉で理解し直している。読むことは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、「わかった」と思っても実装できないのは、頭の中で再構築したものと現実の折り合いがついていないのだ。自分の言葉で書き直せていないのだ。「読解力を分解してちゃんと文章を読む。」という記事を書いたあと、私はあることに気づいた。文章を読む力を分解して説明しようとすればするほど、自分が書く文章の問題点が見えてくるのだ。読み手がどこでつまずくかを想像すると、自分が読むときにどこでつまずいていたかが見えてくる。syu-m-5151.hatenablog.comそして、ある結論に辿り着いた。書けない人間は、読めない。これは挑発でも誇張でもない。書く力と読む力は、コインの表裏ではなく、同じものなのだ。書く経験を通じて、私たちは「文章がどのように読まれるか」を学ぶ。一文が長すぎると読み手の認知負荷が上がること。主語が不明確だと読み手が推測を強いられること。構造が曖昧だと読み手が迷子になること。逆もまたあることだ。読む経験を通じて、私たちは「文章がどのように書かれるべきか」を学ぶ。明快な文章はどのような構造を持っているか。わかりやすい説明はどのように展開されるか。読解力の記事では、読む力を3つの段階に分解した。今回の記事では、書く力を同じように分解していく。第1段階：正確に書く第2段階：誤読されないように書くスキーマを想像し、知識の呪いを断ち切る。認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。第3段階：心を動かすように書く書くことで、初めて読めるようになる。読むことで、初めて書けるようになる。この循環的な関係を理解することが、文章力を高める第一歩だ。そして、この循環が複利的に機能する。書く力が向上すると読む力も向上し、読む力が向上するとまた書く力も向上する。この正のフィードバックループが、指数関数的な成長を生み出す。片方だけを鍛えようとしても、成長は頭打ちになる。両輪を回すことが、文章力を本質的に高める唯一の道だ。では、なぜ書く力と読む力は、これほどまでに密接に結びついているのだろうか。その理由を、まず理解する必要がある。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。書く力と読む力は、なぜ表裏一体なのか書けないということは、理解していないということだエラーログを読めない人は、エラーメッセージを吐き出させるときも曖昧な表現をする。「エラーが発生しました」とだけ書いて、どのエラーが、どの条件で、何が原因で発生したのかを書かない。なぜか？自分がエラーログを読むときに、これらの情報を抽出できていないからだ。というか想像できていないからだ。読んで困った時の自分を。読むときに「どこに何が書いてあるか」を理解できていない人は、吐き出させるときにも「どこに何を書くべきか」を理解できない。これは単なる不注意ではない。書こうとして初めて、「何をどの順序で書くべきか」という問いに直面する。書こうとして初めて、「読み手は何を知りたいのか」という問いに直面する。この問いと格闘する過程で、私たちは文章の構造を深く理解する。技術記事を読んで「わかった」と思うのは、個々の文章を理解したということだ。しかし、それを実装できないのは、全体の構造を理解していないからだ。これは、ラバーダック・デバッギングと同じ原理だ。コードを声に出して説明しようとすると、理解の穴が見えてくる。文章を書こうとすると、読解の穴が見えてくる。書こうとして手が止まる瞬間、そこに理解の穴がある。誤読された経験が、誤読を防ぐ力を育てる理解の穴が見えるだけでは十分ではない。さらに重要なのは、自分が書いた文章がどう読まれるかを知ることだ。「この文章は誤解される」と事前に気づくには、自分が誤読された経験が必要だ。吐き出させた文章が意図と違う形で受け取られた経験。怒りのコメントを受けた経験。これらの痛い経験を通じて、人は「どんな書き方が誤解を生むか」を学ぶ。誤読には、いくつかのパターンがある。パターン1：主語の曖昧さによる誤読この機能の実装が遅れています。仕様が複雑で理解に時間がかかっています。書き手は「私」のつもりで書いている。しかし、読み手は「チーム全体」だと解釈するかもしれない。この誤読は、書き手が主語を省略したことで生じる。パターン2：文脈の欠如による誤読この実装方法は悪くない。書き手は、他の実装方法と比較して「悪くない」と言っている。しかし、読み手は、この実装方法が「及第点」程度だと解釈するかもしれない。パターン3：二重否定による誤読この問題は無視できない。書き手は「重要だ」と言いたい。しかし、読み手は「ある程度重要だが、最優先ではない」と解釈するかもしれない。誤読された経験は、痛い。しかし、その痛みこそが、書く力と読む力を同時に高める。書く経験が乏しい人は、読むときにも「書き手の意図」を想像できない。スキーマは読み書き両方で機能する誤読を防ぐには、さらに深い理解が必要だ。それは、読み手と書き手でスキーマが異なるという理解だ。人はスキーマを通して文章を理解する。スキーマとは、私たちが頭の中に持っている知識の枠組みのこと。例えば、「非同期処理」というキーワードを見たとき、Rustエンジニアの頭の中では、tokio、async/await、Future traitといった関連する概念が自動的に呼び出される。しかし、スキーマは読むときだけでなく、書くときにも機能している。そして、書くときのスキーマの働き方が、しばしば問題を引き起こす。あなたが「非同期処理を実装した」と書くとき、あなたの頭の中には「非同期処理」についての豊富なスキーマがある。だから、読み手もそのスキーマを共有していると無意識に仮定してしまう。これを「知識の呪い」と呼ぶ。【悪い例】非同期処理を実装しました。これでパフォーマンスが改善されます。書き手にとって、これは十分に明確だ。しかし、読み手はどうか？Rustエンジニアは「tokioのasync/awaitを使うのか」と想像する。Goエンジニアは「goroutineを使うのか」と想像する。非同期処理に馴染みのないエンジニアは「何が改善されるのか」すらわからない。書く力が高い人は、「読み手は自分とは違うスキーマを持っている」と意識的に認識する。そして、読み手のスキーマを想像し、橋を架けるように書く。【良い例】非同期処理を実装しました。従来は3つのマイクロサービスへのHTTPリクエストを順番に実行していたため、合計で3秒かかっていました。今回、Rustのtokioとasync/awaitを使ってこれらのリクエストを並行実行するように変更しました。その結果、3つのリクエストが同時に実行されるため、最も遅いリクエスト（1秒）の時間だけで完了するようになりました。これにより、全体の処理時間が3秒から1秒に短縮され、APIのレスポンスタイムが大幅に改善されました。では、この「読み手のスキーマを想像する力」は、どうやって獲得できるのか？答えは、読み手として多様な文章に触れ、「わからない」を経験することだ。自分が知らない分野の技術記事を読んで、「専門用語が多くてわからない」と感じる。その経験が、書き手として「専門用語を使うときは説明を加えよう」という意識を育てる。書くことは、読む力を鍛える最良の訓練ここまで見てきたように、書く経験は読む力を高める。しかし、その逆も真だ。読む経験は書く力を高める。この循環を最も効果的に回す方法が、実は書くことなのだ。なぜか？書こうとすると、言語化できない部分に直面するからだ。頭の中では理解しているつもりでも、いざ文章にしようとすると言葉が出てこない。この瞬間、あなたは「本当は理解していなかった」と気づく。しかし、問題はもっと深い。ちゃんと読むとは、自分の中でちゃんと書くということでもある。複雑な文章を読むとき、私たちは無意識のうちに「これはつまり、こういうことだな」と自分の言葉で要約している。この「内なる執筆」ができない人は、文章を読んでも理解が浅い。例を見てみよう。技術記事に「エラーハンドリングを実装すると、システムの信頼性が向上する」と書いてある。浅い読み方：「エラーハンドリングを実装すると信頼性が向上するのか。なるほど。」深い読み方：「エラーハンドリングを実装すると信頼性が向上する、と言っている。なぜか？エラーハンドリングがないと、エラーが発生したときにプログラムがパニックして停止してしまう。その結果、ユーザーはサービスを使えなくなる。一方、エラーハンドリングを実装すれば、エラーが発生してもプログラムは継続でき、ユーザーに明確なエラーメッセージを返せる。つまり、『信頼性が向上する』とは『エラー時でもサービスを継続できる』という意味だな。」深い読み方をしている人は、頭の中で文章を書いている。この「内なる執筆」の能力は、実際に書く経験を通じて鍛えられる。外に向けて文章を書くとき、私たちは「どう表現すれば伝わるか」を考える。この試行錯誤が、内なる執筆の能力を高める。だから、外に向けて書く訓練をすることは、内に向けて書く力も鍛える。このように、書く力と読む力は表裏一体だ。では、具体的にどう書けばよいのか。読解力の記事と同様、書く力も3つの段階に分解して見ていこう。第1段階：正確に書く読解力の第1段階は「書かれていることを正確に理解する力」だった。文章力の第1段階は、「伝えたいことを正確に伝える力」だ。これは、技術的なスキルだ。感性や才能ではなく、学習可能なスキルだ。悪文とは何か。それは、一義的に解釈できない文章だ。一つの文を読んで、複数の意味に解釈できてしまう。主語が不明確で、誰が何をしているのかわからない。修飾関係が複雑で、何がどこにかかっているのか判然としない。こうした構造的な問題が、悪文を生む。文章を書くコツは、芸術的な名文を書くことではない。読みにくい「悪文」を書かないことである。では、悪文を防ぐにはどうすればよいか。ここでは四つ紹介します。他にも悪文を分かりやすくする方法はいくらかありますがたくさん本が出ていますのでそちらを参考にしてほしいです。悪文の構造　――機能的な文章とは (ちくま学芸文庫)作者:千早耿一郎筑摩書房Amazon「文章術のベストセラー100冊」のポイントを1冊にまとめてみた。作者:藤𠮷 豊,小川 真理子日経BPAmazon一文一義で書く【悪い例】デプロイ作業中にDBマイグレーションが失敗したため、問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明なので、明日Yさんが出社してから対応するか、今日スキップしてデプロイするか、どちらが良いと思いますか？この一文には、6つの義が詰め込まれている。読み手は、これらすべてを一度に処理しなければならない。認知負荷が高すぎる。なぜ一文一義が重要なのか？人間の作業記憶（ワーキングメモリ）の容量は限られている。一文が長く、複数の義が含まれていると、読み手は文の途中で最初の部分を忘れてしまう。一文一義で書くことは、読み手の認知リソースを尊重することだ。【良い例】デプロイ作業中、DBマイグレーションに失敗しました。問題箇所をスキップすればデプロイは可能ですが、Xモジュールへの影響が不明です。対応方針を相談させてください。以下の2つの選択肢のうち、どちらが良いでしょうか？A. 明日Yさんが出社後、一緒に影響範囲を調査してから対応するB. 今日、問題箇所をスキップしてデプロイする一文一義の原則を守るには、3つのルールがある。ルール1：文章は短くするルール2：形容詞と被形容詞はなるべく近づけるルール3：一つの文に、主語と述語はひとつずつ短く、近く、シンプルに。これが機能的な文章の基本だ。主語を明示する一文一義を守るだけでは不十分だ。次に重要なのは、誰が何をしているかを明確にすることだ。日本語は主語を省略できる言語だ。しかし、文章を書くとき、特に技術文書やビジネス文書を書くとき、文脈が常に明らかとは限らない。主語を省略すると、3つの問題が生じる。問題1：責任の所在が不明確になる【悪い例】バグを修正しました。【良い例】私がバグを修正しました。問題2：行為者が不明確になる【悪い例】テストを実行して、結果を確認しました。【良い例】私がテストを実行しました。Aさんが結果を確認しました。問題3：複数の解釈が可能になる【悪い例】レビュー後、デプロイしました。【良い例】Aさんのレビュー後、私がデプロイしました。では、どうすればよいか？主語を省略してもよい場合と、省略してはいけない場合を区別する。主語を省略してもよい場合：直前の文と同じ主語の場合、文脈から主語が明らかな場合。主語を省略してはいけない場合：主語が変わる場合、責任の所在を明確にする必要がある場合、複数の解釈が可能な場合。冗長さを避ける正確に書くことは重要だが、冗長に書くことは避けなければならない。必要な情報だけを、必要な長さで書く。冗長な文章は、読み手の時間を無駄にする。忙しいエンジニアは、冗長な文章を読む時間がない。冗長な文章は、重要な情報を埋もれさせる。冗長さには、いくつかのパターンがある。パターン1：同じことを繰り返す【悪い例】この問題は重要な問題です。なぜなら、この問題を放置すると、ユーザーに影響が出る重大な問題だからです。【良い例】この問題は重要です。放置するとユーザーに影響が出ます。パターン2：不要な修飾語を使う【悪い例】非常に重要な機能の実装を丁寧に進めています。【良い例】重要な機能を実装中です。「非常に」「丁寧に」といった修飾語は、情報を追加していない。削除しても意味は変わらない。パターン3：回りくどい表現を使う【悪い例】バグを修正することに成功しました。【良い例】バグを修正しました。「〜することに成功しました」は、「〜しました」で十分だ。冗長さを避けるには、3つの原則がある。原則1：削除できる言葉は削除する原則2：同じ情報は一度だけ書く原則3：具体的な動詞を使う簡潔さは、尊重の表現だ。読み手の時間を尊重し、認知リソースを尊重する。構造を明確にする一文一義で書き、主語を明示し、冗長さを避ける。しかし、それだけでは不十分だ。文章全体の構造を明確にする必要がある。箇条書きと文章の使い分けは、書き手の重要なスキルだ。並列関係の情報は箇条書きで、因果関係の情報は文章で。なぜ構造が重要なのか？構造は、思考の可視化だからだ。構造を明確にする最も基本的な単位は、パラグラフ（段落）だ。一つのパラグラフには、一つの主張しか含めない。構造を明確にするには、3つのレベルがある。レベル1：文のレベルレベル2：パラグラフのレベルレベル3：セクションのレベルこの3つのレベルの構造が明確な文章は、読み手にとって理解しやすい。第1段階の「正確に書く」力を身につけると、少なくとも誤解されない文章が書けるようになる。しかし、それだけでは不十分だ。読み手は、あなたの意図を汲み取ろうとしてくれるとは限らない。次の段階では、より能動的に誤読を防ぐ技術を学ぶ。ユーザーの問題解決とプロダクトの成功を導く　エンジニアのためのドキュメントライティング作者:ジャレッド・バーティ,ザッカリー・サラ・コーライセン,ジェン・ランボーン,デービッド・ヌーニェス,ハイディ・ウォーターハウス日本能率協会マネジメントセンターAmazon第1段階の実践訓練訓練1：一文一義の練習訓練2：主語の明示訓練3：冗長さの削除訓練4：構造の可視化訓練5：要約を書くAIを使った第1段階の訓練生成AIは、第1段階の訓練に有効だ。AIに構造をチェックさせるAIの文章を添削する重要な注意点第2段階：誤読されないように書く読解力の第2段階は「書かれていない意図を汲み取る力」だった。文章力の第2段階は、「読み手の誤読を防ぐ力」だ。第1段階では、文章の構造的な問題を防ぐ方法を学んだ。一文一義で書き、主語を明示し、冗長さを避け、構造を明確にする。しかし、構造が正しくても、誤読は起きる。なぜか？読み手と書き手でスキーマが異なるからだ。前のセクションで「知識の呪い」について説明した。ここでは、その呪いを断ち切り、読み手のスキーマに合わせて書く具体的な方法を学ぶ。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazon技術ドキュメントの品質は、ここで決まる特に技術ドキュメントにおいては、第2段階が品質を決定づける。第1段階の「正確に書く」は、技術ドキュメントの必要条件だ。構造が曖昧で、主語が不明確で、冗長な技術ドキュメントは、そもそも読むに値しない。しかし、第1段階をクリアしただけでは、良い技術ドキュメントにはならない。技術ドキュメントの良し悪しを分けるのは、読み手が迷わず、誤解せず、必要な情報にたどり着けるかだ。これこそが第2段階の本質だ。構造的には正しいが、読み手のスキーマを無視したドキュメント。専門用語が説明なしに使われ、前提知識が明示されず、文脈が欠如しているドキュメント。こうしたドキュメントは、正確ではあるが、使えない。逆に、読み手のスキーマを想像し、知識の呪いを断ち切り、読み手が必要な情報にたどり着ける文脈を設計したドキュメントは、読み手を迷わせない。読み手は、探している情報をすぐに見つけられる。誤解なく理解できる。そして、次のアクションを取れる。APIリファレンス、設計書、運用手順書、トラブルシューティングガイド。これらの技術ドキュメントは、第3段階の「心を動かす」手法は不要だ。感情に訴える必要はない。しかし、第2段階の「誤読されないように書く」技術は、絶対に必要だ。技術ドキュメントを書くとき、常に自問すべきだ。「読み手は、この情報を探しているとき、どんな状況にいるのか？」「読み手は、どのくらいの前提知識を持っているのか？」「読み手は、この用語を知っているのか？」これらの問いに答えることが、使える技術ドキュメントと使えない技術ドキュメントを分ける。読み手のスキーマを想像するドキュメントを書くとき、まず問うべきは「読み手は誰か？」だ。読み手は誰か？何を知っていて、何を知らないか？どんな問題を解決しようとしているか？知識の呪いを断ち切るには、3つの方法がある。方法1：具体化する方法2：例示する方法3：段階的に説明する読み手のスキーマを想像する能力は、読み手として多様な文章に触れ、「わからない」を経験することで獲得できる。しかし、スキーマを想像するだけでは不十分だ。次に重要なのは、読み手の認知バイアスを考慮することだ。認知バイアスを考慮する読み手がどんなバイアスを持っているかを想定し、誤読を防ぐ。パターン1：二重否定による混乱【誤読されやすい例】この実装方法は悪くない。【誤読されにくい例】この実装方法は、実用上十分な性能を持っています。具体的には、毎秒1000リクエストを処理できます。パターン2：曖昧な数量表現【誤読されやすい例】この問題は重要です。【誤読されにくい例】この問題は、今週中に対応が必要です。なぜなら、放置するとユーザーがログインできなくなるからです。パターン3：主観的な評価【誤読されやすい例】このツールは使いやすい。【誤読されにくい例】このツールは、5分で環境構築できます。コマンド一つで起動でき、GUIで操作できます。認知バイアスを考慮した文章は、客観的で、具体的で、測定可能だ。文脈を設計する技術記事を書くとき、どこまで前提知識を説明すべきか。この判断には原則がある。原則1：読み手のレベルに合わせる原則2：この記事で必要な知識だけを説明する原則3：外部リソースを活用するテンプレートを活用する第2段階における最も実用的な方法の一つが、テンプレートの活用だ。テンプレートは、第1段階の「構造を明確にする」技術と似ているが、その目的は異なる。第1段階では、書き手が構造的に正しい文章を書くためのツールだった。第2段階では、読み手が迷わず、必要な情報にたどり着けるためのツールだ。テンプレートには、3つの利点がある。利点1：読み手の予測可能性を高める利点2：必要な情報を漏れなく提供する利点3：読み手の認知負荷を減らす例えば、バグ報告のテンプレートは次のようになる。## 概要[バグの概要を一行で]## 再現手順1. [手順1]2. [手順2]3. [手順3]## 期待される動作[何が起きるべきか]## 実際の動作[実際に何が起きたか]## 環境- OS: - ブラウザ: - バージョン: ## 追加情報[スクリーンショット、ログなど]このテンプレートを使えば、読み手（バグを修正するエンジニア）は、必要な情報をすぐに見つけられる。「再現手順はどこだ？」「どの環境で起きたんだ？」と探す時間を削減できる。技術ドキュメントのテンプレートは次のようになる。## 概要[この文書が何について説明するか]## 前提条件[読者が知っているべきこと、必要な環境]## 手順[具体的な手順、コード例]## トラブルシューティング[よくある問題と解決法]## 参考資料[関連するドキュメント、リンク]プルリクエストのテンプレートは次のようになる。## 変更内容[何を変更したか]## 変更理由[なぜ変更したか]## 影響範囲[どの機能に影響するか]## テスト[どのようにテストしたか]## レビューのポイント[レビュアーに特に見てほしい箇所]テンプレートを使う際の注意点：テンプレートは、読み手を助ける道具だ。しかし、テンプレートに縛られすぎてはいけない。状況に応じて、テンプレートをカスタマイズする。不要なセクションは削除し、必要なセクションは追加する。重要なのは、「読み手が必要な情報にたどり着けるか」という問いだ。テンプレートは、この問いに答えるための手段であって、目的ではない。第2段階の「誤読されないように書く」力を身につけると、読み手に正確に情報を伝えられるようになる。読み手のスキーマを想像し、認知バイアスを考慮し、読み手が必要な情報にたどり着ける文脈を設計する。しかし、それだけでは不十分だ。情報を伝えるだけでなく、読み手の心を動かす必要がある。なぜなら、心が動かなければ、読み手は行動しないからだ。次の段階では、その方法を学ぶ。第2段階の実践訓練訓練1：説明を書くスキーマを想像しながら書く訓練だ。「この人は何を知っていて、何を知らないか？」を考える。具体的には、次のような取り組みができる。初心者向けに、自分が得意な技術を説明する記事を書く。専門用語を使うたびに、「この用語は説明が必要か？」と自問する。書いた後、その分野に詳しくない人に読んでもらい、わからなかった箇所を聞く。訓練2：批判的に読む訓練3：テンプレートの作成エストなど）のテンプレートを作る。ただし、第1段階の「構造を明確にする」だけでなく、「読み手が必要な情報にたどり着けるか」という視点で作る。読み手が最も知りたい情報は何か？それをどこに配置すれば見つけやすいか？AIを使った第2段階の訓練AIに読み手のスキーマを想像させるAIと対話しながら書く重要な注意点第3段階：心を動かすように書く読解力の第3段階は「本当に重要なことを見抜く力」だった。文章力の第3段階は、「読み手の心を動かす力」だ。なお、この第3段階は、技術記事、ブログ、プレゼンテーションなど、読者の心を動かす必要がある文章に適用される。技術ドキュメント（APIリファレンス、設計書、仕様書など）では、第1段階と第2段階で十分だ。むしろ、客観性と正確性が重視される技術ドキュメントには、この段階の手法は合わない場合が多い。「読みたいこと」とは何か？多くの人が誤解する。「読みたいこと」とは、「自由に好き勝手に自分の気持ちを書くこと」ではない。「読みたいこと」とは、自分が読者だったら読みたいと思うものだ。自分が本屋で金を出して買いたいと思うもの。自分が時間を使って読みたいと思うもの。書きたいことではない。読みたいことだ。これは、他人の視点に立てという話ではない。徹底的に自分の視点で、自分が読者として読みたいかどうかを問うということだ。この問いは、書きたいことを書く自由よりも、はるかに厳しい制約だ。第1段階では構造を学び、第2段階では誤読を防ぐ技術を学んだ。しかし、それだけでは読み手の心は動かない。心を動かすには、まず読者を引きつける必要がある。三行で撃つ 〈善く、生きる〉ための文章塾作者:近藤 康太郎ＣＥメディアハウスAmazon最初の三行で撃つ最初の一文、長くても三行くらいで心を撃たないと、忙しい読者は逃げていく。読者はあなたに興味がない。読者にとって、あなたの書こうとするテーマはどうでもいい。冷厳な現実だ。では、どうすれば最初の三行で読者を撃てるのか？方法1：問題を提示する方法2：驚きを与える方法3：具体的な利益を示すしかし、最も重要なのは、お前が何者かは、読者にとって関係ないということだ。【悪い例】私は10年間、技術記事を書いてきました。その経験から学んだ文章術を共有します。読者は、基本的にあなたの経歴に興味がない。あなたが何年エンジニアをやってきたか、どんな実績があるか、ほとんどの読者にとってどうでもいい。読者が知りたいのは、「この記事は自分の問題を解決してくれるのか？」「面白い時間が過ごせるか？」「読む価値のある新しい視点があるのか？」「具体的で実践できる内容なのか？」「読んだ後、自分は何ができるようになるのか？」。これらの問いだけだ。書き手の自己紹介から始まる記事は、これらの問いに答えていない。だから、読者は離れていく。【良い例】エラーメッセージを読めない人は、エラーメッセージを吐き出させるときも曖昧だ。なぜか？この書き出しは、問題提起だ。読者は「なぜだろう？」と思う。書き出しで読者を引きつけることができた。しかし、心を動かすにはそれだけでは不十分だ。次に必要なのは、空虚な言葉を避けることだ。常套句を避ける書き出しで読者を引きつけても、内容が空虚なら読者は離れていく。そして、内容を空虚にする最大の敵が、常套句だ。常套句は、まさに「わかったつもり」を生み出す装置だ。このアプローチはベストプラクティスです。「ベストプラクティス」とは何か？誰が決めたのか？どういう文脈で最適なのか？なぜ最適なのか？これらの問いに答えない限り、「ベストプラクティス」という言葉は空虚だ。常套句には、いくつかのパターンがある。パターン1：抽象的なバズワードラクティス、レバレッジ、シナジー、エンパワーメント、イノベーション。これらの言葉は、具体的な内容を隠蔽する。パターン2：「としたもんだ表現」パターン3：擬音語・擬態語・流行語常套句を避けることは、思考を深めることだ。「ベストプラクティス」と書こうとして、「本当にベストなのか？」と自問する。この思考の過程が、文章を具体的にし、説得力を高める。常套句を避け、具体的に書くことができたら、次は自分にしか書けない内容を書く。自分の言葉で書く【常套句に逃げる例】Rustの所有権システムは学習が難しい。でも、理解すれば強力だ。これは誰でも書ける文章だ。【自分の言葉で書く例】私がRustの所有権システムを理解するのに、3ヶ月かかった。最初の1ヶ月は、borrowチェッカーのエラーが理解できず、「なぜこのコードが動かないのか」と毎日フラストレーションを感じていた。「cannot borrow `*x` as mutable because it is also borrowed as immutable」このエラーメッセージを見るたびに、「Cのポインタのように自由に使わせてくれよ」と思っていた。転機は、所有権を「責任の所在」として捉え直してからだ。「このデータに対する責任は誰が持つのか」と考えるようになってから、borrowチェッカーのメッセージが「監査人の指摘」として理解できるようになった。この文章は、あなたにしか書けない。あなたの体験、あなたの発見だ。自分の言葉で書くには、3つの要素が必要だ。要素1：具体的な体験要素2：五感で世界を切り取る要素3：思考の過程自分の言葉で書くとは、言い換えることだ。「所有権」という抽象的な概念を、「責任の所在」という具体的な比喩で言い換える。言い換えるとは、考えることだ。しかし、自分の言葉で書くだけでは不十分だ。言葉だけでは、読み手の心は十分には動かない。次に必要なのは、エピソードの力だ。技術ブログの書き方はここに書いているので読んでみてほしいです。syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.com響く文章は説明しない【説明する例】ドキュメントを書くことは重要です。なぜなら、ドキュメントがないとユーザーが困るからです。説明は響かない。【エピソードで語る例】私が初めてオンコール当番を担当したとき、深夜2時にアラートが鳴った。Datadogのダッシュボードには、「CPU usage > 80%」というアラートしか表示されていなかった。「どのサービスのCPUが高いのか」「何が原因なのか」「どうやって対処すればいいのか」何もわからず、私は1時間を無駄にした。結局、先輩を叩き起こして対処してもらった。先輩は5分で原因を特定し、10分で対処した。翌朝、先輩に聞いた。「なぜそんなに早く対処できたんですか？」先輩は言った。「アラートに必要な情報が書いてあったからだよ」そのとき誓った。自分がアラートを作るときは、必ずRunbookへのリンクを含めようと。それから3年、私はこの誓いを守っている。エピソードは響く。具体的な場面、具体的な感情、具体的な決断。これらが、読み手の心を動かす。なぜエピソードは説明よりも響くのかエピソードが響く理由は、共感にある。読み手は、あなたの物語の中に自分を見出す。「深夜2時のアラート」「何もわからない焦り」「先輩を叩き起こす申し訳なさ」。これらの感情は、多くのエンジニアが経験したことがある。あるいは、いつか経験するかもしれない。だから、読み手は「ああ、わかる」と思う。この「わかる」という感覚が、共感だ。共感は、説明では生まれない。「ドキュメントは重要です」という説明は、頭では理解できる。しかし、心は動かない。一方、エピソードは、読み手を物語の中に引き込む。読み手は、あなたの経験を追体験する。あなたの焦りを感じ、あなたの学びを共有する。共感してもらえる物語には、3つの条件がある。条件1：普遍的な感情を含む条件2：具体的な状況を描く追体験できる。「1時間を無駄にした」という具体的な時間。「先輩を叩き起こした」という具体的な行動。条件3：弱さを見せる共感は、信頼を生む。読み手があなたの物語に共感すると、あなたの言葉を信頼するようになる。「この人は、自分と同じ問題に直面して、それを乗り越えた人だ」。この信頼が、読み手を行動に移させる。説明では信頼は生まれない。しかし、共感できる物語は、信頼を築く。ただし、共感を意図的に操作しようとしてはいけない。作られた感情や、誇張された困難は、読み手に見抜かれる。本当に経験したこと、本当に感じたこと、本当に学んだことを書く。その誠実さが、最も強い共感を生む。エピソードで語るには、ストーリーの構造が必要だ。状況 - どんな状況だったか問題 - 何が問題だったか行動 - 何をしたか結果 - どうなったか学び - 何を学んだか自分の言葉で書き、共感してもらえるエピソードで語る。しかし、それでも心を動かすには、もう一つ必要なものがある。それは、あなたの生き方や物語そのものだ。書くことは生きること「書くことは生きること」。文章を書くことは、技術ではない。生き方だ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。技術記事を書くとき、私たちは技術を説明しているだけではない。私たちは、技術を通して世界を理解している。「なぜこの技術は存在するのか」「どんな問題を解決するのか」「どんな未来を可能にするのか」。これらの問いに答えることは、技術を理解することであり、同時に世界を理解することだ。そして、これらの問いに答える過程で、私たちは自分自身を理解する。書くことで、私たちは自分になる。書くことは、自分の物語を紡ぐこと書くことは、単に情報を伝えることではない。自分の物語を紡ぐことだ。あなたがエンジニアとして生きてきた日々。深夜のデバッグ、突然の本番障害、チームでの議論、新しい技術との出会い、失敗から学んだ教訓。これらすべてが、あなたの物語だ。書くとは、これらの断片的な経験を、一つの物語として編集することだ。物語には、3つの力がある。力1：意味を与える力力2：つながりを生む力力3：未来を変える力しかし、物語を紡ぐには、勇気が必要だ。自分の失敗を書くこと。「わからなかった」「1時間を無駄にした」「先輩を叩き起こした」。これらの弱さを見せることは、恥ずかしい。しかし、完璧な成功物語は、誰の心も動かさない。読み手が求めているのは、完璧なヒーローではない。同じように悩み、同じように失敗し、それでも前に進んだ人の物語だ。あなたの物語は、すでにある。日々の仕事の中で、あなたは物語を生きている。書くことは、その物語を可視化することだ。そして、可視化することで、物語はより明確になる。「自分は何を大切にしているのか」「どんな価値観で生きているのか」「どこに向かっているのか」。物語を書くことで、あなたは自分の物語を理解する。わたしにしか、書けないものは、ある。わたしにしか、紡げない物語は、ある。そう信じることから、文章は始まる。第3段階の実践訓練なお、これらの訓練は、技術記事、ブログ、プレゼンテーションを書く人向けだ。技術ドキュメントを書く人は、第1段階と第2段階の訓練に集中してほしい。訓練1：書き出しを3パターン書く訓練2：常套句を見つけて書き直すラクティス」→「なぜベストなのか？どういう条件で？」と問う。技術記事では、抽象的な言葉が説得力を失わせる。訓練3：自分の体験を書く訓練4：説明ではなく、エピソードで語る訓練5：自分の文章を読み直すAIを使った第3段階の訓練AIに書き出しを生成させて、添削するAIに常套句を指摘させるAIに自分の文章を批判させるAIには書けないものを書くおわりに「読解力を分解してちゃんと文章を読む。」を書いたとき、私は気づいた。読む力を説明しようとすることは、書く力を鍛えることでもあると。そして今、「文章力を分解してちゃんと文章を書く。」を書き終えて、改めて実感する。書く力を説明しようとすることは、読む力を鍛えることでもあると。読む力と書く力は、別々のスキルではない。同じスキルの異なる側面だ。この記事の冒頭で、私はこう書いた。「技術記事を読んで『わかった』と思ったのに、いざ実装しようとすると何も書けなかった経験はないだろうか」。なぜ実装できないのか。答えは明確だ。頭の中で再構築できていないからだ。読むとは、実は書くことなのだ。ただ、それが頭の中で行われているだけだ。だから、読む力を高めたいなら、書くことだ。書く力を高めたいなら、読むことだ。この循環が、複利的に機能する。第1段階では、正確に書く技術を学んだ。一文一義、主語の明示、構造の明確化。これは、悪文を書かないための必要条件だ。第2段階では、誤読を防ぐ技術を学んだ。読み手のスキーマを想像し、知識の呪いを断ち切り、文脈を設計する。特に技術ドキュメントでは、この段階が品質を決定づける。第3段階では、心を動かす技術を学んだ。書き出しで引きつけ、常套句を避け、自分の言葉で語り、エピソードで伝える。ただし、これは技術記事やブログに適用される段階であり、技術ドキュメントには不要だ。しかし、文章を書くことの意味は、スキルを高めることだけではない。書くことは、思考を深めることだ。思索が深まるほどに、世界の切り取り方が変わり、自分が変わる。書くことは、世界を理解することだ。技術を説明しようとするとき、私たちは「なぜこの技術は存在するのか」「どんな問題を解決するのか」を問う。書くことは、自分を理解することだ。言語化できない部分に直面したとき、私たちは「本当は理解していなかった」と気づく。だから、書くことは生きることだ。明日から、何か一つ書いてみよう。Slackのスレッドでもいい。プルリクエストのコメントでもいい。技術記事でもいい。書こうとして手が止まる瞬間、そこに理解の穴がある。その穴を埋めることが、あなたの成長だ。わたしにしか、書けないものは、ある。そう信じて、書き続けることだ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TFLintカスタムプラグインで始める Terraformコード品質管理]]></title>
            <link>https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li</link>
            <guid isPermaLink="false">https://speakerdeck.com/bells17/tflintkasutamupuraguindeshi-meru-terraformkodopin-zhi-guan-li</guid>
            <pubDate>Tue, 14 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Go Night Talks – After Conference の LT資料ですhttps://mercari.connpass.com/event/367075/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubで管理されているZennのtopicsを集計するコードをclaude codeに作らせた]]></title>
            <link>https://zenn.dev/akasan/articles/1cc5493f3e077a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/1cc5493f3e077a</guid>
            <pubDate>Mon, 13 Oct 2025 04:17:00 GMT</pubDate>
            <content:encoded><![CDATA[今回はタイトル通り、GitHubでZennの記事を管理している場合に、どのようなtopicsがよく利用されているか集計するための機能をclaude codeに作らせてみました。私自身連続170記事以上出している関係で、どのような技術をよく利用しているか調べたくなり、作らせてみました。 ZennをGitHubで管理するためのフォルダ構成違いはあるかもしれませんが、基本的には以下のフォルダ構成で管理されていると思います。articles/  hogehoge.md  fugafuga.mdbooks/  ...images/  ...scrapes  ...今回はa...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[OpenAI Agent Builderを使ってGuardrail実装してみた]]></title>
            <link>https://zenn.dev/akasan/articles/c1698aa0289828</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/c1698aa0289828</guid>
            <pubDate>Sun, 12 Oct 2025 04:19:21 GMT</pubDate>
            <content:encoded><![CDATA[今回は、現地時間10月6日にOpenAIが発表したAgent Builderという機能を早速使ってみました。Agent Builderを利用することで、GUIを利用してエージェントを作成することができるようになります。 Agent Builderとは？Agent BuilderはOpenAI DevDay 2025にて発表された新しいプロダクトとなっています。Agent Builderを利用すると、ドラッグアンドドロップでロジックを構成し、ツールを接続やカスタムガードレールを構成するためのキャンバスを利用できます。また、プレビューの実行、インラインのeval設定、完全なバージョニン...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[読解力を分解してちゃんと文章を読む。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/10/12/081300</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/10/12/081300</guid>
            <pubDate>Sat, 11 Oct 2025 23:13:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに自分の読解力に絶望する瞬間というものがあります。たとえば、エラーログを読んでいるとき。無意識のうちに「こういうエラーだろう」という仮説を立てて、その証拠を探すように読んでしまっていました。問題を解決した後で同じログを読み返すと、「なんでこんな読み方をしたんだ？」と首をかしげます。明らかに違うことが書いてあるのに、自分の仮説に都合のよい部分だけを拾い読みしていました。エラーログという機械が出力するシンプルな文章ですら、こうなのです。もっと複雑なドキュメントなら、どれほど読み間違えていることでしょうか？ライブラリのドキュメント、APIリファレンス、技術記事、PRのコメント、issueの議論、Slackでのやり取り。すべて同じ問題を抱えている可能性があります。これは挑発でも誇張でもありません。「文章が読める人」は想像以上に希少で、自分も含めて、多くの人は書いてあることを読んでいません。自分の主張や仮説、感情があって、それに合うように拾い読みしているだけなのです。なぜこんなことが起きるのでしょうか？それは人は文章を読む前から、すでに何らかの主張や仮説、感情を持っているからです。そして無意識のうちに、それを正当化できる「都合のよいワード」だけを探している。文章全体の文脈や意図を理解するのではなく、自分の主張や仮説にマッチする断片だけに反応する。これは読解ではありません。結論ありきの確認作業です。虐殺器官 (ハヤカワ文庫JA)作者:伊藤 計劃早川書房Amazon今の時代、わからないことがあれば、ChatGPTやClaudeに聞けばいい。生成AIは、いつでも、何度でも答えてくれます。これは本当に素晴らしいです。でも——生成AIがあれば読解力は不要になるのでしょうか？違います。逆だと思っています。生成AIによって読解力は底上げされます。ただし、それは生成AIをどう使うかにかかっています。生成AIを正しく使えば、読解力を飛躍的に高められます。でも、間違った使い方をすれば、読解力は逆に衰えます。この記事では、「読む」という行為を分解し、それぞれの壁をどう超えるか、そして生成AIをどう活用すべきかを語っていきます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。では、早速はじめていきます。読解力は分解可能なスキル群ですスキルというのは、単一の能力で成り立っているわけではないことが多いです。だいたいは複数の能力の集合体です。コーディングがうまくなりたい？それなら取り組むべきことは山ほどあります。言語仕様を深く理解する、デザインパターンを学ぶ、Effective 〇〇のようなベストプラクティスを身につける、テストの書き方を学ぶ、デバッグの技術を磨く。さらに、メモリ管理を理解する、並行処理を扱えるようになる、セキュリティや運用を考慮できるようになります。でも、技術的なスキルだけじゃないです。コミュニケーション能力を高める、他人のコードを読む力をつける、レビューでフィードバックをする、技術的な議論ができるようになる。業界知識を身につける、ドメイン知識を深める、チーム開発の進め方を学ぶ。コーディングというスキルは、技術、人間関係、知識という軸からなる、いくつものスキルの集合体なんだと思います。漠然と「コーディングが上手くなりたい」と思っているだけでは、何をすればいいかわかりません。でも分解して「Rustの所有権システムを深く理解する」と具体化すれば、The Rust Programming Languageを読む、borrowチェッカーのエラーと向き合う、といった具体的な練習メニューが見えてきます。「デザインパターンを学ぶ」と具体化すれば、GoFのパターンを実装してみる、OSSのコードでパターンを探す、といった具体的な行動が見えてきます。読解力も同じです。書いてあることを正確に読むには、実はいろんなスキルが要ります。語彙力、文法理解力、主語・述語の把握、修飾関係の理解、論理構造の把握、情報の正確な抽出。こういった「書いてあることを正しく読む」基礎的なスキル。さらに、文脈の理解、推測力、共感力、批判的思考、バイアスへの気づき、メタ認知。こうした「行間を読む」応用的なスキル。そして、抽象化能力、本質を見抜く力、問いを立てる力、情報の優先順位づけ。「何が本当に重要なのか」を見極める統合的なスキル。読解力もまた、複数のスキルの集合体です。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon上達とは分解して考えることどんな能力でも、「取り組めるまで分解して考えること」が重要です。漠然と上手になりたいでは、いつまで経っても上達しません（天才を除く）。分解しないとどうなるでしょうか？「ドキュメントをちゃんと読めるようになりたい」では漠然としすぎて何をすればいいかわかりません。練習のしようがないです。でも「仮説を立てる前に、書かれている情報を網羅的に抽出する」と分解すれば、明日から実践できる具体的な読み方が見えてきます。エラーログを開いたとき、まず全行を読んでからメモ帳に情報を列挙する、という具体的な行動に落とし込めます。壮大に見えた挑戦も、分解してみれば、シンプルなタスクの積み重ねでしかありません。コーディングも、読解も、他のどんなスキルも同じです。頭の良さが成功の命運を分けるほど高尚な仕事はありません。必要なのは、分解する視点と、一つずつ取り組む地道さです。この原則は、コーディングでもドキュメントの読解でも、あらゆるスキルに共通しています。そして、生成AI時代においても、この原則は変わりません。むしろ、生成AIがあるからこそ、読解力を分解して鍛えることが、より重要になります。分解できていなければ、生成AIに「何を」「どう」聞けばいいのかもわからないのですから。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon読解力には3つの段階があります読解力には、大きく3つの段階があります。この記事では、その3つの段階を一つずつ分解して説明していきます。ただし、これは一方通行の階段じゃありません。私たちはこれらの段階を行ったり来たりします。第3段階まで到達した人でも、疲れているときや慣れない分野の文章を読むときは、第1段階に戻ります。そう、読解力とは一定じゃありません。「能力」という言葉には「力」という漢字が含まれています。そのせいか、まるで機械のスペックのように「私の読解力は○○レベル」と固定値で捉えてしまいがちです。筋力のように、一定の出力を常に出せるものだと思ってしまいます(筋力も…というツッコミもあります)。しかし実際はそうではありません。能力はその瞬間の状態に大きく左右される可変的なものです。読解力は文脈によって大きく変わります。自分の専門分野のドキュメントなら第3段階まで読めるのに、まったく知らない分野の文章なら第1段階で苦戦します。朝の集中できる時間なら深く読めるのに、疲れた夜には表面的にしか読めません。特に感情状態の影響は大きいです。怒りや悲しみを抱えたまま技術記事を読んでも、書かれている内容が頭に入ってきません。これは単に集中力が切れるという話ではありません。感情が認知のリソースを占有してしまうからです。仮に100のキャパシティがあっても、感情に30使われていたら、読解に使えるのは70だけになります。こうした揺らぎは、誰にでもどんな能力にもあります。この理解は、自己評価にも影響します。ある日うまく読めなかったからといって「自分には読解力がない」と結論づけるのは早計です。単にその瞬間の条件が悪かっただけかもしれません。だからこそ、筋力を鍛えるように、読解力も鍛える価値があります。鍛えるとは、能力の底上げと安定化を意味します。鍛えておけば、疲れているときでも、新しい分野でも、感情が揺れているときでも、ある程度は正確に読めるようになります。新装版 アブダクション　仮説と発見の論理作者:米盛裕二勁草書房Amazon第1段階：正確に読むこれは読解の土台です。書かれていることを正確に理解する力です。エラーログで考えてみましょう。第1段階では、どのコンポーネントが、どんな状態で、どんなエラーを出したのかを正確に読み取ります。エラーメッセージの構造を理解し、どこで何が起きたかを正確に把握します。技術記事なら、著者が説明している手順や概念を、一つ一つ正確に理解することです。「この関数は非同期です」という記述があったとき、それが何を意味するのか（Promiseを返すのか、コールバックを受け取るのか、await可能なのか）を正確に読み取ります。Rustのコンパイラエラーも良い例です。borrowチェッカーのエラーが出たとき、「所有権の問題だ」とざっくり理解するんじゃなくて、どの変数が、どのスコープで、どのように使われようとして、なぜそれが許可されないのか、を正確に読み取ります。これはプログラミングにおける「構文を理解する」に相当します。変数、関数、制御構文といった基本がわからなければ、その先のロジックを理解することはできません。読解も同じです。まず書かれていることを正確に読む。この段階なしに、次の段階には進めません。シン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon第1段階の壁：基礎訓練の不足多くの人はこの第1段階で躓いています。基礎訓練が不足しているんです。例えば、次の2つの記述の違いが分かるでしょうか？「システムは、2025年1月、レガシーAPIを廃止し、クライアントには新APIへの移行を推奨した」と、「2025年1月、レガシーAPIは廃止され、システムはクライアントから新APIへの移行を推奨された」。答えは「異なる」です。前者ではクライアントが移行を推奨されているのに対し、後者ではシステムがクライアントから推奨されている（主従関係が逆）です。もっと身近な例で見てみましょう。技術記事に「このメソッドは非同期です」と書かれています。多くの開発者は「わかった」と思って先に進みます。でも実際には、「非同期である」という情報だけでは不十分です。Promiseを返すのか、コールバックを受け取るのか、await可能なのか、エラーハンドリングはどうするのか。これらの情報も読み取らなければ、正確な理解とは言えません。コーディングに例えるなら、コードはたくさん書くが、変数のスコープを理解せず、型システムの理解もせず、言語仕様の訓練もしない。基礎がないから複雑なシステムを作れない、という状況です。文章の読解も同じ。たくさん読むが、文構造の理解訓練はせず、論理的思考の訓練もしない。基礎がないから正確に読めません。この壁を超えるには基本的な訓練が重要です。主語・述語を意識する。ドキュメントやエラーメッセージで、「誰が」「誰に」「何を」しているのか。これを正確に把握する癖をつけます。仮説を立てる前に全部読む。私はこれでエラーログの読み間違いが激減しました。全行読んで、情報を列挙してから、それから仮説を立てる。順番を変えるだけで、見える景色が変わります。文脈を意識する。これはリファレンスなのか、チュートリアルなのか、トラブルシューティングなのか。文章の「置かれた場所」で、読み方も変わるべきなんです。音読してみる。本質的な訓練ではないが、驚くほど効果的です。声に出すと、飛ばし読みができなくなる。一文字ずつ確実に読むことを強制される。視覚だけでなく聴覚も使うので、「読んだつもり」が減る。特に、複雑なエラーメッセージや理解しにくいドキュメントを読むときは、小声でもいいから音読してみるといいです。読むスピードが落ちる分、思考する時間が生まれる。主語と述語の関係も掴みやすくなります。生成AIは、この基礎訓練を補助してくれます。わからない専門用語が出てきたとき、集中力を途切れさせずに「『非同期処理』とは何ですか？」と聞ける。複雑な文章の主語・述語の関係がわからなくなったとき、「この文章の構造を分解してください」と聞ける。技術記事を読んで「わかった」と思ったとき、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と確認できます。ただし、まず自分で読むことが前提です。最初の一文を読んですぐ「要約して」と頼むのでは、読解力は鍛えられません。生成AIに分解してもらった後、必ず自分でもう一度読み直します。生成AIの説明も間違えることがあるので、公式ドキュメントでも確認します。生成AIはあくまで訓練の補助です。第2段階：裏を読む第1段階で書かれていることを正確に読めるようになったら、次は書かれていない意図を汲み取る力が必要になります。エラーログで考えてみましょう。第2段階では、エラーの背後にある状況を推測します。タイムアウトエラーがあったとき、単に「タイムアウトした」という事実だけじゃなく、「なぜタイムアウトしたのか」を考える。ネットワークが遅いのか、サーバーが応答していないのか、ファイアウォールで遮断されているのか。技術記事を読むときも同じ。「この実装方法を推奨します」という記述があったとき、なぜ著者はそれを推奨するのか、どんな状況を想定しているのか、逆にどんな状況では推奨しないのか、を推測します。PRのコメントで「ここ、もっと良い方法があるかも」と書かれていたとき、それは単なる提案なのか、変更を強く求めているのか、それとも議論を始めたいのか。書かれている言葉だけでなく、その裏にある意図を読み取る力です。Rustのドキュメントを読むとき、「この関数はunsafeです」という記述の裏には、「注意深く使わないとメモリ安全性が損なわれる」という警告がある。「このトレイトはSendです」という記述の裏には、「スレッド間で安全に送信できる」という保証があります。これはプログラミングにおける「ロジックを理解する」に相当します。構文を理解した上で、なぜこのデザインパターンを使うのか、なぜこのデータ構造を選ぶのか、といった背景や意図を理解する段階です。読解力は最強の知性である　１％の本質を一瞬でつかむ技術作者:山口 拓朗SBクリエイティブAmazon第2段階の壁：認知バイアスこの第2段階では大きな壁にぶつかります。それが認知バイアスです。エラーログを読むとき、私は無意識に確証バイアスの罠にはまっていました。確証バイアスとは、自分の信念を裏付ける情報を探し求め、それ以外を見ない・軽視する心理学の概念。既存の仮説として「これはメモリの問題だ」と思っていると、フィルターが発動し、メモリに関する情報だけを拾うようになる。結果として、ネットワークに関する情報を見落としてしまいます。GitHubのissueでも同じことが起きています。「この機能の実装、19時までに終わらせるのは無理だった。他のタスクもあるし、月1回くらいしかこのペースで進められない」というコメントを読んで、「マネジメントに文句を言っている」と受け取る人がいます。でも、よく読んでほしいです。このコメントには「マネジメントが悪い」とは一言も書かれていない。書かれているのは、ただ「間に合わなくて申し訳ない」という弱音だけです。なぜこのような誤読が起きるのか？「この人は以前も遅れていた」「いつも文句を言っている」という既存の印象があると、フィルターが発動し、「マネジメントを批判している」と読み取ってしまいます。でも実際に書かれていることは、「間に合わなくて申し訳ない」という弱音だけです。ここで重要なのは、私たちの直観は想像以上に信頼できないということです。「直観に従えば大丈夫」——もしこれが本当なら、文章の誤読はほとんど起きないはずです。エラーログを読めば直観的に原因がわかる。ドキュメントを読めば直観的に使い方がわかる。コメントを読めば直観的に意図がわかる。でも現実はどうでしょうか？私たちは、人生で何千、何万もの文章を読んできました。それでも、誤読は頻繁に起きます。「ちゃんと文章を読める」と自認している人でも、エラーログを読み間違え、ドキュメントを誤解し、コメントを誤読しています。つまり、直観的な判断は、それなりの確率で裏切ります。ファスト＆スロー　（上）作者:ダニエル カーネマン,村井 章子早川書房Amazonなぜか？直観は過去の経験とパターン認識に基づいているからです。「このエラーは以前見たことがある」「この書き方は○○を意味する」——そう直観的に思った瞬間、私たちは確証バイアスのフィルターをかけてしまいます。直観に従うほど、書かれていることではなく、「自分が予想したこと」を読むようになります。だからこそ、意識的な読み方が必要なんです。直観を完全に排除することはできません。でも、「直観は間違うかもしれない」と自覚するだけで、読み方は変わります。「直観的にこう思う。でも、本当にそう書いてあるか？」と自問する癖をつける。これだけで、誤読は激減します。私たちは、自分が信じたいものを信じるようにできています。ちなみに、SNSでは誤読が頻繁に起こります。でも、発信する側の心持ちとして、SNSでは誤読されるのも投稿する内だと思っていたほうが精神衛生上良いんです。SNSという媒体は本質的に誤読を生みやすいからです。文脈が省略され、文字数に制限があり、読者の背景や感情状態も様々です。「炎上」の多くは、この誤読から生まれる。できるのは、自分自身が読む側に回ったとき、「書かれていないこと」を読み取っていないか、常に自問することだけです。この壁を超えるには基本的な訓練が重要です。「書かれていないこと」を排除する。一文字ずつ丁寧に読み、「これは本当に書いてあるか？」と確認し、「自分が勝手に補完していないか？」と自問する。特に、怒りの感情を覚えたときは要注意だ。複数の解釈を考える。1つの文章に対して、少なくとも3つの異なる解釈を仮定してみる。先ほどの「19時までに終わらせるのは無理だった」なら、①単純に弱音を吐いている、②マネジメントを批判している、③このプロジェクトから離れたいと思っている、という3つの解釈が考えられる。書かれていることだけからは①が最もストレートだけど、「確定」はできません。バイアスのメタ認知。文章を読んで強い感情（怒りや共感）を覚えたら、ちゃんと読み直し、「自分のバイアスではないか？」と自問し、複数の解釈可能性を列挙する。生成AIは、別の視点を提供してくれる。「この文章の別の解釈の可能性を3つ教えてください」と聞けば、あなたが思いつかなかった解釈を示してくれることがある。「このコメントには、『マネジメントを批判している』という意図が書かれていますか？」と聞けば、書かれていることと書かれていないことを区別してくれる。ただし、生成AI自体もバイアスを持っている。生成AIも訓練データに基づいたバイアスを持っているし、あなたの質問の仕方が回答を誘導してしまうこともある。だから、中立的な質問をする。「この文章のトーンを分析してください」といった、オープンな質問をする。そして、まず自分で複数の解釈を考えてから、生成AIで確認します。この順番が大切です。第3段階：本質を読む第1段階で正確に読み、第2段階で裏を読めるようになったら、最後は本当に重要なことは何かを見抜く力が必要になります。エラーログで考えてみましょう。第3段階では、大量のログの中から本当に重要な情報を抽出する。100行のログがあったとき、その中で本当に問題の原因を示しているのはどの部分なのか。表面的には複数の問題が見えても、本質的には1つの根本原因から派生しているかもしれません。技術記事を読むとき、第3段階では表面的な実装方法ではなく、その根底にある設計思想や原則を理解する。「このコードはこう書く」という表層だけでなく、「なぜそう書くのか」「そもそも何を解決しようとしているのか」を見抜きます。Rustのドキュメントを読むとき、個々のAPIの使い方だけでなく、所有権システムという言語の根幹にある哲学を理解する力だ。これはプログラミングにおける「設計を理解する」に相当します。構文とロジックを理解した上で、なぜこのアーキテクチャを採用したのか、トレードオフは何か、本質的な問題は何か、を理解する段階です。ただし、新しい言語を学ぶときは構文から学び直す必要があるように、新しい分野の文章を読むときは第1段階から学び直す必要があります。これは退行ではなく、自然なことなんです。わかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon第3段階の壁：わかったつもり第3段階に到達しても、まだ最後の壁がある。これが一番厄介です。それが「わかったつもり」。「もう理解すべきことは何もない」って思った瞬間、人は思考停止します。新しい視点を受け入れなくなります。成長が、止まります。エラーログを開いて「あ、これはあのエラーだ」と思った瞬間、思考が停止します。そして仮説に合う部分だけ読んで、結果として問題を解決できません。実際には50%程度しか理解していないのに、「わかった」と思い込んでいます。エラーログを見て「ああ、これは接続エラーだ」と思った瞬間、「接続設定を確認すればいい」と結論づけてしまいます。でも実際には、設定以外にも、ファイアウォール、タイムアウト、認証、リトライロジックなど、他にも確認すべきことがあるかもしれない。「わかった」と思った瞬間に、これらの可能性を検討しなくなります。技術記事を読むときも同じ。「この技術は理解した」と思った瞬間、制約条件や例外的な状況を見落とす。「この設計パターンはわかった」と思った瞬間、適用すべきでない場面に気づかなくなります。この「わかったつもり」は、第1段階から第3段階まで、すべての段階で起こりうります。だからこそ、これが最大の壁なんです。読解力が高い人ほど、自分が「わかったつもり」になっていないかを常に点検しています。この壁を超えるには基本的な訓練が重要です。「なぜ」「そもそも」と問う。なぜこのエラーが出たのか？そもそも何が問題なのか？本当に重要なのはどこか？問いとは、答えをただ探すためのものではなく、物事の本質に近づこうとする"姿勢"そのものです。要約訓練。情報を要約する際は、「本当に重要なのは何か？」と自問する癖をつける。これは、99%の情報から1%の本質を抽出する訓練です。でも、「これが本質だ」と決めつけてはいけません。それが「わかったつもり」の罠だからです。情報の精査。情報に触れたら、「それは個人的意見なのか、客観的事実なのか？」と自問する。事実なのか意見なのか、データに基づいているのか印象なのか。この区別が、本質を見抜く力につながります。生成AIは、理解を検証してくれます。「私はこの技術の本質を『○○』だと理解しました。この理解は正しいですか？他にもっと重要な本質はありますか？」と聞ける。「なぜこの技術が必要なのですか？」と聞き、返ってきた答えに対して「なぜそれが問題なのですか？」とさらに聞ける。5回「なぜ」を繰り返す「5 Whys」を実践できます。長大なドキュメントを読んだ後、「このドキュメントの本質を、3つの文で要約してください」と聞けます。ただし、生成AIが示した「本質」も、一つの視点に過ぎません。生成AIは、訓練データに基づいて、「多くの人が本質だと考えていること」を答えます。でも、それが本当の本質かどうかは、わかりません。だから、生成AIの答えを「仮説」として扱う。「本当にそうか？」と疑う。他の情報源でも確認します。実際に使ってみて検証します。そして、まず自分で「なぜ」を考える。自分の考えを生成AIで確認します。この順番が大切です。すべて生成AIに聞いてしまうと、自分で考える力が衰えます。なぜ読解力を鍛えるべきなのかここまで読んで、「めんどくさそうだな」って思いました？正直、わかる。3つの段階、それぞれの壁、訓練方法、生成AIの使い方。別に分けんでもいいやろって思いました？しかも読解力って一定じゃなくて、落ちるらしいし、新しい分野だとまた1からやり直し。でも——これだけは言わせてほしい。生成AI時代だからこそ、読解力を鍛える価値は計り知れないです。「最近の人は長文が読めない」——よく聞く話ですが、これを単なる集中力不足だと片付けてはいけません。SNS、ショート動画、通知、いいね。私たちの脳は短期的な快楽にチューニングされ続けています。このサイクルを何年も繰り返すうちに、長文を読むことが単に「つまらない」だけでなく、苦痛に変わります。文脈を保持しながら論理を組み立てる——この一連のプロセスが、脳にとって「報酬が遠すぎる」活動になってしまうんです。スマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazonさらに深刻なのは、読解力の回路そのものが機能低下することです。文脈を保持する力が衰えると、文章を断片的にしか理解できなくなります。そして、自分の考えを整理する力も、読解力に依存しています。「なぜこのバグが起きたのか」を説明できない。「なぜこの設計を選んだのか」を答えられない。これは語彙不足ではなく、自分の内側で起きていることを掴めず、整理できていない状態です。感じているのに言語化できない。伝えたいのに届かない。誤解されて、孤立感が強まります。説明できる力は、安心感や人とのつながりの土台です。「自分だけは分かっている」という拠り所があるなら、人はまだ耐えられます。でも、自分の感じや考えを誰も拾ってくれないどころか、自分自身も拾えないとなると、存在の手応えや安心感が一気に揺らぎます。増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon読解力は他のすべてのスキルを支える土台である読解力は、エンジニアとしてのキャリアの「土台」のようなものだ。基礎体力に近いかもしれません。コーディングで考えてみましょう。変数、関数、制御構文といった基礎がなければ、どんな技術も身につかない。Rustの所有権システムを学ぼうとしても、デザインパターンを理解しようとしても、並行処理を扱おうとしても、基礎がないと何も始まらない。読解力も同じ。読解力がなければ、どんなドキュメントも正確に理解できず、どんな技術も効率的に学べず、どんなコミュニケーションもうまくいきません。Rustを学びたいとする。でも、Rustのドキュメントを正確に読めなければ、所有権システムを理解できない。borrowチェッカーのエラーメッセージを正確に読めなければ、問題を解決できません。unsafeの意味を深く理解できなければ、適切に使えません。生成AIに「Rustの所有権システムを教えて」と聞けば、説明は返ってくる。でも、その説明を理解するのも、読解力だ。生成AIの説明が正しいかどうかを判断するのも、読解力だ。読解力が貧弱だと、コードを書く、設計する、レビューする、ドキュメントを書く、チームとコミュニケーションする、問題を解決する、新しい技術を学ぶ、生成AIを使いこなす、といった、エンジニアとしてのあらゆる活動で誤作動が生じます。逆に、読解力という土台があれば、すべてがスムーズに機能するようになります。生成AI時代においても、読解力はすべての土台なんです。読解力の差は、時間とともに指数関数的に広がる「読解力があるか、ないか」は、1回だけ見れば小さな差だ。でも、時間とともに指数関数的に広がっていきます。ドキュメントを正確に読める人と読めない人の差は、1回では小さいです。「たった1回の誤解」。でも、1年間ではどうでしょうか？ドキュメントを読めない人は、週に3回、APIの使い方を誤解します。年間で150回。そのたびに、実装をやり直す必要があります。週に3時間、年間で150時間を無駄にする。実装ミスのせいでバグが増える。デバッグに時間がかかる。納期が遅れる。レビュアーに迷惑をかけます。チームからの信頼を失う。新しい技術を学ぶスピードが遅くなる。結果として、キャリアが停滞します。生成AIを使っても、この差は変わりません。むしろ、生成AIがあるからこそ、読解力の差は広がる可能性があります。読解力がある人は、生成AIを補助ツールとして使って理解を深め、さらに読解力が高まる。読解力がない人は、生成AIに全面的に依存し、自分で考えなくなり、さらに読解力が低下します。1回の差は小さいです。でも、積み重なると大差になります。読解力が高い人は、読むことで新しい知識を得て、さらに読解力が高まる。読解力が低い人は、読むことで誤解を重ね、さらに読解力が低下する。時間とともに、差は指数関数的に広がっていきます。そして、自分の読解力が揺らぐことを自覚していれば、「今日は疲れているから、このドキュメントは明日読もう」という判断ができる。「怒りを感じているから、一旦落ち着いてから読み直そう」という戦略が立てられる。「この分野は初めてだから、第1段階から丁寧に読もう」という心構えができる。「疲れているから、生成AIに確認してもらおう」という判断ができます。読解力を鍛えることは、読解力そのものを高めることだけじゃありません。自分の読解力の限界を知り、それに応じた戦略を立てることでもあります。そして、生成AIをいつ、どう使うべきかを判断する力でもあります。読解はコミュニケーション「何回説明しても伝わらない」——こんな経験、誰にでもあるでしょう。上司から同じことを何度も指摘される。部下に説明したのに、まったく違うものができあがる。技術記事を読んだのに、実装したら全然違う結果になりました。多くの人は、これを「伝え方」の問題だと考える。でも、認知科学の研究が示すのは、違う真実です。問題は「言い方」じゃありません。「心の読み方」なんです。「何回説明しても伝わらない」はなぜ起こるのか？　認知科学が教えるコミュニケーションの本質と解決策作者:今井むつみ日経BPAmazonスキーマという名の「当たり前」認知科学には「スキーマ」という概念がある。これは、人それぞれが頭の中に持っている「当たり前」の枠組みのこと。知識や経験の構造化されたまとまりです。重要なのは、私たちは物事を「スキーマを通して」理解しているという点です。エラーログも、スキーマを通して読んでいる。ドキュメントも、スキーマを通して読んでいる。上司の指示も、スキーマを通して聞いている。生成AIの回答も、スキーマを通して読んでいます。「何回説明しても伝わらない」のは、説明する側と受け取る側で、スキーマが違うからです。上司が「この機能を実装してほしい」と言ったとします。上司の頭の中には、長年の経験から作られた「この機能」のスキーマがあります。でも、そのスキーマの大部分は、言葉にされていません。一方、受け取る側も、自分のスキーマを通してその指示を理解します。でも、それは上司のスキーマとは違うかもしれません。結果として、上司は「言ったはずだ」と思い、あなたは「聞いた通りにやった」と思う。でも、出来上がったものは違います。Rustのドキュメントを読むときも同じです。ドキュメントを書いた人には、Rustの所有権システムについての豊富なスキーマがあります。だから、「この関数はborrowします」という一文で、多くのことが伝わると思っています。でも、Rustを学び始めたばかりの人には、そのスキーマがありません。そして、生成AIの回答も、あなたのスキーマに依存しています。生成AIに「Rustの所有権システムを説明して」と聞いたとします。その説明を理解するのは、あなたのスキーマです。C++のスキーマを持っている人と、Pythonのスキーマしか持っていない人では、同じ説明を読んでも、理解する内容が違います。だから、生成AIに質問するとき、自分の前提知識（スキーマ）を明示することが有効なんです。「私はPythonしか知りません。Rustの所有権システムを、Pythonとの違いを中心に説明してください」と聞きます。人生の大問題と正しく向き合うための認知心理学 (日経プレミアシリーズ)作者:今井むつみ日経BPAmazon受け手としてどうすべきかじゃあ、受け手として、私たちはどうすればいいのか？まず、自分が持っているスキーマを自覚すること。「自分はこういう前提で理解している」と認識する。エラーログを読むとき、「これはメモリの問題だ」というスキーマで読んでいないか？生成AIの回答を読むとき、「自分の知っている範囲で」理解しようとしていないか？自分のスキーマを自覚するだけで、誤読は減ります。次に、「わかった」を疑うこと。説明を聞いて「わかった」と思った瞬間、実は自分のスキーマで解釈しているだけかもしれません。だから、理解したことを言い換えて確認します。「つまり、○○ということですか？」と聞く。生成AIを使うなら、「私はこう理解しました。[あなたの理解]。この理解は正しいですか？」と聞きます。そして、質問する勇気を持つこと。「わからない」と言うのは、勇気がいります。でも、わからないまま進むよりは、はるかにマシです。質問することは、恥ずかしいことじゃありません。自分のスキーマと相手のスキーマのズレに気づいて、それを埋めようとしている証拠です。最後に、柔軟にスキーマを更新することです。新しい技術を学ぶとき、既存のスキーマで理解しようとしがちです。でも、それが足枷になることがある。Rustを学ぶとき、C++のスキーマで理解しようとすると、所有権システムの本質を掴めません。コミュニケーションは双方向です。説明する側も、受け手のスキーマを想像する努力が必要だし、「伝わったかどうかを確認する」必要があります。受け手も、自分のスキーマを自覚し、「わかった」を疑い、質問する勇気を持ちます。この両方が揃って初めて、「伝わる」コミュニケーションが成立します。読解力とは、ただ文字を読む力じゃありません。自分のスキーマを自覚し、それを柔軟に更新しながら、相手の意図を理解しようとする力なんです。そして、生成AIを適切に使って、スキーマのズレを埋める力でもあります。情報を正しく選択するための認知バイアス事典作者:情報文化研究所フォレスト出版Amazon完璧を目指さない。でも「わかったつもり」にもならない「読解力を磨くこと」と「わかったつもりにならないこと」の間のバランスを見つけることが、本当の知性なんです。一方で、積極的に理解しようとする。努力して読解力を高める。3つの段階を一つずつ鍛える。基礎訓練の不足を補う。認知バイアスに気づく。「わかったつもり」を警戒する。生成AIを適切に使う。他方で、完璧を目指さない。常に完璧に読める人はいない。疲れているときもある。新しい分野もある。バイアスに引っかかるときもある。「わかったつもり」になってしまうときもある。生成AIの使い方を間違えるときもある。それは人間である以上、避けられません。重要なのは、失敗から学ぶことです。エラーログを読み間違えたなら、「なぜ読み間違えたのか？」と振り返る。確証バイアスに引っかかっていたのか、情報を網羅的に抽出していなかったのか、「わかったつもり」になっていたのか。生成AIに頼りすぎて、自分で考えなかったのか。次は同じ間違いをしないように、読み方を改善します。完璧を目指さない。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。そして、常に「まだ理解できていないかも」という謙虚さを持つ。問いを持ち続ける姿勢を保ちます。優れたエンジニアは、何年コードを書いても、「完璧に理解した」とは思わない。新しい技術を学び続け、既存の知識を疑い続け、より良い方法を探し続ける。失敗から学び続ける。生成AIも適切に活用する。だから成長し続けられます。読解力も同じ。どんなに上達しても、「完璧に読めている」とは思わない。失敗から学び続ける。生成AIも適切に使い続ける。だから成長し続けられます。危険だからこそ知っておくべきカルトマーケティング作者:雨宮純ぱる出版Amazonおわりにエラーログを読み間違え、ドキュメントを誤解し、コメントを誤読する。「書いてあることを読んでいない」という絶望——この記事は、そんな問題からスタートしました。そして、「読む」という行為を分解してみました。読解力は複数のスキルの集合体でした。3つの段階があり、それぞれに壁がありました。第1段階の壁は「基礎訓練の不足」、第2段階の壁は「認知バイアス」、そしてすべての段階に共通する最大の壁が「わかったつもり」。生成AIは、これらの壁を超える補助ツールになる。でも、使い方次第です。まず自分で読む、鵜呑みにしない、依存しすぎない。この原則を守らなければ、読解力は逆に衰えます。読解力は他のすべてのスキルを支える土台であり、その差は時間とともに指数関数的に広がる。コミュニケーションはスキーマを通して行われるため、自分の「当たり前」を自覚し、「わかった」を疑い、柔軟にスキーマを更新することが大切です。完璧である必要はありません。でも、失敗から学び、少しずつ改善する。これが現実的な成長の道です。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonまずは一つだけ、明日から実践してみてほしい。明日エラーログを読むとき、こう自問してみる。「仮説を立てる前に、全行を読んだか？」（第1段階）「自分のバイアスで読んでいないか？」（第2段階）「本当に重要なのはどこか？」（第3段階）「自分のスキーマで解釈していないか？」（スキーマの自覚）明日生成AIに質問するとき、こう実践してみる。「まず自分で読んでから、わからないところだけ聞く」（第1段階）「複数の解釈の可能性を聞く」（第2段階）「理解を言語化して確認してもらう」（第3段階）「前提知識を明示して質問する」（スキーマの明示）それだけで、あなたの読解力は確実に一歩前進します。ところで、ここまで「読む」という行為を分解してきました。でも実は、もう一つの行為があります。「書く」という行為です。読解力の3つの段階——正確に読む、裏を読む、本質を読む——を理解した今、書き手としての視点も変わるはずです。「読めない読み手」を嘆く前に、書き手は自問すべきです。読み手が正確に読める文章を書いているか？誤読されにくい書き方をしているか？本質を掴みやすい構造にしているか？そして何より、読み手の読解力は一定ではないことを理解しているでしょうか？疲れているとき、慣れない分野を読むとき、感情が高ぶっているとき——読み手は第1段階でさえ苦戦します。さらに、スキーマの違いを忘れてはいけません。書き手にとって「当たり前」のことが、読み手にとっては「初めて聞く」ことかもしれません。よく言われる文章作法——「結論を先に書く」「一文を短くする」——これらを抽象化すると、すべて読み手の認知リソースを尊重するという原則に行き着きます。読み手は無限の時間と集中力を持っているわけじゃありません。その限られたリソースを、いかに有効に使ってもらうか。読解力と同じように、文章力も分解可能なスキル群です。読解力を分解して鍛えられるように、文章力も分解して鍛えられます。読解力を理解することは、文章力を理解することでもありますので書きました。syu-m-5151.hatenablog.com生成AIがあれば読解力は不要になるのか？——記事の冒頭で問いかけました。答えは明確です。生成AIがあるからといって、読解力が不要になるわけじゃありません。むしろ、生成AIを使いこなすために、読解力がますます重要になる。そして同じことが、文章力にも言えます。「わかったつもり」という最大の壁を、常に警戒してほしい。「もうわかった」と思った瞬間が、最も危険な瞬間なのですから。それでは。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Modern Monolithを作りましょう！ Inertia.jsの紹介とその先]]></title>
            <link>https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian</link>
            <guid isPermaLink="false">https://speakerdeck.com/aminevg/modern-monolithwozuo-rimasiyou-inertia-dot-jsnoshao-jie-tosonoxian</guid>
            <pubDate>Sat, 11 Oct 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[マイクロサービス流行の時代で、あえてモノリスを作りませんか？バックエンドとフロントエンドの連携を行う際は、辛い思いをした方が多いのではないでしょうか。APIの作成、認証の実装、フォーム送信など、様々なハードルがあります。そういった問題を解決して、フルスタック開発を楽にするライブラリさえあれば...実際にありますよ！このLTでは、SPAのフロントエンドをバックエンド内で作れるInertia.jsをご紹介します。基本的な使い方から、直近の新機能やInertia.jsの将来を解説します。このLTを通じて、「フルスタック開発が楽になった！」「フロントエンドのためのAPI設計はもうさらばだ！」と思ってもらえればと思います。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoのGuardrail機能を試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/48cea67449be64</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/48cea67449be64</guid>
            <pubDate>Sat, 11 Oct 2025 03:09:11 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[楽にあなたのクラウドを守ろう！ - CNAPP概要]]></title>
            <link>https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/cloud-security-using-cnapp</guid>
            <pubDate>Fri, 10 Oct 2025 23:00:05 GMT</pubDate>
            <content:encoded><![CDATA[要約複数のセキュリティツールを使うのって大変だよねCNAPPとは統合セキュリティプラットフォーム っていう概念だよタイトルの「楽に」の意味は、CNAPP導入で結果的に運用が楽になるよ、という意味だよCNAPPを実現するツールは色々あるよ はじめにクラウドネイティブアプリケーションのセキュリティ対策で以下のような課題を抱えていませんか？複数のセキュリティツールを個別に運用しているそれぞれが独立した警告を発し、全体像が見えない運用コストが膨大で重要な脅威を見逃すリスクがあるそんな課題を解決するのがCNAPP（Cloud Native Application ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoを使ってOpenAIのエージェントを作成してみた]]></title>
            <link>https://zenn.dev/akasan/articles/80953b8e206dd0</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/80953b8e206dd0</guid>
            <pubDate>Fri, 10 Oct 2025 13:42:45 GMT</pubDate>
            <content:encoded><![CDATA[今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...]]></content:encoded>
        </item>
    </channel>
</rss>