<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sun, 13 Apr 2025 11:34:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[genai-toolbox を実装して mcp server として公開し adk から使ってみる]]></title>
            <link>https://zenn.dev/satohjohn/articles/dbf4afed585680</link>
            <guid>https://zenn.dev/satohjohn/articles/dbf4afed585680</guid>
            <pubDate>Sun, 13 Apr 2025 01:54:27 GMT</pubDate>
            <content:encoded><![CDATA[mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[既存の mcp を adk 経由で叩いてみる。 playwright を使う。]]></title>
            <link>https://zenn.dev/satohjohn/articles/68bdde2842e8b4</link>
            <guid>https://zenn.dev/satohjohn/articles/68bdde2842e8b4</guid>
            <pubDate>Sat, 12 Apr 2025 10:12:09 GMT</pubDate>
            <content:encoded><![CDATA[mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ADK で作った agent を mcp server で公開する]]></title>
            <link>https://zenn.dev/satohjohn/articles/48a82ff7de531b</link>
            <guid>https://zenn.dev/satohjohn/articles/48a82ff7de531b</guid>
            <pubDate>Fri, 11 Apr 2025 16:21:06 GMT</pubDate>
            <content:encoded><![CDATA[ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ADK + Cloud Run を動かす]]></title>
            <link>https://zenn.dev/satohjohn/articles/b23bd65c289257</link>
            <guid>https://zenn.dev/satohjohn/articles/b23bd65c289257</guid>
            <pubDate>Fri, 11 Apr 2025 08:02:18 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Next '25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞]]></title>
            <link>https://sreake.com/blog/2025-google-cloud-partner-of-the-year/</link>
            <guid>https://sreake.com/blog/2025-google-cloud-partner-of-the-year/</guid>
            <pubDate>Wed, 09 Apr 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年4月9日に、「2025 Google Cloud Partner of the Year」において「Infrastructure Modernization Partner of the Year - Japan」を受賞したことをお知らせします。The post スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Geminiとリアルタイム音声会話できるWebアプリの作り方]]></title>
            <link>https://sreake.com/blog/gemini-realtime-voice-chat-app/</link>
            <guid>https://sreake.com/blog/gemini-realtime-voice-chat-app/</guid>
            <pubDate>Tue, 08 Apr 2025 06:04:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[n8n on Cloud Run （ツール比較から選定まで）]]></title>
            <link>https://zenn.dev/meziron/articles/bff3ac566f8b93</link>
            <guid>https://zenn.dev/meziron/articles/bff3ac566f8b93</guid>
            <pubDate>Tue, 08 Apr 2025 04:53:10 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[mcphub.nvimでNeovimでもMCPを使う]]></title>
            <link>https://blog.atusy.net/2025/04/08/mcphub-nvim/</link>
            <guid>https://blog.atusy.net/2025/04/08/mcphub-nvim/</guid>
            <pubDate>Tue, 08 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[MCP（Model Context Protocol）をNeovimで使うためのmcphub.nvimの導入方法を紹介します。codecompanion.nvimなどのAIチャットプラグインに@mcpと入力するだけで、状況に合わせてツールを選択してくれるので凄く便利。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[エンジニアブログは技術的であるべきで登壇は衒学的であると思う理由]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150</guid>
            <pubDate>Mon, 07 Apr 2025 09:11:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあなたは最後に技術的な記事を読んだとき、何を求めていただろうか？この二つの問いに対する答えは、おそらく大きく異なるのではないだろうか。記事を読むとき、私は再現可能な手順、明確なコード例、具体的な問題解決の道筋を期待する。一方、技術発表を聞くとき、新たな視点やアイデア、そして時に「なるほど、そういう考え方があるのか」という気づきを求めている。技術を共有する手段として、ブログを書き、カンファレンスで登壇する。一見すると同じ「知識共有」という行為に見えるが、この二つは根本的に異なる体験を生み出している。ブログは時間に縛られず、読者が自分のペースで情報を咀嚼できる。一方、登壇は限られた時間の中で、話者の熱量や会場の空気感とともに知識が伝わる。この違いは偶然ではなく、それぞれのメディアには、最適な伝え方があると私は考えている。本稿では、私個人の経験から、エンジニアブログが技術的であるべき理由と、登壇が（ある意味で）衒学的(げんがくてき)である方が効果的である可能性について考察していく。もちろん、これはあくまで一つの視点に過ぎない。技術共有の形は人それぞれであり、正解は一つではないだろう。はじめにエンジニアブログが技術的であるべき理由参照性と再現性の重要性長期的な価値実装の痕跡としての価値集合知の形成と技術の民主化未来の自分への投資思考プロセスの可視化登壇が衒学的であっても良い理由衒学的とは何か「見せかけの深さ」が生む魅力とモチベーション「わかった気にさせる」テクニックと一過性の特性ステータスシンボルとしての衒学記憶に残るメンタルモデルの構築異分野からの知見取り込みの触媒衒学的アプローチの価値と限界まとめエンジニアブログが技術的であるべき理由技術ブログの書き方はこちらでお願いします。syu-m-5151.hatenablog.com参照性と再現性の重要性エンジニアブログの重要な特徴は、読者がいつでも立ち返ることができる参照点となることです。コードの実装例、設定手順、トラブルシューティングの方法など、技術的な内容は「再現できる」ことが最も重要です。技術的であるということは、単に難しい言葉を使うことではなく、読者が同じ結果を得られるように明確で具体的な手順を提供することです。例えば、クラウドでサーバーレスアプリケーションを構築する方法を説明するブログ記事では、使用するサービス、必要な設定、コード例、発生しうる問題とその解決策など、実践的で具体的な情報が求められます。長期的な価値技術的なブログ記事は、時間が経過しても価値を保ちます。もちろんテクノロジーは進化しますが、基本的な概念や問題解決のアプローチは長く参照されることがあります。「どのようにして特定の問題を解決したか」という記録は、数年後の同様の問題に直面したエンジニアにとって貴重な資料となります。例えば、5年前に書かれたコンテナ技術のネットワーク問題のデバッグ方法に関する記事は、現在でも参考になることが多いです。具体的な実装の痕跡は、技術の進化に関わらず価値を持ち続けるのです。実装の痕跡としての価値技術的なブログ記事の価値は、「実際にやってみた痕跡」が残ることです。抽象的な概念や理論ではなく、「この実装でこの問題に直面し、このように解決した」という具体的な記録は、他のエンジニアにとって何物にも代えがたい財産となります。コードスニペット、設定ファイル、エラーメッセージとその対処法などは、まさに泥臭いエンジニアリングの証であり、読者が同じ問題に直面したときの救いの手となります。理論や概念を語るのは簡単ですが、実際の実装の痕跡を残すことこそ、技術ブログの本質的な価値と言えるでしょう。ブログの目的は、実際に同じ道を歩んでいる人の助けになることだからです。集合知の形成と技術の民主化技術的なブログ記事は、個人の経験を超えた「集合知」の形成に貢献します。特に大企業や専門家だけが持っていた知識が、個人のブログを通じて広く共有されることで、技術の民主化が進みます。オープンソースの精神と同様に、技術的なブログは知識のバリアを取り払い、誰もが高度な技術にアクセスできる環境を作り出します。例えば、以前は高価な書籍や専門的なトレーニングでしか学べなかった最先端の技術が、今では個人のブログを通じて無料で学べるようになっています。この知識の解放こそが、技術革新のスピードを加速させる原動力となっています。未来の自分への投資技術ブログを書くことは、未来の自分への最高の投資でもあります。今日困難を乗り越えた方法を記録しておくことは、数ヶ月後、数年後に同じ問題に直面したときの自分自身へのギフトとなります。「あれ、この問題以前にも解決したはずだが、どうやったんだっけ？」という状況は、エンジニアなら誰もが経験するものです。自分のブログは、検索エンジンよりも信頼できる個人的な知識ベースとなり、問題解決の時間を大幅に短縮してくれます。さらに、記録する行為そのものが理解を深め、知識を定着させるため、学習効率も向上します。思考プロセスの可視化優れた技術ブログは、単に「何を」実装したかだけでなく、「なぜそうしたのか」「他にどんな選択肢を検討したのか」という思考プロセスも含みます。この思考の軌跡を残すことで、技術選択の背後にある意思決定の流れが明らかになり、読者はより深い文脈で技術を理解できます。例えば、「Aという技術とBという技術を比較検討した結果、こういう理由でAを選んだ」という記述は、単にAの使い方を説明するよりも価値があります。なぜなら、読者は自分の状況に照らし合わせて意思決定できるようになるからです。思考プロセスの共有は、テクニックだけでなく技術的判断力も養う助けとなります。登壇が衒学的であっても良い理由衒学的とは何かまず「衒学的(げんがくてき)」という言葉について整理しておきましょう。衒学的とは、本質的な理解が伴わないにもかかわらず、学識があるように見せかけ、それを誇示するような様子を指します。つまり、実際には深い知識や経験がなくても、難解な専門用語や引用を多用し、表面的に「賢そうに見せる」テクニックと言えるでしょう。登壇において、この「賢そうに見せる」という要素が、皮肉にも効果的である理由を考えていきます。また、これらは外部登壇を指し社内のプレゼンテーションとは別物ですので御容赦下さい。「見せかけの深さ」が生む魅力とモチベーション登壇の場では、実は技術的な詳細よりも「語り方」や「見せ方」が重要になることが多いのではないかと私は感じています。難解な概念や用語を織り交ぜ、「これは単なる技術ではなく、哲学なのだ」と語ることで、聴衆に「深い知見を得た」という錯覚を与えることができます。例えば、マイクロサービスアーキテクチャの実装という話題でも、具体的な実装方法よりも「組織設計との整合性」「分散システムの哲学的背景」などと語れば、特に具体的な内容がなくても「深い話を聞いた」という満足感を聴衆に与えることができるのです。私個人の考えでは、登壇の一つの重要な目的は、聴衆を「やる気にさせること」であり、具体的な方法論よりも「そういうアプローチもあるのか！」という気づきと挑戦意欲を引き出すことにあります。もちろん、これは私の一意見であり、登壇の目的は発表者それぞれが自由に決めるものです。聴衆が実際に行動を起こす可能性を高めるために解決策の提示が効果的であれば、それも取り入れるべきでしょう。しかし実装の苦労や具体的な失敗談よりも、抽象的な概念を語る方が「賢そう」に見えるという側面があるのも、一つの観察です。登壇スタイルは千差万別で、どれが正解というものではありません。「わかった気にさせる」テクニックと一過性の特性登壇は一過性のメディアです。登壇資料が公開される可能性が高いとはいえ、その場で聞くことと読むことでは体験や雰囲気が大きく異なります。実際には聴衆のほとんどは具体的な技術内容を覚えて帰ることはできないことが多いでしょう。それよりも「あの人は賢そうだった」「深い話だった気がする」という印象だけが残ることが少なくありません。私の経験では、登壇の短い時間内で、全ての文脈やトレードオフを理解してもらい、「なぜこういう判断をしたのか」を完全に伝えることはほぼ不可能です。実際の開発においては数週間から数ヶ月かけて検討したことを、わずか30分や1時間で説明するには限界があります。それぞれの登壇者が、この制約の中でベストだと思う方法を選択していると思います。この特性を踏まえると、実装の詳細や技術的な苦労よりも、引用や専門用語、抽象的な概念を散りばめることで「わかった気にさせる」アプローチが生まれるのも理解できます。私の考えでは、登壇の目的の一つは、人を分かった気にさせてやる気を引き出すことにあります。聴衆は具体的に何を学んだかを説明できなくても、「深い話を聞いた」という満足感と「自分も挑戦してみよう」というモチベーションを得ることができるかもしれません。もちろん、別の目的や価値観を持って登壇に臨む人もいて、それも素晴らしいことだと思います。もちろん、聴衆のやる気を引き出すために具体的な解決策を提示することが効果的であれば、それも積極的に取り入れるべきでしょう。しかし多くの場合、登壇者にとっても、抽象的な概念を語る方が準備も楽で「賢そうに見える」という都合の良さがあります。ステータスシンボルとしての衒学衒学的な登壇は、皮肉にもコミュニティ内での一種のステータスシンボルとなっています。「実装の詳細を語る人」より「大きな概念や哲学を語る人」の方が尊敬されるという暗黙の序列が形成されているのです。技術カンファレンスで最も拍手を浴びるのは、具体的な実装方法を丁寧に説明した発表ではなく、抽象的な概念を難解な用語で彩った発表であることが多いのは、この現象の表れと言えるでしょう。エンジニアであれば誰しも「コードを書く人」より「アーキテクトやコンサルタント」のように見られたいという欲求があり、衒学的な登壇はそれを満たす手段となっています。記憶に残るメンタルモデルの構築例えば、分散システムの説明で「ビザンチン将軍問題」や「CAP定理」といった概念を取り上げることは、単なる実装テクニックの説明よりも聴衆の理解と記憶に残りやすいものです。これらの抽象的なモデルは「問題のやり方」ではなく「問題の捉え方」や「考え方」を提供し、聴衆が様々な状況で応用できる思考ツールとなります。衒学的に思えるこうした抽象化は、表面的な知識の誇示ではなく、実は技術の本質をより効果的に伝えるための有効な手段となり得るのです。特に登壇という限られた時間の中では、具体的な細部よりも「考え方」を伝えることの方が、長期的な価値を生み出す可能性が高いと思います。異分野からの知見取り込みの触媒衒学的なアプローチの興味深い側面として、それが異なる専門分野からの知見を技術の文脈に取り入れる触媒になることがあります。哲学、経済学、心理学、生物学などの概念を技術的課題と結びつけることで、技術コミュニティに新しい視点がもたらされるのです。例えば、システム設計において「アンチフラジャイル」（ナシーム・タレブの概念）や「レジリエンス工学」といった他分野からの概念を導入することで、従来のエンジニアリングの枠を超えた発想が生まれます。一見すると衒学的に見えるこうした「知の越境」は、実は技術の進化において重要な役割を果たしています。異分野の知見を適切に取り入れる衒学的アプローチは、単なる見せかけではなく、技術コミュニティに真の価値をもたらし得るものです。特に複雑な問題に対して、単一分野の知見だけでは不十分な場合、こうした学際的な視点は革新的な解決策を生み出す源泉となり得ます。衒学的アプローチの価値と限界「具体」と「抽象」は物事の捉え方や表現の仕方において相対的な関係性を持ちます。登壇における衒学的アプローチは、多くの場合、抽象度を高めた表現を用いることで成り立っています。抽象的な表現は、個別の事例を超えた共通点や法則性を見出し、多くの状況に適用できる知見を提供できるという利点があります。具体的な表現は直観的でわかりやすく、個々の事例や実装を明確に伝えますが、抽象的な表現は多くの事象に共通する本質や性質を簡潔にまとめることができます。聴衆によって「しっくりくる表現」は異なり、抽象的な概念が腑に落ちる人もいれば、具体例から理解を深める人もいます。衒学的と思われる表現であっても、それが聴衆の一部にとって心に響くものであれば、それは価値あるコミュニケーションと言えるのではないでしょうか。具体と抽象を行き来する思考は、問題解決やコミュニケーション能力を高める上でも重要です。登壇者が衒学的に見える抽象的表現を用いつつも、適切なタイミングで具体例に降りてくる「往復」ができれば、より効果的な知識共有が可能になると思います。以上のような考察は、あくまで個人的な観察と意見です。技術コミュニティには様々な価値観があり、登壇のスタイルも多様であるべきだと思います。優れたエンジニアでも、登壇の場では衒学的になることを求められ、それに応えることでキャリアを築いていく側面があるように感じます。私の見解としては、実装の詳細や技術的な苦労話はブログという形式で書き残しておき、登壇では適度に抽象度を上げた概念を語るという使い分けは、それぞれのメディアの特性を活かした一つのアプローチかもしれません。ブログであれば、読者は自分のペースで何度も読み返し、理解を深めることができます。一方、登壇では限られた時間で複雑な文脈を伝えることは難しく、聴衆の注意を引きつつ主要なメッセージだけを印象づける技術が必要になるケースが多いと感じています。しかし、登壇が衒学的すぎることにも明らかな危険性があります。実体のない難解な言葉だけで埋め尽くされた発表は、短期的には印象的に見えても、長期的には聴衆の信頼を失います。「この人は話が上手いだけで、実際には何も伝えていない」と見抜かれれば、せっかくの登壇も台無しではないでしょうか。また、あまりに現実から乖離した抽象論ばかりでは、聴衆が実際の業務に持ち帰れる価値が少なく、最終的な目的である「やる気にさせる」ことにも失敗してしまうかもしれません。私なりに考える理想的な登壇とは、衒学的アプローチを適度に取り入れつつも、聴衆が明日から使える具体的なヒントや考え方をしっかりと提供するものです。「難解に思えるけれど、よく考えると実践的な知恵がある」という絶妙なバランスこそが、価値ある登壇の鍵かもしれませんが、これはあくまで一つの視点であり、様々な登壇スタイルがあって然るべきだと思います。エンジニアが技術的スキルに加えて、抽象的な概念を効果的に伝えるスキルを磨くことの価値は、人それぞれの考え方によると思います。重要なのは単なる見せかけではなく、本質的な価値を状況や相手に応じて適切に伝えるための表現技術ではないかと考えています。まとめエンジニアブログは具体的で技術的であることで長期的な参照価値を持ち、誰かの実際の問題解決に貢献します。一方、登壇は適度に衒学的なアプローチを取りながらも、聴衆に「深い話を聞いた」という満足感を与え、「自分も挑戦してみよう」というモチベーションを引き出すという役割があるように思います。もちろん、これはあくまで一つの見方であり、登壇やブログの形は多様であってよいと思います。「中身のない衒学」ではなく「知見を効果的に伝える技術」を身につけるべきだと考えています。限られた登壇時間と聴衆の記憶容量を考えると、物事を単純化し印象づける技術には価値がありますが、それが空虚なものであれば、長期的には信頼を失うことになると感じています。他の方は異なる価値観を持っているかもしれませんし、それも尊重されるべきです。個人的に大切だと思うのは、ブログでは誠実に技術を伝え、実際に同じ道を歩む人の助けになる一方で、登壇では効果的な伝え方を工夫しながらも本質的な価値を提供し、聴衆のやる気を引き出す、というそれぞれのメディアの特性を理解して使い分けることではないでしょうか。そして何より、「賢そうに見せる」ことと「本当に賢いこと」の違いを自分自身がしっかりと理解しておくことが重要だと思います。結局のところ、優れた技術共有とは、表面的な知識の誇示ではなく、本質的な価値をいかに効果的に伝えるかというバランスの問題なのかもしれません。メディアの特性を理解し、それぞれに合った形で自分の知見を共有できれば、技術コミュニティ全体がより豊かになっていくのではないでしょうか。これらはあくまで個人の経験と観察に基づく意見であり、みなさんがそれぞれのスタイルや価値観で技術共有を行うことを応援しています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド]]></title>
            <link>https://zenn.dev/meziron/articles/a95d3133a1c385</link>
            <guid>https://zenn.dev/meziron/articles/a95d3133a1c385</guid>
            <pubDate>Mon, 07 Apr 2025 05:34:46 GMT</pubDate>
            <content:encoded><![CDATA[運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CopilotChat.nvimでもギャルとペアプロしたい！]]></title>
            <link>https://blog.atusy.net/2025/04/06/copilotchat-with-gal/</link>
            <guid>https://blog.atusy.net/2025/04/06/copilotchat-with-gal/</guid>
            <pubDate>Sun, 06 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[ギャルとのペアプロが想像以上に楽しかった（VSCodeのカスタム指示）という話を見て、なにそれ面白いとなった。そこへ来て友人が、思慮深いお姉さんも登場させると勝手にプログラミングしてくれて面白いという。これはNeovimでもやってみるしかないと、とりあえずCopilotChat.nvimのユーザープロンプトを試してみた。しかし、見事にコンテンツフィルタに弾かれてしまいました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI時代に必要なシェルの基本知識とシェル芸への入門]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754</guid>
            <pubDate>Thu, 03 Apr 2025 23:57:54 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIの急速な発展により、様々なAIアシスタントが日常的にシェルコマンドを提案してくれるようになりました。また、最新のAI統合ツールは、ユーザーの自然言語指示からコマンドを生成し、場合によっては自動的に実行することさえあります。このような環境では、AIが提案または実行するシェルコマンドを正確に理解し、安全に活用するための知識が不可欠となっています。「コマンドプロンプトやLinuxなんて難しそう」「プログラミングは専門家の領域」と思っている方こそ、この記事をお読みください。AIツールを使う現代では、専門知識がなくても基本を知っておくことで安全性が大きく変わります。本記事では、生成AIが提案するシェルコマンドを適切に評価し、安全に活用するために必要なシェルの基本知識と「シェル芸」と呼ばれる技術について詳しく解説します。難しい専門用語は極力避け、初心者の方でも理解できるよう丁寧に説明していきます。AIが生成したコードを盲目的に実行することのリスクを避けつつ、その強力な機能を最大限に活用するための実践的な知識を身につけていただくことを目指しています。b.ueda.tech普通に無料でダウンロードできるのでLinux標準教科書もオススメです。linuc.orgこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめに生成AIとシェルコマンドの関係シェルの基本概念代表的なシェルシェルの重要な機能1. I/O（入出力）2. パイプ3. リダイレクト4. フィルタ処理5. 内部展開6. 制御構文条件分岐（if文）case文（パターンマッチング）for ループwhile ループuntil ループ（条件が真になるまで繰り返す）関数定義と呼び出しその他の制御構文と技法AIが提案するシェルコマンドを理解するAIが生成するシェルコマンドの特徴ワンライナーの理解と解読ワンライナーの特徴生成AIが提案するワンライナーの例ワンライナーを解読する方法ワンライナーを複数行スクリプトに変換するコマンドを分解して理解する方法危険なコマンドの見分け方注意すべきコマンドとオプション安全に検証する方法安全な実行環境の構築と活用実用的なシェル芸とAIの活用例ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整AIからの提案を検証して実行する例テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価AIと連携したデータ前処理の例環境変数とエイリアスの理解環境変数の確認と活用AIが提案するエイリアスを安全に設定ジョブ制御と長時間実行コマンド長時間実行コマンドの制御実行中コマンドの管理ワンライナーの安全性評価と活用法ワンライナーの安全性評価チェックリストワンライナーを安全に変換する方法AIが提案するワンライナーを効果的に活用するコツワンライナー活用のベストプラクティスまとめ生成AIとシェルコマンドの関係生成AIはシェルコマンドの提案において非常に優れた能力を持っています。複雑な操作を1行のコマンドで実現したり、複数のツールを組み合わせて効率的なデータ処理を行ったりするシェルコマンドを即座に提案できます。しかし、この便利さの一方で、次のような課題も生じています。理解なき実行のリスク: AIが提案するコマンドを理解せずに実行すると、意図しないファイル削除やセキュリティリスクを引き起こす可能性があります環境依存の問題: AIは特定の環境を前提としたコマンドを提案することがあり、異なる環境で実行すると期待した結果が得られないことがあります権限の問題: 管理者権限が必要なコマンドを適切な検証なしに実行すると、システムに重大な影響を及ぼす可能性があります自動実行の危険性: GitHub Copilot CLIなどのツールがコマンドを自動生成し実行する場合、確認の機会なくリスクのあるコマンドが実行される可能性がありますこれらの課題に対処するには、シェルの基本を理解し、AIが提案するコマンドを正確に評価できる能力が必要です。シェルの基本概念シェルとは、オペレーティングシステム（OS）のカーネルと対話するためのインターフェースです。ユーザーがコマンドを入力すると、シェルはそれを解釈し、OSに対して適切な指示を出します。豆知識: シェルという名前は「殻」を意味し、OSの核心部分（カーネル）を覆う層として機能することに由来しています。［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】作者:武内 覚技術評論社Amazon代表的なシェルBash (Bourne Again SHell): Linux/Unixの標準シェルZsh (Z Shell): Bashの機能を拡張したシェル、macOSのデフォルトシェルPowerShell: Windowsで使用されるシェルFish: ユーザーフレンドリーな機能を持つシェル生成AIは異なるシェル環境向けのコマンドを提案することがあるため、自分の環境に合ったコマンドを理解し選択する必要があります。シェルの重要な機能AIが提案するコマンドを理解するには、以下のシェルの基本機能を把握することが重要です。1. I/O（入出力）Linuxの入出力は主に3つのストリームで管理されています。標準入力（stdin）: ユーザーからのキーボード入力（ファイルディスクリプタ 0）標準出力（stdout）: 通常の出力結果（ファイルディスクリプタ 1）標準エラー出力（stderr）: エラーメッセージ（ファイルディスクリプタ 2）AIが複雑な入出力リダイレクトを含むコマンドを提案した場合、これらの概念を理解していないと意図しない動作を引き起こす可能性があります。2. パイプパイプ（|記号）を使うと、あるコマンドの出力を次のコマンドの入力として渡すことができます。AIは複数のコマンドをパイプでつないだ複雑なワンライナーを好んで提案することがあります。例：# AIが提案するような複雑なパイプラインfind . -type f -name "*.log" | grep "ERROR" | awk '{print $1, $2}' | sort | uniq -cこのようなコマンドを理解するには、各部分の役割を個別に把握する必要があります。3. リダイレクトシェルではコマンドの出力を任意のファイルに書き出したり、コマンドへの入力を任意のファイルから行ったりできます。例：# 出力のリダイレクトls -l > file_list.txt  # 上書きls -l >> file_list.txt  # 追記# 入力のリダイレクトsort < unsorted.txt# エラー出力のリダイレクトcommand 2> error.log# 標準出力とエラー出力を同じファイルへcommand > output.log 2>&1AIが提案するコマンドにリダイレクトが含まれる場合、既存ファイルの上書きなど、意図しない結果につながる可能性があるため注意が必要です。4. フィルタ処理生成AIは多くの場合、複数のフィルタコマンドを組み合わせた処理を提案します。代表的なフィルタコマンドとその役割を理解しておくことが重要です。grep: テキスト検索（正規表現可）sed: ストリームエディタ（テキスト置換など）awk: テキスト処理言語（列指向の処理に強い）sort/uniq: 行のソートと重複排除cut/paste: 列の切り出しと結合head/tail: 先頭/末尾の行を表示AIが提案する複雑なパイプラインは、これらのコマンドを組み合わせたものであることが多いため、各コマンドの役割を理解していれば全体の意図も把握しやすくなります。5. 内部展開シェルは入力されたコマンドを実行する前に、様々な展開処理を行います。AIが提案するコマンドに含まれる特殊な構文を理解するには、これらの展開処理の知識が必要です。変数展開: $VAR や ${VAR} で変数の値に置き換えるコマンド置換: `command` や $(command) でコマンドの実行結果に置き換える算術展開: $((expression)) で数式の計算結果に置き換えるブレース展開: {a,b,c} や {1..5} でパターンを展開するパス名展開（グロビング）: *, ?, [abc] などのワイルドカードを使ったファイル名の展開AIが提案するコマンドには、これらの展開を利用した簡潔な表現が含まれていることが多いです。6. 制御構文シェルスクリプト内での処理の流れを制御するための構文です。AIはしばしば複雑な条件分岐やループを含むシェルスクリプトを提案します。これらの構文を理解できないと、AIが提案するスクリプトの意図や潜在的なリスクを見逃す可能性があります。条件分岐（if文）# 基本構文if [ 条件 ]; then    # 条件が真の場合の処理elif [ 別の条件 ]; then    # 別の条件が真の場合の処理else    # どの条件も満たさない場合の処理fi# 数値比較の例if [ $num -eq 10 ]; then    echo "numは10です"elif [ $num -gt 10 ]; then    echo "numは10より大きいです"else    echo "numは10より小さいです"fi# ファイル・ディレクトリのテストif [ -f "$file" ]; then    echo "$fileは通常ファイルです"elif [ -d "$file" ]; then    echo "$fileはディレクトリです"elif [ ! -e "$file" ]; then    echo "$fileは存在しません"fi# 文字列比較if [ "$str1" = "$str2" ]; then    echo "二つの文字列は同じです"fiif [ -z "$var" ]; then    echo "変数は空です"fi主な条件テスト演算子：- 数値比較: -eq(等しい), -ne(等しくない), -lt(より小さい), -le(以下), -gt(より大きい), -ge(以上)- ファイルテスト: -e(存在する), -f(通常ファイル), -d(ディレクトリ), -r(読み取り可能), -w(書き込み可能), -x(実行可能)- 文字列テスト: =(等しい), !=(等しくない), -z(空), -n(非空)高度な条件テスト（[[ ]]構文）：# 拡張条件テストif [[ "$file" == *.txt ]]; then    echo "テキストファイルです"fiif [[ "$str" =~ ^[0-9]+$ ]]; then    echo "数値のみの文字列です"fi# 論理演算子if [[ $num -gt 5 && $num -lt 10 ]]; then    echo "numは5より大きく10未満です"fiif [[ $opt == "a" || $opt == "b" ]]; then    echo "オプションはaまたはbです"ficase文（パターンマッチング）# 基本構文case $variable in    pattern1)        # pattern1にマッチした場合の処理        ;;    pattern2|pattern3)        # pattern2またはpattern3にマッチした場合の処理        ;;    *)        # どのパターンにもマッチしない場合の処理（デフォルト）        ;;esac# 実用例case $action in    start|begin)        echo "サービスを開始します"        service_start        ;;    stop|end)        echo "サービスを停止します"        service_stop        ;;    restart)        echo "サービスを再起動します"        service_restart        ;;    *)        echo "使用法: $0 {start|stop|restart}"        exit 1        ;;esacfor ループ# 基本形（リスト指定）for item in item1 item2 item3; do    echo "処理: $item"done# 範囲指定for i in {1..10}; do    echo "数: $i"done# ステップ付き範囲指定for i in {1..10..2}; do    echo "奇数: $i"  # 1,3,5,7,9done# コマンド出力をループfor file in $(find . -name "*.txt"); do    echo "ファイル: $file"done# ワイルドカード展開for file in *.log; do    echo "ログファイル: $file"done# C言語風の構文for ((i=0; i<5; i++)); do    echo "カウント: $i"donewhile ループ# 基本構文while [ 条件 ]; do    # 条件が真の間、繰り返し実行される処理done# カウンタ変数による繰り返しcount=1while [ $count -le 5 ]; do    echo "カウント: $count"    count=$((count + 1))done# ファイル内容を1行ずつ処理while read line; do    echo "Line: $line"done < input.txt# コマンド結果をチェックするループwhile ping -c 1 example.com > /dev/null; do    echo "サーバーは応答しています"    sleep 5doneuntil ループ（条件が真になるまで繰り返す）# 基本構文until [ 条件 ]; do    # 条件が偽の間、繰り返し実行される処理done# 例: サービスが起動するまで待機until service_is_running; do    echo "サービス起動を待機中..."    sleep 2doneecho "サービスが起動しました"関数定義と呼び出し# 基本的な関数定義function greet {    echo "Hello, World!"}# 別の構文（function キーワードなし）backup_file() {    cp "$1" "$1.bak"    echo "Backed up $1 to $1.bak"}# 引数を受け取る関数print_args() {    echo "第1引数: $1"    echo "第2引数: $2"    echo "すべての引数: $@"    echo "引数の数: $#"}# 戻り値を返す関数is_even() {    if (( $1 % 2 == 0 )); then        return 0  # 成功（真）    else        return 1  # 失敗（偽）    fi}# 関数の呼び出しgreetbackup_file "important.txt"print_args "hello" "world"# 戻り値のチェックif is_even 4; then    echo "4は偶数です"fiその他の制御構文と技法# コマンドの成功/失敗に基づく条件実行command1 && command2  # command1が成功した場合のみcommand2を実行command1 || command2  # command1が失敗した場合のみcommand2を実行# 例grep "pattern" file.txt && echo "パターンが見つかりました"grep "pattern" file.txt || echo "パターンが見つかりませんでした"# サブシェル（グループ化）(cd /tmp && ls -la)  # 現在のディレクトリを変更せずにコマンドを実行# 現在のシェルでのグループ化{ echo "開始"; command1; command2; echo "終了"; }# エラーハンドリングset -e  # エラーが発生したらスクリプトを終了trap 'echo "エラーが発生しました"; exit 1' ERR  # エラー発生時の処理を指定# デバッグモードset -x  # 実行されるコマンドを表示AIが生成するシェルスクリプトには、これらの制御構文が組み合わされて使用されることが多いです。特に注意すべき点は：条件判定の確認: 条件テストが意図したとおりに動作するか確認するループの終了条件: 無限ループになっていないか確認するエラーハンドリング: エラー発生時に適切に処理されるか確認する変数の展開: 変数が適切に展開されて使用されているか確認するAIが提案するスクリプトの制御構文を理解することで、そのスクリプトが何をしようとしているのか、そして潜在的なリスクがあるかどうかを判断できるようになります。AIが提案するシェルコマンドを理解する生成AIは非常に効率的なシェルコマンドを提案できますが、それを理解し安全に実行するにはいくつかのステップが必要です。特に生成AIは複雑な処理を1行で完結させる「ワンライナー」を好んで提案する傾向があります。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社AmazonAIが生成するシェルコマンドの特徴複雑なワンライナー: 複数の処理を1行で実行するコマンド高度なオプションの使用: 一般的ではない特殊なオプションの利用複数のツールの組み合わせ: grep, sed, awk, findなど複数のツールを組み合わせた処理正規表現の多用: 複雑なパターンマッチングを使用したテキスト処理環境依存の記述: 特定の環境を前提としたコマンドリソース集約的な処理: システムリソースを大量に消費する可能性のある処理ワンライナーの理解と解読生成AIは複数のコマンドを組み合わせた「ワンライナー」を頻繁に提案します。ワンライナーとは、複数の処理を1行のコマンドで完結させる技法で、効率的ですが理解が難しい場合があります。ワンライナーの特徴複数コマンドの連結: パイプ（|）やセミコロン（;）で複数のコマンドを連結制御構文の圧縮: if文やループをセミコロンで区切り1行に記述サブシェルの多用: $(command) や `command` でコマンド出力を埋め込みリダイレクトの組み合わせ: 入出力リダイレクトを複雑に組み合わせる特殊な演算子: &&（AND）、||（OR）、{}（グループ化）などの使用生成AIが提案するワンライナーの例# ログファイルからエラーを抽出して集計するワンライナーfind /var/log -name "*.log" -mtime -7 | xargs grep -l "ERROR" | xargs cat | grep -o "ERROR: [^ ]*" | sort | uniq -c | sort -nr | head -10# ディレクトリ内の大きなファイルを検索して移動するワンライナーfind . -type f -size +100M -exec du -h {} \; | sort -hr | head -10 | awk '{print $2}' | xargs -I{} mv {} /backups/# 複数ファイルの文字列を一括置換するワンライナーgrep -l "oldtext" *.txt | xargs sed -i 's/oldtext/newtext/g'# 条件分岐を含むワンライナーfor file in *.log; do [ -s "$file" ] && echo "$file is not empty" || echo "$file is empty"; done# サブシェルと変数展開を使ったワンライナーfor i in {1..5}; do mkdir -p project_$(date +%Y%m%d)_$i/{src,docs,tests}; doneワンライナーを解読する方法セミコロンで分割: セミコロン（;）で区切られた部分を別々のコマンドとして考える   # 元のワンライナー   cd /tmp; mkdir test; cd test; touch file.txt; echo "done"      # 分解したコマンド   cd /tmp   mkdir test   cd test   touch file.txt   echo "done"パイプライン分析: パイプ（|）ごとにデータの流れを追跡する   # パイプラインの追跡   find . -name "*.log" | grep "ERROR" | awk '{print $1}' | sort | uniq -c      # ステップ1: logファイルの一覧を生成   # ステップ2: ERRORを含む行をフィルタリング   # ステップ3: 各行の最初のフィールドを抽出   # ステップ4: 結果をソート   # ステップ5: 重複を数えて集計制御構造の識別: for、if、whileなどの制御構造を識別して展開する   # 元のワンライナー   for file in *.txt; do grep "pattern" "$file" && echo "$file contains pattern"; done      # 展開した形   for file in *.txt   do       if grep "pattern" "$file"       then           echo "$file contains pattern"       fi   doneエコーデバッグ: 実行せずに echo でコマンドを表示する   # 危険そうなワンライナー   find . -name "*.tmp" -delete      # エコーデバッグバージョン   find . -name "*.tmp" -print部分実行: ワンライナーの一部だけを実行して結果を確認   # 完全なワンライナー   find . -name "*.log" | xargs grep "ERROR" | awk '{print $1,$2}' | sort > errors.txt      # 部分実行   find . -name "*.log" | head  # まず対象ファイルを確認   find . -name "*.log" | xargs grep "ERROR" | head  # エラー行を確認ワンライナーを複数行スクリプトに変換するAIが提案する複雑なワンライナーは、理解しやすい複数行スクリプトに変換すると安全性が向上します。# 元のワンライナーfind /var/log -name "*.log" -mtime -7 | xargs grep -l "ERROR" | xargs cat | grep -o "ERROR: [^ ]*" | sort | uniq -c | sort -nr | head -10# 複数行スクリプトに変換#!/bin/bash# 最近7日間のログファイルを見つけるlog_files=$(find /var/log -name "*.log" -mtime -7)# エラーを含むファイルだけを抽出error_files=$(grep -l "ERROR" $log_files)# エラーメッセージを抽出して集計cat $error_files |     grep -o "ERROR: [^ ]*" |     sort |     uniq -c |     sort -nr |     head -10コマンドを分解して理解する方法AIが提案する複雑なコマンドを理解するための効果的なアプローチ：パイプでセグメント化: パイプ（|）ごとにコマンドを分割して考える   # 元のコマンド   find . -name "*.log" | grep "ERROR" | awk '{print $1}' | sort | uniq -c      # 分解して考える   find . -name "*.log"     # ステップ1: logファイルを見つける   grep "ERROR"             # ステップ2: ERRORを含む行を抽出   awk '{print $1}'         # ステップ3: 各行の最初のフィールドを取得   sort                     # ステップ4: 結果をソート   uniq -c                  # ステップ5: 重複をカウント部分的な実行: コマンドの一部だけを実行して結果を確認   # 段階的に実行して結果を確認   find . -name "*.log" | head  # まず対象ファイルを確認   find . -name "*.log" | grep "ERROR" | head  # 次にエラー行を確認マニュアルの確認: 不明なオプションは man や --help で調査   man find   # findコマンドのマニュアルを表示   grep --help  # grepのヘルプを表示テスト環境での実行: 実際のシステムやデータに影響を与えないテスト環境で試す危険なコマンドの見分け方AIが提案するコマンドの中には、システムに重大な影響を与える可能性のあるものもあります。そのようなコマンドを見分けるポイント：注意すべきコマンドとオプションファイル削除系   rm -rf  # 再帰的強制削除（特に /* や / を含む場合は危険）   find ... -delete  # 見つかったファイルを削除ファイル書き換え系   > file  # ファイルの内容を上書き   sed -i  # ファイルを直接編集   dd      # ブロックレベルでのデータコピー（特にofオプションが危険）システム関連   shutdown, reboot  # システムの停止や再起動   chmod -R 777 /  # 危険な権限変更   mkfs  # ファイルシステムのフォーマットネットワーク関連   iptables -F  # ファイアウォールルールの削除   ssh-keygen -R  # 既知のホスト情報の削除安全に検証する方法実行前の確認コマンドの各部分が何をするのか理解する特に -f, -r, --force などの強制オプションに注意ワイルドカード (*, ?) の展開範囲を確認安全なオプションの利用   # 本当に削除する前に確認   rm -i file  # 対話的に確認      # 実際の変更前にシミュレーション   find . -name "*.tmp" -print  # -deleteの代わりに-printで確認   rsync --dry-run src/ dest/  # 実際のコピーなしでシミュレーションエコーやリダイレクト先の変更   # 危険なコマンドの代わりに同等の安全なコマンドで確認   echo "rm -rf /" # 実行せずに表示      # リダイレクト先を変更   command > /tmp/test.out  # 重要なファイルではなくテスト用ファイルに出力実行前のバックアップ   # 重要なファイルのバックアップ   cp -a important_file important_file.bak安全な実行環境の構築と活用これらのコマンドの違いが分からない場合は、システム環境を破壊してしまう可能性があるため、VM（仮想マシン）やDocker（コンテナ技術）、リモートホストなどの隔離環境を使用しましょう。生成AIが提案するシェルコマンドを実行する際には、潜在的なリスクを軽減するために隔離された安全な環境を利用することが推奨されます。特に未知のコマンドや複雑なワンライナー（1行で記述された複合コマンド）を試す場合は、これらの環境を活用することでメインシステムへの悪影響を最小限に抑えることができます。実用的なシェル芸とAIの活用例AIが提案するシェルコマンドを理解し、自分のニーズに合わせて調整することで、日常の作業を効率化できます。ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整# AIが提案した複雑なファイル名変更コマンドfind . -type f -name "log_*.txt" -exec bash -c 'mv "$1" "${1/log_/archive_}"' _ {} \;# より理解しやすく調整したバージョン# まず対象を確認find . -type f -name "log_*.txt" -print# 安全に実行for file in log_*.txt; do  echo "Renaming $file to ${file/log_/archive_}"  mv "$file" "${file/log_/archive_}"doneAIからの提案を検証して実行する例# AI提案: ディレクトリ内の全HTMLファイルでテキスト置換find . -type f -name "*.html" -exec sed -i 's/oldCompany/newCompany/g' {} \;# 検証方法# 1. まず対象ファイルを確認find . -type f -name "*.html" | wc -l  # 対象ファイル数の確認# 2. 一部のファイルで試すfind . -type f -name "*.html" | head -1 | xargs grep "oldCompany"  # 置換前の確認find . -type f -name "*.html" | head -1 | xargs sed 's/oldCompany/newCompany/g'  # 置換シミュレーション# 3. バックアップしてから実行find . -type f -name "*.html" -exec cp {} {}.bak \;  # バックアップ作成find . -type f -name "*.html" -exec sed -i 's/oldCompany/newCompany/g' {} \;  # 実行テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価# AI提案: 複雑なログ解析コマンドcat access.log | grep -o '"GET [^"]*"' | sed 's/"GET \(.*\)"/\1/g' | sort | uniq -c | sort -nr | head -10# 検証と理解# 1. 段階的に実行cat access.log | head -5  # まずログの形式を確認cat access.log | grep -o '"GET [^"]*"' | head -5  # GETリクエストの抽出確認cat access.log | grep -o '"GET [^"]*"' | sed 's/"GET \(.*\)"/\1/g' | head -5  # パスの抽出確認# 2. 最終結果の解釈# このコマンドは「アクセス数の多いパスTOP10」を表示しているAIと連携したデータ前処理の例# AIにデータを渡す前の前処理# 1. 個人情報をマスクcat data.csv | sed 's/\([0-9]\{3\}\)[0-9]\{4\}\([0-9]\{4\}\)/\1-XXXX-\2/g' > masked_data.csv# 2. 必要な列だけを抽出cat masked_data.csv | awk -F, '{print $1,$3,$5}' OFS=, > processed_data.csv# 3. AIに送るデータのサンプルを確認head -10 processed_data.csv環境変数とエイリアスの理解AIが提案するコマンドには、環境変数やエイリアスを利用したものもあります。これらを正しく理解することで、コマンドの意図や潜在的な問題を把握できます。環境変数の確認と活用# AIが提案する環境変数を使ったコマンドcd $HOME/projects && find . -name "*.py" | xargs grep "TODO"# 検証方法echo $HOME  # HOME変数の値を確認ls -la $HOME/projects  # プロジェクトディレクトリの存在確認AIが提案するエイリアスを安全に設定# AI提案: 便利なエイリアスalias ll='ls -la'alias findgrep='find . -type f -exec grep --color=auto -l "$1" {} \;'# 検証と調整# 関数として定義し直す（引数の扱いが明確）findgrep() {  find . -type f -exec grep --color=auto -l "$1" {} \;}# 使い方の確認type findgrep  # 関数定義を確認findgrep "search term"  # 実行テストジョブ制御と長時間実行コマンドAIはしばしば長時間実行する可能性のあるコマンドを提案します。このようなコマンドを実行する際のジョブ制御を理解しておくことが重要です。長時間実行コマンドの制御# AI提案: 大量ファイルの圧縮find /var/log -type f -name "*.log" | xargs gzip# より安全な実行方法# バックグラウンド実行してログを残すfind /var/log -type f -name "*.log" | xargs gzip > compression.log 2>&1 &echo $! > compression.pid  # プロセスIDを保存# 実行状況の確認ps -p $(cat compression.pid)tail -f compression.log実行中コマンドの管理# 実行中のコマンドの一時停止と再開Ctrl+Z  # 一時停止bg      # バックグラウンドで再開fg      # フォアグラウンドで再開# ジョブの一覧と管理jobs    # 現在のジョブ一覧kill %1  # ジョブ番号1を終了# ログアウト後も実行を継続nohup command &  # ログアウト後も実行継続screen           # 仮想端末での実行tmux             # ターミナルマルチプレクサでの実行ワンライナーの安全性評価と活用法生成AIが提案するワンライナーを安全に活用するためのポイントです。ワンライナーの安全性評価チェックリストワンライナーを実行する前に以下の点をチェックすると安全性が向上します。また、これらが通っているからといって必ず安全というわけではない。破壊的コマンドの有無rm, mv, dd, > (上書きリダイレクト)などのデータを破壊する可能性のあるコマンドが含まれているか例: rm -rf, find ... -delete, sed -i などは特に注意システム全体への影響/, /etc, /bin などの重要なシステムディレクトリに対する操作があるかchmod -R, chown -R などの再帰的な権限変更が含まれているかリソース消費find / など広範囲を検索する処理が含まれているか深い再帰処理や大量のファイル処理による負荷の可能性はあるか特権要求sudo や su などの特権昇格が含まれているか実行に特別な権限が必要なコマンドが含まれているかバックドア・不審なコードcurl | bash のようなインターネットからのスクリプト実行が含まれていないか暗号化されたコードや理解できない難読化された部分が含まれていないかワンライナーを安全に変換する方法# 危険なワンライナーfind / -name "*.bak" -delete# より安全な代替案# 1. プレビューモード: 削除せずに表示のみfind / -name "*.bak" -print# 2. 対話モード: 一つずつ確認find / -name "*.bak" -exec rm -i {} \;# 3. 特定ディレクトリに限定find ~/projects -name "*.bak" -delete# 4. スクリプトに変換して段階的に実行#!/bin/bashecho "次のファイルを削除します:"find / -name "*.bak" -printread -p "続行しますか？ (y/n) " answerif [ "$answer" = "y" ]; then    find / -name "*.bak" -deletefiAIが提案するワンライナーを効果的に活用するコツ理解してから実行: 必ず各部分の意味を理解してから実行する段階的な検証: まず無害なオプションで実行し、結果を確認してから本来の処理を実行コメント付きスクリプトへの変換: 複雑なワンライナーはコメント付きの複数行スクリプトに変換変数の活用: ハードコードされたパスや値を変数に置き換えて柔軟性を高める環境に合わせた調整: 自分の環境に合わせてコマンドを調整するワンライナー活用のベストプラクティススクリプト化して再利用: 有用なワンライナーはスクリプトファイルに保存して再利用エイリアスとして登録: 頻繁に使うワンライナーはエイリアスとして登録   alias finderrors='find . -name "*.log" | xargs grep -l "ERROR"'関数化: 引数を受け取れるようにしてカスタマイズ性を高める   find_errors() {       find . -name "*.$1" | xargs grep -l "$2"   }   # 使用例: find_errors log ERRORバージョン管理: 重要なワンライナーやスクリプトはGitなどで管理ドキュメント化: 複雑なワンライナーは使い方や前提条件をドキュメント化まとめ生成AIがシェルコマンドを提案する時代において、以下のポイントを押さえておくことが重要です。理解してから実行: AIが提案するコマンドを盲目的に実行せず、各部分の意味を理解してから実行する段階的な検証: 複雑なコマンドは部分的に実行して、期待通りの動作をするか確認する危険なコマンドの見極め: システムに重大な影響を与える可能性のあるコマンドを識別できるようにする適切な調整: AIの提案を自分の環境や要件に合わせて調整する能力を身につけるバックアップの習慣: 重要なデータは常にバックアップしてから操作するワンライナーの分解理解: 複雑なワンライナーは各部分に分解して理解するスクリプト化の検討: 複雑なコマンドはスクリプトに変換して読みやすく、再利用可能にするこれらの知識とアプローチを身につけることで、生成AIが提案するシェルコマンドを安全かつ効果的に活用し、作業効率を大幅に向上させることができます。AI時代のシェルコマンド活用は、理解に基づいた適切な判断が鍵となります。生成AIとシェルの組み合わせは非常に強力なツールですが、その力を適切に扱うには基本的な理解が欠かせません。この記事が、皆さんがAIと安全に協働するための一助となれば幸いです。入門 モダンLinux ―オンプレミスからクラウドまで、幅広い知識を会得する作者:Michael Hausenblasオーム社Amazonより詳しく知りたい人はLinuxシステムプログラミング作者:Robert Love,ロバート ラブオライリージャパンAmazon狂人はこちらでお願いします。Linuxプログラミングインタフェース作者:Michael KerriskオライリージャパンAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【スリーシェイク】入社エントリ🥳 🎉]]></title>
            <link>https://zenn.dev/meziron/articles/9d727354b70ecd</link>
            <guid>https://zenn.dev/meziron/articles/9d727354b70ecd</guid>
            <pubDate>Thu, 03 Apr 2025 14:01:57 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！🙇 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GTC2025 参加記録　~Keynote~]]></title>
            <link>https://sreake.com/blog/gtc2025-keynote/</link>
            <guid>https://sreake.com/blog/gtc2025-keynote/</guid>
            <pubDate>Mon, 31 Mar 2025 00:26:08 GMT</pubDate>
            <content:encoded><![CDATA[3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Keyball 61にhome row modsを導入した]]></title>
            <link>https://blog.atusy.net/2025/03/31/home-row-mods/</link>
            <guid>https://blog.atusy.net/2025/03/31/home-row-mods/</guid>
            <pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[長らくキー配列についてはKeyball61のオレオレマッピングを語るの通りでしたが、加えてhome row modsを導入しました。home row modsは、ホームポジションのasdf（左）とjkl;（右）を押しっぱなしたときに（hold）、CtrlやShiftなどの修飾キーとして機能させる方法論です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[3年目までに身につけたい技術ブログの書き方]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</guid>
            <pubDate>Sun, 30 Mar 2025 18:44:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあなたは日々、何かを見ている。そう、コードを。エラーを。ドキュメントを。解決策を。そして、それは誰も見ていないものかもしれない。あるいは、多くの人が同じものを見ているのに、誰も記録に残していないのかもしれない。「自分なんてまだ1年目、2年目。経験が浅いから書くことなんてない」そんな思いを抱いていませんか？ しかし、その思い込みは真実ではありません。むしろ、経験の浅さこそが、あなたにしか書けない貴重な視点を生み出します。初めて学ぶ時の困惑、理解するまでの試行錯誤、そして「あ、わかった！」という喜び—これらの生々しい体験は、あなたがまさに今感じているからこそ書ける宝物なのです。「専門家でもないのにブログなんて書けない」「自分の書いたものなんて誰も読まないだろう」という思いも、単なる幻想です。誰もが最初から専門家ではなかった。今あなたが参考にしている記事を書いた人も、最初は不安を抱えながらキーボードに向かったはずです。このブログを書いている私もです。ネット上には膨大な情報があふれていますが、だからこそ、あなたの視点、あなたの言葉、あなたの経験を通して伝えられる情報には価値があります。なぜなら、あなたの記事を必要としている人は、まさにあなたと同じ疑問や課題を持っている人だからです。技術ブログは、完璧な知識や完成された思考を示すためのものではありません。それは思考の過程を記録するものです。完璧を目指すあまり書けなくなるよりも、不完全でも自分の観察と気づきを残していくことに価値があります。自分が躓いたその瞬間こそ、同じ場所で立ち止まっている誰かにとっての地図になる。あなたが苦労して辿り着いた解決策は、未来の誰かの貴重な時間を節約するだけでなく、新たな発見への扉を開くきっかけになるかもしれません。この記事では、技術ブログの種類とその書き方、特に新人エンジニアが取り組みやすいパターンについて解説します。ブログを書く意義、どのようなブログを書けばよいのか、どう書き始めればよいのか、批判されたときにはどうすればよいのかを知ることで、あなたの歩んできた道は他のエンジニアにとって価値ある情報源となり、同時にあなた自身の成長を加速させる強力なツールとなるでしょう。「でも、文章を書くのが苦手で…」「何を書けばいいか分からなくて…」と思っているあなたも、この記事を読み終わる頃には、最初の記事を書くためのアイデアとやる気を手に入れているはずです。さあ、あなたの知識や経験を世界と共有する旅を、一緒に始めましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめにブログ執筆がもたらす価値思考を整理する鏡知識の共有経済への参加思考の足跡としてのブログ技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記2. バグハント記事3. 環境構築ガイド4. 学んだ教訓記事5. プログラミング言語の乗り換え記録6. システム開発の舞台裏7. 技術トレンドの考察8. 技術の性能比較と検証書き始めるための実践ガイド始めやすいブログパターンの選択日常からネタを発掘する技術読者を惹きつける記事構成読みやすさを高める実践テクニック心地よい技術コミュニケーションのために読み手の感情を大切にする好きなものを中心に語る個人の経験として共有する主観的な表現を心がけるポジティブな内容を中心に批判を柔らかく伝える工夫背景情報を丁寧に説明するもし反発を受けたときの心構え人気記事には批判も付きもの反応せずに見守る勇気を持つコメントの背景を想像してみる誤解には丁寧な補足を時間の流れを味方にするブログ公開の場の選択技術特化型プラットフォーム汎用ブログプラットフォーム自前のブログプラットフォーム選びのアドバイス継続のための現実的なアプローチ小さなハードルから始める自分のための記録として書く「十分に良い」の基準を持つ終わりに本気(マジ)の話ブログ執筆がもたらす価値技術ブログを書く行為には、表面的には見えない多くの価値があります。思考を整理する鏡「説明できることは理解している証拠だ」という言葉があります。コードを書くだけではわからなかった理解の穴が、他者に説明しようとする瞬間に見えてきます。ブログ執筆は自分の思考をクリアにし、知識の定着を促す強力なツールです。ラバーダック・デバッギングがコードの理解を深めるように、ブログはあなたの思考を整理します。知識の共有経済への参加オープンソースのコードを共有するように、あなたの解決策や洞察も共有価値があります。あなたが30分かけて解決した問題は、記事を通じて何百人もの時間を節約するかもしれません。それは単なる善意ではなく、テクノロジー業界の発展に寄与する行為です。思考の足跡としてのブログ定期的に書かれたブログは、あなたの専門性と成長の記録となります。それは履歴書やポートフォリオ以上に、あなたの思考プロセスと問題解決能力を示す生きた証拠になります。自然と「個人ブランド」が形成され、思わぬ機会につながることもあるでしょう。技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記新人に特におすすめ新しい技術やツールを学んだ過程を記録するブログです。チュートリアルの穴を埋めたり、つまずいたポイントの解決策を共有したりします。書き方のポイント:学習の目的と背景を明確につまずいたポイントと解決法を詳細に公式ドキュメントには書かれていない気づきを強調スクリーンショットやコードスニペットで手順を明確に構成例:学習の動機（なぜこの技術を学ぼうと思ったか）前提知識と環境学習プロセス（つまずいたポイントを含む）得られた気づきと学び次のステップ2. バグハント記事特定のバグや問題を発見し、追跡し、最終的に修正するまでの旅を共有するブログです。書き方のポイント:問題の症状と影響を具体的に調査プロセスを時系列で詳細に（ミステリー小説のように、叙述トリックを使ってもよいですがほどほどに⋯）フレームグラフ、ログ、診断データなどの「証拠」を提示どのような思考プロセスで原因に辿り着いたかを解説最終的な解決策と学んだ教訓構成例:問題の概要（何が起きたか）調査の開始（最初の仮説）探索と証拠収集誤った道と行き止まり（失敗も正直に）原因の特定と理解解決策と検証学んだ教訓と予防策3. 環境構築ガイド開発環境や特定のツールのセットアップ方法を解説するブログです。書き方のポイント:対象読者（初心者か上級者か）を明確に前提条件と必要なツールを明示手順をステップバイステップで説明トラブルシューティングの情報を含める何のためにこの設定をするのかの理由も説明構成例:目的と概要前提条件と必要なものインストール手順（ステップバイステップ）設定と最適化動作確認の方法よくあるトラブルとその解決法4. 学んだ教訓記事プロジェクトや技術的課題から得た教訓や気づきを共有するブログです。書き方のポイント:率直かつ謙虚なトーンで具体的な状況と文脈を提供失敗や間違った判断からの学びを強調他のエンジニアに適用できる一般的な教訓を抽出時系列に沿った「日記的」な構成も有効構成例:状況と背景直面した課題取った行動と判断結果と振り返り学んだ教訓次回への活かし方5. プログラミング言語の乗り換え記録既存のプロジェクトを新しいプログラミング言語やフレームワークで作り直した経験を共有するブログです。書き方のポイント:言語やフレームワークを変更した理由を分かりやすく説明古い言語と新しい言語の違いと比較移行作業で苦労した点とその解決方法処理速度や保守のしやすさの比較結果言語の乗り換えから学んだこと構成例:現状と移行の動機技術選定と比較検討移行戦略と計画実装の詳細と課題成果と比較（ビフォー・アフター）学んだ教訓と今後の展望6. システム開発の舞台裏システムや機能をどのように考え、設計し、作り上げたかを詳しく説明するブログです。書き方のポイント:システムの目的と必要な機能を明確に設計で迷った点や判断した理由を説明全体の構造を図や図解でわかりやすく重要なコードの部分とその役割の解説ぶつかった壁とその乗り越え方今後の改善点や拡張できる部分構成例:プロジェクトの背景と目標要件と制約条件設計の選択肢と検討プロセス選んだアーキテクチャとその理由実装の重要ポイント課題と解決策結果と評価7. 技術トレンドの考察IT業界の流行りや新しい技術の動きについて、自分なりの意見や分析を述べるブログです。書き方のポイント:堅固な論拠と証拠で意見を裏付ける単なる批判ではなく、建設的な視点を提供自分の経験に基づいた具体例を含める複数の視点を考慮し、バランスの取れた議論を展開明確な結論と、読者が検討すべきポイントを提示構成例:トレンドの概要と背景現在の状況分析メリットとデメリット実務への影響と適用性自分の見解と予測実践的なアドバイス8. 技術の性能比較と検証異なる技術や方法の速度や効率を実際に測って比較し、その結果を共有するブログです。書き方のポイント:テスト方法と環境を詳細に記述公平で再現可能なベンチマーク手法を使用データを明確に視覚化（グラフ・表）結果の解釈と実用的な意味を説明限界と注意点も正直に伝える読者が検証できるようコードや手順を共有構成例:テストの目的と背景検証環境とセットアップテスト方法と条件結果の提示と分析発見と考察実用的な示唆と推奨事項書き始めるための実践ガイド始めやすいブログパターンの選択新人エンジニアが最初に挑戦しやすいのは、自分の直接体験に基づいた記事です。特に以下のパターンは、書きやすく読者にも価値を提供しやすい傾向があります。学習ログ＆チュートリアル体験記 - 公式ドキュメントには書かれていない「実際にやってみたらどうだったか」の記録は、後続の学習者にとって貴重な情報源になります。また、英語のチュートリアルを日本語でやってみるだけでも大きな価値があります。環境構築ガイド - 一度苦労して設定した開発環境の手順は、記録しておくだけで大きな価値があります。読者や半年後の自分も、同じ苦労をせずに済むでしょう。バグハント記録 - 解決に時間がかかった問題は、その過程を含めて記録する価値があります。デバッグの思考プロセスこそが、技術的な洞察を含んでいます。学びの教訓 - 「〜だと思っていたけど、実際は違った」という気づきは、技術記事として非常に価値があります。誤解やミスコンセプションを正す内容は、多くの人の時間を節約します。日常からネタを発掘する技術記事のアイデアは日々の業務や学習の中に隠れています。以下の視点で日常を観察してみましょう。学習過程での「なぜ？」、理解するのに時間がかかった概念や、直感に反する仕様は、記事になりやすいトピックです。繰り返し説明していること、チーム内で何度も同じ説明をしている内容は、記事化する価値が高いでしょう。検索しても満足な答えが見つからなかった問題、そのような問題を解決できたなら、あなたと同じ検索をする誰かのために記録を残しましょう。「あれ？」と思った瞬間、予想通りに動かなかったコード、意外な挙動を示したツール、これらの「あれ？」の瞬間は、貴重な記事の種です。このような日常の発見からブログネタを見つける考え方は、ジェームス・W・ヤングの名著『アイデアのつくり方』に私の考え方は近いです。ヤングによれば、アイデアとは既存の要素の新しい組み合わせであり、その才能は事物の関連性を見つけ出す力に依存しています。ヤングが提唱する5段階のアイデア創出プロセスは、技術ブログ執筆にも応用できます。資料を収集する - 特定のテーマに関する専門知識と、幅広い一般知識の両方を集める資料を噛み砕く - 集めた情報を様々な角度から検討し、関係性を探る問題を放棄する - 一度意識的な思考から離れ、無意識に働かせるアイデアが訪れる - 何気ない日常の瞬間（シャワー中やトイレなど）に閃きが生まれるアイデアを現実に連れ出す - 閃いたアイデアを忍耐強く形にするあなたの「あれ？」という瞬間は、ヤングの創造プロセスの一部として考えることができます。まず資料収集の段階で日々の開発や、読書、学習から知識を蓄え（第1段階）、それらの情報を頭の中で検討し関連付けようとし（第2段階）、一度問題から離れて無意識に働かせ（第3段階）、そして「あれ？」という気づきや閃きが訪れるのです（第4段階）。この瞬間を逃さず記録し、丁寧に育てて記事として形にしていく作業が最終段階（第5段階）となります。日々の疑問や発見を意識的に記録する習慣をつけることで、ヤングのプロセスを体現し、貴重なブログの種を蓄積できるでしょう。「ブログが書けない」と悩んでいるほとんどの人は、この5段階のプロセスのどこかが欠如していることがほとんどです。そして、どの段階が欠如しているかによって、対応方法が大きく変わります。資料収集が不足している人には、まずは情報のインプットを増やすことが重要です。技術書を読む、オンラインコースを受講する、技術カンファレンスの動画を見るなど、様々な方法で知識の幅を広げましょう。また、特定の技術だけでなく、隣接分野や全く異なる分野の知識も取り入れることで、独自の組み合わせが生まれやすくなります。情報の噛み砕きが不足している人には、学んだことをノートにまとめる、同僚に説明する、図解してみるなどの方法がおすすめです。具体化したり抽象化したりするのもおすすめです。情報を受動的に受け取るだけでなく、自分の言葉で咀嚼し直すことで、新たな気づきが生まれやすくなります。リラックスの時間が不足している人には、意識的に「何も考えない時間」を作ることが大切です。常に問題解決モードでは、無意識の働きが活かせません。散歩する、お風呂に浸かる、瞑想するなど、頭を空っぽにできる時間を日常に取り入れましょう。閃きを見逃している人には、スマートフォンのメモアプリやノートを常に持ち歩き、思いついたことをすぐに記録する習慣をつけることをおすすめします。閃きは突然訪れ、すぐに消えてしまうものです。「あとで覚えておこう」と思っても、ほとんどの場合は忘れてしまいます。書ききれない人には、「まずは15分だけ書く」という小さなハードルから始めることをおすすめします。完璧な記事を目指すのではなく、とにかく書き始めること。編集や推敲は後からでも可能ですが、書かれていない文章は編集のしようがありません。また、締め切りを設定したり、書き始める時間と場所を決めておくなど、環境を整えることも効果的です。あなたがブログを書けない理由がどの段階にあるのかを特定することで、より効果的な対策を講じることができるでしょう。アイデアのつくり方作者:ジェームス W.ヤングCCCメディアハウスAmazon読者を惹きつける記事構成技術ブログも、読者が最後まで読みたくなる構成が重要です。以下のような流れを意識すると、読みやすい記事になります。問題提起 - なぜこの記事を書いたのか、読者にとってどんな価値があるのかを明確にします。最初の段落で「この記事を読むことで解決できる問題」を具体的に示すことで、読者の興味を引きつけましょう。「〜に悩んでいませんか？」「〜をもっと効率的にしたいと思いませんか？」といった形で読者の課題に共感を示すと効果的です。ただし、単なるクリックベイト的な見出しや過度な約束は避け、記事の内容と一致した誠実な問題提起を心がけましょう。コンテキスト - あなたの環境や前提条件を説明し、読者が自分の状況と比較できるようにします。「私がこの問題に取り組んだ時の状況はこうでした」と具体的に共有することで、読者は自分のケースとの類似点や相違点を理解できます。使用した技術のバージョン、ハードウェア環境、チームの規模、プロジェクトの背景など、関連する情報を提供しましょう。これにより、読者は記事の内容が自分にとって適用可能かどうかを判断できます。コンテキストが明確であればあるほど、読者は安心して読み進められます。探求の旅 - 単なる解決策ではなく、そこに至るまでの思考プロセスを共有することで、読者は深い理解を得られます。最初に考えたアプローチ、試した方法、直面した課題、そしてなぜ最終的な解決策にたどり着いたのかを時系列で説明しましょう。失敗したアプローチも含めて正直に共有することで、記事の信頼性が高まり、読者も同じ失敗を避けられます。「最初はAという方法を試みましたが、Bという問題に直面したため、Cというアプローチに切り替えました」といった形で、あなたの試行錯誤のストーリーを語ることで、記事に人間味と深みが加わります。発見と学び - 技術的な発見だけでなく、アプローチ方法についての洞察も含めましょう。「この経験から学んだ最も重要なことは〜です」と明確に示すことで、読者は記事の本質的な価値を理解できます。コードやシステムの改善点だけでなく、問題解決プロセス、チーム協力、技術選定の基準など、より広い文脈での学びを共有すると、記事の応用範囲が広がります。特に、「意外だったのは〜」「常識と違ったのは〜」といった予想外の発見は強調する価値があります。こうした「目から鱗」の瞬間は、読者にとって最も記憶に残る部分となるでしょう。次のステップ - 読者が更に探求できるように、参考資料や発展的な内容へのリンクを提供します。「もっと詳しく知りたい方はこちらの資料がおすすめです」「次のステップとして〜を検討するとよいでしょう」といった形で、読者の学習旅行の次の目的地を示唆しましょう。また、未解決の課題や将来の展望についても正直に触れることで、読者との対話を促すことができます。「現在はまだ〜という課題が残っていますが、今後は〜のアプローチを試してみる予定です」といった形で、完璧な解決策だけでなく、進行中の探究であることを示すと、より現実的で共感を得られる記事になります。読みやすさを高める実践テクニック技術的な内容を伝える際、読みやすさは極めて重要です。以下のテクニックを活用して、読者が最後まで読み進められる記事を目指しましょう。最初の3行で読者を掴む - 記事の冒頭3行は、読者が「続きを読むか」を決める重要な部分です。問題提起や具体的な価値を示し、興味を引く導入を心がけましょう。「この記事を読むと〜ができるようになります」「あなたも経験したことがあるかもしれませんが、〜という問題は実は〜で解決できます」といった書き出しが効果的です。ただし、注意点として、技術ブログでは大言壮語や過度な主張（「これが唯一の正しい方法だ」「これさえ知れば全てが解決する」など）は避けるべきです。断定的な表現は炎上リスクを高め、読者の信頼を損なう恐れがあります。「私の経験では」「この特定の状況では」といった限定的な表現を使い、バランスを保ちましょう。見出しを上手に使う - 大見出しと小見出しで内容を整理し、ざっと見ただけでも内容がつかめる構造にします。見出しは「目次」としての役割を持ち、読者が求める情報に素早くアクセスするための道標となります。見出しには具体的な内容や得られるメリットを含めると、さらに効果的です。例えば「実装方法」よりも「3ステップで実装できるシンプルな方法」の方が読者の興味を引きます。また、見出しの階層構造は3段階程度に抑え、整理された印象を与えましょう。長い文章は小分けに - 長い文章が続くと読者は疲れます。適度に区切って、読者が「ここまで読めた」と小さな達成感を得られるようにします。段落は1つの考えにつき1つにし、3〜5行程度を目安にするとよいでしょう。また、読みやすさを高めるために、箇条書きや番号付きリストを活用して情報を整理しましょう。さらに、重要なポイントには太字や斜体などの強調を適切に使い、視覚的なメリハリをつけることで、スキャンしやすくなります。ただし、強調の使いすぎは逆効果なので、本当に重要な部分だけに留めるのがコツです。コードと説明文のバランス - 長すぎるプログラムコードは避け、重要な部分だけを取り出して、それに説明を加えましょう。コードブロックの前には「何をするコードなのか」、後には「なぜそのように実装したのか」「どのような効果があるのか」を説明すると理解が深まります。また、複雑なコードは徐々に構築していく形で示すと良いでしょう。初めに基本形を示し、段階的に機能を追加していくアプローチは、特に初心者にとって理解しやすい方法です。コメントを適切に挿入することも効果的ですが、コード自体が説明的であることを心がけましょう。具体例と全体像を交互に - 具体的なコード例と、そこから学べる一般的な教訓を交互に示すことで、理解が深まります。「木を見て森も見る」アプローチで、読者は個別の実装詳細と、それがどのように大きな概念に適合するかを同時に理解できます。例えば、特定のパターンの実装例を示した後、「このパターンが特に有効なのは〜のような状況です」と一般化すると、読者は自分の状況への応用がしやすくなります。逆に、原則や概念を先に説明してから具体例で補強する方法も効果的です。両方のアプローチを記事内で使い分けると、多様な学習スタイルの読者に対応できます。視覚的要素を活用する - 複雑な概念や関係性は、文章だけでなく図やダイアグラム、スクリーンショットで説明すると理解が格段に向上します。特に、システムアーキテクチャやデータフロー、アルゴリズムの流れなどは視覚化が効果的です。図は装飾ではなく情報を伝える手段として使い、適切なキャプションを付けることで文脈を明確にしましょう。また、長い記事では適度に図を挿入することで、読者に視覚的な休息も提供できます。図の作成には専門的なツールは必ずしも必要なく、シンプルな図であれば手書きスケッチをスキャンしたものでも十分に価値があります。読者の知識レベルを想定する - 対象とする読者層の知識レベルを想定し、それに合わせた説明の詳しさを調整しましょう。初心者向けの記事では基本概念から丁寧に説明し、上級者向けには深い技術的洞察や最適化のポイントに焦点を当てます。どちらの場合も、前提知識を記事の冒頭で明確にしておくと、読者は自分に適した内容かどうかを判断できます。「この記事はXYZの基本を理解している方を対象としています」といった一文を入れるだけでも効果的です。また、専門用語を使う場合は、初出時に簡単な説明を加えるか、リンクで参照先を示すと親切です。余韻を残す結びで読者の思考を広げる - 優れた技術ブログは、単に情報を伝えるだけでなく、読後に読者の思考を広げるものです。結びのパートでは、説明した技術の将来性や発展の可能性、異なる文脈での応用例などに軽く触れておくと、読者は記事を閉じた後も考え続けるきっかけとなります。「この技術は〜の領域でも応用できるかもしれません」「今回紹介した手法をさらに発展させると、どのような可能性が開けるでしょうか」といった問いかけは、読者の創造性を刺激し、自分なりの解釈や発展を考える余韻をもたらします。また、「私自身はこの技術と出会って、〜という視点が変わりました」のような個人的な洞察や、技術の社会的意義に触れることで、読者に新たな気づきや内省の機会を提供できます。心地よい技術コミュニケーションのために技術ブログを書くとき、単に知識を共有するだけでなく、読み手がどう感じるかに気を配ることも大切です。思慮深いコミュニケーションは、あなたのメッセージをより効果的に伝え、建設的な対話を生み出します。以下の考え方を意識することで、知識共有の質を高め、不要な論争を避けることができるでしょう。読み手の感情を大切にする書いた内容が誰かを傷つけていないか考えてみましょう。「この書き方だと、誰かが自分を批判されていると感じるかも」と想像することが大切です。例えば、ある技術について「この方法は時代遅れだ」と書くより、「私の用途ではこの新しい方法がうまく機能しました」と表現する方が、読み手の心を開いたままにします。技術選択は多くの場合、状況やニーズに依存するものであり、一概に優劣をつけられないことを認識しましょう。好きなものを中心に語るあなたが好きな技術や方法について熱く語りましょう。何かを批判するよりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。「Aは問題だらけだがBは素晴らしい」ではなく、「Bのここが素晴らしい」と伝えるだけで十分です。英語圏でよく使われる「not for me」（これは私には合わない）という表現は、技術ブログでも有効です。これは「悪い」というわけではなく、単に「私の状況や好みには合わない」という意味を含んでいるからです。個人の経験として共有する「すべてのエンジニアは〜すべきだ」「この業界では〜が常識だ」といった広い主語での断言は避けましょう。代わりに「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。それでも強引に批判してくる人はいます。そういう人はそもそもめちゃくちゃに批判したくてその構成が目の前に存在しているからめちゃくちゃに言ってくるのですが、日本語をちゃんと読めない人を相手にする必要はありません。あなたの経験を共有する権利は誰にも奪われないのです。主観的な表現を心がける「これは正しい方法だ」「あれは間違っている」という価値判断ではなく、「私はこの方法が好きです」「私の場合はこちらの方法が合っていました」という表現にすることで、異なる意見の人も受け入れやすくなります。私たちはみな異なる状況で働いており、一つの正解があるわけではないことを認識しましょう。特に技術の世界では、同じ問題に対しても多様なアプローチが存在することを尊重することが重要です。ポジティブな内容を中心に問題点や不満よりも、解決策や学びを中心に書きましょう。ネガティブな内容は同様にネガティブな反応を呼びがちです。「〜が使いにくい」より「こうすると〜がもっと使いやすくなりました」という表現の方が、建設的な対話につながります。あなたが困難を乗り越えた経験は、その過程で学んだことと共に共有することで、より価値のある情報になります。批判を柔らかく伝える工夫どうしても批判的な内容を書く必要があるときは、批判の対象をぼかしたり、自分の失敗談を交えたりすることで、攻撃的に見えるのを避けられます。「私も以前は〜と思っていましたが、実際にやってみると〜だとわかりました」といった表現なら、相手の反感を買いにくくなります。また、批判する際も建設的な代替案を提示することで、単なる不満ではなく有益なフィードバックとして受け取られやすくなります。背景情報を丁寧に説明する「これはこういう状況での話です」「私はこういう前提で考えています」と背景を明確にすることで、誤解を防げます。普通に人と喋っている時は省略するかもしれない文脈の紹介も技術ブログを書く時には必要です。誤読する余地を可能な限り減らします。特に技術的な主張をするときは、あなたの環境や条件を明示することで、「それは特定の状況下での話だね」と理解してもらいやすくなります。使用しているハードウェア、ソフトウェアのバージョン、チームの規模、プロジェクトの性質など、具体的な情報を提供することで、読者はあなたの経験を適切に文脈化できます。もし反発を受けたときの心構えどれだけ配慮して書いても、時には予想外の反応を受けることがあります。インターネット上での議論は時に感情的になりがちです。正直なところ、批判されたときの最初の感情は「なんでこんなこと言われなきゃいけないんだ」という怒りや落胆でしょう。そんな感情は自然なものですし、一時的に落ち込んだり、イラっとしたりするのも当然です。でも、そんなときに役立つ考え方をいくつか紹介します。人気記事には批判も付きもの多くの人に読まれるブログには、様々な価値観を持つ人が訪れます。あなたの意図とは関係なく、一定数の批判的なコメントが寄せられるのは自然なことです。人気の証と考えて、あまり気にしすぎないようにしましょう。実際、最も影響力のある技術記事でさえ、必ず反対意見や批判があります。これは多様な視点が存在することの健全な証でもあります。反応せずに見守る勇気を持つ批判的なコメントを見ると、すぐに反論したくなるものです。正直に言えば、「このバカ！ちゃんと記事を読め！」と思うこともあるでしょう。そんな感情を持つのは自然なことです。しかし、インターネット上での議論は感情的になりやすく、さらなる誤解を生むことも。多くの場合、反応しないことが最も賢明な選択です。キーボードから離れて深呼吸し、「本当に返信する価値があるか」を冷静に考えてみましょう。時間が経てば自然と収まることが多いものです。たまには筆を折って、「今日はもうネットを見ない日」を作るのも立派な対処法です。コメントの背景を想像してみる批判的なコメントを残す人の他の発言を見てみると、多くの場合、その人自身の傾向が見えてきます。常に批判的なコメントを残している人もいれば、特定のトピックに強い感情を持っている人もいます。「これはその人の反応パターンなのだ」と理解すれば、個人的な攻撃と受け取らずに済みます。時には「この人、今日はどうしたんだろう？仕事で嫌なことでもあったのかな？」と想像してみるのも手です。多くの批判的コメントは、あなたの記事そのものよりも、コメントした人のその日の気分や状況から生まれていることもあるのです。批判的なコメントをパブリックな場に書く人のほとんどは想像力が欠如しているのでその言葉で他人が傷つくということをほとんど何も考えていないです。実際に会うと優しかったりもします。でも、親切にスルーすることが、時には最大の優しさかもしれません。誤解には丁寧な補足を明らかな誤解に基づいた批判が多い場合は、記事に追記や修正を加えるのが効果的です。「追記：いくつかコメントをいただき、この点が誤解を招いているようなので補足します」といった形で、丁寧に説明すると良いでしょう。個別のコメントに反論するよりも、記事自体を改善する方が建設的です。これは読者全体にとっても価値があり、あなた自身の成長にもつながります。時間の流れを味方にするインターネット上の話題は移り変わりが早いものです。今日の論争も、明日には忘れられていることがほとんどです。一時的な批判に過度に反応するよりも、次の記事作成に前向きに取り組む方が、長期的には実りある選択となるでしょう。実際に「nwiizoさんの記事は役に立ちました」と声をかけられることはあっても、「お前の記事はクソだぞ」と直接言ってくる人は珍しいものです(私もそれぐらい強烈な論を発したいものです)。批判は匿名の場で、称賛は直接あなたに届くという不思議な法則があります。そして、真っ当な批判からは学び、感情的な批判は「私はそれだけの反応を引き出せるだけの影響力を持っているんだ」と前向きに捉える余裕を持ちましょう。ブログ公開の場の選択ブログを書く場所の選択は、思っているより重要な決断です。それぞれの場には一長一短があり、あなたの目的によって最適な選択肢は異なります。技術特化型プラットフォーム技術者向けのプラットフォームは、すでに技術に興味のある読者が集まっているという利点があります。初めから技術的な話題を求めている読者にリーチしやすく、専門的な議論が生まれやすい環境です。一方で、プラットフォームのルールやコミュニティの雰囲気に合わせる必要があり、自由度はやや制限されます。また、特定の技術コミュニティでは賛否両論が起きやすいトピックもあります。汎用ブログプラットフォームより幅広い読者層にアクセスできる汎用プラットフォームは、技術と非技術の境界領域の話題に適しています。テクニカルな内容を非エンジニアに伝えたい場合や、キャリアや働き方など、技術に付随する話題を扱いたい場合に向いています。ただし、深く技術的な内容は響く読者が少なく、反応が薄くなる可能性もあります。自前のブログ自分のドメインで運用するブログは、完全な自由度とブランディングの利点があります。長期的に見れば最も資産価値が高く、あなたのキャリアと共に育てていけるものになります。しかし、読者を集めるための工夫や継続的なメンテナンスが必要で、特に始めたばかりの頃は「誰も読んでいない」という状況に直面することも。SEO対策やSNSでの拡散など、追加の努力が求められます。プラットフォーム選びのアドバイス最初は低いハードルで始められる技術特化型プラットフォームでスタートし、書く習慣が身についてきたら自前のブログも並行して運用するというアプローチが現実的です。どのプラットフォームを選ぶにしても、コンテンツの所有権やエクスポート機能について確認しておくことをお勧めします。いつか別の場所に移行したいと思ったとき、あなたの資産を持ち出せるかどうかは重要な要素です。継続のための現実的なアプローチ技術ブログを一度書くことは難しくない。難しいのは書き続けることだ。以下は実践的な継続のコツだ。小さなハードルから始めるブログ執筆を習慣化するには、負荷を最小限に抑えることが重要です。月1回、あるいは四半期に1回といった現実的な頻度設定から始めましょう。15分でも執筆時間を確保できれば、少しずつ文章は成長していきます。無理な目標設定はモチベーションを消耗させるだけです。自分のための記録として書く「誰も読まないかもしれない」という恐れは、「自分のための記録」という視点で克服できます。将来の自分が参照するための記録として書けば、読者がゼロでも価値があります。実際、多くの技術ブログは、書き手自身が後日参照することで最大の価値を発揮します。「十分に良い」の基準を持つ完璧主義はブログ執筆の最大の敵です。「もっと調査が必要」「もっと洗練された文章にしたい」という思いは尽きませんが、公開されない記事に価値はありません。80%の完成度で公開する勇気を持ちましょう。改善はいつでもできます。このブログも80％ぐらいの完成度で公開してます(本当に)。終わりに技術の世界では、私たちは常に何かの「初心者」であり続けます。むしろ「初心者」であるべきです。新しい言語、新しいフレームワーク、新しいパラダイム—学びに終わりはありません。ベテランエンジニアでさえ、新技術の前では「初心者」に戻るのです。だからこそ、どの経験レベルの視点も価値があります。思い出してみてください。あなたが最初にプログラミングを学んだ時の興奮を。新しいフレームワークに触れた時の発見の喜びを。バグを解決した時の達成感を。これらはすべて、記録する価値のある体験です。そして、どの瞬間においても、あなたの「今」の視点は誰かにとって貴重な道標になります。完璧なブログではなく、あなたの観察と経験を率直に記録したブログこそが、同じ道を歩む誰かの力になるのです。いま書き始めることで、あなたは単なる技術の消費者から、コミュニティに貢献する創造者へと変わることができます。ブログは、知識の完成形を示すものではなく、思考の過程を記録するものです。あなたの躓きと発見の記録が、誰かの旅路を照らす灯になるでしょう。そして、その灯は時間が経っても消えることなく、未来の誰かを導き続けます。書くことで得られるのは、他者への貢献だけではありません。自分自身の思考を整理し、知識を定着させ、キャリアを形作っていく力にもなります。数年後、あなたが書いた記事の蓄積を振り返った時、そこには自分の成長の軌跡が鮮明に記録されているでしょう。継続のコツは「完璧を目指さない」ことです。まずは短く、1回15分でも書ける小さなテーマから始めましょう。また、定期的に書く習慣をつけるために、特定の曜日や時間帯を決めておくと効果的です。そして何より、自分自身が「書いていて楽しい」と感じられるトピックを選ぶことが長続きの秘訣です。技術ブログの世界では、読者からのフィードバックが得られることも大きな魅力です。あなたの記事に寄せられたコメントや質問から、新たな気づきを得ることもあるでしょう。それは、一人では辿り着けなかった視点や解決策との出会いかもしれません。今日から始めてみませんか？ 最初は小さな記事でいいのです。今週解決した問題について、新しく学んだツールの使い方、チームでの取り組みから得た気づき、読んだ技術書の要点と感想、あなたのチームが採用している開発プロセス、先輩から学んだテクニックなど、あなたの日常には書くべき価値のあるトピックがきっと溢れています。あなたの最初の記事は、誰かの最初の一歩を助ける光となるかもしれません。そして、書き続けることで、あなた自身も技術の世界でより深く、より遠くまで進んでいけるでしょう。書き始めることに価値があります。あなただけの観察眼で捉えた技術の風景を、今日から記録してみませんか。その一歩が、あなたのキャリアと技術コミュニティの未来を、より豊かなものにするはずです。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—これが、技術ブログの本当の姿だと思っています。さあ、あなたの最初の記事を、今週ぐらいに書いてみませんか？プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon本気(マジ)の話これは本気で言っているのですが今回は流石にめちゃくちゃに良いブログだと思うので欲しいものリストを公開します。www.amazon.jp]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[gopass を使ってパスワード共有を試す]]></title>
            <link>https://blog.1q77.com/2025/03/share-password-using-gopass/</link>
            <guid>https://blog.1q77.com/2025/03/share-password-using-gopass/</guid>
            <pubDate>Sat, 29 Mar 2025 00:57:32 GMT</pubDate>
            <content:encoded><![CDATA[gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fish 4のabbrはサブコマンドも展開できるぞ]]></title>
            <link>https://blog.atusy.net/2025/03/29/fish-4-abbr/</link>
            <guid>https://blog.atusy.net/2025/03/29/fish-4-abbr/</guid>
            <pubDate>Sat, 29 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishのabbr使ってますか？aliasの強化版といった感じで、短縮した入力をスペースやエンターと共に本来のコマンドに展開してくれる機能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリのサンプルコードから学ぶ活用法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</guid>
            <pubDate>Fri, 28 Mar 2025 04:28:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の「Rust製MCPライブラリの内部実装を徹底解析」では、Model Context Protocol (MCP) のRust SDKの内部実装について詳しく解説しました。今回は、その続編として、examples/ディレクトリに含まれるサンプルコードを詳しく見ていきます。github.comMCPを実際のプロジェクトで活用するためには、抽象的な実装だけでなく、具体的な使用例を理解することが重要です。このブログでは、クライアント実装、サーバー実装、マクロの使用例を通じて、MCPの実践的な活用方法を学び、実際に自分で実装できるようになることを目指します。概念が分からない人や自分の他のブログを読みたいくない人はこちらのドキュメントを一読してから読んでほしいです。modelcontextprotocol.ioexamples/の全体構造MCPのRust SDKには豊富なサンプルが含まれています。examples/ディレクトリは以下のような構成になっています。examples/├── clients/        # クライアント実装例├── servers/        # サーバー実装例├── transport/      # トランスポート実装例├── rig-integration/ # Rigフレームワークとの統合例├── wasi/           # WebAssembly実装例└── README.md       # サンプルの概要それぞれのディレクトリには、特定のユースケースに焦点を当てたサンプルコードが含まれています。これらのサンプルは、MCPの様々な機能や統合シナリオを理解するのに役立ちます。クライアント実装例examples/clients/ディレクトリには、MCPクライアントの様々な実装例が含まれています。これらの例を通じて、異なるシナリオでのMCPクライアントの使い方を学びましょう。基本的なクライアント実装: std_io.rs最も基本的なクライアント実装例はstd_io.rsです。このサンプルは標準入出力を使用してMCPサーバーと通信します。use anyhow::Result;use rmcp::{model::CallToolRequestParam, service::ServiceExt, transport::TokioChildProcess};use tokio::process::Command;use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("info,{}=debug", env!("CARGO_CRATE_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();        // 子プロセスとしてMCPサーバーを起動し、サービスを作成    let service = ()        .serve(TokioChildProcess::new(            Command::new("uvx").arg("mcp-server-git"),        )?)        .await?;    // サーバー情報の取得    let server_info = service.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // 利用可能なツールの一覧取得    let tools = service.list_tools(Default::default()).await?;    tracing::info!("Available tools: {tools:#?}");    // ツールの呼び出し    let tool_result = service        .call_tool(CallToolRequestParam {            name: "git_status".into(),            arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),        })        .await?;    tracing::info!("Tool result: {tool_result:#?}");        // クライアントの終了    service.cancel().await?;    Ok(())}この例での主要な要素を解説します。#[tokio::main]マクロ: Rustの非同期ランタイムを初期化し、非同期コードを実行できるようにします。TokioChildProcess: 子プロセスとしてMCPサーバーを起動するためのトランスポート実装です。この例では「uvx mcp-server-git」コマンドを実行しています。serveメソッド: トランスポートを使ってサービスを初期化するメソッドです。RustのServiceExtトレイトが提供する拡張機能です。call_toolメソッド: 特定のツールを呼び出すメソッドです。CallToolRequestParam構造体を使ってツール名と引数を指定します。SSEトランスポートの使用: sse.rs次に、Server-Sent Events (SSE) トランスポートを使用する例を見てみましょう。これはWebアプリケーションとMCPを統合する際に特に有用です。use anyhow::Result;use rmcp::model::{ClientCapabilities, ClientInfo, Implementation};use rmcp::{ServiceExt, model::CallToolRequestParam, transport::SseTransport};use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化（省略）...    // SSEトランスポートの作成と接続    let transport = SseTransport::start("http://localhost:8000/sse").await?;        // クライアント情報の定義    let client_info = ClientInfo {        protocol_version: Default::default(),        capabilities: ClientCapabilities::default(),        client_info: Implementation {            name: "test sse client".to_string(),            version: "0.0.1".to_string(),        },    };        // クライアントの作成    let client = client_info.serve(transport).await?;    // サーバー情報の取得    let server_info = client.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // ツール一覧の取得（省略）...    // ツールの呼び出し（省略）...        // クライアントの終了    client.cancel().await?;    Ok(())}このサンプルの特徴的な点は：SseTransport: HTTP経由でMCPサーバーと通信するためのトランスポート実装です。長時間接続を維持し、サーバーからのイベントを受信します。ClientInfo: クライアントに関する情報をサーバーに提供する構造体です。名前やバージョン、プロトコル互換性などの情報が含まれます。複数クライアントの管理: collection.rs複数のMCPクライアントを効率的に管理する例も含まれています。use std::collections::HashMap;use anyhow::Result;use rmcp::service::ServiceExt;use rmcp::{model::CallToolRequestParam, transport::TokioChildProcess};use tokio::process::Command;#[tokio::main]async fn main() -> Result<()> {    // ログ初期化は省略...    // 複数クライアントの作成    let mut client_list = HashMap::new();    for idx in 0..10 {        let service = ()            .into_dyn()            .serve(TokioChildProcess::new(                Command::new("uvx").arg("mcp-server-git"),            )?)            .await?;        client_list.insert(idx, service);    }    // 各クライアントの使用    for (_, service) in client_list.iter() {        // サーバー情報の取得        let _server_info = service.peer_info();        // ツール一覧の取得        let _tools = service.list_tools(Default::default()).await?;        // ツールの呼び出し        let _tool_result = service            .call_tool(CallToolRequestParam {                name: "git_status".into(),                arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),            })            .await?;    }        // クライアントのクリーンアップ    for (_, service) in client_list {        service.cancel().await?;    }    Ok(())}この例では、複数のMCPクライアントを作成し、それぞれに対して操作を実行しています。実際のアプリケーションでは、異なるサーバーに接続する複数のクライアントを管理する場合に役立ちます。サーバー実装例examples/servers/ディレクトリには、様々なMCPサーバー実装例が含まれています。ここでは、基本的なサーバー実装と、Webフレームワークとの統合例を見ていきます。基本的なサーバー実装: std_io.rs最もシンプルなサーバー実装はstd_io.rsです。このサンプルは、標準入出力を使用してクライアントとやり取りする基本的なMCPサーバーを実装しています。use anyhow::Result;use common::counter::Counter;use rmcp::{ServiceExt, transport::stdio};use tracing_subscriber::{self, EnvFilter};mod common;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()))        .with_writer(std::io::stderr)        .with_ansi(false)        .init();    tracing::info!("Starting MCP server");    // Counterサービスを作成し、標準入出力トランスポートで提供    let service = Counter::new().serve(stdio()).await?;    // クライアントからの要求を待機    service.waiting().await?;    Ok(())}このサンプルはシンプルですが、重要な要素がいくつか含まれています。Counter型: これはカウンターサービスを提供するサーバーハンドラの実装です。stdio(): 標準入出力をトランスポートとして使用するための関数です。waiting()メソッド: サーバーがクライアントからの要求を待機するためのメソッドです。次に、Counter型の実装を見てみましょう：use std::sync::Arc;use rmcp::{    Error as McpError, RoleServer, ServerHandler, const_string, model::*, schemars,    service::RequestContext, tool,};use tokio::sync::Mutex;#[derive(Clone)]pub struct Counter {    counter: Arc<Mutex<i32>>,}#[tool(tool_box)]impl Counter {    pub fn new() -> Self {        Self {            counter: Arc::new(Mutex::new(0)),        }    }    #[tool(description = "Increment the counter by 1")]    async fn increment(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter += 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Decrement the counter by 1")]    async fn decrement(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter -= 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Get the current counter value")]    async fn get_value(&self) -> Result<CallToolResult, McpError> {        let counter = self.counter.lock().await;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }}#[tool(tool_box)]impl ServerHandler for Counter {    fn get_info(&self) -> ServerInfo {        ServerInfo {            protocol_version: ProtocolVersion::V_2024_11_05,            capabilities: ServerCapabilities::builder()                .enable_tools()                .build(),            server_info: Implementation::from_build_env(),            instructions: Some("This server provides a counter tool...".to_string()),        }    }        // その他の実装は省略...}このCounter実装の重要な点：#[tool(tool_box)]マクロ: これは、メソッドを自動的にMCPツールとして登録するマクロです。これにより、ボイラープレートコードが大幅に削減されます。#[tool(description = "...")]マクロ: 各メソッドにツールの説明を追加します。この情報はクライアントに公開され、ツールの使用方法を理解するのに役立ちます。Arc<Mutex<i32>>: スレッド間で安全にカウンター値を共有するためのラッパーです。これは、Rustの並行性プリミティブの典型的な使用例です。Axumフレームワークとの統合: axum.rsより高度な例として、Axum WebフレームワークとMCPサーバーを統合した例を見てみましょう。use rmcp::transport::sse_server::SseServer;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};mod common;use common::counter::Counter;const BIND_ADDRESS: &str = "127.0.0.1:8000";#[tokio::main]async fn main() -> anyhow::Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| "debug".to_string().into()),        )        .with(tracing_subscriber::fmt::layer())        .init();    // SSEサーバーの起動とカウンターサービスの設定    let ct = SseServer::serve(BIND_ADDRESS.parse()?)        .await?        .with_service(Counter::new);    // Ctrl+Cで終了するまで待機    tokio::signal::ctrl_c().await?;    ct.cancel();    Ok(())}このサンプルの特徴的な点：SseServer::serve: AxumフレームワークをベースにしたSSEサーバーを起動する関数です。これにより、ブラウザからMCPサーバーにアクセスできるようになります。with_service: サービスファクトリを指定するメソッドです。この例ではCounter::new関数をファクトリとして使用しています。tokio::signal::ctrl_c().await?: Ctrl+Cシグナルを受け取るまで待機します。これにより、サーバーはバックグラウンドで動作し続けます。Webフレームワーク統合のポイントWebフレームワーク（Axum、Actix Webなど）とMCPを統合する際のポイント：適切なトランスポート（SSEなど）を選択するセッション管理を適切に行うエラーハンドリングを丁寧に実装するサーバーのライフサイクルを適切に管理するマクロ使用例examples/macros/ディレクトリには、MCPマクロを使用してツールを簡単に定義する例が含まれています。これらのマクロは、ボイラープレートコードを大幅に削減し、MCPサーバーの実装を容易にします。計算機ツールの実装calculator.rsは、#[tool]マクロを使用して計算機ツールを実装する例です。use mcp_core::handler::{ToolError, ToolHandler};use mcp_macros::tool;#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}#[tokio::main]async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {    // ツールのインスタンスを作成    let calculator = Calculator;    // ツール情報の出力    println!("Tool name: {}", calculator.name());    println!("Tool description: {}", calculator.description());    println!("Tool schema: {}", calculator.schema());    // サンプル入力でツールをテスト    let input = serde_json::json!({        "x": 5,        "y": 3,        "operation": "multiply"    });    let result = calculator.call(input).await?;    println!("Result: {}", result);    Ok(())}このサンプルの素晴らしい点：宣言的なツール定義: #[tool]マクロを使うことで、通常の関数にメタデータを追加するだけでMCPツールを定義できます。パラメータドキュメント: params(x = "First number...")のように、パラメータの説明をマクロ内で定義できます。これにより、自己文書化されたAPIが作成されます。型安全: 関数の引数型（i32, Stringなど）を利用して型安全なパラメータを定義します。Rustのコンパイラが型チェックを行うため、型関連のバグを防ぐことができます。マクロの活用術マクロを効果的に使用するためのポイント：適切な名前と説明を提供して、ツールの目的を明確にするパラメータに詳細な説明を追加して、ユーザーが正しい値を入力できるようにする複雑なパラメータには構造体を使用し、#[tool(aggr)]アノテーションで集約するエラーハンドリングを丁寧に行い、具体的なエラーメッセージを提供するトランスポート実装例examples/transport/ディレクトリには、様々なトランスポート実装例が含まれています。トランスポートは、MCPクライアントとサーバーの通信方法を定義します。TCPトランスポートtcp.rsは、TCP接続を使用してMCPメッセージを送受信する例です。use common::calculator::Calculator;use rmcp::{serve_client, serve_server};mod common;#[tokio::main]async fn main() -> anyhow::Result<()> {    tokio::spawn(server());    client().await?;    Ok(())}async fn server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    while let Ok((stream, _)) = tcp_listener.accept().await {        tokio::spawn(async move {            let server = serve_server(Calculator, stream).await?;            server.waiting().await?;            anyhow::Ok(())        });    }    Ok(())}async fn client() -> anyhow::Result<()> {    let stream = tokio::net::TcpSocket::new_v4()?        .connect("127.0.0.1:8001".parse()?)        .await?;    let client = serve_client((), stream).await?;    let tools = client.peer().list_tools(Default::default()).await?;    println!("{:?}", tools);    Ok(())}このサンプルでは：非同期I/O: tokioの非同期I/O機能を使用して、ブロッキングせずに複数の接続を処理します。serve_serverとserve_client: これらは便利なヘルパー関数で、トランスポートをサーバーまたはクライアントとして設定します。並行接続処理: tokio::spawnを使って各接続を別々のタスクで処理し、サーバーのスケーラビリティを確保しています。WebSocketトランスポートwebsocket.rsは、WebSocket接続を使用したMCPトランスポートの例です。async fn http_client(uri: &str) -> anyhow::Result<RunningService<RoleClient, ()>> {    let (stream, response) = tokio_tungstenite::connect_async(uri).await?;    if response.status() != tungstenite::http::StatusCode::SWITCHING_PROTOCOLS {        return Err(anyhow::anyhow!("failed to upgrade connection"));    }    let transport = WebsocketTransport::new_client(stream);    let client = ().serve(transport).await?;    Ok(client)}async fn start_server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    tokio::spawn(async move {        while let Ok((stream, addr)) = tcp_listener.accept().await {            tracing::info!("accepted connection from: {}", addr);            tokio::spawn(async move {                let ws_stream = tokio_tungstenite::accept_async(stream).await?;                let transport = WebsocketTransport::new_server(ws_stream);                let server = Calculator.serve(transport).await?;                server.waiting().await?;                Ok::<(), anyhow::Error>(())            });        }    });    Ok(())}このサンプルでは：WebSocketプロトコル: HTTPからWebSocketにアップグレードする処理が含まれています。カスタムトランスポート実装: WebsocketTransportとしてカスタムトランスポートが実装されています。接続管理: 接続の確立からサーバー待機までの一連のフローが示されています。トランスポート選択のポイント適切なトランスポートを選択するためのポイント：用途に合わせて選択する:標準入出力（stdio）: コマンドラインツールや子プロセスSSE: Webブラウザとのリアルタイム通信TCP: ネットワーク上のサービス間通信WebSocket: 双方向リアルタイム通信Unix Socket: 同一マシン上のプロセス間通信セキュリティを考慮する: 公開ネットワークで使用する場合はTLSなどの暗号化を検討パフォーマンスを考慮する: 大量のデータや頻繁な通信がある場合は効率的なトランスポートを選択応用パターンとベストプラクティスMCPを実装する際の応用パターンとベストプラクティスをいくつか紹介します。エラーハンドリング具体的なエラーメッセージ: クライアントが問題を理解できるよう、具体的なエラーメッセージを提供します。   Err(ToolError::InvalidParameters(format!(       "Unknown operation: {}. Supported operations are: add, subtract, multiply, divide",       operation   )))エラー変換: 低レベルエラーを適切なMCPエラーに変換します。   async fn read_file(&self, path: String) -> Result<CallToolResult, McpError> {       let content = tokio::fs::read_to_string(path)           .await           .map_err(|e| McpError::tool_execution_error(               "file_read_error",               Some(serde_json::json!({ "error": e.to_string() }))           ))?;              Ok(CallToolResult::success(vec![Content::text(content)]))   }非同期処理適切なタスク管理: 長時間実行される処理は別タスクに分離し、クライアントをブロックしないようにします。   #[tool(description = "Run a long process")]   async fn run_long_process(&self) -> Result<CallToolResult, McpError> {       // 別タスクでバックグラウンド処理を開始       let task_id = self.start_background_task().await?;              // タスクIDを即座に返す       Ok(CallToolResult::success(vec![Content::text(format!(           "Task started with ID: {}", task_id       ))]))   }      // 別のツールでタスク状態を確認できるようにする   #[tool(description = "Check task status")]   async fn check_task_status(&self, #[tool(param)] task_id: String) -> Result<CallToolResult, McpError> {       // ...   }タイムアウト管理: 長時間の操作にはタイムアウトを設定します。   let result = tokio::time::timeout(       Duration::from_secs(30),       some_long_operation()   ).await.map_err(|_| McpError::tool_execution_error(       "operation_timeout",       Some(serde_json::json!({"message": "Operation timed out after 30 seconds"}))   ))??;リソース管理共有状態の適切な管理: Arc<Mutex<T>>やArc<RwLock<T>>を使用して、スレッド間で状態を安全に共有します。リソースのクリーンアップ: Dropトレイトを実装して、リソースが確実に解放されるようにします。コネクション管理: クライアント接続を適切に管理し、リソースリークを防ぎます。実際の使用例：LLMとの統合MCPはLLM（大規模言語モデル）に外部ツールへのアクセスを提供するために設計されています。ここでは、LLMとMCPの統合例を見てみましょう。examples/rig-integration/ディレクトリには、Rigフレームワーク（LLMアプリケーションフレームワーク）とMCPの統合例が含まれています。// MCPツールをRigのツールとして適応させるアダプタpub struct McpToolAdaptor {    tool: McpTool,    server: ServerSink,}impl RigTool for McpToolAdaptor {    fn name(&self) -> String {        self.tool.name.to_string()    }    fn definition(        &self,        _prompt: String,    ) -> std::pin::Pin<Box<dyn Future<Output = rig::completion::ToolDefinition> + Send + Sync + '_>>    {        Box::pin(std::future::ready(rig::completion::ToolDefinition {            name: self.name(),            description: self.tool.description.to_string(),            parameters: self.tool.schema_as_json_value(),        }))    }    fn call(        &self,        args: String,    ) -> std::pin::Pin<        Box<dyn Future<Output = Result<String, rig::tool::ToolError>> + Send + Sync + '_>,    > {        let server = self.server.clone();        Box::pin(async move {            let call_mcp_tool_result = server                .call_tool(CallToolRequestParam {                    name: self.tool.name.clone(),                    arguments: serde_json::from_str(&args)                        .map_err(rig::tool::ToolError::JsonError)?,                })                .await                .map_err(|e| rig::tool::ToolError::ToolCallError(Box::new(e)))?;            Ok(convert_mcp_call_tool_result_to_string(call_mcp_tool_result))        })    }}このアダプタは、MCPツールをRigフレームワークのツールとして使用できるようにします。これにより、LLMとMCPサーバーをシームレスに統合することができます。WASI (WebAssembly System Interface) 対応examples/wasi/ディレクトリには、WebAssemblyでMCPサーバーを実装する例が含まれています。これにより、ブラウザやエッジコンピューティング環境でMCPサーバーを実行できます。// wasi/src/lib.rsstruct TokioCliRunner;impl wasi::exports::cli::run::Guest for TokioCliRunner {    fn run() -> Result<(), ()> {        let rt = tokio::runtime::Builder::new_current_thread()            .enable_all()            .build()            .unwrap();        rt.block_on(async move {            tracing_subscriber::fmt()                .with_env_filter(                    EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()),                )                .with_writer(std::io::stderr)                .with_ansi(false)                .init();            let server = calculator::Calculator.serve(wasi_io()).await.unwrap();            server.waiting().await.unwrap();        });        Ok(())    }}wasi::cli::command::export!(TokioCliRunner);WASI環境でMCPサーバーを実行することで、セキュリティやポータビリティが向上し、より多くの環境でMCPを活用できるようになります。まとめMCPのRust SDKには、様々なユースケースに対応するための豊富なサンプルコードが含まれています。これらのサンプルを理解し、実際に試すことで、MCPを活用したアプリケーションの開発スキルを向上させることができます。この記事でカバーした主なポイント：クライアント実装: 基本的なクライアント、SSEトランスポートの使用、複数クライアントの管理サーバー実装: 基本的なサーバー、ツールボックスとマクロの活用、Webフレームワークとの統合トランスポート実装: TCP、WebSocket、Unix Socketなどの様々なトランスポート応用パターン: エラーハンドリング、非同期処理、リソース管理のベストプラクティスLLM統合: Rigフレームワークを使ったLLMとMCPの統合例MCPはまだ比較的新しいプロトコルですが、AIとツールの統合に関する標準化に大きな可能性を秘めています。Rustの強力な型システムと安全性の恩恵を受けながら、MCPの機能を最大限に活用しましょう。生成AIについて興味があればこちらも読んでみてもらいたいです。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nvidia/cuda imageを使ってDockerコンテナでGPUを使用する]]></title>
            <link>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</link>
            <guid>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</guid>
            <pubDate>Thu, 27 Mar 2025 04:33:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリの内部実装を徹底解析]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</guid>
            <pubDate>Thu, 27 Mar 2025 03:16:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに最近注目を集めているModel Context Protocol（MCP）は、大規模言語モデル（LLM）に外部ツールやサービスへのアクセス能力を提供するための標準プロトコルです。中でも公式が提供しているRust SDKはあまり注目されていませんが、私自身が必要としているためこのドキュメントを作成します。github.com以前は自前で実装していましたが、公式SDKが公開されたことでそちらを検討するのが良いと考えました。私の実装と比較してかなり洗練されている点が多く、多くの学びを得ることができました。syu-m-5151.hatenablog.comこの記事では、MCP Rust SDKの内部実装を深掘りし、どのようにRustの強力な型システムと非同期プログラミングモデルが活用されているかを解説します。コードの詳細な分析を通して、Rustの優れた設計パターンや実装テクニックを学びましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれるのもありがたいです。MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月27日 現在)。ちなみに今後MCPがどうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioSDKの全体構成 - 明確な関心の分離MCP Rust SDKは、複数のクレートに明確に分離されており、それぞれが特定の責任を担っています。rust-sdk/├── crates/│   ├── mcp-core/      # プロトコルの基本型とインターフェース│   ├── mcp-client/    # クライアント実装│   ├── mcp-server/    # サーバー実装│   └── mcp-macros/    # ツール実装を簡素化するマクロ└── examples/    ├── clients/       # クライアント使用例    ├── servers/       # サーバー実装例    └── macros/        # マクロ使用例この設計はRustエコシステムでよく見られる「関心の分離」パターンに従っています。各クレートがひとつの責任を持ち、依存関係も明確です。こうすることで、メンテナンス性と再利用性が大幅に向上します。特に注目すべきは、コア型定義とプロトコル実装をmcp-coreに分離している点です。これにより、クライアントとサーバーが共通の型定義を使いながら、それぞれ独立して実装・進化できる柔軟性を確保しています。mcp-core: 堅牢な基盤となる型定義mcp-coreクレートは、MCPプロトコルの心臓部とも言える基本型とインターフェースを提供しています。ここでの実装がSDK全体の品質を大きく左右します。JSON-RPCメッセージの巧妙な実装MCPはJSON-RPCプロトコルをベースにしていますが、その実装が非常に興味深いものになっています#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]#[serde(untagged, try_from = "JsonRpcRaw")]pub enum JsonRpcMessage {    Request(JsonRpcRequest),    Response(JsonRpcResponse),    Notification(JsonRpcNotification),    Error(JsonRpcError),    Nil, // used to respond to notifications}#[derive(Debug, Serialize, Deserialize)]struct JsonRpcRaw {    jsonrpc: String,    #[serde(skip_serializing_if = "Option::is_none")]    id: Option<u64>,    #[serde(skip_serializing_if = "Option::is_none")]    method: Option<String>,    #[serde(skip_serializing_if = "Option::is_none")]    params: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    result: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    error: Option<ErrorData>,}impl TryFrom<JsonRpcRaw> for JsonRpcMessage {    type Error = String;    fn try_from(raw: JsonRpcRaw) -> Result<Self, <Self as TryFrom<JsonRpcRaw>>::Error> {        // If it has an error field, it's an error response        if raw.error.is_some() {            return Ok(JsonRpcMessage::Error(JsonRpcError {                jsonrpc: raw.jsonrpc,                id: raw.id,                error: raw.error.unwrap(),            }));        }        // If it has a result field, it's a response        if raw.result.is_some() {            return Ok(JsonRpcMessage::Response(JsonRpcResponse {                jsonrpc: raw.jsonrpc,                id: raw.id,                result: raw.result,                error: None,            }));        }        // If we have a method, it's either a notification or request        if let Some(method) = raw.method {            if raw.id.is_none() {                return Ok(JsonRpcMessage::Notification(JsonRpcNotification {                    jsonrpc: raw.jsonrpc,                    method,                    params: raw.params,                }));            }            return Ok(JsonRpcMessage::Request(JsonRpcRequest {                jsonrpc: raw.jsonrpc,                id: raw.id,                method,                params: raw.params,            }));        }        // If we have no method and no result/error, it's a nil response        if raw.id.is_none() && raw.result.is_none() && raw.error.is_none() {            return Ok(JsonRpcMessage::Nil);        }        // If we get here, something is wrong with the message        Err(format!(            "Invalid JSON-RPC message format: id={:?}, method={:?}, result={:?}, error={:?}",            raw.id, raw.method, raw.result, raw.error        ))    }}この実装の素晴らしい点は3つあります。#[serde(untagged)]アノテーションの活用：JSONデータの構造に基づいて適切な列挙型バリアントに自動的にデシリアライズします。これにより、外部向けのJSONはシンプルな形式を維持できます。try_from = "JsonRpcRaw"による変換の分離：複雑な変換ロジックを別の型に委譲し、コードの見通しを良くしています。これはRustの型システムを活用した優れたパターンです。段階的な判断ロジック：各メッセージタイプの判定条件を明確にし、順番に評価することで複雑な条件分岐を読みやすく実装しています。これらの工夫により、複雑なJSON-RPCプロトコルの処理を堅牢かつ読みやすいコードで実現しています。特に注目すべきは、Rustの型システムを最大限に活用し、コンパイル時の型チェックでバグを防ぐ設計になっている点です。豊かなコンテンツ型システムMCPはさまざまなコンテンツ型（テキスト、画像、リソースなど）をサポートしています。その実装も非常に洗練されています。#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]#[serde(tag = "type", rename_all = "camelCase")]pub enum Content {    Text(TextContent),    Image(ImageContent),    Resource(EmbeddedResource),}impl Content {    pub fn text<S: Into<String>>(text: S) -> Self {        Content::Text(TextContent {            text: text.into(),            annotations: None,        })    }    pub fn image<S: Into<String>, T: Into<String>>(data: S, mime_type: T) -> Self {        Content::Image(ImageContent {            data: data.into(),            mime_type: mime_type.into(),            annotations: None,        })    }    pub fn resource(resource: ResourceContents) -> Self {        Content::Resource(EmbeddedResource {            resource,            annotations: None,        })    }    // その他のメソッド...}この実装には、使いやすさと型安全性を両立する工夫がいくつもあります。タグ付き列挙型の活用：#[serde(tag = "type")]は、JSONに「type」フィールドを追加し、その値に基づいて適切な型にデシリアライズします。これはJSONとRustの型を自然にマッピングする優れた方法です。ファクトリメソッド：text(), image(), resource()などのメソッドは、わかりやすい方法でコンテンツを作成できるようにしています。これは、制約を守りながら簡潔にオブジェクトを作成するのに役立ちます。ジェネリックな引数：S: Into<String>のようなトレイト境界を使うことで、文字列リテラル、String、&strなど、さまざまな文字列型を引数として受け入れることができます。これは使い勝手を大幅に向上させます。この設計は、使いやすいAPIと堅牢な内部実装のバランスが見事です。とりわけ、列挙型とそのバリアントを活用してドメインの概念を表現する点はRustらしいアプローチと言えるでしょう。mcp-client: 柔軟なトランスポートと抽象化mcp-clientクレートは、MCPサーバーとの通信を担当します。特に注目すべきは、トランスポート層の抽象化です。トランスポートの抽象化MCPサーバーとの通信には複数の方法（標準入出力、HTTP、WebSocketなど）が考えられます。このSDKはそれらを抽象化するための優れた設計を採用しています。/// A message that can be sent through the transport#[derive(Debug)]pub struct TransportMessage {    /// The JSON-RPC message to send    pub message: JsonRpcMessage,    /// Channel to receive the response on (None for notifications)    pub response_tx: Option<oneshot::Sender<Result<JsonRpcMessage, Error>>>,}/// A generic asynchronous transport trait with channel-based communication#[async_trait]pub trait Transport {    type Handle: TransportHandle;    /// Start the transport and establish the underlying connection.    /// Returns the transport handle for sending messages.    async fn start(&self) -> Result<Self::Handle, Error>;    /// Close the transport and free any resources.    async fn close(&self) -> Result<(), Error>;}#[async_trait]pub trait TransportHandle: Send + Sync + Clone + 'static {    async fn send(&self, message: JsonRpcMessage) -> Result<JsonRpcMessage, Error>;}この抽象化にはいくつもの巧妙な工夫があります。関連型（associated type）の活用：type Handle: TransportHandleという関連型を使うことで、トランスポートとそのハンドルを型レベルで紐づけています。これにより、異なるトランスポート実装が異なるハンドル型を持つことができます。非同期トレイト：#[async_trait]マクロを使って、非同期メソッドをトレイトに含められるようにしています。これは標準のRustでは直接サポートされていない機能です。分離された開始と通信：startメソッドで接続を確立し、その結果として得られるハンドルを使って通信するという2段階のパターンを採用しています。これにより、接続のライフサイクルとメッセージ送受信を明確に分離できます。このような抽象化により、新しいトランスポート実装を追加するのが容易になりますし、クライアント側のコードはトランスポートの詳細を気にせず書けるようになります。StdioTransportの実装標準入出力を使ったトランスポート実装も見てみましょう：pub struct StdioTransport {    command: String,    args: Vec<String>,    env: HashMap<String, String>,}impl StdioTransport {    pub fn new<S: Into<String>>(        command: S,        args: Vec<String>,        env: HashMap<String, String>,    ) -> Self {        Self {            command: command.into(),            args,            env,        }    }    async fn spawn_process(&self) -> Result<(Child, ChildStdin, ChildStdout, ChildStderr), Error> {        let mut command = Command::new(&self.command);        command            .envs(&self.env)            .args(&self.args)            .stdin(std::process::Stdio::piped())            .stdout(std::process::Stdio::piped())            .stderr(std::process::Stdio::piped())            .kill_on_drop(true);        // Set process group only on Unix systems        #[cfg(unix)]        command.process_group(0); // don't inherit signal handling from parent process        // Hide console window on Windows        #[cfg(windows)]        command.creation_flags(0x08000000); // CREATE_NO_WINDOW flag        let mut process = command            .spawn()            .map_err(|e| Error::StdioProcessError(e.to_string()))?;        let stdin = process            .stdin            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdin".into()))?;        let stdout = process            .stdout            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdout".into()))?;        let stderr = process            .stderr            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stderr".into()))?;        Ok((process, stdin, stdout, stderr))    }}この実装の素晴らしい点を見てみましょう：プラットフォーム固有の最適化：#[cfg(unix)]と#[cfg(windows)]を使って、各OSに最適な設定を行っています。これはRustの条件付きコンパイルの機能をうまく活用した例です。リソース管理：kill_on_drop(true)を使って、オブジェクトが破棄された時に子プロセスも確実に終了するよう保証しています。これはリソースリークを防ぐための重要な安全策です。エラーハンドリング：ok_or_elseのような関数を使って、エラーケースを明確に処理しています。これにより、どのような状況でもプログラムが予測可能な動作をするようになります。この実装は、複雑な子プロセス操作を安全かつ効率的に行うための優れた例です。特に、クロスプラットフォームな動作を保証するための配慮が随所に見られます。クライアント本体の実装最後に、クライアント本体の実装を見てみましょう：pub struct McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    service: Mutex<S>,    next_id: AtomicU64,    server_capabilities: Option<ServerCapabilities>,    server_info: Option<Implementation>,}impl<S> McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    pub fn new(service: S) -> Self {        Self {            service: Mutex::new(service),            next_id: AtomicU64::new(1),            server_capabilities: None,            server_info: None,        }    }    /// Send a JSON-RPC request and check we don't get an error response.    async fn send_request<R>(&self, method: &str, params: Value) -> Result<R, Error>    where        R: for<'de> Deserialize<'de>,    {        let mut service = self.service.lock().await;        service.ready().await.map_err(|_| Error::NotReady)?;        let id = self.next_id.fetch_add(1, Ordering::SeqCst);        let request = JsonRpcMessage::Request(JsonRpcRequest {            jsonrpc: "2.0".to_string(),            id: Some(id),            method: method.to_string(),            params: Some(params.clone()),        });        let response_msg = service            .call(request)            .await            .map_err(|e| Error::McpServerError {                server: self                    .server_info                    .as_ref()                    .map(|s| s.name.clone())                    .unwrap_or("".to_string()),                method: method.to_string(),                // we don't need include params because it can be really large                source: Box::new(e.into()),            })?;        // ... レスポンス処理 ...    }}この実装には、Rustの現代的な非同期プログラミング技術が凝縮されています。Tower Serviceの活用：低レベルのトランスポート詳細を抽象化するために、Tower crateのServiceトレイトを使用しています。これはミドルウェアの組み合わせや機能拡張を容易にします。ジェネリックな戻り値型：send_request<R>のようなジェネリック関数を使って、様々な型のレスポンスを受け取れるようにしています。これはクライアントAPIを使いやすくする工夫です。スレッドセーフなカウンター：AtomicU64を使って、スレッドセーフなID生成を実現しています。これは並行処理を安全に行うための基本的なテクニックです。非同期排他制御：Mutex<S>を使って、非同期コンテキストでのサービスアクセスを管理しています。tokio::sync::Mutexはブロッキングせずに排他制御を行える優れたプリミティブです。これらの機能を組み合わせることで、堅牢で効率的、かつ使いやすいクライアントAPIを実現しています。特にTowerのサービス抽象化を活用することで、将来的な拡張性も確保されています。mcp-server: モジュラーなサーバー設計mcp-serverクレートは、MCPサーバーをRustで実装するためのフレームワークを提供しています。ここでもいくつか興味深い実装が見られます。ByteTransportの実装#[pin_project]pub struct ByteTransport<R, W> {    // Reader is a BufReader on the underlying stream (stdin or similar) buffering    // the underlying data across poll calls, we clear one line (\n) during each    // iteration of poll_next from this buffer    #[pin]    reader: BufReader<R>,    #[pin]    writer: W,}impl<R, W> ByteTransport<R, W>where    R: AsyncRead,    W: AsyncWrite,{    pub fn new(reader: R, writer: W) -> Self {        Self {            // Default BufReader capacity is 8 * 1024, increase this to 2MB to the file size limit            // allows the buffer to have the capacity to read very large calls            reader: BufReader::with_capacity(2 * 1024 * 1024, reader),            writer,        }    }}impl<R, W> Stream for ByteTransport<R, W>where    R: AsyncRead + Unpin,    W: AsyncWrite + Unpin,{    type Item = Result<JsonRpcMessage, TransportError>;    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {        // Poll実装...    }}この実装には、Rustの非同期I/Oに関する高度な知識が詰まっています。巨大なバッファサイズ：デフォルトの8KBではなく2MBという大きなバッファを使用し、大量のデータを効率的に処理できるようにしています。これは実際のユースケースに基づく現実的な最適化でしょう。pin-projectの活用：非同期処理でピン留めが必要なフィールドを持つ構造体を安全に扱うために、pin-projectクレートを使用しています。これは非同期Rustの複雑な問題を解決するための定石です。Streamトレイトの実装：Streamトレイトを実装することで、メッセージを非同期ストリームとして扱えるようにしています。これは非同期処理パターンとの自然な統合を可能にします。このようなトランスポート実装により、サーバーは効率的に大量のメッセージを処理できるようになります。また、バッファ管理や非同期I/Oの複雑さは抽象化されるため、上位層のコードはビジネスロジックに集中できます。優れたRouterトレイトMCPサーバーの中核となるのがRouterトレイトです。pub trait Router: Send + Sync + 'static {    fn name(&self) -> String;    fn instructions(&self) -> String;    fn capabilities(&self) -> ServerCapabilities;    fn list_tools(&self) -> Vec<mcp_core::tool::Tool>;    fn call_tool(        &self,        tool_name: &str,        arguments: Value,    ) -> Pin<Box<dyn Future<Output = Result<Vec<Content>, ToolError>> + Send + 'static>>;    fn list_resources(&self) -> Vec<mcp_core::resource::Resource>;    fn read_resource(        &self,        uri: &str,    ) -> Pin<Box<dyn Future<Output = Result<String, ResourceError>> + Send + 'static>>;    fn list_prompts(&self) -> Vec<Prompt>;    fn get_prompt(&self, prompt_name: &str) -> PromptFuture;    // 以下はデフォルト実装を持つヘルパーメソッド    fn create_response(&self, id: Option<u64>) -> JsonRpcResponse { ... }    fn handle_initialize(&self, req: JsonRpcRequest) -> impl Future<Output = Result<JsonRpcResponse, RouterError>> + Send { ... }    // その他のハンドラメソッド...}この設計の素晴らしさは以下の点にあります。最小限の実装要件：ユーザーが実装すべきメソッドは基本的な機能に限られており、複雑なプロトコル処理はデフォルト実装として提供されています。これにより、ルーターの実装がシンプルになり、ドメインロジックに集中できます。Futureを返すメソッド：ツール呼び出しなどの処理は非同期で行われるケースが多いため、Pin<Box<dyn Future<...>>>を返すメソッドになっています。これにより、実装者は任意の非同期処理を行う自由を持ちます。明確なトレイト境界：Send + Sync + 'staticという境界により、マルチスレッド環境での使用を安全に行えるようになっています。これは実際のサーバー環境では不可欠な制約です。この設計は、「使いやすさ」と「柔軟性」のバランスがとれた素晴らしい例です。初心者でも簡単に基本的なルーターを実装できますが、高度なユースケースに対応する拡張性も備えています。RouterServiceの実装pub struct RouterService<T>(pub T);impl<T> Service<JsonRpcRequest> for RouterService<T>where    T: Router + Clone + Send + Sync + 'static,{    type Response = JsonRpcResponse;    type Error = BoxError;    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {        Poll::Ready(Ok(()))    }    fn call(&mut self, req: JsonRpcRequest) -> Self::Future {        let this = self.0.clone();        Box::pin(async move {            let result = match req.method.as_str() {                "initialize" => this.handle_initialize(req).await,                "tools/list" => this.handle_tools_list(req).await,                "tools/call" => this.handle_tools_call(req).await,                "resources/list" => this.handle_resources_list(req).await,                "resources/read" => this.handle_resources_read(req).await,                "prompts/list" => this.handle_prompts_list(req).await,                "prompts/get" => this.handle_prompts_get(req).await,                _ => {                    let mut response = this.create_response(req.id);                    response.error = Some(RouterError::MethodNotFound(req.method).into());                    Ok(response)                }            };            result.map_err(BoxError::from)        })    }}この実装は、デザインパターンの「アダプターパターン」を思わせる優れた例です。シンプルなラッパー型：RouterService<T>(pub T)というシンプルな新型でRouterトレイトをTowerのServiceトレイトに適応させています。これは非常にエレガントなアプローチです。メソッドディスパッチ：リクエストのmethod文字列に基づいて適切なハンドラメソッドに処理をディスパッチしています。これはルーティングのための直感的で効率的な実装です。Clone要件：非同期クロージャ内でルーターを使用するためにCloneトレイト境界を要求しています。これにより、所有権の問題を簡単に解決できます。このようなラッパー型とディスパッチロジックにより、開発者はRouterトレイトの実装に集中でき、ServiceやTowerのような低レベルの詳細を気にする必要がなくなります。これは抽象化の良い例です。mcp-macros: 宣言的ツール定義の魔法最後に、mcp-macrosクレートの中核である#[tool]マクロを見てみましょう：#[proc_macro_attribute]pub fn tool(args: TokenStream, input: TokenStream) -> TokenStream {    let args = parse_macro_input!(args as MacroArgs);    let input_fn = parse_macro_input!(input as ItemFn);    // Extract function details    let fn_name = &input_fn.sig.ident;    let fn_name_str = fn_name.to_string();    // Generate PascalCase struct name from the function name    let struct_name = format_ident!("{}", { fn_name_str.to_case(Case::Pascal) });    // Use provided name or function name as default    let tool_name = args.name.unwrap_or(fn_name_str);    let tool_description = args.description.unwrap_or_default();    // パラメータの抽出処理...    // 実装の生成    let params_struct_name = format_ident!("{}Parameters", struct_name);    let expanded = quote! {        #[derive(serde::Deserialize, schemars::JsonSchema)]        struct #params_struct_name {            #(#param_defs,)*        }        #input_fn        #[derive(Default)]        struct #struct_name;        #[async_trait::async_trait]        impl mcp_core::handler::ToolHandler for #struct_name {            fn name(&self) -> &'static str {                #tool_name            }            fn description(&self) -> &'static str {                #tool_description            }            fn schema(&self) -> serde_json::Value {                mcp_core::handler::generate_schema::<#params_struct_name>()                    .expect("Failed to generate schema")            }            async fn call(&self, params: serde_json::Value) -> Result<serde_json::Value, mcp_core::handler::ToolError> {                let params: #params_struct_name = serde_json::from_value(params)                    .map_err(|e| mcp_core::handler::ToolError::InvalidParameters(e.to_string()))?;                // Extract parameters and call the function                let result = #fn_name(#(params.#param_names,)*).await                    .map_err(|e| mcp_core::handler::ToolError::ExecutionError(e.to_string()))?;                Ok(serde_json::to_value(result).expect("should serialize"))            }        }    };    TokenStream::from(expanded)}このマクロは、Rustの宣言的プログラミングの可能性を示す素晴らしい例です。関数からのメタデータ抽出：関数の名前や引数リストを解析して、ツールの基本情報を自動的に取得します。パラメータ構造体の自動生成：関数の引数リストから自動的にパラメータ構造体を生成し、serdeとschemarsのデリバティブを適用してJSON対応にします。ツールハンドラの自動実装：抽出した情報を元に、ToolHandlerトレイトを自動的に実装します。これにより、開発者はツールのビジネスロジックだけに集中できます。このマクロを使うと、以下のように簡潔なコードでツールを定義できます。#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}通常なら数十行のボイラープレートコードが必要なところを、このマクロによって数行のアノテーションだけで実現できています。これは開発者体験を大幅に向上させる素晴らしい例です。Webフレームワークとの統合MCPはしばしばWebアプリケーションと統合されます。そのための優れた実装例を見てみましょう：async fn sse_handler(State(app): State<App>) -> Sse<impl Stream<Item = Result<Event, io::Error>>> {    // it's 4KB    const BUFFER_SIZE: usize = 1 << 12;    let session = session_id();    tracing::debug!(%session, "sse connection");    let (c2s_read, c2s_write) = tokio::io::simplex(BUFFER_SIZE);    let (s2c_read, s2c_write) = tokio::io::simplex(BUFFER_SIZE);    app.txs        .write()        .await        .insert(session.clone(), Arc::new(Mutex::new(c2s_write)));    {        let session = session.clone();        tokio::spawn(async move {            let router = RouterService(counter::CounterRouter::new());            let server = Server::new(router);            let bytes_transport = ByteTransport::new(c2s_read, s2c_write);            let _result = server                .run(bytes_transport)                .await                .inspect_err(|e| tracing::error!(?e, "server run error"));            app.txs.write().await.remove(&session);        });    }    let stream = futures::stream::once(futures::future::ok(        Event::default()            .event("endpoint")            .data(format!("?sessionId={session}")),    ))    .chain(        FramedRead::new(s2c_read, common::jsonrpc_frame_codec::JsonRpcFrameCodec)            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))            .and_then(move |bytes| match std::str::from_utf8(&bytes) {                Ok(message) => futures::future::ok(Event::default().event("message").data(message)),                Err(e) => futures::future::err(io::Error::new(io::ErrorKind::InvalidData, e)),            }),    );    Sse::new(stream)}この実装は、Webアプリケーションとバックエンドサービスを統合する優れた例です。単方向チャネルの活用：tokio::io::simplexを使って、クライアントからサーバーへの通信とサーバーからクライアントへの通信を分離しています。これは各方向の流れを独立して最適化できるようにします。バックグラウンドタスク：MCPサーバーをtokio::spawnを使ってバックグラウンドタスクとして実行しています。これによりWebハンドラーは応答を待つことなく、すぐにSSEストリームを返すことができます。SSEストリームの構築：futures::stream::onceと.chain()を組み合わせて、初期メッセージと継続的なメッセージストリームを連結しています。これはストリーミングAPIの標準的なパターンです。この実装パターンは、MCPサーバーをWebアプリケーションに統合する効果的な方法を示しています。特に注目すべきは、非同期処理とストリーミングを効果的に組み合わせている点です。SDKの設計思想分析このSDKの実装から、いくつかの重要な設計思想が読み取れます。堅牢性と型安全性への徹底したこだわりこのSDKは、Rustの型システムを徹底的に活用して堅牢性を確保しています。トレイト境界（Send + Sync + 'staticなど）の明示的な指定ジェネリックパラメータを使ったAPI設計Result型による包括的なエラーハンドリングasync/awaitとFutureの適切な組み合わせこれらの特徴は、SDKの開発者がRustの強みをよく理解し、それを活かそうとしていることを示しています。特に、コンパイル時に多くのエラーを捕捉できるように設計されており、実行時の予期せぬ動作を最小限に抑える工夫が随所に見られます。拡張性と将来性を考えた設計SDKは将来の拡張を見据えた柔軟な設計になっています。トランスポート層の抽象化サービス層の分離とミドルウェアのサポートプラグイン可能なツール定義このような設計により、MCPプロトコル自体が進化しても、SDKを大きく書き換えることなく対応できるでしょう。また、ユーザーが独自の機能を追加するための拡張ポイントが多く用意されています。開発者体験の重視SDKは、使いやすさにも重点を置いています。マクロによるボイラープレートコードの削減直感的なビルダースタイルAPI豊富なデフォルト実装これらの機能は、SDKを使う開発者の負担を軽減し、本質的なビジネスロジックに集中できるようにするための工夫です。特に#[tool]マクロは、開発者体験を大幅に向上させる優れた例です。パフォーマンスへの配慮実装には、パフォーマンスを考慮した数々の工夫が見られます。大きなバッファサイズ（2MB）の使用非同期I/Oの全面採用ロックの最小化と効率的な並行処理これらの最適化は、MCPが大量のデータや複雑なコンテキストを扱うAIユースケースを想定していることを示唆しています。優れた実装パターンのまとめこのSDKから学べる優れたRust実装パターンをまとめましょう。1. 関心の明確な分離SDKは複数のクレートに分かれており、各クレートが明確な責任を持っています。これは保守性と再利用性を高める優れた設計原則です。2. トランスポート抽象化異なる通信方法（Stdio、SSEなど）を統一的なインターフェースで扱うための抽象化は、拡張性と柔軟性の高いコードを書くための良い例です。3. Tower ServiceパターンTowerのサービス抽象化を活用して、ミドルウェアの組み合わせやサービス合成を容易にする設計は、現代的なRustサーバー実装のベストプラクティスです。4. プロシージャルマクロの効果的な活用ボイラープレートコードを削減し、宣言的なスタイルでコードを書けるようにするマクロの活用は、開発者体験を向上させる優れた方法です。5. 非同期プログラミングのベストプラクティスPin、Box<dyn Future>、async_traitなどを適切に組み合わせた非同期処理の実装は、Rustの非同期プログラミングの洗練されたパターンを示しています。おわりにMCP Rust SDKの内部実装を深掘りすることで、Rustの強力な型システムと非同期プログラミングモデルを最大限に活用した素晴らしい設計パターンを学ぶことができました。このSDKは、「型安全性」「拡張性」「使いやすさ」「パフォーマンス」のバランスが優れており、大規模なRustアプリケーションを設計する際の参考になります。特に、トランスポート抽象化、サービス指向設計、プロシージャルマクロの活用は、他のRustプロジェクトでも応用できる価値のある実践例です。MCPプロトコルの実装を検討している方はもちろん、Rustでの堅牢なライブラリ設計に興味がある方にとっても、このSDKのコードベースは探求する価値のある宝庫と言えるでしょう。次回のブログではサンプルを見ながら実際に色々動かしてみたいと思います。syu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetesで実現できるPlatform Engineering の現在地]]></title>
            <link>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</link>
            <guid>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</guid>
            <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: Kubernetesで実践する Platform Engineering - FL#88- 公式URL: https://forkwell.connpass.com/event/348104/🗣️ 関連スライド- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite- Platform Engineeringは自由のめまい- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimのファジーファインダーtelescope.nvimでよく使っているpicker集]]></title>
            <link>https://blog.atusy.net/2025/03/25/nvim-telescope-pickers/</link>
            <guid>https://blog.atusy.net/2025/03/25/nvim-telescope-pickers/</guid>
            <pubDate>Tue, 25 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Vim駅伝2025-03-24の記事です。1日遅れで申し訳ありません。さて、telescope.nvimは言わずと知れたファジーファインダーと呼ばれるものです。ファジーファインダーとは、ファイルなどの候補一覧から、検索などで欲しいものを絞りこみ、開くなり消すなり任意のアクションを実行するためのツールです。たしかそんなようなことをShougoさんがvim-jp ラジオの#7か#8で語ってたはず。良い話いっぱいなので、聞いてみてください。【Vimプラグイン作者・Shougoさん登場！】エンジニアの楽園 vim-jp ラジオ #7【Shougoさんが考えるプラグインのあるべき姿】エンジニアの楽園 vim-jp ラジオ #8vim-jpではまたファジーファインダーかと叫ばれるくらいには作者が多く、vim-jpにいらっしゃる方の作品だけでもShougo/ddu.vim、vim-fall/fall.vim、hrsh7th/nvim-deckなどがあります。それくらいには求めるところがユーザーによって変わるということでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[論文紹介 ”A Survey on Large Language Model based Autonomous Agents”]]></title>
            <link>https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents</link>
            <guid>https://speakerdeck.com/shukob/lun-wen-shao-jie-a-survey-on-large-language-model-based-autonomous-agents</guid>
            <pubDate>Mon, 24 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://genai-users.connpass.com/event/349197/この論文は大規模言語モデル（LLM）を基盤とする自律型エージェントに関する包括的な調査論文です。この論文は、LLMベースの自律型エージェントの現状、構成要素、課題、そして将来の展望について詳細に解説しています。本論文を読むことで、AIエージェントの概要を体系的に知ることができます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇してきました。　#信頼性向上_findy]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/21/204737</guid>
            <pubDate>Fri, 21 Mar 2025 11:47:37 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは、スリーシェイクのnwiizoです。2025年3月21日に開催されたFindyさん主催のイベントで登壇してきました。findy.connpass.comイベント概要このイベントは、SLI/SLOの導入と運用に焦点を当てたライトニングトーク形式のセッションでした。サービス品質を高めるためのSLI/SLOですが、組織内での運用がうまくいってないケースや導入タイミングに悩まれている方も多いのが現状です。本イベントではSLI/SLOについて向き合っていらっしゃる4名の皆様に、導入までの取り組みや運用上の課題とその解決策を共有していただきます。参加者にとって今後システムの信頼性向上に取り組んでいくための知識やヒントを得られるイベントになることを目指します。私を含めた4名のスピーカーによる多角的なアプローチで、SLI/SLOに関する実践的な知見が共有されました。とても良い会だったと思います。私の発表内容資料 speakerdeck.com👻本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」というタイトルで登壇します。こちら、資料になります。https://t.co/XtbFX2EOSH#信頼性向上_findy— nwiizo (@nwiizo) 2025年3月21日   発表の背景と位置づけこのイベントの準備にあたり、他の登壇者の方々の過去の発表や知見を事前に確認し、全体として何が語られるのかを予想してみました。技術的な実装方法や指標設計については他の方々が深く掘り下げられると考え、あえて私は「個人や組織への適用」という補完的な視点に焦点を当てることにしました。技術的な側面は重要ですが、実際にSLI/SLOが組織に定着するかどうかは、エンジニアリング以外の部分に大きく依存します。そこで今回は「技術をどう実装するか」ではなく「個人や組織をどう変革するか」という視点からSLI/SLOの旅を語ることにしました。発表の核心：三つの壁私の発表ではSLI/SLO導入における「三つの壁」に焦点を当てました1. 既存の習慣や方法からの変更を伴う壁「変化への抵抗」は克服すべき障害ではなく、理解し対話すべき自然な反応です。特に以下の4つの抵抗パターンを理解することが重要です。惰性による抵抗：「今のやり方で問題ない」労力による抵抗：「新しい方法を学ぶコストが高い」感情による抵抗：「自分の立場が脅かされる」心理的反発：変化に対する本能的な抵抗これらの抵抗に対して「北風」（強制）ではなく「太陽」（共感と対話）のアプローチが効果的です。2. 多くのステークホルダーとの協力が不可欠という壁SLI/SLOは技術だけの問題ではなく、むしろ組織の問題です。表向きは「全員で信頼性を高めましょう」という掛け声のもとで始まりますが、裏では様々な力学が働いています。部門間の隠れた対立構造：エンジニアリングは信頼性を重視し、プロダクトは新機能を優先し、経営層はコスト効率を求める。この三すくみの構造がSLI/SLO導入の最大の障壁になります。「会議では言えない本音」の存在：公式の場では皆が納得したように見えても、実際には「またエンジニアの自己満足では？」「数値のために本質を見失っている」といった潜在的な不信感が残ります。非公式なネットワークの重要性：公式のプロセスや説明会より、信頼関係のある個人間の非公式な対話の方が効果的なことが多いです。ランチタイムや1on1の場で地道に信頼関係を築く必要があります。技術と事業の懸け橋となる人材の重要性：各部門の言語を話せるクロスファンクショナルな理解者（技術と事業の両方を理解できる人）が不可欠です。このような架け橋となる存在を味方につけることが成功への近道になります。結局のところ、最も有効な戦略は「自分の専門領域を超えて相手の文脈で語る」ことです。技術者は事業KPIの言葉で、事業側は技術的制約の言葉で対話する努力が必要です。これが「信頼性は会話である」という言葉の本当の意味なのです。3. 目に見える成果が出るまでに時間がかかるという壁SLI/SLOの導入は短期決戦ではなく長期的な取り組みです。導入初期は一時的な作業量増加と基盤構築が先行本当の価値は6-12ヶ月後から現れることが多い「完璧なSLO」より「継続的に改善されるSLO」が重要長期的取り組みのためには、小さな成功の積み重ねと組織的なコミットメントが欠かせません。実務上の重要なポイントは、初期段階で期待値を適切に設定することです。多くの組織では「すぐに効果が出る」という期待から、半年程度で「効果がない」と判断されることがあります。これを防ぐには、短期的な小さな成功（例：アラート削減による疲労軽減）と長期的な大きな成功（例：システム安定性向上によるビジネス成長）の両方を明確に提示しておくことが重要です。発表を終えて今回のイベントでは、他の登壇者の方々もそれぞれの視点から素晴らしい発表をされていました。BASEのtandenさんがアラート品質の改善について、シンプルフォームの守屋さんが開発組織全体でのSLI/SLO実装について、ユーザベースの安藤さんがSREとCTOの両視点からのSLI/SLO活用について語られました。私は意図的に「組織文化と変革マネジメント」という視点から補完的に話すことで、イベント全体として技術から組織まで幅広い視点でSLI/SLOについて学べる場になったのではないかと思います。特に印象的だったのは、どの発表も「数値や指標そのものより、それを活用して何を実現するか」という本質的な部分を大切にしていたことです。形式的なSLI/SLO導入ではなく、真に組織とサービスの価値を高めるための取り組みとして捉えられていたのが印象的でした。まとめSLI/SLOの導入は一朝一夕にはいきません。それは旅のように、ゴールや完璧を目指すのではなく、継続的な前進が大切です。今日から始められることとしては：- 小さく始めて徐々に拡大する- まずは一つのサービスから- 既存の課題から出発するそして成功のための心構えとして：- 完璧よりも継続を重視する- 技術も情熱もどちらも大切- 信頼性は会話/対話から生まれるSLI/SLOの導入は技術的チャレンジであると同時に組織的チャレンジです。小さな一歩から始めて、組織全体で信頼性文化を育んでいきましょう。なお、SLI/SLOの基本概念から実践的な導入方法までを体系的に学ぶには、以下の書籍を必ず一読していただきたいと思います。組織への適用を考える前に、まずはこの本で基礎をしっかり固めることをお勧めします。www.oreilly.co.jpこれらのポイントを心に留めながら、組織にSLI/SLOを適用する旅を続けていきましょう。おわりにまた、他の登壇者の皆さんの発表資料も大変参考になりましたので、ぜひご覧ください。BASEの@tac_tandenさんによる「SLI/SLOの設定を進めるその前に、アラート品質の改善に取り組んだ話」では、SLI/SLO導入の前段階としてのアラート品質向上について詳しく解説されています。SREピラミットの下には常にモニタリングがあり自分の経験からも何よりも重要だと思っています。 speakerdeck.comシンプルフォームの守屋邦昭さんによる「開発組織全体で意識するSLI/SLOを実装している話」では、組織全体でのSLI/SLO実装について具体的な事例が紹介されています。 speakerdeck.comユーザベースの安藤裕紀さんによる「SREとしてSLI/SLOをどう普及してきたか、CTOとしてSLI/SLOをどう活用しているか」では、SRE視点とCTO視点の両面からSLI/SLOの活用方法が解説されています。個人的には俯瞰度合いが好きです。www.docswell.com最後までお読みいただき、ありがとうございました！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishの補完をコマンドラインの内容に応じて変える]]></title>
            <link>https://blog.atusy.net/2025/03/21/fish-completion-considering-tokens/</link>
            <guid>https://blog.atusy.net/2025/03/21/fish-completion-considering-tokens/</guid>
            <pubDate>Fri, 21 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishで補完を定義するとき、コマンドに指定された引数によって補完候補を変えたいことがあります。たとえばメインコマンドの直後だったらサブコマンドを補完したい、--input-fileの後だったらファイル名を補完したいとかいうことありますよね。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SLI/SLO・ラプソディあるいは組織への適用の旅]]></title>
            <link>https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu</link>
            <guid>https://speakerdeck.com/nwiizo/slorapusodeiaruihazu-zhi-henoshi-yong-nolu</guid>
            <pubDate>Thu, 20 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、花粉症が辛いです。登壇する時にくしゃみしないために朝から外出を自粛してます。15分なのにスライドが40枚あります。本日、「信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～」というイベントで「SLI/SLO・ラプソディあるいは組織への適用の旅」🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: 信頼性向上の第一歩！～SLI/SLO策定までの取り組みと運用事例～- 公式URL: https://findy.connpass.com/event/345990/📚 さらに！4日後の3月25日には翻訳した書籍に関する登壇する別イベントもあります！😲「Kubernetesで実践する Platform Engineering - FL#88」🐳⚙️興味がある方はぜひ参加してください！👨‍💻👩‍💻👉 https://forkwell.connpass.com/event/348104/お見逃しなく！🗓️✨]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishの関数で関数外の変数を利用する]]></title>
            <link>https://blog.atusy.net/2025/03/20/use-outer-scope-vars-in-fish/</link>
            <guid>https://blog.atusy.net/2025/03/20/use-outer-scope-vars-in-fish/</guid>
            <pubDate>Thu, 20 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025-03-21時点で最新のFish 4.0.1のデフォルト挙動では、関数が外界のローカル変数を参照できません。ためしに、関数fの外で定義した変数のechoを試みてみると、何も表示されません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIといっしょ: 動作するきれいなコードを生成AIとつくる]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/19/201025</guid>
            <pubDate>Wed, 19 Mar 2025 11:10:25 GMT</pubDate>
            <content:encoded><![CDATA[※こちらは社内で発表したものを外部で登壇できるように修正したものです。はじめに2021年にGitHub Copilotが発表され、2022年に一般利用可能になって以来、生成AIはソフトウェア開発の世界に急速に浸透してきました。「動作するきれいなコード」はソフトウェア開発の理想とされてきましたが、生成AIの登場によってこの理想に到達する道筋が大きく変化しています。本記事では、テスト駆動開発の原典である『テスト駆動開発』の基本理念を踏まえ、生成AIとの協業によって「動作するきれいなコード」を実現する方法について考察します。「動作するきれいなコード」とは何かt-wada氏がSeleniumConf Tokyo 2019での基調講演で引用したように、テスト駆動開発のゴールは「動作するきれいなコード（Clean code that works）」です。Kent Beckによるテスト駆動開発の書籍の冒頭には、次のような一節があります。 speakerdeck.com「動作するきれいなコード」。Ron Jeffriesのこの簡潔な言葉が、テスト駆動開発（TDD）のゴールだ。動作するきれいなコードはあらゆる意味で価値がある「動作する」と「きれい」の2つの要素に分解すると、ソフトウェア開発においては以下の4つの象限が考えられます：きれいで動作する（理想）きれいだが動作しない（机上の空論）きたないが動作する（現実の妥協）きたなくて動作しない（最悪の状態）Kent Beckは、この目標に対して、天才的なプログラマならすぐに到達できるかもしれないが、一般のプログラマはすぐには書けないと述べています。そこで彼は分割統治法を提案し、まず「動作する」ことを優先し、その後「きれい」にすることを推奨しています。テスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon生成AIとテスト駆動開発の融合ソフトウェア開発における三種の神器t-wada氏の講演では、ソフトウェア開発において欠かせない三つの技術的な柱（三種の神器）が紹介されています。これらは生成AIと協働する際にも極めて重要な基盤となります。1. バージョン管理（Version Control）バージョン管理は、人間の記憶力の限界を補うために生まれました。バージョン管理システムは：いつ、誰が、どのような変更をしたかを記録異なるバージョン間の差分を可視化複数の開発者が同時に作業することを可能に過去の状態に簡単に戻れる安全網を提供生成AIとの協働においても、AIが生成したコードを適切に管理し、問題が生じた場合に以前の状態に戻れるようにするためにバージョン管理は不可欠です。2. テスティング（Testing）テスティングは人間の把握力の限界を補います。システムが複雑化するにつれ、変更が他の部分に与える影響を人間が完全に把握することは困難になります。テスティングにより：コードが予期通りに動作することを自動的に検証変更によるリグレッションを早期に発見設計の問題点を可視化リファクタリングの安全網を提供生成AIとの協業では、この安全網がさらに重要となります。AIが生成したコードが本当に要件を満たしているかを客観的に評価するためのテストは不可欠です。3. 自動化（Automation）自動化は人間の忍耐力の限界を補います。自動化により：繰り返し作業を機械に任せることで人間のエラーを減少開発プロセスの一貫性と再現性を確保開発速度の向上と時間の節約継続的インテグレーション・継続的デリバリ（CI/CD）を実現特に重要なのは、自動化がソフトウェア開発におけるガードレールとしての役割です。AIが生成したコードの品質、セキュリティ、パフォーマンスを自動的に検証することで、AIの「創造性」と「安全性」のバランスを取ることができます。三種の神器は、「あれば便利」という加点法ではなく、「なければ危険」という減点法の世界です。生成AI時代においても、これらの基盤があってこそ、安全かつ効率的な開発が可能になります。AIとの協業進化段階AIによる開発支援は、自動車の自動運転レベルに似た段階を経て進化しています：レベル0：AI支援なし - 従来の手動開発レベル1：AI支援（Chat） - LLMによる情報提供のみレベル2：AI支援（補完＋Chat） - GitHub Copilotなどの部分的補完レベル3：Agent（人間が支援） - AIが主に作業し、人間が確認・修正レベル4：Agent（人間の支援なし） - AIが自律的に開発レベル5：業務の完全自動化 - 要求からプロセス全体を自動生成2025年の開発環境は、主にレベル3〜4の間で推移しており、「副操縦士（Copilot）」から「操縦士（Pilot）」へと主役が交代しつつあります。生成AIの強みと限界生成AIの特性は以下のようにまとめられます：強み:膨大なコードパターンとベストプラクティスの学習自然言語からコードを生成する能力環境情報を参照し、実行結果から学習して修正する能力圧倒的な速度でのコード生成・実行・修正多言語・多フレームワークへの対応多様な実装アプローチの提案能力限界:ビジネスロジックやドメイン知識の理解が浅いコンテキストの保持と長期的な一貫性の維持が苦手複雑なコンパイラ制約がある言語での実装に課題「テストを無理に通そうとする」傾向参照の明示的な解決が苦手特にCLINEなどの環境統合型エージェントは、実行と修正のサイクルを驚くべき速度で回すことができ、「どんなエキスパートでも勝てないレベル」に達しつつあります。AIツールを使いこなすためには、「コンテキストを記述する能力」「ドメインを記述する能力」「AIの性能に対する直感」といった新しいスキルセットが求められます。zenn.devドライバー席を譲った後の新しい役割開発者が主導権（ドライバー席）をAIに譲った後、どのような新しい役割を担うべきでしょうか。助手席のナビゲーター最も有望なポジションは「助手席」です：AIに対して適切な指示と方向性を提供する生成された成果物の品質と整合性を評価するAIの能力を最大限に引き出すプロンプトエンジニアリングを行う後部座席への後退リスク一方で、単に「後部座席」に座り、AIの決定に従うだけの受動的な立場になるリスクも存在します：AIが示した選択肢から選ぶだけの存在に専門的理解が浅くなり、本質的な問題解決能力が衰える「運試し」と「結果責任」だけが残される状態 speakerdeck.comこの比喩はとても好きなので将来的には「お前は後部座席に座るなよ」とか言いそう。レッドボックスの内に対処する生成AIの発展に伴い、小説「BEATLESS」で描かれた「人類未到産物（レッドボックス）」の概念が現実味を帯びてきています。「超高度AIが生み出した、今の人類には理解できない超高度技術によってつくられた産物。「レッドボックス」という名称には、観測者から遠ざかる光が赤方偏移により赤から黒（赤外領域）へと変わるように、人類が必死に追いすがらなければいずれ遠ざかりブラックボックスになってしまうという意味が込められている。」現在のAIコーディングでも、AIが生成した複雑なコードや設計に対して、人間が「理解できない」状態に陥るリスクが現実化しつつあります。それらには以下のような対策が考えられます。意図的な単純化 - AIに「人間が理解できるようなシンプルな実装」を明示的に要求する解説の要求 - 実装だけでなく、その設計思想や動作原理の解説を求める段階的な理解 - 複雑な実装を小さな部分に分解して理解するテストによる挙動の可視化 - 振る舞いを詳細なテストで定義することで、ブラックボックス化を防ぐ継続的な学習 - AIが使用する最新の技術やパターンを人間側も学び続ける speakerdeck.comAIの能力が人間の理解を超えた「レッドボックス」となっても、その内部を理解するための努力を怠らないことが、「助手席」の位置を維持するために不可欠です。技術が人間から遠ざかっていくのを防ぐために、テスト駆動開発のような体系的なアプローチが重要な役割を果たします。ＢＥＡＴＬＥＳＳ 上 (角川文庫)作者:長谷 敏司KADOKAWAAmazonバイブス労働とAIコーディングバイブスコーディングとは何かAndrej Karpathy（OpenAI共同創業者）が提唱した"vibe coding"という概念が注目を集めています。「新しい種類のコーディングがあって、私はこれを"vibe coding"と呼んでいます。そこでは完全に"vibe（雰囲気、直感）"に身を任せ、指数関数的成長を歓迎し、コードそのものが存在していることさえ忘れてしまいます。」— Andrej Karpathyこのバイブスコーディングは、以下の特徴を持っています：自力で成果物を作り込まない - AIに指示を出すことに集中ノールックマージ - AIの提案を直感的に受け入れるエラー解決のアウトソース - 問題発生時にAIに解決を依頼理詰めな部分はAIに任せる - 人間は直感と判断に集中Andrej Karpathyが提唱する「バイブスコーディング」の考え方を適度に取り入れることで、生成AIとの協業をより効果的にできます。直感を大切に - AIとの対話では、時に論理的思考よりも直感が良い結果を生むことがある反復の高速化 - AIがエラー修正や実装変更を高速で行える特性を活かし、試行錯誤のサイクルを加速余分な労力の削減 - 自明な実装や定型コードの作成はAIに任せ、本質的な部分に集中創造的提案の受け入れ - AIが提案する予想外のアプローチに対してオープンな姿勢を持つただし、バイブスに任せすぎることなく、テストという客観的基準を常に維持することで、「ノリ」と「品質」の両立を図ります。特に、重要な意思決定やアーキテクチャに関わる部分では、専門知識に基づく判断を優先しましょう。blog.lai.soバイブス労働の広がりバイブスコーディングの概念は、プログラミングの領域を超えて様々な知識労働にも応用できる「バイブス労働」という新たなパラダイムを生み出しています。バイブス労働では、AIを活用して直感的かつ効率的に成果を生み出す働き方が可能になります。バイブス労働の特徴には以下のようなものがあります：プロンプトクラフティング - AIに適切な指示を出すスキルが新たな専門性として価値を持つ創造的監督 - 細部の実装よりも、全体の方向性や品質の判断に人間の能力を集中させる反復と共進化 - 人間とAIが互いにフィードバックを与え合いながら成果物を進化させていくメタ認知の重要性 - 自分の思考プロセスを客観視し、AIとの協業に最適な役割分担を模索するバイブス労働の時代においては、「コードを書く」「文章を作成する」といった直接的な生産活動よりも、「何を作るべきか」「どのような価値を提供するか」という本質的な問いに答えることにより多くの時間とエネルギーを費やすことが可能になります。これにより、人間の創造性と直感が最大限に発揮される新しい働き方が実現するでしょう。生成AIとのテスト駆動開発の実践テスト駆動開発（TDD）の基本サイクル「Red-Green-Refactoring」を生成AIと組み合わせると、以下のようなアプローチが考えられます：Red: AIを活用したテスト設計生成AIはこのステップで：ユーザーストーリーや仕様から、テストケースを提案自然言語からテストコードを生成人間が見落としがちなエッジケースを発見様々なテスト方法を提示人間は機能要件を明確に定義し、AIが提案するテストケースが要件を正確に反映しているか評価します。Green: AIによる実装の高速化生成AIはここで：失敗するテストを満たす実装コードを生成複数の実装アプローチを提案素早いプロトタイピングを実現テスト失敗時のデバッグを支援テストという明確な基準があるため、AIの出力の正確性を客観的に評価できます。Kent Beckの原則通り、まずはテストを通過することを優先し、きれいさは次のステップで追求します。Refactoring: AIと共にコードをきれいにするこのステップでは、生成AIは：コードの問題点や改善点を指摘し、リファクタリング案を提示適切なデザインパターンを提案命名、構造、コメントなどの品質向上策を提案パフォーマンス最適化を提案テストが引き続き成功することを確認しながら、コードの品質を向上させます。AIはコードの「きれいさ」に関する豊富な知識を持っていますが、プロジェクト固有の規約やアーキテクチャの理解には限界があるため、人間による最終確認が不可欠です。Tidy First? ―個人で実践する経験主義的ソフトウェア設計作者:Kent Beckオーム社Amazon生成AIとTDDの相性の良さ生成AIとテスト駆動開発には、以下のような相性の良さがあります：明確な評価基準 - テストがAIの出力の正確性を評価する客観的基準となる繰り返しのフィードバック - 小さなサイクルによる継続的改善がAIとの協業に適している段階的な複雑性の増加 - 単純から複雑へ進むアプローチがAIの能力を引き出す品質保証の自動化 - テストによる安全網でAIコードの品質を保証責任の分担 - 人間がテストで要件を明確にし、AIが実装を担当という自然な役割分担人間の尺度のリファクタリング - AIが生成した複雑なコードを、TDDを通じて人間が理解・保守しやすい形に整理できるプログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ作者:フェリエンヌ・ヘルマンス,水野貴明,水野いずみ秀和システムAmazon効果的な生成AI活用のためのプラクティス1. テスト優先の指示AIに実装を依頼する前にテストを先に書くよう指示することで、テスト駆動の流れを維持します。テストを通じて機能要件を明確に定義し、AIがその要件を正確に理解することを促します。2. 段階的な複雑性の増加単純なテストケースから始め、徐々に複雑なケースを追加していくアプローチがAIとの協業に効果的です。AIが問題を段階的に理解し、複雑性を徐々に取り入れることができます。3. リファクタリングの明示的な依頼具体的なリファクタリングの観点（命名の改善、重複の排除、可読性向上など）を指定すると良い結果が得られます。焦点を絞ることでAIはより的確な改善提案ができます。4. 小さなサイクルの維持小さな機能単位でテスト→実装→リファクタリングのサイクルを回すことで、問題発生時の影響範囲を限定し、修正を容易にします。短いサイクルは、AIにとっても理解しやすく、効率的な協業を促進します。5. 三種の神器を活用したAI協業ワークフローバージョン管理:AIが生成したコードを適切にコミットし、変更履歴を明確に残すAIの提案ごとにブランチを作成して比較検討問題発生時に以前の状態に容易に戻れるよう準備テスティング:先にテストコードを作成し、明確な目標を設定テストと実装の両方を継続的に改善テストカバレッジをモニタリングして品質保証自動化:CIパイプラインでAIコードの品質を自動検証静的解析とセキュリティスキャンでAIの盲点をカバー自動化されたガードレールで意図しない問題を防止三種の神器は、AIとの協業における品質と安全性を保証する基盤となります。6. 私が生成AIの時代にRustを選択する理由プログラミングRust 第2版作者:Jim Blandy,Jason Orendorff,Leonora F. S. TindallオライリージャパンAmazonテスト駆動開発は効果的ですが、テストだけではすべての不具合を検出できないという限界があります。特に生成AI時代において、型システムによる形式検証を提供するRustのような言語を選択することで、AIとの協業をより確実なものにできます。Rustの型システムは「軽量な形式検証」として機能し、テストでは捉えきれない問題を発見します。所有権と借用チェッカーによるメモリ安全性の数学的保証、代数的データ型による未定義状態の排除、トレイト境界によるコードの整合性の静的検証など、多くの利点があります。現時点では、生成AIがRustコードを一発でコンパイル通過させることは難しく、私の経験上も何度か修正が必要になることが多いです。しかし、これは欠点というよりも、Rustのコンパイラが持つ厳格なチェック機能が「ガードレール」として働いている証拠と言えるでしょう。AIが生成したコードでもコンパイラが厳密な検証を行うことで、多くの潜在的な問題が実行前に排除されます。Rustの型システムとテスト駆動開発は相互補完的な関係にあります。型システムがコード全体の整合性と安全性を保証し、テストがビジネスロジックの正確さを検証します。このような組み合わせにより、AIが生成したコードの品質担保と不具合検出の両面をカバーできます。テストだけでは見つけられない並行処理やメモリの問題も、Rustのコンパイラが捕捉してくれるのです。生成AI時代において、言語自体が提供する安全性保証は、人間のレビュー負担を軽減し、AIとの効率的な協業を実現します。コンパイラが通過するまでに何度か調整が必要でも、その過程自体がコードの品質向上に貢献していることを忘れてはなりません。ＲｕｓｔによるＷｅｂアプリケーション開発　設計からリリース・運用まで (ＫＳ情報科学専門書)作者:豊田優貴,松本健太郎,吉川哲史講談社Amazonおわりに生成AIとテスト駆動開発を組み合わせることで、「動作するきれいなコード」を効率的に実現できる可能性が広がっています。AIの創造性と生産性、人間の判断力と創造性を組み合わせるための鍵は、テスト駆動開発の原則と三種の神器という堅固な基盤です。t-wada氏の言葉を借りれば、「テスト駆動開発は、設計のひらめきが正しい瞬間に訪れることを保証するものではない。しかし、自信を与えてくれるテストときちんと手入れされたコードは、ひらめきへの備えであり、いざひらめいたときに、それを具現化するための備えでもある」のです。t-wada.hatenablog.jp生成AIはこの「備え」をより強固にする強力なパートナーとなります。AIとの協業においても、テスト駆動開発の原則を守りながら、AIの能力を最大限に活用することで、より良いソフトウェア開発が実現できるでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[uvでbrowser_useを使用した環境構築したり比べたりするけど責任は取れない。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/19/131957</guid>
            <pubDate>Wed, 19 Mar 2025 04:19:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめに三寒四温（さんかんしおん）というような天気が続いています。これは「三日寒くて四日温かい」という意味で、冬から春への移行期によく見られる気温の周期的な変動を表す言葉です。寒暖の差が激しいこの季節、AIに関しての情報収集よりみなさんが暖かい格好して体調崩さないほうが大切です。とはいえ、技術ブログなので技術的なことも書いていきます。今回はPythonのAI用ブラウザである「browser_use」ライブラリを使用して、AnthropicのClaude 3.5 SonnetとOpenAIのGPT-4oの情報収集能力を実際のコードとログで比較します。github.com実際になにかに使う場合にはドキュメントを読んで下さい。このブログはそのようなことに耐えられるように作られてはいません。docs.browser-use.com環境構築まず、uvを使って環境を構築します。uvはPythonの高速パッケージマネージャーで、依存関係の解決と仮想環境の構築が効率的に行えます。# 仮想環境を作成uv venv# 仮想環境を有効化（macOS/Linux）source .venv/bin/activate# 必要なライブラリをインストールuv pip install langchain-anthropic langchain-openai browser-use実装コードAnthropicのClaudeを使用するコード（3shake_ceo_anthropic.py）:import asynciofrom browser_use import Agentfrom langchain_anthropic import ChatAnthropicllm = ChatAnthropic(model_name="claude-3-5-sonnet-latest")task = "株式会社スリーシェイクのCEOのXアカウントを教えて下さい"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())OpenAIのGPT-4oを使用するコード（3shake_ceo_openai.py）:import asynciofrom browser_use import Agentfrom langchain_openai import ChatOpenAIllm = ChatOpenAI(model="gpt-4o")task = "株式会社スリーシェイクのCEOのXアカウントを教えて下さい"agent = Agent(    task=task,    llm=llm,)async def main():    await agent.run()asyncio.run(main())実行結果(uv run xx.py)Claude 3.5 Sonnet（Anthropic）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - Starting fresh with empty pageINFO     [agent] 🧠 Memory: Starting the task to find X (Twitter) account of 株式会社スリーシェイク's CEO. Step 1/100.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク company information on GoogleINFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO Twitter X"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO Twitter X" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Found search results showing the CEO's X accountINFO     [agent] 🧠 Memory: Found that the CEO of スリーシェイク is 吉田拓真 (Takuma Yoshida) and his X account is @taqqma_ikachan. Step 2/100.INFO     [agent] 🎯 Next goal: Visit the CEO's X profile to confirm informationINFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":19}}INFO     [controller] 🖱️  Clicked button with index 19: 吉田 拓真 / スリーシェイク (@taqqma_ikachan) / XINFO     [agent] 📍 Step 3INFO     [agent] 👍 Eval: Success - I have confirmed that this is indeed the X account of the CEO of スリーシェイクINFO     [agent] 🧠 Memory: Found and confirmed that 吉田拓真 (Yoshida Takuma) is the CEO of スリーシェイク and his X account is @taqqma_ikachan. His profile confirms he is the 代表取締役社長 (CEO) of スリーシェイク.INFO     [agent] 🎯 Next goal: Task completed - provide the answerINFO     [agent] 🛠️  Action 1/1: {"done":{"text":"株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。","success":true}}INFO     [agent] 📄 Result: 株式会社スリーシェイクのCEOのXアカウントは @taqqma_ikachan です。INFO     [agent] ✅ Task completedINFO     [agent] ✅ SuccessfullyGPT-4o（OpenAI）の実行ログINFO     [browser_use] BrowserUse logging setup complete with level infoINFO     [root] Anonymized telemetry enabled. See https://docs.browser-use.com/development/telemetry for more information.INFO     [agent] 🚀 Starting task: 株式会社スリーシェイクのCEOのXアカウントを教えて下さいINFO     [agent] 📍 Step 1INFO     [agent] 🤷 Eval: Unknown - The page is empty and there's no previous context to evaluate.INFO     [agent] 🧠 Memory: Need to find the X account of 株式会社スリーシェイク's CEO.INFO     [agent] 🎯 Next goal: Search for 株式会社スリーシェイク CEO Twitter account on Google.INFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO Twitter account"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO Twitter account" in GoogleINFO     [agent] 📍 Step 2INFO     [agent] 👍 Eval: Success - Google search is displaying links related to the CEO of 株式会社スリーシェイク and their X account.INFO     [agent] 🧠 Memory: Searching for 株式会社スリーシェイク CEO's Twitter account. Found potential link at index 26.INFO     [agent] 🎯 Next goal: Check the link at index 26 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":26}}INFO     [controller] 🖱️  Clicked button with index 26: 株式会社スリーシェイク (@3shake_Inc) / XINFO     [agent] 📍 Step 3INFO     [agent] ⚠ Eval: Failed - The page requires login to access the X account information.INFO     [agent] 🧠 Memory: Currently on the login page of X; unable to access 株式会社スリーシェイク's CEO account information directly without logging in.INFO     [agent] 🎯 Next goal: Search again for 株式会社スリーシェイク's CEO X account from another source.INFO     [agent] 🛠️  Action 1/1: {"search_google":{"query":"株式会社スリーシェイク CEO X account"}}INFO     [controller] 🔍  Searched for "株式会社スリーシェイク CEO X account" in GoogleINFO     [agent] 📍 Step 4INFO     [agent] 👍 Eval: Success - Found a link that likely refers to the CEO's X account.INFO     [agent] 🧠 Memory: Trying to access 株式会社スリーシェイク CEO's X account via the link available at index 25.INFO     [agent] 🎯 Next goal: Click on the link at index 25 to verify if it leads to the CEO's X account.INFO     [agent] 🛠️  Action 1/1: {"click_element":{"index":25}}INFO     [controller] 🖱️  Clicked button with index 25: 内村一行/3-Shake (@KAZUYUKIUCHIMU) / XINFO     [agent] 📍 Step 5INFO     [agent] 👍 Eval: Success - Reached the login page for the user's X account.INFO     [agent] 🧠 Memory: Identified the CEO's Twitter handle as @KAZUYUKIUCHIMU, but login is required to access more information.INFO     [agent] 🎯 Next goal: Provide the CEO's X account and complete the task.INFO     [agent] 🛠️  Action 1/1: {"done":{"text":"The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.","success":true}}INFO     [agent] 📄 Result: The CEO of 株式会社スリーシェイク, 内村一行, has an X account with the handle @KAZUYUKIUCHIMU.INFO     [agent] ✅ Task completedINFO     [agent] ✅ Successfullyコードとログの詳細分析browser_useの動作browser_useライブラリは、AIモデルをWebブラウジングと組み合わせて情報検索を行うエージェントを作成します。このライブラリはログを詳細に記録しており、AIの意思決定プロセスを追跡できます：🚀 Starting task: タスクの開始📍 Step N: 各ステップの開始🤷 Eval: ページの状態評価🧠 Memory: AIのタスク理解と記憶🎯 Next goal: 次の目標設定🛠️ Action: 実行するアクション📄 Result: 最終結果モデル間の違い1. 検索クエリの違いClaude: 株式会社スリーシェイク CEO Twitter XGPT-4o: 株式会社スリーシェイク CEO Twitter accountこの微妙な違いが、初期の検索結果に影響しました。2. 問題解決アプローチの違いGPT-4oは会社の公式アカウント（@3shake_Inc）をまず確認しようとしましたが、ログイン要求に遭遇して別の戦略に切り替えました。一方、Claudeは直接CEOのアカウントを検索してアクセスしました。3. 情報確認の徹底度Claudeはプロフィールにアクセスして「代表取締役社長」の肩書きを確認しましたが、GPT-4oは内村一行氏（実際は取締役）をCEOと誤認したままでした。技術的考察browser_useの利点詳細なログ: browser_useは各ステップを詳細にログに記録するため、AIの判断プロセスを追跡できます。シンプルなAPI: わずか数行のコードでAIエージェントを作成でき、異なるモデルの比較テストが容易です。多様なモデルサポート: browser_useは複数のAIモデルをサポートしており、異なるモデル間の比較が容易です。docs.browser-use.com改善ポイントログから以下の改善点が考えられます：1.検索クエリの最適化# より精度の高いクエリを指定task = "株式会社スリーシェイク 吉田拓真 CEO Xアカウント"2. 複数情報源からの検証agent = Agent(    task=task,    llm=llm,    verify_sources=True,  # 複数ソースでの検証を促す（仮想的なパラメータ）)3. エラー時の代替戦略# ログイン画面に遭遇した場合の対処を明示的に指示agent = Agent(    task=task,    llm=llm,    login_strategy="search_alternative",  # ログイン要求時の戦略)実務への応用AIエージェントを活用する際は、以下の点に注意すると良いでしょう：1. 正確なプロンプトの設計# より具体的なタスク指定task = "株式会社スリーシェイクの代表取締役社長/CEOの公式Xアカウントを会社の公式情報から特定してください"2. 複数モデルでの検証# 複数モデルの結果を比較results = {}for model_name in ["claude-3-5-sonnet-latest", "gpt-4o"]:    agent = create_agent_for_model(model_name)    results[model_name] = await agent.run()# 結果の一致度を確認compare_results(results)3. 結果の人間によるレビュー:特に重要な意思決定には、AIの判断をそのまま信頼するのではなく、人間による最終チェックを行うプロセスを組み込むことが重要です。結果に責任が取れるような仕組みにはまだなっていなさそうです。テスト的になにかのチェックを行わせるというのは必要かと思いました。まとめ今回の実験では、特別なプロンプトエンジニアリングやチューニングを一切行わず、同じコードで二つのモデルを実行した結果を比較しました。思いつきで雑に実行しただけなのに、興味深い違いが出てきたのは面白いポイントです。Claudeは正確にCEOを特定した一方、GPT-4oは取締役を誤ってCEOと判断しました。この結果は、AIエージェントがまだ完璧ではなく、特に重要な情報収集には複数の検証プロセスを設けることの重要性を示しています。今後も気軽に試せるツールとして、browser_useとuvの組み合わせは便利そうです。特に複雑な設定や調整をしなくても、こうした比較実験が簡単にできるのが魅力的です。docs.browser-use.com注：コード例は概念的なものであり、実際のbrowser_use APIとは異なる場合があります。詳細は公式ドキュメントを参照してください。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rでトレースバックつきのエラーログをとる]]></title>
            <link>https://blog.atusy.net/2025/03/19/log-error-on-r/</link>
            <guid>https://blog.atusy.net/2025/03/19/log-error-on-r/</guid>
            <pubDate>Wed, 19 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[エラーログはエラーでユーザーに影響が発生した時に、何が起きたか記録する重要な情報源です。特にどこで問題が起きたか特定を容易にするトレースバックはログに欠かせません。ログをとらなくてもエラーは表示されるよと思いの方も、ログを使うとエラーの発生時刻は関連情報を同時に記録できるので、覚えていて損はないです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fishで非同期処理を実装してみる]]></title>
            <link>https://blog.atusy.net/2025/03/16/fish-async/</link>
            <guid>https://blog.atusy.net/2025/03/16/fish-async/</guid>
            <pubDate>Sun, 16 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishのプロンプトを自作していて、実行に時間がかかる場合に、非同期にプロンプトを更新できるか気になりました。軽く調べてみたところ、ユニバーサル変数を利用するといいよとのこと。]]></content:encoded>
        </item>
    </channel>
</rss>