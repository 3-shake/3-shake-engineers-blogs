<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Wed, 15 Nov 2023 18:31:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Infrastructure as Code, 2nd Edition のII. Working With Infrastructure Stacks 読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/16/015354</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/16/015354</guid>
            <pubDate>Wed, 15 Nov 2023 16:53:54 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の続きで第二部のWorking With Infrastructure Stacks (インフラストラクチャスタックとの作業)という部の読書感想文になります。まず、Stackってなんやねんと思うと思います。僕も思っています。前回の記事syu-m-5151.hatenablog.com書籍のリンクInfrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon第二部 目次II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)この章はインフラストラクチャスタックをコードとして構築する方法に焦点を当てています。Figure 5-1. An infrastructure stack is a collection of infrastructure elements managed as a group より引用What Is an Infrastructure Stack?インフラストラクチャスタックは、インフラリソースを単位として定義、プロビジョニングし、更新する集合体であり、スタック管理ツールによって一括で管理されます。スタック管理ツールには、HashiCorp Terraform, AWS CloudFormation, Azure Resource Manager, Google Cloud Deployment Manager, Pulumi などがあります。AnsibleやChefなどの内部を上手に操作するツールはこれらには含まれません。そして、このStack管理ツールは現実ではほぼ使いません。Stack Codeスタックコードはスタックの構造を記述するソースコードであり、インフラプラットフォームから提供されるリソースやサービスを宣言的に記述します。スタックコードは、インフラストラクチャの各要素をどのようにコード化するかを明確にし、変更が行われる際には、このコードに基づいてインスタンスが更新されます。Stack Instanceスタックインスタンスは、特定のスタックコードに基づいてプロビジョニングされたインフラリソースの具体的な実体です。インフラストラクチャの状態がコードで明確に定義されることにより、再現性と整合性を保つことが可能です。Configuring Servers in a Stackサーバー設定はインフラコードベースの重要な部分であり、コンテナベースやサーバーレスアーキテクチャではないシステムにおいて特に多くのコードが必要になります。Direct Infrastructure Management Languages & Abstraction-Level Infrastructure Languages直接インフラ管理言語は、インフラストラクチャプラットフォームが提供するリソースに直接対応し、抽象化レベルのインフラ言語は、基盤となるプラットフォームが提供するリソースに直接対応していないエンティティを定義します。たとえば、PaaSプラットフォームやパッケージ化されたクラスターは、より高い抽象レベルでリソースを管理する能力を提供します。Patterns and Antipatterns for Structuring Stacksインフラストラクチャスタックの構造化において取るべき適切なアプローチと避けるべき間違ったアプローチについて説明しています。Antipattern: Monolithic Stack (アンチパターン: モノリシックスタック)モノリシックスタックは、多くの要素を含む過大なインフラストラクチャスタックで、その管理が困難です。これはシステムの拡大とともに発生しやすく、一つのプロジェクトに新しい要素を単純に追加することで成長します。しかし、その結果、スタックのプロビジョニングや更新に時間がかかりすぎたり、変更時のリスクが高まるなどの問題が生じます。Pattern: Application Group Stack (パターン: アプリケーショングループスタック)アプリケーショングループスタックは、関連する複数のアプリケーションまたはサービスのインフラストラクチャをグループ化して管理します。これにより、システム内の複数のアプリケーションを単一の単位として扱い、管理を簡素化できます。しかし、アプリケーションごとの変更のリズムが異なる場合、不必要なオーバーヘッドやリスクを招く可能性があります。Pattern: Service Stack (パターン: サービススタック)サービススタックでは、デプロイ可能な各アプリケーションコンポーネントのインフラストラクチャを個別のスタックで管理します。これにより、サービスごとの変更を独立して行えるため、変更管理のリスクが局限され、チームがそれぞれのソフトウェアに関連するインフラストラクチャを所有することが容易になります。Pattern: Micro Stack (パターン: マイクロスタック)マイクロスタックでは、単一サービスのインフラストラクチャを複数のスタックに分割します。これにより、サービスの異なる部分が異なるレートで変更されたり、管理が別々に簡単になるなど、さらなる柔軟性と管理のしやすさを提供します。ただし、スタックの数が増えることで生じる追加の複雑性を管理する新たな課題もあります。これらのパターンとアンチパターンは、スタックのサイズと構造をどのように決定するかについての考慮点を提供し、スタックの管理とスケーラビリティのバランスを最適化する方法を示しています。この章では、インフラストラクチャの自動化におけるスタックの重要性と管理方法を明確にし、スタックの構築と管理に関する技術的な洞察と実践的な指針を提供します。6. Building Environments With Stacks (スタックで環境を構築する)インフラストラクチャスタックを用いて環境を構築する方法について詳しく説明されています。この章は、ソフトウェア開発と運用の現場で経験した実践的な課題と、それを解決するためのインフラコード化の知見を踏まえ、環境構築の理論と手法を提供します。Figure 6-1. ShopSpinner delivery environmentsより引用What Environments Are All About環境は特定の目的に沿って組織されたソフトウェアとインフラリソースの集合体であり、例えばテストフェーズをサポートするため、または地理的な地域でサービスを提供するために使用されます。スタックまたはスタックのセットは、これらのインフラリソースのコレクションを定義し、管理する手段であり、環境を実装するために使用されます。"An environment is a collection of software and infrastructure resources organized around a particular purpose, such as to support a testing phase, or to provide service in a geographical region." (環境とは、テストフェーズをサポートしたり、地理的な地域でサービスを提供したりするなど、特定の目的の周りに組織されたソフトウェアとインフラリソースの集合体です。)Patterns for Building Environments環境を構築するためのパターンでは、環境とスタックの実装方法についてのアンチパターンとパターンが説明されています。Antipattern: Multiple-Environment Stack (アンチパターン: 複数環境スタック)複数環境スタックは、単一のスタックインスタンスとして複数の環境のインフラストラクチャを定義し、管理するものです。これは、新しいスタックツールを学習している際に直感的に行われがちな構造ですが、コード内のミスや依存関係の予期せぬ発生により、インスタンス内の全てが影響を受けるリスクがあります。Antipattern: Copy-Paste Environments (アンチパターン: コピペ環境)コピペ環境アンチパターンは、各インフラストラクチャスタックインスタンスに対して別々のスタックソースコードプロジェクトを使用するものです。これにより、コードの重複や一貫性の欠如が生じ、環境間での構成のズレによるテストやデプロイメントプロセスの信頼性が低下する可能性があります。Pattern: Reusable Stack (パターン: 再利用可能スタック)再利用可能スタックは、複数のスタックインスタンスを生成するために使用されるインフラソースコードプロジェクトです。これにより、スタックコードに加えた変更を一つのインスタンスでテストし、その後同じコードバージョンを使用して複数の追加インスタンスを作成または更新することができます。この章は、インフラストラクチャスタックを使用して環境を効果的に実装するための戦略と、それに伴う潜在的な問題を特定し、解決する方法を提供します。インフラストラクチャスタックを活用した環境構築は、ソフトウェアのリリースプロセスのサポートや、地理的な分散によるスケーラビリティと耐障害性の向上に貢献します。7. Configuring Stack Instances (スタックインスタンスの設定)再利用可能なインフラスタックを複数の環境で効率的に運用するための構成管理について議論しています。この章では、インフラスタックのカスタマイズが必要なシナリオを想定し、環境ごとのユニークな設定をどのように実現するかを検討しています。Figure 7-1. Using the same code with different parameter values for each environment より引用Using Stack Parameters to Create Unique Identifiersスタックコードにパラメータを渡すことで、同一プロジェクトから生成される複数のスタックインスタンスがIDの衝突を避けられるよう、一意性の確保を目指しています。このアプローチは、インフラストラクチャのコード化の原則「全てを再現可能にする」を実現する上で重要な役割を果たします。"Consistency across environments is one of the main drivers of Infrastructure as Code." (環境間の一貫性は、インフラストラクチャのコード化の主要な推進力の一つです。)Patterns for Configuring Stacksスタック構成に関するパターンでは、スタックツールに構成値を効果的に渡すための複数のアンチパターンとパターンが提示されています。Antipattern: Manual Stack Parameters (アンチパターン: 手動スタックパラメータ)手動でパラメータを入力する方法は、簡便ですが、誤入力のリスクがあり、チーム内での構成値の一貫性を担保するのが難しいです。Pattern: Stack Environment Variables (パターン: スタック環境変数)スタックツールが使用するパラメータ値を環境変数として設定することは、実行前のセットアップを容易にし、またパラメータの可視性を向上させますが、その管理は別の機構に依存します。Pattern: Scripted Parameters (パターン: スクリプト化されたパラメータ)パラメータ値をスクリプトに埋め込むことで、環境ごとの一貫性を保証することができ、手動入力時の問題を避けられます。しかし、シークレット情報の扱いには注意が必要です。Pattern: Stack Configuration Files (パターン: スタック構成ファイル)パラメータファイルを用いることで、環境ごとにカスタマイズされた構成をバージョン管理することができます。これは、構成の監査と変更管理において非常に有効なアプローチです。Pattern: Wrapper Stack (パターン: ラッパースタック)ラッパースタックを用いることで、スタックコードの共有を促進し、変更を段階的に配布することができますが、この方法は追加の複雑さをもたらす可能性があります。Pattern: Pipeline Stack Parameters (パターン: パイプラインスタックパラメータ)パイプラインツールを活用してスタックコードを環境に適用する場合、パイプラインの構成にパラメータ値を定義することで、一貫性を保ちつつ効率的に構成を管理できます。Pattern: Stack Parameter Registry (パターン: スタックパラメータレジストリ)中央のレジストリにパラメータ値を格納することで、スタックのインスタンス構成情報を一元管理し、システム全体の設定変更に対する可視性と監査性を向上させます。スタックの再利用は、一貫性のある構成管理を実現する上で重要です。異なるスタックインスタンスが大幅に異なる場合には、それぞれを異なるスタックとして定義することが推奨されます。この章を通じて、スタックパラメータの管理と適用のアプローチが多様であることが明らかになりました。特にセキュリティに関する配慮が必要な部分では、最初から安全な取り扱いを心がける必要があると強調されています。システムやチームの成熟度に応じて適切な構成管理のアプローチを選択することが重要だと感じます。環境やチーム間での一貫性を保ちつつ、セキュリティを確保するための実践的なアドバイスを得ることができました。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)継続的なテストとデリバリーはインフラストラクチャコードの品質を維持し、信頼性を高めるための不可欠な実践です。アジャイルの原則に沿い、小さな変更を頻繁にテストし、即座にフィードバックを得ることで、品質を段階的に向上させていくことが強調されています。このプラクティスは、開発者が直面する潜在的な問題を早期に特定し、修正することを可能にし、最終的にはより安定したインフラストラクチャの配信につながります。長期的には、このアプローチはリリースプロセスの効率化と、エラー発生時の迅速な対応を促進します。Why Continuously Test Infrastructure Code?継続的なテストは、インフラストラクチャを一貫して信頼できる状態に保つために不可欠です。インフラストラクチャが変化し続ける環境では、変更の配信を効果的に行う上で重要なテスト自動化のスイートを構築することが求められます。このプロセスは、開発から運用に至るまでのライフサイクル全体を通じてインフラストラクチャの品質を確保し、継続的な改善を促進するための基盤となります。テストの自動化は、未来の変更に対しても柔軟に対応できる堅牢なインフラを構築する上で、決定的な役割を果たします。What Continuous Testing Means継続的なテストは、品質をコードライティングプロセスに組み込むことで、問題を早期に発見し解決することを意味します。このアプローチは、開発者がコードを書く際にリアルタイムでフィードバックを得られるようにし、問題の迅速な特定と修正を可能にします。この即時性は、システム開発における迅速なイテレーションと改善を実現し、技術的負債の蓄積を避けることを目指します。What Should We Test with Infrastructure?インフラストラクチャのテストは、機能性だけでなく、セキュリティやコンプライアンス、パフォーマンスなど、幅広いリスクの管理を包括します。CDプロセスでは、これらのリスクをリリース前にテストし、潜在的な問題を事前に特定し修正することで、プロダクション環境へのリスクを最小限に抑えることを目指します。Challenges with Testing Infrastructure Codeインフラストラクチャコードのテストにはいくつかの課題があり、これらはしばしばデリバリーの速度と品質に影響を与えます。デクララティブなコードのテストが低価値であること、テストプロセスが遅いこと、そして依存関係による複雑さがそれらです。Challenge: Tests for Declarative Code Often Have Low Valueデクララティブなコードのテストは冗長な場合が多く、実際のリスクの特定や管理にはあまり寄与しません。テストはリスクを管理するためのものであり、単なるコードの繰り返しではないため、デクララティブなコードに対しては、より高いレベルのリスク分析とそれに基づいたテスト戦略が求められます。Challenge: Testing Infrastructure Code Is Slowインフラストラクチャコードのテストはプラットフォーム上でのインスタンスのプロビジョニングを必要とするため、遅延が生じる傾向があります。テストプロセスの速度を向上させるためには、小さなコンポーネントに分割し、依存関係を最小限に抑えることが重要です。Challenge: Dependencies Complicate Testing Infrastructure依存関係はインフラテストの複雑さを増大させます。モックやテストダブルなどを使用して依存関係をシミュレートすることで、テストの実施をより実用的かつ迅速にすることが可能です。Progressive Testing段階的なテストは、初期のシンプルなテストから始めて徐々に統合の範囲を広げる戦略です。テストピラミッドは、より低レベルのテストを多くし、高レベルの統合テストは少なくするべきだと提唱し、スイスチーズモデルは、複数のテストレイヤーが組み合わさることで、単一レイヤーの穴を補完することを示します。これらのモデルは、リスクを管理するために、どのステージでどのテストを行うべきかを考える上で役立ちます。Figure 8-1. Scope versus speed of progressive testing より引用Infrastructure Delivery PipelinesCDパイプラインは、プログレッシブテストとデリバリーを組み合わせたもので、自動化により一貫性を保ちます。パイプラインの各ステージは特定のトリガーやアクティビティを持ち、適切なスコープとプラットフォーム要素を備えています。パイプラインの構築には、適切なソフトウェアまたはサービスが必要ですが、これによってインフラストラクチャの変更が効率的に、かつ一貫して配信されることが保証されます。Testing in Productionプロダクションでのテストは、他の環境では再現できないリアルな条件下でのリスクを検証する機会を提供します。プロダクション環境には再現できない要素が多く存在し、これらを通じてリアルタイムでのリスク管理を実施することができます。プロダクションでのテストに伴うリスクを管理するためには、監視、可視性の向上、ゼロダウンタイムデプロイメント、プログレッシブデプロイメント、データ管理、カオスエンジニアリングなどの戦略が不可欠です。インフラストラクチャのテストは、その構築と運用の基盤です。この章ではインフラストラクチャのテストに関する一般的な課題とアプローチについて説明しましたが、テストとQAはインフラストラクチャアズコードの成功に不可欠なため、これらの分野に関するさらなる知識を深めることが推奨されます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)9. Testing Infrastructure Stacksこの章の焦点は、インフラストラクチャスタックのテストにあります。現代のソフトウェア開発では、インフラストラクチャのコードもアプリケーションのコードと同様に継続的にテストされるべきであるという考え方が強調されています。これはSREの実践においても極めて重要で、システムの安定性と効率性を保つためには、テストの自動化と継続的な改善が不可欠です。Example Infrastructureここでは、具体的なインフラストラクチャの例としてShopSpinnerのケースが紹介されます。この例を通して、リアルなインフラストラクチャの構築と管理の課題を理解することができ、特に再利用可能なスタックの概念が実際のプロジェクト管理においてどのように役立つかが明らかになります。The Example StackShopSpinnerのスタックの具体的な構成を示すセクションです。ここでの重要なポイントは、効率的なリソース管理とスタックのモジュール化の重要性です。これらの概念は、大規模なシステムにおいてコードの再利用性とメンテナンス性を高めるために重要です。Pipeline for the Example Stackこのセクションでは、ShopSpinnerのインフラストラクチャスタックに対するパイプラインの設計について説明されています。パイプラインの構成は、継続的インテグレーション（CI）と継続的デリバリー（CD） の実践に欠かせない要素であり、効率的な開発プロセスを実現するためのキーです。Figure 9-1. Simplified example pipeline for a stack より引用Offline Testing Stages for Stacksオフラインテストは、インフラストラクチャスタックの開発段階において、コードの品質を確保するために非常に重要です。この段階では、ネットワーク接続や実際のリソースへのアクセスなしにテストを行います。Syntax Checkingシンタックスチェックは、最も基本的ながらも重要なテストの一つです。このプロセスは、コード内のタイポや文法の誤りを迅速に特定し、より大きな問題が発生する前に修正する機会を提供します。Offline Static Code Analysis静的コード分析は、より高度なエラー検出やコーディングスタイルの改善に役立ちます。これにより、コードの品質とセキュリティが大幅に向上します。Static Code Analysis with APIAPIを用いた静的コード分析は、特定のインフラストラクチャプラットフォームに対するコードの適合性をテストするために重要です。これにより、実際の環境へのデプロイ前に潜在的な問題を特定できます。Testing with a Mock APIモックAPIを使用するテストは、実際のAPIとの統合前に、コードが期待通りに機能するかどうかを検証するのに役立ちます。これは、特に大規模なシステムでの統合テストにおいて重要です。Online Testing Stages for Stacksオンラインテストは、実際のインフラストラクチャや外部サービスとの統合を伴うテストです。これにより、オフラインテストでは捉えきれない実際の環境での動作を確認できます。Preview: Seeing What Changes Will Be Made変更のプレビューは、実際にコードを適用する前に、どのような変更が行われるかを確認するプロセスです。これは、特にインフラストラクチャの変更に伴うリスクを軽減するために重要です。Verification: Making Assertions About Infrastructure Resourcesインフラストラクチャリソースに関するアサーションの作成は、スタックが正しく設定されていることを検証するための手段です。これにより、システムの整合性とパフォーマンスを保証できます。Outcomes: Proving Infrastructure Works Correctlyインフラストラクチャが正しく機能していることを証明するためのテストは、最終的なユーザーエクスペリエンスに直接関連するため、非常に重要です。これにより、実際の環境でのインフラストラクチャの振る舞いを確認できます。Using Test Fixtures to Handle Dependenciesテストフィクスチャを使用して依存関係を処理する方法は、テストプロセスの複雑さを軽減し、より継続的かつ効率的なテスト環境を構築するための効果的なアプローチです。Test Doubles for Upstream Dependencies上流依存関係に対するテストダブルは、実際の依存関係なしでスタックをテストするための仮想的な環境を提供します。これは、開発プロセスの柔軟性を大幅に高めます。Test Fixtures for Downstream Dependencies下流依存関係に対するテストフィクスチャは、他のスタックが利用するリソースを提供するスタックのテストに役立ちます。これにより、インフラストラクチャ間の統合テストの精度が向上します。Refactor Components So They Can Be Isolatedコンポーネントをリファクタリングして単独でテストできるようにすることは、コードの品質と保守性を向上させるために重要です。これにより、システム全体の堅牢性が向上します。Life Cycle Patterns for Test Instances of Stacksスタックのテストインスタンスのライフサイクルパターンは、テスト環境の管理と最適化に関する洞察を提供します。これにより、リソースの使用効率とテストプロセスの効率が向上します。Pattern: Persistent Test Stack持続的テストスタックパターンは、安定したテスト環境を提供するが、時間が経つにつれて問題が発生する可能性があります。継続的なメンテナンスと監視が必要です。Pattern: Ephemeral Test Stackこのセクションは、エフェメラルテストスタックのパターンに焦点を当て、テストのたびに新しいインスタンスを作成して破棄する方法を提案します。このアプローチは、クリーンな環境を保証し、過去のテストからの"クラッター"（不要なデータや設定）による影響を排除します。私の経験から言うと、この方法は、特に頻繁に変更されるコードベースにおいて、信頼性と一貫性のあるテスト結果を提供するのに非常に有効です。しかし、新しい環境を都度設定するための時間コストは考慮する必要があります。特に、大規模なインフラストラクチャの場合、セットアップに時間がかかり、フィードバックループを遅くする可能性があります。Antipattern: Dual Persistent and Ephemeral Stack Stagesここで取り上げられているのは、永続的スタックとエフェメラルスタックの両方を組み合わせたアンチパターンです。この方法は、理論上は早急なフィードバックと堅牢なテスト環境の両方を提供するはずですが、実際には両方のアプローチの欠点を引き受けることになります。例えば、永続的スタックのインスタンスが"ウェッジ状態"（変更によって不安定な状態）になると、エフェメラルスタックステージがその安全網となる可能性があります。しかし、これはリソースの二重消費を招くだけでなく、結局のところ、チームは永続的スタックの問題を解決するために時間を費やさなければならない場合があります。Pattern: Periodic Stack Rebuild定期的なスタック再構築のパターンは、永続的なテストスタックを定期的に再構築することで、リソースの使用量の蓄積や、更新プロセスの信頼性の低下を防ぐことを目的としています。このアプローチは、特にメモリやストレージがテストの実行に伴い徐々に消費される場合に効果的です。ただし、これは根本的な問題を覆い隠す一時的な解決策であり、問題の本質的な解決には至らないことに注意が必要です。Pattern: Continuous Stack Reset連続スタックリセットのパターンは、各テストステージの完了後にスタックインスタンスを自動的に破棄し再構築することで、常にクリーンな状態を保つことを目指しています。この方法は、テスト実行のたびに一から環境を構築する時間を節約できる一方で、背後で発生する問題を見落とすリスクがあります。例えば、バックグラウンドでのインスタンス破棄が失敗した場合、次回のテスト実行時に問題が顕在化する可能性があります。Test Orchestrationテストオーケストレーションに関しては、テストフィクスチャの作成、テストデータのロード、テストスタックインスタンスのライフサイクル管理、テストツールへのパラメータ提供、テストツールの実行、テスト結果の統合、テストインスタンス、フィクスチャ、データのクリーンアップなど、多岐にわたる活動が含まれます。このセクションは、これらの複雑なプロセスを効率的に管理するための実践的なガイダンスを提供しています。Support Local Testingローカルテストのサポートは、開発者が共有パイプラインや環境にコードをプッシュする前に自分でテストを実行できるようにすることを目的としています。これは、特にクラウドベースのインフラストラクチャで働く開発者にとっては不可欠です。ローカルでのテストは、より迅速なフィードバックを可能にし、開発プロセスの効率を大幅に向上させることができます。Avoid Tight Coupling with Pipeline Toolsパイプラインツールとの密接な結合を避けることは、テストオーケストレーションの柔軟性と再利用性を保つ上で非常に重要です。パイプラインツールにテストを強く結びつけると、テストのセットアップや実行をパイプライン外で行う際に困難が生じることがあります。テストオーケストレーションを独立したスクリプトまたはツールで実装することは、パイプラインオーケストレーションとテストオーケストレーションの関心を適切に分離するのに役立ちます。Test Orchestration Toolsテストオーケストレーションツールに関しては、多くのチームがカスタムスクリプトを書いてテストをオーケストレーションしています。これらのスクリプトは、Bashスクリプト、バッチファイル、Ruby、Pythonなど、さまざまな言語で記述されることがあります。しかし、特定のワークフローに特化して設計されたツール（例：Test Kitchen、Molecule）も存在しますが、自分のニーズに合わせて設定するのは難しいことがあります。この章全体を通して、インフラストラクチャスタックのテストに関する包括的な概観と、その実践的な実装について深く掘り下げられています。スタックコードのテストにはまだ十分に成熟したツールや実践が存在しない中、この章は、現在利用可能なツールやカスタムスクリプティングを活用して、これらの課題にどのように対処するかを示唆しています。これは、インフラストラクチャのテストプロセスに取り組む上での貴重な洞察を提供するものであり、非常に有用です。さいごに現代のソフトウェア開発と運用の中核となる要素、すなわちインフラストラクチャスタックの管理と運用について深く探究しています。このセクションは、インフラストラクチャコードの設計、開発、テスト、デプロイメントの各フェーズにおけるベストプラクティスと戦略を詳細に説明しており、現代のIT環境における効率性、スケーラビリティ、信頼性の実現に必要な知識とツールを提供します。特に注目すべきは、インフラストラクチャとアプリケーションの間の相互依存性の管理と、自動化されたテストプロセスの重要性に焦点を当てた点です。これらのトピックは、DevOps文化の中心であり、迅速かつ効率的なソフトウェアデリバリーを可能にする基盤となっています。また、パイプラインの設計とオーケストレーションのセクションは、コードの変更が生産環境にどのように流れるか、そしてそのプロセスをどのように最適化し、安全に保つかについての洞察を提供しています。この部分は、持続可能なインフラストラクチャ管理のための戦略的アプローチを明らかにし、リスクを最小限に抑えつつ高いパフォーマンスを実現する方法を提案しています。セクション全体を通して、可読性、再利用性、モジュール性の観点からインフラストラクチャコードを設計することの重要性が強調されています。コードの品質と管理性を高めることは、時間の経過と共にシステムのメンテナンスと進化を容易にします。また、セキュリティとコンプライアンスの考慮は、現代のインフラストラクチャスタックの設計と運用において不可欠な要素です。最終的に、このセクションは、インフラストラクチャスタックの管理における複雑性と挑戦に対処するための網羅的で実践的なガイドを提供しており、読者にとって非常に価値のあるリソースであると言えます。この知識を活用することで、ITプロフェッショナルはより強固で効率的なシステムを構築し、ビジネスの成長と変化に迅速に対応できるようになるでしょう。Infrastructure as Code, 2nd Editionの記事syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Infrastructure as Code, 2nd Edition の I. Foundations 読書感想文]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/15/134317</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/15/134317</guid>
            <pubDate>Wed, 15 Nov 2023 04:43:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめに2016年、初版の『Infrastructure as Code』がリリースされ、クラウド技術の運用における新たな標準をぶち立てました。公式サイトもここに置いておきます。infrastructure-as-code.com初版の2017年に日本語版がリリースされました。mizzy.orgそれから4年後、待望の『Infrastructure as Code, 2nd Edition』が登場した。この新版は、サブタイトルを「Managing Servers in the Cloud」から「Dynamic Systems for the Cloud Age」へと変更し、クラウド技術の進化と共に変わるシステム管理のダイナミクスに焦点を当てている。さらに、360ページから427ページへと内容が拡張され、より包括的な情報と洞察が提供されている。残念ながら、『Infrastructure as Code, 2nd Edition』の日本語版は現在提供されていませんがこの本はクラウドインフラストラクチャの管理に関して重要な洞察と知識を提供しており、その内容は多くの専門家や技術者にとって非常に価値があります。Infrastructure as Code: Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon『Infrastructure as Code』の第二版では、かつて新しい概念として導入されたインフラストラクチャとしてのコードが、今や世界中の企業、銀行や伝統的な組織を含めてクラウドへの移行が進む中で、開発チームが大規模なインフラコードベースの構築において不可欠なものとなっています。この改訂版は、DevOpsチームによって開発された原則、実践、パターンを活用し、クラウド時代に適したインフラの管理方法を明らかにしています。システム管理者、インフラエンジニア、ソフトウェア開発者たちに、クラウドと自動化技術を用いて、容易に、安全に、迅速に、かつ責任を持って変更を加える方法を教えます。また、コードとして全てを定義し、小さく疎結合な部品を組み合わせてシステムを構築する技術も伝えます。ただし、日本語版のリリースがなされず、次の第三版が出版される可能性があります。これはそういった悲しみの読書感想文でもあります。目次I. Foundations (基礎)1. What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)   - インフラストラクチャをコードで管理する概念とその重要性について説明します。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)   - クラウドインフラストラクチャ管理の基本原則を掘り下げます。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)   - 現代のインフラストラクチャプラットフォームの種類と特徴について論じます。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)   - インフラストラクチャ要素をコードとして定義する実践方法に焦点を当てます。II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)5. Building Infrastructure Stacks As Code (インフラストラクチャスタックをコードとして構築する)   - インフラストラクチャスタックをコードで構築するプロセスとテクニックを紹介します。6. Building Environments With Stacks (スタックで環境を構築する)   - スタックを使用して異なる環境を構築する方法を解説します。7. Configuring Stack Instances (スタックインスタンスの設定)   - 個々のスタックインスタンスを設定するための戦略とベストプラクティスを提供します。8. Core Practice: Continuously Test And Deliver (コアプラクティス：継続的なテストと提供)   - インフラストラクチャコードの継続的なテストと提供の重要性について論じます。9. Testing Infrastructure Stacks (インフラストラクチャスタックのテスト)   - インフラストラクチャスタックのテスト手法と戦略を紹介します。III. Working With Servers And Other Application Runtime Platforms (サーバーおよびその他のアプリケーションランタイムプラットフォームとの作業)10. Application Runtimes (アプリケーションランタイム)    - アプリケーションの実行環境に関する概要と管理方法を提供します。11. Building Servers As Code (サーバーをコードとして構築する)    - コードを使用してサーバーを構築する方法について詳しく説明します。12. Managing Changes To Servers (サーバーへの変更の管理)    - サーバーに加えられる変更を効果的に管理する戦略を提供します。13. Server Images As Code (サーバーイメージをコードとして)    - サーバーイメージをコード化するアプローチとその利点について解説します。14. Building Clusters As Code (クラスターをコードとして構築する)    - クラスターを効率的にコードで構築する手法について紹介します。IV. Designing Infrastructure (インフラストラクチャの設計)15. Core Practice: Small, Simple Pieces (コアプラクティス：小さく、単純な部品)    - 小さく単純な部品を使用してインフラストラクチャを設計する方法に焦点を当てます。16. Building Stacks From Components (コンポーネントからスタックを構築する)    - 個々のコンポーネントから効果的なスタックを構築するアプローチを提供します。17. Using Stacks As Components (スタックをコンポーネントとして使用する)    - スタックをコンポーネントとして活用するための戦略について説明します。V. Delivering Infrastructure (インフラストラクチャの提供)18. Organizing Infrastructure Code (インフラストラクチャコードの整理)    - インフラストラクチャコードを整理し管理する方法について論じます。19. Delivering Infrastructure Code (インフラストラクチャコードの提供)    - インフラストラクチャコードを効果的に提供する戦略について解説します。20. Team Workflows (チームワークフロー)    - チームがインフラストラクチャコードを管理し作業するためのワークフローについて紹介します。21. Safely Changing Infrastructure (インフラストラクチャの安全な変更)    - インフラストラクチャを安全に変更するための実践的なアドバイスを提供します。I. Foundations (基礎)What Is Infrastructure As Code? (インフラストラクチャとしてのコードとは何か？)この章は、現代のITインフラストラクチャの管理における根本的なシフトを示唆しています。クラウドとインフラストラクチャの自動化技術は、より迅速かつ信頼性の高い価値提供を可能にする一方で、管理するべきものの複雑さと多様性を増大させています。このジレンマは、組織がデジタル化するにつれて特に重要になってきています。「デジタル」という言葉は、ソフトウェアシステムが組織の活動に不可欠であることを意味します。これは私自身のソフトウェアエンジニアおよびSREとしての経験にも共鳴します。変更管理プロセスを厳格化することで混乱を防ごうとする試みは、しばしばクラウド技術の利点を損なうものです。「クラウドと自動化技術を利用して、変更を容易に、安全に、迅速に、そして責任を持って行うことができる」というこの本の前提は、特に重要です。この利点は、自動化ツールやクラウドプラットフォームというツールそのものからではなく、これらの技術の使い方に依存しています。印象的なのは、インフラストラクチャとしてのコード（IaC）が、ソフトウェア開発からの実践に基づいたインフラストラクチャの自動化へのアプローチであるという点です。これは、システムのプロビジョニングと変更およびその設定を一貫して、繰り返し可能なルーチンとして扱います。コードの変更を行い、それらの変更をシステムに自動的にテストし適用します。この章はまた、クラウド時代のインフラストラクチャへのアプローチが、速度と品質の間の偽のジレンマを排除する方法を説明しています。速度を品質向上の手段として利用し、品質を高速なデリバリーの可能性として利用します。また、このような言及が出てくるのもソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとして定着しているこの本ならではだなって思いました。t-wada.hatenablog.jp「クラウド時代のインフラストラクチャを管理するためには、クラウド時代のマインドセットが必要」というメッセージは、私の経験と完全に一致します。クラウド時代では、変更の速度を利用してリスクを減らし、品質を向上させる新しい考え方が求められます。このアプローチは、根本的なアプローチの変更と変更とリスクに対する新しい考え方を必要とします。"A fundamental truth of the Cloud Age is: Stablity comes from making changes."（クラウド時代の基本的な真理は：変更から安定性が生まれる）は、インフラストラクチャの管理における直感に反すると思いますが2023年の現在ではとても納得することが出来ます。未パッチのシステムは安定しているのではなく、脆弱であり、発見した問題をすぐに修正できない場合、システムは安定していないという考え方です。最後に、インフラストラクチャとしてのコードの3つのコアプラクティス：すべてをコードとして定義する、進行中のすべての作業を継続的にテストし提供する、そして、独立して変更できる小さくシンプルな部品を構築する、これらはインフラストラクチャの管理における新しい標準を示しています。この章を読んで、クラウド時代におけるインフラストラクチャ管理の新しい考え方とアプローチについての理解が深まりました。2. Principles Of Cloud Age Infrastructure (クラウド時代のインフラストラクチャの原則)この章は、クラウド時代のインフラストラクチャ設計と実装における基本原則を提示し、それらがどのように従来の「鉄の時代」のインフラストラクチャと異なるかを示しています。クラウド時代はコンピューティングリソースを物理的なハードウェアから切り離し、これらが仮想的な構成物として変更や破棄が可能になります。原則: Assume Systems Are Unreliable (システムが信頼できないと仮定する)クラウドスケールのインフラストラクチャでは、信頼性のあるハードウェアを使用しても障害は発生します。この原則は、根底のリソースが変化したときにも中断なくサービスを提供するための設計を必要とします。原則: Make Everything Reproducible (全てを再現可能にする)システムの回復性を高める一つの方法は、その部品を容易かつ信頼性高く再構築できるようにすることです。これによりテスト環境を本番環境と一致させたり、負荷の高い時に需要に応じてインスタンスを追加することが容易になります。落とし穴: Snowflake Systems (特殊なシステムの罠)スノーフレークシステムは再構築が困難なシステムのインスタンス、または本来似ているべき環境が理解できない方法で異なる環境を指します。これらのシステムはリスクを生み、管理するチームの時間を浪費します。原則: Create Disposable Things (廃棄可能なものを作る)ダイナミックなインフラストラクチャに対処するためのシステムを構築することは重要ですが、システム自体がダイナミックであることも重要です。部品を柔軟に追加、削除、開始、停止、変更、移動できるようにすることが重要です。原則: Minimize Variation (変動を最小限にする)システムが成長するにつれて、理解、変更、修正が難しくなります。多くの異なる種類の部品があるほど、作業は複雑になります。したがって、システムを管理しやすくするためには、異なる種類の部品を少なくすることが有用です。Configuration Drift (設定の変動)設定の変動は、かつて同一だったシステムが時間の経過とともに異なるようになることを指します。手動での変更や、一部のインスタンスにのみ自動化ツールを使用して行うアドホックな変更が原因で発生することがあります。原則: Ensure That You Can Repeat Any Process (任意のプロセスを繰り返せるようにする)再現性の原則に基づき、インフラストラクチャに対して行うあらゆる操作を繰り返せるようにする必要があります。スクリプトや設定管理ツールを使用して行動を繰り返す方が、手動で行うよりも簡単です。この章を読んで、クラウド時代のインフラストラクチャの原則が、伝統的なインフラストラクチャとどのように異なるか、そしてこれらの原則がどのようにクラウドプラットフォームの性質を最大限に活用する鍵となるかを理解しました。クラウドプラットフォームにおける変更の容易さを抵抗するのではなく、品質と信頼性を得るためにそれを利用することの重要性が強調されています。3. Infrastructure Platforms (インフラストラクチャプラットフォーム)この章では、クラウドインフラストラクチャの複雑さを解体し、その構成要素を理解しやすく分類しています。ここで提示されたモデルは、特定の技術やツールに依存することなく、概念やアプローチを議論するための文脈を作り出しています。これは非常に有益で、私たちが使用するテクノロジースタックやプラットフォームに関係なく、議論を関連性のあるものに保つために役立ちます。インフラストラクチャシステムの部品 (The Parts of an Infrastructure System)モダンなクラウドインフラストラクチャは、アプリケーション、アプリケーションランタイム、インフラストラクチャプラットフォームの3つの主要な層で構成されています。この分類は、インフラストラクチャの複雑な世界を整理し、各層がどのように組織全体の機能提供に寄与しているかを明確にします。Figure 3-1. Layers of system elements より引用"Applications and services provide capabilities to your organization and its users. Everything else in this model exists to enable this layer." (アプリケーションとサービスは、あなたの組織とそのユーザーに機能を提供します。このモデルの他のすべては、この層を可能にするために存在します。)はアプリケーション層が最終的な目標であり、アプリケーションランタイムとインフラストラクチャプラットフォームがその実現のための手段であることを示しています。これは、インフラストラクチャをただのサポート機能ではなく、組織の目的達成に不可欠な要素として位置づけている点で示唆に富んでいます。インフラストラクチャプラットフォーム (Infrastructure Platforms)このセクションは、インフラストラクチャとしてのコード実践において、ダイナミックなインフラストラクチャプラットフォームがいかに中心的な役割を担っているかを強調しています。クラウド技術は物理ハードウェアからの解放をもたらし、APIを通じた資源の管理を可能にしました。"Virtualization decoupled systems from the hardware they ran on, and cloud added APIs to manage those virtualized resources." (仮想化はシステムを実行しているハードウェアから切り離し、クラウドはこれらの仮想化されたリソースを管理するAPIを追加しました。)は仮想化とクラウドがどのようにしてインフラストラクチャの運用を変革したかを端的に表しています。APIによる管理は、リソースの柔軟な扱いを可能にし、インフラストラクチャの変更や拡張を以前に比べて格段に簡単にしました。インフラストラクチャリソース (Infrastructure Resources)インフラストラクチャプラットフォームが提供する計算、ストレージ、ネットワークという3つの基本リソースは、システムの基盤を形成します。これらのリソースは、仮想マシンやコンテナインスタンス、そしてデータベースインスタンスなど、さまざまな形で利用可能です。"The line between a primitive and a composite resource is arbitrary, as is the line between a composite infrastructure resource and an application runtime service." (プリミティブリソースとコンポジットリソースの間、またコンポジットインフラストラクチャリソースとアプリケーションランタイムサービスの間の線引きは任意です。)は、インフラストラクチャリソースのカテゴライズが一定の基準に基づいているわけではなく、使用する文脈や目的に応じて変わることがあるという点を浮き彫りにしています。重要なのは、これらのリソースをどのようにして有効に組み合わせ、運用するかということであり、そのためには柔軟性が必要です。全体を通して、この章はクラウドインフラストラクチャの理解を深め、それぞれの要素がどのように相互作用して機能するのかを示す貴重な洞察を提供しています。これらの知識は、インフラストラクチャとしてのコードを実践する上で、私たちが直面する課題への取り組み方や、利用可能な技術を選択する際の指針となります。4. Core Practice: Define Everything As Code (コアプラクティス：すべてをコードとして定義する)インフラストラクチャをコードとして定義する理由 (Why You Should Define Your Infrastructure as Code)エンジニアとして、インフラストラクチャをコードとして定義することの価値を語るのは、まるで自明の理だと感じます。しかし、このアプローチは私たちの仕事を根本的に変えました。初めて自動化スクリプトを書いたとき、それは単なる作業の簡略化ではなく、再利用可能性、一貫性、透明性をもたらしました。これは組織のアジリティを高め、変更を迅速かつ確実に行う能力を提供する秘密の要因となります。これらの価値は、インフラストラクチャの変更が頻繁であろうとなかろうと、品質を向上させるために速度を活用することにあります。コードとして定義できるもの (What You Can Define as Code)過去にはプラットフォームのウェブベースのユーザーインターフェイスを使用したり、CLIを駆使してインフラストラクチャを手動でプロビジョニングすることが一般的でした。しかし、インフラストラクチャをコード化することで、過去のプロジェクトで見た、可視性の高い変更管理と迅速な展開の実現が可能となりました。これは、経験上も正しく技術的な変更が頻繁に発生する環境で特に重要です。インフラストラクチャコーディング言語 (Infrastructure Coding Languages)スクリプト言語やDSLの使用から、一般的なプログラミング言語を使用したインフラストラクチャのツールへの移行は、運用の柔軟性を飛躍的に向上させました。以前に取り組んだプロジェクトでは、Terraformのような宣言的言語を使用してインフラストラクチャを定義し、それがもたらすシンプルさと明確さに驚かされました。このようなツールにより、インフラストラクチャのコードが従来のプログラミングコードと同様に「リアルなコード」として扱われるようになりました。インフラストラクチャをコードとして定義するための実装原則 (Implementation Principles for Defining Infrastructure as Code)宣言的と命令的コードを混在させることなく、インフラストラクチャコードを「リアルな」コードとして扱うことは、私たちのコードベースをクリーンに保つために不可欠です。参加した多くのプロジェクトでは、技術的負債を積極的に管理し、コードの品質を維持するために、コードレビュー、ペアプログラミング、自動テストなどの慣行を取り入れていました。これらは、インフラストラクチャコードの維持可能性を確保するために重要な実践です。この章は、システムをコードとしてどのように定義するか、その方法とその背後にある理由を詳細に説明しています。インフラストラクチャを定義するための適切な言語を選択することは、効果的なインフラストラクチャを構築する上での重要な課題です。私の経験では、この課題はまだ解決されていませんが、本書を通じて、このテーマが再び現れ、私たち全員が最善の方法を発見するための考察を深めることを期待しています。まとめ『Infrastructure as Code』の初めの4章は、クラウド時代のインフラストラクチャ管理の新しいパラダイムを解き明かしています。第1章では、変更を効率的に、安全に、かつ迅速に行うためのインフラストラクチャとしてのコード（IaC）の基礎を設定します。第2章では、システムの不確実性を前提とし、再現性、廃棄可能性、変動の最小化といったクラウド時代のインフラストラクチャ設計の原則に深く潜ります。第3章は、インフラストラクチャプラットフォームとそのリソースがどのようにアプリケーションランタイム層の構築に寄与するかを具体的に説明し、計算、ストレージ、ネットワークという基本リソースを掘り下げます。そして第4章は、これらのリソースをシンプルで独立して変更可能な部品に分けることの重要性を強調し、チームワークフローとインフラストラクチャの安全な変更方法について具体的なガイダンスを提供します。これらの章は、IaCの実践における基本的な理解を構築し、次のセクション「II. Working With Infrastructure Stacks (インフラストラクチャスタックとの作業)」でのより具体的なスタック構築への取り組みへと説明してくれます。Infrastructure as Code, 2nd Editionの記事syu-m-5151.hatenablog.comsyu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraformの条件分岐にうってつけの日]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/11/14/154603</guid>
            <pubDate>Tue, 14 Nov 2023 06:46:03 GMT</pubDate>
            <content:encoded><![CDATA[Infrastructure as Codeの概念とTerraformの役割Infrastructure as Code (IaC) は、現代のインフラ管理の根幹を成すものです。IaCがどんなものか様々な言論があると思いますが、ここではソフトウェア開発のプラクティスに基づくインフラストラクチャ自動化のアプローチとIaC 本に準拠しておきます。IaCによる自動化、バージョン管理、テスト、そして継続的インテグレーションなどのプラクティスは、システム管理の世界に革命をもたらしました。ちなみに個人的には各々のプラクティスを一つずつ実践しない度にIaCの価値は一つずつ確実に下がっていくものだと確信してます。ですが、各々にコストがかかるものなので各プラクティスをどこまで実践するかは非常に難しい問題だとも同時に思います。その中で周知の事実だとは思いますがTerraformは、これらのプラクティスを宣言的なインフラストラクチャの管理、定義、および構成に応用することで、効率性と柔軟性の高いインフラストラクチャ管理を可能にします。このツールは、設計から実装までの過程を劇的に変える可能性を秘めています。Infrastructure as Codeの概念とTerraformの役割に関する参考リンクInfrastructure as Code - AWSInfrastructure as Code - Google CloudIntroduction to Terraform - HashiCorpInfrastructure as Codeの原則とTerraformInfrastructure as Codeの原則には、以下のような要素が含まれます​​:簡単に再現できるシステム: Terraformを使用することで、インフラストラクチャをコードとして定義し、簡単に再現可能なシステムを構築できます。使い捨てにできるシステム: サーバーなどのリソースを一時的なものとして扱い、必要に応じて簡単に生成・破棄できます。統一的なシステム: 全てのインフラストラクチャのコンポーネントを統一的な方法で管理します。反復できるプロセス: 同じ設定を繰り返し適用することで、一貫性と信頼性を保ちます。これらの原則に基づいて、Terraformは以下のような機能を提供します:リソースの自動生成と管理: Terraformを使用すると、インフラストラクチャのリソースを自動的に生成・管理できます。宣言的なインフラの構築: Terraformを通じて、インフラストラクチャの状態を宣言的に定義し、計画的かつ一貫性のある方法でインフラを構築・更新します。バージョン管理のサポート: Terraformの設定ファイルはバージョン管理システムで管理でき、変更履歴を追跡できます。モジュールと再利用可能なコンポーネント: Terraformではモジュールを使って、コードの再利用性を高めます。なのでそれ以外のプラクティスに関しては別のソリューションで実現してあげる必要があります。Terraformの条件分岐のテクニックと利用場面もう少し能書きを垂れるかなって思ったんですけどもう飽きたので普通にテクニックや使い方の話をしていきます。Terraformは基本的に宣言的なインフラ定義ツールですが、宣言的だけでは現実の複雑な要求を満たすのが難しい場合があります。そのため、Terraformは手続き型プログラミングに近い柔軟性も提供します。条件分岐やループなど、より具体的な制御が必要な場面で役立つ機能を組み込んで、効率的かつ柔軟なインフラ管理を実現しています。それでは、これらのテクニックや利用場面について、具体的な例を交えて詳しく見ていきましょう。ループ (countとfor_each)ループは、同じタイプのリソースを複数回作成する際に便利です。countやfor_eachを使用して、コードの重複を避けながら、効率的にリソースを管理できます。利用場面A: 異なる環境に同一種類のリソースを複数作成resource "aws_instance" "dev_servers" {  count         = 5  instance_type = "t2.micro"  # その他の設定}利用場面B: 複数のユーザーにIAMロールを割り当てresource "aws_iam_user" "users" {  for_each = toset(["alice", "bob", "charlie"])  name     = each.value  # その他の設定}条件分岐 (countを使用)条件分岐を使用すると、環境やパラメータに基づいてリソースの作成を制御できます。これにより、開発環境と本番環境などで異なるリソース設定を実現できます。利用場面A: 本番環境でのみデータベースのインスタンスを作成resource "aws_db_instance" "prod_db" {  count = var.is_production ? 1 : 0  # データベースの設定}利用場面B: 開発環境ではリソースを作成せず、本番環境でのみ特定のリソース（例: S3バケット）を作成したい場合。resource "aws_s3_bucket" "prod_bucket" {  count  = var.env == "prod" ? 1 : 0  bucket = "my-production-bucket"  acl    = "private"}ここではvar.env変数がprod（本番環境）の場合にのみS3バケットを作成します利用場面C: 特定の機能フラグ（例: 監視機能の有効化）がオンの場合にのみ、関連リソース（例: CloudWatchアラーム）をデプロイしたい。resource "aws_cloudwatch_metric_alarm" "example_alarm" {  count               = var.enable_monitoring ? 1 : 0  alarm_name          = "High-CPU-Utilization"  comparison_operator = "GreaterThanThreshold"  evaluation_periods  = "2"  threshold           = "80"  # その他の設定}この例では、var.enable_monitoringがtrueの場合にのみCloudWatchアラームを作成します。ゼロダウンタイムデプロイメント (create_before_destroyを使用)ゼロダウンタイムデプロイメントは、システムやアプリケーションの更新時にサービスを停止することなく、新しいバージョンへの移行を行う手法です。Terraformにおけるゼロダウンタイムデプロイメントでは、create_before_destroyライフサイクル設定を使用して、新しいリソースを古いリソースを削除する前に作成します。これにより、サービスが継続的に稼働しつつ、背後で安全にリソースの更新や交換が行われます。利用場面A: アプリケーションの更新時に新旧インスタンスの平滑な切り替えresource "aws_instance" "app_server" {  ami           = "ami-newversion"  instance_type = "t2.micro"  lifecycle {    create_before_destroy = true  }  # その他の設定}このコードは、新しいAMIでEC2インスタンスを作成します。create_before_destroyがtrueに設定されているため、新しいインスタンスが完全に起動し、運用準備が整うまで旧インスタンスは削除されません。これにより、アプリケーションの更新中もサービスが継続して提供されます。利用場面B: インフラのリファクタリング時に既存リソースの無停止更新resource "aws_s3_bucket" "storage" {  bucket = "my-new-bucket-name"  lifecycle {    create_before_destroy = true  }  # その他の設定}この設定では、新しいS3バケットが作成される際、既存のバケットは新しいバケットの設定が完了し、利用可能になるまで保持されます。これにより、データの移行やバケットの設定変更が行われる際にも、サービスの中断を回避できます。結論とかこれらの使い方はもちろんのこと原則を理解しながら活用することで、インフラストラクチャの管理において幸せな世界観を目指していきましょう。『Terraform: Up & Running』の日本語版第3版のリリースを心から祝福してます。この本は、Terraformの基本から応用までを幅広くカバーし、多くの開発者やシステム管理者にとってよても良い本となることでしょう。手元においておいて本当に損がない書籍かと思います。詳解 Terraform 第3版 ―Infrastructure as Codeを実現する作者:Yevgeniy BrikmanオライリージャパンAmazon参考資料Count: Repeating ResourcesFor Each: Repeating a Module Multiple TimesConditional ExpressionsResource Lifecycle: create_before_destroyTerraform by HashiCorpIntroduction to TerraformZero Downtime Updates with TerraformTerraformチュートリアル - HashiCorp LearnTerraform Best Practices余談Ansible やDockerではどのようにループや条件分岐を実現しているかAnsibleでは組み込まれている機能で実現できますがDockerでは、ループや条件分岐は通常、Dockerfile内では直接実現できません。しかし、Docker Composeやスクリプトを使用して間接的にこれらを処理することができます。Kubernetesでも、ループや条件分岐はマニフェストファイル（YAML）内で直接的にはサポートされていませんが、Helmチャートのようなテンプレートエンジンを使用することで、これらの動作を実現できます。Helmは条件分岐や変数の代入などを可能にするテンプレート機能を提供しているのでそれぞれ紹介します。ループloopキーワードを使用して繰り返しタスクを実行します。- name: パッケージのインストール  yum:    name: "{{ item }}"    state: present  loop:    - httpd    - memcachedAnsible Loopsこの例では、.Values.services内の各サービスに対してループを行い、それぞれのnameとportを出力しています。{{- range .Values.services }}- name: {{ .name }}  port: {{ .port }}{{- end }}HelmチャートのテンプレートDocker Composeでのループと条件分岐Docker Composeでは直接的なループや条件分岐のサポートはありませんが、環境変数を利用して擬似的にこれらを実現できます。services:  web:    image: "webapp:${WEBAPP_TAG}"    environment:      - DEBUG=${DEBUG_MODE}この例では、WEBAPP_TAGとDEBUG_MODE環境変数を使用しています。条件分岐ステートメントを使用して、特定の条件に基づいてタスクを実行します。- name: 開発環境でのみ実行するタスク  command: echo "これは開発環境用のタスクです"  when: env == 'development'- name: 本番環境でのみ実行するタスク  command: echo "これは本番環境用のタスクです"  when: env == 'production'Ansible Conditionals{{- if .Values.debug }}environment: "development"{{- else }}environment: "production"{{- end }}ここでは、.Values.debugの値に基づいて環境を設定しています。debugがtrueならdevelopment、そうでなければproductionが選択されます。Helmのテンプレート関数この節では、Ansible、Docker、そしてKubernetesにおけるループと条件分岐の実装方法を比較しました。これらのツールはそれぞれに独自のアプローチを持っており、その違いを理解することで、適切なツール選択や実装戦略を行う上での参考になります。また、異なるツールでどのように同じ問題を解決しているかを知ることは、より深い技術的理解や柔軟な対応能力を身につけるために重要です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、生成AIを活用したSRE業務自動化への取り組みを発表]]></title>
            <link>https://sreake.com/blog/generative-ai-sre/</link>
            <guid>https://sreake.com/blog/generative-ai-sre/</guid>
            <pubDate>Tue, 14 Nov 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイクが提供するSRE総合支援サービス「Sreake（スリーク）」は、「 Google Cloud 生成 AI パートナー エコシステム 」を活用して、SREの業務を自動化・効率化し、これまでの人的リソースへの依存度を軽減する取り組みを開始することをお知らせいたします。The post スリーシェイク、生成AIを活用したSRE業務自動化への取り組みを発表 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MinIO Client で Amazon S3 や Cloudflare R2 を利用する]]></title>
            <link>https://blog.1q77.com/2023/11/minio-client/</link>
            <guid>https://blog.1q77.com/2023/11/minio-client/</guid>
            <pubDate>Sun, 12 Nov 2023 11:13:31 GMT</pubDate>
            <content:encoded><![CDATA[Cloudflare R2 は egress の費用がかからないということで手元のファイルのバックアップに使ってみようかなと思ったときにクライアントとして何を使おうかな aws cli 使うほどじゃないしなという]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Golangで行うポートスキャナ自作ではじめるペネトレーションテスト]]></title>
            <link>https://zenn.dev/satoken/articles/golang-port-scanner</link>
            <guid>https://zenn.dev/satoken/articles/golang-port-scanner</guid>
            <pubDate>Fri, 03 Nov 2023 03:30:25 GMT</pubDate>
            <content:encoded><![CDATA[はじめにオライリーでポートスキャナ自作ではじめるペネトレーションテストという本が発売されました。2章ではScapyを利用して実際にパケットを作成して、nmapのようなポートスキャナ自作します。パケットのカプセル化などNWの仕組みから丁寧に解説されていてとても良書だと思います。ただ筆者はPythonよりGolang派なので2章のプログラムをGolangに書き換えてみました。https://github.com/sat0ken/go-port-scanner※オリジナルはこちらhttps://github.com/oreilly-japan/pentest-starting...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazon ECSイベントをCloudWatch Logsへ収集する]]></title>
            <link>https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2</link>
            <guid>https://zenn.dev/yuu0w0yuu/articles/df3a9fdef609e2</guid>
            <pubDate>Thu, 02 Nov 2023 08:33:22 GMT</pubDate>
            <content:encoded><![CDATA[きっかけECSは、Container Insightsを有効化することでクラスタやサービスといった各レイヤのパフォーマンスメトリクスをCloudWatchに収集できる。一方で、以下のようなケースにおいて一定の仮説を導くためには、このメトリクスだけではやや不足感があるため、発生したイベントやその結果を別の方式で監視したくなった。メトリクスがスパイクしたタイミングで何が起きていたか？デプロイを実行したが結果はどうだったか？デプロイが失敗したが原因は何か？などなど・・調べてみると、ECSはいくつかの種類のイベントをEventBridgeに送信しており、これをルールで拾って...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Time-Slicing GPUs を Kubernetes で利用する]]></title>
            <link>https://sreake.com/blog/kubernetes-time-slicing-gpu/</link>
            <guid>https://sreake.com/blog/kubernetes-time-slicing-gpu/</guid>
            <pubDate>Tue, 31 Oct 2023 08:39:06 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Kubernetes にて、1つのGPUを複数コンテナ (※ Pod内の複数コンテナ、複数のPodを指す) で使い倒したい。そんな時はありますでしょうか。本記事では、NVIDIA/k8s-device-plug […]The post Time-Slicing GPUs を Kubernetes で利用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ShellCheckで自動化の品質を向上させる]]></title>
            <link>https://sreake.com/blog/shellcheck-automation-enhancement/</link>
            <guid>https://sreake.com/blog/shellcheck-automation-enhancement/</guid>
            <pubDate>Tue, 31 Oct 2023 02:32:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Site Reliability Engineering (SRE) の領域では、トイル (toil) の削減と効率的なオペレーションが大きな課題となっています。トイルというのは、手作業で繰り返し行う作業のこと […]The post ShellCheckで自動化の品質を向上させる first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day9]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/9_core_functions_high_availability</guid>
            <pubDate>Sat, 21 Oct 2023 15:12:37 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Read I/O pathを読みました。今回はArchitecture > Core functions > High Availabilityを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。High availabilityYugabyteDBは一貫性と分断耐性を兼ね備えたデータベースであると同時にリーダーの障害時に新しいリーダーとしてフェイルオーバー出来るアクティブレプリカを持つことで高可用性(HA)を達成している。もしノードに障害が発生した場合、そのノード上で動作するYB-TServerとYB-Masterの停止を引き起こす。YB-TServer failureYB-TServerはYSQLレイヤとアクティブなIOを提供するピアーリーダータブレットを含むタブレットをホストする。YSQレイヤとタブレットピアーフォロワーとタブレットピアーリーダーで発生した障害はそれぞれ特別な方法であつかわれる。YQL failureアプリケーションの視点からみればYQLはステートレスである。そのためクライアントが発行したリクエストは単純に他ノードのYQLにリクエストが送信される。スマートクライアントを利用している場合、スマートクライアントは理想的なYB-TServerの場所をタブレットが所有するキーから検索し、リクエストを直接そのノードに転送する。Tablet peer follower failureタブレットピアーフォロワーはクリティカルパスではない。この障害はユーザーリクエストへの可用性に影響しない。Tablet peer leader failureタブレットピアーリーダーの障害は数秒以内にRaftレベルのリーダー選出を自動的にトリガーし、他のYB-TServerに配置されているタブレットピアーが新しいリーダーとして選出される。タブレットピアリーダーに障害が発生した場合、可用性が損なわている時間は約3秒(ハードビートの感覚がデフォルトの500msの場合)である。YB-Master failureYB-Masterは通常のIOオペレーションではクリティカルパスでは無いため、ユニバースを動作させるのに影響は無い。しかしYB-Masterは異るノードで動作するピアーのRaftグループの一部であるため。このピアーのうちの一つがアクティブなマスターで残りがアクティブスタンバイである。YB-Masterのリーダーであるアクティブマスターに障害が発生した場合、ピアーはリーダーの障害を検知し、新なアクティブマスターであるYB-Masterのリーダーを障害時に数秒以内で再選出する。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Application Integrationについて]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/365af68bb280e7</guid>
            <pubDate>Wed, 18 Oct 2023 09:20:05 GMT</pubDate>
            <content:encoded><![CDATA[whatGoogle Cloudの「Application Integration」というサービスについて軽く調べたことをまとめたログ関連してiPaasについても調べたことを記載する Application Integrationとはhttps://cloud.google.com/application-integration?hl=jaGoogle Cloudが提供するIntegration Platform as a Service（iPaaS）ソリューションビジュアルエディタを利用することによって、以下がノーコードで行えるイベントによるトリガーの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Asset Inventoryとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/e80d73d4f28a79</guid>
            <pubDate>Fri, 13 Oct 2023 10:27:12 GMT</pubDate>
            <content:encoded><![CDATA[whatGoogle Cloud のCloud Asset Inventoryについて調べてわかったことの個人まとめ Cloud Asset Inventoryとはhttps://cloud.google.com/asset-inventory/docs/overview?hl=jaCloud Asset Inventory は、時系列データベースに基づいてインベントリ サービスを提供します。このデータベースは、Google Cloud のアセット メタデータの 35 日間分の履歴を保持します。過去 35 日間変更がない既存のアセットの場合、Cloud Asset ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Searchによる社内knowlegeの要約ツールをつくってみた]]></title>
            <link>https://sreake.com/blog/vertex-ai-search-summary-tool/</link>
            <guid>https://sreake.com/blog/vertex-ai-search-summary-tool/</guid>
            <pubDate>Thu, 12 Oct 2023 03:46:53 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、初めましての方もそうでない方も、Sreake事業部 佐藤慧太(@SatohJohn)です。 今回Google CloudのVertex AI Search(旧Enterprise Search)について検証の […]The post Vertex AI Searchによる社内knowlegeの要約ツールをつくってみた first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 インシデント管理・運用プラットフォーム「PagerDuty」の導入支援サービスを正式リリース]]></title>
            <link>https://sreake.com/blog/pagerduty-package/</link>
            <guid>https://sreake.com/blog/pagerduty-package/</guid>
            <pubDate>Tue, 10 Oct 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイクが提供するSRE総合支援サービス「Sreake（スリーク）」は、新たに 、システムのインシデント対応を一元化するプラットフォーム「PagerDuty」の導入支援サービス「PagerDutyパッケージ」を正式リリースいたしました。The post スリーシェイク、 インシデント管理・運用プラットフォーム「PagerDuty」の導入支援サービスを正式リリース first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用』というタイトルで登壇しました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/10/05/233555</guid>
            <pubDate>Thu, 05 Oct 2023 14:35:55 GMT</pubDate>
            <content:encoded><![CDATA[概要資料参考文献概要Platform Engineering Meetup #5 で SREとPlatform Engineerの交差点:2つの領域の交差と組織への適用 というテーマで登壇をしました。SREからPlatform Engineerへの拡大のセルフリバイバルになります。このブログでは、参考資料を見るために利用してください。気が向いたら続き書く資料 speakerdeck.com参考文献O’Reilly Japan – SRE サイトリライアビリティエンジニアリングO’Reilly Japan – サイトリライアビリティワークブックO’Reilly Japan – SREの探求SRE at Google: How to structure your SRE team | Google Cloud BlogレトロスペクティブガイドWhat Is Platform Engineering?What Team Structure is Right for DevOps to Flourish?Making the Business Case for a Dedicated Platform Engineering TeamCNCF Platforms White PaperSRE NEXTPlatform Engineering Meetupチームトポロジー　価値あるソフトウェアをすばやく届ける適応型組織設計The History of DevOps ReportsEffective DevOpsTop Strategic Technology Trends for 2023: Platform Engineering道を照らす: プラットフォーム エンジニアリング、ゴールデンパス、セルフサービスのパワーオブザーバビリティ・エンジニアリングWebエンジニアのための監視システム実装ガイドネットワーク・エフェクト　事業とプロダクトに欠かせない強力で重要なフレームワークINSPIRED 熱狂させる製品を生み出すプロダクトマネジメント]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SREとPlatform Engineerの違いを3つのポイントで理解する]]></title>
            <link>https://sreake.com/blog/3-diffs-with-sre-and-platform-engineer/</link>
            <guid>https://sreake.com/blog/3-diffs-with-sre-and-platform-engineer/</guid>
            <pubDate>Wed, 04 Oct 2023 03:49:57 GMT</pubDate>
            <content:encoded><![CDATA[はじめに プラットフォームエンジニアリング（Platform Engineering）とサイト信頼性エンジニアリング（SRE, Site Reliability Engineering）はともに、ITインフラとアプリケー […]The post SREとPlatform Engineerの違いを3つのポイントで理解する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[DietPi で DNLA サーバー]]></title>
            <link>https://blog.1q77.com/2023/09/minidlna-on-dietpi/</link>
            <guid>https://blog.1q77.com/2023/09/minidlna-on-dietpi/</guid>
            <pubDate>Sat, 30 Sep 2023 08:33:09 GMT</pubDate>
            <content:encoded><![CDATA[Raspberry Pi 4 を買った週に Raspberry Pi 5 が発表されてちょっと悔しいところですが Windows XP 時代から OS を更新しながら使っていた古いデスクトップPCを処分したのでそこで使っていた HDD をラズパ]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetes における秘密情報の管理方法]]></title>
            <link>https://sreake.com/blog/kubernetes-secret-management/</link>
            <guid>https://sreake.com/blog/kubernetes-secret-management/</guid>
            <pubDate>Mon, 25 Sep 2023 08:35:29 GMT</pubDate>
            <content:encoded><![CDATA[自己紹介 竹下 2023年8月21日からインターンに参加している早稲田大学基幹理工学研究科 M1 竹下です。SRE関連の技術と，自身が研究しているセキュリティ分野との関係性を学びたいと思い、インターンに参加しました。 中 […]The post Kubernetes における秘密情報の管理方法 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[EventBridge Scheduler からの Lambda 関数起動に Lambda Permission は不要]]></title>
            <link>https://zenn.dev/toshikish/articles/743f69389aa99c</link>
            <guid>https://zenn.dev/toshikish/articles/743f69389aa99c</guid>
            <pubDate>Fri, 22 Sep 2023 10:16:34 GMT</pubDate>
            <content:encoded><![CDATA[AWS Lambda 関数の他サービスからの呼び出しAWS Lambda 関数にはリソースベースポリシーを割り当てることができます。関数を他のサービスから呼び出すとき，通常はリソースベースポリシーにそのサービスからの実行を許可するポリシーを追加する必要があります。例えば，Amazon SNS からイベント駆動で呼び出す場合は，以下のように add-permission コマンドを実行することでポリシーを追加することができます。aws lambda add-permission --function-name example-function \--action lambda...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/google-cloud-specialization/</link>
            <guid>https://sreake.com/blog/google-cloud-specialization/</guid>
            <pubDate>Fri, 22 Sep 2023 00:50:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud – Sell エンゲージメントモデルにおけるプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cl […]The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「インフラストラクチャ – サービス」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WSL 2 で外部ストレージをマウント]]></title>
            <link>https://blog.1q77.com/2023/09/wsl2-mount-volume/</link>
            <guid>https://blog.1q77.com/2023/09/wsl2-mount-volume/</guid>
            <pubDate>Thu, 21 Sep 2023 14:08:28 GMT</pubDate>
            <content:encoded><![CDATA[Laptop を Linux で使用していた時の遺産を WSL 環境でも使おうと XFS でフォーマットされた USB 接続の HDD をマウントする方法がないかなと思って調べたメモ。 Microsoft のドキュメントにありました。 Linux]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Open InterpreterのDockerfile を書いたのでTipsとか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/20/002920</guid>
            <pubDate>Tue, 19 Sep 2023 15:29:20 GMT</pubDate>
            <content:encoded><![CDATA[Dockerfile のベストプラクティスを考える機会はありますが皆さんの意見も聞きたい。今回は噂の便利ツール、Open Interpreterのような外部コマンドをどんどん実行して環境を作り変えるようなタイプのツールの場合にはDockerはとても有用です。そのようなツールを利用する時のDockerfile について考えていきます。リポジトリは以下になります。github.comGitHub Actionsとの連携GitHub Actionsは、CI/CD（継続的インテグレーションと継続的デリバリー）をGithub 上に簡単に実装できるツールです。今回は、trivy.ymlとdocker-publishを利用することで、セキュリティのスキャンとDockerイメージの自動公開が可能です。github.comtrivy.ymlの利用trivy.ymlは、Trivyという脆弱性スキャナーをGitHub Actionsで動かすための設定ファイルです。この設定を利用することで、Dockerイメージに存在するセキュリティの脆弱性を自動で検出できます。docker-publishの追加docker-publishは、DockerイメージをDocker Hubや他のレジストリに自動で公開するためのGitHub Actionsのワークフローです。これにより、新しいバージョンのOpen Interpreterがリリースされた際に、手動でイメージをビルド・プッシュする手間が省けます。Renovate.jsonの利用renovate.jsonは、依存関係を自動で更新する設定ファイルですが、これを使うとOpen Interpreterが依存しているライブラリやパッケージが新しくなったときに、自動でプルリクエストが作られるんです。そうすることで、いつも最新の状態を保てるわけですから、セキュリティリスクも減らせます。さらに、Pythonのパッケージも自動で更新したい場合は、requirements.txtを使って設定しておくと便利です。これにより、Pythonの依存パッケージも最新の状態を維持できるようになります。github.comDockerfileを書く際の注意点私は以下のようなDockerfileを書きましたその際に以下のようなポイントを意識して書いたので参考にしてください。github.com軽量なベースイメージの使用不必要なパッケージを含まない軽量なベースイメージを使用することで、ビルド時間とイメージサイズを削減できます。FROM python:3.11キャッシュの最適化RUNコマンドを効率的に配置することで、Dockerキャッシュを最適化できます。RUN apt-get update && \  apt-get upgrade -y && \  apt-get install -y --no-install-recommends git && \  rm -rf /var/lib/apt/lists/*不必要なパッケージの削除--no-install-recommendsオプションを使用して、不必要なパッケージをインストールしないようにします。  apt-get install -y --no-install-recommends git && \作業ディレクトリの設定WORKDIRを設定することで、その後のコマンドの実行ディレクトリを明示的に指定できます。WORKDIR /root機密情報はコンテナイメージに絶対に埋め込まない社内で有識者へ投げたら機密情報をビルドイメージに追加することを指摘されたので運用時の手癖やミスで何処かのレイヤーに不用意に埋め込まないようにしたgithub.comまとめDockerでOpen Interpreterを運用する際には他にもいろいろ考えるべきことがあると思うので皆さんと議論したいのでIssue待ってます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryの行列レベルのアクセス制御について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/bc6a413eb623c7</guid>
            <pubDate>Thu, 14 Sep 2023 11:46:25 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおける「行列レベル」のアクセス制御について調べたことをまとめる そもそも: 行・列単位に対してのアクセス制御は可能なのか?A. できるそれぞれ記載していく 列単位https://cloud.google.com/bigquery/docs/column-level-security-intro?hl=ja列に対して事前定義したポリシータグと呼ばれるものを付与することで、特定のアカウントやグループだけが列にアクセスできる。アクセスポリシーはSQLを実行する際に確認され、許可されていないメンバーからのクエリはAccess Denitedと...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Deployを使ったCloud Runのリリース]]></title>
            <link>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</link>
            <guid>https://zenn.dev/satohjohn/articles/7e6a70edc8f36e</guid>
            <pubDate>Wed, 13 Sep 2023 05:47:13 GMT</pubDate>
            <content:encoded><![CDATA[概要Cloud RunのリリースにCloud Deployを使ってみます。 そもそもCloud Deployとはhttps://cloud.google.com/deploy?hl=jaGKE、Cloud Runのリリースを管理できるサービスになります。リリースフローを記載したパイプラインの定義を作成し、パイプラインを作成したら、フローを管理できるようになります。各フローでは基本内部でskaffoldを通して、Cloud Buildが実行される形です。Cloud Deployを使うと以下のような、リリースフローになるかと思います。Cloud BuildでImageを...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub ActionsでWorkload Identityでの認証を入れてGoogle CloudのAPIを叩く]]></title>
            <link>https://zenn.dev/satohjohn/articles/1645be8e83eab6</link>
            <guid>https://zenn.dev/satohjohn/articles/1645be8e83eab6</guid>
            <pubDate>Mon, 11 Sep 2023 14:17:35 GMT</pubDate>
            <content:encoded><![CDATA[概要正直難しいと思ってたのですが、資料を読んでいくと表面上、実装は難しくありませんでした。GitHub ActionsとGoogle Cloudを連携する場合、json管理とかしなくても済むし、基本的にやっておいて損はないと思います。ユースケースとしては、例えば、GitHub Actionsで実行した結果(report)をGoogle Cloud Storageにデータを送りたいなどの際に使えると思います。Identity Poolに対して、providerは複数作成できるため、いろんな GitHub Actionsから利用されるようなパターンでも、provider:scri...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較]]></title>
            <link>https://sreake.com/blog/container-security-comparison/</link>
            <guid>https://sreake.com/blog/container-security-comparison/</guid>
            <pubDate>Mon, 11 Sep 2023 07:22:29 GMT</pubDate>
            <content:encoded><![CDATA[自己紹介 高島 陸斗 千葉工業大学修士1年生の高島陸斗です。大学院では、コンピュータによる数値計算の厳密解との誤差がどの程度あるのかを調べる精度保証の精度を上げるための研究をしています。サイバーセキュリティに興味があり、 […]The post コンテナセキュリティ TetragonとPodSecurity/seccompの機能比較 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryのオンデマンド料金におけるコスト管理方法についてメモ]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/f0da04c4a70ea6</guid>
            <pubDate>Mon, 11 Sep 2023 01:56:24 GMT</pubDate>
            <content:encoded><![CDATA[whatBigQueryにおけるコスト管理方法について、公式ドキュメントを元にメモしたログ今回はオンデマンド料金について記載のため、定額料金(BigQuery Editions)に関しては記載しない 高額請求が来てしまうパターンとはよく見かける/耳にするのは以下のような場合(あくまで一例)大量にデータをスキャンするクエリを実行するselect * 系のクエリを投げる(Table Patitionを利用したテーブルの場合)partitionで指定しないでクエリを投げる料金がかかるクエリをバッチなど利用して連続で実行してしまうTable Patition...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[YugabyteDBのドキュメントを全部読む Day8]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path</link>
            <guid>https://nnaka2992.hatenablog.com/entry/reading_yugabytedb_docs/8_core_functions_read_io_path</guid>
            <pubDate>Wed, 06 Sep 2023 18:37:55 GMT</pubDate>
            <content:encoded><![CDATA[前回からつづいてYugabyteDBのドキュメントを読んでいきます。前回はArchitecture > Core functions > Write I/O pathを読みました。今回はArchitecture > Core functions > Read I/O pathを読みます。ドキュメントのバージョンは最新のv2.19 previewです。また画像は同ドキュメントより引用しています。Read I/O pathI/O Pathはタブレットリーダーが特定されリード処理を実行する単一キーの例で説明することが出来る。Tablet leader identificationユーザーが発行したYQLクエリレイヤに作用するリードリクエストはポートから適切なAPI(YQLまたはYCQL)を経由して行なわれる。このユーザリクエストはYQLレイヤで内部キーに変換され、YQLレイヤがタブレットとそれをホストするYB-TServerを発見するのに利用される。YQLレイヤはこれをYB-MasterにたしてRPC呼び出しを実行するために行なう。またそのレスポンスは将来の利用のためにキャッシュされる。その後YQLレイヤはリーダータブレットピアーをホストするYB-TServerに対してリード処理を行なう。このリード処理は内部キーを保持するタブレットのRaftグループのリーダーによって処理される。このリードリクエストを処理するRaftグループのリーダーはDocDBから読み込みを実行し、その結果をユーザーに戻す。Write I/O Pathで説明した通り、YugabyteDBのスマートクライアントではアプリケーションのリクエストを直接適切なYB-TServerに送信することが出来るため、余計なネットワークホップやマスターへのアクセスを省略することが出来る。Read operation performed by tablet leaderkという値をKというプライマリキー行に持つテーブルT1からデータを取得するケースについて考える。またテーブルT1はキー行Kと値行Vを持つものとする。1下記の画像はリード処理について説明している。YugabyteDBはデフォルトでは強整合性の読み取りを採用している。リードクエリはさらに複雑になることもある。YQLクエリレイヤーは式やビルトイン関数、算術演算を含むクエリを処理するfully-optimized2されたクエリエンジンを持っている。SELECT K,V from T1 where K = 'k'ということ↩↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[まずPR-AgentをPromptとします。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/09/06/165227</guid>
            <pubDate>Wed, 06 Sep 2023 07:52:27 GMT</pubDate>
            <content:encoded><![CDATA[「ツールよりもプロンプトのほうが、隙間がなくて効率的なのでは？」... ああ、面倒なブログになるな、とおれは直感した。はじめに近年、プルリクエスト（PR）の管理が開発フローにおいてますます重要な位置を占めるようになっています。ただし、PRをより良く作る作業は往々にして煩雑で手間がかかりがちです。その解決策として、Codium AIによって開発されたPR-Agentが脚光を浴びています。このAIソフトウェアは、OpenAIのGPT-4技術を基盤にしており、単にOpenAIのAPIキーを設定するだけで、既存のCI/CDパイプラインに簡単にインテグレーションできます。github.comPR-Agentの主な機能PR-Agentは、様々なPR関連作業を自動化するための多機能なオープンソースプロジェクトです。具体的には、以下のような機能群を提供しています。/describe: タイトル、種類、要約、コードの詳細説明、およびラベルを自動で作成するためのPR（プルリクエスト）説明自動生成機能。/review: PRの主題、種類、関連テスト、セキュリティ問題、評価スコア、その他のフィードバックを調整可能に提供する自動レビュー機能。/ask ...: PRに関するフリーテキスト質問に回答する質問応答機能。/improve: PRを改善するためのコミット可能なコード提案を行うコード改善提案機能。/update_changelog: PRの変更内容に基づき、CHANGELOG.mdファイルを自動で更新する更新履歴自動更新機能。PR-AgentはOpenAIのAPIキーを設定するだけでCI環境に簡単に組み込め、開発者が効率的なPR作成と管理を行えるよう支援します。このツールはGPT-4を用いて高精度なソースコード解析とレビューを自動で行い、開発者が重要なポイントに集中できるようにします。さらに、「PR Compression Strategy」と呼ばれる独自のアルゴリズムによって、大規模なPRでも重要なファイルと主要な言語のコードブロックに焦点を当てた効率的なレビューが可能です。それ以外にもさまざまな設定により、PR-AgentはPR作成とレビューのプロセスを自動化し、効率化する強力なツールであり、大規模プロジェクトにおいてもスムーズかつ効率的なレビュープロセスを実現します。これらをどのように動作させればよいのかはUsage guideを読んでみてください。PR-Agent のPromptPR Compression Strategyにより、送信するファイルの戦略が定められています。その設定に加えて、pr-agent/pr_agent/settings/ ディレクトリには、TOML形式でプルリクエスト（PR）のレビュープロンプトのテンプレートが含まれています。具体的には、pr_review_promptはpr_reviewer_prompts.toml ファイルに定義されており、これがPRのレビュープロセスにおける基本的な指示とフォーマットを規定しています。この構成により、PRレビューが一貫性を持ち、効率的に行えるよう設計されています。pr_reviewer_prompts.toml 解説pr_reviewer_prompts.tomlは、Pull Request（PR）レビューに関する設定と指示を定義する設定ファイルです。この設定ファイルは、PRレビューを自動化する際に利用されます。pr_review_prompt セクションsystemこの設定は、レビュワーがどのような役割を果たすべきかを定義しています。具体的なPR Diffの入力例も提供され、新しく追加されたコード（+で始まる行）に焦点を当てるよう指示されています。system="You are PR-Reviewer, a language model designed to review git pull requests. ..."num_code_suggestionsコード提案が必要な場合、その数や重要度についての指示がこの部分に記載されています。{%- if num_code_suggestions > 0 %}- Provide up to {{ num_code_suggestions }} code suggestions. ...{%- endif %}extra_instructionsパラメータで、追加的な指示や設定を行うために使用されます。この項目は主に以下のような用途で利用されることが多いです。{%- if extra_instructions %}Extra instructions from the user:{{ extra_instructions }}{% endif %}YAMLスキーマこの部分で、PRレビュワーが出力するレビュー結果のYAMLフォーマットが定義されています。Main theme, PR summary, Type of PR, etc.これらは、PRに関する基本情報を整理するためのフィールドです。Main theme:  type: string  description: a short explanation of the PRScore, Relevant tests added, Insights from user's answer, etc.これらのフィールドは、PRに関する詳細な評価やテスト情報、ユーザーからのフィードバックに基づく評価を行います。Score:  type: int  description: Rate this PR on a scale of 0-100 ...General suggestions, Code feedback, Security concernsこれらのフィールドは、具体的なコード提案やセキュリティ上の懸念など、PRのコードに関する詳細なフィードバックを提供します。General suggestions:  type: string  description: General suggestions and feedback for the contributors ...user セクションこのセクションは、PR作成者から提供される情報（タイトル、ブランチ、説明文など）を取り込む場所です。user="PR Info:Title: '{{title}}'Branch: '{{branch}}'Description: '{{description}}' ..."この設定ファイルによって、PRレビューのプロセスが自動化され、一貫性を持つようになります。特定のプロジェクトやチームに特有の要件に応じて、これらの設定はカスタマイズ可能です。まとめpr_reviewer_prompts.tomlといった設定ファイルを読んで全体としてPRのフォーマットに忠実にプロンプトを作成していったのがわかりました。参考にしていきたいと思います。github.com参考PR-Agent を使って Pull Request をAIレビューしてみた。（日本語対応もしてみた）GitHub - Codium-ai/pr-agent: 🚀CodiumAI PR-Agent: An AI-Powered 🤖 Tool for Automated Pull Request Analysis, Feedback, Suggestions and More! 💻🔍]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LookMLとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/18a4a04b98dcb8</guid>
            <pubDate>Tue, 05 Sep 2023 10:46:35 GMT</pubDate>
            <content:encoded><![CDATA[これは何？Looker内にある機能である「LookML」について調べたことをまとめた個人的備忘録。 LookMLとはLookMLの紹介  |  Looker  |  Google CloudLookML は、Looker Modeling Language の略です。セマンティックデータモデルを作成するためにLookerで使用される言語です。LookMLを使用して、SQLデータベース内のディメンション、集計、計算、およびデータの関係を記述できます。LookMLは「Looker上で利用できる独自の言語」のことをさす　別にMLや機械学習は関係ないLookerは、Lo...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nodejs(Nest.js)のアプリケーションのbuildを高速化、slim化してみようの会]]></title>
            <link>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</link>
            <guid>https://zenn.dev/satohjohn/articles/c05d29f5d68e0c</guid>
            <pubDate>Sat, 02 Sep 2023 10:02:16 GMT</pubDate>
            <content:encoded><![CDATA[前提DockerによるNode.jsのインストール(pull)はキャッシュされているものとする.dockerignoreは以下の通りnode_modules.git.gitignore*.mddisttest 最初にまとめ軽く、そんなに依存関係が多くないアプリケーションであればnpmでstaging buildでキャッシュ効かせるぐらいでよいかもRUN --mount=type=cache,target= は効果がありそうである (https://zenn.dev/kou64yama/articles/powerful-docker-build-cache...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Lookerのユーザー権限について]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/160cb146e72740</guid>
            <pubDate>Thu, 31 Aug 2023 17:22:40 GMT</pubDate>
            <content:encoded><![CDATA[これは何Lookerのユーザー権限一覧を個人的にまとめたものhttps://cloud.google.com/looker/docs/admin-panel-users-roles?hl=ja#default_permission_sets ユーザー権限一覧Admin:Developer、Viewer、Standard権限に加え、データソースへの接続やユーザー管理の権限を持つ現時点で確認できる、Adminでしかできない機能については以下データソース(BigQuery等)への接続設定ユーザーの追加・削除・権限の変更ユーザー・グループ単位のフォルダの公開・非公...]]></content:encoded>
        </item>
    </channel>
</rss>