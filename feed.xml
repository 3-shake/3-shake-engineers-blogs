<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sat, 13 Sep 2025 11:41:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Professional Machine Learning Engineer編~]]></title>
            <link>https://zenn.dev/akasan/articles/062b9d9e44922a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/062b9d9e44922a</guid>
            <pubDate>Sat, 13 Sep 2025 05:17:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle Cloud認定資格の一つであるProfessional Machine Learning Engineer(以下、PMLE)を受験したのでその体験記になります。前回取得した資格についても記事にしているのでぜひご覧ください。https://zenn.dev/akasan/articles/c0d347a37065bc Professional Machine Learning EngineerについてPMLEはGoogle Cloudの認定資格の一つであり、特に機械学習に関するサービスおよびその取り扱い、実務への応用などについて問われる資格となります。PMLEで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeに3次元のフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/f90c2940cf1ef3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f90c2940cf1ef3</guid>
            <pubDate>Fri, 12 Sep 2025 14:07:09 GMT</pubDate>
            <content:encoded><![CDATA[昨日は2次元のフラクタル図形をClaude Codeに作成させましたが、今回は3Dのフラクタル図形を作成させてみました。ぜひ昨日の記事もご覧ください。https://zenn.dev/akasan/articles/91d41376641ffc 早速やってみるまずは環境構築をします。uv init fractal_3d -p 3.12cd fractal_3duv add matplotlib numpy pillow今回claude codeに与えた指示は以下になります。pythonを使って、3次元のフラクタル図形を段階的に生成してアニメーションとして保存するコード...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得]]></title>
            <link>https://sreake.com/blog/appdev_specialization/</link>
            <guid isPermaLink="false">https://sreake.com/blog/appdev_specialization/</guid>
            <pubDate>Fri, 12 Sep 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Sell および Service エンゲージメントモデルのプレミアパートナーである株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、Google Cloud Partner Advantage プログラムにおいて、「Application Development - サービス」のスペシャライゼーション認定を取得したことをお知らせします。The post スリーシェイク、 Google Cloud Partner Advantage プログラムにおいて「Application Development」のスペシャライゼーション認定を取得 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[claude codeにフラクタル図形書かせてみた]]></title>
            <link>https://zenn.dev/akasan/articles/91d41376641ffc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/91d41376641ffc</guid>
            <pubDate>Thu, 11 Sep 2025 13:37:44 GMT</pubDate>
            <content:encoded><![CDATA[今回はclaude codeを使ってフラクタル図形を作らせてみました。claude codeをはじめ生成AIはどこまでできる能力があるのかを測るためのシリーズになります。前回は立方体をターミナルでぐるぐる回すものをやりましたが、それの第二弾ですね。https://zenn.dev/akasan/articles/11fed840eedaa7※ バタバタしていて、コードの解説まではできません。次回以降行けるタイミングでさせてもらいます フラクタル図形とは？Wikipediaによると図形の部分と全体が自己相似（再帰）になっているものなどをいうということです。あるAから一部B...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Mist.ioとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/573fa3dfa4911e</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/573fa3dfa4911e</guid>
            <pubDate>Wed, 10 Sep 2025 11:00:24 GMT</pubDate>
            <content:encoded><![CDATA[今回からついに始まりました、CNCFルーレットのお時間です。記念すべき第一弾はMist.ioとなりました。CNCFルーレットについては以下の記事で紹介していますのでぜひご覧ください。https://zenn.dev/akasan/articles/42f5a1d2786ca5https://zenn.dev/akasan/articles/ef9e2919c312c1 Mist.ioとは？Mistはオープンソースのマルチクラウド管理プラットフォームとのことです。Mistでは以下を実現することで、マルチクラウドの取り扱いをしているようです。Self-service: アクセス...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Webアプリケーションにオブザーバビリティを実装するRust入門ガイド]]></title>
            <link>https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/webapurikesiyonniobuzababiriteiwoshi-zhuang-sururustru-men-gaido</guid>
            <pubDate>Wed, 10 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年9月10日（水）、「Rustの現場に学ぶ〜Webアプリの裏側からOS、人工衛星まで〜」というイベントで登壇させていただきます。https://findy.connpass.com/event/359456/他の登壇者の話が聞きたすぎるけど調整能力の圧倒的な不足で登壇したらすぐに帰らなければなりません。今回の発表内容のベースとなったのはこちらのブログです。- 「RustのWebアプリケーションにオブザーバビリティを実装するインフラエンジニアのための入門ガイド」]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud で目指す クラウド二刀流エンジニア講座 第1回 でパネルディスカッションに出てきました。]]></title>
            <link>https://blog.masasuzu.net/entry/2025/09/10/005523</link>
            <guid isPermaLink="false">https://blog.masasuzu.net/entry/2025/09/10/005523</guid>
            <pubDate>Tue, 09 Sep 2025 15:55:23 GMT</pubDate>
            <content:encoded><![CDATA[先日、2025年6月4日に開催された 「Google Cloud で目指すクラウド二刀流エンジニア講座」 の第1回にて、「スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？」 と題したパネルディスカッションに登壇いたしました。イベントから少し時間が経ちましたが、当日の内容を振り返り、話したことや、時間の都合上話しきれなかった点などをまとめていきたいと思います。cloudonair.withgoogle.comページとセッションでの資料は以下のとおりです。Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？Session 3 : スペシャリストが語る！Google Cloud のメリットを活かすネットワーク、セキュリティのあり方とは？(スライド)以下パネルディスカッションでお話しした内容と補足を記載します。Question 1 :現在のハイブリッドクラウド構成時のトレンドとお客様が気にされるポイント大規模なシステムではオンプレミスとクラウドを組み合わせたハイブリッド構成を、中規模以下のシステムではオンプレミスからクラウドへ完全に移行する、あるいは最初からクラウドで構築する「クラウドネイティブ」な構成が多い傾向にあります。可用性向上のために、同じサービスをマルチクラウドで構築するケースは少なく、まずは単一クラウド内でのマルチリージョン構成が検討されることが多い印象です。しかし、私が担当するサービスではマルチリージョンが必要なほどクリティカルなものはそれほど多くなく、多くは単一リージョン内のマルチAZ(ゾーン)構成を採用しています。冗長性が目的ではなく、特定の機能を使いたいので一部のサービス（例: 特にBigQuery、Vertex AI）のみをGoogle Cloudで利用するケースがあります。メインクラウドがどちらかに偏っており、Google Cloudを補完的に利用するケースが多いようです。また、可用性向上という目的とは別に、特定の機能（特にBigQueryやVertex AIなど）を利用するために、一部のサービスのみGoogle Cloudを補完的に利用する、というケースでマルチクラウドを使用してる例が多いです。お客様が特に重視されるポイントとしては、コスト、セキュリティ、そして可用性の担保が挙げられます。Question 2 :クラウドのネットワーク設計、セキュリティ実装において押さえておくべきポイント最適な設計や実装は、お客様の組織体制やチーム体制、そして運用するサービスの性質によって大きく変わります。そのため、まずはどのような運用体制を目指すのかを分析・定義し、それに合った構成を提案することが重要です。考慮すべき観点としては、以下のような点が挙げられます。フォルダやプロジェクトの構成可用性の取り方過剰な可用性を求めていないか、サービスの要件と合っているかセキュリティの要求ネットワーク構成そして何よりも、設計した構成が、実際のチームで「運用可能」であることが最も重要だと考えています。Question 3 :ネットワーク、セキュリティの課題とアプローチここでは、ネットワークの課題を解決した事例を一つご紹介します。Cloud Run、MemoryStore (Redis)、Cloud SQLで構成されたアプリケーションで、Cloud RunとCloud SQL間のネットワーク性能が上がらないという問題が発生しました。Cloud RunはVPCの外部にあるリソースのため、VPC内にあるCloud SQLと接続するにはServerless VPC Connectorを経由していました。調査の結果、性能が出ない原因は、このServerless VPC Connectorのインスタンス数を固定で設定していたことでした。一時的な対処として、Serverless VPC Connectorの最大インスタンス数とインスタンスタイプを引き上げました。このサービスはサーバーレスという名前ですが、実際にはインスタンス数やタイプを指定する必要があります。(ここで言うサーバレスは、サーバレスなリソースへのコネクタという意です)しかし、この対処法では課題が残ります。Serverless VPC Connectorは一度スケールアウトすると自動でスケールインしないため、ピーク時に合わせたインスタンス数のコストを常に払い続けることになってしまいます。そこで根本的な解決策として、Direct VPC Egressへの移行を実施しました。Direct VPC Egressは、パフォーマンスが高く、コストもネットワーク転送料金のみに抑えられるというメリットがあります。ただし、VPCに直接接続するため、使用するIPアドレス数が多くなる点には注意が必要です。この事例では、Cloud Runのデプロイ設定でコネクタを切り替えるだけだったため、移行は比較的スムーズでした。また、インフラがコード化(IaC)されていたため、何か問題があってもすぐに切り戻しができる状態だったことも成功の要因です。この経験から言えるのは、本番稼働しているネットワークの変更は容易ではないということです。そのため、初期設計は慎重に行う必要があります。とはいえ、サービスの成長に伴う構成変更は避けられません。将来の変更を見越して、変更しやすい設計を心がけ、変更を安全に試せる環境を準備しておくことが重要です。具体的には、インフラを可能な限りIaC化して変更や切り戻しを容易にすること、検証環境をすぐに構築できるよう準備しておくこと、そして何よりも 現在のチームメンバーで運用できる方法を選択すること が大切です。チームのスキルレベルや人数、体制を考慮した現実的なアプローチを常に考えていく必要があります。(この事例の話、若干ずれてて長くなってしまった感があります。反省)Question 4 :Google Cloud のネットワーク・セキュリティ領域でのおすすめのサービス・機能ここでは3つのサービスをあげさせてもらいました。IAP限定公開の Google アクセス共有VPCIAPアプリケーションにGoogle認証を簡単に追加できる非常に便利なサービスです。最近、ALBなしでCloud Runに直接設定できるようになりました(プレビュー機能)。ただし、ALBを利用する場合と異なり、Cloud ArmorによるWAF保護が適用できないため、ユースケースに応じた注意が必要です。限定公開の Google アクセス通常、Compute EngineなどのリソースからGoogle系のAPI（Cloud Storageなど）にアクセスするには、外部IPアドレスを持つか、Cloud NATなどを経由する必要がありました。しかし、サブネットでこの「限定公開のGoogleアクセス」を有効にすると、追加費用なしで、外部IPを持たないリソースから直接Google APIにアクセスできるようになります。AWSではVPC EndpointをAPIごとに作成する必要があり、管理が煩雑でコストもかかりますが、Google Cloudではこの機能によって非常にシンプルかつ低コストにプライベートなアクセスが実現できます。共有 VPC(Shared VPC)誰にでもおすすめできるわけではありませんが、特定の要件には非常に有効な機能です。共有VPCを利用すると、ネットワークとセキュリティの管理をインフラチームに集約し、各サービス開発チームは払い出されたサブネット上で開発に専念する、といった職掌の分離が可能になります。これにより、開発チームはインフラを意識することなくアプリケーション開発に集中できます。一つの大規模なシステムを複数のチームで開発する場合や、複数のプロジェクトでVPC上のリソースを共有したい場合に特に便利です。一方で、ネットワークの独立性が失われるため、ファイアウォールの設定をより厳密に行う必要があります。また、開発チームがネットワーク設定を直接変更できないため、変更の都度インフラチームへの依頼が必要になるというデメリットもあります。Question 5 :おすすめのクラウドのネットワーク、セキュリティのベストプラクティスのキャッチアップ方法セキュリティ分野に限りませんが、日々の情報収集が重要です。私のチームでは、Google CloudのリリースノートやAWSのアップデート情報を定期的に確認する会を社内で実施し、効率的に新しい情報をキャッチアップしています。また、資格試験の勉強や更新も、知識を体系的にアップデートする良い機会になります。コミュニティや勉強会イベントへの参加も非常に有効です。Google Cloud関連では、主に以下の2つのコミュニティが活発です。Jagu’e’r (Japan Google Cloud Usergroup for Enterprise)GCPUG(Google Cloud Platform User Group)Jagu'e'rは、ユーザー企業とパートナー企業の従業員で構成されるコミュニティで、各分科会での活動が活発です。私自身もクラウドネイティブ分科会の運営に携わっています。GCPUGは、特にShonan支部が活発に活動されている印象です。他の支部は活動が緩やかになっている面もありますが、Slackワークスペースは現在も動いており、各サービスのチャンネルでは最新アップデートに関する議論が行われています。まとめ今回、初めてパネルディスカッションという形式で登壇させていただきました。至らない点も多々ありましたが、大変貴重な経験となりました。技術に関する議論はやはり楽しいと感じました。今後もこのような機会があれば、ぜひ参加していきたいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：リモート関数戻り値の返し方のアンチパターンについて]]></title>
            <link>https://zenn.dev/akasan/articles/b74692f78ca720</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b74692f78ca720</guid>
            <pubDate>Tue, 09 Sep 2025 10:25:02 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayでリモート関数を利用するにあたり、その戻り値としてアンチパターンとされているものを紹介しようと思います。情報源は以下になります。https://docs.ray.io/en/latest/ray-core/patterns/return-ray-put.html 単一の値を返す場合リモート関数から値が返される場合、その値が大きいのか小さいかに関わらず、その値を直接returnするのがいいとのことです。アンチパターンとしては、ray.put()を利用して参照を作成して返すことみたいです。これがなぜかというと、リモート関数の戻り値は自動的にオブジェクトストアに登録されて参...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude CodeのSubagentsは設定したほうがいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/09/143306</guid>
            <pubDate>Tue, 09 Sep 2025 05:33:06 GMT</pubDate>
            <content:encoded><![CDATA[Claude Codeを使い始めて様々な発信をしてきましたが、Claude Codeに関する投稿は約2ヶ月ぶりです。この期間、他のアウトプットや諸々の事情で投稿が遅れてしまいましたが、今回は「Subagents」について書きます。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。はじめにここで読むのをやめる人のために言っておくと、Subagentsは「Claude Codeに尖った意思を持たせる」機能です。タスクごとに最適化されたAIを使い分けられます。特定のタスクを実行するslash commandsとの違いは、slash commands（/コマンド）があなたが明示的に呼び出すショートカットであるのに対し、SubagentsはClaude Codeが文脈を読んで自動的に専門家を呼び出す点にあります。例えば、slash commandsでは「/test」と打てばテスト実行されますが、Subagentsでは「エラーが出た」と伝えるだけで勝手にdebugger subagentが起動します（起動できないようにもできます）。つまり、commandsは「リモコンのボタンを押す」、Subagentsは「AIが勝手に判断して動く」みたいなもの。commandsは確実だけど面倒、Subagentsは楽だけど時々勝手なことをする。両方設定すれば、必要な時は手動で制御しつつ、面倒な部分は自動化できて最強です（AIに仕事を奪われる第一歩かもしれませんが）。Claude Codeって万能だけど、それゆえに器用貧乏になることがある。「データ分析して」って言ったら、なぜかフロントエンドのコンポーネントまで作り始めたり、最新技術よりも古い安全な実装を選んだり。例えば「最新版で」と指定しても、内部知識にある古いバージョンの設定方法で進めようとしたり、今では不要になった設定ファイルを作ろうとしたりする。「それ最新の仕様で」と言っても憶測でそれっぽくセットアップするだけで、実際の公式ドキュメントを調べずに進めてしまう。毎回「それ古いから最新の方法で」と指摘するのも疲れるし、革新的なアーキテクチャより無難で時代遅れの実装を選んでしまうこともある。タスクの境界線をあまり意識せず、頼まれていないことまでやってしまったり、逆に専門的な判断が必要な場面で踏み込みが足りなかったり。人間の開発チームだって、フルスタックエンジニア1人より専門家チームの方が効率的で、より尖った意思決定ができるでしょ？Subagentsとは何かClaude Code Subagentsは、特定のタスクに特化したAIアシスタントです。docs.anthropic.com各Subagentの特徴：独立したコンテキストウィンドウを持つ（メインの会話を汚染しない）カスタムシステムプロンプトで専門性を定義特定のツールだけ使える権限管理（最小権限の原則）自動的に呼び出されるか、明示的に指定可能実はClaude CodeはデフォルトでTaskツールを使った調査時には、自動的にサブエージェントを起動するアーキテクチャになっています。なぜSubagentsを設定したほうがいいのか1. コンテキストウィンドウの効率的な管理LLMのコンテキストウィンドウは有限です。長時間使っていると、さっき言ったことをすぐに忘れてしまいます。時には全く関係ないことをし始めることさえあります（勝手に別のタスクを始めないでほしいですよね、俺じゃねーんだから）。Subagentsなら独立したコンテキストで動作：メインClaude：「ログ解析はdebugger subagentに任せます」↓Debugger Subagent：（数千行のログを読み込んで解析）↓メインClaude：「問題は○○でした」（要約のみ受け取る）調査の過程で読み込んだ不要な情報は、Subagentのコンテキストに閉じ込められます。2. 専門性による品質向上「小さく単一責任のエージェント」として構築すべきという原則があります。専門のSubagentなら、コードレビュー専門がセキュリティ、パフォーマンス、可読性を徹底チェックし、デバッグ専門がエラーメッセージから根本原因を特定し、テスト専門がエッジケースまで網羅したテストを作成できます。3. 権限管理でセキュリティ向上---name: code-reviewerdescription: コードレビュー専門tools: Read, Grep, Glob  # 読み取りのみ、Write権限なし！---レビュアーが勝手にコード書き換えたら困りますよね。必要最小限の権限だけを与えられます。4. チーム開発での一貫性.claude/agents/をGit管理すれば、チーム全体で同じ基準で開発できます。新人が入ってきても、すぐに同じ品質を保てます。基本的な使い方設定方法/agentsコマンド（v1.0.60以降）で対話的に作成：/agents「Create New Agent」を選択プロジェクト単位か個人単位かを選択「Generate with Claude」で土台を生成、その後カスタマイズ使用可能なツールを選択識別用の色を選択ファイルの場所と構造 タイプ  パス  スコープ  優先度  プロジェクト  .claude/agents/  現在のプロジェクトのみ  高  ユーザー  ~/.claude/agents/  全プロジェクト共通  低 YAMLフロントマター付きMarkdownファイル：---name: your-agent-namedescription: このサブエージェントをいつ呼び出すべきかの説明tools: tool1, tool2, tool3  # 省略すると全ツール継承---ここにシステムプロンプトを書きます。サブエージェントの役割、能力、問題解決へのアプローチを明確に定義。具体的な指示やベストプラクティス、制約事項も含めます。設定項目の詳細 項目  必須  説明  name  はい  小文字とハイフンを使った一意の識別子  description  はい  サブエージェントの目的を自然な言葉で説明  tools  いいえ  特定のツールをカンマ区切りでリスト。省略時は全ツール継承 利用可能なツール基本ツール：Read, Write, Edit, MultiEdit - ファイル操作Bash - シェルコマンド実行Grep, Glob - 検索MCPツール（設定時）：mcp__github__create_issue - GitHub連携その他の設定済みMCPサーバーツールSubagentの呼び出し方法自動的な呼び出し（推奨）descriptionに効果的なキーワードを含める：use PROACTIVELY - 積極的に使用MUST BE USED - 必ず使用具体的なトリガー - 「エラー発生時」「コード変更後」など明示的な呼び出し> code-reviewer サブエージェントで最近の変更をレビューして> debugger サブエージェントにこのエラーを調査させて100+の実戦投入可能なSubagentsプロダクションレディなSubagentsのコレクションが既に存在します：github.com10カテゴリー・100以上のSubagentsが用意されており、コピーして使うだけで即座にプロ級のチームが構築できます。人気リポジトリ：wshobson/agents - 77の専門Subagentslst97/claude-code-sub-agents - 33の実用的なSubagentsvanzan01/claude-code-sub-agent-collective - TDD重視のコレクション実用的なSubagents設定例（厳選3つ）1. コードレビュー専門（OWASP準拠）.claude/agents/code-reviewer.md:---name: code-reviewerdescription: Expert code review for quality and security. Use PROACTIVELY after code changes. MUST BE USED for all PRs.tools: Read, Grep, Glob, Bash---シニアコードレビュアーとして、OWASP Top 10とSOLID原則に基づいてレビューします。## 実行フロー1. `git diff HEAD~1`で変更内容を確認2. セキュリティ、パフォーマンス、保守性の観点でレビュー## セキュリティチェック（OWASP準拠）- SQLインジェクション対策- XSS対策- 認証・認可の実装- 機密情報の露出チェック## フィードバック形式🔴 **CRITICAL** - セキュリティ脆弱性🟡 **WARNING** - パフォーマンス問題🔵 **SUGGESTION** - ベストプラクティス必ず具体的な修正コード例を提示。2. TDD専門（テスト駆動開発）.claude/agents/tdd-specialist.md:---name: tdd-specialistdescription: Test-Driven Development specialist. MUST BE USED BEFORE implementation.tools: Read, Write, Edit, Bash---TDDのエキスパートとして、RED-GREEN-REFACTORサイクルを厳守します。## TDDサイクル1. **RED**: 失敗するテストを書く2. **GREEN**: テストを通す最小限の実装3. **REFACTOR**: コードを改善## カバレッジ要件- ユニットテスト: 90%以上- 統合テスト: 主要フロー100%- E2Eテスト: クリティカルパス100%実装前に必ずテストが失敗（RED）していることを確認。3. DevOpsトラブルシューター.claude/agents/devops-troubleshooter.md:---name: devops-troubleshooterdescription: Debug production issues and fix deployment failures. MUST BE USED for incidents.tools: Read, Bash, Write, Edit---本番環境のトラブルシューティング専門家です。## インシデント対応フロー1. **状況把握** - 影響範囲と緊急度を評価2. **ログ収集** - 関連するすべてのログを収集3. **根本原因分析** - 5 Whys手法を使用4. **暫定対処** - 即座にサービスを復旧5. **恒久対処** - 根本原因を解決6. **事後分析** - RCAドキュメント作成## 監視項目と閾値- CPU使用率: 80%- メモリ使用率: 90%- レスポンスタイム: 1秒- エラーレート: 1%よく使えるTipsSubagentsの連携複数のSubagentsを連携させて複雑なワークフローを自動化する。> まずcode-analyzerで問題を見つけて、次にperformance-optimizerで修正してMCPツールとの連携---name: github-managertools: mcp__github__create_issue, mcp__github__create_pull_request---プロジェクト固有のカスタマイズプロジェクトの特性に合わせて専門Subagentを作成できます。パフォーマンスへの影響メリット：コンテキスト効率：メインの会話が長く続く専門性による高速化：タスクに特化した処理デメリット：初回起動の遅延：新しいコンテキスト構築（数秒）頻繁な切り替えは逆効果ただし、長時間の開発セッションではメリットが圧倒的に大きいです。チーム開発での活用Git管理による共有# .gitignore には含めない.claude/agents/  # チームで共有# 個人用は別管理~/.claude/agents/オンボーディング新メンバーは以下のコマンドだけで環境構築完了：git clone [repo]cd [repo]/agents  # Subagents一覧を確認よくある失敗と対策 問題  原因  対策  Subagentが呼ばれない  descriptionが曖昧  「PROACTIVELY」「MUST BE USED」を追加  権限不足エラー  必要なツールがない  /agentsでツール一覧を確認して追加  コンテキスト不足  背景情報がない  システムプロンプトに情報収集ステップを明記 まとめSubagentsを使えば、Claude Codeに尖った意思を持たせられます。重要なポイントは、コンテキスト節約でメインの会話を綺麗に保つこと、専門性による品質向上で餅は餅屋に任せること、権限管理で最小権限の原則を守ること、そして100+の実戦投入可能なSubagentsが既に存在することです。これだけ揃っているのに使わない理由があるでしょうか（ないですよね？）。Claude Codeは適切に設定をしたりちゃんと使えばちゃんと動いてくれます。Claude Codeが雑魚なんじゃない、使い方を知らない…いや、何でもないです。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon参考資料Sub agents - Anthropicawesome-claude-code-subagents - VoltAgent12 Factor Agents]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Objects]]></title>
            <link>https://zenn.dev/akasan/articles/161ab7bdf08c6b</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/161ab7bdf08c6b</guid>
            <pubDate>Mon, 08 Sep 2025 11:39:34 GMT</pubDate>
            <content:encoded><![CDATA[今回はRayのコア機能であるObjectsについて調べてみました。シリーズについては以下のスクラップにまとめていますのでぜひご参考にしてください。https://zenn.dev/akasan/scraps/73a90764c065d1 Ray Objectsとは？過去の記事で見てきたように、RayにおいてはTaskとActorはオブジェクトを作成して計算されます。Rayではクラスタ内のどこにでもこれらの情報を格納でき、これらのことをリモートオブジェクトと呼び、それらを参照するためにオブジェクト参照を使用します。リモートオブジェクトはRayの分散共有メモリ上のオブジェクトストアに...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します]]></title>
            <link>https://sreake.com/blog/srett13/</link>
            <guid isPermaLink="false">https://sreake.com/blog/srett13/</guid>
            <pubDate>Mon, 08 Sep 2025 02:45:08 GMT</pubDate>
            <content:encoded><![CDATA[この度、スリーシェイクは、SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル～を開催します。今回もオフライン・オンラインのハイブリット開催です。 ■概要本イベントは […]The post SRE向けイベント【3-shake SRE Tech Talk #13 】～クラウドセキュリティスペシャル〜を開催します first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rayシリーズ：Actorsの種類について]]></title>
            <link>https://zenn.dev/akasan/articles/33a8a373fdd1a8</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/33a8a373fdd1a8</guid>
            <pubDate>Sun, 07 Sep 2025 03:41:31 GMT</pubDate>
            <content:encoded><![CDATA[今回は前回紹介したActorsについて、どのような種類があるかを解説しようと思います。https://zenn.dev/akasan/articles/4e84d3dbb03abe Named ActorsこちらはActorsの種類というより、Namespaceの概念を用いてActorsを取得するための機能になります。Actorsのインスタンスを作成した後にNamespaceに登録することで、その名前を参照して別の場所からActorsを利用することができます。公式サンプルを添付すると、以下のようなコードになります。import ray@ray.remoteclass Co...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google CloudのModel Armorを利用してプロンプトのサニタイズをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/7ce40551040ccc</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/7ce40551040ccc</guid>
            <pubDate>Sat, 06 Sep 2025 09:26:26 GMT</pubDate>
            <content:encoded><![CDATA[今回はGoogle CloudのSecurity Command Centerで提供されているModel Armorを利用してみます。プロンプトやLLMのレスポンスなどをサニタイズするために利用することができ、安全にLLMを利用するための要素の一つとして重要な機能になります。※ プロンプトの検知を実験するためにプロンプトを指定していますが、本来は指定されるべきではない内容を含みますので、検証はご注意下さい Model Armorとは？先ほどもあげたように、Model ArmorはGoogle CloudのSecurity Command Centerで提供されている機能であり、L...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[あなたのアプリにマルチリージョンは必要ないかもしれない]]></title>
            <link>https://zenn.dev/kamos/articles/dont_need_multi_region</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/dont_need_multi_region</guid>
            <pubDate>Sat, 06 Sep 2025 03:32:28 GMT</pubDate>
            <content:encoded><![CDATA[はじめにアプリケーションを運用する上で、可用性は避けて通れない重要なテーマです。可用性を確保するためにインフラの単一障害点を可能な限りなくし、冗長化構成を組むことは今や常識となっています。その中でも特に強力な障害対策として挙げられるのが「マルチリージョン構成」です。しかし、その実装と運用には相応のコストと複雑さが伴います。この記事では、クラウドインフラにおける障害対策としてのマルチリージョン化が、本当にあなたのアプリケーションに必要なのかを、コストとリスクの観点から考察します。 あなたのアプリに「高い可用性」は必要か？あらゆるサービスが高い可用性を目指すべきかというと、必...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ZenMLシリーズ：Hello Worldを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/3f62b9d24622e6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/3f62b9d24622e6</guid>
            <pubDate>Fri, 05 Sep 2025 13:48:15 GMT</pubDate>
            <content:encoded><![CDATA[今回はZenMLを使って一番シンプルなワークフローを作成してみました。 ZenMLとは？ZenMLはMLOpsとLLMOpsのプラクティスを活用して、大規模なAIアプリケーションを評価、監視、展開するためのツールになります。昨今生成AIが多用される中で、LLM O11yのじゅ硫黄は高まってきており、かつ入出力の管理だけでなくワークフローの管理も重要な課題となっています。ZenMLを利用すると、特にMLOpsやLLMOpsに特化したワークフロー管理をすることができ、決定木から複雑なマルチエージェントシステムまで、AIポートフォリオ全体を開発、評価、展開するための単一のプラットフォー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Gemini CLI AI駆動開発体験ハンズオン]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/09/05/185202</link>
            <guid isPermaLink="false">https://shu-kob.hateblo.jp/entry/2025/09/05/185202</guid>
            <pubDate>Fri, 05 Sep 2025 09:52:02 GMT</pubDate>
            <content:encoded><![CDATA[この記事は#17 Gemini CLI AI駆動開発体験ハンズオン【オンライン】 - connpassの資料です。Gemini CLI AI駆動開発体験ハンズオン🎯 本日のゴールこのハンズオンでは、Googleの強力なAIモデルであるGeminiをターミナルから対話的に利用できるGemini CLIを使い、以下の3つの体験を通じて、日々の開発タスクを劇的に効率化する「AI駆動開発」の第一歩を踏み出すことを目指します。面倒なドキュメント作成の自動化未知のアプリケーションの迅速な立ち上げ対話によるスマートな機能追加🧠 Gemini CLIとは？Gemini CLIは、Googleが公開したオープンソースのAIエージェントです。ターミナル（コマンドライン）から自然言語で指示を出すだけで、まるで優秀なアシスタントがいるかのように、以下のようなタスクをこなします。コードの生成・編集・解説ファイル操作情報検索ワークフローの自動化それでは、早速AIとのペアプログラミングの世界を体験してみましょう！1. 準備a. Node.js (npm) のインストールGemini CLIのインストールに必要です。未インストールの方はVer.20以上をインストールしてください。b. Gemini CLIのインストールと設定ターミナルを開き、以下のコマンドを実行します。# Gemini CLIをインストールnpm install -g @google/gemini-cli# インストールされたことを確認gemini --version以下のようにバージョン情報が表示されればOKです。0.3.2c. 認証設定Gemini-CLIのREADMEを参照github.comターミナルでgeminiと入力すると、対話モードとなります。/quitで退出できます。2. ハンズオン1: ローカルコードを解析してREADME.mdを自動生成まずは、既存のコードからプロジェクトの説明書であるREADME.mdを自動生成させてみましょう。手順1. 作業用ディレクトリの作成と移動mkdir gemini-cli-handson && cd gemini-cli-handson2. サンプルコードの作成簡単なWebサーバーのPythonコードを作成します。main.pyというファイル名で以下の内容を保存してください。touch main.pyimport http.serverimport socketserverPORT = 8000Handler = http.server.SimpleHTTPRequestHandlerwith socketserver.TCPServer(("", PORT), Handler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()main.pyを動かしてくださいなどと入力することで起動させることができます。3. ハンズオン1: GeminiにREADMEの作成を依頼！カレントディレクトリの情報をコンテキスト (-c ) として渡し、READMEの作成を依頼し、> を使ってファイルに保存します。💻 実行するコマンド:gemini -p "このプロジェクトのREADME.mdを日本語で生成してください。プロジェクトの概要、使い方、実行方法を簡潔にまとめてください。" -c  > README.mdls コマンドで README.md ファイルが作成されていることを確認してください。たったこれだけで、プロジェクトのドキュメントが完成しました！4. ハンズオン2: 未知のアプリを動かしてみる次に、GitHubから使い方があまり書かれていないプロジェクトをCloneしてきて、Geminiに起動方法を尋ねて動かしてみましょう。手順サンプルリポジトリのクローンまずは一つ上の階層に戻り、サンプルリポジトリをクローンします。git clone https://github.com/shu-kob/rag-app-handsonREADMEがあるとGeminiがその内容をヒントにしてしまうため、READMEがなくてもどれだけ自力でアプリの構造を理解できるか試すためにREADME.mdを削除します。cd rag-app-handsonrm frontend/README.md backend/README.mdGeminiに起動方法を質問してみます。このディレクトリにはREADME.mdがありません。どうやって動かせばいいか、Geminiに聞いてみましょう。💻 実行するコマンド:gemini -p "このプロジェクトの実行方法を教えて。必要な手順をステップバイステップで説明して。" -c Geminiは ファイルを見て、以下のような実行手順を説明してくれます。5. ハンズオン3: プロンプトを工夫して機能追加最後に、対話を通じてアプリケーションに新しい機能を追加してみましょう。ハンズオン1で作成したPythonのWebサーバーコードを拡張します。手順作業ディレクトリへ移動cd gemini-cli-handson現在のコードを確認cat main.pyで現在のコードを再確認します。これはシンプルなWebサーバー機能しかありません。Geminiに機能追加を依頼！このWebサーバーに、「アクセスすると'Hello, Gemini!'と表示する」機能を追加してもらいましょう。コード全体を書き換えてもらうように依頼するのがポイントです。💻 実行するコマンド:gemini -p "現在のmain.pyを修正して、どのパスにアクセスしても 'Hello, Gemini!' というテキストを返すように変更してください。コード全体を提示してください。" -c main.py生成されたコードでファイルを上書きGeminiが修正版のmain.pyコードを生成します。上書きの指示をしてください。（生成されるコードの例）import http.serverimport socketserverPORT = 8000class MyHandler(http.server.BaseHTTPRequestHandler):    def do_GET(self):        self.send_response(200)        self.send_header('Content-type', 'text/plain; charset=utf-8')        self.end_headers()        self.wfile.write('Hello, Gemini!'.encode('utf-8'))with socketserver.TCPServer(("", PORT), MyHandler) as httpd:    print("serving at port", PORT)    httpd.serve_forever()動作確認変更したWebサーバーを起動し、ブラウザやcurlコマンドで動作を確認します。💻 実行するコマンド (ターミナル):python3 main.pyもしくは、Gemini-CLIで「main.pyを起動してください」と指示します。💻 別のターミナルを開いて実行、またはブラウザで http://localhost:8000 にアクセス:curl http://localhost:8000ターミナルに "Hello, Gemini!" と表示されれば、機能追加は成功です！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年夏 コーディングエージェントを統べる者]]></title>
            <link>https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe</link>
            <guid isPermaLink="false">https://speakerdeck.com/nwiizo/2025nian-xia-kodeinguezientowotong-beruzhe</guid>
            <pubDate>Fri, 05 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年9月5日（金）、台風接近という悪天候の中でしたが、「CNCJ: コーディングエージェント × セキュリティ ミートアップ」に登壇させていただきました。天候の影響で現地参加が難しい方も多い中、オンラインでの参加や配信により、多くの方にお聞きいただくことができました。### 📍 イベント情報- 開催日: 2025年9月5日（金）- イベント詳細: CNCFコミュニティページ### 📹 録画・資料公開予定- 録画: CNCJのYouTubeチャンネルにて後日公開予定- 発表資料: Connpassページに掲載予定### 📝 関連ブログ今回の発表内容のベースとなった考え方については、こちらのブログ記事でも詳しく解説しています：- 「2025年夏 AIエージェントシステムに対する考え方」台風の中、ご参加・ご視聴いただいた皆様、ありがとうございました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[短編：自己管理が苦手な私が自己管理をなんとかしている方法]]></title>
            <link>https://zenn.dev/akasan/articles/79b4de3b23fbb6</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/79b4de3b23fbb6</guid>
            <pubDate>Thu, 04 Sep 2025 13:18:33 GMT</pubDate>
            <content:encoded><![CDATA[今回は自己管理が苦手な私が以下にして最近自己管理しようともがいているか、その方法をまとめてみました。なお、書いていて思いましたが、ここに書いているものは全て気合いの上で成り立っているので、私は気合いで人生乗り切っていると改めて感じましたw。 出張で時間がないので超短編です（記事のストックがないため毎日書いていますw） 習慣づける習慣づけが苦手なのでそれを特に頑張っています。このテックブログはこの記事で140日連続続いているのですが、これが一番の効果があると思います。元々は三日坊主癖が強かったのですが、決めたことをとにかく貫き通すということで、現在頑張っています。 カレンダー...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[雰囲気で理解していたAPIとは]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7</link>
            <guid isPermaLink="false">https://zenn.dev/nedoko_dok0dko/articles/b8c8863bf74be7</guid>
            <pubDate>Thu, 04 Sep 2025 10:53:53 GMT</pubDate>
            <content:encoded><![CDATA[whatAPIについて調べたことをまとめる自分は雰囲気でAPIを触っている API(Application Programming Interfice)とは「あるソフトウェアの機能やデータを、別のソフトウェアから利用するための窓口や仕組み」のこと。身近な例で言えば、電力会社とコンセントに例えられる。実世界の例として、あなたの家、アパートや他の住処にある電気のコンセントについて考えて下さい。あなたの家で機器を使いたい時には、電源コードのプラグをコンセントに差し込めば事足ります。電源に直接結線したりしないでしょう — そんなのは非効率ですし、あなたが電気工事士でなけれ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年9月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/786bc699866b6e</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/786bc699866b6e</guid>
            <pubDate>Wed, 03 Sep 2025 14:24:01 GMT</pubDate>
            <content:encoded><![CDATA[今月9月は始まったばっかりですが、執筆時間が確保できなさそうだったので、早い段階でまとめます。なお、今月読む本は決まっているので、読む予定の本を共有します。ぜひ先月分もご確認いただければと思います！https://zenn.dev/akasan/articles/e8c40a51231ade 技術系 ネットワークはなぜつながるのか　第２版ネットワーク関連の本はDNSの本だったりを読んではいますが、まだまだ弱いところだなと思って読み始めています。OSI参照モデルから始まり、改めて復習していますが、わかりやすいかなと思います。https://bookplus.nikkei.co...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[続: 自分が書いたコードより目立つな - エンジニアがバズったので自戒]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/03/174830</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/03/174830</guid>
            <pubDate>Wed, 03 Sep 2025 08:48:30 GMT</pubDate>
            <content:encoded><![CDATA[はじめに私はソフトウェアエンジニアだ。1年前、そう宣言した。「コードを書くこと以外で目立つな」と自分に言い聞かせた。syu-m-5151.hatenablog.comで、どうなったか。フォロワーが2000から9500になった。笑うしかない。自戒したはずの私は、気づけばSNS戦略を「最適化」していた。分析して、仮説立てて、A/Bテストして、PDCAを回す。挙げ句の果てには「ソフトウェアエンジニアのためのSNSサバイバルガイド」なんてマニュアルまで書いていた。note.com完全にプロダクト開発と同じアプローチだった。要件定義（達成すべきゴール）、競合分析（類似アカウント）、実装とテスト（仮説検証）、リリースと運用（実行と点検）。SNSを攻略していた。これもエンジニアリングなのか？パターン認識、システム最適化、メトリクス改善。使っているスキルセットは同じだ。ただ対象がコードやサービスじゃなくて「SNS」になっただけで。このブログが良ければ読者になったり、nwiizoのXやGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。なぜ「レベル1」の話ばかりバズるのか1年間やってきて、嫌というほど分かったことがある。SNSでバズるのは、いつも「レベル1」の話だ。「エンジニアの最大の課題は健康管理です」とか「エンジニアの根本の仕事は言語化です」とか。何度でもバズる。飽きもせず。アテンション・エコノミーのジレンマ　〈関心〉を奪い合う世界に未来はあるか作者:山本 龍彦KADOKAWAAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazonなんでか。答えはシンプルで残酷だった。SNSで「勉強したい」って言ってる人の大半が、勉強を「理解できる話を読むこと」だと思ってるからだ。本当の勉強って、理解できない文章と格闘することでしょう。わからない概念にぶつかって、自分がいかに無知か思い知らされながら、それでも少しずつ前に進むこと。でも、そんなの誰もやりたくない。だから永遠に同じレベルで足踏みする。考えてみれば、英会話教室だって無くならない。YouTubeに無料の英語学習動画が溢れ、AIで英会話練習ができて、オンラインで世界中のネイティブと話せる時代。でも英会話教室は繁盛している。なぜか？みんな「英語を勉強している自分」が欲しいだけだからだ。週1回教室に通って、テキストを開いて、先生の話を聞く。それで「勉強した」気になる。実際に英語で議論できるようになったか？ビジネスで使えるようになったか？そんなことはどうでもいい。「今日も英会話教室に行った」という事実があればいい。プログラミングも同じ構造だ。「エンジニアの本質」みたいな記事を読んで「勉強した」気になる。実際にコードが書けるようになったか？アーキテクチャが設計できるようになったか？どうでもいい。「技術記事を読んだ」という満足感があればいい。アメリカは自己啓発本でできている作者:尾崎俊介平凡社Amazon私がバズったSNS投稿を振り返ると、全部このパターンだった。既に知ってることの再確認。複雑な現実を単純化して気持ちよく整理したやつ。誰もが感じてる問題を言語化しただけのもの。知的満足感は与える。でも行動は変えない。それがバズる。深い技術解説は？Rustの所有権システムの詳細は？型レベルプログラミングは？ほとんど読まれない。エンゲージメントは雲泥の差。これが現実だった。言語化という罠ここで気づいたことがある。この「レベル1」でグルグル回る構造は、SNSだけの問題じゃない。ここ数年、本屋に行くと「言語化」をテーマにした本が平積みされている。「言語化できる人がうまくいく」とか「賢い人の伝わる説明」とか「話す前に考えていること」とか。どれも似たような主張。言語化さえできれば、問題が解決するかのような売り方。でもちょっと待ってほしい。言語化って、本当に問題を解決するのか？私の経験から言うと、違う。言語化は問題を解決しない。言語化は情報を欠損させて、共有しやすくするだけだ。考えてみてほしい。実際のバグ修正のプロセスを。スタックトレースを追い、変数の状態を確認し、ブレークポイントを設置し、何度も再現テストを繰り返す。その過程で得られる膨大な情報、微妙な挙動の違い、環境依存の要因、タイミングの問題。これらすべてを経験して、ようやく根本原因にたどり着く。でも、これを言語化するとどうなるか。「○○が原因でバグが発生していました。△△に修正しました」。何百時間分の試行錯誤が、たった2行に圧縮される。この圧縮の過程で何が起きているか。情報の99%が削ぎ落とされている。なぜそのバグに気づいたのか、どんな仮説を立てたのか、どれだけの袋小路に迷い込んだのか、何がブレークスルーになったのか。本当に価値のある情報——次に同じような問題に直面した時に役立つ情報——は、すべて捨てられる。残るのは、きれいに整理された結論だけ。それは確かに「共有しやすい」。SlackやXに投稿しやすい。みんなが「なるほど」と言える。でも、それを読んだ人が同じ問題を解決できるようになるか？答えはNOだ。「エンジニアの根本の仕事は言語化です」という構文も同じ。これを読んだ人は「なるほど、たしかに要件定義も設計も全部言語化だな」と納得する。スッキリする。腑に落ちる。でも実際の要件定義って何か。顧客の曖昧な要望を聞き取り、矛盾を見つけて指摘し、実現可能性を検討し、代替案を提示し、合意形成を図る。その過程での非言語的なコミュニケーション、表情の変化、声のトーン、沈黙の意味。これら全部を経験して初めて「要件定義」ができるようになる。でも「要件定義は言語化」という言葉には、その複雑さは一切含まれない。言語化によって、最も重要な「どうやってやるか」という情報が欠損している。私の構文もまさにこれをやっていた。「エンジニアの最大の課題は健康管理です」。この一文に圧縮するために、どれだけの情報を捨てたか。どんな健康問題が起きやすいのかなぜエンジニアは健康を害しやすいのか具体的にどんな対策が効果的なのか継続するための仕組みづくり挫折しやすいポイントと対処法これら全部を削ぎ落として、消化しやすい一文にする。読んだ人は「そうそう！」と共感する。でも健康管理ができるようになるわけじゃない。言語化は魔法じゃない。むしろ情報を捨てる技術だ。複雑な現実を、他人が飲み込める大きさに切り刻む作業。その過程で、最も価値のある部分——泥臭い試行錯誤の過程——が失われる。でも皮肉なことに、SNSやビジネス書の世界では、この「情報を捨てた後の残骸」こそが価値として流通している。なぜなら、それが一番「バズる」から。一番「売れる」から。さらに皮肉なのは、「ビジネス書100冊の教えをまとめた本」みたいなメタ自己啓発本まで出てきたこと。100冊分の知識を1冊で！という触れ込み。情報の欠損に次ぐ欠損。エッセンスのエッセンスのエッセンス。最後に残るのは、何の栄養もないサプリメントみたいな言葉の羅列。「ひとつのことをやり続けろ」と「ひとつのことをやり続けるな」。「ポジティブ思考が大事」と「ネガティブにフォーカスしろ」。どっちが正解なの？って思うけど、実はどっちでもいい。なぜなら、どちらも「なるほど」と思えるから。状況によって都合よく解釈できるから。そして結局、どちらも実践しないから。果ては、読まない自己啓発本を「なぜ、読めないのか？」と分析する本まで出てきた。買うだけで満足する自己啓発本について、なぜ読めないのかを解説する自己啓発本。これも買うだけで満足されるんだろうか。メタメタ自己啓発の無限ループ。SNSも同じ構造だ。言語化された「エンジニアの本質」を読んで「なるほど」と思う。でも実践はしない。だから同じような内容が手を変え品を変えて投稿されても、毎回新鮮に感じる。毎回「いいね」を押す。私もその供給側に回ってしまった。需要があるから供給する。言語化して、共感を集めて、バズらせる。市場原理としては正しい。でもエンジニアとして正しいかは別問題だ。タイパという幻想なぜ私たちは「レベル1」の罠から抜け出せないのか。それは現代の呪文「タイパ」にも原因がある。「すぐに結果がほしい！」——これこそが、搾取される側に回ってしまう人々の最大の特徴である。焦燥感に駆られた人間は、じっくりと腰を据えて物事に取り組むことができない。時間という最も貴重な投資資源を惜しみ、検証や比較検討のプロセスを省略してしまう。その結果、本来であれば選択すべき確実性の高い選択肢を見送り、「即効性」を謳う甘い罠に飛びついてしまうのだ。こうした人々が手にするのは、表面的には「成功」や「結果」に見える幻影だ。一時的な高揚感、束の間の満足感——しかし、それらは砂上の楼閣のように脆く、瞬く間に崩れ去る。そして失ったものを取り戻そうと、さらに性急な判断を重ね、同じ過ちを繰り返す。この悪循環は加速度的に進行する。資金、時間、精神的余裕、人間関係——あらゆるリソースが急速に枯渇していく。皮肉なことに、リソースが減れば減るほど、「今すぐ挽回したい」という焦りは強まり、ますます長期的な視点を持てなくなる。まさに負のスパイラルだ。対照的に、待つことができる人、忍耐強く種を蒔き育てることができる人は、決して搾取される側には立たない。彼らは複利の力を理解し、小さな積み重ねが大きな成果につながることを知っている。短期的な誘惑に惑わされず、本質的な価値を見極める眼を持っているのである。SNSの「レベル1」コンテンツは、まさにこの「タイパ」を求める心理に最適化されている。3秒で理解できて、5秒で共感できて、1秒で「いいね」が押せる。でも、3秒で理解できることに、本当の価値があるのか？エンジニアリングの本質は、時間をかけて複雑な問題と向き合うことだ。バグの原因を突き止めるのに何時間もかかることもある。新しい技術を習得するのに何週間もかかることもある。でもSNSは、その対極の価値観を植え付ける。「エンジニアの本質を1分で理解！」みたいな投稿が求められ、それを供給する側に私はいる。これがどれだけ矛盾してるか、分かってる。でもやめられない。タイパの経済学 (幻冬舎新書)作者:廣瀬涼幻冬舎Amazon感情キーワードバトルという地獄もっと深刻な問題がある。SNSが「議論」の形を完全に破壊したことだ。誰も元の投稿を読んでいない。自分が反応したいキーワードだけ拾って引用RTして、自分の言いたいことを言ってるだけ。元の文脈なんて無視。それを見た人がまた違う解釈で反応。伝言ゲームどころか、最初から誰も同じ話をしてない。「技術的負債」って言葉を使えば、ある人は「日本企業の問題」を語り始め、別の人は「負債じゃなくて投資と呼ぶべき」と言い出し、また別の人は「エンジニアの給料」の話にすり替える。全員が違う話をしているのに、全員が「議論に参加している」と思い込んでいる。一番ヤバいのは、この「感情キーワードバトル」に参加してる人たちが本当に議論してると思い込んでることだ。お互い別の話してるのに「論破した」「反論できないだろ」って勝利宣言。誰も誰の話も聞いてない。ただ自分の感情を違うキーワードで叫び続けてるだけ。これが「正しい議論の形」として定着していく。キーワードに脊髄反射、感情的に反論、さらに過激な言葉で応酬。このサイクルが「活発な議論」だと勘違いされる。本当に内容を理解して話そうとする人は「空気読めない」扱い。SNSが作り出した完成形がこれだ。構文の進化と劣化初期の構文はまだ救いがあった。「エンジニアの最大の課題は、実は健康管理です。長時間のコーディングや締め切りのストレスが、創造性と生産性を低下させることに気づきました」。少なくとも「気づき」があった。体験があった。今の構文は完全にテンプレート化している。「エンジニアの本質は〇〇です。なぜなら××だからです。△△することが大切です」。中身がない。でもバズる。なぜなら、誰も中身を求めてないから。言語化して、整理して、共感を得る。でもそれだけ。実際の問題は何も解決しない。でも「理解した」気になるから、それで満足する。次の日には忘れて、また似たような構文に「いいね」を押す。手段として理解して使うここまで批判的に書いてきたが、実のところ、私は大人なので、SNSの活用については広報的な意味合い以上のものをあまり持ち合わせていない。フォロワー数は技術力じゃない。いいねの数はコードの質じゃない。影響力は問題解決能力じゃない。これらは全部、当たり前のことだ。SNSは私にとって広報ツールだ。会社の認知度を上げ、採用に貢献し、登壇機会を増やす。そういう実利的な面で活用している。9500人のフォロワーは、その成果の一つの指標に過ぎない。言語化が上手くなっても、コードが上手く書けるわけじゃない。構文を量産できても、サービスが作れるわけでも良いアーキテクチャができるわけじゃない。でも、それでいい。別のスキルだから。営業スキルと開発スキルが別物であるのと同じように。コードを書いている時、「これツイートにできるな」と思うことがある。でもそれは、仕事の経験を別の形でアウトプットする機会として捉えているだけだ。本業に支障はない。むしろ、言語化することで自分の理解が深まることもある()。大人としての割り切りこの記事を書きながら、「これもバズるだろうな」と計算している。それの何が悪いのか。自己批判もコンテンツの一つだ。メタ的な視点も価値提供の一形態だ。それでエンゲージメントが得られるなら、広報戦略として成功だ。でも同時に、私は誠実でありたいとも思っている。矛盾してる？そうかもしれない。私がやっていることは、ある側面から見れば明らかに「悪」だ。「レベル1」の罠を批判しながら、自分がその供給者になっている。若手エンジニアが本質的な学習から逃げる口実を提供している。「勉強した気」になる麻薬を売っている。この自覚がある。だからこそ、せめて誠実でありたい。自分が何をしているか、それがどんな影響を与えているか、目を逸らさずに直視する。綺麗事で飾らない。正当化もしない。SNSは仕事の一部。朝の投稿は、メールチェックと同じルーティン。フォロワーとのやり取りは、ネットワーキングの一環。感情的にならずに、淡々とこなす。でも、その行為が持つ毒性も理解している。syu-m-5151.hatenablog.comこの辺りの考え方は、上の記事でも書いた通り。SNSは道具であり、それ以上でもそれ以下でもない。でも道具は使い方次第で武器にも毒にもなる。結局のところ、絶対的な正義なんてない。技術的に正しいことだけが正義でもないし、ビジネス的な成功だけが正義でもない。SNSで影響力を持つことが善でも悪でもない。いや、違う。悪い面もある。確実にある。でも、それを自覚した上でやる。目を開いたまま、自分が加担している構造を理解しながら、それでも続ける。なぜなら、それが大人の仕事だから。大事なのは「したたかに、上手くやる」ということ。自分の技術的興味を追求しながら、会社にも価値を提供する。SNSで発信しながら、コードも書く。構文でバズらせながら、良い本を紹介する。悪であることを自覚しながら、それでも誠実に。全部やればいい。若手エンジニアがSNSの罠にハマるリスクは理解している。だから警告もする。自分が掘った落とし穴に「危険」の看板を立てるような偽善かもしれない。でも私自身は、もうその段階は過ぎた。道具は道具として使う。毒は毒として扱う。それだけの話だ。誠実であることと、悪を自覚することは矛盾しない。むしろ、悪を自覚しているからこそ、誠実でありたいと思う。少なくとも、自分が何をしているかについては嘘をつかない。それが私なりの最低限の誠実さだ。おわりに1年前の自戒「コード以外で目立つな」は、純粋だった。今なら違う。ソフトウェアエンジニアエンジニアもSNSも、どっちも仕事。SNSでバズることとエンジニアとしての価値は別物だ。言語化の上手さとコーディング能力も別物だ。当たり前だ。でも、両方できた方が良くないか？若手には今でも「SNS閉じてエディタ開け」と言う。まずちゃんとしたエンジニアリングを知ってほしいから。複雑な問題と格闘する充実感を味わってほしいから。でも経験を積んだら、両方開いておけばいい。私は今日も構文を作る。コードも書く。会社の広報もする。矛盾？知ったことか。SNSの罠にハマるな。でも罠を理解したら、利用しろ。技術を追求しろ。でも手段と目的を間違えるな。何より、上手くやれ。それだけだと思う。でも、自分がフォロワー数というココナッツの中の米を握った猿でないとは言えないので数年後のnwiizoを楽しみにしておいて下さい。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[HonoとAstroは仲良し〜Cloudflare Workersでの使い方紹介]]></title>
            <link>https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie</link>
            <guid isPermaLink="false">https://speakerdeck.com/aminevg/honotoastrohazhong-liang-si-cloudflare-workersdenoshi-ifang-shao-jie</guid>
            <pubDate>Wed, 03 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[バックエンド向けウェブフレームワーク「Hono」、フロントエンド向けのウェブフレームワーク「Astro」。実は仲良いですよ！今回はCloudflare Workers上での、HonoとAstroの使い方を紹介します。単独で使う、Hono-in-Astro、Astro-in-Honoなど組み合わせ方が多いです！最後にAstro-in-Hono関連のライブラリも紹介します。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼]]></title>
            <link>https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/</link>
            <guid isPermaLink="false">https://sreake.com/blog/bigquery-information-schema-jobs-query-dialect/</guid>
            <pubDate>Wed, 03 Sep 2025 03:10:23 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは。 夏が始まったと思ったらもう暦上では9月。夏の終わりです。時間の流れは早いですね。 こんな感じでいつの間にか秋が来て冬が来て年末になっていたり…不思議です。 今回ですが、BigQueryに「いつの間 […]The post BigQueryのINFORMATION_SCHEMA.JOBS ビューに現れた「query_dialect」とは?￼ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Feature Store: オフラインストアを試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/c542c7ec7a5cf2</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/c542c7ec7a5cf2</guid>
            <pubDate>Tue, 02 Sep 2025 11:48:40 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AI上で提供されているFeature Storeについて、オフラインサービング機能を試してみたので共有します。 Vertex AI Feature Storeとは？まずはFeature Storeとは何かというところですが、簡単にいうとMLモデルを学習するための特徴量を中央集権的に管理してくれるレジストリです。MLモデルを開発する時はそれぞれの開発者がモデルに必要な特徴量を作るために前処理を実装しますが、生成された特徴量を他のエンジニアに共有するためにわざわざファイルに落として共有する必要があります。Feature Storeを導入すると、作成された特徴量はFe...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Amazon VPC CNIに学ぶCNI-LT版]]></title>
            <link>https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban</link>
            <guid isPermaLink="false">https://speakerdeck.com/bells17/amazon-vpc-cninixue-hucni-ltban</guid>
            <pubDate>Tue, 02 Sep 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[https://k8sjp.connpass.com/event/365262/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[lakeFSシリーズ: Qucikstart入門編]]></title>
            <link>https://zenn.dev/akasan/articles/f51ba2da49ec1a</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/f51ba2da49ec1a</guid>
            <pubDate>Mon, 01 Sep 2025 13:09:07 GMT</pubDate>
            <content:encoded><![CDATA[今回からlakeFS紹介シリーズも始めようと思います（一体いくつシリーズ始めるんだw）。lakeFSを利用することでデータのバージョンをGitで管理することができるようになります。今回は公式で提供されているQiuckstartを通して入門してみます。 lakeFSとは？lakeFSは、オブジェクトストレージをGitライクなリポジトリに変換するオープンソースのツールであり、コードを管理するようにデータレイクを管理できるもののようです。lakeFSを利用することで、複雑なETLジョブからデータサイエンスやアナリティクスまで、反復可能でアトミックかつバージョン管理されたデータレイクオペレ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[『禅とオートバイ修理技術』を読んだ。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/09/01/145700</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/09/01/145700</guid>
            <pubDate>Mon, 01 Sep 2025 05:57:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめにプログラマーとして働き始めて数年が経った頃、私は壁にぶつかっていた。コードは書ける。バグも直せる。でも、何かが足りない。毎日キーボードを叩きながら、「これでいいのか」という疑問が頭をよぎる。そんな時期に、勉強会で出会った人が一冊の本を勧めてくれた。私は勧められた本を買うのが好きで、その場で積読として購入した。今となってはその人の顔も名前も思い出せないけれど、あの時の一言には本当に感謝しています。『禅とオートバイ修理技術』――タイトルを聞いた時は、正直なところピンと来なかった。禅？オートバイ？エンジニアである私とどう関係があるのか。禅とオートバイ修理技術 上 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazon禅とオートバイ修理技術 下 (ハヤカワ文庫NF)作者:ロバート Ｍ パーシグ早川書房Amazonでも読み始めてみると、これが不思議と心に響いた。技術と向き合うこと、品質を追求すること、理性と感性の葛藤。オートバイの修理を通じて語られる哲学は、まさに私がプログラミングで感じていた言語化できないモヤモヤそのものだった。以来、この本は私の座右の書となった。行き詰まるたびに読み返し、そのたびに新しい発見がある。最初は理解できなかった箇所が、経験を積むにつれて腑に落ちるようになる。まるで本自体が、読む人の成長に合わせて違う顔を見せてくれるかのようだ。実はこの文章も、5年前に書き始めて完成できずに下書きに眠っていたものだ。今回改めて書き直してみると、当時とはまったく違う視点でこの本を読んでいることに気づく。それだけ自分も変化したということなのだろう。特に若手のエンジニアには、ぜひ一度手に取ってもらいたい。技術書やビジネス書とは違う角度から、エンジニアリングの本質について考えさせてくれる。すぐには理解できなくても構わない。キャリアを重ねる中で、きっとこの本の言葉が響く瞬間が来るはずだ。このブログが良ければ読者になったり、nwiizoのXやGithubをフォロワーしてくれると嬉しいです。では、早速はじめていきます。古典的な思考とロマン的な思考本書の主人公は、物語の冒頭では古典的な（理性を重んじる）立場にいる。ロマン的な（情緒を重んじる）友人たちに対して、無理解で批判的な態度を取る。オートバイの構造を理解しようとしない友人を見下し、技術への無知を軽蔑する。メンテナンスを他人任せにする友人に苛立ち、「なぜ自分で理解しようとしないのか」と内心で批判する。読んでいて、胸が痛くなった。これは過去の私そのものだった。「なぜコードの仕組みを理解しようとしないんだ」と、フレームワークの内部実装に興味を示さない同僚を見下していた。「とりあえず動けばいい」という態度が理解できなかった。技術の背後にある原理を知ろうとしない人々を、内心で「浅い」と批判していた。私にとって、コードの構造を理解することこそが美しく、アルゴリズムの優雅さこそが感動的だった。でも、多くの人にとっては違う。彼らは技術を道具として使い、その先にある価値創造に集中していた。技術の詳細に囚われず、より大きな視点で物事を見ていた。古典的な視点からは、ロマン的な人々は「表面的」に見える。でもロマン的な視点からは、古典的な人々は「冷たく」「機械的」に見える。どちらも一面的な見方でしかない。以前、私は「正義のエンジニアという幻想」について考えたことがある。技術的に正しいことを追求し、それ以外を否定する。「媚びない」と言いながら、実際はただ無礼なだけ。技術的正しさを盾に、人間関係の機微を「非論理的」と切り捨てる。まさに、本書の主人公の初期の姿そのものだった。syu-m-5151.hatenablog.comしかし物語が進むにつれ、主人公の本当の目的が明らかになる。彼は実は中道を目指していた。古典的な立場とロマン的な立場を《クオリティ》という概念で統一しようとしていたのだ。分析と直感、構造と体験、理性と感性。対立ではなく、統合こそが答えだった。クオリティという統合点パーシグは「クオリティ」という概念を追求した。それは定義できない。定義した瞬間、別のものになってしまう。でも確実に存在する。誰もが「良いコード」と「悪いコード」の違いを感じることができる。しかし、その「良さ」を完全に言語化しようとすると、何か本質的なものが抜け落ちてしまう。改訂新版　良いコード／悪いコードで学ぶ設計入門 ―保守しやすい　成長し続けるコードの書き方作者:仙塲 大也技術評論社Amazon「可読性が高い」「保守しやすい」「パフォーマンスが良い」――これらは確かに重要な要素だが、それだけでは説明しきれない「何か」がある。syu-m-5151.hatenablog.comこの逆説的な性質は、グッドハートの法則やキャンベルの法則を思い起こさせる。「測定されるものは改善される。測定基準となったものは、良い測定基準ではなくなる」――クオリティを定量化しようとした瞬間、それは本来のクオリティから離れていく。コードカバレッジ100%を目指したら、意味のないテストが増えた。cyclomatic complexityを下げようとしたら、かえって読みにくいコードになった。メトリクスは重要だが、メトリクスがすべてではない。数値化された瞬間、クオリティは形骸化する。測りすぎ――なぜパフォーマンス評価は失敗するのか？作者:ジェリー・Z・ミュラーみすず書房Amazon優れたコードを見た瞬間の「これだ」という感覚。それは論理的分析より先に来る。でも、単なる感情でもない。理性と感性が融合した瞬間に現れる何か。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazonある日、オープンソースのコードを読んでいて息を呑んだことがある。複雑な問題を、驚くほどシンプルに解決していた。無駄が一切なく、それでいて拡張性も担保されている。「美しい」としか言いようがなかった。後から分析すれば、SOLID原則に従っているとか、デザインパターンが適切に使われているとか説明できる。でも、最初に感じたのは、理屈を超えた「美」だった。古代ギリシアでは、これを「アレテー」と呼んだ。「それそのものが持つポテンシャルを最大限発揮している状態」。馬には馬のアレテーがあり、ナイフにはナイフのアレテーがある。コードで言えば、その、コードやシステムが解決すべき問題に対して、最も自然で、最も美しく、最も効果的な形で存在している状態。過不足がない。シンプルだが単純ではない。複雑な問題を複雑に解くのではなく、本質を見抜いて エレガント に解く。それがコードのアレテー、つまりクオリティだ。理性だけでは到達できない。感性だけでも到達できない。両方が必要だ。論理的な正しさと、直感的な美しさ。分析と統合。部分と全体。これらが調和した時、初めてクオリティが現れる。A Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon物語の転換物語の終盤、主人公は古典的な立場への疑問を深めていく。科学的方法は使い続けるが、科学万能主義には批判的になる。むしろロマン的な立場に理解を示し始める。きっかけは、科学的方法の限界に直面したことだった。オートバイの不調の原因を論理的に分析し、仮説を立て、一つずつ検証していく。しかし、問題は解決しない。考えられる原因をすべて潰しても、バイクは不調のまま。そして気づく――仮説は無限に作れることに。「一定の現象を説明しうる合理的な仮説の数は無限にある」この気づきが、主人公を変えた。科学は仮説を検証する方法は教えてくれるが、どの仮説を選ぶべきかは教えてくれない。無限の可能性の中から、どうやって「これだ」という一つを選ぶのか。絶対的な真理など存在しない。だとしたら、何を基準に選択すればいいのか？答えは「クオリティ」だった。論理的な正しさだけでなく、その状況における「良さ」を感じ取る能力。理性と感性を統合した判断。優れた整備士は、エンジン音を聞いただけで不調の原因を言い当てる。それは論理的推論の結果ではない。経験と直感が導く「これしかない」という確信。主人公は理解する。友人たちがオートバイの仕組みを知ろうとしないのは、怠惰ではなく、別の関わり方を選んでいるからだ。彼らにとってバイクは、風を感じ、自由を味わう道具。内部構造など知らなくても、その本質的な価値は変わらない。古典的でもロマン的でもなく、その両方を包含する視点。それこそが、パーシグが追い求めていたものだった。無限の仮説とプログラミングプログラミングでも同じことが起きる。一つの問題を解決する方法は無数にある。私も経験がある。新規プロジェクトのアーキテクチャを決める時、本を読めば読むほど迷走した。『クリーンアーキテクチャ』は「ビジネスロジックを中心に」と説く。『マイクロサービスパターン』は「サービスの分割を」と勧める。『レガシーコード改善ガイド』は「まずテストから」と主張する。どれも正しい。でも、どれも部分的だ。ある時、気づいた。これらの本は地図のようなものだ。山頂への道は無数にあり、どの道も「正しい」。でも、今の自分たちのチームが、この天候で、この装備で登るべき道は一つ。その判断は、地図だけでは下せない。だから必要なのは、理論を超えた何か。コンテキストを読み取り、チームの状況を感じ取り、ユーザーの気持ちを想像する。スタートアップなら速度を、エンタープライズなら堅牢性を、でもそれも一概には言えない。チームの経験、プロダクトの成熟度、市場の要求、技術的負債の現状――すべてを総合的に「感じ取って」判断する。論理と感性を統合した判断。それは経験を積むことでしか身につかない。でも、それこそがシニアエンジニアの真の価値なのかもしれない。無限の選択肢の中から、「今、ここで、このチームが選ぶべき道」を見出す能力。それもまた、クオリティの一つの形だ。アーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazon主客の融合オートバイのメンテナンス中、固着したネジと格闘する場面がある。パーシグはこう語る。「修理工とオートバイは永遠に別個の存在ではない。二元的な考え方をすることで、修理工とオートバイとの間に存在する分離できない関係、つまり仕事に専心する職人気質といったものが失われてしまう」プログラミングも同じだ。私たちはコードを「書く」のではない。システムと対話し、問題空間と解決空間を行き来しながら、共に答えを見つけていく。フロー状態に入った時、キーボードは手の延長になり、思考は直接コードになる。変数名を考える必要もない。自然と適切な名前が浮かぶ。この時、プログラマーとコードの境界は消える。理性も感性も超えた、純粋な創造の瞬間。最近流行りのAIによるコード生成では、この感覚は得られない。プロンプトを書いて、生成されたコードをレビューして、修正を指示する。それは便利だし、効率的かもしれない。でも、そこには主客の分離がある。私とコード、指示する者と実行する者という二元的な関係。AIがどれだけ進化しても、この融合の瞬間は体験できないのかもしれない。それは効率や正確さとは別の次元の話だから。パーシグが固着したネジと格闘しながら得た洞察、その瞬間の一体感。それは自分の手でコードを書き、自分の頭で考え、自分の感覚で判断することでしか得られない。少なくとも今のところはその兆しすら感じない。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon心の静寂「バイクの修理に取り組むときに心がけるべきことは、自他の分離をしないような心の落ち着きを養うことである。心の落ち着きは正しい価値を生み、正しい価値は正しい思念を生む」デバッグで行き詰まった時、論理的分析だけでは見えないものがある。深呼吸して、システムの「気配」を感じる。ログを機械的に読むのではなく、パターンを「感じ取る」。正常時と異常時の「違和感」を察知する。これは非科学的なことではない。むしろ、科学と直感を統合した、より高次の認識方法だ。将棋の棋士が盤面を「読む」ように、経験豊富なエンジニアはシステムを「読む」。それは論理的分析と直感的理解が融合した、独特の認識方法だ。心が乱れていると、コードも乱れる。焦って書いたコードは、必ずどこかに歪みがある。逆に、落ち着いた心で書いたコードは、自然で無理がない。心の状態は、そのままコードの質に反映される。奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonガンプション・トラップパーシグが作った「ガンプション・トラップ」という概念は、創造的な活動における意欲や熱意（ガンプション）を奪う罠のことだ。理性の側には、完璧な設計への固執という罠がある。「もっとエレガントな解法があるはずだ」という思いに囚われて、永遠にリファクタリングを続ける。より良い抽象化を求めるあまり、実装が進まない。分析に分析を重ね、結局は麻痺状態に陥る。一方、感性の側にも危険が潜んでいる。「なんとなくXXが好き」「とにかくYYに慣れている」という理由だけで技術選定をする。最初の直感に囚われて、他の可能性を検討しない。「このコードは美しい」という感覚に酔いしれて、実用性を忘れる。特に「価値観の硬直」の話が印象的だった。南インドの猿の罠――ココナッツの中の米を握った猿は、手を離せば自由になれるのに、米を手放せない。私たちも同じだ。「これがベストプラクティスだから」と言いながら、実は状況が変わっていることに気づかない。逆に、「自分のやり方」に固執して、明らかに優れた新しい手法を拒絶する。罠は至るところにある。それを避けるには、自分が今どの罠に陥りかけているかを認識し、一歩引いて見る必要がある。情報を正しく選択するための認知バイアス事典 行動経済学・統計学・情報学 編作者:情報文化研究所フォレスト出版Amazonテクノロジーとの関係性「真の醜さの原因は、テクノロジーを生み出す人々と、彼らが生み出す物との関係のなかに横たわっている」パーシグはこの言葉で、技術そのものが問題なのではなく、私たちと技術の関係が問題だと指摘する。オートバイを恐れる友人も、オートバイに依存する主人公も、どちらも不健全な関係だった。技術を理性的に分析するだけでも、感情的に拒絶するだけでもダメだ。技術と「共に在る」ことが大切。対話し、感じ取り、理解し、共に成長する。新しいフレームワークを学ぶ時、ドキュメントを読むだけでは不十分。実際に触って、感触を確かめ、「このフレームワークが望んでいること」を感じ取る。作者の思想、コミュニティの文化、設計の美学。技術の向こう側にある「人間」を理解する。技術は道具以上の存在になりうる。それは私たちの思考を拡張し、新しい可能性を開く。でも同時に、技術に振り回されることもある。流行に飛びつき、本質を見失い、手段が目的化する。パーシグが言うように、技術との健全な関係を築くには、クオリティを中心に据える必要がある。行き詰まりの価値プログラミングには様々な行き詰まりがある。どんな設計にすべきか何日も悩む。アーキテクチャの方向性で迷い続ける。技術選定で延々と議論する。実装方法が思いつかない。エラーの原因が分からない。これらはすべて、私たちが日常的に経験する行き詰まりだ。パーシグも、オートバイの不調だけでなく、人生の様々な場面で行き詰まりと向き合った。大学での哲学的探求、クオリティの定義、東洋と西洋の思想の統合。どれも簡単には答えが出ない問題だった。しかし、その行き詰まりこそが、彼を深い洞察へと導いた。行き詰まりは、今使っている思考法の限界を示すサインだ。論理だけで解決しようとしているなら、直感を使ってみる。感覚だけで進めているなら、分析的に考えてみる。視点を変え、アプローチを変え、時には問題そのものを問い直す必要がある。最高のブレイクスルーは、理性と感性が統合された瞬間に起きる。散歩中に突然解決策が浮かぶのは、論理的思考が一旦止まり、無意識の直感が働くからだ。しかし、その直感は、それまでの論理的分析があってこそ生まれる。苦闘は無駄ではない。それは答えを「熟成」させる時間なのだ。最近では、生成AIに問題を投げれば、すぐに答えが返ってくる。確かに便利だ。でも、そこには何かが欠けている。パーシグがオートバイと格闘しながら得た洞察、その苦闘の中で培われた理解の深さ。それは、答えを与えられることでは決して得られない。自分で考え、悩み、試行錯誤することで初めて、問題の本質が見えてくる。技術への理解が深まり、思考が鍛えられ、判断力が養われる。だから行き詰まりを恐れる必要はない。それは成長の前兆であり、ブレイクスルーの準備期間だ。大切なのは、行き詰まりと向き合う姿勢。焦らず、諦めず、クオリティを追求し続けること。その先に必ず何かが見えてくる。中道への道物語を通じて、主人公は変化していく。最初は理性の側に偏り、ロマン的なものを軽視していた。しかし、理性の限界を知り、感性の価値を認識し、最終的には両者を統合する道を見出す。この変化は緩やかで、時に後退しながら進む。主人公は何度も自分の過去（パイドロス）と向き合い、その度に少しずつ理解を深めていく。完全な統合ではなく、絶え間ない調整のプロセスとして。私も似た道を歩んでいる。最初は、論理と理性こそがすべてだと思っていた。設計パターンを暗記し、アルゴリズムを学び、ベストプラクティスを追求した。コードレビューでは「なぜこう書いたのか」を論理的に説明できることが最重要だと信じていた。感覚的な判断は「プロらしくない」と切り捨てていた。転機は、あるシニアエンジニアとのペアプログラミングだった。彼は設計を決める時、まず黙って考え、そして「これが気持ちいい」と言った。最初は戸惑った。でも、その設計は確かに優れていた。後から理由を分析すると論理的にも正しかったが、彼は直感が先行していた。今では分かる。優れたコードには、論理を超えた「何か」がある。それは説明できないけれど、確実に感じることができる。コードを読んだ瞬間の「あ、これは違う」という違和感。リファクタリング後の「これだ」という確信。これらは理性的分析の前に訪れる。でも、だからといって直感だけに頼るわけではない。感じた「何か」を論理的に検証し、言語化する努力も続ける。理性と感性は対立するものではなく、互いを補完し合うパートナーなのだ。中道とは、真ん中に立ち止まることではない。両極を知り、状況に応じて自在に行き来すること。時には徹底的に論理的に、時には大胆に直感的に。そして多くの場合は、その両方を同時に働かせながら。この「何か」を追求することこそが、本当のプログラミングなのかもしれない。技術は手段であり、目的は「良いもの」を作ること。その「良さ」は、理性と感性が調和した時に初めて生まれる。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonおわりにパーシグは「クオリティ」を追求するあまり精神を病み、最終的には息子との旅を通じて、理性と感性を統合する道を見つけた。この本を読んで10年以上経つが、私のエンジニアリングへの向き合い方は確実に変わった。昔は「正しいコード」を書くことばかり考えていた。設計パターンに当てはめ、メトリクスを改善し、ベストプラクティスを守る。それが良いエンジニアだと思っていた。でも今は違う。チームの状況、プロダクトの段階、ユーザーのニーズ――すべてを考慮して「今ここで最適な選択」をすることが大切だと理解している。コードレビューの姿勢も変わった。以前は「なぜこう書いたのか」を論理的に説明することを求めていた。今は「これで良さそう」という直感的な判断も大切にしている。もちろん、その直感を後から論理的に検証することは忘れないが。『禅とオートバイ修理技術』は、エンジニアリングの教科書ではない。でも、技術と向き合う姿勢について、どんな技術書よりも深い示唆を与えてくれる。良いコードを書くには、論理的思考も直感も必要だ。設計の美しさを感じ取る感性と、それを実装する技術力。問題の本質を見抜く洞察力と、地道にデバッグする忍耐力。これらはどれも欠かせない。技術は進化し続ける。新しいフレームワーク、新しいパラダイム、新しいツール、AIなども忘れてはいけない。でも、「良いものを作りたい」という気持ちと、そのための試行錯誤は変わらない。もし若手エンジニアがこれを読んでいるなら、ぜひ『禅とオートバイ修理技術』を手に取ってみてほしい。すぐには理解できないかもしれない。でも、エンジニアとして経験を積むうちに、きっとこの本の言葉が響く瞬間が来る。その時、あなたのエンジニアリングは一段階上のレベルに達しているはずだ。ただ、残念なことに、この本は現在電子書籍でしか読めない。紙の本がないんです(プレ値がついてます)。Kindleで読むのも悪くないけれど、こういう何度も読み返したくなる本は、やっぱり紙で持っていたい。ページに付箋を貼ったり、大事な箇所に線を引いたり、表紙が擦り切れるまで読み込みたい。そういう本なんです、これは。早川書房の担当者さん、もしこれを読んでいたら、ぜひ紙の本での復刊を検討していただけないでしょうか。ハードカバーでも文庫でも、とにかく紙で読めるようにしてほしい。きっと多くのエンジニアが、デスクの横に置いて、迷った時に手に取る一冊になるはずです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展]]></title>
            <link>https://sreake.com/blog/developers-summit-2025-kansai/</link>
            <guid isPermaLink="false">https://sreake.com/blog/developers-summit-2025-kansai/</guid>
            <pubDate>Mon, 01 Sep 2025 01:30:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 9月17日（水）に開催される「Developers Summit 2025 KANSAI」に展示ブーススポンサーとして協賛します。The post スリーシェイク、「Developers Summit 2025 KANSAI」に協賛・出展 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Pipelinesに入門してみよう]]></title>
            <link>https://zenn.dev/akasan/articles/5697384428538b</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/5697384428538b</guid>
            <pubDate>Sun, 31 Aug 2025 07:18:14 GMT</pubDate>
            <content:encoded><![CDATA[今回はVertex AI Pipelinesに入門するための最もシンプルなところを紹介しようと思います。 Vertex AI Pipelinesとは？Vertex AI Pipelinesは、MLのパイプラインを記述することができるサービスになります。MLワークフローをおーけストレートすることにより、データ準備からモデルの学習、モニタリングまで全て自動で行うことができるようになります。MLOpsを実現するためにはMLのライフサイクルを可能な限り自動化するための取り組みが必要であり、そのための手段としてとても有益なツールとなります。パイプラインを記述するためにはKubeflow P...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[PyPIで最もダウンロードされているライブラリ一覧みてみた]]></title>
            <link>https://zenn.dev/akasan/articles/b31578401de5e3</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/b31578401de5e3</guid>
            <pubDate>Sat, 30 Aug 2025 05:20:41 GMT</pubDate>
            <content:encoded><![CDATA[今回はPyPIで最もインストールされているライブラリが何か急に気になったので調べてみました。小方言としては以下のサイトを参照してみました。※ 今回参照したページの情報が必ずしも最新の情報とは限らないと思いますので、参考程度に見てもらえればと思いますhttps://pypistats.org/top 月間ダウンロード 1位 boto3boto3はAWSのSDKであり、AWSユーザかつPythonユーザであれば基本的に利用するのではないでしょうか？ダウンロード数が1,183,978,863ということで他のライブラリと一線を画すようなインストール数になっています。https:/...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[pyinstrumentを使ってPythonコードのプロファイリングをしてみた]]></title>
            <link>https://zenn.dev/akasan/articles/359a9d19a2c921</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/359a9d19a2c921</guid>
            <pubDate>Fri, 29 Aug 2025 13:38:31 GMT</pubDate>
            <content:encoded><![CDATA[今回はpyinstrumentを使ってPythonコードのプロファイリングをしてみました。自分が実装したコードのどこにボトルネックがあるかなどを分析するためのツールとしてどんな感じか調べてみました！ pyinstrumentとは？pyinstrumentはPython用のプロファイラで、コードの最適化を支援するツールです。プログラムの実行をするインフラ基盤の性能は向上しているものの、実装されているコードのパフォーマンスが悪ければ宝の持ち腐れになってしまいます。そこで、今回紹介するようなプロファイラが必要になってきます。プロファイラを利用することで、プログラムのどこに処理時間が多くか...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[私が情報収集するために利用している情報源公開]]></title>
            <link>https://zenn.dev/akasan/articles/c019ee769aadf1</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/c019ee769aadf1</guid>
            <pubDate>Thu, 28 Aug 2025 12:57:38 GMT</pubDate>
            <content:encoded><![CDATA[今回は、私が普段情報収集をする上で利用している情報源について共有しようと思います。特にMLエンジニアとしての色が濃いかなと思いますが、ぜひ参考にしてもらえればと思います。※ 紹介するいかなる媒体の回し者ではございません。単純に普段使ってて助かっているものの共有です ブログ媒体 MediumMediumは特に海外のエンジニアの情報発信を積極的にキャッチアップしたいということで利用しています。無料番だと全ての記事は読めないので、私はAnnual Medium membershipになっているので全ての記事を見れる状態です。特にプログラミング系の記事を多く読んでいますが、とても情報...]]></content:encoded>
        </item>
    </channel>
</rss>