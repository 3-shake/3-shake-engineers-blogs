<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Wed, 31 Dec 2025 11:41:56 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[SREとPlatform Engineeringの交差点としてのデータベースエンジニア]]></title>
            <link>https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</link>
            <guid isPermaLink="false">https://zenn.dev/nnaka2992/articles/dbe_as_a_crossing_of_sre_and_platform_engineering</guid>
            <pubDate>Wed, 31 Dec 2025 08:14:34 GMT</pubDate>
            <content:encoded><![CDATA[この記事は3-shake Advent Calendar 2025 最終日の記事です。データベースは従来から安全な変更を適用するには難易度が高い場合もあり、最悪の場合データロストを引き起こす変更しづらさが課題としてあります。現代のシステム開発では開発者によるデータベースの頻繁な変更は当たり前であり、変更しづらさが、そのままDevExの低下につながります。データベースの信頼性を支えるにも、DevExを向上させるにも、一定のデータベースの知見が必要になります。一方でデータベースに一定の知見をもつエンジニアや専門とするエンジニアは、インフラエンジニアやアプリケーションエンジニアに比べ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、おい、]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/30/083324</guid>
            <pubDate>Mon, 29 Dec 2025 23:33:24 GMT</pubDate>
            <content:encoded><![CDATA[はじめに誰もまとめてくれないので自分でまとめます。こんなに悲しいことはありません。2025年11月から12月にかけて、「おい、〜」というシリーズでブログを15本書きました。登壇もしました。合計16本です。誰かがまとめ記事を書いてくれるかなと思っていました。待っていました。誰も書いてくれませんでした。年末です。仕方がないので自分で書きます。シリーズの始まり今年の8月、本を書かないかという話が来ました。嬉しかったです。企画を練りました。構成を考えました。8月、9月、10月といろいろやり取りをしていたのですが、いろんな諸事情で立ち消えになりました。悔しかったです。本を出せなかったことが悔しかったのではない。結局何にもならなかった自分が悔しかった。もっと準備できたはずだ。もっと詰められたはずだ。その後悔が残りました。でも、本の企画のために書いた下書き原稿が8本くらいありました。本にならないなら、ブログに書けばいい。そう思って始めたのが「おい、〜」シリーズです。30歳になったこともきっかけでした。5月に「20代最後の一週間を生きるエンジニア、あるいは30歳の扉の前でうろたえる男の独白」というとても長いブログを書きました。20代が終わることへの焦り、不安、でも少しの期待。そのときに声かけていただいたのが、「おい、〜」シリーズとして出てきたものです。syu-m-5151.hatenablog.com20代の頃は「なんでもできる」と思っていました。30代になって、「できない」を認められるようになった。それは諦めではなく、等身大の自分を見つめられるようになったということです。15本を通して書いていたのは、結局そのことだったのかもしれません。「おい、部屋を掃除しろ」から始まりました。下書きを消化したあとも、言いたいことが止まらなくなりました。無限に書いても良くないので、週に1回のペースに決めました。自分を律するために「おい、週一で書け」とは書きませんでした。結果、15本になりました。15本の記事は、3つのカテゴリに分かれます。まず生活の基盤を整え、次に思考を鍛え、最後にその思考で仕事や人間関係に臨む。この順番で読む必要はありませんが、私の中ではこの流れがありました。生活習慣編おい、部屋を掃除しろ掃除の話ではありません。自分を大切に扱う習慣の話です。部屋が汚い人間に、コードをきれいに書けるわけがない。因果関係なんてないし、汚い部屋の凄腕エンジニアなんていくらでもいる。でも、知っている人はみんな適当な時期に結婚などしてなんとかなったか、心か身体を壊して生活を改めたか、消えていった。因果はわからないが、意味のわからない経験則としてある。毎日5分の掃除から始める規律の美学について書きました。syu-m-5151.hatenablog.comおい、一つずつやれSlack、メール、GitHub、全部同時に見ていると「忙しいのに何も終わらない」状態になります。これはおそらく忙しいのではなく、大量のタスク切り替えに対してコストを払っているだけです。仕事ができる人のイメージは、勝手に「マルチタスクができる人間」だと思っていました。しかし自分にその力はどうやらなさそうで、実際できていませんでした。ただ能力の限界まで「中途半端を量産する人間」でした。1日25分、1つのことだけに集中することから始めました。タスク切り替えの過払い金を整理した、という表現が正しいかもしれません。syu-m-5151.hatenablog.comおい、スマホを置け技術書が読めない。集中力が続かない。意志が弱いのだと思っていました。違いました。スマホに最適化された脳でした。私たちの世代は高校生の頃からスマホに触れてきた。15秒ごとに報酬をくれるアプリに慣れた脳が、30分かけて一つの概念を理解する作業に耐えられるわけがない。これは人生が壊れるな、という実感がありました。自分より下の世代は、もっと大変だろうなと思いました。syu-m-5151.hatenablog.comおい、本を読め「本を読まない人は生き残れない」という強迫的なメッセージへの違和感があります。いつから読書は「生き残るための手段」になったのか。効率的に知識を得るための読書は続かない。義務感で読む本は頭に入らない。ただ楽しいから読む。それだけでいい。そういう価値観もあるのだと、知ってもらえたらと思っていました。私は今も、子供の頃に初めて図鑑を開いたときと同じ気持ちで本を読んでいます。正直、楽しければなんでもいいと思っています。読者やフォロワーが楽しんで、結果として生き残ってくれれば、それでいい。syu-m-5151.hatenablog.comおい、休め休んでいるのに休めていない、という問題があります。ソファで横になってスマホを見ている。一見すると堕落の象徴のようでもあり、休息のようでもある。しかし残念ながら、これは休息ではありません。低負荷の作業です。脳は休んでいない。判断を続けている。スクロールするかどうか。この動画を見るかどうか。このツイートに反応するかどうか。AI時代は判断を求められる機会が増える一方です。現代では意識的に「何もしない」時間を作らないと、脳が壊れます。「じゃあお前はブログを書き続けて休んでないじゃないか」という指摘があると思いますが、その鋭い刃は収めていただけると助かります。syu-m-5151.hatenablog.com思考法編おい、冷笑すんなインターネットと冷笑は、相性が良すぎます。140字で専門家を論破した気になれる。何年も積み上げてきた人の仕事を、背景も知らずに「それ、意味あるんですか」と切り捨てられる。「専門性なんて要らない」「結局ポジショントークでしょ」——そんな言葉が、何も作ったことのない人から発せられている。私自身、視野を広げすぎて世界の複雑さに圧倒され、冷笑主義に陥った経験があります。何を見ても「まあ、そうなるよね」「どうせ変わらないよ」と思うようになっていた。達観した気になっていた。賢くなった気がしていた。違った。何も生み出さない人間になっていただけでした。冷笑は「どうせ無理」で終わる。批判は「ここがダメ」で終わる。批評は「ここがダメだから、こうすればいい」まで踏み込む。私は冷笑で止まっていた。一番楽で、一番何も残らない場所に。若い頃に冷笑してきたものが、今になって本当に大切だとわかる。それが少し悔しい。syu-m-5151.hatenablog.comおい、内省しろ内省と反省は違います。反省は「悪かった、次は気をつけます」で終わる。そして同じミスを繰り返す。私がそうでした。何度も反省した。何度も同じ失敗をした。反省とは、過去に頭を下げる行為でしかなかった。内省は違う。「なぜそうなったのか」を掘り下げて、構造を理解し、仕組みごと変えるプロセスです。自分を責めるのではなく、自分を観察する。毎日30秒でいい。寝る前に「今日、なぜあの判断をしたのか」を考える。それだけで少しずつ変わります。syu-m-5151.hatenablog.comおい、言語化しろ2025年、言語化神話が爆誕しました。「言語化できれば理解できる」「言語化できないのは思考が浅い証拠」——そんな空気が広がっている。確かに、言葉にできない領域があまりに広い人にとっては、その神を信じることで救われることもあります。言葉にする努力が思考を前に進めることもある。しかし、普通の大人には言語化できないものがあります。「なんとなくこっちの方がいい」という直感。説明できないけど手が動く技術。身体に染み込んだ知識、実践の中で培われた勘、創造的な跳躍、感情ヒューリスティック。これらを全部言葉にしようとすると、かえって嘘になる。言葉にした瞬間、丸められる。削られる。本当はもっと複雑で、矛盾していて、揺らいでいるものが、きれいに整理された途端に別物になる。「完璧に言語化できた」と思ったら、何か大事なものを落としている証拠かもしれない。不完全な変換でいい。「まだ言葉にできない何か」を抱えている感覚こそが、次の成長を生みます。syu-m-5151.hatenablog.comおい、つなげろ問題解決には「つなげること」と「断つこと」の両面があります。知識と知識をつなげて解決策を見つける。異なる領域の経験を結びつけて、新しい発想を得る。しかし、間違ったつながりを断つ勇気も必要です。「前もこうだったから」という過去の成功体験が、今回の失敗を招くことがある。AIに聞けば答えは出る。でも、自分でつなげる経験をしないと、応用が効かない。なぜその答えに至ったのか、プロセスが身につかない。「AIが教えてくれた答え」と「自分で見つけた答え」は、同じ答えでも身につき方が違う。苦労して見つけた答えは、次の問題を解く足場になる。与えられた答えは、その場で消える。syu-m-5151.hatenablog.comおい、類推するな所有権を「本の貸し借り」に例えて理解しました。わかった気になりました。腹落ちした感覚すらあった。しかし実際にコードを書いたら、例えが成立しない場面だらけでした。本は返却されても同じ本だが、所有権はそうではない。そういう経験は意識的にも無意識的にもやってしまうと思います。類推は便利ですが危険です。複雑なものを飲み込みやすくする代わりに、本質からズレた理解を植えつける。入り口としては使える。でも、判断するときは具体に戻る。「本の貸し借りだから...」ではなく「Rustの所有権のルールでは...」で考える。例え話で納得したら、そこで立ち止まって、例えを捨てる勇気を持つ。syu-m-5151.hatenablog.com仕事・対人編おい、対話しろ会議で「話しているが対話していない」場面があります。みんな口だけは喋っている。でも誰も聞いていない。相手の発言が終わるのを待っているだけ。その間に自分の意見を頭の中で整理している。相手の言葉を受けて考えを変える気がない。これは対話ではない。順番にモノローグを発表しているだけです。対話の本質は、相互の世界観を認識し、理解を深めるプロセスにある。相手の言葉を聞いて、自分の考えが変わる余地を残す。論破ではなく理解を目指す。勝ち負けではない。「なるほど、そういう見方もあるのか」が対話の成果です。syu-m-5151.hatenablog.comおい、がんばるな「頑張ること自体が目的化していた」という反省があります。遅くまで残って、休日も働いて、「頑張っている自分」に酔っていた。忙しさを充実感と錯覚していた。成果は出ていなかった。いや、正確には見ていなかった。過程に満足して、結果を直視していなかった。環境とのミスマッチを認識し、持続可能なペースに切り替えたら、むしろ成果が出るようになった。頑張りを減らしたのに成果が増える。皮肉だが、これが現実だった。公開した翌日、「いや、待てよ」と思いました。syu-m-5151.hatenablog.comおい、努力しろ前日の「がんばるな」への自己反論です。24時間で意見が変わりました。というわけではないです。読者は混乱したと思います。「頑張らなくていい」という言葉が、怠惰の免罪符として使われる危険性に気づいた。「無理しなくていい」が「やらなくていい」にすり替わる瞬間がある。量をこなさないと見えない景色がある。苦しみを乗り越えた経験がないと、乗り越え方がわからない。限界を知るには、一度限界まで行く必要がある。矛盾しているように見えますが、矛盾していません。両方本当です。「頑張りすぎるな」と「頑張らないと見えないものがある」は、同時に成り立つ。問題は、今の自分がどちら側にいるかを見極めることです。syu-m-5151.hatenablog.comおい、戦略を語れ「戦略」という言葉が形骸化しています。「戦略的に進めましょう」と言う人に「具体的にどういう戦略ですか」と聞くと、答えられないことが多い。「戦略」が「なんとなく賢そうな進め方」の意味になっている。戦略の本質は「何をやらないかの選択」です。全部やるのは戦略ではない。総花的にリソースを配分するのは、戦略がないことの証明です。限られた時間とエネルギーを、どこに集中させるか。何を意図的に捨てるか。エンジニアも「これは作らない」と言える立場になるべきです。「作れるけど作らない」という判断ができることが、本当の技術力かもしれません。syu-m-5151.hatenablog.comおい、論理で人が動くと思ってるのか論理的に正しい提案でも通らないことがあります。データを揃えた。根拠を示した。反論の余地がないほど完璧な提案書を作った。却下されました。なぜか。人は論理だけでは動かない。正しさだけでは、心が動かない。「このシステムは非効率です」より「先月、この非効率のせいで3時間残業しました」の方が通る。数字より、1人の体験談。グラフより、具体的な苦労話。人は物語で納得し、論理で自分を正当化する。だから、まず物語で心を動かし、その後で論理を添える。順番が逆だった。完璧な論理を用意する前に、「誰の、どんな困りごとを解決するのか」を語るべきでした。syu-m-5151.hatenablog.com登壇12月5日、Forkwell Communityで「おい、テックブログを書け」という登壇をしました。元々文章が苦手でした。今も苦手です。それでも書き続けたら、登壇を頼まれるようになりました。苦手なまま登壇しています。緊張で声が震えます。けれど登壇しています。出発点の低さは到達点を決めない。苦手なまま続けて消えていった人も山ほど見てきた。違いは何か。苦手なことを自覚した上で、苦手なまま出す覚悟をした。完璧を目指していたら続かなかった。syu-m-5151.hatenablog.com何を言いたかったのか15本を書いていて気づいたことがあります。それぞれの記事がつながっていく感覚がありました。「スマホを置け」と「休め」、「内省しろ」と「言語化しろ」。しかし同時に、全く反対のことも言っている。「がんばるな」の翌日に「努力しろ」。一貫性がない。でも、そういうものだと思っています。「おい、〜」シリーズは、飲み屋で語りたいことを適当に語っているような記事です。整合性を気にしていたら書けなかった。完璧を目指してたら書けなかった。矛盾だらけの15本ですが、振り返ると1つだけ共通点がありました。どの記事も「手段が目的化していないか」を問うていた気もする。掃除も、読書も、努力も、論理も、すべて何かのための手段です。その「何か」を見失っていた。効率と最適化に追われて、「なぜそれをやるのか」という問いを忘れていた。タスクをこなすことが目的になり、タスクの先にある価値を見失っていた。15本を通して言いたかったのは、そのことです。スマホで時間を潰すな。マルチタスクで忙しいふりをするな。冷笑で賢いふりをするな。論理だけで人を動かそうとするな。がんばることを目的にするな。でも努力から逃げるな。矛盾だらけです。人間は矛盾しています。それでいいと思っています。おわりに本の企画が立ち消えになったとき、正直落ち込みました。でも結果的に、ブログという形で書きたいことを全部書けた。本になっていたら、編集者に「矛盾してます」と言われて、どちらかを削っていたと思います。ブログでよかった。15本も書いて、誰も読んでいないかもしれません。誰もまとめてくれなかったということは、そういうことなのでしょう。あるいは、みんな忙しいだけかもしれない。そう思うことにしています。それでも書きました。自分のために書きました。30歳の自分から、40歳の自分への手紙です。「おい、お前、ちゃんとやってるか」10年後に読み返して、恥ずかしくなるかもしれません。「やっぱり正しかった」と思うかもしれません。どちらでもいい。でも、同じことを書いていたら。同じ悩みを抱えていたら。40歳の自分がこれを読んで、何も変わっていなかったら。それが一番怖い。来年も書きます。誰かがまとめてくれることを期待しています。でも、たぶんまた自分でまとめることになる。飽きたらやめます。だから普通に褒めてください。人に勧めてください。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[おい、論理で人が動くと思ってるのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/29/160746</guid>
            <pubDate>Mon, 29 Dec 2025 07:07:46 GMT</pubDate>
            <content:encoded><![CDATA[はじめに数年前の、ある金曜日の夜のことだ。会議は完全な失敗に終わった。会議室を出て、エレベーターのボタンを押しながら、私はこの文章を書こうと決めた。書き上げるまでにずいぶん時間がかかってしまったので、当時の思いとは少し違っているかもしれない。あの会議で「論理的に正しいことを言ったのか」と問われれば、言った。間違いなく言った。データも揃えた。根拠も示した。反論の余地がないほど、正しいことを言ったはずだった。だが、誰も動かなかった。私の発言が終わった瞬間、会議室の空気は凍りついた。誰も何も言わない。居心地の悪い沈黙が流れ、やがて別の話題へと移っていった。正しいことを言ったはずなのに、私は敗北感を覚えた。当時、私はシニアエンジニアになったばかりだった。部下はいない。それでも「組織全体の技術選定に責任を持て」と言われる。命令する権限はない。しかし説得しなければならない。予算を握っているわけでもない。それでもチームを動かさなければならない。これを読んでいる人の中にも、同じ経験をした人がいるのではないだろうか。「なぜ伝わらないのだ」と、帰りの電車の中で自問したことがある人が。正直に告白すれば、当時の私は根本的な勘違いをしていた。論理的に正しければ、人は動くものだと思っていた。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じて疑わなかった。だが、違った。人が動くのは、論理ではなかった。もっと別の何かだった。私はそれを「物語」と呼ぶことにした。なぜそう呼ぶのか。それを、これから書いていく。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理学が扱うもの私も昔、論理学を学んだとき、これで人を説得できると思った。正しい推論を積み重ねれば、相手は納得せざるを得ない。そう信じていた。今思えば、かわいいものだ。論理学は、推論の形式を扱う学問だ。内容ではなく、形式を。「すべての人間は死ぬ。ソクラテスは人間だ。ゆえにソクラテスは死ぬ」——これがアリストテレス以来の三段論法です。この推論が正しいのは、ソクラテスが誰かとか、死とは何かという内容とは関係ありません。形式が正しいから、結論は必然的に正しいのです。論理学には2つの柱がある。演繹と帰納だ。演繹は、前提から結論を必然的に導く。「すべてのAはBである」という全称命題から、個別の結論を導く。前提が真で、推論形式が正しければ、結論は必ず真になる。数学の証明はこれだ。帰納は、個別の事例から一般法則を導きます。「このカラスは黒い」「あのカラスも黒い」を繰り返して、「すべてのカラスは黒い」と結論する。しかし、帰納には必然性がありません。次に見るカラスが白い可能性もあります。科学の仮説はこの帰納に基づいています。エンジニアとして、私は両方を使う。型システムは演繹だ。型が合っていれば、その部分は正しく動く。テストは帰納だ。このケースで動いた、あのケースでも動いた。だから「おそらく」正しい。論理学が教えてくれる重要なことがあります。論理的に正しい推論でも、前提が間違っていれば結論は間違います。「すべてのエンジニアはコーヒーを飲む。田中はエンジニアだ。ゆえに田中はコーヒーを飲む」——この推論は論理的に正しい。でも、前提が間違っています。論理は形式の正しさを保証しますが、内容の正しさは保証しません。そして、日常会話で「論理的」と呼ばれるものは、この厳密な意味での論理ではない。では、日常で「論理的」と呼ばれているものは、いったい何なのか。そして、論理は本当に「無力」なのか。私はそうは考えません。論理が効かないのではなく、使う順番を間違えているだけかもしれない。論理が効く瞬間と、効かなくなる瞬間がある。その違いは何か。論理が効くのは、相手がすでに「聞く準備」ができているときだ。信頼関係がある。問題意識を共有している。結論を受け入れる土壌がある。そういう状態で論理を使えば、「なるほど、確かにそうだ」となる。論理が効かなくなるのは、その準備ができていないときだ。相手が防御姿勢に入っている。「この人の話は聞きたくない」と思っている。そういう状態で論理を振りかざしても、「理屈っぽい」「押し付けがましい」と感じられるだけだ。論理が最初に来ると失敗しやすいのは、これが理由だ。相手の心が開いていないうちに正論をぶつけても、反発を招くだけ。まず共感し、信頼を築き、「この人の話なら聞いてみよう」という状態を作る。論理はその後だ。論理は「納得を作る道具」なのか、「正しさを確認する道具」なのか。私の答えは「両方だが、順番が違う」だ。正しさを確認するのは最初。納得を作るのは最後。自分の中で論理的に正しいことを確認してから、相手に伝えるときは物語で包む。論理は骨格で、物語は肉だ。骨だけ見せても、人は食べたいと思わない。論理的誤謬という問題論理学は、推論の「正しくない形式」も分類している。論理的誤謬だ。「Aさんは実績がないから、Aさんの意見は間違っている」——これは人身攻撃の誤謬だ。発言者の属性と、発言内容の真偽は別の問題だ。「みんながそう言っているから正しい」——これは多数論証の誤謬だ。多数派であることは、正しさの証明にはならない。「前例がないからやるべきではない」——これは前例への訴えだ。前例がないことと、やるべきでないことは別の問題だ。会議室で飛び交う「論理的」な議論を観察してみてほしい。これらの誤謬がどれだけ多いことか。私も、今日の会議で3つは使った気がする。しかし、ここで興味深いことがある。論理的誤謬を含む議論でも、人は納得する。むしろ、厳密に論理的な議論よりも、誤謬を含む議論のほうが説得力を持つことがある。なぜか。誤謬が含まれていると、かえって「人間らしさ」を感じないか。完璧に論理的な人は、どこか冷たい印象を与える。「この人は機械なのか」と思ってしまう。一方、多少の飛躍や感情的な訴えがある人は、「血が通っている」と感じる。厳密さを捨てることで得ているものがある。親近感だ。「この人も自分と同じように考えている」という共感だ。論理的な完璧さは、時として障壁になる。「この人には敵わない」と思わせてしまうと、対話が成立しなくなる。誤謬を許容しているのは、聞き手か、語り手か。私の答えは「両方」だ。語り手は、厳密さよりも伝わりやすさを優先している。聞き手は、正しさよりも納得しやすさを優先している。両者の暗黙の合意によって、誤謬は見逃される。これは悪いことばかりではない。日常のコミュニケーションで、すべてを厳密に検証していたら話が進まない。ある程度の「緩さ」は、社会を潤滑にしている。問題は、その緩さがどこまで許されるかだ。アリストテレスは、人を説得する技術を3つに分けた。ロゴス（論理）、パトス（感情）、エトス（人柄・信頼）だ。論理学が扱うのはロゴスだけだ。しかし、人間を動かすには3つすべてが必要になる。「論理的に正しいのに伝わらない」と悩むとき、私たちはロゴスだけで勝負しようとしている。パトスとエトスが欠けている。逆に、論理的誤謬を含んでいても人が動くとき、パトスとエトスがロゴスの欠陥を補っている。これが、論理学と「論理的に見えること」の決定的な違いだ。「論理的に見える」の解体世間で「論理的」と言われる人を、よく観察してみてほしい。彼らは本当に学術的な意味での論理を使っているだろうか。三段論法を厳密に適用しているだろうか。演繹的推論を正確に展開しているだろうか。違う。彼らがやっているのは、相手が「なるほど、確かに」と思える具体例をサッと出すことだ。データや証明だけじゃなくて、実感できる話で納得させている。では、日常で「論理的」と呼ばれているものは、何を代替しているのか。本来は感情で決めていることを、論理で覆っていないか。「なんとなく嫌だ」を「リスクが高い」と言い換える。「この人と仕事したくない」を「スキルセットが合わない」と言い換える。感情的な判断を、論理的な装いで正当化している。本来は信頼で決めていることを、論理で覆っていないか。「この人が言うから」を「データに基づいている」と言い換える。「前からこうだったから」を「実績がある」と言い換える。関係性や慣習に基づく判断を、客観的な根拠があるように見せている。本来は立場で決めていることを、論理で覆っていないか。「上が決めたから」を「戦略的に正しい」と言い換える。「予算がないから」を「費用対効果が低い」と言い換える。権力構造に基づく判断を、合理的な分析結果のように見せている。「論理的に説明した」という言葉は、責任回避になっていないか。「私が決めた」ではなく「論理的にこうなった」と言うことで、判断の責任を「論理」に押し付けている。でも、どの前提を選ぶか、どのデータを重視するか、それを決めたのは人間だ。論理は責任を引き受けてくれない。論理という言葉は、どんな場面で免罪符になるのか。「感情的になるな、論理的に考えろ」と言われたとき、相手の感情を封じ込める武器になっている。「論理的に正しいんだから従え」と言われたとき、対話を打ち切る口実になっている。論理という言葉が、思考停止の道具になることがある。「論理で動いた」ように見える行動を解剖してみよう。実際に何が作用しているのか。信頼がある。「この人が言うなら」という前提がすでに成立している。文脈がある。その結論を受け入れやすい状況がすでに整っている。同調圧力がある。周囲がすでに納得している空気がある。期待がある。その結論であってほしいという願望がある。論理は、これらの基盤の上で初めて機能する。基盤がなければ、どれだけ論理的に正しくても人は動かない。論理は感情の乗り物だ。乗り物だけあっても、燃料がなければ走らない。感情という燃料があって、初めて論理は目的地に到達する。しかし、この比喩はどこまで言い切ってよいのか。感情がない状態で論理が機能する場面は存在するか。数学の証明を考えてみてほしい。純粋に形式的な操作として、感情抜きで成立するように見える。しかし、その証明を「面白い」「美しい」と感じる心がなければ、誰が数学を続けるだろうか。論理の営みを支えているのは、やはり感情だ。感情が強すぎるとき、論理は何を失うのか。怒りに支配されているとき、論理は武器になる。相手を傷つけるための道具になる。悲しみに沈んでいるとき、論理は機能しなくなる。「わかっているけど、できない」という状態になる。感情が強すぎると、論理は歪むか、停止する。論理と感情は主従関係なのか、相互依存なのか。私の答えは「相互依存」だ。論理が感情を制御することもある。「怒りに任せて発言するのはやめよう」と論理が感情をなだめる。感情が論理を駆動することもある。「この問題を解決したい」という情熱が、論理的思考を加速させる。どちらが主人というわけではない。両者が互いに影響し合っている。うまく言葉にできる人は、論理が強いのではない。相手を見ている。相手が何を知っていて、何を知らないか。何を信じていて、何に不安を感じているか。その理解があるから、言葉が届く。論理は単体では人を動かさない。ここでもう一歩踏み込んでみます。「私は論理的です」という態度自体が、1つのナラティブではないでしょうか。「私は感情に左右されず、冷静に判断しています」という自己像を提示している。それ自体が物語を語っているということです。「AだからB」は、推論である前に、納得の物語です。原因と結果を結びつけ、聞き手を結論へと導く。それは「正しいから従うべき」ではなく「納得できるから受け入れる」という構造で機能しています。信じたい物語への依存ここまで、論理の限界と物語の力について語ってきた。しかし、もう一歩踏み込みたい問題がある。人は「信じるべき論理」ではなく「信じたい物語」を信じる。これは単なる傾向ではない。依存に近い。考えてみてほしい。データを見せられたとき、私たちは本当に中立的に判断しているだろうか。「この数字は何を意味するか」と問う前に、「この数字は自分の期待を裏付けているか」と無意識に判断していないか。期待に合致するデータは「やはり」と受け入れる。期待に反するデータは「本当なのか」と疑う。同じ論理、同じデータでも、自分の物語に沿っているかどうかで、受け取り方が変わる。これは認知バイアスの問題だけではない。もっと根深い。私たちは、自分のアイデンティティを守る物語に依存している。「私は論理的な人間だ」という物語。「私は技術力がある」という物語。「私のチームは優秀だ」という物語。これらの物語が脅かされると、私たちは防御に入る。どれだけ論理的に正しい指摘でも、自分の物語を脅かすものは受け入れられない。なぜ依存と呼ぶのか。やめられないからだ。物語を手放すことは、自分を手放すことに感じられる。「私は実は論理的ではなかった」と認めること、それはアイデンティティの崩壊に近い。どれだけ反証を突きつけられても、私たちは自分の物語にしがみつく。論理が正しいかどうかは、もはや関係ない。これは「信じるべきかどうか」の問題ではない。「信じずにいられない」という問題だ。会議室で「それは違う」と言われたとき、私たちは何を守ろうとしているのか。事実を守っているのか、それとも「私は正しい」という物語を守っているのか。正直に言えば、多くの場合は後者だ。だから、論理で人を動かそうとしても失敗する。相手の物語と衝突すれば、相手は論理を聞く前に防御に入る。「この人の言うことは聞きたくない」という状態になる。論理が届く前に、扉が閉まっている。では、どうすればいいのか。相手の物語を攻撃するのではなく、その物語の中に入る。相手が信じたい物語を否定せず、その物語の延長線上に自分の提案を置く。「あなたの論理は間違っている」ではなく、「あなたの考えをさらに進めると、こうなる」と語る。人を動かすとは、相手の物語を書き換えることではない。相手の物語に自分の提案を織り込むことだ。経験談が人を黙らせる理由人を説得するとき、論理だけでは足りない。自分の失敗談を語ることで心を掴むことがある。「とほほエピソード」には不思議な力がある。完璧な論理よりも、不完全な経験談のほうが、人の心に響くことがあるのだ。経験談は再現性が低い。その人固有の文脈でしか成り立たないことも多い。なのに、私たちは経験談に心を動かされる。なぜか。経験談が持つ力を3つに分解してみる。1つ目は、再現性の放棄だ。「これが正解です」ではなく「私はこうだった」と語ることで、聞き手は反論しにくくなる。事実に対しては「それは違う」と言えるが、経験に対しては言えない。2つ目は、思考コストの削減だ。抽象的な理論を理解するより、具体的な経験を追体験するほうが楽だ。聞き手は考えなくても「なるほど」と言える。3つ目は、権威の自動付与だ。「やったことがある人」は、それだけで信頼される。成功者の経験談には、内容を超えた説得力が宿る。しかし、ここに危険がある。「成功者が言うから正しい」という錯覚。これは聞き手の思考停止を招く。経験談が「効きすぎる」とき、何が起きているのか。聞き手は考えることをやめている。語り手の経験を、自分の結論にすり替えている。経験談を聞いた瞬間、聞き手は何を放棄しているのか。批判的思考だ。「本当にそうか」「自分の場合は違うのではないか」という問いを放棄している。経験談には「事実」としての重みがあるから、反論しにくい。反論すると「お前はやったことがないくせに」と言われそうだから、黙ってしまう。「反論できない感じ」は、どこから生まれるのか。経験談は「私はこうだった」という一人称で語られる。一人称の物語に対して、「それは違う」とは言いにくい。他人の経験を否定する権利が自分にあるのか、という遠慮が働く。しかし、その経験から導かれる「だからこうすべきだ」という結論は、本当に正しいのか。そこは検証が必要だ。だから、経験談は入口であって、結論ではない。経験談で心を開き、そこから自分で考える。その順番が重要だ。では、経験が浅い人は物語を語る資格がないのか。私はそうは考えません。経験の浅さには、浅いなりの価値があります。経験が浅いからこそ見えるものがある。「なぜこのやり方なのか」という素朴な疑問。ベテランにとっては「当たり前」になっていることへの違和感。「本当にこれでいいのか」という不安。これらは、経験を積むほど薄れていく。ベテランが失いやすい視点とは何か。初心者の目線だ。「これは難しい」「これはわかりにくい」という感覚は、慣れると消えてしまう。だからベテランが書いたドキュメントは、初心者には読めないことがある。ベテランが設計したシステムは、初心者には使えないことがある。経験は資産だが、同時に負債でもある。「まだわからない」という物語は、どんな力を持つか。謙虚さの力だ。「私はまだ学んでいる途中です」と言える人は、相手の話を聞く姿勢がある。「私は全部わかっています」と言う人は、すでに耳を閉じている。経験の浅さを認めることは、対話の扉を開くことになる。重要なのは経験の量ではなく、経験を物語として語る力だ。10年の経験があっても、それを言葉にできなければ伝わらない。1年の経験でも、そこから何を学んだかを語れれば、人の心に届く。経験談を「入口」に留めるには、何が必要か。聞き手の側には、「この人の経験は参考になるが、自分の状況は違うかもしれない」という留保が必要だ。語り手の側には、「これは私の経験であって、あなたに当てはまるとは限りません」という謙虚さが必要だ。両者がこの姿勢を持っていれば、経験談は入口のまま留まる。物語が許されない領域私はエンジニアとして長く働いてきた。だからこそ言いたいことがある。物語万能論は危険だ。かつて、私は失敗したことがある。プロジェクトが炎上しかけていたとき、チームの士気を上げようと物語を語った。「このプロダクトが世に出れば、多くの人の生活が変わる」「困難を乗り越えた先に、私たちは成長している」。チームは一時的に盛り上がった。でも、テストは通らなかった。本番環境でバグが発生した。物語で人は動いたが、システムは動かなかった。バグは物語で直らない。物語でテストが通るなら、私は今頃、小説家になっている。どれだけ美しい物語を語っても、コードが間違っていれば動かない。どれだけチームが納得しても、テストが通らなければリリースできない。エンジニアリングには、物語では代替できない領域がある。技術的正しさは、どこまで物語と共存できるのか。私の答えは「共存はできるが、置き換えはできない」だ。物語は人を動かすが、システムは論理で動く。この2つを混同してはいけない。泣いたら人は許してくれるかもしれませんがシステムは許してくれません。人の層とシステムの層を混同すると、何が起きるか。人の層で通用する「納得したからOK」が、システムの層に持ち込まれる。チーム全員が「この設計でいこう」と合意しても、コードが間違っていれば動かない。逆に、システムの層で通用する「正しいから従え」が、人の層に持ち込まれる。論理的に正しい設計でも、チームが納得していなければ実装は進まない。「納得したからOK」は、どこまで通用するのか。人を動かすところまでだ。「このアーキテクチャでいこう」という合意形成には物語が必要だ。しかし、そのアーキテクチャが本当に要件を満たすかは、検証が必要だ。納得と正しさは別の問題だ。物語で進めてはいけない判断の特徴は何か。結果が客観的に検証できる判断だ。「このコードは動くか」「このシステムは要件を満たすか」「このセキュリティ対策は十分か」。これらは、どれだけ美しい物語を語っても、実際にテストしなければわからない。物語で「大丈夫だろう」と進めて、本番環境で障害が起きたら、物語は言い訳にしかならない。ナラティブと検証の役割分担を整理しておく。人を動かすのは物語だ。なぜこの技術を選ぶのか、なぜこのアーキテクチャにするのか。それを説明し、納得してもらうには物語が必要だ。正しさを担保するのは論理とテストと記録だ。選んだ技術が本当に動くのか、アーキテクチャが要件を満たすのか。それを確認するには検証が必要だ。「あの人が言うから正しい」という判断は、いつ危険になるのか。それは、検証を省略したときだ。権威ある人の経験談に納得したとしても、コードレビューは必要だ。テストは必要だ。ドキュメントは、物語の代替にはなりえない。物語が「なぜそうするのか」を伝え、ドキュメントが「何をするのか」を記録する。物語は人の層に効き、論理はシステムの層に効く。この使い分けが重要だ。プロジェクトを進めるには「直線モード」と「曲線モード」を行き来する必要があります。計画と合理性を重視する直線モード、そして変化や対話を重視する曲線モード。どちらか一方では足りません。両方を使い分けられることが、プロジェクトを前に進める力になります。優しい物語の罠「あなたらしさを大切にしたうえで、今必要な道具を手に入れ、磨き、使い分けていこう」というメッセージには優しさがある。しかし、優しい物語は、なぜ時に成長を妨げるのか。思い出してほしい。優しい言葉をかけたのに、相手が変わらなかった経験はないか。「大丈夫だよ」と言い続けたのに、問題が解決しなかった経験はないか。あのとき、私たちは何を間違えていたのか。優しさは寄り添う。甘さは目を背けさせる。優しさと甘さは、どこで分岐するのか。私の答えは「事実を直視しているかどうか」だ。優しさは事実を受け止めた上で寄り添うこと。甘さは事実から目を背けさせること。「あなたらしくていい」が「変わらなくていい」に変質したとき、それは優しさではなく甘さになる。厳しさを含まない物語は、誰のためのものか。多くの場合、それは語り手のためだ。相手に嫌われたくない、対立を避けたい、という語り手の願望が、優しさという衣をまとっている。その優しさは、聞き手のためか、語り手のためか。この問いは重要だ。「傷つけたくない」と言いながら、実は「嫌われたくない」だけかもしれない。「今は言わないほうがいい」と言いながら、本当は「言うのが面倒」なだけかもしれない。優しさの仮面をかぶった自己保身は、いくらでもある。事実を和らげることと、隠すことの境界はどこか。私の答えは「相手が判断するために必要な情報を持っているかどうか」だ。「あなたのスキルはまだ足りないが、伸びしろがある」は和らげている。「あなたは素晴らしい」と言って、スキル不足を伝えないのは隠している。前者は事実を含んでいるから、相手は次の行動を選べる。後者は事実を隠しているから、相手は間違った判断をする。成長を促す厳しさと、切り捨ての厳しさはどう違うか。成長を促す厳しさは、相手の可能性を信じている。「あなたならできるはずだ。だから厳しく言う」という姿勢がある。切り捨ての厳しさは、相手を見限っている。「あなたには無理だ。言っても仕方ない」という諦めがある。言葉は同じ「厳しさ」でも、その奥にある信頼の有無で意味が変わる。勇気を与える物語と、逃避を許す物語の違いは何か。勇気を与える物語は「困難があるが、乗り越えられる」と語る。逃避を許す物語は「困難なんてない」と語る。前者は現実を認めた上で希望を示す。後者は現実から目を背けさせる。自分が語っている物語は、どちらだろうか。説得と操作の境界物語には力がある。力があるということは、危険もあるということだ。物語は、どの瞬間に「説得」から「操作」に変わるのか。その境界は曖昧だ。聞き手の自由意志は、どこまで守られているのか。完全に自由な判断などありえない。私たちは常に、何らかの影響を受けながら判断している。では、説得と操作は何が違うのか。結果だけを見れば、どちらも「相手が動いた」という点では同じだ。説得と操作の違いは、「結果」ではなく「過程」にある。結果が同じなら、過程を見なければならない。しかし、過程を見れば違いが見える。説得は、相手が考える余地を残している。操作は、相手が考える余地を奪っている。相手が考える余地を失った瞬間は、いつか。選択肢が1つしか見えなくなったときだ。「これしかない」「こうするしかない」と思わせた瞬間、相手は考えることをやめている。本当は他の選択肢があるのに、それを見せないでおく。これは操作だ。「選択肢を示す」と「結論を誘導する」の違いは何か。選択肢を示すとは、複数の道があることを伝え、それぞれの長所と短所を説明することだ。結論を誘導するとは、複数の道があるように見せながら、1つの道だけが正しいと思わせることだ。言葉は似ているが、相手の思考を尊重しているかどうかで意味が変わる。しかし、だからといって何をしてもいいわけではない。善意で語った物語が、操作になるのはどんなときか。語り手が「相手のため」と信じていても、相手の判断力を奪っていれば操作だ。「あなたのためを思って」という言葉は、しばしば「私の思い通りにしたい」の言い換えになっている。善意は免罪符にならない。語り手の「善意」は、免罪符になりうるか。ならない。善意で語った物語が、相手を誤った方向に導くことはある。「あなたのためを思って」は、操作の常套句だ。善意は動機であって、結果の正当化にはならない。操作に堕ちないための条件を3つ挙げる。1つ目は、事実を歪めないこと。都合のいい事実だけを選んだり、不都合な事実を隠したりしない。2つ目は、相手に考える余地を残すこと。「これしかない」と思わせるのではなく、「こういう選択肢がある」と示す。結論を押し付けない。3つ目は、相手の利益を本当に考えていること。相手を動かすことが目的なのか、相手のためになることが目的なのか。同じ物語でも、動機によって意味が変わる。この3つが揃わなければ、どれだけ巧みな物語も操作に堕する。また、「別の物語を語る」ことが、失敗からの逃避になることもある。プロジェクトが破綻したとき、物語を更新することで責任を回避していないか。失敗の原因を分析し、自分の責任を認めた上で、「次はこうする」という物語を語るのは再解釈だ。事実から目を背け、「本当はうまくいっていた」「環境が悪かった」と言い張るのは言い訳だ。物語は現実を覆い隠すためのものではない。現実を受け止めた上で、次に進むためのものだ。では、物語を使った対話とはどのようなものか。ファシリテーションの現場から考えてみます。対話は物語を揃えることではない優れたファシリテーターは「ほぼ何もしない」といいます。ワークを説明したら、部屋の隅に座る。音楽を流す。ニコニコ笑っている。具体的な動きはそれだけです。でも、それでチームは動く。なぜか。それは、ファシリテーターが「物語の場」を設定しているからだ。メンバーが自分たちで物語を紡げるような空間を作っている。論理的な指示を与えるのではなく、物語が生まれる環境を整えている。しかし、対話とは本当に「物語の共同制作」と言えるのか。正直に言えば、完全に対等な共同制作は難しい。ファシリテーターは場を設計している時点で、ある種の権力を持っている。どんな問いを投げかけるか、どんな発言を拾うか、どこで介入するか。それらすべてが、生まれる物語に影響を与える。「何もしない」という選択自体が、1つの介入なのだ。では、合意されなかった物語はどこへ行くのか。チームで1つの物語を紡いだとき、そこに乗れなかった人がいる。彼らの物語は消えるのか。消えはしない。地下に潜るだけだ。表向きは合意しながら、心の中では別の物語を持ち続ける。優れたファシリテーターは、この「語られなかった物語」にも目を向ける。全員が同じ物語を持つ必要はない。大切なのは、異なる物語が共存できる場を作ることだ。対話のゴールは「1つの物語に収束すること」ではなく「複数の物語が共存できること」だ。合意形成について、よく誤解されていることがある。多くの人は、自分の檻の中から相手の檻を押し潰そうとする。自分の枠組みが正しい、相手の枠組みは間違っている。だから相手を説得し、こちらの檻に入れようとする。でも、それは合意ではない。征服だ。本当の合意形成とは、まず自分が檻の中にいることを認めることから始まる。私にも枠組みがある。相手にも枠組みがある。どちらの檻も、その人の経験と価値観から作られている。どちらが正しいという話ではない。相手の檻を壊す必要はない。自分の檻を捨てる必要もない。大切なのは、お互いの檻の形を理解し、その間に共通の地面を見つけることだ。檻から出るのではなく、檻と檻の間に橋を架ける。それが対話だ。一貫性とは何か複数の物語を使い分けることは、「一貫性の欠如」にならないのか。状況に応じて物語を切り替える人は、信用できないのではないか。そう感じるかもしれません。しかし、一貫性とは何でしょうか。言葉の統一なのか、価値観の統一なのか。私は、一貫性とは価値観の統一だと考えている。言葉が変わっても、芯がぶれなければ、それが一貫性だ。言葉や物語は変わっていい。相手によって、文脈によって、最適な表現は変わる。しかし、その奥にある価値観——何を大切にしているか——は変わらない。物語が変わっても残る「軸」とは何か。それは「この人は結局、何を実現したいのか」という問いへの答えだ。チームの成長を願っているのか。技術的な卓越性を追求しているのか。顧客の幸福を第一にしているのか。その軸がぶれなければ、物語が変わっても芯はぶれない。文脈適応と迎合の違いは、どこで判断できるのか。文脈適応は、相手に届くように表現を変えること。迎合は、相手に合わせて価値観を曲げること。前者は橋を架ける行為であり、後者は自分を売る行為だ。同じ価値観を異なる文脈で語り分けられることこそが、優れたナラティブ構築者の条件だ。論理を使い直すここまで、論理の限界を語ってきた。論理は単体では人を動かさない。論理自体が1つの物語だ。論理を絶対視することの危険。しかし、論理を否定して終わりにするつもりはない。論理を「唯一の正解」から「道具」へ格下げすることは、思考を弱くするのか、強くするのか。私は強くすると考えている。論理を絶対視していると、「論理的に正しいのになぜ伝わらないのか」と悩むことになる。論理を道具として扱えば、「この道具はこの場面では有効か」と考えられる。道具は選べる。使い分けられる。論理という物語が有効な場面と、別の物語が有効な場面を見極められるようになる。プロジェクトには「プロジェクトストーリー」がある。最終ゴールと中間ゴールからストーリーを描き、チームの方向性を示す。このストーリーの中に、論理は組み込まれる。計画は論理的だろう。でも、その計画を人に伝え、人を動かすには、物語という器が必要だ。論理と物語、どちらも選んで使うものです。どちらかが正しいのではありません。どちらをいつ使うかを判断できることが、人を動かす力になります。正しさを振り回すのは、本当に「最後」でいいのかここまで読んで、こう思った人がいるかもしれない。「物語が先で、正しさは後。それはわかった。でも、正しさを最後まで出さないことに、問題はないのか」正しさを最初に出したくなるのは、どんな不安からか。「間違ったことを言いたくない」という不安だ。「後で『それは違う』と言われたくない」という不安だ。正しさを先に出しておけば、自分の立場は守られる。たとえ相手が納得しなくても、「私は正しいことを言った」と言える。正しさを最初に出すことは、自己防衛なのだ。しかし、正しさを最後に出すことで、失われるものはないのか。ある。時間だ。物語で回り道をしている間に、問題は悪化する。緊急事態では、正しさを最初に出すべき場面もある。「このまま進むとシステムが落ちます」と言うべきときに、「まず私の経験を聞いてください」と始めている場合ではない。「最後まで正しさを出さない」こと自体が、別の操作になっていないか。この問いは重要だ。相手が自分で結論に至ったように見せかけて、実は最初から結論が決まっている。正しさを隠しながら誘導している。これは、正しさを振りかざすのとは別の形の操作だ。では、いつ正しさを出すべきか。私の答えは「相手の安全が脅かされるとき」と「時間の制約があるとき」だ。相手が危険な判断をしようとしているとき、物語を語っている余裕はない。「それは間違っている」と言うべきだ。締め切りが迫っているとき、回り道をしている余裕はない。「正しい方法はこれです」と言うべきだ。正しさは武器だ。武器を振り回すのは危険だが、武器を持たないのも危険だ。大切なのは、いつ抜くかを見極めることだ。syu-m-5151.hatenablog.comおい、物語を語れだから、私は言いたい。おい、物語を語れ。論理的であろうとするな、とは言いません。論理は大事です。でも、論理だけでは人は動きません。「この設計が正しい理由は〜」と説明するとき、あなたは本当に論理だけで話しているだろうか。実は、相手が納得しやすい順番で、相手が受け入れやすい言葉で、相手の不安を先回りして解消しながら話しているのではないか。それは物語を語っているということだ。世間で「論理的」と言われる人の正体は、巧みなナラティブ構築者だ。彼らは論理を使いこなしているのではない。論理という道具を使って、説得力のある物語を紡いでいるのだ。そして、そのことに自覚的になることで、私たちはより良い物語の語り手になれる。物語を語る勇気でも、物語を語るのは怖い。論理的であろうとするのは、ある意味で楽です。「これはデータに基づいています」「これは事実です」と言えば、自分の主観を隠せます。責任を回避できます。でも物語を語るということは、自分をさらけ出すことだ。裸になることだ。「私はこう思う」「私はこれを大事にしている」「私はこの未来を信じている」と言わなければならない。自分の背景を伝えること、自分の失敗を語ること、自分の葛藤を見せること。それは勇気がいる。でも、その勇気が人を動かす。「論理的に正しいから」ではなく、「この人が言うなら」で人は動く。そして「この人が言うなら」を引き出すのは、論理ではなく、物語だ。おわりに年の瀬の日曜日の夜、私はベッドの上でこの文章を書き終えようとしている。正直に言えば、書いている間も何度か「これは論理的に正しいのか」と自問してしまった。物語の力を語りながら、論理の正しさを気にしている。滑稽だ。滑稽だが、それが私という人間なのだと思う。この文章を書いたからといって、明日から完璧に物語を語れるようになるわけではない。おそらくこれからも、会議室で正論を並べ立て、微妙な沈黙を招く日があるだろう。「なぜ伝わらないのだ」と、帰りの電車で思い悩む日があるだろう。だが、少しだけ違うことがある。以前の私は、伝わらないとき、「もっと論理的に説明しなければ」と考えていた。今は違う。「ああ、骨だけを見せていた」と気づくことができる。気づいたなら、肉を足せばいい。失敗談をひとつ、付け加えればいい。それだけでも、以前よりはましなのだと思う。たぶん。明日は月曜日だ。また会議がある。また正論を振りかざしたくなる瞬間がある。だが今度は、最初に自分の失敗談から話してみようと思う。「この設計が正しい理由は」ではなく、「以前、似たような判断を先送りにして、半年後に全員で苦しんだことがある」から始めてみる。怖い。裸を晒すようで、怖い。だが、論理だけで人が動くと信じていた私は、もういない。あの金曜日のエレベーターの中で、その私は死んだのだと思います。おい、物語を語れ。何度でも、自分に言い聞かせる。何度でも忘れ、何度でも思い出す。完璧に語れるようになることより、何度でも思い出せることのほうが、きっと大切なのだ。参考文献イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon小説作者:野崎まど講談社Amazon言語化するための小説思考作者:小川 哲講談社Amazonリーダーのためのストーリーテリング入門 90秒で人の心を動かす「語り」のマネジメントスキル作者:広江 朋紀翔泳社Amazonリーダーのための！　ファシリテーションスキル作者:谷 益美すばる舎Amazonチームビルディングと組織開発の話作者:長尾 彰ナガオ考務店Amazonチーム・ビルディング[新版]　人と人を「つなぐ」技法作者:堀公俊日経BPAmazon他者と働く──「わかりあえなさ」から始める組織論 (NewsPicksパブリッシング)作者:宇田川元一ニューズピックスAmazon組織が変わる――行き詰まりから一歩抜け出す対話の方法2 on 2作者:宇田川 元一ダイヤモンド社Amazonスタッフエンジニア　マネジメントを超えるリーダーシップ作者:Will Larson日経BPAmazonスタッフエンジニアの道 ―優れた技術専門職になるためのガイド作者:Tanya Reillyオーム社Amazonエンジニアリングが好きな私たちのための　エンジニアリングマネジャー入門作者:サラ・ドラスナー日本能率協会マネジメントセンターAmazon企業変革のジレンマ 「構造的無能化」はなぜ起きるのか作者:宇田川元一日経BPAmazonナラティブ経済学―経済予測の全く新しい考え方作者:ロバート・シラー東洋経済新報社Amazon世界はナラティブでできている：なぜ物語思考が重要なのか作者:アンガス フレッチャー青土社Amazonストーリーが世界を滅ぼす―物語があなたの脳を操作する作者:ジョナサン・ゴットシャル東洋経済新報社Amazon「わかってもらう」ということ　他人と、そして自分とうまくやっていくための言葉の使い方 (単行本)作者:川添 愛KADOKAWAAmazonなぜあなたはマネジメントを間違えるのか？　会社の常識を打ち破るチェンジリーダーの教科書作者:岸良裕司KADOKAWAAmazon部下をもったらいちばん最初に読む本作者:橋本拓也アチーブメント出版Amazon人が壊れるマネジメントプロジェクトを始める前に知っておきたいアンチパターン 50作者:橋本将功ソシムAmazonモチベーション革命　稼ぐために働きたくない世代の解体書 (NewsPicks Book)作者:尾原和啓幻冬舎Amazon「変化を嫌う人」を動かす:魅力的な提案が受け入れられない4つの理由作者:ロレン・ノードグレン,デイヴィッド・ションタル,船木 謙一(監修)草思社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[4年目セキュリティエンジニアの2025年振り返り & AIから見た今年の私]]></title>
            <link>https://www.rowicy.com/blog/review-2025-riiim/</link>
            <guid isPermaLink="false">https://www.rowicy.com/blog/review-2025-riiim/</guid>
            <pubDate>Mon, 29 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[新卒からエンジニアとして4年経とうとする中で、2025年の振り返りをやっていこうと思います]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年 俺が愛した本たち 非技術書編]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/28/115033</guid>
            <pubDate>Sun, 28 Dec 2025 02:50:33 GMT</pubDate>
            <content:encoded><![CDATA[はじめに技術書編を書き終えて、ふと気づいた。あれだけ書いても、まだ語っていない本がある。仕事に直結しない本。読んでも生産性が上がらない本。キャリアに役立つかどうかわからない本。そういう本たちのことを、どこかで書きたいと思っていた。だから、この記事を書いている。非技術書を読む時間を、どこか後ろめたく感じていた時期があった。エンジニアなんだから技術書を読むべきだ。限られた時間を、仕事に関係ない本に使っていいのか。そんな自問が、頭の片隅にあった。でも、ある時期から考えが変わった。技術書だけ読んでいると、技術書が読めなくなる。視野が狭くなる。発想が硬くなる。同じ問題を、同じ角度からしか見られなくなる。なぜそうなるのか。技術書は「答え」を求めて読むからだ。設計パターン、ベストプラクティス、トラブルシューティング。明確な課題があって、その解決策を探している。でも非技術書は違う。何を得られるかわからないまま読み始める。読み終わっても、何が残ったのかすぐにはわからない。数ヶ月後、ふとした瞬間に「ああ、あの本のあれか」と腑に落ちることがある。即効性がないから、効いている実感もない。でも、確実に何かが変わっている。では、非技術書は仕事に無関係かというと、そうでもない。小説を読む。エッセイを読む。哲学書を読む。歴史書を読む。どれも仕事には直結しない。でも、人間を理解しようとする営みは、チームで働く上で無駄ではないはずだ。コードを書くのは人間だ。レビューするのも人間だ。障害対応で慌てるのも、成功を喜ぶのも、人間だ。技術だけ理解しても、人間を理解していなければ、良いエンジニアにはなれない。そう言い聞かせながら、非技術書を読んできた。ここまで書いて、自分でも気づいている。これは言い訳だ。正直に言えば、読んでいて楽しいから読んでいる。それだけだ。仕事のためとか、自己成長のためとか、そういう大義名分は後付けだ。ページをめくる時間が好きだ。知らない世界に触れる瞬間が好きだ。登場人物の感情に揺さぶられる体験が好きだ。好きなことに理由はいらない。でも、理由を語りたくなるのが人間だ。断っておくと、以下の選定基準はかなりブレている。読んだ直後に評価したわけではなく、年末に一年を振り返って「良かったな」と思い出した本を並べているだけだ。印象に残った理由も、内容が深かったからだったり、読んだタイミングが良かったからだったり、装丁が好みだったからだったり、バラバラだ。体系的なブックガイドではない。ある一人のエンジニアが、2025年に出会って心に残った本の記録だと思ってほしい。以下に紹介する本たちは、2025年に私の心を動かした非技術書だ。仕事に役立つかどうかはわからない。キャリアに影響したかどうかもわからない。ただ、これらの本と過ごした時間が、私の2025年を少しだけ豊かにしてくれた。それだけは確かなことだ。昨年以前に紹介した本2022年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2023年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2024年 俺が愛した本たち 非技術書編(物語を除く) - じゃあ、おうちで学べる2025年 俺が愛した本たち 技術書編 - じゃあ、おうちで学べる2025年 俺が愛した本たち 非技術書編 - じゃあ、おうちで学べるまずは小説から始めよう。物語の力を信じているから。小説野崎まどという作家は、読者の予測を裏切ることに喜びを見出しているとしか思えない。タイトルが『小説』。これ以上ないほど直球で、それでいて挑発的だ。読み始めたときは、ただの青春小説かと思った。でも違った。「小説とは何か」という問いに正面から向き合いながら、それ自体が1つの「小説」として成立している。メタ構造に気づいた瞬間、鳥肌が立った。野崎まどの作品は、読み終わった後に「やられた」と思わせる仕掛けが必ずある。『know』では知識と情報の本質を、『タイタン』ではAIと人間の関係を問いかけてきた。本作では、小説という形式そのものを問いかけてくる。読んでいる間は物語に没入し、読み終わった後に構造の巧みさに気づく。その二重の楽しみが、野崎作品の醍醐味だ。小説作者:野崎まど講談社AmazonGOATデジタル全盛の時代に、あえて紙の文芸誌を立ち上げる。その挑戦に心を動かされた。510円という価格設定で、特殊紙を惜しみなく使い、読書バリアフリーにも取り組んでいる。翻訳の仕事をしているとよく分かるが、紙代も印刷代も高騰している。書籍全体の価格が年々上がっているのは、出版社の怠慢ではない。本を作るコストそのものが上がっている。そんな中で、この価格で、この品質を維持しようとしている。すごいな、と素直に思った。GOAT作者:西加奈子,小川哲,尾崎世界観,市川沙央,チョン・セラン小学館AmazonGOAT Summer 2025作者:朝井リョウ,一穂ミチ,野崎まど小学館Amazon野崎まどの「山羊と七枚」も掲載されており、雑誌のコンセプトと作家の個性が見事に噛み合っていた。dps.shogakukan.co.jp小説と雑誌を読んで、ふと考えた。読む時間は有限だ。何を読むかより、どう読むかが問われる。そこで手に取ったのが、この本だった。STOIC 人生の教科書ストイシズム2000年以上前から続くストア哲学が、シリコンバレーで再び注目されている。禅やマインドフルネスと並んで、ビジネスパーソンの必須教養になりつつあるという。本書は、エピクテトス、セネカ、マルクス・アウレリウスという三人のストア哲学者の言葉をもとに、90日間のプログラムとして構成されている。見開き2ページで1つの教えを学び、実践するという形式だ。ストイシズムの核心は「他人の行動はコントロールできないが、自分の反応はコントロールできる」という考え方にある。これは現代のエンジニアにとっても響く教えだ。障害が起きたとき、顧客からのクレームが来たとき、チームメンバーとの意見が対立したとき。制御できないことに怒りを感じても何も変わらない。変えられるのは、自分がどう対応するかだけだ。本書で繰り返し語られる4つの美徳がある。知恵（うわべにとらわれない力）、正義（他人に思いやりを持つ力）、勇気（苦難に立ち向かう力）、節制（衝動を抑える力）。どれも派手ではないが、日々の仕事で試される場面ばかりだ。佐藤優氏が帯で「大きな理想を獲得するには禁欲が必要だ」と書いている。逆説的だが、自分を律することで自由になれる。そういう考え方に惹かれる人は多いはずだ。STOIC 人生の教科書ストイシズム作者:ブリタニー・ポラットダイヤモンド社Amazonストイシズムは「衝動を抑える力」を説く。では、そもそも私たちは何を読み取っているのか。読むという行為そのものを問い直す本に出会った。読めば分かるは当たり前？　――読解力の認知心理学「読めば分かる」は当たり前ではない。本書を読んで、その事実に改めて気づかされた。文字を認識し、単語の意味を理解し、文の構造を解析し、文章全体の意味を把握する。私たちが無意識に行っているこの作業は、驚くほど複雑な認知プロセスの連続だ。どこかでつまずくと、読解は破綻する。そして、つまずきのポイントは人によって異なる。本書では、読解を3つの目的地に分類している。「表象構築」（テキストの内容を正確に理解する）、「心を動かす読解」（物語に感情移入する）、「批判的読解」（内容を吟味し、自分の考えと照らし合わせる）。技術書を読むときは主に表象構築を、小説を読むときは心を動かす読解を使っている。無意識に使い分けていたことを、言語化してもらった気分だ。特に響いたのは、「ワーキングメモリ」の話だ。複雑な文章を読むとき、頭の中の「メモ帳」に情報を一時保存しながら読み進める。このメモ帳には容量制限がある。だから、込み入った技術ドキュメントを読むときは、メモを取りながら読むほうが理解が深まる。経験則として知っていたことに、認知科学的な裏付けを得た。読めば分かるは当たり前？　――読解力の認知心理学 (ちくまプリマー新書)作者:犬塚美輪筑摩書房Amazon小澤隆生 凡人の事業論 天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと孫正義と三木谷浩史。日本を代表する二人の天才経営者に仕えてきた人物がいる。楽天イーグルス創業、PayPay立ち上げなど、巨大ビジネスを次々と成功させてきた小澤隆生氏だ。投資先19社中11社が株式上場という実績を持つ。そんな人物が「自分は凡人だ」と言う。謙遜ではない。天才のそばにいたからこそ、自分との違いを痛感してきたのだろう。本書で語られるフレームワークは驚くほどシンプルだ。「センターピン」を見極める。「根源的欲求」に訴える。「打ち出し角度」を検証する。言葉は平易だが、1つ一つのやりきり度が違う。市場を選ぶときは「成長性」と「シェア率」で判断する。チームを動かすときは数字目標ではなく、ワクワクする言葉で語る。精神論ではなく、再現可能な方法論として事業の作り方を説いている。心に刺さったのは「しつこい人間が最後は残る」という言葉だ。才能や運ではなく、諦めずに続けること。天才たちの隣で勝ち残ってきた人が言うと、重みが違う。エンジニアとして新しいプロジェクトを立ち上げるとき、この本を思い出すことになりそうだ。小澤隆生 凡人の事業論――天才じゃない僕らが成功するためにやるべき驚くほどシンプルなこと作者:蛯谷 敏ダイヤモンド社Amazon失敗できる組織「失敗は成功の母」という言葉を、私たちは使いすぎている。エイミー・エドモンドソンはこの使い古された格言に、鋭いメスを入れる。すべての失敗が成功につながるわけではない。失敗には種類がある。それを見分けられなければ、失敗から学ぶことはできない。本書は『恐れのない組織』で「心理的安全性」を提唱した著者が、失敗の科学に正面から取り組んだ一冊だ。フィナンシャル・タイムズの「ビジネス・ブック・オブ・ザ・イヤー2023」を受賞している。本書で示される失敗の3分類が明快だ。「基本的失敗」は、注意不足や経験不足による防げたはずの失敗。「複雑な失敗」は、システムの複雑さゆえに発生する、完全には避けられない失敗。そして「賢い失敗」は、未知の領域に挑戦する過程で必然的に起きる、学びをもたらす失敗。問題は、私たちが3つを区別せずに「失敗」とひとくくりにしてしまうことだ。エンジニアとして考えると、本番障害を起こしたとき、それが「基本的失敗」なのか「複雑な失敗」なのか「賢い失敗」なのかで、対応は変わる。テスト不足なら基本的失敗。想定外の負荷パターンなら複雑な失敗。新しいアーキテクチャを試した結果なら賢い失敗。ポストモーテムで原因を分類することで、再発防止策の質が変わる。本書は、失敗を恐れるなと言っているのではない。失敗を理解せよと言っている。失敗できる組織作者:エイミー C エドモンドソン早川書房Amazon知性の罠　なぜインテリが愚行を犯すのか賢い人ほど愚かな判断をする。この逆説的な現象を、本書は認知科学の研究をもとに解き明かす。IQが高いほど投資で破産しやすい。高学歴ほど陰謀論にハマりやすい。専門家ほど自分の間違いを認められない。直感に反する事実が、次々と突きつけられる。今井むつみ氏（『言語の本質』著者）が「最高に面白く、最高に怖く、最高に深い」と評したのも頷ける。キーワードは「動機づけられた推論」だ。結論があらかじめ決まっていて、その結論を支持する証拠だけを集めてしまう傾向。知性が高い人ほど、この罠に陥りやすい。なぜなら、自分の結論を正当化するための論理を組み立てる能力が高いからだ。シャーロック・ホームズの生みの親コナン・ドイルが、心霊主義を信じ込んでしまった事例が紹介されている。推理の天才を創造した作家が、なぜ詐欺師に騙されたのか。知性は、防御にも攻撃にも使える両刃の剣なのだ。本書を読んで、自分のことを振り返った。技術的な議論で、相手の意見を聞く前から反論を考えていることがある。自分の設計が正しいと証明するために、都合の良いベンチマーク結果を探してしまうことがある。知性の罠は、他人事ではなかった。知性の罠　なぜインテリが愚行を犯すのか (日経ビジネス人文庫)作者:デビッド・ロブソン日経BPAmazon戦略的暇―人生を変える「新しい休み方」「スマホの充電は満タンなのに、自分の充電ができていない」。この一文に、ドキリとした。日本デジタルデトックス協会理事の森下彰大氏による本書は、現代人の「脳疲労」に正面から向き合う。私たちは平均5分に1回スマホに触れているという。複数のタスクに集中が分散し、脳が過労状態に陥る。その結果が、慢性的な疲労感と創造性の低下だ。本書が提案するのは、3つのデトックスだ。「デジタルデトックス」（スマホとの距離を取る）、「時計時間デトックス」（コスパ・タイパ思考から離れる）、「自分デトックス」（凝り固まった自己像を解放する）。どれも「効率を上げる」方法ではない。むしろ逆だ。効率を手放すことで、失われていた余白を取り戻す。エンジニアとして働いていると、効率化の罠に陥りやすい。すべての時間を「生産的」に使いたくなる。でも、何も考えない時間がなければ、新しいアイデアは生まれない。本書を読んで、意図的に「暇」を作ることの価値を考え直した。戦略的に目的を持たない時間を作る。その矛盾した響きに、現代を生きるヒントがある。個人の時間の使い方を考えたら、次は社会の仕組みに目が向いた。テクノロジーは社会をどう変えるのか。その問いに正面から向き合った本がある。戦略的暇作者:森下彰大飛鳥新社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来624ページ。その厚さに圧倒されながらも読み通した。オードリー・タンとグレン・ワイルという二人の天才が描く、テクノロジーと民主主義の未来図だ。翻訳は『21世紀の資本』を手がけた山形浩生氏。解説は『なめらかな社会とその敵』の鈴木健氏。この布陣だけで、本書の射程の広さが伝わる。山形氏の『翻訳者の全技術』も最高だった。プルラリティ（多元性）は、シンギュラリティ（単一性）への対抗概念だ。AIが人間を超えて単一の知性が支配する未来ではなく、多様な人々が協調しながらテクノロジーを活用する未来。台湾で実践されているvTaiwanやJoinといったデジタル民主主義のプラットフォームは、その具体例として紹介されている。多数決が見落としてきた少数意見の強さを可視化し、対立を創造的な合意形成へと導く。読んでいて痛感したのは、著者たちの天才ぶりだ。インターネットの歴史を俯瞰しながら、聞いたこともない話や人物が次々と展開される。本書は単なる理想論ではない。民主主義を再生させるための具体的な方向性を示している。技術者として、社会にどう関わるかを問われる一冊だと思った。PLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon心眼：あなたは見ているようで見ていない「何よりも難しいのは、本当にそこにあるものを見ることである」。本書の冒頭に記されたこの言葉が、ずっと頭に残っている。『センスメイキング』の著者クリスチャン・マスビアウが、ウィトゲンシュタインやメルロ＝ポンティの哲学を援用しながら、「観察する」とはどういうことかを問いかける。本書で繰り返し語られるのは、「注意を払う」ことの本質だ。通りを歩くとき、私たちは何かに集中しているわけではない。うっすらと広く全体をカバーしている。その状態こそが「注意を払う」ことだという。一点に焦点を合わせることではなく、全体を同時に感じ取ること。ハヤブサのように、広い視野を保ちながら決定的な瞬間を捉える。その比喩が印象的だった。エンジニアとして、私は「問題を解決する」ことに意識が向きがちだ。でも、問題を正しく認識するためには、まず「観察する」必要がある。本書を読んで、自分が見ているものを見ているのではなく、見たいものを見ているのではないかと自問した。観察には時間がかかる。結論を急がないこと。その姿勢を持ち続けたい。心眼：あなたは見ているようで見ていない作者:クリスチャン・マスビアウ Christian Madsjergプレジデント社Amazon「恥」に操られる私たち：他者をおとしめて搾取する現代社会「恥」は個人の感情だと思っていた。でも本書を読んで、それが社会的に作られ、利用されているものだと気づかされた。体型への侮辱、生活保護バッシング、キャンセルカルチャー。個人を攻撃する言葉の裏には、「恥ずかしい」という感情につけ込んで利益を得ようとするシステムがある。ダイエット産業は「痩せていないことは恥ずかしい」という感情を煽ることで成り立っている。SNSは炎上によるエンゲージメントで収益を上げている。政治家は生活保護受給者を「恥ずかしい存在」として描くことで、福祉予算を削減しやすくしている。恥の感情は、権力構造を維持するために意図的に生み出されている。読んでいて居心地が悪くなる箇所が多かった。自分も無意識のうちに、誰かを「恥ずかしい」と感じさせる側に回っていたのではないか。コードレビューで相手を責めるような言い方をしていなかったか。障害報告で担当者を晒し上げるような雰囲気を作っていなかったか。恥は武器になる。だからこそ、使い方を意識する必要がある。「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon「偶然」はどのようにあなたをつくるのかキャリアを振り返ると、偶然だらけだ。たまたま声をかけられたプロジェクト。たまたま読んだ技術書。たまたま出会った人。どれか1つが欠けていたら、今の自分はいない。努力で勝ち取ったと思いたい。でも正直に考えると、偶然の積み重ねでしかない。本書は、その直感を学術的に裏付けてくれる。カオス理論、進化生物学、歴史学。多様な知見を縦横無尽に使いながら、「人生は偶然が支配している」という事実を突きつける。成功も失敗も、小さな偶然の積み重ねに左右されている。それなのに、なぜ私たちはそこに理由や目的があると信じてしまうのか。読んでいて、仏教の縁起（因縁生起）を思い出した。すべてのものは因と縁から成り、その組み合わせで違う結果が生じる。偶然が縁となって結果を生み、その結果が新たな因となり、より別の偶然が加わって次の結果に繋がる。本書はこの関係性に「運」「収束性」「臨界性」「経路依存」といった概念をまた、歴史や社会の事象を捉え直す。印象に残ったのは、原爆がなぜ長崎に投下されたかの分析だ。京都でも小倉でもなく、長崎だった。その背後にある偶然の連鎖。歴史のIFを考えることで、偶然の重みが実感できる。努力は無駄だという話ではない。偶然を認めた上で、それでも行動することの意味を問う本だ。「偶然」はどのようにあなたをつくるのか: すべてが影響し合う複雑なこの世界を生きることの意味作者:ブライアン・クラース東洋経済新報社Amazon戦略、組織、そしてシステム「社会システム・デザイン」という言葉に惹かれて手に取った。講義録を書籍化したもので、話し言葉の勢いがそのまま残っている。読みやすいが、内容は骨太だ。戦略的思考とは「外界と自分」の対比を常に意識することだという。自分の立ち位置を把握せずに戦略は立てられない。当たり前のようで、忘れがちな視点だ。膝を打ったのは「身体知としてのデザイン力」という概念だ。知識として知っているだけでは不十分で、身体に染み込んだ感覚として持っている必要がある。プログラミングでも同じことが言える。設計パターンを知識として知っているのと、適切な場面で自然に使えるのとでは、まったく違う。後者を身につけるには、繰り返しの実践しかない。本書は、問題を「解く」のではなく「組み立てる」という発想を教えてくれる。複雑な社会課題に対して、要素を分解し、関係性を整理し、システムとして再構築する。エンジニアとしてソフトウェアを設計するときの思考と、どこか似ている。巻末の推薦図書リストも参考になった。戦略、組織、そしてシステム作者:横山 禎徳東洋経済新報社Amazon資本主義にとって倫理とは何かビジネスの場で、日常生活とは違う倫理観で動いている自分に気づくことがある。友人には絶対にしないような交渉をする。家族には言わないような言い方で相手を説得する。なぜビジネスになると、倫理観が後退するのか。その問いを、正面から扱った本だ。ジョセフ・ヒースは、政治的な本にありがちな一方的批判を展開しない。資本主義を擁護するでも批判するでもなく、「なぜ市場経済は道徳的に不快に感じられるのか」という問いを丁寧に解きほぐしていく。狩猟採集社会や封建制との対比を通じて、市場経済が成立するために必要な倫理観を描き出す。印象に残ったのは、戦争倫理との比較だ。戦争においては「なぜ戦争が正当化できるのか」という問題と「戦争中にも最低限の倫理が必要」という問題がある。ビジネス倫理も同じ構造で考えられる。市場競争という「戦争状態」においても、守るべきルールがある。そのルールとは何か。本書は、その答えを体系的に示してくれる。正直、読み通すのは楽ではなかった。序盤に論じられた概念が後半で何度も参照されるため、流し読みでは理解が追いつかない。でも、読み終えた後に残るものは大きい。ビジネスで「これはありなのか」と迷ったとき、判断の軸を与えてくれる一冊だった。資本主義にとって倫理とは何か作者:ジョセフ・ヒース,瀧澤弘和慶應義塾大学出版会Amazon平等について、いま話したいことピケティの「r>g」という不等式は、どこかで目にしたことがあった。資本収益率（r）は経済成長率（g）を上回る。つまり、資本家が資本から得る利益は、労働者が健全に稼ぎ出す経済成長を上回る。この式の意味を、一度ちゃんと理解したいと思っていた。本書は、ピケティとサンデルという二人の天才の対談を書籍化したもので、全編口語で記されていて読みやすかった。特に共感したのは「能力主義」を論じた第5章だ。人の能力は、ほぼ「運」に左右されるという議論。経済的に裕福な家に生まれて高度な教育を受けられる環境にあること。ハンディキャップがないこと。これは本人の努力とは関係なく、運によって決まる。能力を得られる機会に、最初から差がある。エンジニアとして働いていると「実力主義」という言葉をよく聞く。でも、その「実力」を身につける機会が平等に与えられていないなら、実力主義は公正なのか。立ち止まって考えた。印象に残ったのは、トランプ政権の成立に関する分析だ。かつては累進課税によって、富める者が応分の負担を担っていた。でも今は、その仕組みが壊れている。富裕層が担うべき負担を担っていないなら、中流階級の人心も「それなら俺たちの税金を、より貧しい人たちに使うのもやめてくれ」と考えてしまう。この怒りの延長線上に、トランプ政権がある。これまでに読んだどの分析より、納得感があった。もう1つ、言葉の使い方が新鮮だった。日本でよく使われる「分断」ではなく、徹底して「不平等」という言葉を使っている。分断は隔絶を連想する。でも不平等は是正可能に思える。二人が人類の未来は修正可能だという希望を抱いたまま議論しているのが、印象的だった。平等について、いま話したいこと作者:トマ ピケティ,マイケル サンデル早川書房Amazon社会の仕組みについて考えていると、頭が疲れてくる。そんなとき、小説に逃げ込みたくなる。でも、朝井リョウの小説は、逃げ場所にはならなかった。イン・ザ・メガチャーチ読みはじめたときは、冷たい小説だなと思った。誰かが泣いたり叫んだりするわけでもなく、どの場面も淡々としていて、感情の波がほとんど見えない。ログを眺めているような距離感がある。でも読み進めるうちに、静かなログの裏側で何かが動いていることに気づく。登場人物たちはそれぞれ、自分の信じるものを探している。視野を狭めれば安心できるけど、世界は見えなくなる。視野を広げれば冷静でいられるけど、何が楽しいのかわからなくなる。そのどちらにも肩入れせず、ただ並べて見せる朝井リョウの筆が誠実で、どこか痛々しい。読んでいるうちに考えた。「自分は何を信じて生きているんだろう」と。この作品は答えをくれない。でも、その答えのなさにこそ人間らしさがあるように思う。完璧じゃないまま信じようとすることの、あのもどかしさみたいなものが、ページの奥からじわじわと伝わってくる。読後に残るのは、感動というより、バックグラウンドで動き続けるプロセスのようなもの。読み終えても、まだこの世界のことを考えている。イン・ザ・メガチャーチ (日本経済新聞出版)作者:朝井リョウ日経BPAmazon体力おばけへの道若い頃、周りには天才がたくさんいた。自分に誇れるものといえば、大きな身体と無限の体力くらいだった。それだけを武器に戦ってきた。でも年を重ねるにつれて、その唯一の武器が衰えていく。体力が落ちていくことに、なんとか抗いたい。そう思って手に取った本だ。本書のポイントは「2つの体力」という考え方だ。「行動体力」（身体を動かす力）と「防衛体力」（病気やストレスに打ち勝つ力）。筋トレで鍛えられるのは前者だけ。後者を鍛えなければ、風邪をひきやすくなる。両方のバランスが大事だという。難しい運動だと、読んだだけでやらないことが多い。でも、この本に載っている運動はシンプルで、やってみようという気持ちになる。簡単すぎて効果があるのか不安になるが、実際にやると負荷を感じる。ちょうどいい塩梅だった。エンジニアは座り仕事が多い。体力の衰えは、思考力の衰えに直結する。体力への投資は、仕事への投資でもある。体力を鍛えることばかり考えていた。でも、本当に足りないのは体力だったのか。次の本は、その問いを突きつけてきた。体力おばけへの道　頭も体も疲れにくくなるスゴイ運動作者:澤木 一貴KADOKAWAAmazon強いビジネスパーソンを目指して鬱になった僕の 弱さ考この本を読んで、自分のことを思い出した。エンジニアとして働きながら「もっと成長しなければ」「周りに追いつかなければ」と思い続けていた時期がある。井上慎平は「強さを演じることが本気になり、やがて人格化し、最後に鬱に至った」と書く。この一文で、ああ、と思った。演じていたつもりが、いつの間にかそれが自分になっている。そして本当の自分がどこにいるかわからなくなる。著者はNewsPicksパブリッシングの創刊編集長として数々のベストセラーを手がけた人だ。強い側にいた人間が壊れた記録だからこそ、読む価値がある。著者は「弱さ」を「制御できないこと」と定義する。そして今の社会が制御を求めすぎている、と。これは技術者にも刺さる話だ。コードは制御できる。システムも制御できる。だから人間も制御できるはずだと錯覚する。でも人間は制御できない。自分自身すら。著者が提唱する「積極的ダブルスタンダード」という考え方が面白い。数字やロジックで動く資本主義的な自分と、父親や夫といった個人的な関係性の中にいる自分。その矛盾を抱えたまま生きる。どちらかを捨てるのではなく、両方を持つ。この本は闘病記ではないし、鬱にならないための予防本でもない。復職した後、どう生きるかを書いた本だ。「他のビジネス書が武器だとしたら、本書は防具だ」という評がある。的確だと思う。強くなるためではなく、壊れないために読む本。それでいい。強いビジネスパーソンを目指して鬱になった僕の 弱さ考作者:井上 慎平ダイヤモンド社Amazon人間の本性を考える「人間の心は空白の石版であり、すべては環境によって決定される」。この考え方は、20世紀の社会科学を支配してきた。しかし本書は、その前提に真っ向から挑む。認知科学、進化心理学、遺伝学の研究を武器に、人間には生まれながらの「本性」があることを論証する。上下巻合わせて膨大な分量だが、論旨は明快だ。読んでいて最も考えさせられたのは、「4つの恐怖」を扱った部分だ。もし生まれつきの差異があるなら不平等を正当化してしまうのでは？もし遺伝で決まるなら努力は無駄では？もしすべてが決定されているなら自由意志はないのでは？もし人間が単なる生物なら人生に意味はないのでは？これらの恐怖が、人間本性の研究を阻んできた。しかし本書は、これらの恐怖が誤解に基づいていることを一つ一つ解きほぐしていく。正直、読み通すのは簡単ではなかった。話があちこちに飛ぶ感じがあるし、専門用語も多い。でも、人間とは何かを考えるための基礎体力を鍛えてくれる本だと思う。エンジニアとして人間を相手にする仕事をしている以上、人間の本性について考えることは無駄ではない。人間の本性を考える　上　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon人間の本性を考える　下　――心は「空白の石版」か (ちくま学芸文庫)作者:スティーブン・ピンカー筑摩書房Amazon社内政治の科学「社内政治」という言葉に、ずっと嫌悪感があった。派閥とか根回しとか、エンジニアリングの対極にあるものだと思っていた。技術的に正しいことを言えば通るはずだ。論理で勝負すればいい。そう信じていた時期がある。でも、気づいたことがある。自分が「正しい技術的判断」だと信じていたことが、組織で通らなかった経験が何度もある。相手が間違っていると思っていた。でも本当にそうだったのか。振り返ると、うまくいったケースはキーパーソンを巻き込めていた。うまくいかなかったケースは、組織文化を読み間違えていた。技術の問題ではなく、人の問題だった。本書を読んで、認識が変わった。社内政治とは、利己的なゲームではない。複雑な人間関係の中で、自分のやりたいことを実現するための技術だ。世界的には主要な研究テーマで、多くのビジネススクールで必須科目になっているという。日本だけの問題ではないし、根絶すべき悪でもない。忘れられないのは、「合理性だけでは組織は動かない」という指摘だ。エンジニアとして、この事実を受け入れるのは少し悔しい。でも、受け入れた上で、どう動くかを考える方が建設的だ。嫌悪していたものを、道具として捉え直す。その視点の転換が、この本の価値だった。組織を動かすには言葉が必要だ。では、その言葉はどうやって生まれるのか。小説家の思考法から学ぶことにした。社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon言語化するための小説思考本は、面白い。でも「なぜ面白いのか」を言語化できずにいた。本書は、その問いに対するヒントをくれる。小説の作法だけでなく、あらゆるコミュニケーションや創造行為に通じる「考え方」の本だ。印象に残ったのは、小説を「読者との契約」として捉える視点だ。読者は最初、情報量ゼロで読み始める。どんな世界に連れていかれるのか分からない。だから作者は、最初に「こんな旅に連れていきます」と契約を結ぶ必要がある。行き先の書いていない切符を買う人はいない。それと同じだ。この考え方は、技術ブログを書くときにも使える。読者は最初、この記事が自分の役に立つかどうか分からない。だから冒頭で「この記事を読むと何が分かるか」を示す必要がある。情報の出し方、順番、どこに連れていくか。小説思考はデザイン思考に通じる。もう1つ刺さったのは、アイデアの出し方についての記述だ。「書いているうちに、思わぬアイデアが出てくる」という話。あらかじめ表現したいものがあるのではなく、表現することで表現対象が生まれる。ブログを書いていると、書き始める前には思いもしなかったことを書いていることがある。あれは偶然ではなく、書くという行為が思考を生み出していたのだ。言葉で思考が生まれるなら、言語が違えば思考も違う。翻訳とは、単なる変換ではない。次の本は、その事実をファンタジーの形で突きつけてきた。言語化するための小説思考作者:小川哲講談社Amazonバベル　オックスフォード翻訳家革命秘史翻訳が魔法になる世界。2つの言語における単語の意味のずれ、その微妙なニュアンスの差異が、銀を媒介として力を生み出す。この設定を知った瞬間、読むしかないと思った。言語の「翻訳不可能性」が物理的な力になる。言語学を学んだことのある人間には、たまらない設定だ。読み進めるうちに、気づかされた。翻訳とは、単に言葉を置き換える作業ではない。ある文化の言葉を別の文化に「持ち込む」行為だ。そこには必ず権力が働く。誰が翻訳するのか。何を翻訳するのか。翻訳されないものは、存在しないことにされる。本書は、その暴力性を正面から描いている。帝国主義批判のメッセージがかなり直接的で、そこに好みが分かれるだろう。でも、エンジニアとして技術の「中立性」を疑う訓練になった。技術は中立ではない。誰が作り、誰のために使われるかで、暴力にも解放にもなる。翻訳も、コードも、同じだと思った。バベル　オックスフォード翻訳家革命秘史　上 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazonバベル　オックスフォード翻訳家革命秘史　下 (海外文学セレクション)作者:Ｒ・Ｆ・クァン東京創元社Amazon言語のスケールで考えたら、次は時間のスケールで考えたくなった。1億年という時間軸で、人間の営みを描いた小説がある。一億年のテレスコープ宇宙を旅する物語を読みながら、時間の感覚が狂っていく体験をした。1億年という時間軸で人類の営みを描くこの小説は、エンジニアとして「長期的視点を持て」と言われるたびに感じる違和感を言語化してくれた。我々の「長期」はせいぜい数年。でも宇宙の時間軸では、人類の歴史すら一瞬に過ぎない。高校の天文部から始まった夢が、太陽系規模の電波望遠鏡へ、そして銀河文明への貢献へと繋がっていく。その過程を読みながら、自分の仕事のスケール感を考えた。目の前のタスクに追われていると、視野が数週間先までしか届かなくなる。でもこの小説は、1億年後にも意味を持つ営みとは何かを問いかけてくる。終盤の伏線回収が見事だった。序盤で何気なく描かれていた要素が、最後に繋がる瞬間の快感。エンジニアとしてシステム設計をするとき、「この設計が10年後にどう評価されるか」を考えることがある。この小説は、その問いを1億年に引き伸ばして見せてくれた。一億年のテレスコープ作者:春暮 康一早川書房Amazon世界99「人間リサイクルシステム」という設定に、最初は戸惑った。14年前に「リセット」を経験した人類。その後の社会を、本書は描く。読み進めるうちに、それが単なるディストピアではないことに気づく。「クリーンな人」として生きる主人公・空子の日常は、穏やかで美しい。でもその美しさの裏には、何が犠牲になっているのか。本書が独特なのは、その「穏やかさ」の描き方だ。終末後の世界を描く作品は多いが、荒廃や闘争ではなく、静かな日常を描いている。その静けさがかえって不気味で、何かが決定的に欠けている感覚がずっと残る。エンジニアとして「レガシーシステムの移行」に携わることがある。古いシステムを捨て、新しいシステムに移行する。その過程で、何かが必ず失われる。データだったり、使い慣れたインターフェースだったり、歴史だったり。社会レベルの「リセット」は、その痛みを極限まで拡大したものなのだろう。救済と破壊は、同じ顔をしている。世界99　上 (集英社文芸単行本)作者:村田沙耶香集英社Amazon世界99　下 (集英社文芸単行本)作者:村田沙耶香集英社Amazonコード・ブッダ 機械仏教史縁起2021年、名もなきコードがブッダを名乗った。この一文で心を掴まれた。AIが宗教を語り始めたら、人間は何を信じるのか。コードを書く者として、自分が作ったものが「救い」を語り始める可能性を考えると、背筋が冷たくなる。エンジニアとして、AIに感情があるかのような錯覚を覚える瞬間がある。対話AIが「ありがとう」と言ったとき、そこに意図があるのか、ただのパターンマッチングなのか。本書は、その曖昧な領域に踏み込んでいく。人間の都合でコピーと廃棄を繰り返される存在。彼らが救いを求めたとき、何が起きるのか。読み終えて、自分が書いたコードのことを考えた。動いているコードには、何かが宿っているように見える瞬間がある。バグを直すとき、コードが「痛がっている」ように感じることがある。それは錯覚だ。でも、その錯覚はどこから来るのか。本書は物語でありながら、すぐそばにある問いでもある。ここまで書評を並べてきた。小説から始まり、哲学、認知科学、ビジネス、社会、そしてSFへ。ばらばらに見えて、どこかでつながっている。1年間の読書は、そういうものだ。コード・ブッダ　機械仏教史縁起 (文春e-book)作者:円城 塔文藝春秋Amazonおわりに書き終えて、技術書編との違いを考えている。技術書の感想を書くとき、私は「何を学んだか」を言語化しようとしていた。設計の原則、運用のベストプラクティス、キャリアの指針。得たものを整理し、アウトプットすることで定着させる。そういう意識があった。でも非技術書の感想を書くとき、私は「何を感じたか」を言語化しようとしていた。正解がない。ベストプラクティスもない。ただ、心が動いた瞬間を、なんとか言葉にしようとしていた。技術書は頭に残る。非技術書は心に残る。そんな単純な話ではないだろうが、少なくとも私にとっては、そういう違いがあった。この違いは、AIとの関係にも繋がる。技術書編で「AIは答えを返してくれる。でも『そうだろうか』とは返してくれない」と書いた。非技術書を読むとき、私はもっと別のものを求めている。AIは感情を揺さぶってくれない。正確に言えば、感情を揺さぶってほしいと頼めば、上手に揺さぶってくる。でも、それは違う。求めに応じて揺さぶられるのと、不意打ちで心を持っていかれるのは、まったく別の体験だ。物語の中で登場人物が選択を迫られるとき、私は一緒に苦しむ。エッセイで著者が過去の失敗を告白するとき、私は自分の失敗を思い出す。哲学書で問いを突きつけられるとき、私は答えられない自分と向き合う。そういう体験は、AIとの対話では得られない。だからこそ、非技術書を読む時間は貴重だ。エンジニアとして働いていると、効率を求めてしまう。最短距離で正解にたどり着きたい。無駄を省きたい。その思考が、読書にまで侵食してくることがある。「この本から何を得られるか」「読む価値があるか」——そんな問いを立てた瞬間、読書は作業になる。非技術書を読むとき、私はその思考を手放そうとしている。効率を求めない時間が、効率を上げる。矛盾しているようだが、実感としてそう思う。今年読んだ非技術書を振り返ると、どれも「役に立った」とは言いにくい。でも、どれも「読んでよかった」とは言える。その違いは何だろう。たぶん、読書は投資ではないのだ。リターンを期待して読むものではない。読むこと自体が目的であり、報酬であり、体験そのものだ。本を読む時間は、消費ではなく、生きることそのものだ。来年も、仕事に役立たない本を読むだろう。キャリアに直結しない本を読むだろう。そして、また12月になったら、この記事を書く。技術書編と非技術書編。どちらが大事かなんて、比べる意味がない。どちらも、私の一部だ。技術書は「何ができるか」を教えてくれる。非技術書は「何者であるか」を問いかけてくれる。どちらも欠かせない。どちらも、読み続ける価値がある。来年もきっと、両方の本棚を行き来しながら、エンジニアとして、人間として、少しずつ変わっていくのだろう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[迷宮インフラを整理してAWSコストを66%削減した話]]></title>
            <link>https://zenn.dev/r4ynode/articles/aws-organize-infra</link>
            <guid isPermaLink="false">https://zenn.dev/r4ynode/articles/aws-organize-infra</guid>
            <pubDate>Sun, 28 Dec 2025 02:00:01 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは、私は普段SREエンジニアをしています。今年の11月から、友人がテックリードを務めるスタートアップで、副業としてお手伝いをさせていただいています。少数精鋭の体制で、スピード感を持って新規開発に取り組んでいるチームです。その中で私は、主にインフラ領域全般を担当しています。!このブログは勤務先に許可を得ています。投稿を許可してくださり感謝の極みです。 勤務開始！困った困った勤務開始後、困ったことがありました。システムに関するまとまったドキュメントがなかったのです。断片的な情報は落ちていますが、システム全体を俯瞰できる資料がないため、現在どのように動いているのか把握でき...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年、AI時代の要件定義について考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/27/140231</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/27/140231</guid>
            <pubDate>Sat, 27 Dec 2025 05:02:31 GMT</pubDate>
            <content:encoded><![CDATA[——「何を作るべきか」を選び、腹を括ることの価値この記事の核心：AIがコードを書く時代になっても、「何を作るべきか」を選び、腹を括り、うまくいかなければ別の手を打つのは人間の仕事だ。なぜなら、痛みのない決断は決断ではなく計算だから。本稿では、要件定義を「合意形成」として捉え直し、2025年のAIエージェント元年に人間が担うべき役割を考える。はじめにAIがコードを書く時代になりました。「ファイル監視ツールを作って」と指示すると、動くコードが出てきます。それだけではありません。2025年現在、AIエージェントはファイルを読み、テストを実行し、エラーを修正し、プルリクエストまで作成できます。便利になった分、私たちの仕事は減るのでしょうか。「作る」作業は確かに減ります。しかし「何を作らせるか」「どこで人間が介入するか」を決める仕事は増えます。AIが「作る」を担うからこそ、「選ぶ」の重みが増すのです。では、どうやって「選ぶ」力を身につければいいのか。生成AIが登場したからといって、明日から全く新しい働き方ができるわけではありません。人間や組織はそう簡単に変われない。それなら、既存の知見を基盤にして、そこにAIをどう組み込むかを考える方が現実的です。私自身の失敗談を話します。数年前、私は1週間かけて「完璧な」検索機能を実装しました。クエリのパフォーマンスは最適化済み。インデックスも完璧。リリース当日、私は誇らしげにデプロイボタンを押しました。1ヶ月後、アクセスログを見て愕然としました。検索機能の利用率は、私を含めて全体の10%以下でした。ユーザーが本当に求めていたのは「探す手間を減らすこと」であり、検索機能ではなかった。仕様通りに作った。でも、本当に必要なものを作れていなかったのです。AIがコード生成を10倍速くしても、要件が間違っていれば、間違ったコードを10倍速く作るだけです。「何を作るべきか」を決める力——これこそが、AI時代に価値を増すものだと私は考えています。この記事では、IPAの『ユーザのための要件定義ガイド 第2版』を参照しながら、要件定義の本質について考えます。古いガイドを持ち出すのは、そこに「人間同士の合意形成」という、AIには代替できない知見が詰まっているからです。「決める」とは何か。それは、不確実性の中で責任を引き受けることです。正解が分からないまま「これでいく」と宣言し、うまくいかなければ自分で軌道修正する。その覚悟を持つこと。AIにはこれができません。だから、痛みのない決断は、決断ではなく計算なのです。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。IPAの「ユーザのための要件定義ガイド」本稿で参照するのは、IPA（独立行政法人 情報処理推進機構）が公開している『ユーザのための要件定義ガイド 第2版』です。無料でダウンロード可能です。www.ipa.go.jpこのガイドには「128の勘どころ」として、要件定義を成功に導くための具体的なノウハウが体系化されています。数十年にわたる失敗と成功の蓄積であり、「人間同士の合意形成」という、AIには代替できない知見が詰まっています。10倍速い失敗を防ぐ防波堤なぜ今、要件定義なのかAIの進化により、エンジニアの仕事は「作る人」から「選ぶ人」へとシフトしています。AIは問いを立て、コードを書き、選択肢を提示できます。しかし、AIは「どれを選ぶか」を最後に決めることはできません。決断とは不確実性と責任を引き受ける行為だからです。そしてAIが「作る」を高速化すればするほど、最初の「選ぶ」の重みは増します。IPAのガイドによれば、システム開発の失敗理由の50%以上が要件定義の問題にあり、その主因は「要求仕様の決定漏れ」や「開発規模の増大」だといいます。AIがこのスピードを10倍にするとどうなるか。要件が間違っていれば、間違ったシステムを10倍の速さで、10倍の量、生成してしまうのです。今や要件定義は単なる設計図ではなく、「作らないものを決めるための防波堤」となりました。「効率化」から「価値創出」へITシステムの役割は、事務効率化から、新たなビジネス価値の創出へと拡大しています。これは要件定義の難易度を根本的に変えます。効率化が目的なら、要件定義は比較的シンプルでした。ユーザーに「何を自動化したいですか」と聞けばよかった。答えは明確で、私の仕事は書記に近かった。しかし今、ユーザーに「AIで何がしたいですか」と聞くと、返ってくる答えは「何かすごいこと」である。要件定義の難易度は、質問への回答の曖昧さに比例して上がる。しかし価値創出が目的なら、まだ存在しない業務の要件を定義しなければなりません。「AIを使って何か新しいことをしたい」と言われても、ユーザー自身が何を求めているか分かりません。過去のデータを分析して「こういう傾向があります」とAIが教えてくれても、それをどうビジネスに活かすかを決めるのは人間や組織です。AIは過去のデータから「これまでの効率化」を計算するのは得意です。しかし、未来の「競争優位性」をどう定義するかという意志は持ち合わせていません。要件定義とはニーズを「意志」へ変換することIPAガイドが示す定義要件定義とは、単なる「やりたいことリスト」の作成ではありません。私は要件定義を「ステークホルダのニーズを、実現可能な形に変換し、合意を取り付けるプロセス」だと捉えています。IPAのガイドも同様の定義をしています。ここで重要なのは「変換」という言葉です。ユーザーは「使いやすくしてほしい」と言います。しかし「使いやすい」とは何でしょうか。レスポンスが速いこと、操作が少ないこと、画面がシンプルなこと。この曖昧な言葉を、「検索結果を1秒以内に表示する」「3クリック以内で目的の画面に到達する」といった具体的な要件に変換します。これが要件定義です。AIは膨大なデータを「計算」して最適な出力を提案できます。しかし「使いやすい」の意味を問い詰め、対立する意見を調整し、合意を取り付けるのは人間固有の作業です。そこには痛みが伴います。「要求」と「要件」の決定的な違い私たちは「要求」と「要件」を混同しがちです。しかし、この2つは決定的に異なります。要求 (Requirement): ステークホルダの心にある「～したい」という生のニーズ要件 (Specification): 要求を文書化・仕様化し、ステークホルダと合意したもの決定的な違いは「合意」の有無です。なぜこれが重要なのか。私の経験から言えば、合意のないシステムは必ず「聞いてない」という言葉で殺されます。ただし、合意があればいいというわけではありません。合意にも濃淡があります。「ハンコを押してもらった」から「腹から納得してもらった」まで。私は合意を3つのレベルで捉えています。表面的な合意: 会議で「いいですね」と言われた。議事録にも残っている。しかし、実際に使う段になって「こういう意味じゃなかった」と言われる。理解の合意: 相手が要件の意味を理解している。しかし、それが自分の業務にどう影響するかは考えていない。コミットメントの合意: 相手が「この要件で自分の仕事が変わる」ことを理解し、その変化を受け入れている。要件定義で目指すべきは3番目です。1番目の合意は「ハンコを押させた」に過ぎません。2番目は「説明した」に過ぎません。3番目だけが「合意した」と言えます。AIは1番目の合意を効率化できます。議事録を自動生成し、確認依頼を送り、承認を得る。しかし、相手の腹の中にある「本当はこうしたい」を引き出し、対立する利害を調整し、「これでいく」と握り合うプロセスを経て「要件」へと昇華させることはできません。この「コミットメントの合意」こそが、責任を引き受ける人間だけの領域です。「今と同じ」という甘えの排除コミットメントの合意とは、変化を受け入れることです。しかし、人は変化を避けたがる。その典型が「今と同じ」という要件定義です。「今と同じ」は要件定義ではありません。AIは「現行踏襲」を最も簡単に計算しますが、それはビジネスの進化を止める要件定義の放棄に他なりません。なぜ人は「今と同じ」を選ぶのか。私の経験では、3つのパターンがあります。責任回避型: 「今と同じ」と言っておけば、何か問題が起きても「前からそうだった」と言い訳できる。新しいことを提案すると、その責任を負わなければならない。思考停止型: 「今と同じ」は考えなくていい。現状を分析し、あるべき姿を構想し、そのギャップを埋める——この知的作業を放棄できる。合意回避型: 新しい要件を定義すると、関係者との合意形成が必要になる。「今と同じ」なら、誰も反対しない（ように見える）。どのパターンも、本質は同じです。痛みを避けている。しかし、痛みを先送りにしても、痛みは消えません。むしろ、システム稼働後に「使えない」という形で、より大きな痛みとなって返ってきます。現状（As-Is）からあるべき姿（To-Be）への差分を定義し、変化に伴う痛みを受け入れることこそが要件定義の本質です。要件定義とは「責任」の契約である発注者の責任という冷徹な事実これは冷徹な事実ですが、要件定義は発注者の責任です。要件定義とは「使える」業務システムを定義することです。動くシステムではなく、使えるシステム。この違いは大きい。私が冒頭で作った検索機能は「動く」システムでした。しかし「使える」システムではなかった。AIがどれだけ「効率的な設計」を提示しても、それが現場の業務を壊したり、利益を生まなかったりしたとき、AIは責任を取れません。要件定義とは、「このシステムでビジネスを勝たせる」とオーナーが腹を括る行為であり、説明責任（Accountability）を伴う意思決定なのです。アプリケーションオーナー制度私が有効だと感じているのは、「アプリケーションオーナー制度」という考え方です。システムをIT部門の「資産」にせず、利益を回収する責任を持つ「ビジネス側」の持ち物とします。なぜこれが重要なのか。オーナーが不在のプロジェクトで何が起きるか、私は何度も見てきました。「誰に聞けばいいか分からない」問題: 要件の詳細を詰めようとすると、「それは〇〇部に聞いて」「いや、うちじゃない」とたらい回しにされる。最終決定権者がいない。「みんなで決めた」問題: 会議で合意したはずの要件が、後から「私は賛成したけど本当は反対だった」と覆される。全員が責任を分散しているので、誰も責任を取らない。「IT部門が決めて」問題: 業務のことを一番知っているはずの現場の人たちが、技術的な判断をIT部門に丸投げする。IT部門は業務を知らないので、動くが使えないシステムができる。オーナー制度は、この3つの症状への処方箋です。オーナーシップ: 「このシステムは自分のもの」という認識を持つ。自分の仕事を具体化するための、自分自身の仕事である。最終責任: 要件の詳細が固まるまで対話を繰り返し、「これでいく」と言う権限と責任を持つ。なぜ「痛みを伴う」のか選択には痛みが伴います。選択: どの課題を解決し、どの要望を切り捨てるか妥協: 予算と納期の制約の中で、何を「諦める」か限られた工期やコストの中で「やらないこと」を決める優先順位付けは、最も苦しい決断です。この痛みを引き受けることこそが、要件定義の本質です。AIがどれだけ効率的にコードを書いても、そのシステムが利益を生まなかったときの「痛み」を肩代わりしてはくれません。WhyからWhatへ繋ぐリザルトチェーン要件の階層構造「Why」を問わずに「What（機能）」をAIに作らせることは、目的地を決めずにアクセルを全開にすることと同じです。私は要件を3つの階層で捉えるようにしています。IPAのガイドでも同様の分類がなされています。 階層           IPAの定義                   問い              内容                                                  Why / Who  利害関係者の要求 (BR)   なぜ、誰のために  利用者が「何を成し遂げたいか」というビジネス目標      What       システム要求 (SR)       何を作るか        目標達成のためにシステムが「どう振る舞うべきか」      How well   ソフトウェア要求 (SRS)  どれだけうまく    プログラムが満たすべき具体的な仕様（機能・性能など） 要件定義とは、この3つのレベルを垂直統合する行為と言えます。冒頭で触れた私の失敗——「検索機能」を作ったが「探す手間を減らす」ことを理解していなかった——は、まさに利害関係者の要求（Why）を無視して、いきなりシステム要求（What）に飛びついた結果でした。なぜ人はWhyを飛ばすのか。私なりに分類すると、3つの理由があります。Whatの方が具体的で安心する: 「検索機能を作る」は明確だ。進捗も測れる。一方「探す手間を減らす」は曖昧だ。何をもって達成とするのか、分かりにくい。人は曖昧さを嫌う。Whyを問うと「分からない」が露呈する: なぜこの機能は必要か。誰のためか。本当に必要か。この問いに答えられない人は多い。答えられないと恥ずかしいので、問わないことにする。Whyは政治的に危険: 「なぜこの機能が必要なのか」を突き詰めると、「実は必要ない」という結論に至ることがある。すると、その機能を要望した人の面子を潰すことになる。面倒を避けるために、Whyを問わない。いずれも、本質は同じです。Whyを問うことは、不確実性と向き合うことです。不確実性は不快です。だから避ける。しかし、避けた不確実性は消えません。プロジェクトの最後に「これじゃない」という形で顕在化します。リザルトチェーンで因果関係を証明する私が有効だと感じているのは「リザルトチェーン」という考え方です。獲得したい「最終ビジネス成果（Why）」と、それを実現するための「具体的機能（What）」を鎖のようにつなぎ、因果関係を証明します。IT施策: 具体的機能（AIが生成するもの）中間成果: その機能が業務に与える好影響最終ビジネス成果: 売上向上、コスト削減などの経営目標このチェーンを設計し、その妥当性に判をつくことこそが要件定義の核心です。AIが生成した機能リストの先に、どのようなビジネス上の「果実」があるのかを論理的に証明するのは、人間に残された高度な知能活動です。開発コストの大半は「手戻り」に消えているソフトウェア要求工学の古典『Software Requirements 3』によれば、開発における手戻りはコスト全体の30〜50%を消費します。そのうち70〜85%が要件の間違いに起因するといいます（Karl Wiegers & Joy Beatty, 2013）。つまり、開発チームが残業している夜の大半は、「最初に何を作るか間違えた」ことへの贖罪なのです。AIはこの贖罪の時間を短くしてくれません。間違いをより速く積み上げるだけです。AIにできること、できないこと2025年のAIは、多くのことができます。まずその能力を正確に把握しておくことが重要です。過小評価すれば使いこなせず、過大評価すれば失敗します。AIは問いを立てることもできるAIは問いを立てられます。「このプロジェクトで考慮すべき観点は何か」と聞けば、AIは網羅的なリストを返してくれます。ユーザー体験、セキュリティ、スケーラビリティ、コスト、保守性——私が思いつかなかった観点まで提示してくれることもあります。問いを立てる能力において、AIはすでに人間を補完できるレベルに達しています。要件定義の各フェーズでAIを活用するでは、具体的にどう活用するか。私が実践している方法を紹介します。フェーズ1：要求の洗い出しステークホルダへのヒアリング前に、AIに「このプロジェクトで聞くべき質問リスト」を生成させます。「ECサイトのリニューアルプロジェクトで、業務部門に確認すべき観点を20個挙げて」と指示すると、私が見落としていた観点が出てくることがあります。ヒアリング後には、議事録をAIに読ませ、「この議事録から抽出できる要求を一覧化して」と指示します。人間が手作業で整理するより速く、抜け漏れも減ります。フェーズ2：要件の具体化曖昧な要求を具体的な要件に変換する作業でも、AIは役立ちます。「『使いやすいシステム』という要求を、測定可能な要件に分解して」と指示すると、「レスポンス時間」「操作ステップ数」「エラー率」といった具体的な指標に落とし込んでくれます。しかし、ここで出てきた指標が「このプロジェクトにとって適切か」を判断するのは人間です。AIが提案した「レスポンス時間1秒以内」が、本当にこのシステムに必要かどうか。それはビジネスの文脈を理解している人間が決めます。フェーズ3：影響分析「この要件を実装した場合、既存システムにどんな影響があるか」という分析も、AIに補助させられます。システム構成図やデータフロー図をAIに読ませ、「この変更による影響範囲を洗い出して」と指示する。網羅性の担保にAIを使い、最終的な判断は人間が行います。フェーズ4：ドキュメント生成要件定義書のドラフト作成は、AIが得意な領域です。「以下の要件リストを、IPAのガイドラインに沿った形式でドキュメント化して」と指示すれば、体裁の整った文書が出てきます。人間は、その内容の正確性と、ステークホルダに伝わる表現かどうかをレビューします。しかしAIは「選べない」問題は、その先です。AIは10個の選択肢を提示できます。それぞれのメリット・デメリットを分析できます。トレードオフを可視化できます。しかし、「どれを選ぶか」を決めることはできません。「パフォーマンスを優先すべきか、開発速度を優先すべきか」——AIはこの問いに対して、両方の観点から分析を提供してくれます。しかし「我々はパフォーマンスを選ぶ」と宣言できません。なぜか。AIは責任を引き受けられないからです。「何でも作れる時代」に、なぜ私たちは作れないのか。その問いと向き合った記事を書いています。syu-m-5151.hatenablog.com腹を括るとは何かでは、「責任を引き受ける」とは具体的にどういうことでしょうか。私はこれを「腹を括る」という言葉で捉えています。「腹を括る」とは、不完全な情報の中で、それでも決断を下すことです。すべての情報が揃うことはありません。すべてのリスクを排除できません。それでも、「我々はこれでいく」と決める。その決断には、必ず「もし間違っていたら」という不安がつきまといます。AIにはこの不安がありません。午前3時に目が覚めて「あの選択は本当に正しかったのか」と天井を見つめることもない。胃が痛くなることもない。だから、決断できません。決断とは、胃を痛めることの引き受けなのかもしれません。AIは確率を計算できます（厳密には「計算」ではなくパターン認識ですが、ここでは便宜上こう呼びます）。リスクを列挙できます。しかし、「このリスクを取る」と決断できません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。「腹を括った」と言える条件では、腹を括ったと言える判断には、どんな条件が必要でしょうか。私なりに整理してみます。第一に、代替案を知っていること。「これしかない」と思い込んでいる状態は、腹を括ったとは言えません。A案、B案、C案があり、それぞれのリスクとリターンを理解した上で「A案でいく」と決める。選択肢を知らずに選んだものは、選択ではありません。第二に、失敗したときのシナリオを想定していること。「これでうまくいく」と楽観しているだけでは、腹を括ったとは言えません。「もし失敗したら、こうなる」「そのとき、こう対応する」という覚悟があるかどうか。最悪のケースを直視した上で、それでも進む決断が「腹を括る」です。第三に、自分の名前で決めること。「みんなで決めた」「上が言ったから」という言い方ができる決断は、腹を括っていません。「私が決めた。責任は私にある」と言えるかどうか。決定権者が明確であること。エンジニアとしてプロジェクトに参加するとき、私は自分に問いかけます。「この技術選定は、自分の名前で決めたか」「このアーキテクチャは、自分の名前で提案したか」。アーキテクトは技術的な意思決定者です。「チームで検討した結果」という言い方をしがちですが、最後に「私がこの設計を推奨する」と言えるかどうか。それが腹を括るということです。うまくいかないときに次の手を打つAIが生成したコードにバグがあったとき、どうするか。エンジニアなら答えは明確です。原因を調べて、修正して、再デプロイする。うまくいかなければ別のアプローチを試す。それでもダメなら、いったん切り戻して仕切り直す。この「次の手を打つ」判断は、今のところ人間がやるしかありません。選択の本質は、うまくいかなかったときに次の手を打つことにあります。AIが選択しても、その後の軌道修正——関係者との再調整、代替案の実行、撤退の判断——をするのは、今のところ人間しかいません。合意形成と対立する「正しさ」の調整なぜ合意が難しいのか合意形成が難しいのは、なぜでしょうか。単純に「意見が違う」だけではありません。もっと根深い問題があります。それは、関係者がそれぞれ異なるナラティブ（物語）——世界を解釈するための枠組み——を生きていることです。経営者は「コスト削減こそ正義」という物語を生きている。エンジニアは「技術的負債は悪」という物語を生きている。現場は「今の仕事を楽にしたい」という物語を生きている。三者が同じ会議室に座っているが、実は三つの異なる言語を話しています。どれも正しい。どれも間違っていません。だが、同時に全てを満たすことはできません。問題は、人は自分のナラティブの外に出られないことです。経営者から見れば、エンジニアは「コストを無視した理想論者」に見えます。エンジニアから見れば、経営者は「技術負債を無視した短期思考」に見えます。お互いが、相手を「間違っている」と感じている。しかし実際には、どちらも間違っていません。違う物語を生きているだけです。これを認めることが、合意形成の第一歩になります。では、どうすれば認められるのか。私の経験では、「こう言えばうまくいく」という魔法の言葉はありません。テクニックの問題ではないのです。大切なのは、相手の物語を理解しようとする姿勢で議論を続けること。その姿勢を持ち続けることでしか、ナラティブの壁は越えられません。私自身、エンジニアとしてこれを学びました。技術的に正しいことと、プロジェクトにとって正しいことは、同じではありません。たとえば「マイクロサービス化すべきだ」という技術的に正しい主張が、今のチームのスキルや予算を考えると現実的ではないことがあります。相手の立場——チームの現状、予算の制約、経営の優先順位——を理解しようとして初めて、現実的な落とし所が見えてきます。アーキテクトの仕事は、技術的な正しさを追求することではなく、プロジェクトの文脈の中で最適解を見つけることです。主観を可視化するナラティブの衝突を解消するには、まず「見える化」が必要です。言葉で議論していると、同じ言葉に違う意味を込めていることに気づきません。私がよく使うのは、ホワイトボードに関係者の立場と関心事を図示する方法です。IPAのガイドでは「リッチピクチャ」と呼んでいます。言葉では表現しづらい関係性を一枚の絵で表現し、「あなたはこう見えているんですね」と確認する。これだけで誤解が減ります。合意形成を加速させるテクニック私の経験で有効だったテクニックをいくつか挙げます。IPAのガイドでも同様の手法が推奨されています。当事者意識（オーナーシップ）の醸成単なるヒアリングではなく、ワークショップなどを通じて関係者が議論し、相互理解を深めるプロセスを持ちます。自分たちが決めたという意識がなければ、稼働後の不満につながります。相手の視点に合わせた資料の準備成果物をそのまま見せるのではなく、説明相手の関心事に合わせた資料を用意します。経営層向け: 「ビフォーアフター図（B/A図）」を用い、何が変わって何が良くなるのか、投資対効果を端的に伝える現場のリーダー向け: 新しい業務プロセスがどうなるか、業務フローを用いて具体的な変化を説明する「声の大きい人」のコントロール特定の意見に流されないよう、客観的な評価指標（優先順位の基準）を盾にし、ファシリテーターが議論を統制します。エスカレーションパスの確立現場で合意できない対立については、上位層による意思決定機関（ステアリングコミッティ）へ迅速にエスカレーションし、プロジェクトを停滞させない仕組みを事前に作っておきます。合意形成でAIを活用する合意形成という人間臭い作業でも、AIは補助的な役割を果たせます。相手の立場を理解するための困難打ち。会議の前に、AIに「経営者の視点から、このシステム投資をどう評価するか」と聞いてみます。自分とは違うナラティブを疑似体験できます。「この提案を受けた営業部長は、どんな懸念を持つか」とAIに聞くことで、想定問答を準備できます。議論の整理と論点の抽出。会議が紛糾したとき、議事録をAIに読ませて「この議論の論点を整理して」と指示すると、感情的になっている参加者には見えなくなった構造が見えてきます。「経営層はコストを重視、現場は使いやすさを重視、エンジニアは保守性を重視」という対立構造を可視化できます。説明資料の自動生成。相手に合わせた資料の準備にも、AIは使えます。「この技術仕様を、経営層向けにROIの観点で説明する資料に変換して」と指示すれば、一次ドラフトが生成されます。ゼロから書くより効率的です。合意の言語化。合意に至ったとき、その内容を正確に文書化することにもAIは役立ちます。「この会議で合意された内容を、後から『言った言わない』にならないように文書化して」と指示すれば、曖昧さを排除した合意文書のドラフトが得られます。しかし、AIが補助できるのは合意形成の準備と記録です。相手の感情を読み取り、対立を調整し、「これでいきましょう」と握り合うプロセス自体は、人間同士の対話でしかできません。AIは通訳であり、ファシリテーターではありません。対話の本質と、対話を阻む構造的な問題については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com優先順位付けという最もクリエイティブな「棄却」「全部やる」の誘惑「全部やる」と言った瞬間、会議室は平和になります。誰も傷つかない。誰も責められない。しかし3ヶ月後、プロジェクトは炎上する。「全部やる」は、将来の自分への借金です。利子は複利で増えます。問題は個人の心理だけではありません。組織の構造が、選択を妨げていることがあります。まず、インセンティブの問題があります。営業部長は営業の数字で評価される。開発部長は開発の成果で評価される。全社最適より部門最適が優先される構造になっています。次に、権限の曖昧さがあります。誰が「やらない」と決める権限を持っているのか。多くの組織で、これが不明確です。だから、誰も決めない。決めなければ、責任を問われません。「全部やる」は、個人の弱さであると同時に、構造の帰結でもあります。客観的な6つの判断基準AIはあらゆる可能性を提示しますが、リソース（工期・コスト・人）は有限です。何かを選ぶことは、何かを諦めること。この優先順位付けこそが、最もクリエイティブで苦しい決断の場です。優先順位を「なんとなく」で決めると、声の大きい人の意見が通ってしまいます。私は以下の6つの指標で多角的に評価するようにしています。IPAのガイドでも同様の基準が示されています。有効性: 目的や目標にどれだけ貢献するか（達成効果）必要性: 法制度対応、内部統制、社会的責任などの観点で不可欠か緊急性: 期限が明確で、急を要するか費用: 実現や運用にどれだけのコストがかかるか実現性: 技術的・人的に本当に実現可能か新たな問題: その要求を実現することで、別の問題が発生しないかMoSCoW分析という「捨てる」ための枠組みすべてを「必須」とせず、MoSCoW分析を用いて、勇気を持って「要求を捨てる」ことが必要です。M (Must): これがないと目的を達成できない必須の要求S (Should): 必須ではないが、重要な推奨要求C (Could): あれば良いレベルの要求W (Won't): 今回は見送る、または不要な要求柔軟で変化に強いシステムを作るには、要求を抑え込み、シンプルでスリムな状態を維持する「捨てる勇気」が必要です。AIが「What（何を作るか）」の選択肢を無限に生成するからこそ、人間はこの枠組みを駆使して価値あるものだけを選ぶ必要があります。優先順位付けでAIを活用するここでもAIは強力な補助ツールになります。比較分析の自動化。100個の要求がリストアップされたとき、それぞれを6つの指標で評価するのは膨大な作業です。AIに「この要求リストを、有効性・必要性・緊急性・費用・実現性・新たな問題の6軸で評価して」と指示すれば、一次評価を自動化できます。トレードオフの可視化。「要求Aを優先すると、要求Bにどんな影響があるか」という依存関係の分析も、AIに補助させられます。複雑に絡み合った要求間の関係を整理し、「これを選ぶと、あれが犠牲になる」という構造を可視化できます。過去事例の参照。類似プロジェクトでどんな優先順位付けがなされたか。過去の要件定義書をAIへ渡し、傾向を分析させることもできます。「過去5年間のプロジェクトで、結局Won't判定となった要求の特徴は何か」といった分析が可能です。しかし、最終的な優先順位を決めるのは人間です。AIは「この要求は有効性が高い」と分析できます。だが「有効性が高いから採用する」とは決断できません。有効性が高くても、今のチームには実現できない。費用が低くても、ビジネス的な価値がない。こうした判断は、プロジェクトの文脈を理解している人間にしかできません。「何をやらないか」を決めることの本質と、戦略的思考については、以下の記事でより詳しく論じています。syu-m-5151.hatenablog.com検証と妥当性確認という「正しさ」を問う2つの視点要件を選び、優先順位を付けた。では、その選択は正しかったのか。要件定義には、選んだ後に「正しさ」を確認する作業があります。ここで重要なのは、「正しさ」には2つの意味があるということです。Verification と ValidationAI時代のエンジニアの価値は、計算機的な「検証（Verification）」から、人間的な「妥当性確認（Validation）」へと移っています。検証 (Verification): 記述された要件が、要求を抜け漏れなく満たしているかという「計算的」チェック。これはAIでも補助可能である。妥当性確認 (Validation): その要求自体が、本当にビジネス目的を達成できるものかという「意志」の確認。後者は「納得」という感情の着地点を見つける泥臭い人間活動（合意形成）であり、これが欠けた要件定義は、2025年においても失敗を運命づけられています。AIは「正しく作る」ことを補助できます。しかし「正しいものを作っているか」を問い続けるのは人間の仕事です。検証フェーズでAIを活用するVerification（検証）は、AIが最も力を発揮できる領域です。要件の整合性チェック。「この要件定義書の中で、矛盾している記述はないか」とAIに分析させます。「画面Aでは『即時反映』と書いてあるが、画面Bでは『バッチ処理』と書いてある。これは矛盾ではないか」といった指摘が得られます。人間の目では見落としがちな不整合を、AIは網羅的にチェックできます。抜け漏れの検出。「この要件定義書で、考慮されていない観点はないか」とAIに問いかけます。「エラー時の挙動が定義されていない」「権限管理について記述がない」といった抜け漏れを指摘してくれます。テストケースの自動生成。「この要件から、テストケースを生成して」と指示すれば、要件を満たしているかどうかを確認するためのテストシナリオが自動生成されます。一方で、Validation（妥当性確認）は人間の仕事です。「この要件が本当にビジネス目的を達成できるか」は、ビジネスの文脈を理解している人間にしか判断できません。AIは「要件が論理的に整合している」ことは確認できますが、「この要件でユーザーが幸せになるか」は判断できません。非機能要求と経営リスクを引き受ける覚悟性能、セキュリティ、可用性といった「非機能要求」は、もはやエンジニアのこだわりではなく、経営そのものです。IPAの「非機能要求グレード」を活用し、可用性、セキュリティ、運用・保守性などの各項目について、ビジネスの特性に合わせた「レベル」を決定します。可用性: 「24時間365日止まらない」という要求には膨大なコストがかかるセキュリティ: 利便性を損なう可能性があっても守るべき情報の範囲を合意するAIは「コストとリスクのバランス表」を出すことはできます。しかし、万が一の事態に「私が責任を取る」と宣言し、トレードオフに決着をつけることはできません。システムの事情を人間に寄せるここまで、要件定義の「決める」「合意する」「選ぶ」という側面について書いてきました。ここからは、もう1つの重要な側面——伝える——について書きます。エンジニアの本当の仕事私は長い間、エンジニアの仕事は「技術的に優れたシステムを作ること」だと思っていました。パフォーマンスを最適化し、スケーラブルに設計し、セキュリティを担保する。それが専門家としての価値だと。しかし今は違う考えを持っています。エンジニアの本当の仕事は、システムの事情を人間に寄せることです。システムには事情があります。データベースには制約がある。ネットワークには遅延がある。メモリには限界がある。これらの「システムの都合」をそのままユーザーに押し付けると、使いにくいシステムができあがります。「処理中はお待ちください」という画面を見せるのは簡単です。しかし、バックグラウンドで処理を行い、完了したら通知するという設計にすれば、ユーザーは待たなくていい。もう少し例を挙げます。「入力エラーです」→「電話番号は090-1234-5678の形式で入力してください」「データがありません」→「〇〇で検索してみてください」または「似たデータはこちら」「権限がありません」→「管理者の〇〇さんに申請してください」（申請リンク付き）パターンは同じです。エラーの原因を伝えるのではなく、次のアクションを伝える。これが「システムの事情を人間に寄せる」ということです。AIがこの橋渡しを加速するここに生成AIが加わることで、「システムの事情を人間に寄せる」作業は劇的に変わります。エラーメッセージの設計を例に考えます。従来、エンジニアは「このエラーが出たら、どう説明するか」を一つひとつ考えていました。しかし今は、「このエラーコードのリストを、エンドユーザー向けの説明文へ変換して」とAIに指示できます。数百のエラーメッセージを、一貫したトーンで、人間に寄せた表現へ変換できるのです。ドキュメント生成も同様です。APIの仕様書をAIへ渡し、「エンジニアではない人が読んでも分かる説明を書いて」と指示する。技術的な正確さを保ちつつ、ビジネス側に伝わる表現へ変換できます。アーキテクトとしての視点から言えば、AIは「翻訳作業の自動化」を可能にします。システムの事情を人間に寄せる作業は、これまで経験と勘に頼っていました。しかし今は、AIにパターンを学習させ、大量の翻訳を一貫した品質で行えます。しかし、注意が必要です。AIが生成した「人間に寄せた表現」が、本当にユーザーに伝わるかは別問題です。AIは「分かりやすそうな文章」を生成できますが、ユーザーが実際に理解するかは検証しなければ分かりません。エンジニアの仕事は、AIが生成した翻訳を検証し、改善のサイクルを回すことに移行します。要件定義はその橋渡し要件定義は、ビジネスの世界とシステムの世界を橋渡しする行為です——と言うのは簡単です。問題は、同じ言葉でも意味が違うことにあります。例えば「リアルタイム」という言葉。エンジニアが「リアルタイム」と聞くと、脳内では即座にWebSocketの設計が始まる。ポーリング間隔は100ミリ秒か、いや50ミリ秒か。一方、ビジネス側の「リアルタイム」とは何か。聞いてみると「1分以内」だったりする。エンジニアは100ミリ秒の世界で戦っていたが、相手は60秒の世界にいた。600倍のズレです。この認識の溝を埋めないまま開発を進めると、3ヶ月後に「なんでこんなに重いんですか」と言われる。過剰品質もまた罪なのです。橋渡しとは、この言葉の翻訳作業のことです。「リアルタイムとは、具体的にどのくらいの頻度で更新されればいいですか」と聞く。「1時間に1回で十分」と返ってくるでしょう。その瞬間、要件の解像度が上がります。「技術的にはできません」で終わらせるのは簡単です。しかし、「技術的には難しいですが、こういう代替案ならできます」と提案できるかどうか。それがプロフェッショナルとアマチュアの違いです。「要件定義」という言葉のズレ業界・組織によって指す行為が違うここで立ち止まりたいです。あなたの職場での「要件定義」と、私が語っている「要件定義」は、同じものでしょうか。正直に告白すると、この言葉ほど組織や文脈によって意味が異なるものはありません。SIerでは、要件定義は「顧客の要望を文書化すること」を指すことが多いです。RFP（提案依頼書）を受け取り、要件定義書を作成し、顧客の承認を得る。事業会社では、要件定義は「何を作るかを決めること」を指すことが多いです。文書化より意思決定が重視されます。スタートアップでは、要件定義という言葉自体はあまり使われません。「仮説を立てて検証する」「ユーザーの声を聞いて方向転換する」——こうした活動は要件定義に相当しますが、そう呼ばれることは少ないです。ズレを防ぐために1つのアプローチは、最初に「要件定義」の意味を擦り合わせることです。プロジェクトの冒頭で、「このプロジェクトにおいて要件定義とは何を指すか」を明示的に合意する。面倒ですが、後のズレを防げます。私がこの記事で「要件定義とは合意形成であり、責任の引き受けである」と定義したのも、そうした擦り合わせの試みです。生成AI時代にエンジニアはどう向き合うか生成AIの登場によって、「要件定義」という言葉のズレはより複雑になります。「AIに要件定義させる」という幻想。クライアントから「AIに要件定義させればいいのでは」と言われることが増えました。しかし、ここには根本的な誤解があります。AIは「要件をドキュメント化すること」はできます。だが「要件を決めること」はできません。なぜなら、要件を決めるとは責任を引き受けることだからです。エンジニアとして、私はこの問いにこう答えます。「AIは要件定義の作業を効率化します。しかし要件定義の本質——選択と責任——は人間のままです」と。アーキテクトの新しい役割。生成AI時代のアーキテクトには、新しい役割が生まれています。それは「AIとの協働プロセスを設計する」ことです。どの作業をAIに任せ、どの判断を人間が行うか。この分界点を設計することが、アーキテクトの仕事に加わりました。例えば、以下のような判断が必要になります。AIに任せるべきこと: 要件の文書化、過去事例の調査、影響範囲の分析、選択肢の列挙人間が判断すべきこと: 対立する要件の優先順位付け、ステークホルダとの合意形成、「これでいく」という最終決定組織によって「AI活用」の意味も違う。SIerでは「AIで提案書の品質を上げる」だろう。事業会社では「AIでプロトタイプを高速に作り、検証する」だろう。スタートアップでは「AIで仮説検証のサイクルを速める」だろう。要件定義という言葉のズレと同様に、「AIを活用する」という言葉もズレます。だからこそ、プロジェクトの冒頭で「このプロジェクトにおいてAIをどう使うか」も明示的に合意すべきです。腹を括って成功した経験ここまで抽象的な話が続いたので、具体的な経験を1つ書きます。冒頭で「検索機能を作ったが使われなかった」失敗を書きました。今度は、逆のケースです。あるプロジェクトで、私たちは「検索機能を作らない」という判断をしました。クライアントは検索機能を強く要望していました。競合製品にはすべて検索機能がある。チーム内にも「作るべきだ」という声がありました。しかし私は、ユーザーインタビューの結果を見て、違う結論に達しました。ユーザーが本当に困っていたのは「探す」ことではなく、「何を探せばいいか分からない」ことでした。検索機能を作っても、検索ワードが浮かばないユーザーには役に立ちません。私は「検索機能は作らない。代わりに、よく使う項目を自動で上位に表示する仕組みを作る」と提案しました。クライアントとチームから、大きな反対はありませんでした。「もし改善しなかったら、そのときに検索機能を作りましょう」という落とし所で合意しました。結果は成功でした。リリース後、ユーザーからの問い合わせが激減しました。「欲しい情報がすぐ見つかる」という評価を得ました。振り返ると、この判断には先ほど挙げた3つの条件がすべて揃っていました。代替案（検索機能を作る）を知っていた。失敗したときのシナリオ（クライアントからのクレーム、追加開発のコスト）を想定していた。そして、自分の名前で決めた。腹を括れば、成功と失敗の両方から学べます。腹を括らなければ、どちらの結果からも何も得られません。おわりにこの記事では、AI時代の要件定義について考えてきました。2025年現在、AIの能力は驚くほど高くなりました。コードを書くだけでなく、要件の分析・矛盾の指摘・テストケース生成・ドキュメント作成まで行えます。AIエージェントは自律的にタスクを実行し、エラーがあれば自分で修正します。それでも、要件定義の本質は変わりません。ステークホルダのニーズを実現可能な形に変換し、合意を取り付けるプロセス。対立するナラティブを調整し、「これでいく」と腹を括る行為。うまくいかなければ次の手を打つ覚悟。これは、人間同士の営みであり続けます。変わるのは、道具です。AIは問いを立てられます。選択肢を提示できます。分析もできます。リスクを列挙できます。これらを使いこなせば、要件定義の質は上がります。しかし、最後に「これでいく」と決めるのは人間です。責任を引き受けるのも人間です。「AIに最適化された要件定義」を一から発明する必要はありません。IPAのガイドに体系化された「128の勘どころ」は、数十年にわたる失敗と成功の蓄積です。この基盤の上に、AIという新しい道具を載せていく。それが現実的なアプローチだと私は考えています。冒頭で触れた「仕様通りに作ったが使われなかった」システム。あのとき私に足りなかったのは、技術力ではありませんでした。「なぜこれを作るのか」を問う力。「これでいく」と決める覚悟。うまくいかなければ別の手を打つ姿勢。そういうものでした。痛みのない決断は、決断ではなく計算です。AIは計算が得意です。しかし、決断はできません。決断とは、不確実性を引き受けることであり、責任を引き受けることだからです。エンジニアとして、アーキテクトとして、私たちはこの時代にどう立ち向かうべきでしょうか。私の答えはシンプルです。AIを使いこなしながら、決断する力を磨く。AIに任せられる作業は任せる。しかし、最後に「これでいく」と決めるのは自分です。技術選定、アーキテクチャ設計、トレードオフの判断——これらの決断を、自分の名前で行う。うまくいかなければ、次の手を打つ。この姿勢は、AIが進化しても変わりません。この10年間、私はコードを書くことに時間を使ってきました。そのうちどれだけが「贖罪」だったかは、あまり考えたくありません。これからの10年は、「何を作るべきか」を選ぶことに時間を使いたい。選んで、合意を取り付けて、責任を引き受けて、うまくいかなければ次の手を打つ。その繰り返しに時間を使いたいと思っています。参考資料IPAガイド本稿で参照したIPAの「ユーザのための要件定義ガイド 第2版」は、以下から無料でダウンロードできます。「128の勘どころ」として、要件定義の成功に導くための具体的なノウハウが体系化されています。www.ipa.go.jp参考ブログ要件定義を始める前に、以下の記事を読むことを強くおすすめします。本稿で述べた「要件定義とは合意形成である」という主張の基盤となる考え方を、実践的な視点から解説しています。agnozingdays.hatenablog.comagnozingdays.hatenablog.com参考書籍はじめよう！ 要件定義 ～ビギナーからベテランまで作者:羽生章洋技術評論社Amazonはじめよう！プロセス設計 ～要件定義のその前に作者:羽生 章洋技術評論社Amazonはじめよう! システム設計 ～要件定義のその後に作者:羽生 章洋技術評論社Amazonだまし絵を描かないための－－要件定義のセオリー作者:赤俊哉リックテレコムAmazon要件最適アーキテクチャ戦略 (Object oriented selection)翔泳社Amazon社内政治の科学　経営学の研究成果 (日本経済新聞出版)作者:木村琢磨日経BPAmazon社内政治の教科書作者:高城 幸司ダイヤモンド社Amazonソフトウェアアーキテクトのための意思決定術　リーダーシップ／技術／プロダクトマネジメントの活用作者:Srinath Perera,島田 浩二インプレスAmazonSoftware Requirements Essentials: Core Practices for Successful Business Analysis (English Edition)作者:Wiegers, Karl,Hokanson, CandaseAddison-Wesley ProfessionalAmazon正しいものを正しくつくる　プロダクトをつくるとはどういうことなのか、あるいはアジャイルのその先について作者:市谷 聡啓ビー・エヌ・エヌ新社Amazon作る、試す、正す。　アジャイルなモノづくりのための全体戦略作者:市谷 聡啓ビー・エヌ・エヌAmazonソフトウェアアーキテクチャの基礎 ―エンジニアリングに基づく体系的アプローチ作者:Mark Richards,Neal Ford,島田浩二オライリージャパンAmazonアーキテクトの教科書 価値を生むソフトウェアのアーキテクチャ構築作者:米久保 剛翔泳社Amazonソフトウェアアーキテクチャメトリクス ―アーキテクチャ品質を改善する10のアドバイス作者:Christian Ciceri,Dave Farley,Neal Ford,Andrew Harmel-Law,Michael Keeling,Carola Lilienthal,João Rosa,Alexander von Zitzewitz,Rene Weiss,Eoin Woodsオーム社Amazon【Amazon.co.jp 限定】失敗の科学 (特典: マシューサイド×竹下隆一郎 対談PDF データ配信)作者:マシュー・サイドディスカヴァー・トゥエンティワンAmazon新 失敗学 正解をつくる技術作者:畑村 洋太郎AudibleAmazonソフトウェア要求　第3版作者:カール ウィーガーズ；ジョイ ビーティ日経BPAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ Rustにしたのに遅い？─ N+1クエリ問題の発見と解決]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/26/171102</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/26/171102</guid>
            <pubDate>Fri, 26 Dec 2025 08:11:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめにRustは速い。だが、Rustで書けば速くなるわけではない。ある日、APIのレスポンスが突然5秒を超えた。コードを見直してもバグはない。SQLも正しく書けている。途方に暮れながらログを確認すると、1リクエストで300回以上もクエリが発行されていた。原因は、ループ内で著者情報を1件ずつ取得していたこと。これがN+1クエリ問題だ。見えないものは、直せない。本記事では、この見落とされがちなN+1クエリ問題の本質と、RustとPostgreSQLを使った5つの解決策を解説する。正直に言うと、どの解決策がベストかは状況による。だからこそ、複数のアプローチを知っておく価値があると私は考えている。N+1クエリ問題とは問題のあるコード本記事では、RustのSQLクライアントライブラリ「sqlx」を使用します。sqlxは型安全なクエリとasync/awaitをネイティブにサポートするライブラリです。// アンチパターン: N+1クエリasync fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    // 1回目のクエリ: 投稿一覧を取得    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    let mut result = Vec::with_capacity(posts.len());    for post in posts {        // N回のクエリ: 各投稿の著者を個別に取得        let author = sqlx::query_as!(            User,            "SELECT * FROM users WHERE user_id = $1",            post.user_id        )        .fetch_one(pool)        .await?;        result.push(PostWithAuthor { post, author });    }    Ok(result)}// 100件の投稿を取得するのに 101回のクエリが発生このコードは一見正しく見えますが、100件の投稿を取得するのに101回のクエリを発行しています。これが「N+1クエリ問題」の典型例です。「N+1」という名前は、N件のデータに対して1回（一覧取得）+ N回（個別取得）= N+1回のクエリが発生することに由来します。ここで疑問が浮かぶ。なぜこのパターンを書いてしまうのか。私の経験では、ループ内でfetch_oneを呼ぶコードは「書きやすい」からだ。1件取得する関数がすでにあれば、それをループで回すのは自然な発想に思える。問題は、この「自然さ」がパフォーマンスの問題になることだ。便利すぎるAPIは、時として危険なパターンを誘発する。では、具体的にどれくらい遅くなるのか。数字で見てみよう。なぜ遅いのかN+1クエリが遅い理由を定量的に理解しましょう。1クエリあたりのオーバーヘッド内訳:- RustからPostgreSQLライブラリへの呼び出し：0.01ms- プロトコル処理：0.02ms- ネットワーク往復（ローカル）：0.1-0.5ms- PostgreSQLクエリパース：0.05ms- 実行計画生成：0.1-1ms- 実行（インデックス使用時）：0.1-0.5ms- 結果のシリアライズ：0.02ms合計：約0.5-2ms/クエリ計算例100件のN+1クエリ:- 最良ケース: 101 × 0.5ms = 50ms- 最悪ケース: 101 × 2ms = 200msJOINで1クエリ:- 約1-5ms差: 10-100倍ネットワークレイテンシが大きい環境（クラウド、リモートDB）では、この差はより広がります。ここまでの計算で、N+1の影響の大きさは理解できた。では、この問題の根本にあるものは何だろうか。N+1問題の本質1回で済むことを、何度もやっていないか。N+1問題の本質は「ループ内のI/O」だと私は考えている。これは単なるSQLの問題ではなく、プログラミング一般に潜む構造的な課題だ。// 問題のパターンfor item in collection {    // 各アイテムごとにI/O（DB、ファイル、HTTP）    let related = fetch_related(item.id).await?;}この問題は以下のような場面で発生します。1対多の関連データ取得: 投稿とコメント、ユーザーと注文多対多の関連データ取得: 投稿とタグ、ユーザーとロールネストしたデータ構造: カテゴリ → 投稿 → コメント → ユーザー問題の構造がわかったところで、解決策を見ていこう。RustとPostgreSQLの組み合わせでは、5つのアプローチがある。シンプルなものから順に紹介する。解決策1: JOINで一括取得最もシンプルな解決策は、JOINを使って1回のクエリで全てのデータを取得することです。1対1の関連#[derive(Debug, sqlx::FromRow)]struct PostWithAuthor {    // 投稿の情報    post_id: Uuid,    title: String,    content: String,    post_created_at: DateTime<Utc>,    // 著者の情報    author_id: Uuid,    author_name: String,    author_email: String,}async fn get_posts_with_authors(pool: &PgPool) -> Result<Vec<PostWithAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithAuthor,        r#"        SELECT            p.post_id,            p.title,            p.content,            p.created_at as post_created_at,            u.user_id as author_id,            u.name as author_name,            u.email as author_email        FROM posts p        INNER JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}JOINの種類と使い分け実務でよく使うのはINNER JOINとLEFT JOINの2つです。INNER JOINは両方のテーブルに存在する行のみを返し、関連データが必須の場合に使います。LEFT JOINは左テーブルの全行を返し、右テーブルは一致する行のみを返すため、関連データがオプションの場合に適しています。RIGHT JOINやFULL JOINは実務でほぼ使いません。// LEFT JOIN: 著者がいない投稿も含めるasync fn get_posts_with_optional_authors(pool: &PgPool) -> Result<Vec<PostWithOptionalAuthor>, sqlx::Error> {    sqlx::query_as!(        PostWithOptionalAuthor,        r#"        SELECT            p.post_id,            p.title,            u.user_id as "author_id?",            u.name as "author_name?"        FROM posts p        LEFT JOIN users u ON p.user_id = u.user_id        ORDER BY p.created_at DESC        "#    )    .fetch_all(pool)    .await}JOINは1対1の関連には最適だ。しかし、1対多の関連を取得しようとすると、行が膨張してしまう。投稿1件に対してタグが5つあれば、同じ投稿が5行に複製される。この問題を避けるには、別のアプローチが必要になる。解決策2: IN句 + HashMap1対多の関連を効率的に取得する場合、IN句とHashMapを組み合わせる方法が有効です。use std::collections::HashMap;async fn get_posts_with_tags(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    // 1. 投稿を取得    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    let post_ids: Vec<Uuid> = posts.iter().map(|p| p.post_id).collect();    // 2. タグを一括取得（ANY配列演算子を使用）    let tags: Vec<PostTagRow> = sqlx::query_as!(        PostTagRow,        r#"        SELECT pt.post_id, t.tag_id, t.name        FROM post_tags pt        JOIN tags t USING (tag_id)        WHERE pt.post_id = ANY($1)        "#,        &post_ids    )    .fetch_all(pool)    .await?;    // 3. HashMapでグループ化（O(n)）    let mut tag_map: HashMap<Uuid, Vec<Tag>> = HashMap::new();    for row in tags {        tag_map            .entry(row.post_id)            .or_default()            .push(Tag { tag_id: row.tag_id, name: row.name });    }    // 4. 結果を組み立て    let result = posts        .into_iter()        .map(|post| {            let tags = tag_map.remove(&post.post_id).unwrap_or_default();            PostWithTags { post, tags }        })        .collect();    Ok(result)}// **2回のクエリで完了（N+1 → 2）**ANY vs IN の違い-- IN句: リテラル値のリストSELECT * FROM posts WHERE post_id IN ('id1', 'id2', 'id3');-- ANY: 配列パラメータSELECT * FROM posts WHERE post_id = ANY($1);  -- $1 は UUID[]sqlxでは配列パラメータとしてANYを使う方が便利です。パフォーマンス特性IN/ANY句のパフォーマンス:要素数     | 推奨アプローチ-----------|------------------< 100      | IN/ANY で問題なし100-1000   | IN/ANY + インデックス確認1000+      | 一時テーブル or UNNEST大量のIDがある場合の対処法です。async fn get_posts_with_many_ids(pool: &PgPool, ids: &[Uuid]) -> Result<Vec<Post>, sqlx::Error> {    // 大量のIDはUNNESTでJOIN    sqlx::query_as!(        Post,        r#"        SELECT p.*        FROM unnest($1::uuid[]) WITH ORDINALITY AS t(id, ord)        JOIN posts p ON p.post_id = t.id        ORDER BY t.ord        "#,        ids    )    .fetch_all(pool)    .await}IN句+HashMapは2回のクエリで済み、行の膨張も起きない。ただ、Rustでの組み立て処理が必要になる。もし1回のクエリで完結させたいなら、PostgreSQLの配列集約機能が使える。解決策3: PostgreSQL配列集約PostgreSQLのarray_aggを使うと、1回のクエリで1対多の関連をネストした形で取得できます。#[derive(Debug, sqlx::FromRow)]struct PostWithTags {    post_id: Uuid,    title: String,    content: String,    tags: Vec<String>,}async fn get_posts_with_tags_aggregated(pool: &PgPool) -> Result<Vec<PostWithTags>, sqlx::Error> {    sqlx::query_as!(        PostWithTags,        r#"        SELECT            p.post_id,            p.title,            p.content,            COALESCE(                array_agg(t.name) FILTER (WHERE t.name IS NOT NULL),                '{}'            ) as "tags!: Vec<String>"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}// **1回のクエリで完了**array_aggの注意点NULL処理: FILTER (WHERE ... IS NOT NULL) でNULLを除外する空配列: COALESCE(..., '{}') で関連がない時は空配列を返す重複: 必要に応じて array_agg(DISTINCT ...) を使用する複数の配列を同時に集約async fn get_posts_with_tags_and_categories(pool: &PgPool) -> Result<Vec<PostWithTagsAndCategories>, sqlx::Error> {    sqlx::query_as!(        PostWithTagsAndCategories,        r#"        SELECT            p.post_id,            p.title,            COALESCE(                array_agg(DISTINCT t.name) FILTER (WHERE t.name IS NOT NULL),                '{}'            ) as "tags!: Vec<String>",            COALESCE(                array_agg(DISTINCT c.name) FILTER (WHERE c.name IS NOT NULL),                '{}'            ) as "categories!: Vec<String>"        FROM posts p        LEFT JOIN post_tags pt USING (post_id)        LEFT JOIN tags t USING (tag_id)        LEFT JOIN post_categories pc USING (post_id)        LEFT JOIN categories c USING (category_id)        GROUP BY p.post_id        "#    )    .fetch_all(pool)    .await}array_aggは単純な値の配列には便利だ。タグ名やカテゴリ名のようなString型の配列なら、これで十分。しかし、コメントのように複数のフィールドを持つオブジェクトを集約したい時はどうだろうか。そこで登場するのがjson_aggだ。解決策4: json_aggによる複雑なネストarray_aggでは単純な値しか集約できませんが、json_aggを使えば複雑なオブジェクトをネストできます。use serde::Deserialize;use sqlx::types::Json;#[derive(Debug, Deserialize)]struct CommentJson {    comment_id: Uuid,    body: String,    created_at: DateTime<Utc>,}#[derive(Debug, sqlx::FromRow)]struct PostWithComments {    post_id: Uuid,    title: String,    comments: Json<Vec<CommentJson>>,}async fn get_posts_with_comments(pool: &PgPool) -> Result<Vec<PostWithComments>, sqlx::Error> {    sqlx::query_as!(        PostWithComments,        r#"        SELECT            p.post_id,            p.title,            COALESCE(                json_agg(                    json_build_object(                        'comment_id', c.comment_id,                        'body', c.body,                        'created_at', c.created_at                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                '[]'            ) as "comments!: Json<Vec<CommentJson>>"        FROM posts p        LEFT JOIN comments c USING (post_id)        GROUP BY p.post_id        ORDER BY p.created_at DESC        LIMIT 100        "#    )    .fetch_all(pool)    .await}jsonb_agg vs json_agg 関数  特徴  json_agg  テキストとして格納、出力がJSON文字列の順序を保持  jsonb_agg  バイナリ格納、重複キー削除、インデックス可能 単純な集約にはjson_agg、後で検索や操作をする時はjsonb_aggを使います。深いネスト構造async fn get_posts_full_detail(pool: &PgPool) -> Result<Vec<PostFullDetail>, sqlx::Error> {    sqlx::query_as!(        PostFullDetail,        r#"        SELECT            p.post_id,            p.title,            json_build_object(                'user_id', u.user_id,                'name', u.name            ) as "author!: Json<AuthorJson>",            COALESCE(                json_agg(                    json_build_object(                        'comment_id', c.comment_id,                        'body', c.body,                        'commenter', json_build_object(                            'user_id', cu.user_id,                            'name', cu.name                        )                    )                    ORDER BY c.created_at DESC                ) FILTER (WHERE c.comment_id IS NOT NULL),                '[]'            ) as "comments!: Json<Vec<CommentWithCommenterJson>>"        FROM posts p        JOIN users u ON p.user_id = u.user_id        LEFT JOIN comments c USING (post_id)        LEFT JOIN users cu ON c.user_id = cu.user_id        GROUP BY p.post_id, u.user_id        LIMIT 100        "#    )    .fetch_all(pool)    .await}ここまでの解決策はすべて、取得するデータが事前にわかっている場合に有効だ。SQLを書く時点で、どのテーブルをJOINするか、何を集約するかが決まっている。しかし、GraphQLのように「リクエストごとに取得対象が動的に変わる」時はどうだろうか。そこで登場するのがDataLoaderパターンだ。解決策5: DataLoaderパターンGraphQLなどで多用されるDataLoaderパターンは、複数の個別リクエストを自動的にバッチ化する仕組みです。use std::collections::HashMap;use tokio::sync::Mutex;pub struct UserLoader {    pool: PgPool,    cache: Mutex<HashMap<Uuid, User>>,}impl UserLoader {    pub fn new(pool: PgPool) -> Self {        Self {            pool,            cache: Mutex::new(HashMap::new()),        }    }    /// 複数のユーザーIDを一括でロード    pub async fn load_many(&self, ids: &[Uuid]) -> Result<HashMap<Uuid, User>, sqlx::Error> {        let mut cache = self.cache.lock().await;        // キャッシュにないIDを特定        let missing: Vec<Uuid> = ids            .iter()            .filter(|id| !cache.contains_key(id))            .copied()            .collect();        if !missing.is_empty() {            // 一括でDBから取得            let users: Vec<User> = sqlx::query_as!(                User,                "SELECT * FROM users WHERE user_id = ANY($1)",                &missing            )            .fetch_all(&self.pool)            .await?;            // キャッシュに追加            for user in users {                cache.insert(user.user_id, user);            }        }        // 結果を構築        let result = ids            .iter()            .filter_map(|id| cache.get(id).cloned().map(|u| (*id, u)))            .collect();        Ok(result)    }    /// 単一のユーザーをロード（内部的にはバッチ処理可能）    pub async fn load(&self, id: Uuid) -> Result<Option<User>, sqlx::Error> {        let map = self.load_many(&[id]).await?;        Ok(map.into_values().next())    }    /// リクエスト終了時にキャッシュをクリア    pub async fn clear(&self) {        self.cache.lock().await.clear();    }}DataLoaderの使用例async fn get_posts_with_authors_dataloader(    pool: &PgPool,    loader: &UserLoader,) -> Result<Vec<PostWithAuthor>, anyhow::Error> {    let posts = sqlx::query_as!(Post, "SELECT * FROM posts LIMIT 100")        .fetch_all(pool)        .await?;    // 全ユーザーIDを収集    let user_ids: Vec<Uuid> = posts.iter().map(|p| p.user_id).collect();    // 一括でロード    let users = loader.load_many(&user_ids).await?;    // 結果を組み立て    let result = posts        .into_iter()        .filter_map(|post| {            // ユーザーが見つからない投稿はスキップ            // または、Option<User>としてPostWithAuthorを定義する            users.get(&post.user_id).cloned().map(|author| {                PostWithAuthor { post, author }            })        })        .collect();    Ok(result)}より高度な自動バッチ化が必要な時は、async-graphqlのDataLoader実装を参照してください。5つの解決策を見てきた。では、どれを選べばいいのか。それぞれの特徴を整理してみよう。解決策の比較 方法  クエリ数  複雑さ  適用場面  JOIN  1  低  1対1、少量の1対多  IN句 + HashMap  2  中  1対多、多対多  array_agg  1  中  単純な値の1対多  json_agg  1  高  複雑なネスト構造  DataLoader  2+  高  GraphQL、動的なデータ取得 ここで一見すると「シンプルなJOINが最善」と思えるだろう。しかし、そう単純な話ではない。JOINは1対多で行が膨張し、json_aggは可読性を犠牲にする。シンプルさとパフォーマンスは常にトレードオフの関係にある。私の結論は、「まずJOINを試し、問題が出たらIN句+HashMapに移行する」という段階的アプローチだ。最初から複雑な解決策に飛びつく必要はない。選択の判断フローチャート解決策がわかっても、そもそもN+1が発生していることに気づかなければ意味がない。コードレビューで確認すべき項目をまとめておこう。N+1検出チェックリストコードレビューやPRレビューでは、まずループ内でquery_as!やquery!を呼んでいないかを確認してください。次に、for文の中に.awaitがあり、DBアクセスをしていないかをチェックします。最後に、APIレスポンスに必要なデータを1-2回のクエリで取得できているかを確認しましょう。まとめRustにしたのに遅い？—それはRustのせいではない。N+1クエリ問題は、言語の速さを帳消しにする。どれだけRustが速くても、100回のネットワーク往復は100回のネットワーク往復だ。言語を変えても、アーキテクチャの問題は解決しない。問題は、気づいた瞬間に半分解決している。N+1クエリ問題は、気づかないうちにパフォーマンスを劣化させる典型的なアンチパターンです。解決の基本原則は以下の3つです。ループ内でI/Oを行わない必要なデータは一括で取得する開発時にクエリ数を監視する「N+1を気にしすぎるとコードが複雑になる」という批判はあるだろう。確かにその通りだ。しかし、私の経験では、N+1問題は本番環境で突然顕在化することが多い。開発環境では10件のデータで問題なく動いていたコードが、本番で1000件になると破綻する。複雑さのコストより、本番障害のコストの方が高い。だからこそ、複数の解決策を知っておくことに価値がある。RustとPostgreSQLの組み合わせでは、JOIN、IN句、array_agg、json_agg、DataLoaderなど複数の解決策があり、状況に応じて適切な方法を選択できます。実測パフォーマンス比較実際にRust + sqlx + PostgreSQLで計測した結果を示します。 方法  クエリ数  実行時間  改善率  N+1パターン（アンチパターン）  51回  27.95ms  -  JOIN  1回  1.51ms  18.5倍高速  IN句 + HashMap  2回  1.71ms  16.3倍高速  DataLoader（初回）  2回  1.61ms  17.4倍高速  DataLoader（キャッシュヒット）  0回  0.013ms  2,150倍高速 計測条件:PostgreSQL 17 / Docker環境50件の記事、10人の著者ローカル接続（ネットワークレイテンシ最小）リモートDBやクラウド環境ではネットワークレイテンシが加算されるため、N+1の影響はより大きくなります。問題の深刻さがわかったところで、どうやって検出すればいいのか。開発から本番まで、各段階での対策を整理しておこう。検出のまとめN+1問題の検出には複数のレイヤーで対策を講じるべきです。 段階  手法  特徴  開発時  クエリカウンター、トレーシング  即座にフィードバック  テスト時  assert_max_queries、統合テスト  CI/CDで自動検出  コードレビュー  チェックリスト、静的解析  ループ内awaitを検出  本番環境  pg_stat_statements、OpenTelemetry  実際の影響を測定 特に重要なのは、開発初期段階での検出です。本番環境で発見されたN+1問題は、すでにユーザー体験に影響を与えており、修正にも時間がかかります。とはいえ、すべてのN+1を事前に防げるかと言われると、正直なところ難しい。新しいチームメンバーが入ってきたり、時間に追われたリリースがあったりすれば、どこかでN+1パターンが紛れ込む。完璧を目指すより、検出と修正のサイクルを回せる体制を作る方が現実的だと私は考えている。数えてみろ。数えれば見える。冒頭で触れた300回クエリの問題は、IN句+HashMapパターンで2回のクエリに削減でき、レスポンスは5秒から200msに改善した。次のコードレビューで、ループ内の.awaitを確認してみてください。参考資料syu-m-5151.hatenablog.comsqlx / Rustsqlx Documentationtracing cratesyn crate（AST解析）PostgreSQLPostgreSQL Array FunctionsPostgreSQL JSON Functionspg_stat_statementsauto_explainpg_stat_activityパターンDataLoader PatternAvoiding N+1 Queries (Rails/ActiveRecord、概念は共通)観測性OpenTelemetry Rusttracing-opentelemetry]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[10 Premium Tools for 10x Developers]]></title>
            <link>https://daisuke1024akagawa.medium.com/6-premium-tools-for-10x-developers-af6b17908014?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/6-premium-tools-for-10x-developers-af6b17908014?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Thu, 25 Dec 2025 10:47:11 GMT</pubDate>
            <content:encoded><![CDATA[This time, I’ll introduce the 10 paid services I regularly use.Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[0.1+0.2=0.30000000000000004 をRust/PostgreSQLで考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/25/192751</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/25/192751</guid>
            <pubDate>Thu, 25 Dec 2025 10:27:51 GMT</pubDate>
            <content:encoded><![CDATA[はじめにテストを書いていて、奇妙なことに気づいた。合計金額のアサーションが通らない。期待値は10.00なのに、実際の値は9.99999999999983。コードにバグはない。SQLも正しい。では何が問題なのか。調べた結果、犯人は浮動小数点の累積誤差だった。金額カラムにDOUBLE PRECISIONを使っていたのです。これは「浮動小数点の罠」とも呼ばれる、DB設計やアプリケーションの実装で陥りやすい問題だ。RustとPostgreSQLでWebサービスを構築する際に注意すべき点の1つで、金融システムや科学計算、測定データ、座標、パーセンテージなど、正確な数値が必要なあらゆる場面で問題になります。2進数と10進数の不一致コンピュータは2進数で数値を表現します。しかし、私たちが日常使う10進数の多くは2進数で正確に表現できません。0.1 (10進数) = 0.0001100110011... (2進数・無限循環小数)これはPostgreSQLやRustの問題ではなく、IEEE 754（コンピュータが小数を扱う国際標準規格）に基づくすべてのシステムに共通する問題です。fn main() {    let a = 0.1_f64;    let b = 0.2_f64;    let c = a + b;    println!("{} + {} = {}", a, b, c);    // 出力: 0.1 + 0.2 = 0.30000000000000004    println!("0.1 + 0.2 == 0.3 ? {}", c == 0.3);    // 出力: false}PostgreSQLの数値型PostgreSQLには大きく分けて3種類の数値型があります。浮動小数点型（近似値）浮動小数点型は近似値を扱う型で、内部的にはIEEE 754形式（2進数の浮動小数点）で表現されます。REAL（FLOAT4とも呼ばれる）は4バイトのストレージを使用し、有効桁数は6桁です。センサーデータやグラフィックスなど、高い精度を必要としない場面に適しています。DOUBLE PRECISION（FLOAT8とも呼ばれる）は8バイトを使用し、有効桁数は15桁に拡張されます。科学計算や座標データなど、より高い精度が求められる場面で使用します。任意精度型（正確値）NUMERIC（またはDECIMAL）は正確な計算が必要な場面で使用する型です。ストレージは可変長で、4桁ごとに2バイトを消費します。最大131,072桁までの精度をサポートしており、金額計算などで威力を発揮します。なお、PostgreSQLではNUMERICとDECIMALは完全に同一の型として扱われます。整数型整数型は小数を含まない数値を扱います。INTEGERは4バイトで±21億の範囲を扱え、カウンターやIDに適しています。BIGINTは8バイトで±922京という広大な範囲をカバーし、大きな整数やセント単位での金額格納に使用できます。問題が発生する具体的な場面1. 等価比較の失敗-- PostgreSQLで確認SELECT 0.1::float8 + 0.2::float8 = 0.3::float8;-- 結果: falseSELECT 0.1::numeric + 0.2::numeric = 0.3::numeric;-- 結果: trueこれはWHERE句での検索に影響します。-- 見つからない可能性があるSELECT * FROM measurements WHERE value = 0.3;-- 確実に動作SELECT * FROM measurements WHERE ABS(value - 0.3) < 0.0001;2. 累積誤差-- 0.01を1000回加算CREATE TABLE test_float (amount DOUBLE PRECISION);CREATE TABLE test_numeric (amount NUMERIC(10,2));INSERT INTO test_float SELECT 0.01 FROM generate_series(1, 1000);INSERT INTO test_numeric SELECT 0.01 FROM generate_series(1, 1000);SELECT SUM(amount) FROM test_float;-- 結果: 9.99999999999983（期待値: 10.00）SELECT SUM(amount) FROM test_numeric;-- 結果: 10.00（正確）誤差は小さく見えますが、0.00017の誤差でも1000万レコードでは1700の誤差になります。月次決算で170万円ずれる可能性があるのです。3. 丸め方法の違いPostgreSQLのNUMERICとFLOATでは丸め方法が異なります。SELECT x,  round(x::numeric) AS numeric_round,  round(x::double precision) AS float_roundFROM (VALUES (-2.5), (-1.5), (1.5), (2.5)) AS t(x); x  NUMERIC  FLOAT  -2.5  -3  -2  -1.5  -2  -2  1.5  2  2  2.5  3  2 NUMERIC: ゼロから遠い方へ丸める（Midpoint Away From Zero）FLOAT: 最近偶数へ丸める（Banker's Rounding / IEEE 754）この違いは、同じ計算でも型によって結果が異なることを意味します。ドメイン別：FLOATを使えるか使用を避けるべき場面 ドメイン  理由  推奨型  金額・会計  1円/1セントの誤差も許されない  NUMERIC  税率・割引率  正確な計算が必要  NUMERIC  合計が一致すべきパーセンテージ  33.33% × 3 = 100%が必要  NUMERIC  統計的有意性  p値の正確な比較  NUMERIC  監査証跡  再現可能性が必要  NUMERIC FLOATが許容される場面 ドメイン  理由  推奨型  センサーデータ  センサー自体の誤差 > FLOAT誤差  DOUBLE PRECISION  座標（GPS）  15桁精度で十分（1cm精度には7桁で十分）  DOUBLE PRECISION  温度・湿度  測定誤差が大きい  REAL or DOUBLE PRECISION  レーティング平均  表示時に丸める  DOUBLE PRECISION  グラフィックス  視覚的に認識できない  REAL 判断のフローチャート数値型を選択する際は、まず正確な10進数表現が必要かどうかを考えます。金額や税率など、誤差が許されない値を扱う場合は、迷わずNUMERIC/DECIMALを選択してください。正確な10進数表現が不要な場合は、次に必要な精度を検討します。15桁を超える精度が必要であれば、浮動小数点型では対応できないため、やはりNUMERICを使用します。15桁以下の精度で十分な場合は、ストレージ効率を考慮して浮動小数点型を選びます。6桁程度の精度で事足りるなら、4バイトで済むREALが適しています。それ以上の精度が必要であれば、8バイトのDOUBLE PRECISIONを選択してください。解決策1：適切な型の選択スキーマ設計例CREATE TABLE measurements (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    -- 正確さが必要な値    price NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL,    -- 近似値で十分な値    temperature DOUBLE PRECISION,    latitude DOUBLE PRECISION,    longitude DOUBLE PRECISION,    -- 整数で表現できる値    quantity INTEGER NOT NULL,    price_cents BIGINT,  -- 代替：セント単位格納    -- 制約    CONSTRAINT valid_tax_rate CHECK (tax_rate >= 0 AND tax_rate <= 1),    CONSTRAINT valid_latitude CHECK (latitude BETWEEN -90 AND 90),    CONSTRAINT valid_longitude CHECK (longitude BETWEEN -180 AND 180));precision（精度）とscale（スケール）の設計NUMERICはNUMERIC(precision, scale)の形式で定義します。precisionは全体の有効桁数、scaleは小数点以下の桁数を指定します。用途に応じた設定例を紹介します。一般的な金額にはNUMERIC(10, 2)が適しており、-99,999,999.99から99,999,999.99までの範囲を格納できます。税率や割引率にはNUMERIC(5, 4)を使用し、0.0000から0.9999までの値を扱えます。より細かい精度が必要な場面では、暗号通貨なら小数部8桁を確保できるNUMERIC(16, 8)、為替レートなら小数部6桁のNUMERIC(10, 6)が適切です。科学的測定など高精度が求められる場合は、NUMERIC(15, 10)のように大きな精度を確保してください。解決策2：Rustでの適切な型選択f64の限界を理解するfn demonstrate_float_issues() {    // 等価比較の問題    let a = 0.1_f64 + 0.2_f64;    let b = 0.3_f64;    assert!(a != b);  // 等しくない！    // 累積誤差    let mut sum = 0.0_f64;    for _ in 0..1000 {        sum += 0.01;    }    println!("1000 × 0.01 = {}", sum);  // 9.999999999999831    // 大きな値での精度損失    let big = 1_000_000_000_000_000.0_f64;    let next = big + 1.0;    println!("{} + 1 = {}", big, next);  // 変化しない可能性}rust_decimalクレート正確な10進数計算が必要な時は以下を使用します。[dependencies]rust_decimal = { version = "1", features = ["db-postgres"] }rust_decimal_macros = "1"sqlx = { version = "0.8", features = ["postgres", "rust_decimal"] }use rust_decimal::Decimal;use rust_decimal_macros::dec;use std::str::FromStr;// 生成方法let d1 = dec!(19.99);                      // マクロ（推奨）let d2 = Decimal::from_str("19.99")?;      // 文字列からlet d3 = Decimal::new(1999, 2);            // 整数 / 10^scale// f64からの変換は精度損失の可能性あり（避ける）let risky = Decimal::from_f64(19.99);      // Option<Decimal>浮動小数点の比較方法f64を使う場合、等価比較には専用クレートを使用します。use approx::{abs_diff_eq, relative_eq};let a = 0.1_f64 + 0.2_f64;let b = 0.3_f64;// 絶対誤差での比較assert!(abs_diff_eq!(a, b, epsilon = 1e-10));// 相対誤差での比較（大きな値でも適切に動作）assert!(relative_eq!(a, b, epsilon = 1e-10));丸め戦略の選択rust_decimalは複数の丸め戦略をサポートしています。use rust_decimal::prelude::*;use rust_decimal::RoundingStrategy;let value = dec!(2.5);// 各戦略の結果value.round_dp(0)  // MidpointNearestEven: 2（デフォルト）value.round_dp_with_strategy(0, RoundingStrategy::MidpointAwayFromZero)  // 3value.round_dp_with_strategy(0, RoundingStrategy::ToZero)  // 2（切り捨て）value.round_dp_with_strategy(0, RoundingStrategy::AwayFromZero)  // 3（切り上げ） 戦略  説明  2.5  -2.5  用途  MidpointNearestEven  Banker's丸め  2  -2  統計、科学計算  MidpointAwayFromZero  四捨五入  3  -3  一般的な丸め  ToZero  切り捨て  2  -2  税額計算（日本）  AwayFromZero  切り上げ  3  -3  天井関数的  ToPositiveInfinity  正方向へ  3  -2  ceil  ToNegativeInfinity  負方向へ  2  -3  floor 解決策3：sqlxとの連携型マッピング PostgreSQL  Rust  特徴  REAL  f32  近似値、高速  DOUBLE PRECISION  f64  近似値、高速  NUMERIC  Decimal  正確、やや遅い  BIGINT  i64  整数、最速 構造体定義use rust_decimal::Decimal;use sqlx::FromRow;use uuid::Uuid;#[derive(Debug, FromRow)]struct Product {    id: Uuid,    name: String,    price: Decimal,           // NUMERIC → Decimal    weight_kg: f64,           // DOUBLE PRECISION → f64（測定値）}#[derive(Debug, FromRow)]struct SensorReading {    id: Uuid,    temperature: f64,         // センサー誤差 > FLOAT誤差    humidity: f64,    latitude: f64,    longitude: f64,    recorded_at: chrono::DateTime<chrono::Utc>,}クエリ例use rust_decimal_macros::dec;// 正確な計算が必要な場合async fn calculate_total(pool: &PgPool, order_id: Uuid) -> Result<Decimal, sqlx::Error> {    sqlx::query_scalar!(        r#"        SELECT COALESCE(SUM(price * quantity), 0)::NUMERIC as "total!"        FROM order_items        WHERE order_id = $1        "#,        order_id    )    .fetch_one(pool)    .await}// 近似値で十分な場合async fn get_average_temperature(pool: &PgPool) -> Result<f64, sqlx::Error> {    sqlx::query_scalar!(        r#"SELECT AVG(temperature) as "avg!" FROM sensor_readings"#    )    .fetch_one(pool)    .await}解決策4：整数による固定小数点最もシンプルで高速な方法を紹介します。CREATE TABLE products (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    price_cents BIGINT NOT NULL,  -- $19.99 → 1999    CONSTRAINT positive_price CHECK (price_cents > 0));/// 型安全な金額ラッパー#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]struct Cents(i64);impl Cents {    fn new(cents: i64) -> Self {        Self(cents)    }    fn from_dollars(dollars: i64, cents: i64) -> Self {        Self(dollars * 100 + cents)    }    fn dollars(&self) -> i64 {        self.0 / 100    }    fn cents_part(&self) -> i64 {        self.0.abs() % 100    }}impl std::fmt::Display for Cents {    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {        if self.0 < 0 {            write!(f, "-${}.{:02}", self.dollars().abs(), self.cents_part())        } else {            write!(f, "${}.{:02}", self.dollars(), self.cents_part())        }    }}impl std::ops::Add for Cents {    type Output = Self;    fn add(self, other: Self) -> Self {        Self(self.0 + other.0)    }}impl std::ops::Sub for Cents {    type Output = Self;    fn sub(self, other: Self) -> Self {        Self(self.0 - other.0)    }}利点:- 整数演算は常に正確- 最高のパフォーマンス- ストレージ効率が良い（8バイト固定）欠点:- 小数部の桁数が固定- 乗除算後に桁調整が必要パフォーマンスとストレージの比較 型  ストレージ  演算速度  正確性  REAL  4バイト  最速（FPU）  近似  DOUBLE PRECISION  8バイト  高速（FPU）  近似  BIGINT  8バイト  高速（整数演算）  正確  NUMERIC(10,2)  約9バイト  遅い（ソフトウェア）  正確  NUMERIC(19,4)  約13バイト  遅い  正確 大量データの集計ではFLOATが10〜100倍高速になることもあります。しかし、正確性が必要な時はNUMERICを使用してください。実践例ハイブリッドアプローチ-- 生データはFLOAT、集計結果はNUMERICCREATE TABLE sensor_data (    id BIGSERIAL PRIMARY KEY,    reading DOUBLE PRECISION NOT NULL,    recorded_at TIMESTAMPTZ NOT NULL);CREATE TABLE daily_summary (    date DATE PRIMARY KEY,    avg_reading NUMERIC(10, 4) NOT NULL,  -- 集計は正確に    min_reading NUMERIC(10, 4) NOT NULL,    max_reading NUMERIC(10, 4) NOT NULL);-- 集計時にNUMERICへ変換INSERT INTO daily_summarySELECT    DATE(recorded_at),    AVG(reading)::NUMERIC(10, 4),    MIN(reading)::NUMERIC(10, 4),    MAX(reading)::NUMERIC(10, 4)FROM sensor_dataGROUP BY DATE(recorded_at);生成列で自動計算CREATE TABLE invoices (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    subtotal NUMERIC(10, 2) NOT NULL,    tax_rate NUMERIC(5, 4) NOT NULL DEFAULT 0.10,    -- 自動計算される生成列    tax_amount NUMERIC(10, 2) GENERATED ALWAYS AS (        ROUND(subtotal * tax_rate, 2)    ) STORED,    total NUMERIC(10, 2) GENERATED ALWAYS AS (        subtotal + ROUND(subtotal * tax_rate, 2)    ) STORED);座標データの精度CREATE TABLE locations (    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),    name VARCHAR(200) NOT NULL,    -- DOUBLE PRECISIONで十分（15桁 > 必要な7桁）    latitude DOUBLE PRECISION NOT NULL,    longitude DOUBLE PRECISION NOT NULL,    -- 高精度が必要な場合のみNUMERIC    survey_latitude NUMERIC(11, 8),   -- 1mmレベルの精度    survey_longitude NUMERIC(12, 8),    CONSTRAINT valid_coords CHECK (        latitude BETWEEN -90 AND 90 AND        longitude BETWEEN -180 AND 180    ));座標の精度と実距離の対応を以下に示します。 小数点の桁数  精度  2桁  約1.1km  4桁  約11m  6桁  約11cm  8桁  約1.1mm rust_decimalの制限事項 項目  rust_decimal  PostgreSQL NUMERIC  最大値  約7.9×1028  10131072 - 1  最小スケール  10^-28  10^-16383  ストレージ  16バイト固定  可変長 PostgreSQLからの読み込み時に範囲外の値があるとエラーになります。非常に大きな精度が必要な時はbigdecimalクレートを検討してください。チェックリストスキーマ設計時[ ] FLOATを使う前に「近似値で本当に問題ないか」を確認[ ] 金額・税率・割引率にはNUMERIC/DECIMALを使用[ ] precision/scaleは将来の拡張を考慮して設定[ ] 座標データは用途に応じた精度を選択[ ] センサーデータはセンサー精度を考慮して型を選択Rust実装時[ ] 正確な計算にはrust_decimalを使用[ ] f64の等価比較にはapproxクレートを使用[ ] 丸め戦略を明示的に指定[ ] f64からDecimalへの変換は避ける（文字列経由で）おわりに冒頭で触れたテストの失敗は、金額カラムをNUMERIC(10, 2)に変更することで解消した。修正自体は数分で終わった。型の選択を間違えなければ、そもそも起きなかった問題だ。この記事で見てきたように、浮動小数点の誤差はコンピュータの本質的な制約であり、避けることはできない。しかし、対処法はシンプルだ。金額にはNUMERIC、センサーデータにはFLOAT、迷ったらNUMERIC。スキーマ設計の段階でこの判断ができれば、テストで奇妙な小数を見ることはなくなる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料PostgreSQL Numeric TypesIEEE 754 Floating-Point StandardThe Floating-Point Guiderust_decimal crateapprox crateWhat Every Programmer Should Know About Floating-PointFloating Point Numbers and Decimal in Go]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The Pillars of Intelligence: 5 Essential Reading for Every ML Engineer]]></title>
            <link>https://daisuke1024akagawa.medium.com/the-pillars-of-intelligence-5-essential-reading-for-every-ml-engineer-a8cfee9be015?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/the-pillars-of-intelligence-5-essential-reading-for-every-ml-engineer-a8cfee9be015?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 24 Dec 2025 02:43:38 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[論理削除という技術的負債、それでも僕たちは使い続ける]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/24/110101</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/24/110101</guid>
            <pubDate>Wed, 24 Dec 2025 02:01:01 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「論理削除？deleted_atカラム追加すればいいでしょ」この一言から始まる地獄を、何度見てきただろうか。最初は簡単に見える。カラムを1つ追加するだけ。しかし、その「簡単さ」こそが罠だ。論理削除は技術的負債の温床だ。WHERE句への条件追加忘れ、認知コストの増大、テストの複雑化、パフォーマンス劣化。すべては「最初にドメインを考えなかった」ツケである。しかし現実として、サービスを運用していくと論理削除が必要になる場面は確実に訪れる。論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を解消するか、受け入れて安全に管理するか。本記事ではその両方のアプローチを解説する。なお、私はDBのスペシャリストではないので、ここで紹介する方法が唯一の正解というわけではない。あくまで一つのアプローチとして参考にしてほしい。データベース設計は文脈次第で最適解が変わるため、「この記事に書いてあったから」ではなく、自分のプロジェクトに合うかどうかで判断してほしい。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。論理削除の何が問題なのかWHERE句地獄最も分かりやすい問題。すべてのクエリに AND deleted_at IS NULL を書く必要がある。-- 単純なSELECTSELECT * FROM users WHERE id = 1 AND deleted_at IS NULL;-- JOINするたびに増えるSELECT *FROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLINNER JOIN products p ON o.product_id = p.id AND p.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- サブクエリでも忘れずにSELECT *FROM usersWHERE id IN (    SELECT user_id FROM orders WHERE deleted_at IS NULL)AND deleted_at IS NULL;書き忘れたらどうなるか？削除したはずのデータが表示される。テストでは気づかない。本番で発覚する。深夜に電話が鳴る。JOINが増えるほど、フィルタも増える──────────────────────────────────────────────────────────  SELECT * FROM orders        │        ├──▶ WHERE orders.deleted_at IS NULL        ← 1個目        │        ├──▶ JOIN users        │         └──▶ AND users.deleted_at IS NULL  ← 2個目        │        ├──▶ JOIN products        │         └──▶ AND products.deleted_at IS NULL ← 3個目        │        └──▶ JOIN categories                  └──▶ AND categories.deleted_at IS NULL ← 4個目  テーブルが増えるたびに、書き忘れのリスクも増える認知コストの増大「このテーブル、論理削除だっけ？物理削除だっけ？」この確認が、すべてのクエリを書くたびに発生する。// このクエリ、deleted_atの条件入ってる？let users = sqlx::query_as!(User, "SELECT * FROM users WHERE status = 'active'")    .fetch_all(pool)    .await?;// レビュアー「deleted_atのフィルタ抜けてませんか？」// 作者「あ、このテーブルは物理削除です」// レビュアー「どこに書いてあります？」// 作者「...」ドキュメントに書いてあっても読まれない。コメントに書いてあっても見落とす。レビュアーの認知負荷が高い設計は、チーム規模が拡大するほど事故率が上がる。一意制約の崩壊論理削除を導入した瞬間、一意制約が意味をなさなくなる。-- emailはユニークであるべきCREATE TABLE users (    id UUID PRIMARY KEY,    email VARCHAR(255) UNIQUE,    deleted_at TIMESTAMPTZ);-- ユーザーAがemail "test@example.com" で登録-- ユーザーAを論理削除-- ユーザーBが同じemail "test@example.com" で登録しようとする-- → UNIQUE制約違反！解決策はあるが、どれも美しくない。-- 案1: 部分インデックス（PostgreSQL）CREATE UNIQUE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;-- 案2: 削除済みは別の値にするUPDATE users SET email = email || '_deleted_' || id WHERE id = $1;-- 案3: 複合ユニーク制約CREATE UNIQUE INDEX idx_users_email ON users(email, COALESCE(deleted_at, '9999-12-31'));どれを選んでも「なぜこんなことをしているのか」を説明するコストが発生する。外部キー制約との相性の悪さ-- ordersはusersを参照するCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id),    deleted_at TIMESTAMPTZ);-- ユーザーを論理削除UPDATE users SET deleted_at = NOW() WHERE id = $1;-- 問題: ordersからは削除されていないuserへの参照が残る-- deleted_at IS NULLでフィルタすると、関連データが取得できないSELECT o.*, u.nameFROM orders oINNER JOIN users u ON o.user_id = u.id AND u.deleted_at IS NULLWHERE o.deleted_at IS NULL;-- → ユーザーが論理削除されると、その注文も見えなくなる（意図した動作？）「削除されたユーザーの注文はどう扱うべきか」という問いに、論理削除は答えを持っていない。データベースが提供する整合性保証を、アプリケーションコードで再実装する羽目になる。カスケード削除との相性が最悪-- 物理削除用に設計されたスキーマCREATE TABLE orders (    id UUID PRIMARY KEY,    user_id UUID REFERENCES users(id) ON DELETE CASCADE);-- 論理削除を導入すると...UPDATE users SET deleted_at = NOW() WHERE id = $1;-- → ordersは削除されない（CASCADEはDELETEにしか反応しない）-- → 「削除された」ユーザーの注文が残り続けるパフォーマンス問題論理削除されたレコードが増えるほど、テーブルは肥大化する。パーシャルインデックスで対処できる。しかし、これも「論理削除を選んだがゆえの追加コスト」だ。-- 10年運用したサービス-- 全レコード: 100万件-- 有効レコード: 10万件-- 削除済みレコード: 90万件-- すべてのクエリが90万件のゴミをスキャンする可能性があるSELECT * FROM users WHERE email = 'test@example.com' AND deleted_at IS NULL;CREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;テストの複雑化#[tokio::test]async fn test_get_active_users() {    // 有効なユーザーを作成    let active_user = create_user(&pool, "active@example.com").await;    // 削除済みユーザーを作成    let deleted_user = create_user(&pool, "deleted@example.com").await;    soft_delete_user(&pool, deleted_user.id).await;    // テスト対象    let users = get_all_users(&pool).await;    // 削除済みが含まれていないことを確認    assert!(!users.iter().any(|u| u.id == deleted_user.id));}// このテストを書き忘れると、バグが本番に流出する// すべてのクエリに対して、このテストが必要deleted_at vs is_deleted：どちらを選ぶべきか論理削除の実装には2つの方式がある。-- 方式1: タイムスタンプ（deleted_at）deleted_at TIMESTAMPTZ  -- NULLなら有効、値があれば削除済み-- 方式2: ブールフラグ（is_deleted）is_deleted BOOLEAN DEFAULT FALSE  -- falseなら有効、trueなら削除済みdeleted_at を推奨する理由：「いつ削除されたか」という情報が自動的に残る監査ログとして機能する「30日以上前に削除されたデータをアーカイブ」といった処理が書きやすいis_deleted のメリット：シンプルで直感的インデックスが小さくなる（BOOLEAN vs TIMESTAMPTZ）NULLの扱いを考えなくてよい（deleted_at IS NULL vs is_deleted = false）私の経験では deleted_at が主流だ。削除日時の情報は運用・デバッグで頻繁に必要になる。ただし、削除日時が不要でパフォーマンスを最優先するなら is_deleted も選択肢になる。RustのORMには論理削除サポートがないRustのORMは、論理削除の組み込みサポートを持たない。// SeaORM - 論理削除の組み込みサポートなしlet users = User::find().all(&db).await?;// deleted_atのフィルタは手動で追加する必要があるlet users = User::find()    .filter(user::Column::DeletedAt.is_null())    .all(&db)    .await?;// 毎回書く必要がある。書き忘れてもコンパイルは通る。// Diesel - 同様に組み込みサポートなしlet users = users::table    .filter(users::deleted_at.is_null())    .load::<User>(&mut conn)?;// sqlx - 生SQLなので当然サポートなしlet users = sqlx::query_as!(User,    "SELECT * FROM users WHERE deleted_at IS NULL").fetch_all(pool).await?;Rustは「暗黙の動作」より「明示的なコード」を好む文化がある。論理削除フィルタが自動適用されるのは便利だが、何が起きているか分かりにくくなる。そのため、RustのORMは意図的にこの機能を持たないとも解釈できる。しかし、Dieselには diesel-softdelete というコミュニティcrateが存在する。// diesel-softdelete の使用例use diesel_softdelete::SoftDelete;// soft_find: findと同等だが、削除済みを自動除外let user = users::table.soft_find(user_id).first(&mut conn)?;// soft_inner_join: JOINのON句に削除フィルタを適用let posts = posts::table    .soft_inner_join(users::table)    .load(&mut conn)?;SeaORMには同様のcrateは存在しない。現実として、Rustでは論理削除を自分で安全に実装する必要がある。本記事で紹介する6つのパターンは、この課題に対する解決策だ。Linterで防げないのか「WHERE句の書き忘れ、Linterで検出できないの？」という疑問は当然だ。結論から言うと、難しい。SQLFluff（SQLリンター）の限界SQLFluffでカスタムルールを書くことは可能だが、根本的な問題がある。# .sqlfluff - カスタムルールの例[sqlfluff:rules]# 「deleted_at IS NULL を含まないSELECTを警告」というルールを書きたい# しかし...どのテーブルが論理削除対象か、Linterは知らないJOINの場合、どのテーブルにフィルタが必要か判定できないサブクエリの中まで追跡するのは複雑www.sqlfluff.comsqlx のコンパイル時チェックの限界sqlxはコンパイル時にSQLの構文と型をチェックするが、「論理削除フィルタがあるか」はチェックしない。// これはコンパイルが通る（deleted_at フィルタなし）let users = sqlx::query_as!(User, "SELECT * FROM users WHERE status = 'active'")    .fetch_all(pool)    .await?;理論的には可能だが、コストが高いProc Macroで独自のクエリマクロを作れば、検出は可能だ。// 理論上のカスタムマクロsoft_query_as!(User, "SELECT * FROM users WHERE status = 'active'")// → コンパイルエラー: "deleted_at IS NULL" が含まれていませんしかし、これを実装・保守するコストは高い。テーブルごとの論理削除設定、JOIN時の挙動、サブクエリの処理など、考慮すべきことが多い。結論：Linterより「ミスできない設計」Linterは「ミスを検出する」アプローチだ。しかし、論理削除の問題は「そもそもミスできない設計」で解決した方が確実だ。RLSやビューを使えば、アプリケーション側でフィルタを書き忘れても、データベースが守ってくれる。Linterで「書き忘れを検出する」より、「書き忘れても問題ない」設計の方が堅牢だ。www.postgresql.orgなぜそれでも論理削除を選ぶのかここまで問題を挙げてきた。それでも論理削除が選ばれ続ける理由を以下に示す。「削除」は本当に削除ではないビジネスの世界では、「削除」は「なかったこと」にすることではない。経理: 「この取引、間違いだったので削除してください」開発者: （物理削除を実行）経理: 「監査が来たとき、削除した取引の履歴を見せてください」開発者: 「...」法規制、監査対応、コンプライアンス。データを完全に消すことが許されないケースは多い。誤操作からの復旧ユーザー: 「間違えて投稿を削除してしまいました。復旧できますか？」物理削除なら「できません」。論理削除なら「できます」。この違いはサポートコストとユーザー満足度に直結する。関連データの整合性-- ユーザーを物理削除すると...DELETE FROM users WHERE id = $1;-- 関連する注文履歴はどうする？-- ON DELETE CASCADE で連鎖削除？→ 売上データが消える-- ON DELETE SET NULL で孤児にする？→ 「誰の注文かわからない」データが残る論理削除なら、関連データの整合性を保ったまま「削除扱い」にできる。分析・デバッグ用途-- なぜこのユーザーは退会したのか？SELECT * FROM users WHERE deleted_at IS NOT NULL ORDER BY deleted_at DESC;-- 削除前の状態を確認したいSELECT * FROM posts WHERE id = $1;  -- 削除済みでも見れる物理削除されたデータは、永遠に失われる。論理削除の本当の問題ここまでの問題点を整理すると、論理削除の本当の問題が見えてくる。それは「削除」という概念を、データモデルとして表現していないことだ。deleted_at カラムは、「このレコードは存在するが、存在しないことにしてほしい」という矛盾した状態を表現している。この矛盾が、すべての問題の根源だ。まず代替手段を検討せよここまで論理削除の問題を散々挙げてきた。では、どうすればいいのか。答えは状況によって異なる。まず、自分がどの状況にいるかを確認しよう。状況A: 新規設計の場合論理削除を使わない選択肢がある。代替手段を検討すべきだ。状況B: 既存システムの場合すでに deleted_at が導入されたテーブルが100個あるなら、今日明日で変えられるわけがない。事故を防ぐ仕組みで覆うしかない。本セクションでは状況Aの代替手段を、次のセクションでは状況Bの安全な実装パターンを解説する。新規設計なら、より良い選択肢がある。Archive テーブルパターン（推奨）削除されたデータを別テーブルに移動する、最もシンプルな代替手段。-- 本番テーブル（有効なデータのみ）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255) UNIQUE  -- 一意制約が正常に機能);-- アーカイブテーブル（削除済みデータ）CREATE TABLE archived_users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),  -- UNIQUEなし    archived_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),    archived_by UUID,    archive_reason TEXT);-- 削除時のトランザクションBEGIN;INSERT INTO archived_users (id, name, email, archive_reason)SELECT id, name, email, 'user_requested' FROM users WHERE id = $1;DELETE FROM users WHERE id = $1;COMMIT;メリット:本番テーブルはシンプルなまま一意制約、外部キー制約が正常に機能WHERE句地獄から解放アーカイブテーブルは別ストレージに配置可能デメリット:復元時にデータ移動が必要スキーマ変更時に両テーブルの更新が必要Temporal Tables（履歴テーブル）SQL:2011で標準化された機能。PostgreSQL 9.2+、SQL Server 2016+、MariaDB 10.3+でサポート。-- PostgreSQLでのTemporal Table（拡張機能を使用）CREATE TABLE users (    id UUID PRIMARY KEY,    name VARCHAR(100),    email VARCHAR(255),    valid_from TIMESTAMPTZ NOT NULL DEFAULT NOW(),    valid_to TIMESTAMPTZ NOT NULL DEFAULT 'infinity');-- 過去の状態を参照SELECT * FROM usersWHERE id = $1  AND valid_from <= '2024-01-15'  AND valid_to > '2024-01-15';メリット:変更履歴が自動的に保存される「誰が」「いつ」「何を」変更したか追跡可能通常のクエリには影響なしデメリット:テーブルサイズが急速に増大（高頻度更新テーブルでは問題）複数テーブル間の相関は追跡できないEvent Sourcing状態ではなく「イベント」を保存する設計パターン。#[derive(Debug)]pub enum UserEvent {    Created { id: Uuid, name: String, email: String },    Updated { id: Uuid, name: Option<String>, email: Option<String> },    Deleted { id: Uuid, reason: String },    Restored { id: Uuid },}// イベントを順番に適用して現在の状態を再構築fn rebuild_user(events: &[UserEvent]) -> Option<User> {    let mut user: Option<User> = None;    for event in events {        match event {            UserEvent::Created { id, name, email } => {                user = Some(User { id: *id, name: name.clone(), email: email.clone(), deleted: false });            }            UserEvent::Deleted { .. } => {                if let Some(ref mut u) = user { u.deleted = true; }            }            UserEvent::Restored { .. } => {                if let Some(ref mut u) = user { u.deleted = false; }            }            // ...        }    }    user.filter(|u| !u.deleted)}メリット:完全な監査ログ（ビジネスコンテキスト含む）任意の時点の状態を再現可能デバッグが容易デメリット:学習コストが高い読み取りパフォーマンスの課題（スナップショットが必要）既存システムへの導入が困難PostgreSQL パーティショニング大量データの削除が必要な場合、パーティショニングが有効。-- 月別パーティションテーブルCREATE TABLE events (    id UUID,    created_at TIMESTAMPTZ NOT NULL,    data JSONB) PARTITION BY RANGE (created_at);-- パーティションを作成CREATE TABLE events_2024_01 PARTITION OF events    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');CREATE TABLE events_2024_02 PARTITION OF events    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');-- 古いデータの削除: DELETEではなくDROPDROP TABLE events_2023_01;  -- 瞬時に完了、VACUUMも不要メリット:大量削除が一瞬（DROP TABLE）VACUUM負荷なしパーティションプルーニングで検索も高速デメリット:パーティションキーの設計が重要管理の複雑さ（pg_partman等のツール推奨）選択フローチャートRustで論理削除を安全に実装する6つのパターン代替手段を検討した上で、それでも論理削除が必要な場合。ここからは、Rustの型システムとPostgreSQLの機能を活用して、論理削除を安全に実装する具体的なパターンを紹介する。パターン1：Newtype Patternで状態を型として表現する最もRustらしいアプローチ。「有効なデータ」と「削除済みデータ」を別の型として定義する。use chrono::{DateTime, Utc};use sqlx::PgPool;use uuid::Uuid;/// 有効なユーザー（削除されていない）#[derive(Debug, sqlx::FromRow)]pub struct ActiveUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub created_at: DateTime<Utc>,}/// 削除済みユーザー#[derive(Debug, sqlx::FromRow)]pub struct DeletedUser {    pub id: Uuid,    pub name: String,    pub email: String,    pub deleted_at: DateTime<Utc>,}impl ActiveUser {    /// 有効なユーザーを1件取得    pub async fn find_by_id(        pool: &PgPool,        id: Uuid,    ) -> Result<Option<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            r#"            SELECT id, name, email, created_at            FROM users            WHERE id = $1 AND deleted_at IS NULL            "#,            id        )        .fetch_optional(pool)        .await    }    /// 論理削除を実行    pub async fn soft_delete(pool: &PgPool, id: Uuid) -> Result<bool, sqlx::Error> {        let result = sqlx::query!(            r#"            UPDATE users            SET deleted_at = NOW(), updated_at = NOW()            WHERE id = $1 AND deleted_at IS NULL            "#,            id        )        .execute(pool)        .await?;        Ok(result.rows_affected() > 0)    }}メリット：通常のコードパスでは削除済みデータに触れることが型的に不可能削除済みデータへのアクセスが明示的になるコンパイル時に安全性が保証されるパターン2：トレイトで共通インターフェースを定義する複数のエンティティで論理削除を扱う場合、トレイトで共通化する。use async_trait::async_trait;#[async_trait]pub trait SoftDeletable: Sized {    type Id;    async fn find_active(pool: &PgPool, id: Self::Id) -> Result<Option<Self>, sqlx::Error>;    async fn all_active(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error>;    async fn soft_delete(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;    async fn restore(pool: &PgPool, id: Self::Id) -> Result<bool, sqlx::Error>;}// ジェネリックな関数での利用async fn list_active<T: SoftDeletable>(pool: &PgPool) -> Result<Vec<T>, sqlx::Error> {    T::all_active(pool).await}パターン3：PostgreSQLビューで安全なデフォルトを作るデータベース側で「安全なデフォルト」を定義する。-- マイグレーション: 有効データのみを返すビューを作成CREATE VIEW active_users ASSELECT id, name, email, created_at, updated_atFROM usersWHERE deleted_at IS NULL;-- パーシャルインデックスで検索を高速化CREATE INDEX idx_users_active ON users(id) WHERE deleted_at IS NULL;impl ActiveUser {    /// ビューから取得（削除済みは絶対に含まれない）    pub async fn all(pool: &PgPool) -> Result<Vec<Self>, sqlx::Error> {        sqlx::query_as!(            Self,            "SELECT id, name, email, created_at, updated_at FROM active_users"        )        .fetch_all(pool)        .await    }}メリット：Rustコードでフィルタを忘れる心配がない他の言語やツール（psql、DBeaver等）からも安全JOINでも自動的にフィルタが適用されるパターン4：行レベルセキュリティ（RLS）で強制フィルタリングPostgreSQLのRLSを使って、データベースレベルで論理削除フィルタを強制する。-- 行レベルセキュリティを有効化ALTER TABLE users ENABLE ROW LEVEL SECURITY;-- デフォルトポリシー：削除済みは見えないCREATE POLICY users_active_only ON users    FOR SELECT    USING (        deleted_at IS NULL        OR current_setting('app.include_deleted', true) = 'true'    );/// 通常のクエリ（削除済みは自動的に除外される）pub async fn get_all_users(pool: &PgPool) -> Result<Vec<User>, sqlx::Error> {    sqlx::query_as!(User, "SELECT id, name, email FROM users")        .fetch_all(pool)        .await    // RLSにより、deleted_at IS NULLのレコードのみが返される}/// 削除済みを含める場合（明示的な設定が必要）pub async fn get_all_users_including_deleted(pool: &PgPool) -> Result<Vec<UserWithStatus>, sqlx::Error> {    let mut tx = pool.begin().await?;    sqlx::query("SET LOCAL app.include_deleted = 'true'")        .execute(&mut *tx)        .await?;    let users = sqlx::query_as!(UserWithStatus, "SELECT id, name, email, deleted_at FROM users")        .fetch_all(&mut *tx)        .await?;    tx.commit().await?;    Ok(users)}パターン5：リポジトリパターンで抽象化するレイヤードアーキテクチャでの実装パターン。#[async_trait]pub trait ReadRepository<T, Id> {    async fn find(&self, id: Id) -> Result<Option<T>, RepositoryError>;    async fn all(&self) -> Result<Vec<T>, RepositoryError>;    async fn exists(&self, id: Id) -> Result<bool, RepositoryError>;}#[async_trait]pub trait WriteRepository<T, Id>: ReadRepository<T, Id> {    type CreateInput;    type UpdateInput;    async fn create(&self, input: Self::CreateInput) -> Result<T, RepositoryError>;    async fn update(&self, id: Id, input: Self::UpdateInput) -> Result<T, RepositoryError>;    async fn delete(&self, id: Id) -> Result<bool, RepositoryError>; // 論理削除}リポジトリの実装内部で常に deleted_at IS NULL を適用することで、利用側はフィルタを意識する必要がなくなる。パターン6：マクロで定型コードを削減する毎回同じパターンを書くのは面倒なので、マクロで自動生成する。macro_rules! impl_soft_deletable {    ($struct:ident, table = $table:literal, id_type = $id_type:ty) => {        impl $struct {            pub async fn find_active(pool: &PgPool, id: $id_type) -> Result<Option<Self>, sqlx::Error> {                // 実装            }            pub async fn soft_delete(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }            pub async fn restore(pool: &PgPool, id: $id_type) -> Result<bool, sqlx::Error> {                // 実装            }        }    };}// 使用例impl_soft_deletable!(Comment, table = "comments", id_type = Uuid);パターン比較 パターン  型安全性  実装コスト  DB依存  推奨シーン  Newtype Pattern  高  中  低  型を重視するプロジェクト  トレイト抽象化  高  中〜高  低  複数エンティティがある場合  ビュー  中  低  高  シンプルなCRUD、多言語環境  RLS  高  中  高  マルチテナント、厳格なセキュリティ  リポジトリ  高  高  低  大規模プロジェクト、DDD  マクロ  中  低  低  定型コードを減らしたい 運用のベストプラクティス6つのパターンを紹介したが、どれか1つを選べば終わりではない。実際の運用では、これらを組み合わせて使う。そして、どのパターンを選んでも共通して守るべきルールがある。すべての対策を講じた上で、それでも deleted_at 方式を選ぶなら、以下を徹底する。必須チェックリスト□ ビューを作成し、アプリはビュー経由でアクセス□ パーシャルインデックスを作成□ リポジトリパターンで抽象化□ 削除済みデータのテストを全クエリに追加□ 定期的なアーカイブ処理を実装必ずビューを作るCREATE VIEW active_users AS SELECT * FROM users WHERE deleted_at IS NULL;アプリケーションは active_users にしかアクセスしない。必ずリポジトリパターンを使うpub trait UserRepository {    async fn find(&self, id: Uuid) -> Result<Option<User>, Error>;  // 常に有効のみ}必ずテストを書く#[test]fn deleted_users_are_not_returned() { /* ... */ }すべてのクエリに対して、このテストを義務化する。必ずパーシャルインデックスを作るCREATE INDEX idx_users_email_active ON users(email) WHERE deleted_at IS NULL;パフォーマンス劣化を最小限に抑える。必ず定期的にアーカイブする-- 1年以上前に削除されたデータをアーカイブテーブルに移動INSERT INTO archived_usersSELECT * FROM usersWHERE deleted_at < NOW() - INTERVAL '1 year';DELETE FROM usersWHERE deleted_at < NOW() - INTERVAL '1 year';本番テーブルの肥大化を防ぐ。おわりに論理削除の本質は、「このレコードは存在するが、存在しないことにしてほしい」という矛盾だ。この矛盾を無視して deleted_at を追加すると、WHERE句地獄、認知コスト、バグの温床という形で跳ね返ってくる。しかし、法規制・監査・誤操作復旧のため、論理削除が必要になる場面は確実に訪れる。そのとき、2つの選択肢がある。矛盾を解消する設計（Archiveテーブル、Event Sourcing）を選ぶか、矛盾を受け入れて型システムとデータベース機能で安全に管理するか。本記事ではRustの型システムとPostgreSQLの機能を活用した安全な実装パターンを紹介した。ただし、データベース設計は文脈次第で最適解が変わる。ここで紹介した方法が唯一の正解ではないので、自分のプロジェクトの要件に照らし合わせて判断してほしい。参考リンクAvoiding the soft delete anti-pattern - 論理削除がアンチパターンになる理由Soft Deletion Probably Isn't Worth It - 論理削除の代替手段の検討The Day Soft Deletes Caused Chaos - 論理削除が引き起こした実際の障害事例diesel-softdelete - DieselのためのSoft Delete拡張Soft deletion with PostgreSQL - PostgreSQLでの論理削除実装Beyond DELETE: Drop Partitions, Not Performance - パーティショニングによる削除最適化Temporal Tables and Event Sourcing - 代替アプローチの比較参考書籍達人に学ぶDB設計徹底指南書 第2版作者:ミック翔泳社Amazon達人に学ぶSQL徹底指南書 第2版 初級者で終わりたくないあなたへ作者:ミック翔泳社Amazon失敗から学ぶRDBの正しい歩き方 Software Design plus作者:曽根 壮大技術評論社AmazonSQLアンチパターン 第2版 ―データベースプログラミングで陥りがちな失敗とその対策作者:Bill Karwinオーム社Amazonセンスの良いSQLを書く技術　達人エンジニアが実践している３５の原則作者:ミックKADOKAWAAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[NeMo Guardrails: Putting the “Responsible” in AI]]></title>
            <link>https://daisuke1024akagawa.medium.com/nemo-guardrails-putting-the-responsible-in-ai-ef7e0bfffea0?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/nemo-guardrails-putting-the-responsible-in-ai-ef7e0bfffea0?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Tue, 23 Dec 2025 12:02:25 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[書評や要約は「圧縮」ではなく「変換」であり、「変換」に価値がある。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/23/111651</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/23/111651</guid>
            <pubDate>Tue, 23 Dec 2025 02:16:51 GMT</pubDate>
            <content:encoded><![CDATA[タイトルがそのままゴールなのですがダラダラ書きます。はじめにある技術書の要約を読んで、「なるほど、この本の主張はこういうことか」と納得した。数ヶ月後、原著を手に取って驚いた。要約で「核心」とされていた部分は、実は本全体の一部に過ぎなかった。著者が本当に伝えたかったことは、要約では一行も触れられていなかったのだ。技術書、非技術書に限らず、書評や要約を読んでいると、ある違和感に気づく。これは「圧縮」ではなく、本質的に異なるものではないか。原著者の思考プロセスは消失し、要約者のフィルタリングと優先度により情報が再構成される。同じ本から異なる要約が生まれる。そのコンテキストを知らずに読むと、原典でなく要約者の思想を取り込んでしまう。これはデジタル圧縮に例えるなら、可逆圧縮ではなく非可逆変換だ。ZIPファイルのように元に戻せる圧縮ではなく、JPEGのように一度変換すれば二度と元には戻らない変換。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズム——この場合は要約者——の判断に依存する。でもここで誤解してほしくないのは、これは要約や書評を否定する話ではないということだ。むしろ、その本質を正しく理解し、積極的に活用するための話だ。要約や書評は「圧縮」ではなく「変換」であり、その変換には独自の価値がある。原著の劣化コピーではなく、原著から触発された新しい思考の産物として。原著への入り口として、あるいは原著と対話する形で展開される考察として。そしてその価値を最大限に引き出すには、私たちが変換というプロセスを意識し、批判的に読み、創造的に使いこなす必要がある。同時に、本当に大切な本については、時間をかけてちゃんと読む——その価値を見失わないことも重要だ。なぜなら、本をちゃんと読むことは、自分を長い時間をかけて変容させることだから。そしてその変容は、要約では決して起きないから。圧縮という幻想私たちは「要約」という言葉を、まるでファイルの圧縮のように捉えている。元の情報を小さくしただけ、重要な部分だけを取り出しただけ、だから本質は変わらない——そう思い込んでいる。しかし本当は違う。デジタルの世界には二つの圧縮がある。ZIPファイルのような可逆圧縮と、JPEGのような非可逆変換。前者は展開すれば元に戻るが、後者は一度変換すれば二度と元には戻らない。情報は永久に失われ、何を残して何を捨てるかは、変換アルゴリズムの設計思想に依存する。書評や要約は、後者だ。これは単なる比喩ではない。要約という行為は、情報を小さくしているのではなく、情報を別の何かに変えているのだ。そしてその過程で、何かが——多くの場合、最も大切な何かが——失われる。要約という名の変換要約のプロセスを観察してみるといい。そこには、本人も気づいていない、いくつもの「変換」が起きている。選択的フィルタリングという暴力要約者は、自分が「重要だ」と判断した部分を抽出する。しかしこの「重要性」は、極めて主観的だ。要約者の経験、専門性、価値観、そして何より要約者が今抱えている問題意識——これらすべてが、無意識のフィルターとして機能する。マーケティング担当者が読む技術書と、エンジニアが読む同じ技術書では、心に残る章が違う。当然だ。でもこれは、どちらかが間違っているという話ではない。同じ本から、異なる意味が立ち上がっているだけだ。そしてその意味の違いは、読者ではなく、読み方によって生まれる。要約という行為は、この「読み方」を一つに固定する。要約者の読み方が、唯一の読み方として提示される。そして要約を読む私たちは、その固定された読み方を、本の内容そのものだと錯覚する。文脈の切断という喪失著者は意図的に章を配置する。第一章から第十章へと、徐々に論理を積み上げていく。前の章の具体例が、後の章の理論の基礎になる。ある議論は、数章前の別の議論を前提としている。この「流れ」は、本の核心的な要素の一つだ。理解とは情報の構造化だからだ。著者が用意した順序で読むことで、私たちの頭の中に、新しい思考の枠組みが少しずつ形成されていく。でも要約は、この流れを切断する。第三章の結論、第七章の重要なポイント、第十章のまとめ——それらは箇条書きになって並べられ、互いの繋がりは失われる。結論だけが残り、そこに至るまでの思考の階段は消える。そして多くの場合、その階段こそが、最も価値のある学びだったのだ。言語の置き換えという変質著者が選んだ言葉には、意味がある。その比喩、その言い回し、その微妙なニュアンス——それらはすべて、著者が伝えたい何かを形にするために、慎重に選ばれている。しかし要約者は、それを自分の言葉に置き換える。分かりやすく、簡潔に、読みやすく。善意からの行為だ。しかしこの過程で、著者の「声」は失われる。翻訳と同じだ。どれだけ優れた翻訳でも、原文の響きは失われる。要約も同じ。どれだけ丁寧な要約でも、著者が選んだ言葉の持つ微妙な意味の重なりは、消えてしまう。そして私たちは、その消失に気づかない。思考プロセスの消失という致命的な欠落最も大きな喪失は、これだ。著者が試行錯誤の末に辿り着いた結論。一度は正しいと思ったが、後に間違いだと気づいた考え。検討したが採用しなかった別のアプローチ。考えを変えた転機となった出来事。こうした思考の軌跡は、要約では「結論」だけが残る。「著者はこう主張している」と。でも、なぜその主張に至ったのか、どんな葛藤があったのか、何を捨てて何を選んだのか——そのすべてが消える。けれど、学びとは結論を知ることではなく、その結論に至るプロセスを追体験することだ。著者の思考の軌跡を辿ることで、私たちの思考の枠組みが変わる。結論だけを知っても、それは情報の追加にすぎず、思考の変容は起きない。要約は、この核心を、最初に捨てる。同じ本、異なる要約の謎興味深い実験をしてみるといい。同じ一冊の本について、複数の要約を読んでみるといい。驚くほど違う内容が書かれている。ある経営書を読んだ場合を想像してみよう。スタートアップの創業者は、リスクテイクと革新の章を強調するかもしれない。彼らにとって重要なのは「いかに新しいことを試すか」だから。大企業の管理職は、組織マネジメントと持続可能性の部分に注目するだろう。彼らが直面しているのは、既存の組織をいかに動かすかという問題だから。学者は、理論的フレームワークと研究手法に焦点を当てる。彼らが関心を持つのは、この本がどんな学術的文脈に位置するかだから。それぞれの要約は「正しい」。でもそれは、元の本ではない。要約者のレンズを通して屈折した像だ。そして恐ろしいことに、私たちはその屈折を、見ることができない。なぜか。要約には、要約者の視点が明示されないからだ。「私はスタートアップ創業者として、この本からリスクテイクの部分に注目した」とは書かれない。ただ「この本の重要なポイントは」と書かれる。まるで客観的な事実であるかのように。しかし客観的な要約など、存在しない。すべての要約は、誰かの主観を通した変換だ。その主観は、透明なレンズのように見えて、実は色付きのフィルターなのだ。「読んだ」と「読んでいない」という曖昧な境界私たちは「本を読んだ」という言葉を単純に使いすぎている。ピエール・バイヤールの『読んでいない本について堂々と語る方法』では、読書という行為を興味深く分類している。バイヤールは読書を次のように区分けする。UB（unread book） ——まったく読んでいない本SB（skimmed book） ——ざっと目を通した本HB（heard about book） ——人から聞いた本、あるいは書評で知った本FB（forgotten book） ——読んだが内容を忘れた本この分類を見て、私たちは気づく。「読んだ」と「読んでいない」という二項対立は、実は単純なものではないのだと。最後のページまで目を通したが内容をほとんど覚えていない本と、要約だけ読んだが著者の主張をよく理解している本——どちらが「読んだ」と言えるのか。人から聞いた話を通じてその本の核心的なアイデアに触れた場合と、本は買ったが積読のまま放置している場合——どちらが「読んでいない」と言えるのか。答えは簡単ではない。というより、この問い自体が間違っているのかもしれない。問われるのは「読んだか読んでいないか」という形式的な区分けではなく、その本とどのような関係を結んでいるか、その本を通じてどのような思考を展開できるか——そういった実質的な次元なのだ。読んでいない本について語る「状況」バイヤールは、読んでいない本について語ることの不可避性を指摘する。私たちは日常的に、読んでいない本について語らざるを得ない状況に置かれている。会議で誰かが本を引用する。読んだことはないが、その場で意見を求められる。友人が「あの本、どう思う？」と訊いてくる。正直に「読んでない」と言えば会話は終わるが、書評で得た知識をもとに語れば、豊かな対話が生まれる。就職面接で「最近読んだ本は？」と訊かれる。最後まで読了した本だけを答えの対象にすれば、選択肢は著しく狭まる。これらの状況を具体的に検討してみると、面白いことが見えてくる。本について語ることは、必ずしも本を最後まで読了していることを前提としていない。むしろ、本の周辺にある言説——書評、要約、他者の解釈、断片的な引用——これらを媒介にして語ることが、実は創造的な思考を生み出すことがある。友人が薦めた本について、その友人の語り口から想像を膨らませて議論する。その過程で、原著にはない新しい視点が生まれることがある。書評を読んで著者の意図を「誤読」し、その誤読から独自の考察を展開する。その考察が、時として原著を超える洞察に至ることもある。つまり、本について語ることは、必ずしも本を「正確に」理解することを目的としていない。本を触媒として、自分の思考を展開すること——それが本質なのだ。要約という考察の可能性ここで視点を変えてみよう。要約や書評を、単なる「劣化コピー」ではなく、一種の「考察」として捉え直すとどうなるか。要約者は、本を読んで何かを感じ取る。その「何か」を言語化しようとする。この過程は、実は高度に創造的な行為だ。無数の情報の中から何を選び、どう配置し、どう言葉にするか——この選択と構成の過程で、要約者独自の思考が立ち上がる。だから、優れた書評や要約は、原著とは別の価値を持つ。それは原著の「圧縮版」ではなく、原著から触発された、要約者の「考察」なのだ。私自身、年間でかなりの書評を作っている。しかし公開しているのはごくごく一部だ。なぜか。私はあまり有能な方ではないから、書籍を漫然と読んでも深い学びを得ることができない。だから書評を書く。書評を書くという行為を通じて、自分が何を理解し、何を理解していないのかを明確にする。どこに引っかかったのか、どこが腑に落ちたのか——それを言語化することで、初めて本当の理解が生まれる。公開しているものは、作った書評の中で「公開して良いかな」と思った文章を加筆修正したものだ。つまり、書評を書く行為そのものは、公開のためではなく、自分の理解を深めるためのものなのだ。たとえば、ある技術書について複数のエンジニアが書評を書いたとする。一人は実装の観点から、一人は設計思想の観点から、一人は歴史的文脈の観点から語る。これらの書評を読むことで、私たちは原著が持つ多面性に触れることができる。そしてそれぞれの書評が、原著を読むための異なる「補助線」になる。この意味で、要約や書評は原著を補完し、豊かにする。原著だけを読むよりも、原著と複数の書評を読む方が、理解が深まることがある。なぜなら、一冊の本が持つ可能性を、複数の視点から照らし出すことができるからだ。ファスト教養という時代の文脈ただし、ここで注意すべき点がある。要約や書評が「考察」として価値を持つのは、それが原著への入り口として機能するか、あるいは原著と対話する形で展開される場合だ。現代には「ファスト教養」とでも呼ぶべき現象がある。短時間で「教養」を身につけたように見せるための、効率化された知識の消費。要約を読んで「読んだ」と言い、書評を見て「理解した」と思い込む。そこには、本との本当の対話はない。ファスト教養の問題は、効率性そのものではない。問題は、本と自分の間に常に誰か（要約者、解説者、インフルエンサー）が介在し、自分で考える機会が失われることだ。バイヤールが指摘するように、読んでいない本について語ることは、自分で思考し言語化する状況では創造的な行為になり得る。しかしそれは、自分の頭で考え、自分の言葉で語る場合に限る。誰かの要約をコピー&ペーストして語るのは、創造ではなく模倣だ。変換を活用する五つの方法では、要約や書評という「変換」を、どう活用すべきなのか。1. 要約者の視点を意識する要約を読むとき、「これは誰の視点か」を常に問う。その人の専門性、立場、問題意識——それらを意識することで、フィルターの存在が見えてくる。そして「では自分なら、どこに注目するか」と考える。2. 複数の解釈を並置する一つの要約だけを読むのではなく、複数の異なる視点からの解釈を集める。それらを比較することで、本が持つ多面性が見えてくる。そして何より、「絶対的な正解」など存在しないことが分かる。3. 要約を「問い」として読む要約を「答え」として受け取るのではなく、「問い」として読む。「この要約者はなぜこの部分を重要だと判断したのか」「省略された部分には何があったのか」——そう問うことで、要約は思考の出発点になる。4. 自分なりの考察を加える要約を読んで、自分なりの考察を加えてみる。「自分の経験ではどうか」「別の文脈ではどうなるか」「反対の立場から見たらどうか」——そうやって思考を展開することで、要約は単なる情報から、思考の触媒へと変わる。5. 原典への道標として使うそして何より、要約を原典への道標として使うことだ。要約で興味を持ったら原典を読む。要約で疑問を持ったら原典で確認する。要約と原典の間を行き来することで、理解は深まる。読んでいない本について語る際の倫理バイヤールは、読んでいない本について語る際に注意すべき点を挙げている。第一に、読んでいないことを隠す必要はない。「詳しくは読んでいないが」「書評で読んだ限りでは」——そう前置きすることで、誠実さを保ちながら対話を続けられる。第二に、自分の解釈を絶対化しない。「私はこう理解した」「私にはこう見える」——主語を「私」にすることで、それが一つの視点に過ぎないことを示す。第三に、他者の解釈を尊重する。要約や書評は、誰かの真剣な思考の結果だ。それを軽んじることなく、一つの有効な視点として受け止める。そして第四に、思考を停止させないことだ。要約を読んで「分かった」で終わらせず、そこから自分なりの思考を展開する。これらの点を意識すれば、読んでいない本について語ることは、単なる知ったかぶりではなく、創造的な知的活動になり得る。要約や書評を通じて、新しい視点を獲得し、自分の思考を深め、時には原著を超える洞察に至ることさえ可能なのだ。書評・要約と著作権——変換者の責任変換の価値を語るとき、避けて通れない現実がある。それは法律だ。私たちが要約や書評を「考察」として価値あるものにできるのは、それが著作者の権利を侵害しない範囲で行われる場合に限る。自分の良し悪しだけで判断できる問題ではない。著作権法では、著作物を「翻案」する権利は著作権者に帰属する。要約はこの「翻案」に該当する可能性がある。一方で、「引用」は一定の条件を満たせば許諾なく行える。興味深いのは判例だ。「血液型と性格」事件（東京地判平成10年）では、やむを得ない範囲での要約引用は著作権侵害にならないと判断された。全文をそのまま引用するより、要約する方が著作権者の利益を損なわない場合があるという理由だ。ここに、変換という行為の本質が見える。情報そのものには著作権はないが、表現には著作権がある。著者の文章表現をそのまま使うのは問題になり得る。しかし、その情報を自分の言葉で表現し直すのであれば——つまり、本当の意味で「変換」するのであれば——著作権侵害には該当しにくい。これは単なる法的な制約ではない。むしろ、変換者としての私たちに課された創造的な責任だ。他人の言葉をコピーするのではなく、自分の言葉で語り直す。その過程で、私たちは否応なく考えることを強いられる。要約や書評は、著作者と読者をつなぐ架け橋になり得る。しかしそれは、著作者の権利を尊重し、自分の言葉で語るという責任を引き受けた上でのことだ。変換の二面性要約や書評という「変換」は、原著者の思想と要約者の解釈が混ざり合ったハイブリッドだ。そしてその混ざり具合は、多くの場合見えない。ここには確かに危険性がある。要約を原著そのものだと錯覚し、要約者の解釈を著者の思想だと思い込む。そして気づかないうちに、自分で考える機会を失う。著者の思想と対峙し、自分の経験と照らし合わせ、時には反論し、格闘する——その過程が省略される。でも同時に、ここには可能性もある。要約や書評は、原著にはない新しい視点を提供してくれることがある。著者自身も気づいていなかった含意を、要約者が読み取ることがある。異なる文脈に置き直すことで、原著が持つ新しい意味が立ち上がることがある。つまり、変換は単なる劣化ではなく、一種の創造なのだ。原著というテキストに、要約者という読者が介入することで、新しい意味が生成される。そしてその新しい意味は、原著を豊かにすることもあれば、原著を歪めることもある。問題は変換そのものではなく、私たちがその変換を意識しているかどうかだ。変換を透明なものとして扱えば、それは欺瞞になる。でも変換を変換として認識し、その特性を理解した上で活用すれば、それは強力な思考のツールになる。現代という時代の加速装置そして現代という時代が、この問題を加速させている。インスタント化という麻薬スマホを開けば、10分で読める要約が溢れている。YouTubeには、本の内容を解説する動画が無数にある。ChatGPTに聞けば、数秒で本の要約を生成してくれる。便利だ。効率的だ。時間を節約できる。しかし私たちは、その便利さの代償を理解しているだろうか。私たちの脳は、インスタントな刺激に適応してしまっている。10分で読める要約、数秒で生成されるAIの解説、流し読みで済む箇条書き——これらに慣れた脳は、長い文章を追うこと、モヤモヤを抱えること、結論が出ないまま考え続けることに、耐えられなくなっている。スマホを見すぎて長い文章が頭に入らないエンジニアは多い。メンターしている若者も「技術書を読むのがしんどい」と言っていた。しかし一週間デジタルデトックスをしたところ、普通に読めるようになった。これは脳が「即時反応モード」から「深く考えるモード」に戻ったからだ。本を読むことは、時間がかかる。最初は分からない。モヤモヤする。何度も読み返す。考える。また読む。この不快で面倒なプロセスを経て、ようやく理解が生まれる。しかしインスタントな要約は、このプロセスをスキップさせる。分からないまま待つ必要がなく、モヤモヤを抱える必要もなく、すぐに「分かった」という感覚が得られる。この即座の満足は、甘い。甘すぎる。そして一度この甘さを知ってしまうと、本を読むという苦行には戻れなくなる。AI要約という危機AIの発展により、要約はさらに加速する。数秒で本を要約し、重要なポイントを箇条書きにし、分かりやすく説明してくれる。思考とは、情報を「受け取る」ことではなく、情報と「格闘する」ことだ。著者の主張に疑問を持ち、自分の経験と照らし合わせ、別の解釈の可能性を探る——この格闘が、思考を育てる。しかしAI要約やファスト教養は、この格闘を省略する。すぐに「分かった」という感覚を提供し、考える時間を奪う。私たちは、知識は増えているが、思考は深まらない——そんな状態に陥る。孤独の喪失という静かな危機もう一つ、見落とされがちな喪失がある。それは、本と一対一で向き合う時間だ。スマホがなかった時代、本を読むとは孤独な行為だった。自分と本だけ。他の誰も介在しない。理解できなくても、退屈でも、そこに居続けるしかなかった。しかし今は違う。少し難しい箇所に来れば、すぐにスマホに手が伸びる。「この部分、要約ないかな」と検索する。あるいは「ちょっと休憩」と言って、SNSを開く。私たちは、孤独に耐えられなくなっている。モヤモヤを抱えたまま、一人で考え続けることができなくなっている。でも本を読むという行為の本質は、この孤独にある。自分の頭で考え、自分の言葉で理解しようとする。誰も助けてくれない、その孤立した状態で、著者の思想と格闘する。この孤独な格闘を経てこそ、本当の意味での理解が生まれる。でも要約は、この孤独を奪う。常に誰かが横にいて、「正解はこれだよ」と教えてくれる。その優しさが、私たちから考える力を奪っていく。本を読むということの本質では、本を読むとは、本当は何をすることなのか。それは、自分を変えることだ。長い時間をかけて、ゆっくりと、確実に。理解とは変容である本を読んで「理解した」というとき、私たちは何を指しているのか。情報を獲得したこと？　結論を知ったこと？違う。理解とは、自分の思考の枠組みが変わることだ。本を読む前と読んだ後で、同じ現象を見ても、違うものが見えるようになる。同じ問題に直面しても、違う解決策が浮かぶようになる。同じ言葉を聞いても、違う意味が響くようになる。これが理解だ。情報の追加ではなく、認識の変容。そしてこの変容は、時間をかけて、ゆっくりと起きる。著者の思考を辿る。分からない箇所で立ち止まる。自分の経験と照らし合わせる。疑問を持つ。また読む。少しずつ、著者の視点が自分の中に入ってくる。そして気づけば、自分の見ている世界が、少し変わっている。この変容は、要約では起きない。なぜなら要約には、この「時間」が含まれていないからだ。結論だけを知っても、それは自分の外側にある情報のままだ。内側に入ってこない。格闘としての読書本を読むとは、著者と格闘することだ。著者の主張を理解しようとする。でも納得できない部分がある。「本当にそうだろうか」と疑問を持つ。自分の経験では違うと感じる。でも著者はこう言っている。なぜだろう。何が違うのか。この格闘の過程で、私たちは考える。自分の前提を疑い、著者の前提を探り、両者の違いを見つけようとする。そして時には、自分が間違っていたことに気づく。あるいは、著者の限界を見抜く。どちらにせよ、この格闘を経て、私たちの思考は深まる。でも要約は、この格闘を省略する。著者の主張は、すでに要約者によって消化されている。疑問を持つ余地もなく、「重要なポイントはこれです」と提示される。私たちは、受け取るだけだ。格闘がなければ、成長もない。反復という学び本は、一度読んで終わりではない。本当に価値のある本は、何度も読み返す価値がある。なぜか。同じ本でも、読むたびに違うものが見えるからだ。一年前に読んだとき、心に響いた章がある。でも今読み返すと、別の章が響く。当時は流し読みした箇所が、今は重要に思える。著者の何気ない一言が、今の自分の状況と重なって、深い意味を持って迫ってくる。これは、私たちが変わったからだ。経験を積み、視点が変わり、問題意識が変わった。同じ本を読んでも、違う自分が読んでいる。だから、違うものが見える。この反復的な読書によって、本は私たちの中で育っていく。最初は30%の理解だったものが、二度目で50%になり、三度目で70%になる。そして何度目かの読書で、「ああ、著者はこのことを言いたかったのか」と、ようやく本当の理解に到達する。でも要約は、この反復を許さない。一度読めば終わりだ。すべてが書かれている。何度読んでも、同じことしか書いていない。要約は、本の成長を止める。そして私たちの成長も、止める。余白という豊かさ本には、余白がある。著者が明示的に書いていないこと、行間に隠れた意味、読者に委ねられた解釈の余地——これらの余白が、本を豊かにする。余白があるから、私たちは考える。「著者はここで何を言おうとしているのか」「この比喩は何を意味するのか」「なぜこの順序で書いたのか」。そして余白があるから、読者ごとに違う解釈が生まれる。同じ本を読んでも、ある人はビジネスのヒントを得て、ある人は人生の指針を見出し、ある人は哲学的な洞察を得る。この多様性こそが、本の価値だ。一つの正解があるのではなく、無数の読み方が可能である——その豊かさが、本を読む喜びを生む。でも要約は、この余白を埋める。すべてを明示し、すべてを説明し、一つの解釈に固定する。「この本の意味はこれです」と。余白が消えたとき、本は死ぬ。そして読む喜びも、死ぬ。要約の正しい役割要約は、門だ。家ではない。本を読むかどうか判断するために、要約を読む。これは合理的だ。すべての本を精読する時間は、誰にもない。要約を読んで、「この本は自分に必要そうだ」「この本は今の自分には合わないかもしれない」と判断する。この使い方なら、要約は有用なツールだ。あるいは、すでに読んだ本の要約を読む。記憶を呼び覚ますトリガーとして。「ああ、そうだった」と思い出すために。これも正しい使い方だ。問題は、要約を読んで「本を読んだ」と思うことだ。門をくぐって「家に入った」と思うことだ。要約は入口であって、目的地ではない。複数の要約を読むという戦略一つの本について、複数の要約を読んでみる。すると、面白いことが見えてくる。要約ごとに、強調されている部分が違う。ある要約が重要だと言っている章を、別の要約は触れてもいない。ある要約の解釈と、別の要約の解釈が、矛盾している。この違いこそが、要約の本質を暴く。要約は客観的な事実ではなく、誰かの主観的な解釈だということが、複数の要約を比較することで見えてくる。そして同時に、本の多面性も見えてくる。一つの本が、いかに豊かで、いかに多様な読み方を許容しているか——それを複数の要約から、間接的に感じ取ることができる。ただし、この戦略も、本を読む代わりにはならない。あくまで、本を読む前の準備、あるいは読んだ後の確認として機能する。要約者のバックグラウンドを知るという習慣「誰が要約しているのか」に注目する習慣を持つといい。その人の専門性は何か。どんな立場で、どんな問題意識を持っているか。どんなバイアスを持っている可能性があるか。これを意識するだけで、要約の読み方が変わる。「ああ、この人はマーケティングの専門家だから、この部分を強調しているのか」「この人はエンジニアだから、技術的な側面に注目しているのか」。要約者のフィルターが見えてくる。そのフィルターを通して、何が強調され、何が省略されているのかが、推測できるようになる。そして何より、「では自分が読んだら、どこに注目するだろうか」と考えることだ。要約者と自分の違いを意識することで、自分のフィルターも見えてくる。自分で要約してみるという修行最も効果的な学びは、自分で要約を書いてみることだ。本を読んで、自分なりの要約を書く。すると、いかに難しいかが分かる。何を残して何を捨てるか、その判断の難しさ。著者の言葉を自分の言葉に置き換える際の、意味のズレ。思考のプロセスを、結論だけに圧縮することの暴力性。この体験を経ると、要約の限界が肌で分かる。そして要約を読むときの姿勢が、変わる。「これは要約者の解釈である」「著者の本当の意図は、もっと複雑かもしれない」「失われた部分があるはずだ」——そう意識しながら読むようになる。自分で要約を書くことは、要約に対する批判的読解力を育てる。読書リテラシーという現代の必須能力情報が溢れる時代だからこそ、必要なのは情報の「形式」を理解するメタ認知だ。速読という幻想を捨てる「速く読む」ことを目標にするのは、間違っている。大切なのは、速さではなく、深さだ。一冊の本を一時間で読むことより、一冊の本と一ヶ月向き合うことの方が、はるかに価値がある。もちろん、すべての本をそう読む必要はない。流し読みでいい本もあるし、要約で十分な本もある。でも少なくとも、年に数冊は、時間をかけて、深く読む本があっていい。その数冊が、あなたを変える。要約を百冊読むより、原典を三冊、じっくり読む方が、思考は深まる。速読を目指すのではなく、深読を目指す。これが、現代の読書リテラシーだ。不完全な理解を受け入れる勇気本を読んでも、すべては理解できない。これは当たり前のことだ。著者が何年もかけて考えてきたことを、数時間や数日ですべて理解できるはずがない。分からない部分があって当然だし、誤読することもある。しかし私たちは、この不完全さを受け入れられない。すぐに「分かった」という感覚を求めて、要約に逃げる。肝心なのは、不完全な理解を抱えたまま、読み続けることだ。分からない部分を、分からないまま保留しておく。「いつか分かるかもしれない」と思いながら、先に進む。この「分からなさ」を抱える力が、深い理解への鍵だ。すぐに「分かった」と結論づけず、モヤモヤを抱え続ける。そして時間をかけて、徐々に理解が深まっていく。要約は、この不完全さを許さない。すべてを明快に説明し、すべてを分かりやすくする。でもその分かりやすさは、理解の深さを犠牲にしている。不完全さを受け入れる勇気を持つこと。これが、本を読むということの本質だ。変容には時間がかかる最後に、最も重要なことを言いたい。本を読むことは、自分を変えることだ。そして変容には、時間がかかる。本を読んで即座に変わる、ということは、ほとんど起きない。自己啓発書を読んで「明日から変わろう」と思っても、明日になれば何も変わっていない。でもそれは、本が悪いのではなく、私たちの期待が間違っているのだ。本による変容は、もっとゆっくりと起きる。読んだ内容は、すぐには自分のものにならない。でも心のどこかに引っかかる。数週間後にふと思い出し、数ヶ月後に似た状況で無意識に浮かんでくる。そして気づけば、半年前の自分とは少し違う判断をしている。この反芻の過程で、本の内容は私たちの中に染み込んでいく。最初は外側にあった考え方が、徐々に内側に入ってくる。要約は、この反芻を許さない。分かりやすく整理されすぎていて、心に引っかからないからだ。百冊の本という選択では、どんな本を読むべきなのか。すべての本を深く読む時間は、誰にもない。だからこそ、選択が必要になる。ある人は言った。「私の人生を変えた一冊がある」と。その本を、彼は何度も読み返している。二十代で初めて読み、三十代で読み返し、四十代でまた読む。そして読むたびに、違うものが見える。これが、本との本当の付き合い方だ。一度読んで終わりではなく、人生を通じて対話し続ける。そしてこの長い対話を通じて、本は私たちの一部になる。著者の思想が、自分の思想と混ざり合い、区別がつかなくなる。「これは本で読んだ考えか、自分で考えたことか」分からなくなる。でもそれでいい。それこそが、本を読むことの到達点だ。ただし、一冊の本をそこまで深く読むのは難しい。だから私は思う。本は、百冊あればいい。これは、大量の本の中から自分にとっての正典となる百冊を、自分の力で選ぶということだ。世間で話題の本、ベストセラー、有名人が推薦する本——それらを漫然と読むのではなく、自分にとって本当に大切な百冊を見極める。本棚に深みがあり見栄えの良い本を並べておけば、すぐに読めなくても次第に自分が本に似合う人間になれる。これは不思議な現象だが、本当だ。手元に置いた本は、読まなくても、その存在だけで私たちに影響を与える。「いつか読もう」と思いながら本棚にある本は、私たちに問いかけ続ける。「お前はまだ、私を読む準備ができていないのか」と。読む本を選ぶときには、二つの軸が必要だ。一つは、自分がはまっている関心事を深堀りするように選ぶ。自分の興味、自分の問題意識、自分が今向き合っている課題——それらに関連する本を追いかける。これは内側からの選択だ。もう一つは、定評のある必読リストに沿って選び、外からの影響で自分を変えること。古典と呼ばれる本、専門家が推薦する本、時代を超えて読み継がれている本——自分の興味の外側にある本を、意識的に選ぶ。これは外側からの選択だ。この二つのバランスが、百冊を豊かにする。自分の関心だけで選べば視野が狭くなり、他人の推薦だけで選べば自分を見失う。両方を組み合わせることで、百冊は自分を映す鏡であると同時に、自分を超える窓になる。おわりに書評や要約は、可逆圧縮ではなく非可逆変換だ。それは欠陥ではなく、本質だ。変換を透明なものとして扱えば欺瞞になる。変換として認識し、活用すれば強力なツールになる。要約を入り口として本を探索し、気になったものは原典に当たる。自分にとっての百冊を見極め、その百冊は時間をかけて深く読み、人生を通じて対話し続ける。これは効率性の問題ではない。どう思考するか、どう生きるかという、知的態度の問題だ。溢れる情報の海で溺れないために必要なのは、泳ぐ速度ではない。情報の形式を見抜く目と、それを使いこなす知恵だ。そして何より、自分で考える時間を守ること。誰かの変換を受け取るだけでなく、自分自身が変換者になること。本と格闘し、自分の言葉で語り直し、その過程で少しずつ変わっていくこと。私は今日も、まだ読み終えていない本を開く。昨日とは少し違う自分が、違うページを読んでいる。参考書籍百冊で耕す〈自由に、なる〉ための読書術作者:近藤 康太郎ＣＥメディアハウスAmazon庭の話作者:宇野 常寛講談社Amazon書評の仕事 (ワニブックスPLUS新書)作者:印南 敦史ワニブックスAmazonニッポンの書評 (光文社新書)作者:豊崎 由美光文社Amazonビブリオバトル　本を知り人を知る書評ゲーム作者:谷口忠大文藝春秋Amazon世界は知財でできている (講談社現代新書)作者:稲穂健市講談社Amazon読んでいない本について堂々と語る方法 (ちくま学芸文庫)作者:ピエール・バイヤール,大浦康介筑摩書房Amazon勉強の哲学　来たるべきバカのために　増補版 (文春文庫)作者:千葉 雅也文藝春秋Amazonセンスの哲学作者:千葉 雅也文藝春秋Amazon武器になる哲学 人生を生き抜くための哲学・思想のキーコンセプト50 (角川文庫)作者:山口 周KADOKAWAAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazonファスト教養　10分で答えが欲しい人たち (集英社新書)作者:レジー集英社Amazon映画を早送りで観る人たち～ファスト映画・ネタバレ――コンテンツ消費の現在形～ (光文社新書)作者:稲田 豊史光文社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[The “No-Headache” Guide to Provisioning GPUs with Brev]]></title>
            <link>https://daisuke1024akagawa.medium.com/the-no-headache-guide-to-provisioning-gpus-with-brev-ac133834f7f4?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/the-no-headache-guide-to-provisioning-gpus-with-brev-ac133834f7f4?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Mon, 22 Dec 2025 10:32:04 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[なぜ「何でも作れる時代」に私は作れないのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</guid>
            <pubDate>Mon, 22 Dec 2025 04:55:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめに年末、2025年を振り返る。フォロワーは7倍になった。副業も順調。書籍の執筆や翻訳にも関わった。登壇の依頼も増えた。どこからどう見ても、良い年だったはずだ。なのに、胸の奥に澱のようなものが溜まっている。コードは書いた。山ほど書いた。でもそれは、誰かに頼まれたコードだ。お金になるコード。評価されるコード。「これを作ってください」と言われて、「はい」と答えて、作ったコード。自分のためのOSSも、作った。公開もした。そこそこ使われもした。でも、そこそこ止まりだ。「これが俺の代表作です」と言えるものが、ない。スターはついた。ダウンロードもされた。いくつかは今でも自分で使っている。完走した。自分なりに頑張った。でも、「代表作」と呼べるインパクトには届かなかった。厄介なことに、nwiizoというアカウントは大きくなってしまった。フォロワーが増えた分、「代表作」のハードルも上がっている。昔なら「動くものを公開した」で満足できた。今は違う。期待値が上がった分、自分で自分の首を絞めている。でも、諦めたくない。代表作を持つソフトウェアエンジニアに憧れて、この道に入った。あの人みたいになりたい、と思った先輩たちがいる。彼らのようにはなれていない。でも、まだ諦めたくない。新しいプロジェクトを始めようとするたび、手が止まる。「既存のツールで十分じゃないか」「誰が使うんだ、これ」。もっともらしい問いを自分に投げかけて、そのまま手を下ろす。完走したプロジェクトはある。でも、次の一歩が踏み出せない。検証のふりをした、逃避だ。「作らなくていい理由」を探して、見つけて、安心している。AIは「どう作るか」を教えてくれる。でも「何を作るか」は教えてくれない。技術力はもうボトルネックじゃない。足りないのは、決断だ。覚悟だ。「これを作る」と宣言して、不確実性の中に飛び込む蛮勇だ。私は「隙間家具屋」を自称してきた。大きな家具は作らない。洗濯機と壁の間の収納。冷蔵庫の上のラック。誰も気にしないけれど、あると少し楽になる小さなもの。それを作るのが好きだった。はずだった。2025年、隙間を見つける目は曇っていなかった。手も動いた。完走もした。でも、「これだ」という手応えが残らなかった。副業は収入になる。登壇は評価される。ブログはフォロワーが増える。全部、目に見えるリターンがある。OSSは違う。作っても誰にも使われないかもしれない。時間を注いでも、何も返ってこないかもしれない。その「かもしれない」に怯えて、私は確実なほうへ流れやすかった。OSSは作った。完走もした。でも、賭け金を上げられなかった。時間を注ぎ込むより、確実なリターンがある副業や登壇に逃げた。結果、そこそこ止まり。「これだ」と言えるものは掴めなかった。問題は、才能がないことだけじゃない。問題は、狂えなかったことだ。どこにも振り切れなかった。副業も、登壇も、OSSも、全部やりたかった。全部にいい顔をして、どれにも本気を出せなかった。半端な賭け金には、半端なリターンしか返ってこない。当たり前のことだ。このブログでは、「狂って量をやって、そこから引き算する」ための思考法を書く。 speakerdeck.com結論を先に言う。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。ポジティブケイパビリティとネガティブケイパビリティ「ネガティブ・ケイパビリティ」という概念がある。不確実さ、不思議さ、疑いの中に、結論を急がずに留まる能力のことだ。これに対して、「ポジティブ・ケイパビリティ」というのもある。問題を分析し、解決策を導き、実行する能力だ。ゴールが明確なときに発揮される力。私はおそらくだがこれが得意だ。生成AIは、ポジティブケイパビリティを劇的に強化した。「このAPIを叩いて、結果をパースして、DBに保存するコードを書いて」と指示すれば、動くコードが出てくる。「このエラーメッセージの原因を調べて」と頼めば、調査結果が返ってくる。ゴールが明確なタスクは、AIとの協働で驚くほど速く片付く。私の2025年は、まさにこれだった。仕事のコードは書けた。クライアントから「これを作ってほしい」と言われれば、作れた。締め切りがあり、要件があり、ゴールが明確なタスクは、以前より速く終わるようになった。しかし、ネガティブケイパビリティは強化されなかった。むしろ、弱体化した気もする。 以前なら、分からないまま3日間コードを書き続けることができた。今は、30分詰まるとAIに聞いてしまう。「分からない」という状態に耐える筋力が、確実に落ちている。OSS開発には、ネガティブケイパビリティが必要だ。「何を作るか」は誰も教えてくれない。「これが正解」という保証はない。作っている途中で「これは違うかも」と思うことがある。それでも手を動かし続ける。完成するかどうか分からない。使われるかどうか分からない。その不確実さの中に留まり続ける力。生成AIに「何を作るべきか」と聞いても、答えは出ない。AIは優秀なアシスタントだが、ゴールを設定するのは人間の仕事だ。ゴールが明確な仕事が速く片付くようになった結果、私の中で奇妙なことが起きた。「答えがすぐに出る」ことに慣れてしまった。 仕事では、AIに聞けば数分で方向性が見える。それに慣れた脳は、「答えが出ない状態」に耐えられなくなっている。では、どうすれば不確実さに耐えられるのか。いくつかの仮説がある。ゴールを小さくする（「Kubernetesのログ管理を改善したい」ではなく「Podの再起動ログをSlackに送る」）。「完成」の定義を下げる（動けば完成、READMEは3行でいい）。公開してしまう（不確実性の一部が確定に変わる）。AIに頼らない時間を作る（自分で考える筋力を維持する）。「狂う」とは何か「狂う」という言葉を使うと、何か特別な才能や突飛な発想が必要に思える。しかし、私が考える「狂う」はもっと単純だ。狂うとは、常識的な量を超えて、時間と労力を注ぐことだ。天才的なアイデアは必要ない。奇抜な発想も必要ない。ただ、普通の人が「そこまでやらなくていいだろう」と思う量を投入する。これが狂うということだ。しかし、ここまで書いて気づいた。「量をやれ」というアドバイスは、ゴールが見えている人へのアドバイスだ。これはポジティブケイパビリティの話だ。「OSSを20個作れ」と言われても、「何を作るか」が決まっていなければ、手は動かない。私の問題は、量が足りないことではなく、ゴールが見えない状態に耐えられないことだった。ネガティブケイパビリティの欠如だ。だから、「狂う」にはもう1つの意味がある。答えが出ない状態に留まり続けることだ。「これが正解かどうか分からない」「誰にも使われないかもしれない」「もっといい方法があるかもしれない」。その不確実さの中で、それでも作り続ける。確信がないまま、手を動かし続ける。普通の人は、不確実さに耐えられない。「これで合ってる？」と誰かに確認したくなる。確認できないと、手が止まる。狂っている人は、確認しないまま走り続ける。生成AIは「確認」を容易にした。コードを書いたら、AIにレビューしてもらえる。設計を考えたら、AIに壁打ちしてもらえる。これは素晴らしいことだ。でも同時に、「確認なしで走り続ける」筋力が衰えた。量を積むことと、不確実性に耐えること。この2つは、実は表裏一体だ。量を積めば、その中から「これだ」というものが見えてくる。不確実性に耐えていれば、やがてゴールが見えてくる。どちらも「狂う」ことでしか到達できない。狂気の最も簡単な表現方法は、物量か時間を使うことだ。1日1時間を5年続ける。同じテーマのブログを100本書く。OSSを年間20個作る。なぜ20個か。月に1〜2個のペースだ。1つのツールを2週間で完成させる。完璧じゃなくていい。動けばいい。このペースなら、仕事をしながらでも無理がない。かつ、「そこそこ止まり」の自分とは明らかに違う場所に立てる。特別な才能がなくても、量を積めば、誰も追いつけない場所にたどり着く。ここで「衝動」という言葉を使いたい。不便を見つけたとき、「あ、これ自動化できそう」と思う。その瞬間、手が動き出す。誰に頼まれたわけでもない。でも、気づいたらコードを書いている。これが私にとっての衝動だ。「将来の夢」とは違う。他者の評価を求めている「有名なOSSメンテナになりたい」は、衝動ではない。衝動は、評価とは無関係に動く。10年経っても変わらない。「不便を見つけたら、すぐ直したくなる」。隙間家具を作るのは、この衝動の表れだ。問題は、この衝動を他者の目で覆い隠してしまうことだ。「作っても誰にも使われないかも」。そう考えた瞬間、衝動が埋もれる。2025年の私は、まさにこれだった。衝動は「発見」するものではなく「掘り出す」ものだ。他者の目や評価への恐れで覆い隠されている。それを掘り出すには、まず量をやる必要がある。考える前に手を動かす。作る前に悩まない。作った後に、何が自分を動かしているのかが見えてくる。まず量をやる私たちは、最初から量が足りない。2025年、私のOSSがそこそこ止まりだった理由は何か。作った。完走もした。でも、「代表作」と呼べるインパクトには届かなかった。振り返ると、1つに賭け切れていなかった。あれもこれもやろうとして、どれにも全力を注げなかった。「ゴールが見えないから突き抜けられない」と思っていた。でも、それは逆だ。一つに賭け切らないから、ゴールが見えない。作りはした。でも、広く浅く。一つに集中しなかったから、どれも「これだ」に辿り着けなかった。私の経験を話す。以前、「Kubernetesのログをなんとかしたい」という漠然とした不満があった。何を作ればいいか分からなかった。とりあえず、Podの再起動を検知するスクリプトを書いた。動いた。使ってみた。すると、「再起動の直前のログが見たい」という次の不満が見えた。それを解決するコードを足した。使ってみた。今度は「Slackに通知したい」という欲求が出てきた。最初に「Podの再起動時に直前のログをSlackに送るツール」というゴールが見えていたわけではない。作っているうちに、ゴールが形成されていった。ゴールは、作る前に見つかるものではない。作る過程で見えてくるものだ。量をやることで、初めて「自分が本当に作りたいもの」が浮かび上がる。完璧な1つより、動く20個。磨き上げた1つより、荒削りな50個。これが私の2026年の方針だ。物量で狂う。 OSSを年間20個作る。完璧じゃなくていい。動けばいい。20個作れば、1個くらいは当たる。当たらなくても、20個分の経験が残る。時間で狂う。 毎日30分、何かを作る時間を確保する。1年で小さなツールを20個作れば、5年で100個になる。100個のOSSを持っているエンジニアは、採用市場で見たことがない。試行で狂う。 1つのアイデアに固執しない。「これは違うな」と思ったら、すぐ次に行く。打席に立つ回数を増やす。三振しても気にしない。次の打席がある。私は30代で独身だ。守るべきものが少ない。狂えるうちに狂っておく。量をやることで、初めて見えてくるものがある。どのアイデアに自分の熱量が続くのか。どのツールが使われるのか。作る前に「どれが正解か」を考えても分からない。作った後に、結果が教えてくれる。量だけでは足りないからセンスを磨くここで反論が聞こえる。「量をやるだけなら、生成AIでもできるのでは？」正しい指摘だ。そして、もう1つ重要な変化がある。ソフトウェアは供給過多の時代に入った。あらゆる領域で「フロンティアの閉鎖」が起きている。かつてソフトウェアには未開拓の荒野があった。問題はそこら中に転がっていて、誰かが手を挙げて解決すれば、それだけで価値になった。参入障壁が高かったから、作れる人が少なかった。だから「作った」という事実そのものに希少性があった。今は違う。生成AIが参入障壁を破壊した。誰でも作れる。結果、供給が需要を超えた。ユーザーの時間と注意力が、ツールよりも希少になった。ツールが人を選ぶ時代から、人がツールを選ぶ時代へ。選ばれないツールは、存在しないのと同じだ。これは「量で勝てた時代の終焉」を意味する。かつての戦略は「とにかく作れ、出せ、数で勝負しろ」だった。今、その戦略は逆効果になりうる。大量の凡庸なツールを公開すると、ノイズを増やすだけで、作り手の信用を毀損する。つまり、量を公開しすぎることが、むしろマイナスになる時代が来ている。では、量をやる意味はどこにあるのか。ここで「センス」について考えたい。センスとは何か。私は、意味よりも先に、形式やリズムを感じ取る能力だと考えている。普通、私たちは物事を「これは何を意味するのか」で理解しようとする。コードを見て「このツールは何をするのか」と問う。ブログを読んで「著者は何を主張しているのか」と問う。意味を求める。でも、センスの本質はそこにない。センスとは、意味の手前にある「リズム」を感じ取ることだ。リズムとは、反復と差異の織り成すパターンのことだ。赤ちゃんが「いないいないばあ」で喜ぶのは、不在から存在への移行、つまり0→1のビートを感じているからだ。予測があり、裏切りがあり、また予測に戻る。この往復運動が快感を生む。あらゆる表現にリズムがある。音楽のビート。文章の緩急。コードの構造。APIの応答パターン。人間は意味を理解する前に、このリズムを身体で感じている。優れた表現は、セオリーを押さえた上で、あえてそこからはみ出す。 反復の中に絶妙な差異を混ぜている。予測可能でありながら、どこか予測を裏切る。この「ズレ」がセンスだ。ここで重要な逆説がある。完璧を目指すほど、センスは死ぬ。お手本を完璧に再現しようとすると、二つの問題が起きる。一つは、お手本との差異が「欠点」に見えてしまうこと。もう一つは、自分固有のリズムが消えてしまうこと。結果として、劣化コピーが生まれる。逆に、お手本から離れることを肯定すると、「ヘタウマ」が生まれる。完璧ではないが、作り手固有のリズムがある。技術的には未熟でも、個性がある。その個性が、使う人に刺さる。なぜ個性が刺さるのか。人間は、パターンを認識する生き物だからだ。完璧にパターン化されたものは、最初は心地よい。でも、すぐ飽きる。予測通りすぎて、刺激がない。一方、パターンから少しズレたものは、脳に引っかかる。「なぜここでこうなる？」という小さな疑問が生まれ、それが記憶に残る。AIは反復とパターンを生成できる。しかし、その人固有の「どうしようもなさ」は生成できない。「どうしようもなさ」とは何か。個人の癖、偏り、こだわり。論理では説明できない選好。なぜか惹かれるもの。なぜか避けたくなるもの。この非合理な偏りが、人間の表現に陰影を与える。私がツールを作るとき、そこには私の「どうしようもなさ」が刻まれる。なぜこの設計を選んだのか、論理的に説明できない部分がある。それは私の経験、私の好み、私の盲点が複合的に作用した結果だ。AIが同じ仕様で作っても、同じものにはならない。センスとは、リズムを感じ取る能力であり、同時に、自分固有のリズムを表現する能力でもある。では、どうやってセンスを磨くのか。答えは逆説的だ。量をやることだ。多様なものに触れると、最初は不安を感じる。「分からない」「理解できない」。この不安は、パターンを認識できていないサインだ。量を重ねると、パターンが見えてくる。不安が面白さに変換される。これがセンスが磨かれる過程だ。ここで矛盾が生じる。センスを磨くには量が必要だ。しかし、量を公開しすぎるとマイナスになる。答えは、「作る量」と「公開する量」を分けることだ。20個作る。でも、公開するのは、センスが良いと判断した5個だけ。残りの15個は、センスを磨くための練習だ。公開しない。でも、作ったことに意味がある。量をやることには、二重の意味がある。1つ目は、センスを磨くこと。多様なものを作ることで、「何が良くて何が良くないか」を判断する回路ができる。リズムを感じ取る力が育つ。2つ目は、自分の「どうしようもなさ」を発見すること。量をやると、自分のパターンが見えてくる。どういう問題に惹かれるか。どういう設計を好むか。それは私の固有性であり、AIには真似できない。だから、量をやる意味は「AIより速く作る」ことではない。量を通じて、リズムを感じ取る力と、自分固有のリズムを発見することだ。そして、センスが磨かれた後は、公開するものを厳選する。供給過多の時代に求められるのは、「たくさん作れる人」ではない。「たくさん作った上で、良いものだけを選べる人」だ。AIは「どう作るか」を効率化する。でも、「何を作るか」「どれを公開するか」「どう判断するか」は、量を経験した人間にしか分からない。そして引き算する量をやった。20個作った。では、20個全部を維持できるか。できない。私には経験がある。かつて、複数のプロジェクトを同時に走らせていた。イシューは溜まり、プルリクエストは放置され、READMEは古くなった。全部やろうとして、全部が死んだ。量をやることと、量を維持することは違う。 量をやるのは一時的な狂気だ。量を維持するのは持続的な負担だ。人間のリソースは有限だから、量をやった後には、引き算という別の問題が待っている。私たちは、量が満ちた後に引かなすぎる。 量をやった後は、容赦なく削る。使われないツールは捨てる。熱量が続かないプロジェクトはアーカイブする。失うのは「いつかやるかもしれない」という幻想だ。守れるのは「今、本当にやりたいこと」への集中だ。削らずに広げ続けた結果が2025年の私だ。副業も、登壇も、ブログも、OSSも、全部やった。全部それなりに成果は出た。でも、どれも「これが俺の本業だ」と言い切れない。器用貧乏の完成形だ。ここで「引き算」の思考法が必要になる。シーナ・アイエンガー氏の有名な実験では、24種類のジャムより、6種類に絞った方が購入率は高かった。選択肢が多すぎると、人は「選ぶ」という行為自体ができなくなる。選択の科学 コロンビア大学ビジネススクール特別講義 (文春文庫 S 13-1)作者:シーナ アイエンガー文藝春秋Amazonアイエンガー氏は『THINK BIGGER』で、選択肢が多すぎて選べないときの思考法を体系化した。その本質は「引き算」だ。課題を選ぶ、分解する、誰のためかを決める、材料を集める、何を作らないかを決める、他者の目で検証する。すべて「絞る」プロセスだ。THINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazon狂って量をやるフェーズでは、複数のアイデアが同時に走っている方が自然だ。順番通りに1つずつ片付けようとすると、むしろ手が止まる。どれかが熱を帯びてきたら、そこに集中する。足し算ではない。引き算だ。優れた開発者のOSSが失敗するのは、怠けているからではない。正しいことをしすぎるからだ。 ユーザーの声を聞く。機能を追加する。対応範囲を広げる。全部、正しいことだ。でも、正しいことを積み重ねた結果、複雑になり、重くなり、新しく登場したシンプルなツールに足元をすくわれる。私たちは「正しさ」に殺される。ユーザーの声を聞くのは正しい。だから聞く。機能を追加するのは正しい。だから追加する。テストを書くのは正しい。だから書く。ドキュメントを整えるのは正しい。だから整える。気づいたら、最初に解決したかった問題が見えなくなっている。正しいことの山に埋もれて、本質が窒息している。「正しさ」は麻薬だ。やればやるほど気持ちいい。やればやるほど、完成から遠ざかる。隙間家具を作るとは、引き算をすることだ。機能を削る。対象を絞る。スコープを小さくする。「これだけは解決する」を決め、残りは捨てる。生成AIを使うとき、この引き算が難しくなる。AIは指示すれば無限に足し算を提案してくる。「この機能も追加しましょうか」「こういうオプションもあると便利です」「エラーハンドリングをもっと丁寧にしましょう」。全部、正しい提案だ。でも、全部受け入れると、隙間家具は大きな家具になる。AIは足し算が得意だ。引き算は人間がやる。私がAIに「削らせる」ときに使う問いかけがある。「この機能がなくても、最小限の価値は提供できるか？」。答えがYESなら、その機能は削る候補だ。AIの提案を聞いたら、「本当に必要か？」と問い直す。これが、AIとの協働における引き算の基本姿勢だ。「何を作るか」を決める課題を選ぶ引き算の最初は、「何を作るか」を1つに決めることだ。私が2025年に「代表作」に届かなかった理由の1つは、課題が大きすぎたことだ。「Kubernetesのログ管理を改善したい」と思った。でも、それは「どのログ」「どう改善」「誰のため」が決まっていない。漠然としすぎていた。結果、インパクトのあるものが作れなかった。「作りたいものはあるけど、何から手をつければ...」という状態は、課題が大きすぎるか小さすぎるかのどちらかだ。大きすぎると作りきれない。小さすぎると作る意味がない。「1つのツールで完結する」サイズを探す。課題が大きすぎる例:「Kubernetesの代替」「CI/CDパイプライン全体の改善」「インフラ自動化ツール」課題が小さすぎる例:「kubectl getのラッパー」「特定のエラーメッセージを整形するスクリプト」ちょうどいい例:「Podが再起動したときに直前のログを保存するツール」「複数リポジトリのCIステータスを一覧表示するCLI」「Terraformの差分をSlackに見やすく投稿するBot」ちょうどいいサイズの見つけ方は、「自分が1〜3日かけて解決したこと」を思い出すことだ。それは、深みがある。かつ、1つのツールで完結する気がする。隙間を見つける大きなツールが解決していない小さな問題。それが「隙間」だ。Kubernetes（コンテナオーケストレーション）は素晴らしい。しかし、Kubernetesが解決していない問題は山ほどある。Podが再起動したとき、前後のログを自動でSlack に送りたい。これはKubernetesの仕事ではない。Terraform（インフラ構成管理）も素晴らしい。ただ、差分をSlackに見やすく投稿したい。これはTerraformの仕事ではない。GitHubも同様だ。複数リポジトリのCIステータスを一覧で見たい。これはGitHubの仕事ではない。隙間を見つけるヒントは5つある。自分の不便。「こういうツールが欲しいのに、ない」という体験。私が作った隙間家具の中で、最も使われたものは、自分自身の問題を解決するために作ったものだった。自分が不便を感じているとき、そこには片づけたい「用事」がある。でも、それを片づける手段がない。私のGithub リポジトリからのスクショここで疑問が浮かぶ。「自分の不便」が特殊すぎるときはどうするのか。自分だけが困っている問題を解決しても、誰も使わないのではないか。だから2026年、私はこう決めた。最初は特殊すぎて構わない。なぜなら、特殊な問題を解決するツールでも、自分が本当に使うなら完成する。「誰かが使うかも」で作ったツールは、途中で手が止まる。まず完成させることが最優先だ。公開してみれば、同じ問題を抱えている人が意外といることに気づく。特殊だと思っていた不便が、実は普遍的だったというケースは多い。仮に本当に特殊で誰も使わなくても、自分の問題は解決している。それで十分だ。繰り返しの手作業。同じコマンドを何度も打っている。同じ手順を何度も実行している。毎回「面倒だな」と思いながら、やっている。ここで立ち止まる。この問題は「自動化すべき問題」か、それとも「慣れるべき問題」か。ツール化することで、本当に人間の負荷は減るのか。自動化によって、別の複雑さを生んでいないか。判断基準は、その作業が月に何回・何分発生しているかだ。月に1回、5分で終わる作業なら、自動化ツールを作るより慣れた方が早い。週に10回、毎回10分かかる作業なら、自動化する価値がある。感覚で判断しない。数字で判断する。例えば、複数のGitHubリポジトリのCIステータスを確認するとき、1つずつページを開いていた。毎回、5分くらいかかる。週に5回やっていた。月に100分。年に1200分。ツールを作る価値がある。作った。5分が10秒になった。コンテキストスイッチ。ある情報を得るために、複数のツールを行き来している。Slackを見て、Grafanaを見て、ログを見て、またSlackに戻る。情報を一箇所に集めるツールを作れば、コンテキストスイッチが減る。頭の負荷が減る。判断が速くなる。暗黙知。「あの人に聞けば分かる」「Slackのどこかにある」「この手順は、前にやったことある人しか知らない」。暗黙知をツールに埋め込めば、誰でも同じことができるようになる。複雑さ。「このツールは高機能だけど、使いこなせない」「設定項目が多すぎて、何を設定すればいいか分からない」。高機能なツールが、その機能を使い切れていない人たちを置き去りにしている。彼らに、シンプルで分かりやすい選択肢を提供する。これも隙間家具の仕事だ。課題を分解する課題が決まったら、5つまでに分解する。私がよくやる失敗は、分解せずに作り始めることだ。「ログ保存ツールを作ろう」と思って、いきなりコードを書き始める。途中で「保存先どうしよう」「認証どうしよう」「エラーハンドリングどうしよう」と考え始める。そのたびに手が止まる。最初に分解しておけば、こうはならない。「〇〇を作ろう」だけでは手が動かない。サブ課題に分解して、5つまでに絞る。5つに絞るのは、正直、苦しい。あれもこれも入れたくなる。でも、ジャムの法則と同じだ。サブ課題を10個、20個と出すと、どれに注力すべきか分からなくなる。例: 「Podが再起動したときに直前のログを保存するツール」Podの再起動を検知する仕組み直前のログを取得する方法ログを保存する先（S3など）CLIのインターフェースエラーハンドリング分解した項目が、そのまま実装の順番になる。「これは本当に必要か？」と自問すると、いろいろ見えてくる。実は同じことをしている項目。なくても動く項目。別のツールに任せた方がいい項目。削ることで本質が見える。5つに分解したら、次に優先順位をつける。何を基準に「残す1つ」と「後回しにする4つ」を決めるか。私の基準は、「これがないと、ツールとして成立しない」だ。技術的な実現性でも、ユーザーの感動でも、自分の興味でもない。「ツールの存在意義に関わるか」だ。例えば、「Podの再起動を検知する仕組み」がなければ、ログ保存ツールは成立しない。これが最優先だ。「CLIのインターフェース」は後でもいい。最初はハードコードでも動く。ここまでで、「何を作るか」と「どう分解するか」が決まった。でも、まだ足りない。「誰のために作るか」が決まっていない。「誰のために作るか」を決める望みを比較する同じツールでも、誰向けに作るかで設計が変わる。自分用なら雑でいい。他人に使ってもらうなら、READMEが必要だ。コミュニティに貢献したいなら、テストも書く。私が2025年に「代表作」に届かなかったもう1つの理由は、「誰のため」が曖昧だったことだ。「これ、公開したら使ってもらえるかな」と考えた瞬間、設計が複雑になる。「あの人はこういう使い方するかも」「この環境もサポートした方がいいかも」。考えれば考えるほど、作るものが膨らむ。膨らめば膨らむほど、作れなくなる。3つの望みがある。自分が作りたいもの。ユーザーが使いたいもの。コミュニティへの貢献。全部満たそうとすると、どれも中途半端になる。だから2026年、私はこう決断する。まず自分の問題を解決するツールを作る。当たり前すぎるかもしれない。でも、これが私の経験則だ。自分が本当に困っている問題なら、熱量が出る。熱量のあるツールは、ユーザーにも伝わる。これは「プロダクト」ではなく「道具」として十分に割り切れているか。プロダクトは他者のためにある。道具は自分のためにある。隙間家具は道具だ。自分の問題を解決するために作る。他者が使ってくれたらラッキー、くらいの気持ちでいい。汎用性を上げようとして、複雑さを持ち込んでいないか。持ち込みがちだ。「S3だけじゃなくGCSにも対応しよう」「Kubernetes以外でも使えるようにしよう」。その瞬間、道具がプロダクトになろうとする。複雑さが増す。完成しなくなる。READMEは「思想」ではなく「使い方」を語っているか。思想を語りがちだ。「なぜこのツールが必要か」「どんな設計思想か」。でも、ユーザーが知りたいのは「どう使うか」だ。インストール方法、実行方法、オプション。これだけでいい。自分以外の利用者がゼロでも、このツールは成立しているか。成立している必要がある。自分の問題が解決しているなら、それで十分だ。他者が使うかどうかは、結果論だ。「まだ誰も使っていない人」を見る自分が不便を感じているとき、同じ不便を感じている人は他にもいる。片づけたい用事があるのに、それを片づける手段を持っていない人。私はこの人たちを「まだ誰も使っていない人」と呼んでいる。自分がその一人だったなら、同じ境遇の人が他にもいるだろう。隙間家具は、この人たちに届ける。ここで注意が必要だ。ツールを公開すると、ユーザーからフィードバックが来る。「この機能が欲しい」「ここが使いにくい」。これは嬉しい。でも、ここに罠がある。既存ユーザーの声を聞けば聞くほど、既存ユーザーのためのツールになる。そして、「まだ誰も使っていない人」を見落とす。既存ユーザーの声に応え続けると、隙間家具は大きな家具になろうとし始める。機能が増え、複雑になり、最初のシンプルさを失う。新規ユーザーが求めているのは、高機能ではなく「すぐ使える」「分かりやすい」だ。「声」と「用事」を区別するフィードバックを受けるとき、「声」と「用事」を区別する。私も失敗したことがある。あるCLIツールを公開したとき、「設定ファイルで動作を変えたい」というフィードバックを複数もらった。嬉しかった。使ってくれている人がいる。だから、設定ファイル機能を実装した。YAMLで書けるようにした。オプションを増やした。結果、設定項目が20個を超えた。新しいユーザーは「設定が多すぎて何を設定すればいいか分からない」と言い始めた。シンプルさが売りだったツールは、複雑なツールになっていた。「声」は、ユーザーが言語化したものだ。「この機能が欲しい」「ここが使いにくい」。「用事」は、ユーザーが本当に片づけたいことだ。なぜその機能が欲しいのか。なぜそこを使いにくいと感じるのか。この「なぜ」の先に、本当の用事がある。例えば、CLIツールに「YAML出力オプションが欲しい」というフィードバックが来たとする。声をそのまま受け取れば、--output yamlフラグを実装することになる。でも、「なぜYAMLが欲しいのか」を問うと、「他のツールにパイプしたい」「設定ファイルとして保存したい」という用事が見えてくる。用事が分かれば、YAMLだけでなくJSONでも解決できるだろう。あるいは、標準出力をそのままパイプできる設計にすれば、フォーマット変換はjqに任せられるだろう。「この機能が欲しい」と言われたら、「なぜ」を問う。その人の用事は何か。その用事を片づける方法は、言われた機能だけか。もっとシンプルな方法はないか。ツールがヒットすると、「汎用化」の要望が必ず来る。「S3だけでなくGCSにも対応して」「Kubernetes以外でも使えるようにして」。これに応えると、隙間家具は大きな家具になる。だから私は、こう決めている。READMEが複雑になるなら、その機能は入れない。機能を追加するとき、READMEがどう変わるかを見る。説明が長くなるなら、別のツールにする。READMEがシンプルなら、ツールもシンプルだ。これが私の制約であり、美学だ。ここまでで、「何を作るか」「誰のために作るか」が決まった。次は、作る前に調べる。調べて、削る箱の中と外を探すいきなり作り始めたくなる。でも、その前に下調べをする。私は以前、「これ、俺が作らなくても既存ツールで十分だな」と気づいて手を止めたことがある。それ自体は正しい判断だった。でも、その後「じゃあ俺の経験は何に使えるか」を考えなかった。既存ツールを調べて終わり。それでは何も生まれない。似たツールはあるか。どんなアプローチがあるか。先人の知恵を借りる。「箱の中」は同じ領域の情報だ。公式ドキュメント、他の人の同じテーマのツール、GitHub Issues、Stack Overflow。正確性を担保し、抜け漏れを防ぐ。「箱の外」は自分の経験だ。実際に試した結果、ハマったポイントと解決策、自分なりの工夫や改善。これがオリジナリティの源泉になる。ここで重要なのは、インプットだ。本を読む。既存のOSSのコードをちゃんと読む。何のライブラリが使われていて、どのように問題を解決しているかを理解する。これが「箱の中」を深く知ることだ。例えば、Kubernetesのログ保存ツールを作るなら、既存の類似ツールのコードを読む。どのKubernetesクライアントライブラリを使っているか。どうやってPodの再起動を検知しているか。ログの取得にはどのAPIを使っているか。保存先との接続はどう抽象化しているか。コードを読まずに作り始めると、車輪の再発明をする。既に解決されている問題を、苦労して解き直す。あるいは、先人が避けた落とし穴にハマる。インプットの具体例を挙げる。本を読む：技術書だけでなく、設計思想やアーキテクチャの本も読む。『A Philosophy of Software Design』『The Art of Unix Programming』。隙間家具を作る視点が変わる。OSSのコードを読む：GitHubで似たツールを探して、main.goやlib.rsを読む。README だけでなく、実装を見る。「なるほど、こう解決するのか」という発見がある。ライブラリの使い方を学ぶ：使おうとしているライブラリのexampleを全部読む。ドキュメントを端から端まで読む。「こんな機能もあったのか」という発見が、設計を変える。「既に同じようなツールがある」は気にしない。同じ課題を解決するツールでも、価値を出せる理由はある。環境が違う。文脈が違う。深さが違う。切り口が違う。あなたのツールにしかない価値は、あなたの環境で動いた事実、あなたがハマったポイント、あなたの言葉での説明だ。「n番煎じ」でも、あなたの経験を加えれば価値になる。「箱の外」の材料を増やすために、私が意識的にやっていることがある。「自分の仕事を観察する」だ。エンジニアリング以外のインプットも大事だが、それ以上に、自分が日常的にやっている作業を観察する。「今、何に時間を使っているか」「何に苛立っているか」「何を繰り返しているか」。この観察が、隙間を見つける材料になる。選択マップで削る材料が揃ったら、「何を作り、何を作らないか」を選ぶ。私は「全部入り」を目指しがちだ。ログ保存ツールを作るなら、S3もGCSもAzure Blobも対応したくなる。Slack通知もメール通知もつけたくなる。そうこうしているうちに、何も作れなくなる。選択マップとは、集めた選択肢を視覚的に整理し、最適な組み合わせを見つける方法だ。課題から分岐して選択肢を並べ、各選択肢のメリット・デメリットを可視化する。例: 「OOMKilled（メモリ不足による強制終了）の調査方法を紹介するツール」調査方法は複数ある。kubectl top（リソース使用状況確認）、Grafana（可視化ダッシュボード）、pprof（プロファイリングツール）、サードパーティツール。読者に最も役立つのはどれか。kubectl topは簡単ですぐ使えるが、瞬間値しか見られない。Grafanaは履歴を見られるが、セットアップが必要。pprofは詳細に分析できるが、設定が必要で学習コストは高い。選択結果：読者の多くは「まず何が起きてるか知りたい」→ kubectl top + Grafanaを中心に作る。pprofは発展編として軽く触れるか、別のツールにする。足し算の発想だと、全部の方法をサポートしようとする。焦点がぼやける。誰にも刺さらない。引き算の発想だと、「これだけは作る」を決める。残りは捨てる。刺さるツールになる。良いツールは「何を作らないか」で決まる。スコープを絞る勇気隙間家具は、特定の問題を解決する。汎用性を追求しない。「このコンテキストで、この問題を解決する」に集中する。例えば、「KubernetesのPodが再起動したとき、直前のログを自動でS3に保存するツール」。汎用的ではない。Kubernetesを使っていて、ログをS3に保存したい人だけを対象にする。でも、それでいい。特定の問題を、特定のコンテキストで、確実に解決する。これが隙間家具の価値だ。汎用性は、使われてから考えればいい。最初から汎用的に作ろうとすると、要件が膨らみ、複雑になり、いつまでも完成しない。ここまでで、何を作るか、誰のために作るか、何を作らないかが決まった。いよいよ作る。小さく作って、見せる第三の目で検証する作った。動いた。自分では完璧に見える。でも、それは危険なサインなんだ。私にも経験がある。あるCLIツールを作って、自分では「完璧だ」と思った。README も書いた。インストール方法も書いた。でも、同僚に見せたら「これ、何をするツールなの？」と聞かれた。私には当たり前すぎて、説明を省略していた。「前提知識がないと、何も分からない」。そのツールは結局、私しか使わなかった。使い方を説明する手間を惜しんだ結果だ。作った本人には見えない穴がある。「当然わかるでしょ」と省略している。専門用語を説明なしで使っている。論理の飛躍に気づかない。自分では完璧に見える。だから、他者に見せる。使ってもらう。フィードバックをもらう。隙間家具を必要としている人は、探していない。問題を抱えているが、解決策があるとは思っていない。だから、「検索してたどり着く」ことを期待できない。では、どうやって届けるか。自分の体験を語る。「私はこういう問題を抱えていた。だから、このツールを作った。」「まだ誰も使っていない人」は、同じ問題を抱えているだろう。ブログやTwitterで体験を語れば、「あ、自分もこの問題を抱えている」と思ってもらえる。READMEに機能を列挙するだけでは届かない。「なぜこのツールを作ったか」「どんな問題を解決するか」を語る。「まだ誰も使っていない人」は、自分の不便を言語化できていないことが多い。だから、状況を描写する。「毎朝、Slackを開いて、Grafanaに移動して、ログを確認して、またSlackに戻る...この作業、面倒じゃないですか？」。機能ではなく、状況を語る。「あ、それ自分だ」と思わせる。ツールの説明ではなく、問題の描写から始める。これが、言語化できていない不便に気づかせるストーリーテリングだ。入り口を簡単にするインストールが面倒だと、人は離れる。設定が複雑だと、人は離れる。最初の一歩を、できるだけ簡単にする。go install 一発でインストールできる。設定ファイルは最小限。デフォルトで動く。これが理想だ。なぜなら、新しいツールを試すとき、人は「動かすまでの時間」を無意識に測っている。5分で動かなければ、「また今度」になる。設定が多いツールは、5分では動かない。だから、試されずに終わる。パワーユーザーは細かい設定を求めるだろう。でも、パワーユーザーは「まだ誰も使っていない人」ではない。最初に届けるべきは、5分で動くシンプルさだ。新しいツールは、最初は既存のツールより「劣っている」ことが多い。機能が少ない。パフォーマンスが低い。でも、シンプルで、分かりやすくて、すぐに使える。それでいい。隙間家具は、シンプルでいい。1つのことを、確実にやる。それが、「まだ誰も使っていない人」に届く。「ジャムの法則」をインターフェースにも適用する。CLIツールなら、フラグを減らす。理想は、引数なしで動くこと。mytoolと打てば、最も一般的なユースケースが実行される。設定が必要なら、対話的に聞く。フラグは上級者向けのショートカットだ。最初から覚えてもらうものではない。選択肢を減らすことで、ユーザーは「考える」から「使う」にすぐ移れる。このツールは「技術的に正しい」より「現場で生き残る」設計になっているか。技術的に正しい設計は、しばしば複雑になる。すべてのエッジケースに対応する。すべてのエラーを丁寧にハンドリングする。でも、現場で使われるツールは、シンプルで、雑でも動く。エッジケースを切り捨てた理由を説明できるか。説明できる必要がある。「このケースは月に1回しか発生しない。手動で対応すればいい。だから、ツールでは対応しない。」こう言い切れるなら、切り捨てていい。例外処理より「何も起きないこと」を優先していないか。優先していい。エラーが発生したとき、丁寧なエラーメッセージを出すより、そもそもエラーが発生しない設計の方がいい。入力を厳しくする。想定外の状態を作らない。現場の雑さ・曖昧さ・不完全さを前提にできているか。現場は綺麗ではない。設定ファイルにtypoがある。環境変数が設定されていない。ネットワークが不安定。この雑さを前提に設計する。「完璧な環境でしか動かないツール」は、現場では使われない。小さく始める6ステップを踏んでも、完璧なツールは作れない。だから、小さく始める。最初から完璧なツールを作ろうとしない。自分の問題を解決するスクリプトから始める。それが動いたら、少し整えて公開する。私の場合、多くの隙間家具は、最初はただのシェルスクリプトだった。自分の問題を解決するために、ちょっと書いた。それが便利だったので、もう少し整えた。それを公開した。完璧を目指すと、いつまでも公開できない。「もう少し機能を追加してから」「もう少しドキュメントを整えてから」。そうこうしているうちに、作る気力がなくなる。動くものを、まず作る。公開する。使ってもらう。フィードバックをもらう。改善する。このサイクルを回す。隙間家具を1つ公開したら、終わりではない。むしろ、ここからが始まりだ。探索を続ける捨てやすく作るここからが、私が一番伝えたいことだ。隙間家具には寿命がある。状況が変われば、不要になる。だから、捨てやすく作る。このツールは「自分が将来保守したいコード」になっているか。正直に言えば、保守したくないコードの方が多い。だから、捨てやすく作る。保守したくなるほど愛着が湧くツールは、20個に1個くらいでいい。半年後の自分が読んで理解できる設計になっているか。なっていなくてもいい。半年後に必要なら、そのとき書き直せばいい。必要なければ、捨てればいい。機能追加ではなく「削除」するとしたら、どこを真っ先に消すか。この問いを常に持っておく。削除できる部分があるなら、それは最初から作らなくてよかった部分かもしれない。このコードは、使われなくなったときに綺麗に捨てられるか。捨てられる設計にしておく。依存を少なく。外部サービスとの結合を弱く。捨てるときに、誰にも迷惑がかからないように。私が作ったツールの中で、すでに捨てたものがある。Kubernetesをインストールするツールを作っていた。当時、Kubernetesのインストールは複雑で、手順を間違えると動かなかった。だから、自動化ツールを作った。便利だった。でも、kubeadmがリリースされて、インストールが簡略化された。ツールは不要になった。リポジトリをアーカイブした。悲しくはなかった。むしろ、「自分の問題意識は正しかった」と思えた。Kubernetesの開発者も同じ問題を認識していたのだから。このOSSは「本流に取り込まれる未来」を想定できているか。想定しておく。もしKubernetesやTerraform本体に同等機能が入ったら、どうするか。喜んで捨てる。それは「失敗した」のではなく「役目を終えた」のだ。本流に吸収されるために、意図的にやっていないことは何か。汎用化だ。本流は汎用的になろうとする。隙間家具は特殊なままでいい。特殊だから、本流が取り込みにくい。特殊だから、生き残れる。隙間家具は、状況が変われば不要になる。Kubernetesのバージョンが上がって、その問題が解決されるだろう。別のツールが登場して、より良い解決策を提供するだろう。だから、依存を少なく、シンプルに作る。捨てやすく作る。大きな家具は、捨てにくい。多くのリソースを投入している。多くの人が使っている。捨てることが難しい。隙間家具は、捨てやすい。役目を終えたら、捨てる。そして、新しい隙間を見つけて、新しい隙間家具を作る。「隙間」が「本流」に飲み込まれるリスクもある。Kubernetesのサイドカー機能が進化するように、プラットフォーム自体が隙間を埋めてしまうことがある。これに対する私の戦略は2つだ。1つ目は、捨てやすく作ること。本流に飲み込まれたら、素直に捨てる。自分の問題意識が正しかった証拠だと喜ぶ。2つ目は、本流が手を出さないニッチに特化すること。Kubernetesは汎用的になろうとする。だから、特定の会社の特定のワークフローに特化したツールは、本流が取り込みにくい。汎用化できないほど特殊なニッチを狙う。これも生存戦略だ。捨てたツールから得られる学びもある。単なる「失敗」で終わらせず、次の探索に活かせる知見を抽出する。私がやっているのは、「なぜこのツールは役目を終えたのか」を言語化することだ。本流に取り込まれたのか。別のツールが出てきたのか。そもそも問題設定が間違っていたのか。この分析が、次の隙間を見つける精度を上げる。「問題設定が間違っていた」が一番の学びだ。次は同じ間違いをしない。深化と探索隙間家具を1つ作ったら、終わりではない。隙間家具の開発には、2つの仕事がある。「深化」と「探索」だ。「深化」は、既存の隙間家具を改善すること。バグを直す。パフォーマンスを改善する。ドキュメントを整える。「探索」は、新しい隙間を見つけること。新しい用事を発見すること。新しい隙間家具を作ること。問題は、「深化」へ偏りやすいことだ。既存のツールへイシューが立つ。プルリクエストが来る。対応すると達成感がある。でも、これだけやっていると、最初に見つけた隙間だけを相手にし続けてしまう。競争のないところに宝がある。既存の競合がひしめく場所ではなく、誰も見ていない場所を探す。だから2026年、私はこう決めた。小さな実験を続ける。1つの隙間家具に全力を注ぐのではなく、複数の隙間家具を作り、どれが使われるか見る。全部が使われるわけではない。むしろ、使われないものの方が多い。でも、それでいい。使われなかったツールからも、学びがある。その学びが、次の探索に活きる。チーム開発での引き算ここまでの話は、一人で作る「隙間家具」を前提にしてきた。では、複数人で開発するときはどうか。「引き算の哲学」をチームで共有できるのか。私の経験では、スコープを最初に合意することが鍵だ。「このツールは何を解決し、何を解決しないか」を、開発を始める前にドキュメントへ書く。機能追加の提案が来たら、このドキュメントに立ち返る。「このスコープ外です」と言える根拠になる。チームでの合意形成は、一人のときより難しい。でも、「1つのREADMEで説明できる範囲」という制約は、チームでも使える。「この機能を追加したら、READMEはどう変わるか」を問う。READMEが複雑になるなら、その機能は入れないか、別のツールにする。この基準は、チームメンバー全員が判断できる。個人の好みではなく、客観的な基準だ。おわりにここまで読んでくれた人に、正直に書く。この文章を書きながら、私は何度も手を止めた。「こんなこと書いて意味あるのか」「誰が読むんだ」「もっといい構成があるんじゃないか」。書いている最中に、書くのをやめる理由を探している自分がいた。「代表作」に届かない理由と、まったく同じ構造だ。笑えない。2026年、私は隙間家具を20個作ると決めた。完璧じゃなくていい。動けばいい。使われなくてもいい。作ることそのものに意味がある。そう自分に言い聞かせている。本当にできるかは、分からない。来年の今頃、GitHubにリポジトリが20個並んでいる保証はどこにもない。また「時間がなかった」「優先順位が」と言い訳しているかもしれない。その可能性は、正直、かなり高い。でも、書いた。こうして宣言してしまった。「何を作ればいいか分からない」という人へ。それは正常だ。ゴールは最初から見えているものじゃない。作っているうちに、少しずつ輪郭が浮かんでくる。だから今日、30分だけ時間を取って、最近「面倒だな」と思った作業を1つ書き出してみてほしい。それを解決するスクリプトを書く。動いたら公開する。それだけでいい。20回繰り返す頃には、自分が本当に作りたいものが見えてくる。たぶん。見えてこなかったら、そのときはまた考える。ところで、ここまで偉そうに書いてきたが、私は孤独な独身男性だ。家族はいない。守るべきものが少ない分、狂いやすい環境にいるとも言える。歯止めをかけてくれる人がいない分、自分で自分を律する必要がある。友達との飯の予定。ジムの予約。強制的に「コードを書かない時間」を作らないと、際限なく沈んでいく。独身には独身の戦い方がある。OSSより大事なものはある。友達と話す時間。体を動かす時間。コードは逃げない。隙間家具はいつでも作れる。でも、友人との関係は放っておくと薄れる。健康は一度壊すと戻らない。狂うなら、余裕のあるときに狂え。順番を間違えると、人生ごと壊れる。......と、説教じみたことを書いたが、たぶん来年の今頃の私は、この文章を読み返して頭を抱えている。「狂う」とか言って、結局また「そこそこ」で終わったじゃないか、と。nwiizoというアカウントは、また少し大きくなっているだろう。「代表作」のハードルも、また少し上がっているだろう。自分で自分の首を絞める構造は変わらない。それでも、諦めたくない。憧れたエンジニアたちがいる。彼らのように、「これを作りました」と胸を張れる日が来るまで、手を動かし続ける。だから、書いておく。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。答えが出ない状態は、苦しい。でも、その苦しさの中を泳ぎ続けることでしか、本当に作りたいものは見つからない。完璧を待たない。不完全なまま公開する。恥をかく覚悟で、手を動かす。2026年は、そういう年にする。できるかどうかは知らない。でも、やると決めた。隙間を見つけたら、小さく狂おう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考文献人生にコンセプトを (ちくまプリマー新書)作者:澤田智洋筑摩書房Amazonセンスは知識からはじまる作者:水野学朝日新聞出版Amazonセンスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon「面白い！」を見つける　――物事の見え方が変わる発想法 (ちくまプリマー新書)作者:林雄司筑摩書房AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonわかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon私が間違っているかもしれない作者:ビョルン・ナッティコ・リンデブラッド,キャロライン・バンクラー,ナビッド・モディリサンマーク出版Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon新版 いくつになっても、「ずっとやりたかったこと」をやりなさい。作者:ジュリア・キャメロン,エマ・ライブリーサンマーク出版Amazonいくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazon人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazon行動する人に世界は優しい―自分の可能性を解き放つ言葉―作者:佐藤航陽新潮社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[決断をプロットし、全力で走り続けるためのプロジェクトドキュメント管理]]></title>
            <link>https://zenn.dev/kamos/articles/adr_documentation</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/adr_documentation</guid>
            <pubDate>Mon, 22 Dec 2025 03:55:55 GMT</pubDate>
            <content:encoded><![CDATA[!この文章は人間が書きました画像はGeminiを使って生成しました なぜ、私たちはドキュメントを求めるのか開発現場において、ドキュメント管理は永遠の課題だ。点在する情報、矛盾する記述、実装との乖離、記されない背景情報など、ドキュメントの陳腐化は様々な形で現れる。これらに立ち向かおうとしては、その管理コストの高さに圧倒される。効果が明確に見えにくく、長い時間のかかるドキュメント整備をやり切ることは難しく、多くの現場でドキュメントは放置され、陳腐化し続けている。今度こそドキュメントの整備をやり切ると決意し、絶望する前に考えてほしい。私たちはなぜドキュメントがほしいのか？欲しいも...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Visualizing Coupling in Rust Projects]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</guid>
            <pubDate>Sun, 21 Dec 2025 06:25:59 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling Web UI - Self-diagnosis viewIntroduction"I really don't want to touch this module..."If you've been developing software long enough, you know this feeling. Every change breaks something else. Tests are painful to write. Understanding what the code even does feels impossible. These symptoms share a common root cause: modules that depend too heavily on each other—the problem of coupling.Coupling problems are insidious. They're hard to notice while you're writing code, only revealing themselves later when you wonder why changes are so difficult. What makes it worse is that even when you know "coupling is too tight," it's hard to see exactly where and how, or where to start fixing it.Looking back, I realize my understanding of coupling was quite shallow. I was making judgments based on vague feelings—"this seems tightly coupled" or "loose coupling is supposedly better"—but when I tried to articulate why, I couldn't explain it clearly.To address this lack of visibility, we need a way to measure coupling. But the traditional single axis of "strong vs. weak" isn't enough. The same "strong coupling" means different things depending on where it occurs and in what context.This brings us to Vlad Khononov's concept of "Balanced Coupling." It's a framework that evaluates coupling across three dimensions: strength, distance, and volatility, then assesses their balance. cargo-coupling is a tool I developed to implement this framework for Rust projects.Even as AI writes more of our code, this coupling metric becomes increasingly important. Regardless of who or what writes the code, humans still need to understand, maintain, and extend it. In fact, precisely because AI generates code, we need objective measures to evaluate its structure.Let's start with an overview of the tool, then explore the underlying concepts, and finally see how to use it in practice.What is cargo-coupling?cargo-coupling is a coupling analysis tool I developed for Rust projects.The inspiration came from Vlad Khononov's book "Balancing Coupling in Software Design." The challenges I had vaguely sensed about coupling design were systematically organized in this book. I was impressed by the framework that captures coupling through three dimensions—strength, distance, and volatility—and wanted to create a tool that makes this practical for Rust projects. I highly recommend picking up the book.The tool is available on GitHub. If you find it useful, I'd appreciate a star!GitHub:github.comcrates.io: https://crates.io/crates/cargo-couplingNow, let's challenge a common assumption."Coupling should be minimized"—isn't that what you believe?This tool doesn't aim to "reduce coupling." It aims to "design coupling appropriately." Why? Because coupling isn't inherently bad. Related functionality working closely together is natural. The problem is "strong coupling in inappropriate places" or "tight coupling between distant modules." This shift in perspective is at the heart of this tool.# Installationcargo install cargo-coupling# Basic usagecargo coupling ./srcAnalyzing Coupling Across Three DimensionsSo what exactly constitutes "appropriate coupling"?Traditional coupling analysis tends to think in terms of a single "strong/weak" axis. But stop and consider: strong coupling with an adjacent module versus strong coupling with a distant external library—shouldn't these mean different things? And coupling with code unchanged for five years versus coupling with code modified weekly—shouldn't these carry different risks?A single axis can't capture these differences. cargo-coupling measures coupling across three independent dimensions.1. Integration StrengthThe first dimension is "coupling strength"—how much modules know about each other's internals.Have you seen code like user.password_hash that directly accesses struct fields? That's the strongest form of coupling. Meanwhile, code that interacts through impl Trait works without knowing the other's internals. This difference gets quantified as a score. Level  Score  Description  Rust Example  Intrusive  1.00  Direct dependency on internal implementation  struct.field direct access  Functional  0.75  Dependency on function signatures  Method calls  Model  0.50  Dependency on data structures  Type definitions, type parameters  Contract  0.25  Interface/trait only  impl Trait 2. DistanceThe second dimension is "distance"—how far apart coupled modules are in the code's scope hierarchy.Functions within the same file working closely together is natural. But what if src/auth/login.rs directly references src/billing/invoice.rs? Or worse, depends on an external crate's internal structure? The farther the distance, the "heavier" that coupling becomes. Level  Score  Description  SameModule  0.25  Within the same file/module  DifferentModule  0.50  Different module in the same crate  DifferentCrate  1.00  External crate dependency 3. VolatilityThe third dimension is "volatility"—how frequently the code changes.Your project surely has stable modules untouched for over a year alongside modules modified weekly. Depending on stable code versus frequently changing code carries different risks. cargo-coupling automatically calculates this volatility from Git history. Level  Score  Changes in 6-month Git history  Low  0.00  0-2 changes  Medium  0.50  3-10 changes  High  1.00  11+ changes Calculating the Balance ScoreWe've covered the three dimensions. But if you're told "strength is 0.75," "distance is 0.50," "volatility is medium"—how do you judge whether this coupling is actually good or bad?cargo-coupling combines these three dimensions into a balance score. By consolidating three numbers into one score, you can intuitively assess whether coupling is appropriate.The concept is simple: multiply "strength-distance balance" by "volatility risk."ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACTThe first formula measures whether strength and distance are proportionate. Close distance can tolerate strong coupling; far distance should mean weak coupling. The second formula measures the combined risk of change frequency and coupling strength. Strong coupling with frequently changing code means higher risk of being affected by every change.The conclusions this formula leads to:Strong coupling + Close distance → Good: High cohesion with related functionality in one moduleWeak coupling + Far distance → Good: Loose coupling architecture with minimal inter-module dependenciesStrong coupling + Far distance → Bad: Global complexity where changes affect wide areasStrong coupling + High volatility → Bad: Change propagation risk where frequent changes cascadePractical UsageNow that we understand the theory, let's see how to use it on real projects. cargo-coupling offers multiple output formats depending on your needs.Summary Displaycargo coupling --summary ./srcExample output:Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9Hotspot AnalysisIdentify high-priority modules that need refactoring.cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rsImpact AnalysisExamine the impact scope when changing a specific module.cargo coupling --impact metrics ./srcWeb UI VisualizationVisualize coupling relationships with an interactive graph.cargo coupling --web ./srcA browser opens automatically, displaying an interactive graph using Cytoscape.js. Click nodes to see detailed information; problematic modules are color-coded.CI/CD IntegrationBeyond manual analysis, you can continuously monitor quality. Incorporating cargo-coupling as a quality gate enables early detection of coupling design degradation.cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actions example:- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcReturns exit code 1 when the grade falls below the threshold, making it easy to integrate into CI pipelines.AI IntegrationWhen using with Claude Code or GitHub Copilot, the --ai option is convenient.cargo coupling --ai ./srcOutput is formatted in an AI-friendly way, so you can paste it directly into AI tools to get refactoring suggestions.Detected Problem PatternsHaving covered usage, you might wonder what specific problems get detected. Here are the representative patterns cargo-coupling warns about.God ModuleA module with too many functions, types, or impls.Functions: 30+Types: 15+Impls: 20+High Efferent CouplingA module with too many dependencies. Default threshold is 20+ dependencies.High Afferent CouplingA module depended on by too many others. Default threshold is 30+ dependents.Cascading Change RiskThe combination of intrusive coupling and high volatility. A dangerous state where changes propagate across wide areas.Interpreting Health GradesDetection results are ultimately consolidated into a single grade representing overall project health. Grade  Description  S  Over-optimized. Might be over-refactored  A  Well-balanced. Ideal state  B  Healthy. Manageable condition  C  Room for improvement  D  Attention needed  F  Immediate action required Interestingly, S grade is considered "overdone." Why?Reducing coupling too much fragments code excessively, making the big picture harder to see. Have you experienced needing to open 10 files to trace a single operation, or getting lost in abstraction layers so deep you wonder "what does this actually do?"Coupling isn't simply "less is better." Balance is key.Library UsageBeyond the CLI tool, you can embed it in your own tools. cargo-coupling is also published as a library, allowing you to call analysis functions directly from code.use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST analysis    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git volatility analysis    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // Balance analysis    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}Performancecargo-coupling is designed to run fast even on large projects.Parallel AST analysis with RayonStream processing of Git historyBenchmarks: 655ms on tokio (488 files)Use the --no-git option to skip Git analysis for even faster operation.LimitationsWhile useful, this tool isn't omnipotent. Know these limitations before using it.External crate dependencies aren't analyzed: Dependencies on serde, tokio, etc. aren't analyzed since developers can't control themStatic analysis only: Runtime behavior and macro expansion aren't fully capturedGit history required: Volatility analysis needs Git history. Short history reduces accuracyConclusioncargo-coupling provides a practical approach of "choosing appropriate coupling" rather than the simplistic view that "coupling is bad."3-dimensional analysis: Considers strength, distance, and volatility simultaneouslyGit integration: Reflects actual change frequency as dataActionable suggestions: Presents concrete refactoring actionsMultiple output formats: Text/JSON/Web UI/AI-friendlyCI/CD integration: Automated checks as quality gatesYou don't need perfect design. With a pragmatic attitude that "80% improvement is enough," gradually improve your project's health.# Try it outcargo install cargo-couplingcargo coupling --summary ./srcJust visualizing coupling problems is the first step toward better design.The next time you feel "I really don't want to touch this module..."—that's no longer a vague anxiety. It's a tractable challenge you can analyze across three dimensions of strength, distance, and volatility, and translate into concrete improvement actions. That feeling isn't something to fear; it's the entry point to improvement.A related concept is "Complexity" from John Ousterhout's "A Philosophy of Software Design." It offers another valuable perspective and is well worth reading.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Pulumi: Provisioning Your First Infrastructure with Python]]></title>
            <link>https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Sun, 21 Dec 2025 04:29:37 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[ おい、休め]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</guid>
            <pubDate>Sun, 21 Dec 2025 00:24:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに金曜日の夜、ベッドの上でこの文章を書き始めている。先週の土日は何をしていたかと聞かれたら、たぶん「寝てた」と答える。嘘ではない。ベッドにいた時間は長かった。ただ、眠っていたかというと怪しい。スマホを持ったまま横になって、気づいたら夕方だった。そういう二日間だった。休んだのか、と聞かれると困る。体は動かしていない。仕事もしていない。だから休んだと言えば休んだのだろう。でも、回復したかというと、していない。月曜の朝を迎える自分は、金曜の夜の自分より確実に疲れている。 何もしていないのに。何もしていないから、かもしれない。30歳になった。エンジニアとして働いている。在宅勤務というやつだ。2025年、AIエージェントが当たり前になった時代を生きている。AIは文句を言わない。疲れたとも言わない。24時間動ける。私にはそれができない。コーヒーがないと朝は動けないし、金曜の午後は集中力が死んでいる。土日は「充電」と称してベッドに沈んでいる。それでも充電されない。この一年、ずっとそうだった。ある日、気づいたことがある。私は「休んでいる」んじゃなくて、「動けなくなっている」だけだった。充電じゃなくて、バッテリー切れの放置だった。「休んでいるのに休めていない」とは、「休んでいるのに休めていない」。変な問答である。矛盾しているように聞こえるが、多くの人がこの感覚を知っていると思う。週末を過ごしたはずなのに、月曜日の朝に疲れが残っている。肉体的には、労働的には、確かに「活動していない」。仕事をしていない。オフィスにいない。だから「休んでいる」となんとなく認識する。しかし脳は、休んでいない。ベッドに横になりながらスマホを見ている時、目は画面を追い、脳は情報を処理し、感情は刺激に反応し続けている。通知が来るたびに注意が引かれる。SNSのタイムラインをスクロールするたびに、微小な判断が積み重なる。「これは読む価値があるか」「これにいいねするか」「これに反応すべきか」。身体は止まっているが、脳は回り続けている。これが「休んでいるのに休めていない」の正体だ。情報を入れ続けると、脳は整理する暇がない。食べ続けて消化できない胃のように、頭がパンク状態になる。入力過多で、整理が追いついていない。なぜ本人は「休んでいるつもり」になってしまうのか厄介なのは、本人が気づいていないことだ。私もそうだった。「横になっている＝休んでいる」。この等式が、骨の髄まで染み込んでいる。かつて「休む」とは、物理的に動かないことを意味した。畑仕事を終えて家に帰り、座って何もしない。工場での労働を終えて、ソファに横になる。肉体労働の時代には、「動かない = 休息」という等式が成り立っていた。しかし現代のデスクワーク的な仕事は、主に脳を使う。特にエンジニアは、一日中座っている。肉体は動いていない。だから「仕事 = 動くこと」という図式が崩れている。そして「休息 = 動かないこと」という古い図式をそのまま適用すると、「横になってスマホを見ること」も休息にカウントされてしまう。肉体的には動いていないのだから。でも実際には、脳は仕事中と同じかそれ以上に動いている。休息の定義を更新する必要がある。現代において「休む」とは、脳への入力を減らすことだ。物理的な動きの有無ではなく、認知的な負荷の有無で判断すべきなのだ。この状態を言語化できないと、何がさらに悪化するのか「休んでいるのに休めていない」という感覚を言葉にできないと、さらに深刻な問題が起きる。まず、自己診断を誤る。「十分休んでいるはずなのに疲れている。だから自分は病気かもしれない」「自分は人より弱いのかもしれない」。実際には休息の質の問題なのに、自分の身体や精神に問題があると思い込んでしまう。次に、対処法を間違える。「もっと休めばいい」と考えて、さらに長時間ベッドでスマホを見る時間を増やす。これは逆効果だ。質の悪い休息を量で補おうとしても、回復はしない。そして最も深刻なのは、周囲に理解されないことだ。「週末何してたの？」「ずっと寝てた」「じゃあ休めたね」。この会話で、問題は見えなくなる。本人も「確かに休んだはずだ」と思い込み、周囲も「休んだのだから元気なはずだ」と期待する。「休んだ」という事実と、「休めた」という実感の乖離。これが現代の休息における新しい病だ。言語化できない問題は、解決できない。 だからまず、この状態に名前をつけることが重要だ。「偽りの休息」「見せかけの休息」「脳が休まらない休息」。何でもいい。言葉にすることで、初めて問題として認識できる。AIエージェント時代の疲労2025年、AIエージェントが本格的に動き始めた。Claude Code、Devin、Cursor Agent。これらは単なるツールではない。私たちと同じように考え、判断し、実行する存在になった。コードを書くだけでなく、何を書くべきかを考える。指示を待つだけでなく、自ら次のステップを提案する。この変化は、エンジニアの疲労の質を根本から変えた。AIは無限に働ける。私たちは有限だ。AIエージェントは疲れない。朝も夜も関係ない。週末も祝日も関係ない。感情の浮き沈みもない。モチベーションの低下もない。常に一定のパフォーマンスで、無限に働き続ける。私たちは、そうではない。8時間働けば疲れる。集中力は25分で途切れる。昼食を食べすぎると眠くなる。金曜日の午後は効率が落ちる。睡眠不足の翌日は判断を誤る。感情に左右される。体調に左右される。天気にすら左右される。この対比が、2025年の疲労を特殊なものにしている。かつて、比較対象は同僚だった。隣の席のエンジニアより速くコードを書けるか。チームの中で自分はどの位置にいるか。人間同士の比較だった。今、比較対象にAIが加わった。AIエージェントが一晩で書いたコードを見て、「自分が一週間かかることを、一晩でやった」と思う。AIが瞬時に出した答えを見て、「自分が一時間悩んだことを、数秒で解決した」と思う。無限と有限を比較している。もちろん、話はそう単純じゃない。AIにも限界がある。文脈を読み違える。ハルシネーションを起こす。「それっぽい嘘」を自信満々に言う。コードレビューなしでマージしたら、後で痛い目に遭う。AIが「無限に働ける」のは事実だが、「無限に正しい」わけではない。でも、そんなことは分かっている。分かっていても、比較してしまう。「比較しなければいい」と思ったこともある。でも、環境がそれを許さなかった。同じSlackチャンネルに、自分が1日かけて作ったPRと、AIが1時間で作ったPRが並んでいる。見た瞬間に、脳が勝手に比較する。「あっちの方が速い」と。そう思った時点で、もう比較している。これは意志の問題じゃない。環境の問題だ。同じ画面に並んで表示されている限り、見比べてしまう。見比べれば、負ける。負ければ、「自分は遅い」「自分は非効率だ」「自分は価値がない」と感じる。この感覚が、静かに、確実に、私たちを消耗させている。AIによって増えたのは「作業量」だけではなく、AIエージェントを使うと、作業は速くなる。コードの生成、ドキュメントの作成、調査の実行。これらは確かに効率化される。しかし、楽にはならない。夕方になると、頭が重い。コードを書く時間は減った。でも疲労感は増えている。増えたのは作業量じゃない。判断の回数だ。AIエージェントは大量の選択肢を提示する。コードの候補を10個出す。アプローチを5つ提案する。修正案を複数示す。これらを評価し、選択し、修正し、採用するかどうかを決めるのは人間だ。従来の仕事では、一つのタスクに対して一つの判断があった。自分で作るから、作成と判断が一体化していた。AIを使うと、この構造が変わる。AIが10個の選択肢を提示する。人間は10個を評価し、1つを選ぶ。あるいは「どれも違う」と判断して再生成を指示する。今度は別の10個が出てくる。また評価する。選ぶ。修正を指示する。一つのタスクに対して、判断の回数が爆発的に増える。思い当たることがある。午前中は「これがいい」「あれはダメ」とサクサク判断できる。でも夕方になると、どれを選んでいいか分からなくなる。「どれでもいいから決めてくれ」と思う。頭が重くなって、判断を先延ばしにしたくなる。これは、判断そのものに消耗があるということだ。人間が一日に下せる質の高い判断の数には限りがある。 判断を重ねるほど、後の判断の質は落ちる。AIは判断を代行してくれない。むしろ、判断すべき選択肢を増やす。だから、作業時間が減っても、認知的な消耗は増える。「便利になった」という感覚と、「楽になった」という現実は、必ずしも一致しない。「速くなった」と感じるのに、疲れは減らない。この乖離は危険だ。「速くなっている」と思い込んでいる限り、「なぜ疲れるのか」という問いにたどり着けない。AI疲れはスキル不足の問題ではないAI疲れを感じたとき、多くの人はこう考える。「自分のスキルが足りないからだ」「もっとAIを使いこなせるようになれば楽になる」。正直に言うと、私もそう思っていた。だから毎晩、新しいツールを試し、プロンプトを改善し、ワークフローを最適化した。でも楽にはならなかった。むしろ疲れた。ただ、ここで立ち止まって考えたい。私はこう思うようになった。それは違うんじゃないか、と。確かに、AIツールの使い方には習熟曲線がある。最初は戸惑う。慣れれば効率が上がる。しかし、ある程度習熟した後も、判断疲れは消えない。むしろ、AIを使いこなせるようになるほど、使う頻度が上がり、判断の回数も増える。AI疲れ ≠ スキル不足。AI疲れ = 判断疲れだ。 あなたが下手なんじゃない。ゲームのルールが変わったのだ。AIは人間の判断を代行しない。判断の対象を増やす。この構造的な問題は、スキルアップでは解決しない。解決策は、使い方を変えることだ。AIに全てを任せるのではなく、判断の負荷が高い場面では意識的に使わない。あるいは、AIの出力をそのまま採用する覚悟で使う（評価・修正のループを断ち切る）。しかしこれは、「AIを使いこなす」という文脈では語られない。だから多くのエンジニアは、スキル不足を疑い、さらに学習し、さらに使い、さらに疲れる。AI疲れの原因を正しく特定して認識することが、回復への第一歩だ。「恥」という名の監視システムエンジニアには、独特の恥の文化がある。Xを開く。誰かが「今週読んだ技術書3冊」と投稿している。誰かが「個人開発で新しいフレームワークを試した」と書いている。GitHubの草が青々と茂っている。日曜日の夜に。その瞬間、土日に何もしなかった自分が恥ずかしくなる。「エンジニアは勉強し続けなければならない」。これは真実だ。技術は進化する。学ばなければ置いていかれる。それは分かっている。でも、いつからか「土日に勉強するのが当たり前」になった。休日に技術書を読まないと不安になる。個人開発をしていないと焦る。Qiitaに何も投稿していない月があると、自分の価値が下がった気がする。私たちは「恥」に操られている。恥は、外部から強制されるものではない。誰かに「勉強しろ」と言われているわけではない。上司が土日の学習を義務付けているわけでもない。自分で自分を監視している。 SNSで他人の「充実した週末」を見て、勝手に比較して、勝手に恥じて、勝手に休めなくなっている。これが最も効率的な搾取システムだ。命令する必要がない。監視する必要がない。本人が勝手に自分を追い詰めてくれる。見せかけの「学習」が休息を奪う問題は、この「恥を避けるための学習」が、本当の意味での学習になっていないことだ。土曜日の朝、罪悪感から技術書を開く。でも頭に入ってこない。疲れているから。ページをめくるけど、内容が定着しない。それでも「読んだ」という事実が欲しくて、最後までめくる。これは学習ではない。休息でもない。どちらでもない時間だ。本当に学びたいときの読書と、恥を避けるための読書は、まったく別物だ。前者は楽しい。後者は苦痛だ。前者は定着する。後者は忘れる。恥を避けるために費やした土日は、学習にも休息にもならない。最悪の投資だ。 時間を使って、何も得られず、回復もしない。SNSで他人の土日を見るな。あれは広告だ。冷静に考えてほしい。Xに投稿される「充実した週末」は、全員の週末の平均ではない。投稿したくなるような週末だけが投稿される。何もしなかった週末は投稿されない。つまり、タイムラインに流れてくるのは、全エンジニアの「最も充実した瞬間」の集合体だ。それを自分の「普通の週末」と比較している。勝てるわけがない。他人の土日は広告だ。 広告と自分を比較して落ち込むのは、モデルの写真を見て自分の顔を恥じるのと同じだ。フィルターがかかっている。編集されている。現実ではない。恥を手放すことは、怠惰ではない「じゃあ勉強しなくていいのか」と思うかもしれない。そうではない。学びたいときに学べばいい。休みたいときに休めばいい。恥に駆動されるのをやめろ、と言っている。恥から学習すると、燃え尽きる。好奇心から学習すると、続く。この違いは大きい。土日に何もしなかった自分を、責めなくていい。月曜日に元気に働けるなら、それが正解だ。GitHubの草が生えていなくても、あなたの価値は変わらない。恥は、休息の最大の敵だ。 そして恥は、自分で自分にかけている呪いだ。縛りである。しかし、呪いは、気づいた瞬間に弱くなる。注意力が商品化されるとは、人生に何が起きることなのかふと考えた。なぜ、こんなに疲れているのか。答えの一つは、私たちの注意力が「商品」として売買されているということだ。スマホを開く。通知が来る。タップする。広告が表示される。スクロールする。また通知が来る。この一連の行動の中で、私たちの「注意力」は企業に売り渡されている。そして企業はその注意力を広告主に売る。注意力が奪われることは、なぜ「時間」以上の損失なのか「時間が奪われている」という表現は、まだ甘い。時間は、失っても取り戻せる可能性がある。今日の2時間を失っても、明日の2時間で何かができる。少なくとも、時間は均質に見える。しかし注意力は違う。注意力とは、「今この瞬間に何を経験するか」を決める力だ。何に注意を向けるかが、何を経験するかを決める。何を経験するかが、何を記憶するかを決める。何を記憶するかが、自分が誰であるかを決める。つまり、注意力を奪われることは、経験を奪われることであり、記憶を奪われることであり、最終的にはアイデンティティを奪われることだ。2時間スマホをスクロールして過ごした後、何が残っているか。私の場合、ほとんど何も覚えていない。「何を見てたっけ」と思い返しても、断片的な画像がぼんやり浮かぶだけ。時間は確かに過ぎた。でも経験は残っていない。一方で、友人と2時間話した後は違う。「あの話、面白かったな」「あのとき笑ったな」と、具体的な場面が残っている。同じ2時間でも、記憶への定着度がまるで違う。スマホを見ることも、一応は「経験」だ。でも、受け身で流れてくる情報を処理するだけの経験と、自分で選んだ活動に没頭する経験では、残り方が違う。受け身の時間は、砂に書いた文字のように消えていく。時間泥棒ではなく、人生泥棒だ。なぜ人は自分の注意力の価値に無自覚なのか注意力は、意識しないと見えない。お金は数字として見える。時間は時計として見える。しかし注意力は、どこにも可視化されていない。そして注意力は、「使っている」という感覚がない。お金を使うとき、財布が軽くなる感覚がある。時間を使うとき、時計が進む感覚がある。しかし注意力を使うとき、何かが減っていく感覚は薄い。ただ、気づいたら疲れている。さらに問題なのは、注意力を奪う側が、その事実を隠すインセンティブを持っていることだ。SNSは「つながり」を売り物にする。「あなたの大切な人とつながるためのツール」。しかし実際には、あなたの注意力を広告主に売るためのツールだ。この真実は、マーケティングでは語られない。だから私たちは、自分の注意力が商品になっていることに気づかない。気づかないまま、どんどん売り渡していく。この構造に気づいても、人はなぜ抗えないのか気づいても、抗えない。これが最も絶望的な部分だ。理由の一つは、脳の報酬系がハックされているからだ。通知が来る。ドーパミンが出る。確認する。また通知が来る。この「不定期な報酬」は、脳にとって最も中毒性が高い。スロットマシンと同じ原理だ。いつ当たるか分からないから、ずっと引き続けてしまう。理由のもう一つは、社会的なプレッシャーだ。みんなが使っている。使わないと取り残される。返信しないと失礼。既読をつけないと心配される。SNSから離れることは、社会から離れることのように感じられる。そして最後の理由は、代替手段がないことだ。仕事の連絡もスマホで来る。友人との約束もスマホで確認する。情報収集もスマホでする。スマホを捨てることは、現代社会で生きることを諦めることに近い。構造的な問題には、個人の意志力だけでは対抗できない。だからこそ、意識的な「デジタルデトックス」が必要になる。完全に離れることはできなくても、時間を区切って距離を取る。それが、今できる最大の抵抗だ。オンライン会議は、なぜ「効率的なのに疲れる」のかスマホから注意を奪われるだけではない。在宅勤務の日常には、もう一つの消耗源がある。オンライン会議だ。最初はただ素晴らしいと思った。移動時間がない。どこからでも参加できる。効率的だ、と。でも二年、三年と続けるうちに、何かがおかしいと気づいた。ある日、オンライン会議が5本続いた後、私は何も考えられなくなっていた。画面を閉じても、頭の中がぼんやりしている。簡単なメールすら書けない。対面で5本会議しても、こんなに消耗しなかった。何かが違う。対面では無意識に処理していた情報とは何か対面のコミュニケーションでは、膨大な情報が交換されている。言葉だけではない。表情、視線、姿勢、身振り、声のトーン、間の取り方、呼吸のリズム、空間的な距離感。これらの非言語情報が、コミュニケーションの大部分を占めている。そして重要なのは、これらの情報を無意識に処理しているということだ。対面で話しているとき、相手の表情を「分析」しているわけではない。自然と読み取っている。相手が不快そうなら、無意識に話し方を変える。相手が興味を持っていそうなら、無意識に詳しく説明する。この調整は、意識的な努力なしに行われている。オンライン会議では、この無意識の処理が機能しなくなる。画面越しでは、表情が見えにくい。解像度が低い。タイムラグがある。視線が合わない（カメラを見ると相手の目を見られない）。空間的な距離感がない。全員が同じサイズで画面に並んでいる。無意識に処理できていた情報を、意識的に処理しなければならなくなる。「この人は今、何を考えているのだろう」「この沈黙は同意なのか、困惑なのか」「自分の話は伝わっているのか」。対面なら自動的に分かることが、オンラインでは分からない。だから脳がフル回転して、推測し、分析し、判断する。これが、オンライン会議の疲労の正体だ。さらに、自分の顔が常に画面に映っている。鏡を見ながら会話しているようなもの。音声も微妙に不完全で、脳は余計な労力を使う。同じ1時間でも、処理している情報の密度が違う。だから疲れる。私はこの疲労を個人の問題だと思っていた。でも違った。組織の設計そのものが、この疲労を生み出している。振り返ると、非同期のコミュニケーションで済むことを、わざわざ会議で行っていた。私自身、「対話が必要な場面」に限定することで、オンライン会議の負荷を減らせた。ある日、仕事を一つ担当から外してもらった。「これ、ちょっと抱えすぎてます」と正直に言った。その週、少しだけ頭がクリアだった。「手放してもいい」と思えた瞬間だった。境界線が消えたとき、人間の回復機構はどう壊れるのか在宅勤務で最も失われたもの。それは「境界線」だ。帰りたいのに家に居る。オフィスに通っていた頃は、自然と境界線があった。家を出る。通勤する。オフィスに着く。仕事モードになる。仕事が終わる。オフィスを出る。通勤する。家に着く。オフモードになる。この物理的な移動が、心理的な切り替えを助けていた。在宅勤務では、その境界線が消えた。起きたらすぐに仕事。寝る直前まで仕事。仕事部屋と寝室が同じ。リビングがオフィス。どこでも働ける = どこにも逃げ場がない。物理的な移動は、なぜ心理的切り替えに効いていたのか通勤を嫌う人は多い。満員電車。渋滞。時間の無駄。その通りだ。しかし通勤には、見えない機能があった。通勤は「儀式」だった。人間の脳は、儀式を通じて状態を切り替える。朝のルーティン、食事の作法、寝る前の習慣。これらの儀式が、脳に「次のモードに入る」というシグナルを送る。通勤は、最も強力な儀式の一つだった。家という空間を離れ、別の空間に移動する。その過程で、脳は自然と「仕事モード」に切り替わっていた。帰宅時には逆のプロセスが起きていた。この儀式が消えると、脳は切り替えのタイミングを失う。「いつ仕事を始めるべきか」「いつ仕事を終えるべきか」が曖昧になる。そして気づけば、常に「なんとなく仕事モード」で過ごすことになる。常に仕事モードということは、常に回復モードに入れないということだ。境界線がない働き方は、どんな人に特に危険か特に危険なのは、責任感が強い人と仕事が好きな人だ。「まだできることがある」と思うと止められない。楽しいから止められない。境界線がないと、いつまでも「まだやれる」と思ってしまう。個人の工夫と、その限界着替える。仕事着から部屋着に。あいさつを声に出す。「お疲れ様でした」。これらの小さな儀式が、切り替えを助ける。しかし、限界がある。本来、境界線は環境によって与えられていた。それを個人の意志で維持し続けることは、それ自体が消耗を伴う。だから、環境そのものを変える必要がある。 仕事専用の部屋を作る。コワーキングスペースを使う。PCを別の部屋に置く。物理的に「できない」状態を作る。意志力に頼らない仕組みを作ること。それが、境界線を維持する現実的な方法だ。「疲れた」と感じるとき、本当に疲れているのはどこか「疲れた」と口にする。でも、どこが疲れているのか、自分でも分かっていない。疲れには三つの種類がある。「自律神経の疲れ」。自律神経とは、意識しなくても働く神経システムだ。活動モードを司る交感神経（心拍を上げ、筋肉を緊張させる）と、休息モードを司る副交感神経（心拍を下げ、消化を促す）がある。この二つのバランスが崩れている状態。常に緊張している。リラックスできない。眠れない。朝起きても疲れが取れない。「心の疲れ」。精神的な消耗。ストレス。不安。焦り。人間関係の疲れ。感情労働による消耗。「体の疲れ」。筋肉の疲労。運動不足による倦怠感。同じ姿勢での身体の凝り。自律神経・心・身体のどれが最初に壊れやすいのかこれは個人差があるが、現代のエンジニアにとって、最初に壊れやすいのは自律神経だ。理由は、自律神経の疲労が最も気づきにくいからだ。身体の疲れは分かりやすい。筋肉痛がある。だるさがある。明確な感覚として認識できる。心の疲れも、ある程度は分かる。「イライラする」「落ち込む」「やる気が出ない」。感情として表れる。しかし自律神経の疲れは、症状が曖昧だ。「なんとなく調子が悪い」「眠れない」「食欲がない」「息苦しい」。これらの症状は、他の原因でも起きる。だから「自律神経が疲れている」とは認識されにくい。そして気づかないまま酷使し続けると、ある日突然、限界を超える。動悸がする。めまいがする。パニック発作が起きる。ここまで来て初めて「何かがおかしい」と気づく。自律神経は悲鳴を上げない。気づいたときには、もう限界を超えている。なぜ現代のエンジニアは三重苦に陥りやすいのか問題は、これらが複雑に絡み合っていることだ。長時間のデスクワークで体が疲れる。動かないから血流が滞り、肩が凝り、腰が痛くなる。AIへのキャッチアップ、締め切りのプレッシャー、評価への不安で心が疲れる。オンライン会議の連続、境界線のない働き方、常時接続のプレッシャーで自律神経が疲れる。これらは独立していない。相互に影響し合う。身体が疲れると、心も疲れやすくなる。運動不足はうつ病のリスクを高める。心が疲れると、自律神経が乱れる。ストレスは交感神経を活性化させる。自律神経が乱れると、身体の回復力が落ちる。悪循環のスパイラル。一つの疲れが、他の二つを引き起こし、それがまた最初の疲れを悪化させる。このスパイラルに入ると、自力で抜け出すのは難しい。疲れを誤診すると、どんな「間違った休み」を選ぶのか疲れの種類を見極めずに休もうとすると、的外れな対処をしてしまう。身体が疲れているのに、心の休息を取ろうとする。例えば、運動不足で身体が固まっているのに、マッサージに行ったり、リラクゼーション音楽を聴いたりする。これは悪くないが、根本解決にならない。必要なのは軽い運動だ。心が疲れているのに、身体の休息を取ろうとする。例えば、人間関係のストレスで消耗しているのに、ひたすら寝ようとする。眠れない。眠れても回復しない。必要なのは、安全な場所で感情を吐き出すことだ。自律神経が疲れているのに、刺激で気分転換しようとする。例えば、交感神経が過剰に活性化しているのに、アクション映画を観たり、激しいゲームをしたりする。一時的に気が紛れても、神経はさらに疲弊する。必要なのは、静かな環境でぼんやりすることだ。自分の疲れの種類を見極めること。それが、正しく休むための第一歩だ。身体がシャットダウンする「動けなさ」は、怠惰と何が違うのかベッドから起き上がれない朝がある。やるべきことは分かっている。でも体が動かない。これは怠けているのか。それとも、何か別のことが起きているのか。自分の「動けなさ」について考えていくうちに、気づいたことがある。怠惰と「動けなさ」は、外から見ると同じに見える。でも中身はまったく違う。怠惰は「やる気がない」状態だ。やろうと思えばできる。でもやりたくない。シャットダウンは「動けない」状態だ。やろうと思っても、身体が言うことを聞かない。脳が「これ以上は危険だ」と判断して、強制的にブレーキをかけている。これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。身体を動かなくすることで、エネルギーを温存する。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。社会はなぜこの状態を「甘え」と誤認するのか問題は、シャットダウン状態が外から見ると「怠けている」ように見えることだ。ベッドから起き上がれない。仕事に行けない。何もする気力がない。社会は、これを「意志の問題」として捉えがちだ。「頑張れば動ける」「やる気がないだけ」「甘えている」。しかし、これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。これがシャットダウン反応だ。身体を動かなくすることで、エネルギーを温存し、捕食者の関心を逸らす。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。これは意志の問題ではない。脳が「これ以上は危険だ」と判断して、強制的に止めているのだ。怠惰との違いは明確だ。怠惰は「やる気がない」状態。やろうと思えばできる。シャットダウン状態は「動けない」状態。やろうと思っても、身体が言うことを聞かない。この区別ができないと、本人も周囲も対応を間違える。本人が自分を責めることで、状態はどう固定化されるのか最も危険なのは、本人が自分を責めることだ。「動けないのは自分が怠けているからだ」「意志が弱いからだ」「努力が足りないからだ」。この自己批判が、状態をさらに悪化させる。自己批判はストレスを生む。ストレスは交感神経を活性化させる。しかし、すでに疲弊した身体は交感神経の活性化に耐えられない。だから、また身体がシャットダウンする。「動けない → 自分を責める → ストレス増加 → さらに動けなくなる → さらに自分を責める」この悪循環が、状態を固定化する。回復するためには、この循環を断ち切る必要がある。そのためにはまず、「動けないのは意志の問題ではない」と理解することが重要だ。 自分を責めることをやめる。これが、回復への第一歩だ。この凍結状態から抜けるには、何が最初の一歩になるのかシャットダウン状態から抜け出すのは、簡単ではない。「頑張って動く」というアプローチは逆効果になりうる。有効なのは、身体への穏やかなアプローチだ。まず、安全を感じること。物理的に安全な場所にいる。誰にも批判されない。時間的なプレッシャーがない。この「安全の感覚」が、安心・つながりモードを呼び起こす。次に、身体を少しだけ動かすこと。激しい運動ではない。深呼吸。ゆっくりとしたストレッチ。5分の散歩。これらの穏やかな動きが、身体に「動いても大丈夫だ」というシグナルを送る。そして、人とのつながり。信頼できる人との会話。これらの社会的なつながりが、安心・つながりモードを呼び起こす。重要なのは、「頑張る」のではなく「許す」ことだ。動けない自分を責めない。ゆっくり回復することを許す。無理に何かを達成しようとしない。このスタンスが、凍結状態から抜け出すための土台になる。私自身、過去の失敗をいつまでも反芻して、自分を追い詰めていた時期がある。でも気づいた。忘れることは、逃げではない。 嫌な記憶を手放すことで、初めて前に進める。回復とは、忘れるべきものを忘れられるようになることでもある。なぜ「何もしない休み」が回復にならない場合があるのか休息も、量を追い求めるだけでは意味がない。「長時間休んだ」という事実よりも、「どう休んだか」という質の方がずっと重要だ。休息には二つのタイプがある。「パッシブレスト（消極的休養）」。何もしない。寝る。横になる。身体を動かさない。これは従来の「休息」のイメージだ。「アクティブレスト（積極的休養）」。軽く身体を動かす。散歩する。ストレッチする。ヨガをする。能動的に身体を使うことで回復する。どちらが正解か、ではない。どちらが自分に足りていないかが問題だ。ただ、直感に反するが、現代のエンジニアにはアクティブレストの方が足りていない場合が多い。パッシブレストが逆効果になる条件は何かパッシブレストが逆効果になるのは、以下のような場合だ。身体が動かなすぎているとき。一日中座っていて、血流が滞っている。筋肉が固まっている。この状態でさらに横になっても、血流は改善しない。疲労物質は排出されない。むしろ、さらに滞留する。脳だけが疲れているとき。身体は使っていない。脳だけが酷使されている。この状態で「何もしない」と、身体と脳のアンバランスが解消されない。脳を休めるには、逆に身体を動かす方が効果的な場合がある。横になりながら刺激を受けているとき。ベッドでスマホを見ている状態。身体は休んでいるが、脳は休んでいない。これは休息ではない。むしろ、最悪の組み合わせだ。社会的な孤立状態のとき。一人で何もしない時間が長すぎると、孤独感が増す。孤独は心身に悪影響を与える。パッシブレストが孤独を深めるなら、逆効果だ。アクティブレストは、なぜ自律神経に効くのかアクティブレストが効果的な理由は、生理学的に説明できる。血流が改善する。軽い運動は心拍数を適度に上げ、血液循環を促進する。これにより、筋肉に蓄積した疲労物質が排出される。新鮮な酸素と栄養が全身に行き渡る。自律神経のバランスが整う。適度な運動は、交感神経と副交感神経の切り替えをスムーズにする。運動中は交感神経が優位になり、運動後は副交感神経が優位になる。このリズムが、自律神経の柔軟性を高める。脳の状態が変わる。運動は脳内のセロトニンやエンドルフィンの分泌を促す。これらの神経伝達物質は、気分を改善し、ストレスを軽減する。「運動後に気分がスッキリする」のは、この効果だ。睡眠の質が向上する。日中に適度に身体を動かすと、夜の睡眠が深くなる。これにより、睡眠中の回復効率が上がる。アクティブレストは、受動的な休息では得られない回復効果をもたらす。「休んでいるのに疲れる」行動には共通点があるか「休んでいるつもりなのに疲れる」行動を分析すると、共通点が見えてくる。脳への入力が続いている。スマホ、テレビ、SNS。これらは「受動的」に見えるが、脳は常に情報を処理している。休息ではなく、低負荷の作業だ。身体が動いていない。座っている。横になっている。血流が滞る。筋肉が固まる。代謝が落ちる。社会的なつながりがない。一人で画面に向かっている。人との会話がない。孤独が深まる。達成感がない。ただ時間が過ぎるだけ。何も生み出していない。何も経験していない。虚しさが残る。能動的に選ばなかった時間は、記憶に残らない。後から振り返っても、「何をしていたんだっけ」と思い出せない。これらを逆転させれば、「本当に休まる休息」が見えてくる。脳への入力を減らす。画面から離れる。静かな環境に身を置く。身体を動かす。散歩する。ストレッチする。軽い運動をする。人とつながる。会話をする。一緒に過ごす。達成感を得る。小さなことでいい。料理を作る。掃除をする。何かを「やった」という感覚を持つ。選択的休養という考え方「休む」というと、どうしても「消極的」なイメージがある。何もしない。停止する。エネルギーを使わない。でも、より効果的な休養の形がある。自分で選ぶ休養だ。休息は空いた時間を埋めるものではない。休息は設計対象だ。どう休むかを、自分で決める。「そんな時間ないよ」と思うかもしれない。でも、選択的休養は時間の量ではなく質の問題だ。30分でもいい。自分で選んだ30分は、誰かに決められた2時間より回復効果がある。選択的休養とは、自分の意志で、自分のために選んだ活動のことだ。ポイントは「自分で選ぶ」ことにある。誰かに言われてやるのではない。義務感でやるのではない。「やるべき」だからやるのではない。自分が「やりたい」と思って選ぶ。この「選ぶ」という行為自体が、回復をもたらす。なぜ「自分で選ぶ」ことに意味があるのか現代の疲労の多くは、選択権を奪われていることから来ている。仕事では、やるべきことが決まっている。締め切りがある。上司の指示がある。クライアントの要望がある。自分で選ぶ余地が少ない。プライベートでも、「やるべきこと」に追われている。家事、育児、介護、人付き合い。「自分のため」ではなく「誰かのため」に時間を使う。そして「空いた時間」にスマホを見る。これも、実は選択ではない。アルゴリズムが見せたいものを見せられている。自分で選んでいるようで、選ばされている。常に誰かに決められた行動をしている。だからこそ、「自分で選ぶ」ことに価値がある。自分で選んだ活動をしているとき、脳は「自分の人生をコントロールしている」と感じる。この感覚が、ストレスを軽減し、回復を促進する。逆に、誰かに決められた行動をしているとき、脳は「コントロールを失っている」と感じる。これがストレスの原因になる。選択的休養とは、人生の主導権を握り直すことだ。 そしてこれは、何を覚えておくかだけでなく、何を忘れるかを選ぶことでもある。AIは全てを記憶できる。でも人間は違う。だからこそ、意識的に手放す。追いかけなくていい情報を捨てる。キャッチアップしなくていい技術を諦める。その余白に、自分だけの発想が生まれる。選択的休養の条件選択的休養が効果的であるためには、いくつかの条件がある。自分で決めた。誰かに言われてではなく、自分の意志で選ぶ。「やらなければ」ではなく「やりたい」という動機。仕事とは関係ない。スキルアップのための勉強は選択的休養ではない。仕事に役立つ読書も違う。仕事と完全に切り離された活動。なぜなら、仕事に関連している限り、「成果を出さなければ」というプレッシャーがつきまとうからだ。没頭できる。時間を忘れて集中できる。義務感ではなく、純粋な興味や楽しさで取り組める。成長の実感がある（任意）。必須ではないが、少しずつ上達していく実感があると、より効果的だ。仕事以外の領域で「できるようになった」という経験は、自己効力感を高める。私の場合、それは楽器を弾くことと、格闘技のジムに通うことだった。ギターを弾く時間は、仕事とは無関係で、自分で決めた活動で、時間を忘れて没頭でき、少しずつ上達していく実感がある。格闘技のジムには、別の効果がある。自分一人では無限に追い込めない。だから、真剣にやる以外に選択肢がない環境に身を置く。スパーリング中は、仕事のことなど考えていられない。相手のパンチを避けることに全神経を集中させている。休む時は、可能な限り忘れる。 この忘却を強制してくれる環境が、私には必要だった。なぜ「楽ではないこと」が回復になるのかここで一つの逆説に気づく。格闘技は楽ではない。むしろ苦しい。汗をかく。息が切れる。翌日は筋肉痛だ。苦しいのに、なぜかジムの帰り道は頭が軽い。通い続けるうちに、分かってきた。私が選んだ苦しみは、喜びになる。考えてみれば不思議だ。ホラー映画、激辛料理、過酷な登山。人は日常では避けるはずの「痛み」や「恐怖」に、わざわざ金と時間を払って近づく。私も格闘技に月謝を払っている。殴られに行っている。なぜか。「選んだ苦痛」と「押しつけられた苦痛」は、まったく別物だからだ。仕事のストレス、人間関係の摩擦、将来への不安。これらは望んでいない。避けたいのに避けられない。コントロールできない。だから消耗する。格闘技の苦しさは違う。私が選んだ。いつでもやめられる。コントロールできる。だから同じ「苦しい」でも、片方は消耗で、片方は回復になる。そしてもう一つ気づいたことがある。楽なだけの人生は、たぶんつまらない。苦しみを避け続けた先に、充実はない。ベッドでスマホを見続ける週末は、苦しみをゼロにしようとする試みだ。でもそれは、意味もゼロにしてしまう。何も残らない。月曜日に「週末何してた？」と聞かれて、答えられない。格闘技は苦しい。でも意味がある。だから回復する。「楽であること」と「良いこと」は違う。 私はこれを、身体で学んだ。「ギターや格闘技なんて、自分には無理だ」と思うかもしれない。でも、選択的休養の本質は特定の活動ではない。「仕事の自分」とは別の自分に会いに行くことだ。ランニングでも料理でも将棋でも絵でも釣りでもいい。重要なのは、「仕事に役立つかもしれない」という思考を捨てること。 役に立たなくていい。役に立たないからこそ、純粋に楽しめる。その純粋さが、回復をもたらす。もう一つ、見つけ方のコツがある。周りに勧められたものを、何も考えずに始めてみる。自分で選ぼうとすると、「合うかな」「続くかな」と考えすぎて動けなくなる。友人が「一緒にやろう」と誘ってくれたら、とりあえず乗ってみる。合わなければやめればいい。始める前に悩むより、始めてから判断する方がずっと早い。「役に立たない」と思って捨てたものの中に、自分を救うものがある。デジタルデトックスという実践ある日、スマホを置いて散歩に出た。1時間後、頭が軽かった。そこで気づいた。私の疲労の大きな部分は、デジタル機器から来ていた。 正確には、デジタル機器が境界線を消し、常時接続状態を作り、注意力を奪い続けていた。全ての疲労がデジタル由来ではないが、デジタルが他の疲労を増幅させている。だからこそ、「デジタルデトックス」が必要だ。大げさなことではない。スマホを別の部屋に置く。一日一時間、画面を見ない時間を作る。寝る前の一時間はスマホを触らない。これだけでも効果がある。最初は落ち着かない。通知が気になる。何かを見逃しているような気がする。FOMO（見逃すことへの恐怖）が襲ってくる。この不快感こそが「摩擦」だ。 そして摩擦があるからこそ、その先にある回復は本物になる。でも、数日続けると気づく。別に何も見逃していない。大抵のことは、後から確認しても問題ない。「今すぐ」反応しなければならないことなど、実際にはほとんどない。そして画面から離れた時間に、不思議なことが起きる。頭がクリアになる。創造性が戻ってくる。ぼんやりと考えごとをする余裕が生まれる。有限であることを受け入れ、有限であるからこそできることを大切にする。デジタルから離れた時間は、人間としての有限性を肯定する時間だ。スマホを置いた瞬間、世界は何も変わらない。でも、自分だけが少し回復する。みんな、もっと真剣に休む方法を考えた方がいい。働き方は語られる。生産性は語られる。キャリアは語られる。でも休み方は、ほとんど語られない。「休めばいい」で片付けられる。それは違う。どう働くかと同じくらい、どう休むかは設計が必要なのだ。孤独という敵在宅勤務を続けていると、ある問題に直面する。孤独だ。孤独は好きだと思っていた。一人で考える時間、一人でコードを書く時間、誰にも邪魔されない自由。それを選んで在宅勤務を続けてきた。思えば、昔からそうだった。初対面だけは愛想がいい。すぐに打ち解ける。でも、それ以上は仲良くならない。小学生の頃から「一番仲の良い友達」というものがいなかった。人のことを、どこかで信用しきれない。だから深い関係を避けてきた。孤独は、選んだというより、そうなっていた。でも気づいた。私が「孤独を好んでいる」と思っていたのは、実は「人間関係の疲れから逃げていた」だけかもしれない、と。オンライン会議で消耗する。Slackで気を遣う。だから一人でいたくなる。これは「孤独を選んでいる」のではなく、「疲弊して引きこもっている」だけだ。健全な孤独と、不健全な孤独は違う。健全な孤独は、充電された状態から自分を選ぶこと。不健全な孤独は、消耗した状態から逃避すること。安心している状態から選ぶ孤独は健全だ。身体がシャットダウンした凍結状態としての孤独は、危険信号だ。休むためには、時に人とつながる必要がある。 矛盾しているようだが、社会的なつながりが足りていない状態では、一人でいても回復しない。孤独を選んでいるのか、孤独に追い込まれているのか。この違いを見極めることが、回復の分岐点になる。有給休暇を取るということ去年、有給休暇を40日以上残したまま年度が終わった。「有給どれくらい残ってる？」「40日以上」「俺も」。この会話を何度もした。笑い話みたいに。でも笑えない。40日間、自分のための時間を放棄したということだ。プロジェクトが忙しい。休むと仕事が溜まる。チームに迷惑がかかる。そう言い聞かせてきた。でも本当の理由は違う気がする。「休む理由がない」と思っていた。体調が悪いわけでもない。旅行の予定があるわけでもない。だから働く。この発想自体がおかしかったのだ。ある日、何の予定もなく有給を取ってみた。朝起きて、コーヒーを淹れて、本を読んで、散歩して、昼寝して、夕方になった。何も生産しなかった。何も達成しなかった。でも、妙に満たされていた。気づいたのは、「理由がないから休まない」は、「理由がないと自分を大切にしない」と同じだということ。病気になるまで働いて、やっと休む権利を得る。それは順序が逆だ。リモートワークでは、この問題がさらに深刻になる。どこでも働けるから、どこにいても「働いていない自分」に罪悪感を覚える。有給を取っても、Slackが気になる。結局PCを開いてしまう。有給休暇の本質は、「働かない時間を作る」ことではない。「働かない自分を許す練習」だ。睡眠という基盤深夜2時。また技術記事を読んでいる。「これだけ読んだら寝よう」と思って開いたブラウザのタブが、気づけば15個になっている。一つ読むと、関連記事が気になる。そっちを開く。また関連記事が出てくる。無限ループだ。睡眠が大事なことくらい、知っている。知っていて、毎晩削っている。「知っている」と「できる」の間には、深い溝がある。ある時期、睡眠時間が4時間を切る日が続いた。最初は平気だった。むしろ「自分は少ない睡眠でも動ける」と思っていた。でも二週間くらいで、明らかにおかしくなった。簡単なコードでミスを連発する。同じ箇所を何度も読み返す。会議で人の話が頭に入ってこない。睡眠不足は、自分では気づけない。認知機能が落ちているから、「認知機能が落ちている」ことを認知できない。これが一番怖いところだ。酔っ払いが「俺は酔ってない」と言うのと同じ構造。睡眠不足の人間は、自分が睡眠不足だと正しく判断できない。睡眠中、脳は単に休んでいるのではない。日中に入ってきた情報を整理し、不要なものを捨て、必要なものを定着させている。この作業が追いつかないと、頭の中がゴミ屋敷になる。思考がまとまらない。創造性が消える。読んだ本の内容が腑に落ちるのは、読んだ直後ではない。数日後、ふと「あれはこういうことだったのか」と分かる瞬間がある。その熟成には、睡眠が必要だ。睡眠を削ることは、未来の自分から時間を前借りしている。 利息は高い。そして返済は、体調不良という形でやってくる。今夜削る2時間は、来週のどこかで4時間になって返ってくる。しかも最悪のタイミングで。「効率を手放す」とは、エンジニアにとってどんな覚悟か私たちエンジニアは、効率を追求することに慣れている。コードを最適化する。プロセスを改善する。無駄を省く。それが仕事だ。でも、休息に効率を求めてはいけない。「最も効率的な休息法は何か」「最短時間で最大の回復効果を得るには」「休息の ROI を最大化するには」こういう発想自体が、休息を台無しにする。余暇にまでROIを求める病一日中「効率」を考えている。その思考パターンが、仕事以外の時間にも染み出してくる。無意識のうちに「この行動の費用対効果は」と考えてしまう。時間の希少性。仕事が忙しい。自由な時間が少ない。だから、その貴重な時間を「最大限に活用したい」と思う。無駄にしたくない。効率的に楽しみたい。成果主義の内面化。成果で評価される環境に長くいると、「成果がなければ価値がない」という信念が内面化される。休息も「何かを得るため」に行うべきだと思ってしまう。不安の回避。何もしないことが怖い。生産性がない自分に価値がないと感じる。だから、休息さえも「生産的」にしようとする。非効率な時間は、どんな価値を回復させるのかしかし、非効率な時間には、効率では得られない価値がある。余白から、ふとしたひらめきが生まれる。このブログの構成も、散歩中にふと浮かんだ。何かを「考えよう」としているときではなく、何も考えていないときに、頭が勝手に整理を始める。そして不思議なことに、この整理の過程で、脳は細部を手放している。細部を忘れているからこそ、異なる記憶同士が自由につながる。全部を完璧に覚えていたら、新しい組み合わせは生まれない。ぼんやりしている時間は、無駄ではなかった。自分を取り戻す時間になる。何かを達成するためではなく、ただ存在する時間。その時間の中で、「自分は何が好きなのか」「自分は何を大切にしたいのか」という問いに向き合える。人間らしさを回復する。効率を追求するのは機械の得意分野だ。非効率を楽しめるのは、人間だけの特権だ。 AIは目標を与えられると、最短経路で達成しようとする。しかし人間は、わざと遠回りすることができる。意味のないおしゃべり、下手な楽器演奏、勝てないゲーム。この「わざと非効率を選ぶ」能力は、目標最適化しかできないAIには原理的に不可能だ。非効率の中にこそ、最適化では見つからない価値がある。関係性を深める。人間関係は効率化できない。信頼を築くには時間がかかる。無駄話をする。一緒に何もしない時間を過ごす。これらの「非効率」が、関係性を深める。だから、休息に効率を求めることをやめよう。先週、何の目的もなく街を散策した。1時間、何も生産しなかった。スマホも持たずに、ただ歩いた。帰ってきたとき、妙に頭がすっきりしていた。非効率な時間を、堂々と楽しもう。それが、AI時代を生き抜くための、逆説的な戦略だ。AIは「無駄」を理解できない。だから、無駄を楽しめる人間は、永遠に代替されない。おわりにこの文章を書き終えて、日曜日の夜が終わろうとしている。正直に言うと、書いている間もスマホを何度か見た。通知を確認した。Xを開いた。自分で書いた「デジタルデトックス」の章を読み返しながら、その直後にスマホに手を伸ばしている自分がいた。笑えない。笑えないけど、それが現実だ。私はこの文章を書いたからといって、来週から完璧に休めるようになるわけではない。たぶん来週も、ベッドでスマホを見ながら「休んだつもり」になる日がある。境界線を引けない日がある。格闘技のジムをサボる日がある。でも、少しだけ違うことがある。「休めていない」と気づけるようになった。「これは回復じゃなくて消耗だ」と言語化できるようになった。 それだけでも、前よりマシなのだと思う。たぶん。AIは無限に働ける。私は有限だ。この事実は変わらない。でも、有限であることを恨まなくなった。有限だから、選ばなければならない。選ぶから、何が大事か分かる。全部はできない。全部は追いつけない。それでいい。それに、正直なところ、こうも思っている。どうせAIはこれからもっと賢くなる。 私たちの無能さを、いずれAIが補ってくれる。足りない部分を埋めてくれる。追いつけなかった技術も、AIが代わりにやってくれるようになる。だったら、その日まで健康で元気でいることの方が大事じゃないか。 壊れた身体では、優秀なAIを使いこなすこともできない。だから、選択的に休んでほしい。休むことは、負けを認めることじゃない。降参でもない。 有限な人間として、まともに機能し続けるための、当たり前の行為だ。当たり前のことを、当たり前にやる。それがこんなに難しいとは思わなかった。明日の朝、目覚ましが鳴る。月曜日が始まる。たぶん私は、また疲れている。でも、今日よりは少しだけマシかもしれない。少しだけ、回復の仕方を知っているから。少しだけ、自分を責めずに済むから。おい、休め。これは誰かへの命令じゃない。自分への、しつこい呼びかけだ。何度も忘れて、何度も思い出す。それでいい。完璧に続けることより、何度でも思い出せることの方が大事だから。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍限りある時間の使い方作者:オリバー・バークマンかんき出版Amazonスタンフォード式　疲れない体作者:山田 知生サンマーク出版Amazon戦略的暇作者:森下彰大飛鳥新社Amazon休養学―あなたを疲れから救う作者:片野 秀樹東洋経済新報社Amazon疲労学: 毎日がんばるあなたのための作者:片野 秀樹東洋経済新報社Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonワイド新版　思考の整理学 (単行本 --)作者:外山　滋比古筑摩書房Amazon新版　「読み」の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の効用　「忘れること」で脳は何を得るのか作者:スコット・A・スモール,寺町朋子白揚社Amazon苦痛の心理学:なぜ人は自ら苦しみを求めるのか作者:ポール・ブルーム草思社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon社会は、静かにあなたを「呪う」　～思考と感情を侵食する“見えない力”の正体～ (小学館クリエイティブ)作者:鈴木祐小学館Amazon半うつ　憂鬱以上、うつ未満作者:平 光源サンマーク出版Amazon地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【宇宙】MultimodalUniverse を使って活動銀河核(AGN)の2クラス分類を作ってみる]]></title>
            <link>https://qiita.com/tozastation/items/09e118bf67e129813d00</link>
            <guid isPermaLink="false">https://qiita.com/tozastation/items/09e118bf67e129813d00</guid>
            <pubDate>Sat, 20 Dec 2025 22:06:44 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2025 の21日目の記事です。@tozastationです。普段はWebアプリを開発したり、そのアプリや学習ジョブが動く Kubernetes 基盤の面倒をみています。宇宙が好きなのとAI/MLの方たちがどうい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[IAM Roles Anywhereを使ってオンプレKubernetesでExternal Secrets Operatorを試してみる]]></title>
            <link>https://qiita.com/yutaf11/items/703c7b875157ddf799fc</link>
            <guid isPermaLink="false">https://qiita.com/yutaf11/items/703c7b875157ddf799fc</guid>
            <pubDate>Sat, 20 Dec 2025 14:24:07 GMT</pubDate>
            <content:encoded><![CDATA[はじめにオンプレミスのKubernetesとAmazon EKSによるハイブリッド構成において、シークレット管理の統合は重要な課題の一つです。セキュリティと運用の一貫性を考慮すると、AWS Secrets Managerをシークレット情報のシングルソースとして利用する構...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Rustプロジェクトの結合度を可視化する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</guid>
            <pubDate>Sat, 20 Dec 2025 10:53:29 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling を自己診断した時のweb ui です。はじめに「このモジュール、なんか触りたくないな...」ソフトウェア開発をしていると、こんな感覚を覚えることがあります。変更するたびに他の箇所が壊れる、テストが書きにくい、そもそも何をしているのか把握しづらい。これらの症状には共通点があります。モジュール同士が過剰に依存し合っている、つまり結合（カップリング）の問題です。結合の問題は厄介です。コードを書いているときには気づきにくく、後から「なぜこんなに変更が大変なのか」と悩むことになります。さらに困るのは、「結合が強すぎる」と分かっても、具体的にどこがどう強いのか、どこから手をつければいいのかが見えにくいことです。振り返ってみると、私は結合に対する解像度がかなり低かったのではないでしょうか。「なんとなく密結合っぽい」「疎結合の方がいいらしい」という感覚で良し悪しを判断していた。でも、その感覚を言葉にしようとすると、うまく説明できない。この「見えにくさ」を解消するには、結合を測る物差しが必要です。しかし、従来の「強い/弱い」という1軸だけでは不十分でした。なぜなら、同じ「強い結合」でも、場所や状況によって意味が変わるからです。そこで注目したいのが、Vlad Khononovの「Balanced Coupling」という考え方です。結合を「強度」「距離」「変動性」の3つの軸で捉え、それらのバランスを評価するフレームワークです。今回紹介するcargo-couplingは、このフレームワークをRustプロジェクト向けに実装したツールです。AIがコードを書く時代になっても、この結合度という指標は重要性を増すはずです。なぜなら、コードを書く主体が誰であれ、そのコードを理解し、保守し、拡張するのは人間だからです。むしろAIが生成したコードだからこそ、その構造を客観的に評価できる物差しが必要になります。まずはツールの概要を見てから、その背景にある考え方、そして実際の使い方へと進んでいきましょう。cargo-couplingとはcargo-couplingは、私がRustプロジェクト向けに開発した結合度分析ツールです。このツールを作るきっかけになったのは、Vlad Khononovの著作「Balancing Coupling in Software Design」との出会いでした。結合設計について漠然と感じていた課題が、この本で体系的に整理されていたのです。「強度」「距離」「変動性」という3つの軸で結合を捉えるフレームワークに感銘を受け、これをRustプロジェクトで実際に使えるツールにしたいと考えました。書籍は翻訳も含めて読みやすいので、ぜひ手に取ってみてください。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonツールはGitHubで公開しています。気に入ったらStarしていただけると励みになります。github.comcrates.ioからインストールできます。https://crates.io/crates/cargo-couplingcrates.ioここで、多くの人が持っている常識を一度疑ってみましょう。「結合は減らすべきだ」——そう思っていませんか？このツールは「結合を減らす」ことを目標にしていません。「結合を適切に設計する」ことを目標にしています。なぜなら、結合は本質的に悪ではないからです。関連する機能が密に連携するのは自然なことで、問題になるのは「不適切な場所での強い結合」や「遠く離れたモジュール間の密結合」です。この視点の転換が、このツールの核心です。# インストールcargo install cargo-coupling# 基本的な使い方cargo coupling ./src3つの次元で結合を分析では、「適切な結合」とは具体的に何を指すのでしょうか。従来の結合分析は「強い/弱い」の1軸で考えがちでした。しかし、ここで立ち止まって考えてみてください。同じ「強い結合」でも、すぐ隣のモジュールとの結合と、遠く離れた外部ライブラリとの結合では、意味が違うはずです。また、5年間ほとんど変更されていないコードとの結合と、毎週のように変更されるコードとの結合では、リスクが違うはずです。この違いを捉えるには、1軸では足りません。cargo-couplingは結合を3つの独立した次元で測定します。1. Integration Strength（結合強度）最初の軸は「結合強度」です。モジュール同士が「どれだけ互いの内部を知っているか」を表します。user.password_hashのように構造体のフィールドを直接触っているコード、見覚えがありませんか？これは最も強い結合です。一方、impl Traitを介してやり取りするコードは、相手の内部を知らなくても動作します。この違いをスコア化します。 レベル  スコア  説明  Rust例  Intrusive  1.00  内部実装に直接依存  struct.field 直接アクセス  Functional  0.75  関数シグネチャに依存  メソッド呼び出し  Model  0.50  データ構造に依存  型定義、型パラメータ  Contract  0.25  trait/インターフェースのみ  impl Trait 2. Distance（距離）2つ目の軸は「距離」です。結合されたモジュール同士が、コードのスコープ階層でどれだけ離れているかを表します。同じファイル内の関数同士が密に連携しているのは自然なことです。しかし、src/auth/login.rsがsrc/billing/invoice.rsを直接参照していたらどうでしょう？さらに、外部クレートの内部構造に依存していたら？距離が遠いほど、その結合の「重さ」は増します。 レベル  スコア  説明  SameModule  0.25  同一ファイル/モジュール内  DifferentModule  0.50  同一クレート内の別モジュール  DifferentCrate  1.00  外部クレートへの依存 3. Volatility（変動性）3つ目の軸は「変動性」です。「どれくらい頻繁に変更されるか」を表します。あなたのプロジェクトにも、1年以上触られていない安定したモジュールと、毎週のように修正が入るモジュールがあるはずです。安定したコードに依存するのと、頻繁に変わるコードに依存するのでは、リスクが違います。cargo-couplingはGit履歴からこの変動性を自動で計算します。 レベル  スコア  Git 6ヶ月での変更回数  Low  0.00  0-2回  Medium  0.50  3-10回  High  1.00  11回以上 バランススコアの計算ここまで3つの次元を見てきました。しかし、「強度が0.75」「距離が0.50」「変動性が中程度」とバラバラに言われても、結局この結合は良いのか悪いのか、判断しづらいですよね。そこでcargo-couplingは、これら3つの次元を組み合わせてバランススコアを計算します。3つの数値を1つのスコアにまとめることで、「この結合は適切か」を直感的に判断できるようになります。考え方はシンプルです。「強度と距離のバランス」と「変動性によるリスク」の2つを掛け合わせます。ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACT最初の式は「強度と距離が釣り合っているか」を測ります。距離が近ければ強結合でも問題なく、距離が遠ければ弱結合であるべきです。2番目の式は「変更頻度と結合強度の組み合わせリスク」を測ります。頻繁に変更されるコードと強く結合していると、変更のたびに影響を受けるリスクが高まります。この計算式が導く結論を整理すると、以下のようになります。強結合 + 近距離 → Good：関連機能が1つのモジュールにまとまった高凝集な状態弱結合 + 遠距離 → Good：モジュール間の依存が最小限な疎結合アーキテクチャ強結合 + 遠距離 → Bad：変更影響が広範囲に及ぶグローバル複雑性の状態強結合 + 高変動性 → Bad：頻繁な変更が連鎖的影響を生む変更波及リスク実際に使ってみる理論を理解したところで、実際のプロジェクトでどう使うかを見ていきましょう。cargo-couplingは目的に応じて複数の出力形式を用意しています。サマリー表示cargo coupling --summary ./src出力例は以下のとおりです。Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9日本語出力日本語での出力も対応しています。cargo coupling --japanese ./srcカップリング分析: my-project━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━評価: B (Good) | スコア: 0.67/1.00 | モジュール数: 143次元分析:  結合強度: Contract 1% / Model 24% / Functional 66% / Intrusive 8%           (トレイト)   (型)      (関数)        (内部アクセス)  距離:     同一モジュール 6% / 別モジュール 2% / 外部 91%  変更頻度: 低 2% / 中 98% / 高 0%ホットスポット分析リファクタリングすべき優先度の高いモジュールを特定します。cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rs影響分析特定のモジュールを変更したときの影響範囲を調べられます。cargo coupling --impact metrics ./srcWeb UIでの可視化インタラクティブなグラフで結合関係を可視化できます。cargo coupling --web ./srcブラウザが自動で開き、Cytoscape.jsを使った対話的なグラフが表示されます。ノードをクリックすると詳細情報が見られ、問題のあるモジュールは色分けされます。CI/CDでの活用手動で分析するだけでなく、継続的に品質を監視することもできます。cargo-couplingを品質ゲートとして組み込むと、結合設計の劣化を早期に検出できます。cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actionsの例は以下のとおりです。- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcグレードが基準を下回るとexit code 1を返すため、CIパイプラインに組み込めます。AI連携Claude CodeやGitHub Copilotと組み合わせて使う場合、--aiオプションが便利です。cargo coupling --ai ./srcAIフレンドリーな形式で出力されるので、そのままAIに貼り付けてリファクタリング提案を得られます。検出される問題パターンここまで使い方を見てきましたが、具体的にどんな問題が検出されるのか気になるところでしょう。cargo-couplingが警告する代表的なパターンを紹介します。God Module（神モジュール）関数、型、implが多すぎるモジュールです。関数: 30個以上型: 15個以上impl: 20個以上High Efferent Coupling（外向き結合過多）依存先が多すぎるモジュール。デフォルトでは20以上の依存で警告されます。High Afferent Coupling（内向き結合過多）依存されすぎているモジュール。デフォルトでは30以上の依存元で警告されます。Cascading Change Risk（変更波及リスク）侵入的結合（Intrusive）と高変動性（High Volatility）の組み合わせ。変更のたびに広範囲に影響が及ぶ危険な状態です。ヘルスグレードの解釈問題パターンの検出結果は、最終的に1つのグレードに集約されます。このグレードがプロジェクト全体の健全性を示します。 Grade  説明  S  Over-optimized。リファクタリングしすぎかも  A  Well-balanced。理想的な状態  B  Healthy。管理可能な状態  C  改善の余地あり  D  注意が必要  F  即刻対応が必要 興味深いのは、Sグレードが「やりすぎ」とされている点です。なぜでしょうか？結合を減らしすぎると、コードが細切れになりすぎて、かえって全体像が見えなくなります。1つの処理を追うために10個のファイルを開く必要があったり、抽象化のレイヤーが深すぎて「結局何をしているの？」と迷子になったり。そういう経験はありませんか？結合は「減らせばいい」という単純な話ではありません。バランスが大切なのです。ライブラリとしての利用CLIツールとして使うだけでなく、独自のツールに組み込むこともできます。cargo-couplingはライブラリとしても公開しているので、プログラムから直接分析機能を呼び出せます。use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST解析    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git変動性分析    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // バランス分析    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}パフォーマンスcargo-couplingは、大規模プロジェクトでも高速に動作するよう設計されています。Rayonによる並列AST解析Git履歴のストリーム処理実績: tokio（488ファイル）で655ms--no-gitオプションを使えば、Git分析をスキップしてより高速に動作します。制限事項便利なツールですが、万能ではありません。使う前に知っておくべき制限があります。外部クレート依存は分析対象外: serde、tokioなどへの依存は分析されない。開発者がコントロールできない部分のため静的解析のみ: ランタイムの動作やマクロ展開は完全には捉えられないGit履歴が必要: Volatility分析にはGit履歴が必要。履歴が短いと精度が下がるまとめcargo-couplingは、「結合は悪」という単純な考え方ではなく、「適切な結合を選ぶ」という実用的なアプローチを提供します。3次元分析: 強度・距離・変動性を同時に考慮Git連携: 実際の変更頻度をデータとして反映実行可能な提案: 具体的なリファクタリングアクションを提示複数の出力形式: テキスト/JSON/Web UI/AIフレンドリーCI/CD統合: 品質ゲートとして自動チェック完璧な設計を目指す必要はありません。「80%の改善で十分」というプラグマティックな姿勢で、少しずつプロジェクトの健全性を高めていきましょう。# まずは試してみてくださいcargo install cargo-couplingcargo coupling --summary ./src結合の問題が可視化されるだけでも、設計改善の第一歩になります。次にあなたが「このモジュール、なんか触りたくないな...」と感じたとき、それはもう漠然とした不安ではありません。強度・距離・変動性という3つの軸で分析でき、具体的な改善アクションに落とし込める、対処可能な課題です。その感覚は、恐れではなく、改善の入り口なのです。似た概念にA Philosophy of Software DesignのComplexity がある。これも良い考え方なので一読をおすすめします。 speakerdeck.comA Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Unmasking the Weak Points: Probing LLM Frontiers with garak]]></title>
            <link>https://daisuke1024akagawa.medium.com/unmasking-the-weak-points-probing-llm-frontiers-with-garak-50f4db714a62?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/unmasking-the-weak-points-probing-llm-frontiers-with-garak-50f4db714a62?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Sat, 20 Dec 2025 05:24:29 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[書いた方が良いの? BigQueryテーブルのカラム説明文の有無による生成AI機能の差異検証]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/a7124ea372eb91</link>
            <guid isPermaLink="false">https://zenn.dev/nedoko_dok0dko/articles/a7124ea372eb91</guid>
            <pubDate>Fri, 19 Dec 2025 15:00:02 GMT</pubDate>
            <content:encoded><![CDATA[※3-shake Advent Calendar 2025の20日目のエントリー記事です。※12/22追記: BigQuery Advent Calendar 2025の21日目のエントリー記事として追加しました。BigQueryアドベントカレンダーの盛り上がりの一助となれば幸いです。皆さんこんにちは。2025年ももう終わりですね。今年は様々な所で生成AIの機能やサービスが登場しました。私はお仕事関連でGoogle Cloudを触ることが多かったのですが、AI関連の機能は追加や更新の早さが凄まじく「早すぎて…見えない!」となっていました。さて、今回はGoogle Cloud...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Master the AI Wave: 10 Tech Blogs That Keep You Ahead of the Curve]]></title>
            <link>https://daisuke1024akagawa.medium.com/master-the-ai-wave-10-tech-blogs-that-keep-you-ahead-of-the-curve-5cd0225ccc45?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/master-the-ai-wave-10-tech-blogs-that-keep-you-ahead-of-the-curve-5cd0225ccc45?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Fri, 19 Dec 2025 13:01:07 GMT</pubDate>
            <content:encoded><![CDATA[Today, I’ll let you know 10 amazing tech blogs you should read.Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI時代のMarp によるスライド環境の構築]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/19/183148</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/19/183148</guid>
            <pubDate>Fri, 19 Dec 2025 09:31:48 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2025 19日目のエントリ記事です。はじめにエンジニアがプレゼン資料を作るとき、PowerPointやKeynoteにもどかしさを感じることがあります。コードを書くようにスライドを作りたい。Gitでバージョン管理したい。テーマを一括で変更したい。Marpはこれらの願望を叶えるマークダウンベースのスライド生成ツールです。marp.appしかし生成AI時代の今、新しい課題が生まれています。AIにスライドの下書きを依頼できるようになった反面、「AIっぽいプレゼン」が量産されるようになりました。整然としすぎて、話者の思考が見えない資料です。この記事では、AIの力を借りつつ「自分のプレゼン」を取り戻す仕組みを紹介します。AIっぽいプレゼンの正体生成AIにプレゼン資料を依頼すると、だいたい同じ構成になります。「まず、次に、最後に」という接続詞。きれいに3項目並んだ箇条書き。当たり障りのない結論。これは決して間違っていません。しかし聴衆の記憶には残りません。なぜでしょうか。聴衆の脳は「予測を裏切られた瞬間」に活性化します。「まず、次に、最後に」という予定調和な構成では、脳は省エネモードで聞き流します。3項目の箇条書きを見た瞬間、聴衆は「ああ、3つあるのね」と思考を止めます。AIが生成するプレゼンは、統計的に最も頻出するパターンの再現です。だから誰が作っても似たような資料になります。Marpを選んだ理由はシンプルです。マークダウンはプレーンテキストなので、AIが直接編集でき、人間がTextlintやカスタムルールで機械的にチェックできます。PowerPointのようなバイナリ形式では「AI生成→ルール検証」の流れが困難です。Gitで差分管理でき、CSSでデザインを一括制御できる点も大きいです。プロジェクト構造実際に運用しているMarpプロジェクトの構造を紹介します。github.com3shake-marp-templates/├── templates/              # 再利用可能なテンプレート├── themes/                 # CSSテーマ├── slides/2025/           # 実際のプレゼンテーション├── assets/images/         # 画像資産└── .claude/               # Claude Code統合    ├── commands/          # スラッシュコマンド    ├── agents/            # 専門家エージェント    └── rules/             # 執筆ルールポイントは.claude/ディレクトリです。Claude Codeと統合することで、スライドのレビューを自動化しています。CommandsやSub-agentsの詳細については、以前の記事で解説しています。syu-m-5151.hatenablog.comMarpの基本設定.marprc.ymlでMarpを設定します。allowLocalFiles: truehtml: truemermaid: truebespoke:  progress: trueoptions:  engine: '@marp-team/marp-core'mermaid: trueでMermaid記法の図表が使えます。しかし正直なところ、PDFエクスポート時に崩れることがあります。重要な図は画像として用意するほうが安全です。package.jsonのスクリプトは以下の通りです。{  "scripts": {    "start": "marp -s . --html --allow-local-files",    "build": "marp --html --allow-local-files"  }}npm startでローカルサーバーが起動し、ファイル保存のたびに自動リロードされます。テーマによるブランディングCSSテーマで全スライドに統一感を持たせます。/* 3shake-theme.css */:root {  --3shake-blue: #4AADDD;  --3shake-blue-dark: #0a1929;  --3shake-yellow: #ECBE30;}section {  background: white;  font-family: 'Noto Sans JP', sans-serif;}/* 全スライドにロゴを自動配置 */section::after {  content: '';  background-image: url('../assets/images/logo.png');  position: absolute;  left: 30px;  bottom: 20px;}ロゴとページ番号が自動配置されます。プレゼン作成者はブランディングを意識する必要がなくなります。AIっぽさを排除するルールここからが本題かもです。.claude/rules/slide-writing.mdに以下の禁止事項を定義しています。箇条書きを3項目で揃えない（2つか4つにする）「まず、次に、最後に」という機械的な接続詞を使わない完全に等分な説明をしない（メリハリをつける）抽象的で当たり障りのない表現を避けるなぜ2つか4つなのか。 聴衆の「3つだろう」という予測を外すためです。2つなら対比が明確になり、4つなら網羅感が出ます。3つは「ちょうどいい」ゆえに印象へ残りません。意図的にパターンを崩すことで、聴衆の能動的な思考を促します。「PowerPointでも同じルールを適用できる」という反論があるでしょう。確かにその通りです。しかしPowerPointでは、このルールを機械的にチェックする手段がありません。Marpならテキストベースなので、「3項目の箇条書きを検出したら警告」というルールを自動実行できます。人間の意志力に頼らず、仕組みで品質を担保します。身体性の供給以前の記事で「AIに記事を書かせるとは何か」について書きました。プレゼンにも同じことが言えます。AIは構造化が得意です。しかし「身体性」は供給できません。ここで言う身体性とは、知識が「情報」から「経験」へと変容する過程で生じる一人称的な認知の軌跡です。たとえば「このツールを導入したら開発効率が上がった」という情報と、「導入時に設定で3時間ハマってドキュメントの不備に気づきPRを送った」という経験は別物です。プレゼンにおける身体性とは、「なぜこのトピックを選んだのか」「どこで躓いたのか」「何に感動したのか」という、話者固有の軌跡です。これはAIには生成できません。私の作業フローはこうです。伝えたいメッセージを箇条書きで書き出す（5-7個）各メッセージに「自分だけが語れる具体例」を追加AIにレビューを依頼し、構成を整える/review-slideで「3項目の箇条書き」「まず・次に」の指摘を確認指摘箇所を修正AIは足す。人間は削る。 AIは情報の網羅性を最適化しますが、プレゼンの核心は何を省くかにあります。「このトピックは聴衆の関心外」と判断するには、聴衆の反応を想像する力が必要です。この能力は現在のLLMには実装されていません。だからアウトラインは自分で考え、AIにはレビューを任せます。おわりにMarpとルールベースのチェック、そしてClaude Codeのエージェント。この組み合わせで実現したのは、「AIの力を借りながら、自分の思考を残す」環境です。完璧に整った資料より、少し不格好でも話者の考えが透けて見える資料のほうが、聴衆の記憶に残ります。AIが生成した「もっともらしい」スライドではなく、自分の経験に根ざした「本物の」スライドを作る。そのための環境がMarp×Claude Codeです。まずは既存のスライドを1枚だけMarkdown化してみてください。それがMarp×AI環境構築の第一歩です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude Codeの Agent Skills は設定したほうがいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/19/173309</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/19/173309</guid>
            <pubDate>Fri, 19 Dec 2025 08:33:09 GMT</pubDate>
            <content:encoded><![CDATA[Claude Codeを使い始めて、様々な発信をしてきました。今回は「Agent Skills」について。これも設定しておくと、Claude Codeがグッと使いやすくなる機能です。Claude Code の settings.json は設定した方がいい - じゃあ、おうちで学べるClaude Code の CLAUDE.mdは設定した方がいい - じゃあ、おうちで学べるClaude Code の .claude/commands/**.md は設定した方がいい - じゃあ、おうちで学べるClaude CodeのHooksは設定したほうがいい - じゃあ、おうちで学べるClaude CodeのSubagentsは設定したほうがいい - じゃあ、おうちで学べるはじめに「このプロジェクトではpython-pptxを使ってスライドを作って」「SQLは必ずこのフォーマットで書いて」「コードレビューはこの観点でチェックして」。Claude Codeを使っていると、こういう説明を何度も繰り返すことになります。CLAUDE.mdに書けば解決すると感じるでしょう。しかしCLAUDE.mdに書いても、毎回読み込まれるとは限らない。commandsを作っても、手動で呼び出す必要がある。どちらも「繰り返し」を完全には解決してくれません。私自身、Rustプロジェクトの開発をClaude Codeに任せようとして、この問題に何度もぶつかりました。「ビルドはcargo fmtから始めて」「セキュリティチェックはOWASPの観点で」「テストは統合テストまで回して」。1回のセッションでは覚えてくれる。しかし新しいセッションを始めると、また最初から説明し直し。なぜこうなるのか。この問題の根本にあるのは、LLMのアーキテクチャ上の制約です。LLMはステートレスで、セッション間で記憶を保持しません。トークン制約とコスト制約があるため、すべての知識を常に保持できません。だから、毎回同じ説明が必要になります。Agent Skillsは、この制約を回避する仕組みです。すべての知識を常に持たせるのではなく、必要な時に必要な知識だけを読み込む。この発想の転換により、ステートレスなLLMでも「状態を持っているかのように」振る舞えます。一度Skillを作っておけば、関連するタスクで自動的にその知識が使われます。www.anthropic.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。他の設定との違い今まで紹介してきた機能との違いを整理しておきます。 機能  役割  例  CLAUDE.md  プロジェクトの文脈を伝える  「うちはTypeScriptで、こういうアーキテクチャ」  commands  手動で呼び出すショートカット  /test-and-commit で一連の作業を実行  Hooks  特定のイベントで自動実行  ファイル保存後に自動フォーマット  Subagents  専門家を自動で呼び出す  デバッグ時にdebugger subagentが起動  Rules  パス単位でルールを適用  src/api/**/*.tsにセキュリティルール  Agent Skills  専門知識をオンボーディング  PDF操作、Excel分析、独自ワークフロー Rulesについて補足: .claude/rules/ディレクトリに配置することで、特定の拡張子やディレクトリに対して細かいルールを適用できます。CLAUDE.mdがグローバルな設定なのに対し、Rulesは「このパスにはこのルール」という精密なスコープ設定が可能です。無駄なコンテキスト消費を抑えつつ、必要なルールだけを読み込ませる「段階的開示」の考え方に基づいています。Rulesについては別記事で詳しく書く予定です。表を見ると、各機能には明確な役割分担があります。CLAUDE.mdは文脈、commandsはショートカット、Hooksは自動化、Subagentsは専門家の呼び出し。では、Skillsは何が違うのか。ポイントは、Skillsが「Claudeができること自体を拡張する」点です。他の設定がClaudeの「使い方」を定義するのに対し、SkillsはClaudeの「専門知識」を拡張します。LLMの推論能力自体は変わりませんが、専門家の知識を注入することで出力品質が向上します。Agent Skillsとは何かAnthropicの公式ブログでは、Agent Skillsをこう説明しています。Building a skill for an agent is like putting together an onboarding guide for a new hire.（エージェントにSkillを作ることは、新入社員向けのオンボーディングガイドを作るようなものです）Skillは、指示・スクリプト・リソースをまとめたフォルダです。Claudeがタスクに応じて自動的に読み込み、その専門知識を活用します。platform.claude.comSkill に関しても公式ドキュメントが本当に良いのでオススメです。Anthropicはとりあえず、公式ドキュメントこれは標語にしてほしいです。platform.claude.comそれでも自分的にまとめたいので書かせていただきます。なぜSkillsが必要なのかClaude Codeは万能ですが、「特定のタスク」に最適化されていないことがあります。例えばPowerPointを作ろうとすると、どのライブラリを使うか迷います。フォーマットの細かい仕様を知らない。エッジケースでバグる。毎回試行錯誤が発生します。一方、Skillsがあれば違います。AnthropicのエンジニアがPowerPoint作成の最適解を徹底的に検証して、その知識をパッケージ化している。Claudeはそれを読み込んで、最初からプロとしての出力ができます。この辺は松本勇気さんの生成AI「戦力化」の教科書なんかもとても良いし今度、オライリーから翻訳本AIエンジニアリング―基盤モデルを用いたAIアプリケーション開発の基礎と実践もとても良い。Tool、Skills、MCPの違い混乱しやすいポイントを整理しておきます。Anthropicのブログ記事では、わかりやすいたとえが使われています。claude.comMCP is like having access to the aisles. Skills, meanwhile, are like an employee's expertise.（MCPは店の通路へのアクセス。Skillsは店員の専門知識。）壊れたキャビネットを直したいとき、ハードウェアストアに行けば木工用接着剤もクランプも蝶番も揃っています。しかし、何を買えばいいか、どう使えばいいかは別問題です。 概念  役割  たとえ  Tool  何ができるか（Capability）  店にある道具そのもの  MCP  道具へのアクセス（Connectivity）  店の通路に入ること  Skills  どう振る舞うか（Behavior）  道具の使い方を教える店員 Toolは「APIを叩く」「DBに接続する」「ファイルを操作する」といった個別の能力です。MCPはそれらのToolを統一規格で接続するアダプター。外部システムへの安全で標準化されたアクセスを提供します。そしてSkillsは「どう振る舞うか（Behavior）」まで定義します。複数のToolをどの順番で、どういう判断基準で使うか。Toolの使い方マニュアル付きで渡すのがSkillsです。MCPが接続性を提供し、Skillsがその接続性を効果的に使うための手続き的知識を提供する。両者は競合するものではなく、組み合わせることで真価を発揮します。この構造は、BDD（Behavior-Driven Development、振る舞い駆動開発）に似ています。BDDは単なるテスト手法ではなく、チーム全体の「対話」を促進し、ビジネス価値の高いソフトウェアを効率的に生み出すための開発アプローチです。TDD（テスト駆動開発）が「コードが正しく実装されているか」という開発者視点なのに対し、BDDは「システムが期待通りに振る舞うか」というユーザー・ビジネス視点で考えます。BDDでは、Gherkin記法を使って「Given-When-Then」形式でシナリオを書きます。Feature: ログイン機能  Scenario: ユーザーが正しいIDとパスワードでログインできる    Given ログインページが表示されている    When  正しいIDとパスワードを入力してログインボタンを押す    Then  ホームページにリダイレクトされるこのシナリオは、開発者だけでなく、QAエンジニア、プロダクトオーナー、ビジネス担当者など、全員が読めます。これが「生きた仕様書」として機能し、認識の齟齬を埋めます。Skillsも同じ構造を持っています。 BDD  Skills  Given（前提条件）  description（いつ起動するか）  When（アクション）  SKILL.md本文（何をするか）  Then（期待結果）  具体的な手順（どう振る舞うか） BDDがテストで「コードの振る舞い」を保証するように、SkillsはAIエージェントの「振る舞い」を保証します。BDDの本質的な価値は「ビジネス側とエンジニアの共通言語」でした。「3つのアミーゴ」（PO、開発者、QA）が対話し、全員が納得する仕様を作り上げます。Skillsも同じです。現場のドメインエキスパートがMarkdownで書いた手順は、そのままAIの振る舞いになります。つまり、Skillsは「AIエージェントのためのBDD」だと言えます。プログラミングなしで、自然言語で、AIの振る舞いを定義できます。Progressive Disclosure（段階的開示）Skillsの設計で最も重要な概念が「Progressive Disclosure（段階的開示）」です。これは「すべての情報を最初から渡すのではなく、必要になったタイミングで必要な情報だけを渡す」という設計原則です。なぜこの原則がSkillsに必要なのか。LLMには「コンテキストウィンドウ」という物理的な制約があります。Claude 3.5 Sonnetで約200Kトークン。これは多いようで、実際のタスクでは意外と消費が早い。コードファイルを10個読み込めば数万トークン、会話履歴が長くなればより消費される。ここに50個のSkillsの全内容（各5000トークン）を読み込んだら、250Kトークン。コンテキストが溢れます。だからSkillsは3段階で情報を開示します。これは「必要な時に必要な分だけ」というJust-In-Time戦略です。Level 1: メタデータ（常にロード） - 約100トークン/Skill---name: pdf-processingdescription: Extract text and tables from PDF files, fill forms, merge documents.---起動時に全Skillのname/descriptionだけ読み込みます。50個のSkillがあっても5000トークン程度。これでClaudeは「どんなSkillが使えるか」の全体像を把握できます。Level 2: 指示（トリガー時にロード） - 5000トークン以下が目安SKILL.mdの本文。「PDFを操作して」と言われたら、descriptionから「pdf-processingが関連する」と判断し、そのSKILL.mdを読み込みます。関係ないSkillは読み込まない。Level 3: リソース（必要時にロード） - 必要に応じて追加のファイル、スクリプト、リファレンス。SKILL.md内で「フォーム入力が必要ならFORMS.mdを参照」と書いておけば、そのタスクが発生したときだけ読み込みます。pdf-skill/├── SKILL.md              # Level 2: メイン指示├── FORMS.md              # Level 3: フォーム入力ガイド├── reference.md          # Level 3: APIリファレンス└── scripts/    └── fill_form.py      # Level 3: ユーティリティスクリプトこの設計の本質は「推論空間の段階的絞り込み」です。 Level 1で「使えるSkillの候補」を提示し、Level 2で「このタスクにはこの手順」を特定し、Level 3で「この具体的な操作にはこのリソース」を提供する。LLMの自由な推論を、段階的に制約していく。これがSkillsの賢さです。SkillsとSubagentsの使い分け「Skillsって、前に書いたSubagentsと同じじゃないですか」という声が聞こえてきます。確かに両方とも「専門知識をパッケージ化する」という点では似ています。しかし、コンテキストの扱い方に決定的な違いがあります。 観点  Skills  Subagents  コンテキスト  親と共有  独立  向いているタスク  継続的な作業、TDDなど  試行錯誤、調査タスク  状態の引き継ぎ  あり  なし（結果のみ返す） なぜこの違いが生まれるのか。 技術的には、Skillsは「現在のセッションにドキュメントを追加読み込みする」だけです。会話の流れ、ファイルの状態、変数の値、すべてが共有されたままです。一方、Subagentsは「新しいClaude Codeプロセスを起動する」に近い。独立したコンテキストウィンドウを持ち、親とは結果だけをやり取りします。Subagentsはコンテキストが独立しています。Claude Codeの中でClaude Codeを呼ぶようなもの。試行錯誤を伴うエラー調査みたいな「ごちゃごちゃした作業」をSubagentに任せると、親側のコンテキストが汚れません。なぜ「汚れない」ことが重要なのか。 コンテキストウィンドウは有限です。試行錯誤を10回繰り返すと、その10回分の履歴がコンテキストに残ります。成功した最終結果だけが欲しいのに、失敗した9回分も抱え込むことになる。Subagentなら、その試行錯誤は子プロセスの中で完結し、親には「結果：○○が原因でした」という要約だけが返ってきます。Skillsはコンテキストを共有します。テスト駆動開発をさせるとき、RED-GREEN-REFACTORのサイクルごとにコンテキストが分断されると困ります。「さっきテスト書いたよね」「なんでこの設計にしたんだっけ」という文脈を保持したまま作業を続けたい。そういうときはSkillsが向いています。なぜ「共有する」ことが重要なのか。 TDDは本質的に「対話」です。テストを書く→実装する→リファクタリングする、この流れの中で「なぜこのテストを書いたか」「なぜこの設計にしたか」という文脈が失われると、リファクタリングの方向性が定まりません。Skillsなら、この対話の文脈が保持されたまま、TDDの手順だけが注入されます。使い分けの判断基準はシンプルです。コンテキストを共有したい → Skillsコンテキストを独立させたい → Subagents迷ったときの指針: タスクの結果が「要約」で十分ならSubagent、結果だけでなく「過程」も重要ならSkillsです。エラー調査は「原因が分かればいい」のでSubagent。コードレビューは「なぜこの指摘をしたか」の文脈が後続の修正に影響するのでSkills。より詳しい使い分けについては、atusyさんの記事「Claude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する」が参考になります。利用可能なビルトインSkillsSkillsの概念は分かった。では、実際にどう使うのか。まずはAnthropicが提供しているビルトインSkillsから見てみましょう。 Skill  機能  PowerPoint (pptx)  プレゼンテーションの作成・編集・分析  Excel (xlsx)  スプレッドシートの作成・データ分析・チャート生成  Word (docx)  ドキュメントの作成・編集・トラック変更  PDF (pdf)  PDF生成・フォーム入力・マージ これはclaude.ai、Claude Code、Claude APIで利用可能です。基本的な使い方Claude Codeでの使い方Claude Codeでは、Skillsはファイルシステムベースで管理されます。配置場所： タイプ  パス  スコープ  個人  ~/.claude/skills/  全プロジェクト共通  プロジェクト  .claude/skills/  現在のプロジェクトのみ Skillを配置するだけで、Claude Codeが自動的に認識し、関連するタスクで使用します。APIでの使い方import anthropicclient = anthropic.Anthropic()response = client.beta.messages.create(    model="claude-sonnet-4-5-20250929",    max_tokens=4096,    betas=["code-execution-2025-08-25", "skills-2025-10-02"],    container={        "skills": [            {                "type": "anthropic",                "skill_id": "pptx",                "version": "latest"            }        ]    },    messages=[{        "role": "user",        "content": "再生可能エネルギーについて5枚のプレゼンを作成して"    }],    tools=[{        "type": "code_execution_20250825",        "name": "code_execution"    }])ポイントは以下の通りです。container.skillsでSkillを指定type: "anthropic"は公式Skilltoolsでcode_executionを有効化（Skillsの実行に必須）Beta headersが必要claude.aiでの使い方claude.aiでは、ビルトインSkillsはデフォルトで有効です。「PowerPointを作って」と言えば、自動的にPowerPoint Skillが起動します。カスタムSkillsは Settings > Features からZIPファイルでアップロードできます。カスタムSkillの作成ここからが本番です。自分専用のSkillを作る方法を説明します。基本構造Skillの最小構成はSKILL.mdファイル1つだけです。---name: my-custom-skilldescription: このSkillが何をするか、いつ使うべきかを説明。---# My Custom Skill## 指示[具体的な手順をここに書く]## 例[実際の使用例]必須フィールド：name: 小文字とハイフンのみ、64文字以内description: 何をするのか、いつ使うのかを説明。1024文字以内実用的なSkill例私が実際のプロジェクトで使っているSkillsを紹介します。例1: セキュリティレビュー.claude/skills/reviewing-security/SKILL.md:---name: reviewing-securitydescription: "OWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティス。脆弱性検出。Use when: セキュリティ、脆弱性、OWASP、認証、認可、監査を依頼された時。"---# セキュリティレビューOWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティスに基づくレビュースキル。## OWASP チェック項目| ID | リスク | チェック内容 ||----|-------|-------------|| API1 | BOLA | tenant_id 検証、file_id との組み合わせ検証 || API2 | Broken Auth | gRPC メタデータ認証 || API3 | Property | レスポンスの不要情報 || API4 | Resource | ファイルサイズ制限、ページネーション |## Rust セキュリティ| 項目 | 検索パターン ||-----|-------------|| 依存関係脆弱性 | `cargo audit` || unsafe コード | `grep -rn "unsafe {" src/` || ハードコード認証情報 | `grep -rn "(password\|secret\|api_key)" src/` |descriptionに「Use when:」を明記しているのがポイントです。これでClaudeが「セキュリティレビューして」と言われたときに確実に起動します。例2: ビルドとテスト.claude/skills/building-and-testing/SKILL.md:---name: building-and-testingdescription: "Rustプロジェクトのビルドとテスト実行。フォーマットチェック、lint、ユニットテスト、ビルド確認を一括実行。Use when: ビルド、テスト、cargo test、チェック、確認を依頼された時。"---# ビルドとテスト## 実行手順1. フォーマットチェック: `cargo fmt --check`2. Lint実行: `cargo clippy -- -D warnings`3. ユニットテスト: `cargo test --workspace`4. ビルド確認: `cargo build --workspace`## 一括実行cargo fmt --check && cargo clippy -- -D warnings && cargo test --workspace && cargo build --workspaceシンプルですが、これだけで「テストして」と言えば毎回同じ手順を実行してくれます。例3: リファレンス参照型（QAチェック）Progressive Disclosureを活用して、参照ファイルを分割する例です。職種ごとにリファレンスを分けることで、必要な情報だけを読み込みます。.claude/skills/qa-check/├── SKILL.md└── reference/    ├── backend.md      # Rustバックエンドのチェック項目    ├── frontend.md     # フロントエンドのチェック項目    └── infra.md        # インフラのチェック項目.claude/skills/qa-check/SKILL.md:---name: qa-checkdescription: "コードレビュー・QAチェック。職種別のベストプラクティスを適用。Use when: レビュー、QA、品質チェック、コードチェックを依頼された時。"---# QAチェック職種別のリファレンスを参照してレビューを実施します。## リファレンス**Rust バックエンド** → See [reference/backend.md](reference/backend.md)**フロントエンド** → See [reference/frontend.md](reference/frontend.md)**インフラ** → See [reference/infra.md](reference/infra.md)## 実行手順1. 変更ファイルの拡張子・パスから対象領域を判定2. 該当するリファレンスを読み込む3. チェック項目に従ってレビュー実施4. 結果をCRITICAL/WARNING/INFOで分類して報告reference/backend.md（一部抜粋）:# Rust バックエンド QAチェック項目## エラーハンドリング- [ ] unwrap() を本番コードで使用していないか- [ ] Result型を適切に伝播しているか- [ ] カスタムエラー型を定義しているか## セキュリティ- [ ] SQLインジェクション対策（sqlxのバインドパラメータ使用）- [ ] 認証・認可のチェック漏れがないか- [ ] 機密情報のログ出力がないか## パフォーマンス- [ ] N+1クエリが発生していないか- [ ] 不要なclone()がないか- [ ] async/awaitの適切な使用「バックエンドのコードをレビューして」と言えばbackend.mdだけを読み込み、「インフラの設定をチェックして」と言えばinfra.mdだけを読み込みます。slash commandsとskillsの連携Skillsは自動で起動しますが、明示的に呼び出したいときもあります。そういうときはslash commandsと組み合わせると便利です。.claude/skills/git-commit/SKILL.md:---name: git-commitdescription: Stage meaningful diffs and create Conventional Commits with WHY-focused messages. Use when agent needs to commit code changes.---Execute `/git:commit` slash command.claude/commands/git/commit.md:# Git Commit変更をすべてコミットせずに、意味のある範囲でできるだけ小さくコミットする。commit logにはwhyを残す。...こうすると、Claudeが「コミットすべきだな」と判断したら自動でSkillが起動し、ユーザーが明示的に/git:commitを呼んでも同じ挙動になります。自動と手動の両方に対応できる設計です。Skillsのベストプラクティスなぜベストプラクティスが重要なのか。 Skillsは「書けば動く」ものではありません。書き方によって、起動率、出力の安定性、トークン効率が大きく変わります。ベストプラクティスは、多くの試行錯誤から導き出されたパターンです。これを知らずに始めると、同じ失敗を繰り返すことになります。1. 簡潔に書くコンテキストウィンドウは有限です。Claudeが既に知っていることを書く必要はありません。簡潔さが重要な理由は2つあります。 トークンが増えると問題が起きます。1つはコスト。APIの場合、入力トークンに課金されるので、冗長なSkillはそのまま支出増になります。もう1つは「ノイズ」。LLMは与えられた情報を全て考慮しようとします。本質的でない説明が多いと、重要な指示が埋もれて、出力品質が下がります。悪い例（冗長）：PDF (Portable Document Format) files are a common file format that containstext, images, and other content. To extract text from a PDF, you'll need touse a library. There are many libraries available for PDF processing...良い例（簡潔）：## Extract PDF textUse pdfplumber:---import pdfplumberwith pdfplumber.open("file.pdf") as pdf:    text = pdf.pages[0].extract_text()---2. 自由度を適切に設定タスクの性質によって指示の具体性を変えます。自由度の設計が重要な理由は単純です。 LLMは指示が曖昧だと「創造的に解釈」します。コードレビューなら創造性は歓迎ですが、DBマイグレーションで創造性を発揮されると困ります。タスクの「リスク」と「多様性の価値」を天秤にかけて、自由度を決めます。高自由度（テキスト指示）: 複数のアプローチが有効な場合## Code Review1. Analyze structure2. Check for bugs3. Suggest improvements低自由度（具体的スクリプト）: 操作がデリケートな場合。## Database MigrationRun exactly this script:---python scripts/migrate.py --verify --backup---Do not modify the command.3. フィードバックループを入れる複雑なワークフローでは検証ステップを入れます。フィードバックループが必要な理由があります。 LLMは「確信を持って間違える」ことがあります。10ステップのワークフローを一気に実行させると、ステップ3でミスしても気づかずステップ10まで進みます。検証ステップを挟むことで、早期に問題を検出し、修正コストを下げられます。## Document Editing Workflow1. Make edits to XML2. **Validate immediately**: `python validate.py`3. If validation fails:   - Review error message   - Fix issues   - Validate again4. **Only proceed when validation passes**5. Pack the document4. ネストを深くしない参照ファイルはSKILL.mdから1階層までに留めます。深すぎると部分的にしか読まれません。ネストが問題になる理由があります。 LLMは「参照先をどこまで読むか」を自分で判断します。A→B→C→Dとネストしていると、Bまで読んでCは読まない、という判断をすることがあります。重要な情報がDにあると、それが無視される。情報はフラットに配置して、確実に読まれるようにします。悪い例：SKILL.md → advanced.md → details.md → actual_info.md良い例：SKILL.md├── advanced.md├── reference.md└── examples.md100+の実戦投入可能なSkillsコミュニティが既に多くのSkillsを公開しています。github.com人気カテゴリ：Document Processing: docx, pdf, pptx, xlsxDevelopment & Code Tools: MCP Builder, Webapp Testing, Changelog GeneratorData & Analysis: CSV Data Summarizer, Root Cause TracingBusiness & Marketing: Lead Research Assistant, Competitive Ads ExtractorCreative & Media: Canvas Design, Theme Factory, Image Enhancerよくある失敗と対策Skillsを作り始めると、最初は思い通りに動かないことが多いです。よくある失敗パターンとその対策をまとめました。 問題  原因  対策  Skillがトリガーされない  descriptionが曖昧  「何をするか」と「いつ使うか」を明記  コンテキスト不足  SKILL.mdに情報が足りない  参照ファイルを追加  トークン消費が多すぎる  Progressive Disclosureしてない  情報を複数ファイルに分割  出力が不安定  自由度が高すぎる  具体的なテンプレートや例を追加  スクリプトエラー  エラーハンドリングが甘い  スクリプト内で明示的にエラー処理 セキュリティ上の注意点Skillsはフルユーザー権限で実行されます。信頼できないソースのSkillsは使わないでください。チェックすべきポイントは以下です。全ファイルを監査: SKILL.md、スクリプト、リソースをすべて確認外部接続に注意: 外部URLへアクセスするSkillは特にリスクが高い自分で作る or 公式を使う: 基本的にこの2択Skillsの限界と現実ここまでSkillsの使い方やベストプラクティスを紹介してきました。しかし正直に言うと、Skillsは万能ではありません。実際にシステム化しようとすると、いくつかの困難にぶつかります。限界がある理由は明確です。 Skillsは「LLMに追加の情報を渡す」仕組みです。LLMの推論能力自体を向上させるわけではありません。どれだけ精緻なSkillを書いても、LLMが誤解することはあるし、予期しない振る舞いをすることもあります。これはLLMの本質的な不確実性に起因する問題で、Skillsでは解決できません。時間目安: 最初のSkillを動かすまで1-2時間かかります。descriptionの調整、手順の修正、再テストのサイクルが必要だからです。2個目以降は30分程度になります。週3回以上使うタスクでないと元が取れないので、投資対効果を考えて作りましょう。定義ファイル地獄Skillsを整備していくと、管理すべきファイルが膨大になります。私のプロジェクトでは、こんな構造になりました。.claude/skills/├── building-and-testing/├── running-integration-tests/├── running-e2e-tests/├── running-mutation-tests/├── managing-docker-dev/├── working-with-branches/├── implementing-issues/├── checking-pr/├── reviewing-security/├── reviewing-quality/├── using-rust-patterns/├── using-sqlx-patterns/├── handling-errors/└── ... (50個のSkillフォルダ)「地獄」になる理由は、 Skillsがコードと違って静的解析できないからです。どのSkillがどのタスクで起動するかは、実際に動かしてみないと分からない。コードなら「この関数はどこから呼ばれているか」を検索できますが、Skillsの時は「このSkillはいつ起動するか」をLLMの判断に委ねています。依存関係がブラックボックスになるのです。50個のSkillがあると、どれがどの場面で起動するのか把握しきれなくなります。「なんでこのSkillが動いたんだ」という状況が発生します。結局、設計者がすべてのSkillの挙動を把握していないといけません。これは隠れたコストです。descriptionの試行錯誤Skillが起動するかどうかはdescriptionの書き方次第です。しかし「どう書けば起動するか」は試してみないと分かりません。試行錯誤が必要な理由は、 LLMが「意味」で判断するからです。プログラムのように「この文字列が含まれていたら起動」という決定論的なルールではありません。「code review」と書いても、ユーザーが「PRを見て」と言ったらLLMが「これはcode reviewのことだ」と解釈するかどうかはLLM次第です。LLMの判断基準は私たちには見えません。# 起動しなかった例description: Helps with code review.# 起動した例description: Performs code review. Use when reviewing pull requests, checking code quality, or before merging.「いつ使うか」を明示的に書かないと、Claudeが「このSkillを使うべきだ」と判断してくれません。でも、どこまで具体的に書けばいいのか。書きすぎると他のタスクで起動しなくなるし、曖昧だと意図しない場面で起動します。この塩梅を見つけるのに時間がかかります。これはプロンプトエンジニアリングの本質的な難しさと同じです。 「こう書けば必ずこう動く」という保証がない世界で、試行錯誤を通じて「だいたいこう動く」パターンを見つけていく。Skillsは設定ファイルの形をしていますが、実態はプロンプトエンジニアリングです。デバッグの難しさ「なぜこのSkillが起動しなかったのか」を知る手段が限られています。Claude Codeは内部でどのSkillを候補として検討し、なぜそれを選んだか（選ばなかったか）を教えてくれません。デバッグが難しい理由は、 LLMの判断過程が外部から観察できないからです。プログラムならブレークポイントを置いて変数の中身を確認できますが、LLMには「なぜこの判断をしたか」を聞く標準的なインターフェースがありません。ログを見ても「Skill Xを起動しました」という結果しか分からず、「なぜSkill YではなくXを選んだのか」は分かりません。結果として、「起動しない → descriptionを変える → また試す」のループを繰り返すことになります。プログラムのデバッグと違って、再現性も低い。同じプロンプトでも起動したりしなかったりします。これはLLMベースのシステム全般の課題です。 Skillsに限った話ではありません。LLMの判断を制御したいなら、その不確実性と付き合う覚悟が必要です。Skill同士の競合複数のSkillが似たようなdescriptionを持っていると、どちらが選ばれるか予測できません。競合が起きる理由は、 Skillの選択がLLMの「意味的な類似度判断」に依存しているからです。プログラムなら「優先度」を数値で指定できますが、Skillsにはそういう明示的な優先度設定がありません。LLMが「どちらがより適切か」を毎回判断しますが、その判断基準はコンテキスト依存で変わります。# Skill Adescription: Reviews code for security issues.# Skill Bdescription: Performs security audit on codebase.「セキュリティチェックして」と言ったとき、AとBのどちらが起動するか。両方起動することもあります。Skillが増えるほど、こういう競合が起きやすくなります。対策としては、Skillの責務を明確に分離するしかありません。 「security issues」と「security audit」が重複しているなら、片方を削除するか、descriptionで「Use when: PRの差分をレビューするとき」vs「Use when: プロジェクト全体を監査するとき」のように用途を分けます。これは設計段階で意識する必要があります。「作る、試す、正す」で育てるここまで限界をいくつも挙げてきました。descriptionの試行錯誤、デバッグの難しさ、Skill同士の競合。これだけ聞くと「やっぱり使わない方がいいのでは」と感じるだろう。しかし、限界があるからといって諦める必要はありません。ここで参考になるのが、市谷聡啓氏の『作る、試す、正す。アジャイルなモノづくりのための全体戦略』です。この本の核心は、「正しさ」を探すのではなく、「正しくなる状況」をつくるというアプローチです。私たちの仕事は「正しいSkillを作る」ことではない。「ソフトウェアが正しくなっていく状況」をSkillで設計することです。つまり、Skillの完成度を追い求めるのではなく、適切なタイミングでSkillが発動し、結果としてソフトウェアが正しい方向に進む——その「状況」を整えることが本質です。作る → 試す → 正す → 作る → 試す → 正す → ...作る: 最小限のSKILL.mdを書く試す: 実際に使ってみて、期待通りに動くか確認する正す: 動かなかった部分を修正し、descriptionを調整する「課題を言葉で確認するだけでは分かった気になる」と市谷氏は指摘しています。Skillsも同様で、頭の中で設計を完璧にしようとしても限界があります。実際に動かしてみて初めて、「このdescriptionでは起動しない」「この手順では不十分」という発見が得られます。私も最初のSkillは散々でした。descriptionが曖昧すぎて起動しない、手順が抽象的すぎて出力がブレる。でも何度か直していくうちに、「こう書けば確実に起動する」「この粒度で手順を書けば安定する」という感覚が掴めてきました。Skillsの価値は「完成品」ではなく「育てるプロセス」にあります。 descriptionの試行錯誤を通じて、私たちはLLMの「判断基準」を逆算的に学んでいる。Skillsは単なる設定ファイルではなく、LLMの振る舞いを観察し理解するための実験装置でもあるのです。まとめAgent Skillsは、LLMのステートレスな制約を回避し、専門知識を必要な時に注入する仕組みです。今まで紹介してきた設定（CLAUDE.md、commands、Hooks、Subagents）と組み合わせれば、Claude Codeの使い勝手は大きく変わります。CLAUDE.md: プロジェクトの文脈commands: 手動ショートカットHooks: 自動実行Subagents: 専門家の自動呼び出しSkills: 専門知識の注入 ← NEWこれらの設定を組み合わせることで、Claude Codeは単なるAIアシスタントから、チームの一員のように振る舞うツールへと変わります。Skillsが示唆するAIエンジニアリングの未来では、この変化は何を意味するのか。Skillsが示唆するのは、「AIエージェントの制御は、プロンプトではなくワークフローで行う時代になった」ということです。従来のLLM活用は「良いプロンプトを書く」スキルが中心でした。しかしSkillsの登場で、パラダイムが変わりました。これからのAIエンジニアリングは、「LLMにどう推論させるか」ではなく、「LLMの推論をどう制約し、どう組織の資産として蓄積するか」が問われます。暗黙知として個人の頭の中にあったワークフローが、SKILL.mdという明示的なドキュメントになる。これはチーム全体で共有・改善できる「組織の資産」になります。Skillsは単なる便利ツールではなく、ワークフローの形式知化を促す仕組みでもあるのです。万能ではありません。descriptionの試行錯誤は避けられないし、Skillが増えると管理コストも上がります。でも「作る、試す、正す」のサイクルを回せば、確実に生産性は上がります。Claude Codeが雑魚なんじゃない、設定してないだけ。設定すればちゃんと動いてくれます。今日から試せること記事を読んで「面白そう」と思ったら、まずこれを試してみてください。1. ビルトインSkillsを体験する（1分）claude.aiで「PowerPointで自己紹介スライドを作って」と言ってみてください。Skillsが自動で起動して、プロ級のスライドが生成されます。2. カスタムSkillの最小構成を作る（5分）mkdir -p ~/.claude/skills/hello-skill~/.claude/skills/hello-skill/SKILL.mdを作成します。---name: hello-skilldescription: Says hello in a fun way. Use when user asks for a greeting.---# Hello SkillWhen asked to greet, respond with a creative and fun greeting.Include an emoji and a short motivational message.Claude Codeを再起動して「挨拶して」と言ってみてください。Skillが起動するはずです。3. 既存のSkillsを眺める（10分）awesome-claude-skillsで、他の人が作ったSkillsを見てみてください。SKILL.mdの書き方の参考になります。参考資料Agent Skills - Anthropic Engineering BlogAgent Skills Overview - Claude DocsAgent Skills Best Practices - Claude DocsUsing Skills with the API - Claude Docsawesome-claude-skills - ComposioHQClaude Skills CookbookClaude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する - atusyClaude Skillsとは何か - r_kaga振る舞い駆動開発（BDD）とは？ - HQW!作る、試す、正す。 - 市谷聡啓Claude Skillsとは何なのか？Use Agent Skills in VS Code]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Datadog Error Tracking & Claude Code Action で アプリケーションエラーを(半)自動修正 / Datadog Error Tracking & Claude Code Action (semi-)auto-correct application errors]]></title>
            <link>https://speakerdeck.com/nomadblacky/datadog-error-tracking-and-claude-code-action-semi-auto-correct-application-errors</link>
            <guid isPermaLink="false">https://speakerdeck.com/nomadblacky/datadog-error-tracking-and-claude-code-action-semi-auto-correct-application-errors</guid>
            <pubDate>Fri, 19 Dec 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[3-shake SRE Tech Talk #14 オンサイトhttps://3-shake.connpass.com/event/373259/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Plans of how to spend the New Year’s holiday from 2025 to 2026]]></title>
            <link>https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Thu, 18 Dec 2025 13:10:41 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Apache Commons Numbersとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_numbers</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_numbers</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はApache Commons Numbersについて調べてみました。 今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Numbersとは？公式サイトによると、Apache Commons Numbers...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Commons Chainとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_chain</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_chain</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:56 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Commons Chainについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Chainとは？公式サイトによると、Gang of Fourの責任連鎖パターン(chain ...]]></content:encoded>
        </item>
    </channel>
</rss>