<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Sun, 01 Jun 2025 22:35:21 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[Pythonのtypingについて改めて調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/b1643e49d81dfe</link>
            <guid>https://zenn.dev/akasan/articles/b1643e49d81dfe</guid>
            <pubDate>Sun, 01 Jun 2025 10:21:58 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonのtypingについて今までちゃんと調べずに使っていたこともあったので調べてみることにしました。 typingとは？Pythonでデフォルトで利用可能なtypingは、Pythonにおけるタイプヒントをサポートする目的で実装されています。以下が公式ページになります。注釈にも書いてありますが、一般的はPythonランタイムは関数や変数のアノテーションについて強制することはありません。あくまで型アノテーションは明示的に型を示すことでセルフドキュメントとして機能します。※ mypyなどの静的型チェッカーを利用するさいはタイプヒントが必要です。基本的にはmypyを利用し...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIが進化しても、なぜそのコードを書いたかは消えていく]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/06/01/122352</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/06/01/122352</guid>
            <pubDate>Sun, 01 Jun 2025 03:23:52 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIを使ったコード開発が急速に普及している。GitHub Copilot、ChatGPT、Claude、そして各種IDEに統合されたAIアシスタントや独立したコーディングエージェント。これらのツールは開発効率を飛躍的に向上させ、もはやAIなしでの開発は考えられないという声も聞こえてくる（主に心の底から）。しかし、この革新的な変化の中で、看過できない問題が顕在化している。現在のAIで生成したコードは、2年後の進化したAIで再生成すれば、より効率的で保守性の高いコードに置き換えられる。これ自体は技術進歩として歓迎すべきことだが、重要な情報が失われている。それは「なぜそのコードをそのように実装したのか」という意思決定の記録だ。この問題は単なる技術的な課題ではない。私たちがどのようにソフトウェアを作り、保守し、進化させていくかという、エンジニアリングの本質に関わる問題だ（そして、2年後の自分に恨まれない方法でもある）。プロンプトと成果物の分離がもたらす課題従来の開発では、コードとともにコメントやドキュメントで意図を残してきた。しかしAI時代では、以下の情報が分離してしまう：入力：プロンプト（要件、制約、背景情報）出力：生成されたコード生成されたコードだけがリポジトリに残り、そのコードを生成した際のプロンプトや文脈は失われる。2年後、より優れたAIでコードを改善しようとしても、元の要件や制約条件、設計判断の根拠が不明なため、適切な改善ができない。これは「なんでこんな実装になってるの？」と聞かれて「AIがそう書いたから...」としか答えられない悲しい未来への第一歩だ。ADRからPDRへ：解決策の提案ソフトウェアアーキテクチャの分野では、ADR（Architecture Decision Records）によって設計判断を記録する文化が定着している。同様に、AI時代にはPDR（Prompt Decision Records）が必要だ。syu-m-5151.hatenablog.comPDRに記録すべき要素：使用したAIモデルとバージョン（GPT-4なのかClaude-3なのか、未来の自分は知りたがっている）入力したプロンプトの完全なテキストプロンプトに込めた意図と背景検討した他の選択肢採用した理由とトレードオフ生成パラメータ（temperature、max_tokens等）既存ツールにおける実装例Cursor Rulesdocs.cursor.comCursorでは.cursorrulesファイルでプロジェクト固有のコンテキストを定義できる。これにより、AIは常にプロジェクトの規約や方針を理解した上でコードを生成する（理解しているフリをすることもあるが）。具体的には、プロジェクトのルートディレクトリに.cursorrulesファイルを配置することで、以下のような指示を永続化できる：このプロジェクトではTypeScriptを使用し、関数型プログラミングのアプローチを優先する。エラーハンドリングはResult型を使用し、例外は投げない。すべての関数にはJSDocコメントを必須とする。このファイルはプロジェクト全体で共有される暗黙知を形式知化する役割を果たし、新しいメンバーがジョインした際のオンボーディングツールとしても機能する。Cline Rulesdocs.cline.botClineも同様に、プロジェクトルールを定義する仕組みを提供している。これらのルールファイルは、実質的にプロンプトの一部を永続化する仕組みだ。Clineの特徴的な点は、ルールを階層的に管理できることだ。グローバルルール、プロジェクトルール、ディレクトリ固有のルールを定義でき、より細かい粒度でAIの振る舞いを制御できる。例えば：/backendディレクトリ：「APIエンドポイントはRESTfulな設計に従う」/frontendディレクトリ：「ReactコンポーネントはHooksを使用した関数コンポーネントとする」/testsディレクトリ：「テストはAAA（Arrange-Act-Assert）パターンに従う」このようなコンテキストの階層管理により、大規模プロジェクトでも一貫性を保ちながら、部分ごとに最適化されたAI支援を受けられる。Anthropic CLAUDE.mdwww.anthropic.comAnthropicのCLAUDE.mdアプローチは、プロジェクトの全体的なコンテキストを単一のマークダウンファイルにまとめる。これは包括的なプロンプトテンプレートとして機能し、AIとの対話の基盤となる。CLAUDE.mdの強みは、単なるルールの羅列ではなく、プロジェクトのストーリーを語る点にある。典型的な構成は：# プロジェクト概要このプロジェクトの目的と背景# アーキテクチャシステムの全体構成と主要コンポーネントの説明# 開発規約- コーディングスタイル- 命名規則- ディレクトリ構造# よくある質問と回答過去の設計判断とその理由この形式により、AIは単にルールに従うだけでなく、プロジェクトの「なぜ」を理解した上でコードを生成できる。まさに本記事で提唱するPDRの考え方を先取りした実装と言えるだろう。実装における具体的な課題バージョン管理プロンプトもコードと同様にバージョン管理が必要だ。しかし、以下の課題がある：プロンプトの変更がコードに与える影響の追跡AIモデルのバージョンアップに伴う互換性管理プロンプトとコードの紐付けの維持（gitのblameコマンドに「AI」と表示される悲しさ）標準化の欠如現状、プロンプトを記録・管理する標準的な方法は存在しない。各ツールが独自の方法を実装しているため、ツール間での移植性がない。まるで文字コードの乱立時代を彷彿とさせる。再現性の問題同じプロンプトでも、以下の要因により出力が変わる：AIモデルのバージョン生成パラメータAPIのバージョン実行タイミング（モデルの更新）今後の展望と提案短期的な対策既存ツールの活用Cursor、Cline、GitHub Copilotなどが提供するルールファイル機能を積極的に活用し、プロジェクト固有のコンテキストを記録・管理する。プロンプトのコメント埋め込み生成されたコードに、使用したプロンプトをコメントとして埋め込む（将来の自分への手紙として）。専用ディレクトリでの管理/promptsディレクトリを作成し、コードファイルと対応するプロンプトファイルを保存。生成メタデータの記録生成日時、モデルバージョン、パラメータをJSONで保存。中長期的な標準化業界標準として、以下のような仕様が必要になるかもしれない：# prompt-decision-record.yamlversion: 1.0timestamp: 2024-12-XXmodel:  provider: openai  name: gpt-4  version: gpt-4-0125-preview  mood: cooperative  # 冗談ですparameters:  temperature: 0.7  max_tokens: 2000prompt: |  実際のプロンプトテキストcontext:  requirements: |    要件の説明  constraints: |    制約事項  decisions: |    設計判断の根拠output_file: src/feature/***.pyおわりにAI活用が当たり前になる開発環境において、コードの「なぜ」を残すことは、技術的負債を防ぐ重要な実践だ。2年後により良いAIが登場したとき、過去の意思決定を理解できれば、真に価値のある改善が可能になる。私たちエンジニアは、常に未来の自分や同僚のことを考えてコードを書いてきた。可読性、保守性、拡張性—これらはすべて「未来の誰か」のための配慮だ。AI時代においても、この精神は変わらない。むしろ、AIの進化速度を考えれば、より一層重要になる。プロンプトは新しい形の設計書だ。コードレビューと同じように、プロンプトレビューが必要になるかもしれない。リファクタリングと同じように、プロンプトリファクタリングが日常になるかもしれない（プロンプトの可読性を議論する日も近い）。PDRのような仕組みの標準化は、AI時代のソフトウェア開発における必須要件となるだろう。エンジニアとして、この課題に真剣に取り組む時期に来ているが、個人ではどうにもならない気もするので。頑張れ、Anthropic！！！]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitLabでCIを実行する方法を調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/fb2c0453fde9fa</link>
            <guid>https://zenn.dev/akasan/articles/fb2c0453fde9fa</guid>
            <pubDate>Sat, 31 May 2025 06:39:06 GMT</pubDate>
            <content:encoded><![CDATA[今回はGitLabを利用してどのようにCIを実行するかについて試してみました。私自身今までGitHub Actionsしか使ってこなかったので、今回試してみました。 GitLabとはGitLabはGitLab社が展開しているGitを利用するためのバージョン管理システムのサービスになります。DevOpsだけでなくDevSecOpsのワークフローを意識したサービスとなっています。以下が公式ページとなっております。https://about.gitlab.com/ja-jp/ CIとは？CIとは継続的インテグレーション、英語にするとContinuous Integrationの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[marp.nvimを開発してCursorから完全移行した話]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/31/105405</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/31/105405</guid>
            <pubDate>Sat, 31 May 2025 01:54:05 GMT</pubDate>
            <content:encoded><![CDATA[なぜmarp.nvimが必要だったのか前回の記事でClaude Codeに移行し、Neovimに完全回帰することを決めた。コーディング、ドキュメント作成、設定ファイルの編集――すべてが再びターミナルで完結するようになった。しかし、一つだけ問題があった。Marpでのプレゼンテーション作成だ。Marpは素晴らしいツールだが、公式のNeovimサポートは存在しない。プレゼンテーションを作るたびに、仕方なくVSCodeやCursorを起動していた。せっかくNeovimに完全回帰したのに、プレゼン作成のためだけに別のエディタを立ち上げる。この矛盾が許せなかった。marp.app既存のソリューションを探したが、満足できるものはなかった。ならば答えは一つ――自作するしかない。こうしてmarp.nvimは生まれた。Neovimですべてを完結させるという理想を、妥協なく追求した結果だ。github.commarp.nvimの技術的アプローチアーキテクチャ┌─────────────┐     ┌─────────────┐     ┌─────────────┐│   Neovim    │────▶│  marp.nvim  │────▶│  Marp CLI   ││   Buffer    │     │  Lua Plugin │     │  --watch    │└─────────────┘     └─────────────┘     └─────────────┘                            │                            ▼                    ┌─────────────┐                    │   Browser   │                    │  Auto-open  │                    └─────────────┘コア実装の詳細1. Marp CLIのプロセス管理これは完全にMarp の作者が優秀なのですがMarpには--watchオプションが存在しています。これを使わない手はないです-- プロセスをバッファごとに管理M.active_processes = {}-- jobstart で Marp CLI を起動local job_id = vim.fn.jobstart(shell_cmd, {    pty = true,  -- 擬似端末で適切な出力キャプチャ    stdout_buffered = false,    stderr_buffered = false,    on_stdout = function(_, data)        -- 出力処理    end,    on_exit = function()        M.active_processes[bufnr] = nil    end})重要なポイント：pty = trueを使用することで、Marp CLIのカラー出力を適切に処理stdout_buffered = falseでリアルタイム出力を実現バッファ番号をキーにしてプロセスを管理2. 自動クリーンアップの実装vim.api.nvim_create_autocmd({"BufDelete", "BufWipeout"}, {    buffer = bufnr,    once = true,    callback = function()        M.stop(bufnr)    end})VSCode拡張機能では当たり前の機能だが、Neovimでは自前実装が必要。バッファのライフサイクルに合わせてプロセスを管理。3. ウォッチモード vs サーバーモードif M.config.server_mode then    cmd = string.format("%s -s '%s'", marp_cmd, file)else    -- デフォルトは --watch モード    cmd = string.format("%s --watch '%s'", marp_cmd, file)end2つのモードをサポート：ウォッチモード（デフォルト）: HTMLファイルを生成し、変更を監視サーバーモード: HTTPサーバーを起動（ポート競合の可能性あり）4. ANSIエスケープシーケンスの処理local function clean_ansi(str)    return str:gsub("\27%[[%d;]*m", ""):gsub("\27%[[%d;]*[A-Za-z]", "")endMarp CLIの美しいカラー出力をNeovimの通知システムで扱うための処理。これがないと文字化けする。実装で工夫した点1. 初回HTML生成の最適化-- ウォッチモード開始前に初回HTMLを生成if not M.config.server_mode then    local init_cmd = string.format("%s '%s' -o '%s'", marp_cmd, file, html_file)    vim.fn.system(init_cmd)        if vim.fn.filereadable(html_file) == 1 then        -- 即座にブラウザを開く        M.open_browser("file://" .. html_file)    endend--watchモードは初回生成が遅いため、事前に生成してUXを改善。2. クロスプラットフォーム対応function M.open_browser(url)    local cmd    if vim.fn.has("mac") == 1 then        cmd = "open " .. url    elseif vim.fn.has("unix") == 1 then        cmd = "xdg-open " .. url    elseif vim.fn.has("win32") == 1 then        cmd = "start " .. url    end    vim.fn.jobstart(cmd, {detach = true})end3. デバッグモードM.config = {    debug = true,  -- 詳細ログを有効化}-- :MarpDebug コマンドで診断function M.debug()    local test_cmd = string.format("%s --version", marp_cmd)    -- Marp CLIの動作確認endトラブルシューティングを容易にするため、詳細なログ出力機能を実装。VSCode拡張機能との機能比較 機能  Marp for VS Code  marp.nvim  ライブプレビュー  ✅  ✅  自動リロード(書き込みイベント時)  ✅  ✅  テーマ切り替え  GUI  :MarpTheme  エクスポート  GUI  :MarpExport  スライドナビゲーション  ✅  ❌（開発中）  スニペット  ✅  ✅  複数ファイル同時編集  ✅  ✅ 使用方法インストール-- lazy.nvim{    "nwiizo/marp.nvim",    ft = "markdown",    config = function()        require("marp").setup({            marp_command = "npx @marp-team/marp-cli@latest",            debug = false,            server_mode = false,  -- ウォッチモードを使用        })    end,}基本的なワークフロー:e presentation.md:MarpWatch          " プレビュー開始(ファイル名をClipboardに書き込みもしている):MarpTheme uncover  " テーマ変更:MarpExport pdf     " PDF出力:q                  " バッファを閉じると自動でサーバー停止トラブルシューティング:MarpDebug          " Marp CLIの動作確認:MarpList           " アクティブなサーバー一覧:MarpStopAll        " 全サーバー停止パフォーマンスと制限事項メモリ使用量Marp CLIプロセス: 約50-100MB/インスタンス複数ファイル同時編集時は線形に増加既知の制限ホットリロードの遅延: ファイル保存からブラウザ更新まで約100-200ms大規模ファイル: 100スライド以上でパフォーマンス低下画像の相対パス: 作業ディレクトリに依存まとめmarp.nvimの開発により、Marpプレゼンテーション作成のためだけにCursorを起動する必要がなくなった。Neovimのjob APIを活用することで、VSCode拡張機能と似た体験を実現できることを証明できた。重要なのは、完璧を求めすぎないこと。VSCode拡張機能のすべての機能を再現する必要はない。ターミナルでの開発に必要十分な機能を、シンプルに実装することが大切だ。Claude Codeとの組み合わせで、プレゼンテーション作成もAIアシスト付きで行える。これで本当にすべての開発作業をNeovimで完結できるようになった。vimmer村への完全帰還、達成。実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：tldr]]></title>
            <link>https://zenn.dev/akasan/articles/dd94771d828ec7</link>
            <guid>https://zenn.dev/akasan/articles/dd94771d828ec7</guid>
            <pubDate>Fri, 30 May 2025 10:37:03 GMT</pubDate>
            <content:encoded><![CDATA[コマンド紹介シリーズ第2回は、tldrというコマンドを紹介します。名前からして何かしらの情報をまとめて表示してくれる系のコマンドと予想できるかと思いますが、実際はどんなコマンドなのかみていきましょう。 tldrとは？一言で言ってしまうと、コマンドラインツールのヘルプページで、man pagesをよりシンプルにしたものと思ってもらえればと思います。公式GitHubは以下にありますのでぜひ参照ください。https://github.com/tldr-pages/tldrそもそもman pagesとは何かという話ですが、コマンドラインツールで使い方がわからない時に利用されるm...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude Code を利用しようと思っているのでvimmer が住む村に帰ろうと思います。]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/30/180912</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/30/180912</guid>
            <pubDate>Fri, 30 May 2025 09:09:12 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回、「NeovimをCursorのように進化させる - yetone/avante.nvim の導入」を書いた。あの記事では、まるで自分だけの剣を鍛え上げていくように、エディターと共に成長していくPDEの哲学について語った。syu-m-5151.hatenablog.comあれから数ヶ月、私のNeovimはavante.nvimによってCursor + Roo-Codeライクな体験を手に入れ、PDEとしてさらなる進化を遂げた。しかし、告白しなければならないことがある。vimmerを自称しながら、実は日常的にCursorを使っていた。この矛盾と向き合う時が来た。www.cursor.comそして先週の土曜日、私はClaude Codeを使い始めた。今日で1週間。短い期間だが、これが私のPDEに新たな可能性をもたらすことを確信している。そして、Cursor のサブスクを解約してClaude をMAX Planにした。www.youtube.com私は、Claude Code を利用しようと思っているのでvimmer が住む村に帰ろうと思います。一旦、お別れです。 pic.twitter.com/Is5fAUD5hI— nwiizo (@nwiizo) 2025年5月29日   「いいえ、Neovimはもっと強くなれます」前回からの旅路：PDEという哲学前回の記事で、私はこう書いた：Neovimの最大の魅力は、その圧倒的なカスタマイズ性。それは単なるIDE（統合開発環境）ではなく、PDE（Personal Development Environment：個人開発環境）とも呼べる存在です。この言葉は、今思えば預言的だった。PDEという概念は、単にツールをカスタマイズすることではない。それは、開発者が自分自身の思考プロセスと一体化したツールを作り上げることだ。まるで自分だけの剣を鍛え上げていくように、エディターと共に成長していく。そして今、私は気づいた。PDEとは、一人で剣の丘で鉄を鍛つような孤独で崇高な作業なのだと。誰かが用意した完成品ではなく、自分の手で、自分のために、一つ一つ形作っていくもの。avante.nvimは、その第一歩だった。しかし、6ヶ月間Cursor + Roo-Codeを使い込んだことで、私は逆説的にPDEの価値を理解した。Cursor + Roo-Codeは確かに完成度の高い「製品」だ。しかし、私が求めていたのは「作品」—自分の手で育てていけるものだった。実際には育ててなくても育てている感覚があるものだ。正直に告白しよう。vimmerを自称しながらも、実は各所でCursor + Roo-Codeを使っていた。クライアントワークでは生産性を優先してCursor、個人プロジェクトではNeovim。そんな二重生活を送っていた。この矛盾に、私自身も気づいていた。なぜ今、Claude Codeなのか正直に言えば、Claude Codeを使い始めた最大の理由は、Claude Opus 4がリリースされたからだ。最新にして最強のモデル。その能力を、私の愛するターミナル環境で直接使えるなんて—これは試さずにはいられなかった。zenn.devしかし、それだけではない。Claude Codeが掲げる「Terminal Velocity」という概念に、私は強く惹かれた。www.anthropic.com考えてみてほしい。私たちvimmerは、なぜターミナルから離れないのか？それは、思考の流れを断ち切りたくないからだ。GUIアプリケーションへの切り替え、マウスへの手の移動、異なるUIパラダイムへの適応—これらすべてが、私たちの集中を妨げる。Claude Codeは、その問題を根本から解決する。「コンテキストスイッチをゼロにする」—これは、PDEの究極の形かもしれない。そしてもう一つ、個人的に重要だったのがMAX Planという料金体系だ。トークン数無制限。これは貧乏性の私にとって革命的だった。Cursorでは常に「今月あとどれくらい使えるか」を気にしていた。コーディングエージェントでコードを書く前に「これ、AIに聞くほどの価値があるかな？」と躊躇する。そんな心理的ブレーキが、創造性を阻害していたことに気づいた。MAX Planは、その制限から私を解放してくれた。思考のままに、遠慮なくAIと対話できる。まるで無限のメモ帳を手に入れたような感覚だ。「トークンがもったいない」という貧乏性マインドから解放されて初めて、本当の意味でAIとの協働が始まる。これこそが、私のメンタルモデルと完璧に合致した。先週土曜日から使い始めて、まだ1週間。しかし、その短い期間でも、Claude Codeの持つ独特の「控えめな賢さ」に魅了された。Roo-Codeのような積極性はない。しかし、それがかえって心地よい。必要な時に、必要なだけ、的確な支援をしてくれる。Claude Opus 4の高い理解力が、控えめながらも的確なアドバイスを可能にしているのだろう。そして何より、もうトークン数を気にする必要がない。深夜のコーディングセッションで「あと何回質問できるかな...」と計算する必要もない。この精神的な自由度が、私の開発スタイルを根本から変えつつある。zenn.devzenn.devnote.comCursor + Roo-Codeへの敬意、そして決別誤解しないでほしい。私はCursor + Roo-Codeを否定したいわけではない。実際、この6ヶ月間、私は久しぶりにVSCodeベースのCursorをメインエディタとして使い込んだ。そしてそれは、驚くほど素晴らしい体験だった。特にRoo-Codeとの組み合わせで実感したのは、これは単にAIモデルを統合しただけのツールではないということだ。それは開発体験そのものが根本的に違う。github.com考えてみてほしい。従来の開発では、私たちは一つのファイルを開き、一行ずつコードを書いていた。しかしCursor + Roo-Codeの世界では、コードベース全体が一つの有機体として扱われる。「このコンポーネントをリファクタリングして」と言えば、関連する全てのファイルが瞬時に更新される。「このテストを追加して」と言えば、適切なディレクトリに適切な形式でテストが生成される。さらに驚くべきは、Roo-Codeが持つ「意図の理解」だ。曖昧な指示でも、プロジェクトの文脈を読み取り、開発者が本当に必要としているものを推測して提案してくる。それは、経験豊富な同僚とペアプログラミングをしているような感覚だった。これは単なる効率化ではない。これは開発の概念そのものの再定義だった。正直に言えば、これほど生産的な6ヶ月は久しぶりだった。前回の記事でavante.nvimを導入したのも、このCursor + Roo-Codeの革新的な開発体験に触発されたからこそだった。6ヶ月のCursor + Roo-Code体験は、確かに私の開発スタイルを変えた。Tab補完を超えた、AIペアプログラミング。しかし同時に、ある種の違和感も育っていった。それは、自分がコードを「書いている」のか「選んでいる」のか、境界が曖昧になる感覚だった。そして、もう一つの違和感。朝はNeovimで始めたはずが、気がつけばCursorを開いている。締切が迫ると、つい効率的な方を選んでしまう。vimmerとしてのアイデンティティが揺らいでいた。この6ヶ月は、技術的な進歩と同時に、自分自身との葛藤の期間でもあった。Roo-Codeが見せてくれた「開発体験の違い」は革新的だった。しかし、それゆえに気づいたことがある。開発者として長年培ってきた直感が教えてくれる。私たちには「まだ形になっていないアイデアを、コードという形で具現化する」という独特の能力がある。AIはコードを生成できる。しかし、なぜそのコードが必要なのか、それが解決すべき本質的な問題は何かを理解することはできない。そして今、6ヶ月の濃密な体験を経て、私は確信を持って言える—Cursor + Roo-Codeは素晴らしい。その組み合わせは革命的だ。しかし、私にはPDEとしてのNeovimがある。それは単なるエディタではなく、私の思考の延長線上にある道具なのだ。PDEの完成形を目指してしかし、正直に言えば、この6ヶ月はNeovimとCursorの間で揺れ動いていた。月曜の朝は「今週こそNeovimで」と決意するも、水曜には締切に追われてCursorを開く。金曜には罪悪感を感じながらも、Roo-Codeの生産性に頼っていた。vimmerとしての矜持はどこへ行ったのか。だが、この葛藤の中で私は気づいた。PDEとは、単に優れたツールを集めることではない。それは、自分の開発哲学と完全に一致した環境を構築することだ。そして今、NeovimコミュニティはAI時代に適応し、驚くべき進化を遂げている。以下に紹介する3つのプラグインは、その進化の最前線にある。yetone/avante.nvim - 前回の記事で導入したこのプラグインは、Cursor AI IDEの体験をNeovimで完璧に再現する。サイドバーでのAI対話、差分の視覚的表示、ワンクリックでのコード適用など、Cursor + Roo-Codeユーザーが慣れ親しんだ機能をすべて提供する。しかし、それだけではない。Neovimのモーダル編集と完全に統合されているため、思考の流れを妨げることなくAIとの対話を行える。ravitemer/mcphub.nvim - AnthropicのModel Context Protocol (MCP)をNeovimに統合する革新的なプラグイン。MCPサーバーの集中管理により、AIが外部ツールやデータソースにシームレスにアクセスできるようになる。データベースへの直接クエリ、ファイルシステムの操作、外部APIとの連携—これらすべてがNeovimの中で完結する。これこそが、未来のAI開発環境の標準となるだろう。こちらでMCP経由でもclaude-codeを利用している。greggh/claude-code.nvim - Claude Code CLIとNeovimを完全に融合させる野心的なプロジェクト。ターミナル内でClaude Opus 4を含む最新モデルの全能力を解き放ち、まさに「Terminal Velocity」を体現する。:ClaudeCodeコマンド一つで、現在のバッファやプロジェクト全体のコンテキストを理解した上で、最適な提案を行ってくれる。これは単なるプラグインではない—開発体験の再定義だ。これらのツールを組み合わせることで、私のNeovimは単なるテキストエディタから、真のAI統合開発環境へと進化した。もはやCursorを羨む必要はない。むしろ、より深く、より個人的な形でAIと協働できる環境が、ここにある。github.comPDEという哲学の深化PDEとは何か。それは、開発者の思考パターンとツールが完全に一体化した環境だ。前回の記事で初めてこの概念を提示したが、6ヶ月の実践を経て、その意味がより深く理解できるようになった。筆者は専門家ではないため、あくまで個人的な経験に基づく話として聞いていただきたいが、優れたPDEには以下の特徴がある：思考の流れを妨げない：Warp + Neovim + Claude Codeの組み合わせ拡張可能性：新しいツールを取り込める柔軟性個人の哲学の反映：設定ファイルという形での思想の具現化私の~/.config/nvim/lua/plugins/init.luaは、単なる設定ファイルではない。これは私の開発思想の結晶だ。Lazy.nvimを通じて管理されるプラグインの一つ一つが、私の開発哲学を体現している。Cursor + Roo-Codeの体験を経て、その設定はさらに洗練された。そして何より、PDEの構築は一人で剣の丘で鉄を鍛つ行為に似ている。誰も代わりにはできない。自分の手で、自分のために、ひたすら打ち続ける。時に孤独で、時に苦しい。しかし、その先に待っているのは、自分だけの、世界に一つだけの剣だ。Cursor + Roo-Codeが示してくれた新しい開発体験は、確かに革新的だった。しかし、それらは「完成品」だ。一方、PDEとしてのNeovimは「進化し続ける生き物」のようなものだ。私の成長と共に、私の理解と共に、そして私の哲学と共に変化していく。この1週間、Claude Codeを使いながら感じたのは、「これこそが私の求めていたAIとの距離感だ」ということだった。過度に依存せず、しかし必要な時には頼れる。まさに理想的なパートナーシップだ。そして何より、もう環境を使い分ける必要がない。朝から晩まで、クライアントワークも個人プロジェクトも、すべてを私のPDEで完結できる。この統一感が、開発者としての一貫性を取り戻してくれた。おわりに前回の記事から始まった旅は、今、新たな段階に入った。avante.nvimで手に入れたCursor + Roo-Codeライクな体験に、Claude Codeの「Terminal Velocity」が加わることで、私のPDEは更に進化した。興味深いのは、最先端を追求した結果、最も原始的なツール—ターミナルとテキストエディタ—に戻ってきたことだ。しかし、これは後退ではない。これは螺旋的な進化だ。AIとの協働が当たり前になる時代において、私たちに必要なのは、AIとの適切な距離感を保ちながら、共に新たな地平を切り開いていく勇気かもしれない。そして、その第一歩が、自分のPDEを完成させることなのだ。Cursor + Roo-Codeが示してくれた新しい開発体験は、確かに未来の一つの形だ。しかし、それが唯一の答えではない。私たちには、自分自身の開発哲学に基づいて、自分だけの環境を構築する自由がある。「いいえ、Neovimはもっと強くなれます」—この言葉は、単なる願望ではない。それは、PDEという哲学を持つ私たちvimmerの確信なのだ。そして今、Claude Codeの登場により、私はついに二重生活から解放される。もうクライアントワークでCursor、個人でNeovimという使い分けをする必要はない。私のPDEが、すべての開発シーンで通用する強さを手に入れたのだから。そして、PDEの構築とは、一人で剣の丘で鉄を鍛つような営みだ。誰かが用意した剣ではなく、自分の手で打ち、自分の手で研ぎ、自分だけの刃を作り上げる。その過程こそが、私たちを真の開発者にするのかもしれない。この記事を書いている間、私はWarpターミナル上でNeovimとClaude Codeを行き来している。前回のavante.nvim導入から数ヶ月、そして Claude Code導入から1週間。私のPDEは確実に進化した。Lazy.nvimの設定ファイルは公開しているので、興味があれば参考にしてほしい。「Terminal Velocity」を「ターミナルベロシティ」とカタカナ表記したのは、この概念の持つ物理学的な含意—終端速度、つまり最高効率—を日本語でも感じてもらいたかったからだ。「Cursor + Roo-Codeのサブスクリプションを払い続けるか、vimの学習コストを払うか」—これは単なる経済的判断ではない。私たちが開発という行為にどう向き合うか、そしてPDEという哲学をどこまで追求するかという、実存的な選択なのかもしれない。6ヶ月のCursor + Roo-Code体験は本当に素晴らしかった。特にRoo-Codeが示してくれた「開発体験の違い」は、私の開発観を根本から変えた。もしあなたがまだ試していないなら、一度は体験する価値がある。その上で、自分にとっての最適な開発環境を選ぶべきだ。私にとって、それはPDEとしてのNeovimだった。この二重生活は疲れるものだった。.vimrcと.vscode/settings.jsonを行き来し、キーバインドの違いに戸惑い、どちらが本当の自分なのか分からなくなることもあった。しかし、その経験があったからこそ、今の決断に至ることができた。あなたも、vimmer村への帰郷を考えてみてはどうだろうか。Claude Codeという新しい仲間と共に、自分だけのPDEを完成させるために。VimConf 2025 Smallにも行こうかな…。今度こそ、胸を張って「私はvimmerです(え、Neovim ですよね？)」と言えるように。vimconf.org実践Vim　思考のスピードで編集しよう！ (アスキー書籍)作者:Ｄｒｅｗ Ｎｅｉｌ,新丈 径角川アスキー総合研究所Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GoogleのAI Agent]]></title>
            <link>https://speakerdeck.com/shukob/googlenoai-agent</link>
            <guid>https://speakerdeck.com/shukob/googlenoai-agent</guid>
            <pubDate>Fri, 30 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年5月30日(金) AI Agent 勉強会 Vol.3 にて、Google CloudのAI AgentサービスとGoogle I/O 2025 で発表された内容の概要を紹介させていただきました。https://almondo.connpass.com/event/355297/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[宝くじに当たる方法を思い出して、明日も頑張ることにした]]></title>
            <link>https://blog.atusy.net/2025/05/30/how-to-win/</link>
            <guid>https://blog.atusy.net/2025/05/30/how-to-win/</guid>
            <pubDate>Fri, 30 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[宝くじに当たりたければ、まず買うことだ。成功も行動の先にある。宝くじと違って、うまくいかなかった時も戦略を練り直せるから、どんどん挑戦しよう。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud 認定資格奮闘記 ~Generative AI Leader編~]]></title>
            <link>https://zenn.dev/akasan/articles/c0d347a37065bc</link>
            <guid>https://zenn.dev/akasan/articles/c0d347a37065bc</guid>
            <pubDate>Thu, 29 May 2025 13:24:41 GMT</pubDate>
            <content:encoded><![CDATA[この記事の続編になります。https://zenn.dev/akasan/articles/e2416e40a90499 Generative AI LeaderについてGenerative AI Leader（以下、GenAI Leader）は、今月公開された新しいGoogle Cloudの認定資格です。こちらの資格については公式で以下のように説明がされています。A Generative AI Leader is a visionary professional with comprehensive knowledge of how generative AI (gen A...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展]]></title>
            <link>https://sreake.com/blog/kubecon-cloudnativecon-japan-2025/</link>
            <guid>https://sreake.com/blog/kubecon-cloudnativecon-japan-2025/</guid>
            <pubDate>Thu, 29 May 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年6月16日（月）・17日（火）に開催される「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「KubeCon + CloudNativeCon Japan 2025」にGoldスポンサーとして協賛およびブース出展 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装]]></title>
            <link>https://sreake.com/blog/image-creation-and-execution-with-go-containerregistry/</link>
            <guid>https://sreake.com/blog/image-creation-and-execution-with-go-containerregistry/</guid>
            <pubDate>Thu, 29 May 2025 00:40:36 GMT</pubDate>
            <content:encoded><![CDATA[この記事ではコンテナイメージがどのように作成されているのかを、go-containerregistryライブラリを使った実装例を通して解説します。Dockerfileを使わずに、プログラムからコンテナイメージを作成する過 […]The post Dockerを使用せずにイメージを作成し実行してみる – go-containerregistryによる実装 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[セルフエンドレスアドベントカレンダーを通してエンジニアとして成長できました報告]]></title>
            <link>https://zenn.dev/akasan/articles/4aba4d3a0616ce</link>
            <guid>https://zenn.dev/akasan/articles/4aba4d3a0616ce</guid>
            <pubDate>Wed, 28 May 2025 12:47:33 GMT</pubDate>
            <content:encoded><![CDATA[今回は、私が仕事とも関係なく勝手にやっているセルフエンドレスアドベントカレンダーを通して、どう成長していると感じているか共有しようと思います。今回は技術的な話はあまりないですが、仕事以外の時間をどう使うかについて共有できればと思います。 そもそもアドベントカレンダーとは？というか、そもそもアドベントカレンダーとは何かについて理解しておかないといけないですね、、、。Wikipediaによるとインターネット上などで、12月の1日から25日までに、特定のテーマに沿って毎日ブログなどに記事を投稿していくという企画がある[1][2]。元々のアドベントカレンダーになぞらえて、この企画も...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛]]></title>
            <link>https://sreake.com/blog/google-cloud-next-tokyo-2025/</link>
            <guid>https://sreake.com/blog/google-cloud-next-tokyo-2025/</guid>
            <pubDate>Wed, 28 May 2025 06:27:59 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025 年 8 ⽉ 5 日（火）~  6 ⽇（水）に東京ビッグサイトにて開催される Google Cloud Next Tokyo  (主催：グーグル・クラウド・ジャパン合同会社) にDiamondスポンサーとして協賛いたします。The post スリーシェイク、Google Cloud Next Tokyo にDiamondスポンサーとして協賛 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AIコードエディタは開発を変えるか？Cursorをチームに導入して1ヶ月経った本音]]></title>
            <link>https://speakerdeck.com/ota1022/aikodoedeitahakai-fa-wobian-eruka-cursorwotimunidao-ru-site1keyue-jing-tutaben-yin</link>
            <guid>https://speakerdeck.com/ota1022/aikodoedeitahakai-fa-wobian-eruka-cursorwotimunidao-ru-site1keyue-jing-tutaben-yin</guid>
            <pubDate>Wed, 28 May 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[2025年5月28日 Qiita Bash 最近ハマっている生成AI活用法を語ろう！のLT登壇資料です。https://increments.connpass.com/event/351227/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ディレクトリ構成 ~フィーチャーベース編~]]></title>
            <link>https://sreake.com/blog/feature-based-directory-structure-good-practice/</link>
            <guid>https://sreake.com/blog/feature-based-directory-structure-good-practice/</guid>
            <pubDate>Wed, 28 May 2025 02:18:09 GMT</pubDate>
            <content:encoded><![CDATA[はじめに アプリケーション開発において、ディレクトリ構成は保守性・拡張性・開発効率に直結する設計要素です。 本記事では、以下のような課題に悩む現場に向けて、「機能ごとに整理しやすく、拡張にも強い」フィーチャーベース構成を […]The post ディレクトリ構成 ~フィーチャーベース編~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RedisのPub/Subを使用したリアルタイム通知の実現]]></title>
            <link>https://sreake.com/blog/realtime-notification-with-redis-pubsub/</link>
            <guid>https://sreake.com/blog/realtime-notification-with-redis-pubsub/</guid>
            <pubDate>Wed, 28 May 2025 01:18:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部のアプリケーションエンジニアの角谷です。 リアルタイム通信を実現する手段は様々ありますが、その一つにPub/Subがあります。 Pub/Subを実装する方法は様々ありますが、今回はRedisを […]The post RedisのPub/Subを使用したリアルタイム通知の実現 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Nix Meetup #3 大阪に参加した]]></title>
            <link>https://blog.atusy.net/2025/05/28/nix-meetup-3-in-osaka/</link>
            <guid>https://blog.atusy.net/2025/05/28/nix-meetup-3-in-osaka/</guid>
            <pubDate>Wed, 28 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Nix meetup #3 大阪が2025-05-24に開催されました。技術への愛溢れた濃いい話がいっぱいできてよかったです。いっぱい聞けて、じゃなくてできてってところがまた素敵。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[コマンド紹介シリーズ：thefuck]]></title>
            <link>https://zenn.dev/akasan/articles/fff0cfa9beadbc</link>
            <guid>https://zenn.dev/akasan/articles/fff0cfa9beadbc</guid>
            <pubDate>Tue, 27 May 2025 11:22:06 GMT</pubDate>
            <content:encoded><![CDATA[今回から、私が普段使ってるコマンドを紹介していくシリーズを始めたいと思います。記念すべき第一回は、thefuckというコマンドを紹介します。名前だけ見るとなかなかにパンチが効いたものですが、スター数も多いコマンドですので、ぜひ興味がある方はみてください。※ 本記事を書くにあたり、果たしてこの文字を入力して良いのか迷いましたが、①あくまでコマンド紹介であること、②他の記事で4文字が入っている記事も結構ありそうだったので採用しました thefuckとは？一言で言ってしまうと、コマンド入力をミスした時に、本来実行したかったコマンドを想定して出してくれるコマンドになります。例えば...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇]]></title>
            <link>https://sreake.com/blog/developer-productivity-conference-2025/</link>
            <guid>https://sreake.com/blog/developer-productivity-conference-2025/</guid>
            <pubDate>Tue, 27 May 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、 2025年 7月3日（木）4日（金）に開催される「開発生産性Conference 2025」にGoldスポンサーとして協賛します。The post スリーシェイク、「開発生産性Conference 2025」にGoldスポンサーとして協賛およびブース出展・登壇 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[alphaXivを使って論文要約してみた]]></title>
            <link>https://zenn.dev/akasan/articles/feaca6271b5f0c</link>
            <guid>https://zenn.dev/akasan/articles/feaca6271b5f0c</guid>
            <pubDate>Mon, 26 May 2025 13:01:26 GMT</pubDate>
            <content:encoded><![CDATA[今回は、先日Xにて見つけたalphaXivというものを使って、arXiv上の論文を要約する方法を調べてみました。 alphaXivとは？alphaXivとは、arXiv上にアップロードされている論文を要約できるサービスです。自分の指定した論文を要約できるだけでなく、コミュニティを作成・参加したりおすすめの論文を一覧に出してもらったりと、様々なことを実施できます。また、なんと言っても一番の特徴が、要約に利用されるLLMに関して料金がかからないところです。記事執筆時点ではaplhaXivで利用されるLLMについて無料で使えており、このサービスが無料で使えるのが不思議ですw。http...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[RAGアプリ開発ハンズオン（後編：フロントエンド編）]]></title>
            <link>https://shu-kob.hateblo.jp/entry/2025/05/26/185645</link>
            <guid>https://shu-kob.hateblo.jp/entry/2025/05/26/185645</guid>
            <pubDate>Mon, 26 May 2025 09:56:45 GMT</pubDate>
            <content:encoded><![CDATA[genai-users.connpass.com上記ハンズオン勉強会の資料になります。前回資料shu-kob.hateblo.jp前回の課題retriever_service を定義しましたが、検索結果をcontextとして、LLMへの問い合わせを行なってください。llm_serviceでretriever_serviceを使うようにします。@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    template = """質問: {question}    ステップバイステップで考えてください。"""    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp↓@app.post('/api/llm')def llm_service(question: Question):    human_question = question.query    model = VertexAI(model_name="gemini-2.0-flash-001", location="us-west1")    context_resp = retriever_service(question)    context = context_resp['search_result']    print(context)    template = """質問: {question}    以下の情報を参考にして、質問に答えてください。    {context}    """    prompt_template = PromptTemplate.from_template(template)    chain = prompt_template | model # prompt_templateをmodelに引き渡す処理を"|"を用いて簡単に実現    response = chain.invoke({"question": human_question, "context": context}) # invokeは全ての処理が終わってから値を返す。他にはstreamなど    print(response)    resp = { 'answer': response }    return resp以下も行っておくと便利です。.envを作成DISCOVERY_ENGINE_ID=XXXXXXXXXXXXX以下の行を main.pyに追記from dotenv import load_dotenvload_dotenv()engine_idの行を変更@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = 'DISCOVERY_ENGINE_ID'↓@app.post('/api/retriever')def retriever_service(question: Question):    search_query = question.query    project_id    location: str = "global"    engine_id: str = os.environ['DISCOVERY_ENGINE_ID']動作確認QUESTION='{"query":"情報セキュリティにおいて気をつけるべきことを教えてください"}'curl -X POST -H "Content-Type: application/json" -d "$QUESTION" -s http://localhost:8000/api/llm | jq .参考）ソースコード差分retriever_serviceで得た検索結果をcontextに by shu-kob · Pull Request #4 · shu-kob/rag-app-handson · GitHubフロントエンドの実装フォルダ整理これまでバックエンドを追加してきたのと同じリポジトリでフロントエンドも管理いたします。そのためにこれまで追加してきたファイルをバックエンド用のフォルダに移動させます。mkdir backend# 下記以外にも必要なファイル、フォルダはbackendに移動してください。# - __pycache__とfastapi-envは削除してください。# - .gitがある場合は移動も削除もしないでください。mv *.md *.py *.txt .env backendアプリ作成アプリの雛形を作成し、起動を確認します。npx --yes create-react-router@latest --install --no-git-init frontendcd frontendnpm run devブラウザでhttp://localhost:5173/を開いてReact Routerの画面が表示されればOKです。画面を変更してみる見た目を定義しているコンポーネントはfrontend/app/welcome/welcome.tsxです。Welcomeコンポーネントを以下のように変更します。export function Welcome() {  return (    <main className="flex items-center justify-center pt-16 pb-4">      <div className="flex-1 flex flex-col items-center gap-16 min-h-0">        <div>          <div>            <label htmlFor="message">メッセージ</label>          </div>          <div>            <textarea              id="message"              rows={4}              cols={50}              style={{                padding: "0.5rem",                border: "1px solid #ccc",                outline: "none",                boxShadow: "none",              }}            />          </div>          <div>            <button              type="button"              style={{                border: "1px solid #ccc",                padding: "0.5rem 1rem",              }}            >              送信            </button>          </div>        </div>      </div>    </main>  );}画面に入力欄とボタンが表示されればOKです。入力をコントロールする上記で入力欄に文字を入力することはできますが、その値はブラウザ側で管理されており、Reactアプリ側では取得できません。そこでstateを用いてアプリ側で入力を制御します。import { useState } from "react";export function Welcome() {  const [input, setInput] = useState("");  const onSend = () => {    console.log(input)  }  return (    <main className="flex items-center justify-center pt-16 pb-4">      <div className="flex-1 flex flex-col items-center gap-16 min-h-0">        <div>          <div>            <label htmlFor="message">メッセージ</label>          </div>          <div>            <textarea              id="message"              rows={4}              cols={50}              style={{                padding: "0.5rem",                border: "1px solid #ccc",                outline: "none",                boxShadow: "none",              }}              value={input}              onChange={(e) => setInput(e.target.value)}            />          </div>          <div>            <button              type="button"              style={{                border: "1px solid #ccc",                padding: "0.5rem 1rem",              }}              onClick={onSend}            >              送信            </button>          </div>        </div>      </div>    </main>  );}テキストを入力して送信ボタンをクリックするとログにテキストの内容が表示されるようになります。ログの確認はブラウザの開発者ツールで行います。バックエンドとの接続フロントエンドはバックエンドと異なるオリジンで動かしているため、CORSエラーにならないようバックエンドを修正します。backend/main.pyに以下を追加してください。# CORSミドルウェアの設定from fastapi.middleware.cors import CORSMiddlewareapp.add_middleware(    CORSMiddleware,    allow_origins=["*"],  # すべてのオリジンを許可    allow_credentials=True,    allow_methods=["*"],  # すべてのメソッドを許可    allow_headers=["*"],  # すべてのヘッダーを許可    expose_headers=["*"]  # すべてのヘッダーを公開)変更後、バックエンドを起動します。python -m venv fastapi-envsource fastapi-env/bin/activateWindowsのコマンドプロンプトの場合fastapi-env/Scripts/activateuvicorn main:app --reload送信ボタンが押された際に入力されたテキストをバックエンドに送信し、生成AIの回答を取得できるようにします。レスポンスの確認はブラウザの開発者ツールで行います。  const onSend = () => {    fetch("http://localhost:8000/api/llm", {      method: "POST",      headers: {        "Content-Type": "application/json",      },      body: JSON.stringify({ query: input }),    })  }演習バックエンドのResponseを画面に表示させましょう例バックエンドからのresponseをフロントエンドに表示 by shu-kob · Pull Request #6 · shu-kob/rag-app-handson · GitHub]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Vertex AI Agent Engine のカスタムテンプレートでセッション機能付きチャットボットを作る]]></title>
            <link>https://zenn.dev/kimitsu/articles/agent-angine-custom-agent</link>
            <guid>https://zenn.dev/kimitsu/articles/agent-angine-custom-agent</guid>
            <pubDate>Mon, 26 May 2025 07:02:31 GMT</pubDate>
            <content:encoded><![CDATA[Vertex AI Agent Engine は AI エージェントを構築・デプロイするための Google Cloud のマネージドサービスです。[1]以下のフレームワークに対してはテンプレートが用意されており、簡単にデプロイすることができます。Agent Development KitLangChainLangGraphAG2LlamaIndexまた上記に挙げられていないフレームワークについても、カスタムテンプレートを作成することでデプロイすることができます。今回はカスタムテンプレートを用いて、セッション機能付きの AI チャットボットを実装してみます。なお本記...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[TerragruntでTerraformをいい感じに管理する]]></title>
            <link>https://zenn.dev/kojake_300/articles/9b008349fa8310</link>
            <guid>https://zenn.dev/kojake_300/articles/9b008349fa8310</guid>
            <pubDate>Sun, 25 May 2025 14:05:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに皆さんはTerraformをどのような管理していますか？最近では、Google Cloudがベストプラクティス[1]を公開していたり、FUTURE社が設計ガイドライン[2]を提供していたりと、Terrafromの設計・開発ガイドラインは成熟して来ているのではないでしょうか。それでも、何となくもっと良い管理の方法はないかなあ？ と思ったことはありませんか。そんなTerraform Loverに送る、Terragruntというツールを紹介します。 Terraformの課題基本的なTerraformのディレクトリ構成を以下に示します。AWSリソースを管理することを想定と...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年5月版読んでいて良かった本紹介]]></title>
            <link>https://zenn.dev/akasan/articles/b37d1767115ee0</link>
            <guid>https://zenn.dev/akasan/articles/b37d1767115ee0</guid>
            <pubDate>Sun, 25 May 2025 11:52:17 GMT</pubDate>
            <content:encoded><![CDATA[5月も終わりに近づいてきました。そこで、先月に続いて、今月読んでいた本を紹介しようと思います。4月版はこちらになりますので、ご興味があればぜひ参照してください！https://zenn.dev/akasan/articles/9b2e5528548353 クラウド系 Google Cloudではじめる実践データエンジニアリング入門こちらは先月も載せていた本ですが、改めて載せています。その理由としてですが、5月にProfessional Data Engineerを受験しまして、その勉強にとてもよく立ちました。PDEではBigQueryをはじめデータレイク・データウェアハウスの...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【思考実験】バイブコーディング(Vibe coding)と多腕バンディット問題 - 選択の最適化と報酬の探索]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/25/143646</guid>
            <pubDate>Sun, 25 May 2025 05:36:46 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIが普及して、プログラミングの世界に「バイブコーディング（Vibe Coding）」という面白い言葉が生まれています。なんとなくの感覚や「バイブ(雰囲気)」に頼りながら、AIとやり取りしてコードを作るこの方法は、従来のプログラミングとは全く違うアプローチです。www.gitpod.iolearning.oreilly.com一方で、確率論の世界には「多腕バンディット問題」という古典的な問題があります。限られた時間の中で、どの選択肢が一番良い結果をくれるか分からない状況で、どうやって最良の選択をするか—という問題です。この二つ、一見全く関係なさそうですが、よく観察してみると驚くほど似ています。私たちがAIに色々なプロンプトを試している行動は、実は多腕バンディット問題を解いているのと同じようなことをしているのです。本稿では、この意外な共通点を深く探りながら、日常的なバイブコーディングの中に隠れている、洗練された認知メカニズムの正体に迫ってみたいと思います。注：筆者は多腕バンディット問題の専門家ではないため、解釈に誤りがある可能性があります。あくまで思考実験として読んでいただければと思います。バイブコーディングという新しい認知活動バイブコーディングをしている時、私たちは無意識に以下のようなことをしています：「こういう書き方でプロンプトを書いてみよう」「前回これでうまくいったから、今回も同じパターンでやってみよう」「なんか今日は調子悪いな、違うアプローチを試してみるか」「この例を見せた方が良いコードが出そうだ」興味深いのは、これらの行動が極めて自然に、まるで本能のように現れることです。特別な訓練を受けたわけでもないのに、多くの人が似たような試行錯誤のパターンを示します。www.businessinsider.com多腕バンディット問題多腕バンディット問題を簡単に説明すると：状況： カジノに複数のスロットマシンがあります。それぞれ当たりやすさが違いますが、どれが一番当たりやすいかは分かりません。目標： 限られた時間で、できるだけ多くの当たりを出したい。ジレンマ： 新しいマシンを試して情報を集める（探索）べきか、今まで当たりが多かったマシンをずっと使う（活用）べきか？この「探索と活用のトレードオフ」は、実は生物の進化から人間の日常生活まで、あらゆる場面に現れる根本的な意思決定パターンです。新しいレストランを試すか、お気に入りの店に行くか。新しい本を読むか、好きな作家の作品を読み返すか。私たちは常にこのジレンマと向き合っています。バンディット問題の理論とアルゴリズム (機械学習プロフェッショナルシリーズ)作者:本多淳也,中村篤祥講談社Amazonバイブコーディングをほぼスロットマシンなので...バイブコーディングを多腕バンディット問題として見たとき、その対応関係は驚くほど明確です。「スロットマシン」= プロンプトのパターン「詳しく説明してからコードを書いて」「具体例を示してから実装して」「ステップバイステップで教えて」「エラーハンドリングも含めて書いて」「当たり」= 期待する品質のコードが生成される「探索と活用のジレンマ」= 新しいプロンプト戦略を試すか、慣れ親しんだ方法を使うかしかも、この対応関係は表面的なものではありません。行動パターンの時間的変化、学習曲線、意思決定の心理的メカニズムまで、驚くほど一致しているのです。学習段階の自然な進化初心者期：無制限探索の混沌プログラミングを始めたばかりの人がAIを使う時は、まさに「片っ端から試してみる」状態です。成功率は低いものの、各プロンプトパターンがどれくらい有効かを肌感覚で学習しています。これは多腕バンディット問題における「純粋探索フェーズ」に相当します。中級者期：偏った活用の安定ある程度経験を積むと、「この書き方はいつもうまくいく」という黄金パターンを発見し、それに依存するようになります。これは効率的ですが、より良い戦略を見逃すリスクもはらんでいます。多腕バンディット問題で言う「早期収束の罠」です。上級者期：動的バランスの芸術経験豊富な人は、状況に応じて探索と活用のバランスを直感的に調整します。新しいモデルが出れば探索モードに戻り、安定したタスクでは効率的なパターンを活用します。これは最も洗練された多腕バンディット戦略と言えるでしょう。この自然な進化過程は、特別な理論を学ばなくても、人間が本能的に最適化アルゴリズムを身につけることを示しています。コンテキストによる戦略の分化興味深いことに、プログラミング言語やAIモデルが変わると、最適なプロンプト戦略も変化します。Pythonでうまくいくアプローチが、C++では効果的でない。GPT-4で成功した方法が、Claude では通用しない。これは多腕バンディット問題における「コンテキスト付きバンディット」の典型例です。同じ「腕」（プロンプトパターン）でも、文脈によって期待報酬が変わるのです。熟練したエンジニアは、この文脈の切り替えを無意識に行います。言語を変えると同時に、プロンプト戦略も自動的に調整される。これは、人間の適応的学習能力の驚くべき柔軟性を物語っています。「報酬」の多次元性と測定の難しさバイブコーディングにおける「報酬」は、多腕バンディット問題の古典的な設定よりもはるかに複雑です。即座に測定できる報酬コンパイルが通る期待した動作をする実行時間が短い長期的な報酬コードの可読性保守のしやすさチーム開発での再利用性主観的な報酬「美しい」コード学習になるコード創意工夫のあるコードこの多次元的な報酬構造が、バイブコーディングを単純な最適化問題以上の、芸術的な活動にしているのかもしれません。自動テストが変革する「報酬関数」ここで自動テストの存在が、バイブコーディングの性質を根本的に変えることに注目したいと思います。テストがない状況では、報酬の測定は主観的で曖昧です。「なんとなく動いているから良いコード」という判断は、多腕バンディット問題で言う「ノイズの多い報酬シグナル」です。一方、自動テストがある場合、報酬は明確で客観的になります。「全テストが通る」は0か1かの明確な成功指標です。これにより、どのプロンプト戦略が本当に効果的かを正確に学習できるようになります。この変化は単なる測定精度の向上以上の意味を持ちます。報酬関数の明確化により、学習アルゴリズムそのものが高度化するのです。syu-m-5151.hatenablog.comプロンプトエンジニアリングという「期待値制御」プロンプトエンジニアリングを多腕バンディット問題の視点で見ると、これは「各腕の期待報酬を高める技術」と解釈できます。曖昧なプロンプト「ログイン機能を作って」は、期待報酬の分散が大きい「腕」です。うまくいく時もあれば、全く期待外れの結果になることもある。一方、詳細で構造化されたプロンプトは、期待報酬の平均値を高め、分散を小さくします。これは多腕バンディット問題において、明らかに優位な「腕」です。興味深いのは、多くの人がプロンプトエンジニアリングの重要性を、理論を知らずとも実感していることです。これは、人間が直感的に「期待値と分散の最適化」を理解していることを示唆しています。チーム協働における「集合知のバンディット」個人でのバイブコーディングから、チームでの協働に視点を移すと、さらに興味深い現象が見えてきます。複数のエンジニアが異なる「腕」を並行して探索し、成果を共有する。これは「協調型バンディット」と呼ばれる高度な問題設定です。全員が同じ試行錯誤を繰り返す無駄を避け、チーム全体として効率的に最適解に近づいていきます。「このプロンプトパターンが効果的だった」「このアプローチは避けた方がいい」こうした情報共有は、個人の学習速度を遥かに超える集合的な最適化を可能にします。人間が本能的に行う知識共有行動が、実は数学的に最適な協調戦略だったのです。AIモデル進化への適応：非定常環境での生存戦略AIモデルの頻繁なアップデートは、バイブコーディングに非定常性という新たな次元を加えます。昨日まで最適だった戦略が、新しいモデルでは全く効果がない。これは生物の進化圧にも似た、動的な環境変化です。この変化に対して、経験豊富なエンジニアは見事な適応を見せます。新しいモデルが出ると、自動的に「探索モード」に切り替わる。過去の成功体験にとらわれず、新たな最適解を求めて試行錯誤を始める。この柔軟性は、多腕バンディット問題の理論が想定する以上の高度な適応能力です。環境の変化を察知し、学習戦略そのものを動的に調整する—これは人間の認知能力の真骨頂と言えるでしょう。「バイブ」の正体：統計的直感の結晶「バイブ」や「勘」と呼ばれる現象の正体を、多腕バンディット問題の枠組みで考えてみると、驚くべき洞察が得られます。経験豊富なエンジニアが「なんとなくこのアプローチが良さそう」と感じる時、それは過去の膨大な試行錯誤から蓄積された統計的パターンの内在化です。意識的には覚えていない微細な成功・失敗の記憶が、直感的判断として表面化している。これは、Thompson Samplingという高度なアルゴリズムと本質的に同じメカニズムです。過去の経験から各戦略の成功確率分布を学習し、その分布に基づいて確率的に選択を行う。完全に論理的でもなく、完全にランダムでもない、絶妙なバランスの意思決定です。「バイブ」は非科学的なものどころか、むしろ最先端の確率的アルゴリズムを人間が自然に実装している証拠なのです。中毒性の数学的説明バイブコーディングに多くの人が「ハマる」理由も、多腕バンディット問題の枠組みで説明できます。新しいプロンプトを試すたびに得られる「うまくいくかもしれない」という期待感。実際に良いコードが生成された時の達成感。これらは、不確実性の中で最適解を探索する過程で得られる本能的な報酬です。人間の脳は、探索と活用のバランスを取る活動に対して、進化的に報酬を与えるよう設計されています。バイブコーディングがこの古い報酬系を刺激するからこそ、多くの人が夢中になるのでしょう。なぜこの類似性が存在するのかここで根本的な問いに向き合ってみましょう。なぜバイブコーディングと多腕バンディット問題は、これほどまでに似ているのでしょうか？一つの仮説は、人間の学習と意思決定の根底にある共通のメカニズムです。不確実な環境で最適な選択を見つけるという課題は、人類が何十万年もの間直面してきた生存問題でした。どの狩場が豊富な獲物をもたらすか。どの植物が安全で栄養価が高いか。多腕バンディット問題は、この根本的な生存戦略を数学的に抽象化したものです。そして、バイブコーディングは、この古い学習メカニズムが新しい技術的環境で発現したものなのかもしれません。イプシロン-グリーディ戦略としての日常多くのエンジニアが無意識に実践している行動パターンを詳しく観察すると、「イプシロン-グリーディ戦略」との類似性が見えてきます：大部分の時間（90%）: 今まで最も成功率の高かった方法を使う（活用）少しの時間（10%）: 新しい方法を試してみる（探索）「いつものパターンでやってみよう。あ、でもたまには違うアプローチも試してみるか」この何気ない意思決定が、実は数学的に洗練された最適化戦略だというのは、驚くべき発見です。UCB的思考の高次元化より洗練された判断をする人は、UCB（Upper Confidence Bound）アルゴリズムに似た思考を示します：「このプロンプトは過去に良い結果を出したけど、まだ試行回数が少ないから、もう少し試してみる価値がある」これは、平均的な成功率だけでなく、「不確実性」も考慮した意思決定です。試行回数が少ない選択肢に対して「まだ可能性がある」という判断を下す。この高次な推論を、多くの人が自然に行っているのです。認知バイアスとしての「過度な活用」一方で、バイブコーディングには多腕バンディット問題と同様の落とし穴もあります。早期収束の罠: 最初に見つけた成功パターンに固執し、より良い方法を探索しなくなる。確証バイアス: 自分のお気に入りの方法がうまくいった事例ばかりを記憶し、失敗例を忘れてしまう。環境変化への適応遅れ: 新しいAIモデルが出ても、古い戦略に固執し続ける。これらの認知バイアスは、多腕バンディット問題における「準最適解への収束」と本質的に同じ現象です。人間の学習メカニズムの限界が、両方の文脈で同様に現れているのです。思考実験から見えてくることこの思考実験から得られる洞察を、整理してみましょう。第一に、私たちが日常的に行っている「試行錯誤」は思っているより合理的だということです。「なんとなく」でプロンプトを選んでいるように見えて、実は過去の経験から学習した効率的な戦略を使っているのです。第二に、自動テストやプロンプトエンジニアリングが効果的な理由が、多腕バンディット問題の観点から説明できることです。これは単なる「ベストプラクティス」ではなく、学習効率を上げる合理的な手法だったのです。第三に、チームでのAI活用が個人より効果的な理由も明確になります。みんなで情報共有することで、効率的に最適解を見つけられる。これは感覚的に分かっていたことですが、理論的な裏付けがあったということです。エンジニアとしての実感実際にバイブコーディングをしている身として、この類似性には「なるほど、そういうことか」という納得感があります。新しいプロジェクトを始める時の「色々試してみる」段階、ある程度慣れてきて「いつものパターン」を使うようになる段階、そして新しいAIモデルが出ると再び「探索モード」に戻る段階。この流れは、多くのエンジニアが体験していることでしょう。特に興味深いのは、「なんか今日は調子悪いな」と感じて戦略を変える時の判断です。これも、実は環境の変化を察知した合理的な適応行動だった可能性があります。おわりにこの思考実験の面白さは、日頃「感覚的」だと思っていた行動に、実は理論的な構造があったという発見にあります。「バイブ」と呼んでいた直感は、決してランダムな当て推量ではありませんでした。それは、過去の大量の試行錯誤から学習した、効率的な意思決定メカニズムのように思えます。私たちがAIに向かって何気なくプロンプトを打っている時、実は無意識のうちに確率的な最適化を行っている。理論を知らなくても、効果的な学習戦略を実践している。この発見は、バイブコーディングをただの「なんとなくのコーディング」から、理論に裏打ちされた合理的なアプローチとして捉え直すきっかけを与えてくれます。最終的に、この思考実験が示しているのは、私たちエンジニアが思っているより賢く、効率的に学習し、適応しているということです。それは決して特別なことではなく、人間が持つ自然な学習能力の現れなのかもしれません。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache jcloudsとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/c4783b7b825847</link>
            <guid>https://zenn.dev/akasan/articles/c4783b7b825847</guid>
            <pubDate>Sat, 24 May 2025 10:30:19 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache jclouds。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache jcloudsとは？公式サイトによると、Java向けのマルチクラウドツールキットクラウド特有の機能を完全に利用しつつ、クラウドを横断した...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud の生成 AI オブザーバビリティ機能まとめ]]></title>
            <link>https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y</link>
            <guid>https://zenn.dev/kimitsu/articles/google-cloud-gen-ai-o11y</guid>
            <pubDate>Sat, 24 May 2025 09:01:25 GMT</pubDate>
            <content:encoded><![CDATA[生成 AI アプリケーションにおけるオブザーバビリティの必要性ここ数年の生成 AI 技術の発展に伴い、RAG や AI エージェントなど生成 AI のアプリケーションへの応用が進んでいます。一方で生成 AI アプリケーションを本番利用していくにあたっては以下のような課題があります。確率的な挙動モデルの出力生成にかかる時間トークンに対する課金額外部サービス呼び出し（RAG であれば検索サービス、AI エージェントであればツール）実行経路（ワークフロー型エージェントの場合）モデルの更新、プロンプトの更新これらの課題に対し、生成 AI アプリケーションにおいて...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cursorの@Symbolsについて調べてみた]]></title>
            <link>https://zenn.dev/akasan/articles/6e1770944b3a1e</link>
            <guid>https://zenn.dev/akasan/articles/6e1770944b3a1e</guid>
            <pubDate>Fri, 23 May 2025 13:55:25 GMT</pubDate>
            <content:encoded><![CDATA[今回はCursorの機能である@Symbolsについて、公式ドキュメントの内容をまとめてみます。 @Symbolsとは？Cursorにはチャットを利用したコーディングアシスト機能がありますが、その機能についてどのようにコードやファイル、ドキュメントなどのコンテキストを参照するかということを制御するために@Symbolsというものがあります。https://docs.cursor.com/context/@-symbols/overviewCmd + Kなどで表示できるチャットボックスでは、一般的には例えば〜の計算をするための関数を実装してのような指示を投げたりするかと思いますが...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Pythonを利用してPub/Subトピックを扱ってみた]]></title>
            <link>https://zenn.dev/akasan/articles/471883f3a9495f</link>
            <guid>https://zenn.dev/akasan/articles/471883f3a9495f</guid>
            <pubDate>Thu, 22 May 2025 12:00:04 GMT</pubDate>
            <content:encoded><![CDATA[今回はPythonを利用して、Google CloudのPub/Subを利用してみました。認定資格の勉強中にももちろん出てきますし、以前実施したGCSとDataflowの連携においてもPub/Subを利用しました。Pub/SubはGoogle Cloudのサービスの中でも特に重要な要素の一つだと思いますが、直接利用したことがなかったので、PythonのSDKを利用して実際に使ってみました。https://zenn.dev/akasan/articles/e17a1867408c53 実際に使ってみる今回は、公式のこちらのドキュメントに従ってチュートリアルをしてみようと思います！...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Portalsとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/344ee65cfc92fb</link>
            <guid>https://zenn.dev/akasan/articles/344ee65cfc92fb</guid>
            <pubDate>Wed, 21 May 2025 12:09:04 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Portalsとは何かについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Portalsとは？公式サイトを見ると、Apache Portalsとは以下のようなもののようです。ロバスト...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[これから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/05/21/122752</guid>
            <pubDate>Wed, 21 May 2025 03:27:52 GMT</pubDate>
            <content:encoded><![CDATA[この記事で得られる3つのポイント「つぶしが効く」エンジニアになる: 表面的な技術習得ではなく、根本原理の深い理解と問題解決能力が長期的な市場価値を創出するAI時代の新たな役割: テクノロジーと人間の強みを組み合わせ、AIとの効果的な協働を設計・実現できる「アーキテクト」としての視点計画的偶発性の活用: 不確実性を受け入れ、専門性と横断性のバランス、継続的学習、そして「偶然を必然に変える」姿勢の重要性はじめにみなさん、こんにちは！本日はアカリクの就職ラウンジイベント＠会津大学に来ていただき、ありがとうございます。「AI時代に市場価値を高めるキャリア戦略」というテーマでお話しさせていただきます。口頭で補足しながらいろいろやっていきます。よろしくお願いします。acaric.jp現役エンジニアとして日々AIの進化と自身のキャリアパスに向き合う中で、私が得た気づきや思考を皆さんと共有できればと思います。なお、本発表では何冊かの書籍を紹介していますが、必ずしも読む必要もないです。興味があればでよいです。購入する必要も余計にありません。図書館での閲覧や貸出サービスを活用していただければと思います。疑問があればこの場でもDMでも聞いていただければと思います。完全に別件で20代のキャリア形成を振り返ったブログ記事も紹介しますので、同じ道を歩む方々の参考になれば幸いです。syu-m-5151.hatenablog.com会津大学の皆さんは、日本有数のコンピュータサイエンス教育を受けている最中ですね。私がコンピュータサイエンスを学んでいた頃と比べると、周りの環境は一変しています。ほんの10数年前、私が学生だったころには「AIがコードを書く」というのはまだSFの世界の話でした。「そんな日が来るのかな〜」なんて友達と冗談半分で話していたのに、気づけばそれが当たり前になっている。2020年の「アップロード ～デジタルなあの世へようこそ」（死後デジタル世界へアップロードされた主人公を描くSFコメディ）には、AIによるコード支援の形でペアプロのような描写がありましたが、今や私たちの現実はそれを遥かに超えています。ja.wikipedia.org2025年の今、生成AIはもはや「選択肢」ではなく「前提」です。私の職場でも、多くのエンジニアがCline、Cursor、RooといったAIコーディングアシスタントを日常的に活用しています。「人間がコードを書く」という、これまでエンジニアの核心的業務だと思われていた部分が急速に変化しつつあります。zenn.devこの変化に直面して、皆さんはこんな疑問を持っているかもしれませんね：「プログラミング言語やアルゴリズムを学ぶ意味は、これからどこにあるんだろう？」「AIがコードを書く時代に、エンジニアとして私は何をすればいいんだろう？」実は、私も同じような疑問を感じながら日々仕事をしています。でも、この変化は単なる脅威ではなく、新たな可能性も開いてくれると思うんです。AIの登場によって、私たちエンジニアの役割も進化していくのかもしれません。www.oreilly.com今日の講演では、プログラミングの基礎知識の重要性はもちろん、それに加えて「文脈に応じた適切な問いの立て方」や「AIとの効果的な協働方法」など、これからのエンジニアに求められるスキルについて考えていきたいと思います。本日は、実際の現場での経験や試行錯誤から学んだことをもとに、具体的で実践的なお話ができればと思っています。皆さんはAIと共に成長する世代のエンジニアです。これは確かに挑戦ですが、同時に新しい可能性にも満ちています。それでは、まずは将来価値のあるエンジニア像から考えていきましょう。この記事で得られる3つのポイントはじめに1. 「つぶしが効く」エンジニアになるために深い理解の価値なぜ専門家ほどAIを使いこなせるのか理解の範囲がツール活用の上限を決める原理原則は腐らない知識になるAI時代における深い理解の実践的意味実践のためのアドバイス2. 技術を点ではなくて線で見極める目を養う技術の進化と本質的価値長期的に価値を持つスキルの見極め方実践のためのアドバイス3. 技術革新と不平等の歴史から学ぶ歴史に見る技術革命と不平等AI革命の文脈で考えるエンジニアの責任と可能性4. そして、エンジニアになるユーザーに寄り添うエンジニアになる技術に寄り添うエンジニアになる自分に寄り添うエンジニアになる量をこなすことの本質的価値ちゃんと、エンジニアになる5. 計画的偶発性理論とAI時代のキャリア戦略計画的偶発性理論とは計画的偶発性を生み出す5つの行動特性1. 好奇心（Curiosity）2. 持続性（Persistence）3. 楽観性（Optimism）4. 柔軟性（Flexibility）5. 冒険心（Risk Taking）計画的偶発性理論に基づくキャリアの基礎構築専門性と横断性のバランス実践的な問題解決経験人間同士のコミュニケーション能力明日からの具体的なアクションAIツールの実験と比較日記を通じた言語化能力の向上コミュニティへの参加と知識の還元不確実性を受け入れ、偶然を活かす姿勢おわりにこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はてなブログに投稿しましたこれから伸びるエンジニア職とは？  - AI時代に市場価値を高めるキャリア戦略 @エンジニア業界セミナー in 会津大学 - じゃあ、おうちで学べる  https://t.co/cUS6z4nBmt#はてなブログ— nwiizo (@nwiizo) 2025年5月21日   1. 「つぶしが効く」エンジニアになるために皆さん、エンジニアとして長く活躍するために最も重要なことは何でしょうか？それは「つぶしが効く」エンジニアになることです。つまり、どんな環境でも、どんな技術変化が起きても適応できる基盤を持つことが重要です。「つぶしが効く」エンジニアになるには、標準化された技術スタックの習得だけでは不十分です。 技術の深層に潜り、なぜそう設計されているのかを理解し、他社や他プロジェクトでも応用できる原理原則を掴むことが重要です。表面的な技術習得より、深い洞察を積み重ねることこそが差別化につながります。エンジニアとしての私自身の経験から言えることですが、本当にキャリアの長期的な安定性をもたらすのは、特定のプログラミング言語やフレームワークの知識ではなく、「なぜそのように設計されているのか」という根本的な理解です。例えば、10年前にモバイルアプリ開発で流行していたフレームワークの多くは今や使われていませんが、その基盤となるアーキテクチャパターンや並行処理の原則は今でも変わらず価値を持っています。もし、Webのバックエンドエンジニアとして就職がしたいと思っているなら「データ指向アプリケーションデザイン ―信頼性、拡張性、保守性の高い分散システム設計の原理」などを読むとよいのではないでしょうか？ちょうど、来年ぐらいに第2版もリリースされることですし、learning.oreilly.com若いうちからやっておいた方がよく、失ってから「なぜ誰も教えてくれなかったのか」と後悔することが多い健康管理。これはAI時代においても最も必要なものの一つです。そして見落とされがちですが、「つぶしが効く」エンジニアキャリアの持続可能性において身体的・精神的健康の維持は極めて重要です。 デスクワークが中心のエンジニアは運動不足になりがちで、長時間のコーディングや深夜の障害対応などで睡眠リズムが乱れやすい職業です。健康管理は本当に大切なことです。理想的には、週に3回程度の有酸素運動と軽い筋トレを習慣化することをお勧めします。特にデスクワークによる姿勢の悪化を防ぐために、背中や体幹の筋肉を鍛えることは効果的です。また、1時間に一度は立ち上がって5分程度ストレッチするだけでも違います。最近では多くのエンジニアが導入している昇降式デスクも検討する価値があるでしょう。精神面では、定期的な休息とメンタルリフレッシュの時間確保が重要です。技術の進化が早いIT業界では常に学び続ける必要がありますが、それだけに燃え尽き症候群のリスクも高いです。趣味や運動など、コーディング以外の活動に意識的に時間を割くことで、長期的には創造性や問題解決能力も向上します。運動脳作者:アンデシュ・ハンセンAmazon深い理解の価値なぜ専門家ほどAIを使いこなせるのか現在のLLMはプログラミング教師としてはもはや人間より性能が上だと言えるでしょう。膨大なコードベースから学習したLLMは、何千もの言語やフレームワークについての知識を持ち、無限の忍耐力で初心者の質問に答えることができます。そして次の世代のLLMは今の世代よりさらに優秀になることが予想されます。このような状況で、多くの人が「AIがコードを書いてくれるなら、私たちエンジニアは何をすればいいの？」と疑問に思います。しかし、興味深い現象が起きています。AIツールを最も効果的に使いこなしているのは、すでにその分野に深い知識を持つエンジニアたちなのです。これは「生成AIが何でもやってくれる」という主張と矛盾しているように思えますが、実は理にかなっています。深い理解を持つエンジニアは、AIの提案を適切に評価し、改善点を見つけ、より良い解決策へと導くことができるからです。センスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon理解の範囲がツール活用の上限を決めるここで重要な原則があります。「自分の認知を超えるものは活用できない」ということです。例えば、プログラミングの基本概念を理解していない人がAIに「効率的なアルゴリズムを書いて」と頼んでも、生成されたコードが本当に効率的かどうかを判断できません。データベース設計の原則を知らない人が「スケーラブルなデータモデルを設計して」と指示しても、結果の質を評価する基準がないのです。現場の視点から言えば、AIが生成したコードを無批判に受け入れた結果、既にいくつかの重大なパフォーマンス問題やセキュリティホールを生み出してしまう例を何度も目にしてきました。反対に、基礎をしっかり理解しているエンジニアは、AIの提案を適切に評価し、時には「ここはこうした方がいい」と修正を加えることができます。ファンタジア(吹替版)ミッキーマウスAmazon原理原則は腐らない知識になるなぜAIの時代にも深い理解が重要なのでしょうか。その答えは、コードの「良い」「悪い」を決めるのは、AIでも人間の主観でもなく、そのコードが負う責任だからです。責任の評価: その責任の重さと範囲を正確に評価できるのは、システムの基盤となる原理を深く理解している人だけです影響範囲の見極め: AIが提案する解決策の影響範囲と限界を見極め、より適切な方向性を示せるのは、システム設計の原則と実世界での影響を理解している人だけです統合と責任: AIが生成した出力を実際の問題解決に統合し、その結果に責任を持てるのは、全体的なアーキテクチャを理解しているエンジニアだけですプログラミング言語やツールは変わっても、基本的な原則や設計パターンは何十年も変わりません。アルゴリズム、データ構造、分散システム、データベース設計などの基礎的な知識は、AIの時代になってもその価値が色あせることはありません。むしろ、AIが成熟するほど、ソフトウェアの量は爆発的に増えます。その基盤となる原理原則を理解している人の価値は高まるのです。syu-m-5151.hatenablog.comAI時代における深い理解の実践的意味結局のところ、AIをパートナーとして活用し、その出力を批判的に評価し、改良できる能力こそが、これからのエンジニアに求められる真の価値なのです。これは次のような実践を意味します：AIとの対話における質問力: 適切な問いを立て、AIから価値ある回答を引き出す能力出力の評価眼: AIが生成したコードやアイデアの品質を見極める判断力改善と統合: AIの提案を実際のプロジェクトに適用し、必要に応じて改善する技術力責任ある実装: 最終的な成果物に対して技術的責任を負える専門性AIが発展すればするほど、私たち自身も成長し続ける必要があります。AIと効果的に協働するための使い方は、自分自身の学びと経験に基づいて考え、発展させていくものなのです。これからのエンジニアは、AIを単なる「便利なツール」として使うのではなく、深い理解に基づいた「創造的なパートナーシップ」を築いていく必要があるでしょう。そのパートナーシップの質を決めるのは、結局のところ、私たち人間が持つ基礎的理解の深さなのです。 speakerdeck.com実践のためのアドバイスでは、大学生の皆さんが「つぶしが効く」エンジニアになるために、具体的に何をすべきでしょうか？基礎を徹底的に学ぶ：授業で教わるアルゴリズムとデータ構造を丸暗記ではなく、本質的に理解する講義だけでなく、自分で実装してみることで理解を深めるコンピュータサイエンスの基礎科目を軽視せず、しっかり身につけるOSの仕組みやメモリ管理などのローレベルな動作原理も抽象化に頼らず理解する「なぜ」を常に問う：新しい技術やツールに出会ったとき、「なぜこれが存在するのか」を考える課題やレポートに取り組む際、「これはなぜこの方法で解くのか」を自問自答するAIがコードを生成したときも、「なぜこのような実装になるのか」を考察する「どうやって」の前に「なぜ」を問うことで、表面的な理解を超える多様な経験を積む：授業の課題だけでなく、サークル活動やハッカソンなど異なる環境での開発を経験するチームプロジェクトに積極的に参加し、異なる役割を経験してみるコンテストや学外の活動にも挑戦して視野を広げる可能であれば異なる規模のプロジェクト（小規模な個人プロジェクトから大規模なチーム開発まで）を経験するいいやつになる：技術力だけでなく、チームの中で信頼される人間性を育む知識やスキルを惜しみなく共有し、他者の成長を支援する批判するだけでなく建設的なフィードバックを心がける自分の間違いを素直に認め、修正できる謙虚さを持つ技術的な決断において倫理的な側面も考慮できる視点を養う一時的な効率より長期的な関係構築を重視する姿勢を持つ「つぶしが効く」エンジニアは、特定の技術やツールに依存しません。彼らは根本的な問題解決能力と適応力を持ち、どんな状況でも価値を生み出せるのです。皆さんも大学時代から、そのような柔軟性と深い理解を育てていきましょう。『コンサル一年目が学ぶこと ― 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選』は、論理的思考・プレゼン・タイムマネジメントなど30の汎用スキルを「話す技術／思考術／デスクワーク術／ビジネスマインド」の４カテゴリに整理し、AIでは置き換えにくい問題解決プロセスを基礎から鍛えてくれる。コンサル一年目が学ぶこと 新人・就活生からベテラン社員まで一生役立つ究極のベーシックスキル30選作者:大石哲之ディスカヴァー・トゥエンティワンAmazon『コンサルティング会社 完全サバイバルマニュアル』は、アナリストからマネージャーまでに潜む罠と突破口を３部構成で描き、クライアント合意形成やチーム動員術など"人間関係の摩擦"を乗り越える実践策を開示し、苛烈な業界で残業せず成果を出すための暗黙知を授ける。コンサルティング会社　完全サバイバルマニュアル (文春e-book)作者:メン獄文藝春秋Amazon『シン・ロジカルシンキング』は、問い（Q）→仮説（A）→示唆（D）→結論（I）のQADIサイクルで〈発見〉と〈論証〉を往復し、生成AI時代にこそ差別化源となる"問う力"と独創的洞察の生み出し方を提示する。基礎体力を底上げする一冊、苛烈な現場を生き抜く一冊、思考をアップデートする一冊——この３冊を通読すれば、ビジネスパーソンはAIが代替できない知的生産プロセスを多角的に武装できる。シン・ロジカルシンキング作者:望月安迪ディスカヴァー・トゥエンティワンAmazon生成AIの時代には、単にコードを書く技術だけでは「AIに任せた方が早いもしくは安い(易い)」と思われてしまう危険性があります。これは新卒のみなさんだけではなく中堅やベテランエンジニアも同様にです。AI時代を生き抜くには、技術スキルだけでなく、問題の本質を見抜く力、ビジネス感覚、そして人間関係の機微を読む力を意識的に磨くことが不可欠で、これらのスキルを身につけることで、技術力と人間力を兼ね備えた「AIより人間に任せたい」「〇〇といっしょに働きたい」と思われるエンジニアになれるのです。www.slideshare.netバカと無知―人間、この不都合な生きもの―（新潮新書） 言ってはいけない作者:橘玲新潮社Amazon2. 技術を点ではなくて線で見極める目を養うAIやテクノロジーの進化が加速する中、多くの学生や若手エンジニアはこの変化について行こうと焦っています。「最新技術を習得しないと就職で不利になるのでは？」「他の人に遅れを取るのでは？」という不安も理解できます。しかし、最先端の技術を追いかけることだけに集中すると、むしろ長期的な成長を妨げる可能性があります。皆さんには、「技術を点ではなくて線で見極める目」を養ってほしいと思います。syu-m-5151.hatenablog.com技術の進化と本質的価値技術の進化に振り回されず、本質を見極めることがエンジニアの価値です。 最新技術への焦りは不要で、顧客価値を軸に選択すべきです。「流行りの技術を使っていない」ことへの不安より、「なぜその技術が必要か」を問い続けることが、長期的に価値あるエンジニアになる道筋です。ハラリが「NEXUS 情報の人類史」で指摘しているように、人類の進化はつねに「情報ネットワーク」と密接に関わってきました。そして今、私たちは人類史上初めて「人間ならざる知能」の時代に突入しています。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon技術者として重要なのは、この歴史的文脈の中で自分たちの立ち位置を理解することです。私たちは単なる「コード生産者」ではなく、情報の流れ方そのものを設計する重要な役割を担っています。特にAIモデルが日々進化する中で、「どのような情報をどのように処理し、どのような形で人間に提示するか」という選択は、社会に大きな影響を与えます。「新しい技術に追いつかなければ」という焦りはエンジニアなら誰しも感じるものです。しかし、重要なのは技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。長期的に価値を持つスキルの見極め方技術の世界は常に変化していますが、すべての変化が同じ重要性を持つわけではありません。「新しい技術に追いつかなければ」という焦りに駆られる前に、次の3つの質問を自分に問いかけてみてください：この技術は一時的なトレンドか、根本的な変化か？このフレームワークの流行り廃りは一時的なトレンドか？バージョン管理システムの普及は根本的な変化か？クラウドインフラの普及やコンテナ技術の標準化は根本的な変化の原因は？この技術は問題解決の新しい方法を提供しているのか？単に既存の解決策を少し改良したものかまったく新しいアプローチを可能にするものか解決できる問題の範囲を根本的に拡大するものかこの技術の基礎となる原理は何か？表面的な実装詳細を超えて、根底にある考え方は何かその原理は他の文脈でも適用可能かその原理が解決している根本的な問題は何かこれらの質問に答えることで、目の前の技術が「追いかける価値があるもの」なのか、それとも「様子を見るべきもの」なのかを判断する力が養われます。重要なのは、技術そのものではなく、その技術が解決する問題の本質を理解することです。なぜこの技術が必要なのか、これによってどのような価値が生まれるのか、そして他の方法では解決できないのか。これらの問いに答えられるエンジニアは、単なる「技術の使い手」を超えた存在になります。また、個人ですべての技術動向を追うのは現実的ではありません。信頼できる技術ブログや専門家の意見、実際に手を動かしている現場のエンジニアの知見を参考にしながら、情報収集の効率化を図ることも重要です。そこで、今のXは少々使いづらいのでControl Panel for Twitterなどのプラグインを利用すると良いユーザー体験が生まれるのでオススメです。システム設計の現場では、「賢い」デザインと「単純」なデザインの選択に直面することがよくあります。経験から言えることですが、長期的に価値を持つのは後者です。いくら「賢く」見える技術ソリューションでも、あまりに複雑で他者が理解しにくいものは、長期的にはメンテナンスコストが高くなり、チームの足かせになります。「単純さ」を追求することこそ、実は高度な技術力の現れなのです。 speakerdeck.com実践のためのアドバイスでは大学生の皆さんは、どうすれば技術の本質を見極める目を養えるのでしょうか？「なぜ」を5回問う：新しい技術に出会ったら、連続して「なぜ」を問いかけましょう。例えば：なぜDockerが人気なのか？ → 環境の一貫性を提供するからなぜ環境の一貫性が重要か？ → 開発と本番環境の差異を最小化するためなぜ環境差異の最小化が必要か？ → デプロイの信頼性向上のためなぜデプロイの信頼性が重要か？ → 継続的なサービス提供のためなぜ継続的なサービス提供が求められるか？ → デジタルサービスの常時稼働が期待されるからこの連鎖的な問いかけで、技術の表層から社会的・経済的な本質へと掘り下げられます。古典的で嫌う人もいますが一定の価値はあると思います。技術の歴史を学ぶ：デカルトは「困難を分割せよ」と言い、ビル・ゲイツは「問題を切り分けろ」と言った。この思想はコンピュータサイエンスの基盤ですが、実は問題の分解法こそが難所です。歴史的変遷を学ぶことで、なぜ現在の解法が選ばれたのか、試行錯誤のプロセスも含めて理解でき、「創造の追体験」という知的興奮を得られます。プログラミング言語の進化やプロトコル設計の歴史を知ることで、表層的な知識を超えた洞察が得られるでしょう。知的多様性と創造的衝突を求める：技術の価値は多様な視点がぶつかる場で鮮明になります。同じ技術でも、バックエンド、フロントエンド、デザイン、マネジメントの観点で評価が異なります。計算機科学だけでなく、心理学や経営学など異分野からの視点が予想外の気づきをもたらすことも。研究室やサークルでの議論から始め、カンファレンスやオンラインコミュニティへと視野を広げ、「異質な他者」との対話を通じて技術の多面性を理解しましょう。コードを「読む」文化を身につける：優れたミュージシャンが名曲を聴き込むように、良いエンジニアは質の高いコードを読み込みます。GitHubの時代は「巨人の肩」への前例のないアクセスを提供しています。LinuxカーネルやPostgreSQLなど様々な成熟度のプロジェクトから生きた知恵を吸収しましょう。コミットメッセージや設計ドキュメントを読むことで、技術選択の背景にある思考プロセスも理解できます。「読む」という行為は「書く」能力を飛躍的に高める最も効率的な投資です。技術の本質を見極める目を持つことは、AI時代のエンジニアにとって最も価値ある資質です。流行りに惑わされず「なぜ」を問い続けることで、変化する環境でも揺るがない判断軸を持てるようになるでしょう。3. 技術革新と不平等の歴史から学ぶ技術の本質を見極める視点をさらに深めるために、ここで少し歴史的な視点から考えてみましょう。技術革新は本当に社会を良くするのでしょうか？その恩恵は誰に届くのでしょうか？2024年のノーベル経済学賞受賞者ダロン・アセモグルとサイモン・ジョンソンも「技術革新と不平等の1000年史」で重要な警鐘を鳴らしています。彼らの研究によれば、技術革新は自動的に社会全体の富や幸福をもたらすわけではありません。むしろ歴史は、技術革命の果実が一部の人々に集中し、不平等を拡大させてきた事例で満ちています。技術の恩恵が広く社会に行き渡るかどうかは、技術そのものではなく、その「ビジョン」と「設計された分配システム」に依存するのです。技術革新と不平等の1000年史　上作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon技術革新と不平等の1000年史　下作者:ダロン アセモグル,サイモン ジョンソン早川書房Amazon歴史に見る技術革命と不平等人類の歴史を振り返ると、多くの技術革命は必ずしも万人に恩恵をもたらしてきませんでした。農業革命は食料生産を増加させましたが、その恩恵は主に土地を所有するエリート層に集中し、多くの人々はかえって過酷な労働を強いられました。情報の視点で見れば、これは「中央集権的な情報管理」の始まりでもありました。少数の支配者が情報を独占することで、多数の人々を統制する仕組みが生まれたのです。産業革命の初期段階では、工場労働者の生活水準は実際に悪化しました。機械化による生産性向上の恩恵は工場主に集中し、労働者は危険で過酷な環境で働かされました。情報の観点では、「標準化された情報」と「階層的な情報の流れ」が特徴的でした。コンピュータ革命でさえ、デジタル格差と所得格差の拡大をもたらしました。プログラミングのスキルを持つ人々と持たない人々の間に新たな分断が生まれ、技術の発展が必ずしも平等な社会をもたらさなかったのです。ハラリは「情報が多いほど真実に近づける」という素朴な前提が実は誤りであることを指摘しています。同じ情報インフラが科学を発展させる一方で、魔女狩りのような集団ヒステリーを引き起こすこともあるのです。決定的な分かれ道となるのは、「間違いを前提に互いに補正できる仕組みがあるかどうか」なのです。カルトのことば　なぜ人は魅了され、狂信してしまうのか作者:アマンダ・モンテル,青木音白揚社AmazonAI革命の文脈で考える私たちが今経験しているAI革命も、同様の歴史的パターンを繰り返す可能性があります。AIが生み出す生産性向上の恩恵は、AIを所有・制御する企業や個人に集中するかもしれません。また、AIを効果的に活用できるスキルを持つ人々と持たない人々の間に新たな格差が生まれる可能性もあります。エンジニアとして私たちは、技術が社会に与える影響に対して無関心ではいられません。私たちが設計するシステムが、意図せず不平等を拡大したり、一部の人々を排除したりする可能性を常に意識する必要があります。大規模言語モデルは新たな知能か　ＣｈａｔＧＰＴが変えた世界 (岩波科学ライブラリー)作者:岡野原 大輔岩波書店AmazonLLMのプロンプトエンジニアリング ―GitHub Copilotを生んだ開発者が教える生成AIアプリケーション開発作者:John Berryman,Albert Ziegler,服部 佑樹（翻訳）,佐藤 直生（翻訳）オーム社Amazonエンジニアの責任と可能性歴史は決定論的ではありません。私たちには選択肢があります。エンジニアとして、技術の恩恵がより広く社会に行き渡るような設計や実装を意識的に選ぶことができます。具体的には：アクセシビリティを考慮した設計：すべての人がテクノロジーの恩恵を受けられるよう、多様なユーザーのニーズを考慮する倫理的な視点を持つ：開発するシステムが社会に与える可能性のある影響を常に考えるオープンな技術の推進：知識や技術へのアクセスを広げるオープンソースやオープン教育の取り組みに参加する多様性のある開発チーム：様々な背景や視点を持つ人々が開発に参加することで、より包括的な技術を生み出す技術史を学ぶことは、未来を形作るために不可欠です。私たちは過去の過ちを繰り返さないよう、意識的に行動することができます。AI時代のエンジニアとして、技術の社会的影響を理解し、より公正で包括的な未来に貢献する責任があるのです。デジタルの皇帝たち――プラットフォームが国家を超えるとき作者:ヴィリ・レードンヴィルタみすず書房Amazon4. そして、エンジニアになるここまで、技術的な深さと歴史的視点について話してきましたが、次に「人間的な側面」に目を向けていきましょう。AI時代において価値あるエンジニアとなるために必要な、「ユーザー」「技術」「自分自身」との3つの関係性について考えていきます。ユーザーに寄り添うエンジニアになる技術に精通することはエンジニアにとって重要ですが、それだけでは十分ではありません。価値のあるエンジニアとなるためには、自分の作るものが最終的に誰に届き、どのような影響を与えるのかを常に意識する必要があります。エラーログの向こうに人がいることを忘れるな。0.01%の障害も、誰かの人生を大きく狂わせる可能性があります。 数字だけで判断せず、実際にサービスを触り、ユーザー体験を自分の目で確かめるエンジニアこそが、信頼性の高いシステムを作れるのです。例えば私の経験からですが、あるサービスで「99.9%の可用性」というメトリクスに満足していたチームがありました。しかし、実際にユーザーとして使ってみると、残りの0.1%の障害が、ユーザーが最も重要なタイミング（プレゼンの直前や商談中など）に発生していることが分かりました。統計的には小さな数字でも、ユーザーにとっては致命的な問題になり得るのです。エンジニアの世界では、しばしば数字やメトリクスで成功を測ります。「99.9%の可用性」「平均応答時間50ms」「エラー率0.01%」といった具合です。これらの数字は確かに重要ですが、その裏側にある人間の体験を見失ってはいけません。技術的な指標だけでなく、「この機能が失敗したとき、ユーザーはどう感じるか」「彼らの人生にどんな影響を与えるか」を常に考えることが、価値のあるシステムを作る鍵となります。エンジニアとして成長するために最も効果的な方法の一つは、自分が作ったシステムを実際のユーザーとして使ってみることです。これは「ドッグフーディング」とも呼ばれますが、単なる形式的なテストではなく、ユーザーの立場に立つことを意味します。この体験を通して、技術的な視点だけでは見えてこなかった問題点や改善の機会に気づくことができるでしょう。技術に寄り添うエンジニアになるエンジニアとして価値を発揮するためには、技術そのものを深く理解し、技術の特性や進化の方向性に寄り添う姿勢も重要です。技術に寄り添うとは、単に最新技術を追いかけることではなく、各技術の本質や適切な使いどころを見極める目を持つことです。技術を目的化せず、手段として適切に選択できるエンジニアが良い価値を生み出せます。 データベースの負荷問題も、技術的な最適化、アーキテクチャの再設計、あるいはビジネス要件の見直しなど、複数の視点から最適な解決策を見つけられる柔軟性が重要です。技術に寄り添うエンジニアは、次のような特徴を持っています：技術の「なぜ」を理解している：特定の技術がなぜ生まれたのか、どのような問題を解決するために設計されたのかを理解しています。この理解があるからこそ、適切な場面で適切な技術を選択できるのです。技術の限界を認識している：どんな優れた技術にも限界があることを知っています。「この技術では解決できない問題は何か」を理解しているからこそ、過剰な期待や誤った適用を避けることができます。技術間の関係性を把握している：個々の技術を孤立して見るのではなく、技術エコシステム全体の中での位置づけを理解しています。これにより、相互運用性の問題や将来的な拡張性を考慮した設計が可能になります。技術の進化の方向性を予測できる：過去の技術進化のパターンを理解し、将来の方向性を予測する目を持っています。これにより、一時的なトレンドに振り回されず、長期的な視点で技術選択ができます。技術に寄り添うためには、幅広い知識と経験が必要です。異なる専門領域の知識を組み合わせ、多角的な視点で問題を捉える能力が重要になります：フロントエンドとバックエンドの両方の視点から考えるインフラストラクチャとアプリケーション開発の関係性を理解するセキュリティとユーザビリティのバランスを考慮するパフォーマンスと保守性のトレードオフを意識するAIの時代においては、「人間とAIの協働」という新たな視点も必要です。AIツールの特性を理解し、人間の創造性と判断力を活かしながら、AIの処理能力と効率性を組み合わせていく視点が重要になるでしょう。技術に寄り添うエンジニアになるには、一朝一夕ではなく日々の小さな習慣の積み重ねが鍵です。毎日15分の技術調査、週一回のコード見直し、月一冊の技術書など、小さくても継続的な取り組みが深い理解を育みます。ジェームズ・クリアー式 複利で伸びる1つの習慣作者:ジェームズ・クリアーパンローリング株式会社Amazon200万人の「挫折」と「成功」のデータからわかった 継続する技術作者:戸田大介ディスカヴァー・トゥエンティワンAmazonAI時代では特に、新しいツールを定期的に試し、結果を記録する習慣が重要です。理解のプロセスは螺旋状に進みます。この道のりには挫折もありますが、小さな習慣を粘り強く続けることで、技術に対して誠実なエンジニアへと成長できるのです。私たちはどう学んでいるのか　――創発から見る認知の変化 (ちくまプリマー新書)作者:鈴木宏昭筑摩書房Amazon自分に寄り添うエンジニアになる技術の急速な進化と複雑化が進む中、エンジニアとして長く活躍し続けるためには、「自分自身に寄り添う」姿勢も欠かせません。これは単に自己満足や自己中心的になることではなく、自分の学習プロセス、強み・弱み、成長の方向性を理解し、持続可能なキャリアを構築することを意味します。元オリンピック選手で「熟達論」で知られる為末大氏は、熟達を単なる技術の向上ではなく、「技能と自分」を一体として捉え、人間という総体を高めていくプロセスだと説明しています。このアプローチはAI時代のエンジニア育成においても極めて示唆に富んでいます。熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon為末氏による熟達の5段階を見ていきましょう：遊(ゆう) - 探索と実験: すべての学びは「遊び」から始まります。好奇心に導かれ、新しい言語やフレームワーク、AIツールと自由に戯れる段階です。ここでの自由な探索が長期的な学習のエネルギー源となります。型(かた) - 基本を身につける: 基本的な動きや思考パターンを繰り返し練習し、無意識にできるようになる段階です。AIがコード生成を担う時代でも、この「型」の理解なしにAIの出力を評価・改善することはできません。観(かん) - 深い理解: 対象を部分に分解し、その関係性と構造を深く理解する段階です。コードが「動く」だけでなく、「なぜそう動くのか」を考察し、見えない部分まで想像できるようになります。心(しん) - 本質の把握: 細部にとらわれず全体のバランスを保ち、本質的な部分を直感的に見抜ける段階です。AIとのコラボレーションにおいても、本質的な方向性を見失いません。空(くう) - 創造的境地: 既存の枠組みを超え、純粋に目的や価値の創造に集中できる境地です。AI時代においてこそ、この創造的な「空」の境地が人間の価値となります。重要なのは、熟達のプロセスが一直線ではなく螺旋状に進むということです。新しい技術やAIモデルに出会うたびに、再び「遊」の段階から始まり、徐々に「型」「観」「心」へと進んでいきます。この螺旋的な成長過程を理解し、受け入れることで、変化の激しいAI時代においても心理的な安定を保ちながら成長し続けることができるのです。自分に寄り添うエンジニアになるための具体的なアプローチとしては：自分の学習スタイルを理解する：人によって効果的な学習方法は異なります。読書、実践、教えること、議論など、自分にとって最も効果的な学習方法を見つけ、意識的に活用しましょう。自分のエネルギー源を知る：何に取り組むとエネルギーが湧いてくるか、逆に何をするとエネルギーを消耗するかを理解しましょう。持続可能なキャリアのためには、エネルギーを与えてくれる活動と消費する活動のバランスが重要です。適切な休息と内省の時間を確保する：常に新しい技術を追いかけ続けるのではなく、学んだことを内省し、自分のものにするための時間も大切です。定期的な休息や趣味の時間も、長期的な創造性と生産性のために不可欠です。自分の強みと弱みを正直に評価する：すべてを完璧にこなそうとするのではなく、自分の強みを活かし、弱みは補完するアプローチを考えましょう。チームやコミュニティの中で、互いの強みを活かし合う関係を構築することも重要です。量をこなすことの本質的価値ここまで「寄り添う」という質的な側面について語ってきましたが、エンジニアとして成長する上で避けて通れない真実があります。それは「質は量から生まれる」ということです。AI時代になって「もうコードを大量に書く必要はない」と考える人もいるかもしれません。しかし、これは大きな誤解です。AIを効果的に使いこなせる人は、例外なく膨大な量のコードを書いてきた人たちです。なぜなら、量をこなすことで初めて得られる「暗黙知」があるからです。為末氏の熟達論でも触れたように、成長は螺旋状に進みます。量をこなすことで質が向上し、質の向上によってより高度な量をこなせるようになるという好循環が生まれます。最初の1000時間は基礎的なコーディングスキルの習得に費やされるかもしれません。次の1000時間では、より複雑な問題解決に挑戦できるようになります。そして次の1000時間では、AIと協働しながら、以前は想像もできなかった規模のプロジェクトに取り組めるようになるでしょう。「とにかく手を動かせ」という古からのアドバイスは、AI時代においても色褪せることはありません。むしろ、AIという強力なパートナーを得た今こそ、かつてない速度で量を積むことができる絶好の機会なのです。ちゃんと、エンジニアになるこれまで述べてきた「ユーザーに寄り添う」「技術に寄り添う」「自分に寄り添う」という3つの姿勢を総合して、初めて「ちゃんとしたエンジニア」になれるのではないでしょうか。では、実際にどのようにすれば、これらの要素を日々の実践に落とし込んでいけるのでしょうか？自分の作ったものを実際に使う習慣をつける：自分が開発したシステムやアプリケーションを、定期的に実際のユーザーとして使ってみましょう。理想的には、業務外の時間や異なる環境で使うことで、新たな視点が得られます。「ユーザーに寄り添う」姿勢を具体化する第一歩です。異なる専門性を持つ人々との協働を積極的に求める：デザイナー、プロダクトマネージャー、マーケター、ビジネス部門の人々など、多様な背景を持つ人々との協働プロジェクトに参加しましょう。これにより、多角的な視点で問題を捉える力が養われ、「技術に寄り添う」視野の広さが育まれます。AIとの「遊び」の時間を確保する：AIツールを業務だけでなく、創造的な探索のために使う時間を意識的に確保しましょう。例えば、週に1時間だけ「AIとの実験タイム」を設け、新しい使い方や可能性を探求するのも良いでしょう。為末氏の言う「遊」の段階を大切にすることで、AIとの共創の可能性が広がります。振り返りとフィードバックを習慣化する：プロジェクトやタスクの終了後に、「何がうまくいったか」「何が改善できるか」「どんな学びがあったか」を振り返る時間を持ちましょう。また、同僚や顧客からのフィードバックを積極的に求め、それを次の成長につなげましょう。これは「自分に寄り添う」ための重要な習慣です。「技術以外の本」を読む習慣をつける：技術書だけでなく、デザイン、心理学、ビジネス、哲学など様々な分野の本を読むことで、多角的な思考が育まれます。これらの知識は、技術的な問題に対しても新たな視点をもたらすことがあります。「ちゃんとしたエンジニア」とは、単に技術が優れているだけでなく、その技術を通じて人々の生活や仕事をより良くする価値を生み出せる人です。そのためには、技術的なスキルだけでなく、ユーザーへの共感力、技術の本質を見極める洞察力、そして自分自身の成長プロセスを理解する内省力が必要です。AI時代のエンジニアとして、これらの要素をバランスよく発展させることで、単なる「コードを書く人」を超えた、価値あるエンジニアへと成長することができるでしょう。技術の進化がどれほど加速しても、最終的に価値を生み出すのは人間です。その原点を忘れずに、日々の実践を積み重ねていきましょう。エンジニアとしての総合的な成長を目指す方には、技術的スキルだけでなく人生全体のマネジメントや自己投資の方法を網羅的に解説した『ソフトスキル：ソフトウェア開発者の人生マニュアル』と、プログラミングの技術的側面に加えてプロフェッショナルとしての心構えや実践的知恵を提供する古典的名著『達人プログラマー：熟達に向けたあなたの旅』の2冊をぜひお読みいただきたいと思います。前者は「自分に寄り添う」姿勢を育み長期的なキャリア構築の指針となり、後者は「技術に寄り添う」ための具体的なプラクティスが豊富で、両書を通じてAI時代においても普遍的な価値を持つエンジニアリングの本質と、バランスの取れた成長への道筋を学ぶことができるでしょう。SOFT SKILLS ソフトウェア開発者の人生マニュアル 第2版作者:ジョン・ソンメズ日経BPAmazon達人プログラマー ―熟達に向けたあなたの旅― 第2版作者:David Thomas,Andrew Huntオーム社Amazon5. 計画的偶発性理論とAI時代のキャリア戦略ここまで「つぶしが効くエンジニア」「技術の本質を見極める目」「エンジニアとしての在り方」について話してきました。では、AIの急速な進化という大きな変化の中で、皆さんは具体的にどのようなキャリア戦略を持ち、どのような選択をすればよいのでしょうか？「AIに代替されない職業を選ぶべきか」「これから伸びる分野はどこか」という問いに明確な答えを出すことは困難です。その代わりに、不確実性の高い時代におけるキャリア構築の考え方として、「計画的偶発性理論」（Planned Happenstance Theory）をご紹介します。この理論を理解した上で、大学時代の選択と明日からの具体的なアクションについて考えていきましょう。計画的偶発性理論とは計画的偶発性理論は、スタンフォード大学の心理学者ジョン・D・クランボルツ教授が1999年に提唱したキャリア発達理論です。この理論によれば、個人のキャリアの約8割は、本人が予想していなかった偶然の出来事によって方向づけられるとされています。クランボルツ教授は、成功したビジネスパーソンのキャリアを調査した結果、多くの人のターニングポイントが「計画されたもの」ではなく「偶然の出来事」だったことを発見しました。しかし重要なのは、その「偶然」をただ待つのではなく、偶然を活かすための準備と行動が必要だということです。この理論がAI時代において特に重要なのは、テクノロジーの進化があまりに速く、将来どのような職種が残るか、どのようなスキルが求められるかを正確に予測することがほぼ不可能だからです。例えば、数年前には「AIプロンプトエンジニア」という職業は存在していませんでした。現在から見たら過去のトレードオフが分からないので、分かったような顔して「これが正解だった」と言う人はあとから来ていろいろ語りますが、だいたい運で勝っている人も多いです。技術の歴史を振り返ると、「明らかに正しい選択だった」と思えることでも、当時は複数の選択肢の中からの賭けだったことが少なくありません。計画的偶発性を生み出す5つの行動特性クランボルツ教授によれば、計画的偶発性を生み出すには5つの重要な行動特性があるとされています：1. 好奇心（Curiosity）好奇心とは、新しい知識や経験に対して積極的に探求する姿勢です。AIツールやモデルに対する好奇心は、その可能性と限界を見極める上で重要です。「これは何ができるのだろう？」と試してみる姿勢が、未知の可能性を開拓します。学生のうちからできること：講義で紹介された技術を授業以外でも試してみる新しいAIツールが登場したら、すぐに実験してみる「こんなことはできないだろう」と決めつけず、実際に試してみる姿勢を持つ2. 持続性（Persistence）持続性は、困難や障害に直面しても諦めず、目標に向かって努力し続ける能力です。AIツールは万能ではなく、期待通りの結果が得られないことも多々あります。そんなとき、一度や二度の失敗で諦めず、異なるアプローチを試みる持続力が重要です。学生のうちからできること：課題で壁にぶつかったとき、別のアプローチを試みる習慣をつけるAIとの協働でうまくいかない場合も、プロンプトや方法を変えて複数回試す失敗した試みも記録に残し、何が学べたかを振り返る3. 楽観性（Optimism）楽観性は、将来に対する前向きな見方と、成功の可能性を信じる姿勢です。技術変革期には、「AIに仕事を奪われる」といった不安や悲観的な見方が広がりがちです。しかし、歴史が示すように、新技術は常に新たな職種や専門性を生み出してきました。AIを脅威ではなく、可能性を拡張するパートナーとして前向きに捉えることが重要です。学生のうちからできること：技術の変化を「危機」ではなく「機会」として捉える視点を養う失敗やミスを「学びの機会」として前向きに受け止める習慣をつける週に一度、自分の小さな成功や進歩を書き出してみる未来について友人と前向きな対話をする時間を定期的に持つ4. 柔軟性（Flexibility）柔軟性は、変化する状況や予期せぬ出来事に適応する能力です。AI技術は日々進化し、その可能性と制約も常に変化しています。特定のツールや方法論に固執せず、状況に応じて最適なアプローチを柔軟に選択する能力が重要になります。学生のうちからできること：複数のプログラミング言語やフレームワークに触れる「これが唯一の正解」という思考を避け、複数の解法を探る習慣をつける計画変更を余儀なくされたとき、それを学びの機会と捉える姿勢を持つ異なる文化や背景を持つ人々との交流を通じて多様な視点を学ぶコンフォートゾーンを意識的に離れる小さな挑戦を定期的に行う5. 冒険心（Risk Taking）冒険心とは、不確実性や失敗の可能性があっても、新しいことに挑戦する勇気です。AI技術の最前線は常に変化しており、確立された「正解」が存在しないことも多いです。誰も試したことのない方法やアプローチに挑戦する冒険心が、イノベーションを生み出します。学生のうちからできること：ハッカソンやコンテストなど、短期間で新しいことに挑戦する機会に参加する未知の技術領域のプロジェクトにあえて挑戦してみる「失敗しても構わない」と考えられる安全な環境で、リスクを取る経験を積む自分のアイデアを公の場で発表する機会を積極的に求める「ちょっと無理かも」と思うようなプロジェクトや役割に手を挙げてみる計画的偶発性理論に基づくキャリアの基礎構築キャリアとは何でしょうか？「キャリア」の語源はラテン語の「carrus（車輪の付いた乗り物）」に由来し、後にイタリア語（carriera）、フランス語（carriere）となり、レールコース（通り道）を意味するようになりました。つまり、キャリアとは車輪の通った跡（轍・わだち）を意味しています。語源としてはそうですが実際もそうでこれは前もって計画できるものではなく、進んだ後に振り返って初めて見えるものなのです。誰かが「成功したキャリア」を語るとき、それは無数の選択肢と偶然の中から結果的に選び取った一本の道を後付けで説明しているにすぎません。特に現代のように技術革新と不確実性が加速する時代では、10年後、20年後の働き方を正確に予測することはほぼ不可能です。「偶然を必然に変えるのは、あなた自身の行動と姿勢なのです」計画的偶発性理論が教えてくれるのは、予測不能な未来に対して完璧な計画を立てるのではなく、偶然の出会いや機会を活かせるよう準備し、自分だけの独自の轍を刻んでいく姿勢の重要性です。就活生が見る労働の世界はいろんな人達が作った虚構の上に成り立っているので仕事選びや仕事で馬鹿を見ないために読んでおくのありかと思います。NINE LIES ABOUT WORK 仕事に関する9つの嘘は、私たちが当然と受け入れている職場の「常識」が実は神話に過ぎないことを鋭く指摘します。「どの会社で働くかが大事」「リーダーシップというものがある」といった広く信じられている前提を覆し、実際のデータと研究に基づいて職場の真実を明らかにしています。特に就職活動中の方や、キャリアの岐路に立つエンジニアにとって、この本は組織や仕事の本質を見抜く目を養い、自分が本当に活躍できる環境を見極める力を与えてくれるでしょう。NINE LIES ABOUT WORK　仕事に関する９つの嘘作者:マーカス・バッキンガム,アシュリー・グッドールサンマーク出版Amazon専門性と横断性のバランスAI時代においても、深い専門性の価値は決して減じません。むしろ、ChatGPTのような汎用AIが「浅く広い」知識を提供できるようになるほど、特定分野における「深く狭い」専門知識の希少性は増していきます。しかし同時に、複数の領域を横断する能力も重要です。ここでのポイントは「浅く広く」ではなく「深く狭い専門性を複数持つ」というアプローチです。T型人材（1つの分野で深い専門性+広い一般知識）からπ型人材（複数の分野での深い専門性）へのシフトが、AI時代には価値を発揮します。これから10年、20年と生成AIはますます賢くなっていくでしょう。多くの領域で、AIに「優れる」ことは非常に難しくなります。しかし、「異なる」ことは常に可能です。AI時代のキャリア戦略として大切なのは、「優れる」よりも「異なる」ことを目指すアプローチです。「異なる」とは、独自の視点、独自の問い、独自の関心領域を持つことです。これは必ずしも仕事や学問の組み合わせだけではありません。あなたのユニークな趣味、特異な経験、異文化での生活体験など、あなただけの「異なる」要素がキャリアの差別化につながることもあります。将棋や囲碁が好きな人は、その戦略思考がシステム設計に活きるかもしれません。山登りが趣味の人は、「少しずつ高みを目指す」という考え方がソフトウェア開発に応用できるかもしれません。重要なのは、自分が本当に情熱を持てる「異なる」要素を見つけ、それを技術と組み合わせる方法を探ることです。AIは多くのタスクで人間を超えるかもしれませんが、あなただけの独自の視点と問いは、AIにはない価値を生み出す源泉となるでしょう。実践的な問題解決経験AIがコードを生成できる時代において、「Todoアプリを作りました」といった基本的な実装経験の差別化価値は相対的に低下します。代わりに、「具体的な問題を解決した」という経験が価値を持ちます：特定の地域や集団の課題をテクノロジーで解決するプロジェクト既存ソリューションの特定の制限や課題を克服する独自アプローチニッチな領域の特殊なニーズに対応するツールの開発採用面接で最も印象に残るのは「こういう課題があって、このアプローチを試したがうまくいかなかった。そこでこの解決策を考え、実装した結果、こうなった」と問題解決のプロセス全体を説明できる学生です。人間同士のコミュニケーション能力AI時代こそ、人間同士のコミュニケーション能力が重要になります。特に技術的な内容を非技術者に分かりやすく伝える能力は、AIと人間の橋渡しをする上で不可欠です。技術ブログの執筆、プレゼンテーションの機会の獲得、異なる背景の人々との協働などを通じて、この能力を磨きましょう。明日からの具体的なアクション計画的偶発性理論に基づくなら、重要なのは「偶然の機会に気づき、活かすための行動」です。不確実性が高まる時代だからこそ、以下のような具体的なアクションを通じて、偶然を必然に変える力を養いましょう。AIツールの実験と比較様々なAIコーディングツールを使い倒してみることから始めましょう。これは単なるお遊びではなく、AIの本質と限界を理解するための重要な実験です。GitHub Copilot、Cline、Cursor、など、様々なツールを同じタスクに適用し、それぞれの得意・不得意を体系的に記録してみましょう。これだけ変化が激しい世界で人生を賭けるのはリスクすぎる。「AI比較実験ノート」をつけることで、ただ使うだけでは得られない洞察を得ることができます。重要なのは、AIを「答えをくれる先生」ではなく「一緒に問題を解決するパートナー」として位置づけることです。プロンプトを工夫し、AIの提案を批判的に評価し、改善を求め、最終的には自分で最適化するというサイクルを通じて、効果的な協働方法を見つけていきましょう。自分で手を動かしてない人のいうことはあまり信用しなくてよいです。読んでいない本について堂々と語る方法 (ちくま学芸文庫 ハ 46-1)作者:ピエール・バイヤール筑摩書房AmazonAfter Cline - あるいは語りえぬ者について語ろうとする時代について · GitHubzenn.dev日記を通じた言語化能力の向上TikTokやYouTubeを見る時間の一部を、日記を書く時間に変えてみましょう。たった5分でも構いません。現代の娯楽は文字どおり１分１秒を奪い合うレベルにまで特化していて、長い時間をじっくりかけて楽しむ娯楽は、かれらの目まぐるしい日々の暮らしのなかでそのポジションを急激に失いつつあります。そんな中で、日記を書くことには、多くの利点があります。言語化能力の向上: 自分の考えや経験を言葉にする習慣がつくことで、コミュニケーション能力が自然と高まります。自己認識の深化: 日々の出来事や感情を振り返ることで、自分自身の思考パターンや価値観に気づくことができます。前向きな思考の促進: 特に「今日学んだこと」「今日感謝したいこと」などポジティブな視点を含めた日記は、心理的な健康にも良い影響を与えます。アイデアの整理と発見: 断片的な思考を書き出すことで、新たな関連性やアイデアに気づくことがあります。日記のテーマとしては、「今日学んだ技術のこと」「気になる技術トレンド」「解決した問題とその過程」など、技術に関連したものでも構いませんし、「今日感じた感情」「未来の自分への手紙」など、より個人的なものでも良いでしょう。重要なのは継続することです。スマートフォンのリマインダーを設定したり、就寝前の習慣にするなど、自分に合った方法で習慣化してみてください。スマホ脳（新潮新書） 『スマホ脳』シリーズ作者:アンデシュ・ハンセン新潮社Amazonコミュニティへの参加と知識の還元技術の学習や成長は、一人で行うよりもコミュニティの中で行う方が効果的です。AIツールを活用しながらプログラミングやプロジェクト開発に取り組む仲間と定期的に経験を共有する場を作りましょう。また、学ぶだけでなく、自分の知識や発見を積極的にコミュニティに還元することも重要です。AIツールの活用で得た知見をブログに投稿したり、学内勉強会で発表したりすることで、自分の理解が深まり、新たな視点を得ることができます。不確実性を受け入れ、偶然を活かす姿勢この理論は、「明確なキャリアプランを持つな」と言っているわけではありません。むしろ、計画に固執しすぎず、予期せぬ出来事に柔軟に対応できる準備をしておくことの重要性を教えてくれます。現代のように技術革新のスピードが加速し、不確実性が高まっている時代には、10年後の働き方を正確に予測することはほぼ不可能です。そんな中で「これが絶対の正解」と信じて一つの道に固執するよりも、様々な可能性に目を向け、偶然の機会を活かせるよう自分を準備しておくことが賢明でしょう。「偶然は準備された心にのみ微笑む」という言葉があるように、偶然の出会いや機会を価値あるものに変えるのは、あなた自身の行動と姿勢なのです。AI時代のキャリアにおいては、「これが正解」という単一の道筋はないでしょう。むしろ、好奇心を持って多様な可能性に目を向け、変化に柔軟に対応できる力を養うことが、長期的な市場価値を高める最も確かな戦略かもしれません。完璧を求めすぎないことも重要です。提案した活動のすべてを同時に実行する必要はありません。自分の興味や強みに基づいて、できることから始めましょう。失敗を恐れず、様々なことに挑戦し、可能性を広げることこそが、予測不可能なAI時代に対応するための最良の準備となるでしょう。結局のところ、この話の落としどころは極めて凡庸な結論に帰着します。不確実性を受け入れ、偶然を活かす姿勢といっても、最終的には「自分が選んだ選択肢を正解にするしかない」という単純な事実に行き着くのです。これは特別な知恵でもなんでもない当たり前の話かもしれません。しかし、この凡庸な事実こそが、急速に変化するAI時代において最も実践的な知恵なのかもしれません。どんなに理論を語っても、どんなに戦略を練っても、最後は自分の選んだ道を誠実に歩み、その選択に意味を見出し、自らの手で「正解」に変えていく努力以外に道はないのです。おわりにここまで様々な観点からAI時代のエンジニアキャリアについてお話ししてきましたが、最後に少し本音をお伝えしたいと思います。実は、この講演のタイトル「AI時代に市場価値を高めるキャリア戦略」を見たとき、少し困ってしまいました。このような強いタイトルのもとで講演するには、あまりにも重い責任を感じたからです。「市場価値を高める」などと言えるほど、私自身が確固たる答えを持っているわけではないですし、AIの進化は日々予測を覆しています。しかし、このタイトルが私自身への挑戦状となり、真剣に考える機会となりました。率直に申し上げて、私自身もAIの急速な進化には戸惑いを感じています。現役エンジニアとして、これまで時間をかけて身につけたスキルの一部が、あっという間にAIで代替されていく現実は、正直なところ不安を覚えます。しかし、こうした変化の波に対しては、抵抗するよりも乗る方が賢明でしょう。私たちエンジニアは、望むと望まざるとにかかわらず、この技術革新の最前線に立っています。ただ、この状況をむしろポジティブな視点で捉えることも可能です。今日お話した計画的偶発性理論は、私自身のキャリアを振り返った時に非常に納得感があります。実際、私のキャリアも「計画通り」には進まず、予想外の出会いや偶然の機会が、振り返ってみれば重要なターニングポイントになっていました。例えば、趣味で始めたオープンソース活動が、思いがけず重要な仕事の機会につながったり、一見無関係に思えた副業プロジェクトでの経験が、後の大型プロジェクトで決定的な価値を持ったりしました。このような「計画できない幸運」は、実はキャリア形成の重要な要素ではないかと考えています。最近の経験から、AIツールを積極的に活用することで興味深い発見がありました。当初は「自分の仕事が奪われる」という懸念を抱いていましたが、実際には単調な作業から解放され、より創造的な領域に集中できるようになったのです。コーディングの基礎的な部分や定型的なタスクをAIに委託することで、システム設計や問題の本質的な解決により多くの時間と思考を割けるようになりました。これは決して悪い変化ではないと感じています。今、大学生の皆さんは、AIと共に成長する先駆的な世代です。困難も多いでしょうが、それだけ新しい可能性に満ちた時代でもあります。皆さんが構築するエンジニアとしてのキャリアは、私たち世代のものとは大きく異なるかもしれませんが、それはより創造的で多様な可能性を秘めていると確信しています。皆さんのキャリアが、AIとの創造的な協働を通じて、より充実したものになることを心から願っています。本日はありがとうございました。最後になりますが、今お話したような「AIと共に成長するエンジニア」を私たちの会社でも募集しています。本日の内容に共感いただけた方は、ぜひよろしくお願いします。jobs-3-shake.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[vim-jp ラジオ #41聞いた - モバイルDevOpsエンニジアのgiginetさん登場！]]></title>
            <link>https://blog.atusy.net/2025/05/21/vim-jp-radio-giginet/</link>
            <guid>https://blog.atusy.net/2025/05/21/vim-jp-radio-giginet/</guid>
            <pubDate>Wed, 21 May 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[最近ちっともvim-jp ラジオをきけてなかった。特段理由らしい理由はないのだけれど、強いていうならYAMORIのビートボックスがよすぎてYoutubeあさったり、TENDREのライブに行ったり、耳は音楽を聴くのに忙しかったのかも。]]></content:encoded>
        </item>
    </channel>
</rss>