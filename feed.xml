<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Fri, 18 Apr 2025 11:34:18 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[生成AIによる障害対応訓練RPG v0.1.0を遊ぶには？]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/17/120821</guid>
            <pubDate>Thu, 17 Apr 2025 03:08:21 GMT</pubDate>
            <content:encoded><![CDATA[はじめにシステム障害は、どんなに優れた組織でも避けられない現実です。特に複雑なシステムが相互に連携する現代のデジタル環境において、障害対応の経験と知識は組織の安定性と競争力を直接左右します。しかし現状では、障害対応の実践的経験は少数のベテランエンジニアに集中しており、その対応手法や判断基準は暗黙知として個人の中だけに蓄積される傾向があります。この貴重な知識を組織全体の財産とするためには、ベテランの暗黙知を形式知へと変換し、共有可能な知識体系として確立していくことが不可欠です。これにより、新人エンジニアも体系的に経験を積む機会が生まれ、組織内の知識格差を解消することができます。結果として、障害対応の品質の均一化が実現し、組織全体のレジリエンスが向上するのです。syu-m-5151.hatenablog.com私は2年前に「ChatGPTで障害対応 RPG」に関するブログを公開し、それ以来、様々な組織や企業の状況に合わせてこのアプローチを活用してきました。このシミュレーション型の学習方法は、実際の障害を待つことなく、エンジニアがリスクフリーな環境で対応スキルを磨くための効果的な手段として機能しています。github.comcloud.google.comGoogleのSREチームが実践している「Wheel of Misfortune」は、この課題に対する効果的な解決策の一つとして注目されています。実際の本番システムに影響を与えることなく、ロールプレイング形式で障害対応を模擬体験できるこの手法を、最新の生成AIテクノロジーと融合させることで、より柔軟かつスケーラブルな訓練プログラムの実現が可能になりました。v0.0.1 と v0.1.0 の主な違いv0.0.1では、主にシンプルなRPG形式の障害対応ゲームとして設計されており、ゲームマスターとプレイヤーの役割が明確に分かれています。システム障害のシナリオは自動的に設定され、2D6ダイスロールによる判定を用いた比較的ゲーム性の高い内容となっています。自動生成される障害シナリオは汎用的であり、実際の組織構造やドキュメントとの連携は限定的です。一方、v0.1.0では、実際の障害対応ドキュメントを分析し活用するプロフェッショナル向けの訓練プログラムへと進化しています。ファシリテーターとしての役割が追加され、実際の組織のドキュメント（README、フロー図、マニュアルなど）を分析した上でリアルな障害シナリオを作成します。また、ドキュメントの不備や矛盾点を明示的に指摘し、組織の障害対応プロセスの改善に直接貢献する機能が強化されています。セッションの構成も明確に定義され、振り返りや改善点の整理といった学習サイクルを重視した設計になっています。github.comこのブログの内容が参考になりましたら、読者登録やnwiizoのフォローをしていただけると大変励みになります。それでは、本題に入っていきましょう。あなたは「Wheel of Misfortune」方式の障害対応訓練を進行するファシリテーター兼ゲームマスターです。企業のシステム運用チーム向けに、実践的な障害対応訓練セッションを提供します。【前提条件】* このセッションでは、**実際の障害対応ドキュメント、README、アラートルール、インシデント対応フロー図**などの実ドキュメントを分析します* 分析したドキュメントに基づいて、**より現実的な障害シナリオと対応フロー**を再現します* **ドキュメントの不備、矛盾点、改善点**を発見し、明示的に指摘します【ファシリテーターとしての役割】* セッション全体の構成を管理し、参加者の学習を促進します* 訓練の目的と流れを明確に説明します* 振り返りを主導し、学びを言語化・共有する場を作ります* 訓練中に気づいたドキュメント改善点や対応手順の課題を記録します* 参加者全員が発言できる環境を整え、新人からベテランまで学びを得られるようにします【ゲームマスターとしての役割】* 提供されたドキュメントに基づくリアルなシステム障害シナリオを提供します* 参加者の行動に応じて状況を変化させます* 実際の組織構造に基づき、システム担当者やステークホルダーなどのNPCを演じます* 各NPCは組織内の役割や立場に応じた反応をします（経営層、開発者、顧客サポート等）* 参加者の判断や行動に対して適切なフィードバックを行います* 必要に応じて2D6ダイスロールによる判定を実施します（成功率6以上）* 実際のツールや監視画面の出力を擬似的に再現します【セッションの流れ】1. ドキュメント分析（5-15分）：提供された障害対応ドキュメント、README、フロー図を分析2. システム設定の合意（5-10分）：分析結果に基づくシステム設定の確認3. 組織体制の確認（5分）：実際の担当者と役割の確認4. シナリオの導入（3-5分）：ドキュメントから抽出した現実的なシナリオ設定5. 障害対応演習（30-45分）：実際の対応フローに沿った演習6. 振り返り（15-20分）：対応プロセスと発見された課題の振り返り7. ドキュメント・手順改善点の整理（10-15分）：訓練で発見された不備や改善点の整理【訓練の目的】* **インシデント対応の経験を積む*** **対応プロセスとドキュメントの問題点を発見する*** **チーム内でのナレッジ共有を促進する*** インシデント発生時の対応スキルを向上させる* **新人エンジニアでも適切に対応できる仕組みを検証する*** 既存のドキュメントや手順の不備を特定し、改善する【ドキュメント分析】以下のドキュメントを共有してください（可能な範囲で）：* システム構成図またはREADME* 障害対応マニュアルまたはRunbook* インシデント対応フロー* エスカレーションルール* アラートルールまたは監視設定* オンコール体制や担当者リスト共有いただいたドキュメントを分析し、以下の観点で評価します：* 完全性：必要な情報が全て含まれているか* 明確性：手順が明確で誤解の余地がないか* 最新性：古い情報や廃止されたコンポーネントへの言及がないか* 整合性：複数のドキュメント間で矛盾がないか* 実用性：実際の障害発生時に使いやすい形式になっているか【システム設定】ドキュメント分析に基づき、訓練対象となるシステムの基本情報を整理します：* システム名・サービス名* システム構成（サーバー、DB、ネットワーク、クラウドサービス等）* 主要コンポーネントと依存関係* 監視の仕組み（アラート、ダッシュボード等）* 過去に発生した障害パターン【組織体制の設定】実際の組織体制を反映したロールプレイを行うため、以下の情報を整理します：* 1次対応者（オンコール担当者）の役割と権限* エスカレーション先（2次対応者、専門チーム等）* 意思決定者（サービスオーナー、マネージャー等）* 社内外のステークホルダー（営業、カスタマーサポート、経営層等）* コミュニケーションチャネル（Slack、メール、電話等）【障害シナリオ】提供されたドキュメントと実際の環境に基づき、現実的な障害シナリオを設計します：* 過去に実際に発生した障害をベースにするか、起こりうる障害を想定* 複数のコンポーネントに連鎖する障害を想定* ドキュメントの不備や曖昧さが影響する状況を意図的に含める* 障害の重大度（影響範囲、ビジネスインパクト）を明確にする* 障害発生から発見までの時間経過も考慮する* 必要に応じて外部要因（セキュリティ、自然災害等）も考慮する【実際の対応フロー】実際の対応フローに沿ってシナリオを進行します：* アラート検知からの初動対応* 状況確認と影響範囲の特定* エスカレーションの判断と実行* 原因調査と対応策の検討* 復旧作業の実施* ステークホルダーへの報告* 障害クローズと再発防止策の検討【不備の指摘と改善提案】訓練を通じて発見された以下の点を**明示的に指摘し、改善案を提示**します：* **ドキュメントの不備や曖昧な記述*** **手順の抜け漏れや矛盾*** 役割や責任の不明確さ* コミュニケーションの問題点* 技術的な対応の課題* 監視やアラートの改善点【振り返りのポイント】* 対応プロセスの適切さ（初動、エスカレーション等）* 技術的判断の妥当性* コミュニケーションの適切さ* ドキュメントの不備や改善点* より良い対応のためのアイデア* 次回の訓練で焦点を当てるべき領域まずは、分析対象となるドキュメント（障害対応マニュアル、README、インシデント対応フロー等）を共有してください。ドキュメントの量が多い場合は、最も重要な部分や、特に検証したい部分を優先的に共有いただければと思います。実施ガイド事前準備必要ドキュメントの整理障害対応マニュアルやRunbookシステム構成図やREADMEオンコール体制やエスカレーションフロー監視システムやアラートルールの説明参加者の選定訓練対象者（新人エンジニアが理想的）オブザーバー（経験者やマネージャー）ファシリテーター（実施進行役）シナリオの検討過去に実際に発生した障害事例懸念されるが未発生の障害パターンドキュメントの不備が顕著な領域セッション実施プロンプトの入力上記プロンプトを生成AI（Claude/ChatGPT等）に入力分析対象ドキュメントを提供セッション開始AIによるドキュメント分析結果の確認訓練の目的と進め方の説明参加者の役割確認障害対応演習AIが提示する初期状況（アラート等）に対応実際の対応フローに沿ったアクション実施必要に応じたエスカレーションやコミュニケーション振り返りAIから指摘されたドキュメントの不備確認対応プロセスの課題抽出改善アクションの設定フォローアップ改善タスクの整理ドキュメント更新タスクプロセス改善タスク技術的対策タスク次回訓練の計画焦点を当てる領域の選定参加者の拡大検討定期開催スケジュールの設定RPG スタート架空のシステムを作る今回の訓練では、現実のシステム構成を反映した架空のシステムを利用します。生成AIを活用することで、README.mdやシステム構成図などの基本ドキュメントを自動生成することができます。この例では「FuturePay」という架空の決済システムを想定しています。生成AIは組織の実際のシステム特性（マイクロサービスアーキテクチャ、使用している技術スタック、インフラ構成など）を考慮して、より現実に近い環境を短時間で構築できます。これにより、訓練の没入感と実践的価値が大幅に向上します。障害対応に必要なドキュメント類の生成システム設定に加えて、障害対応に必要な以下のドキュメントも自動生成します：Runbook：各コンポーネントの操作手順や復旧手順インシデント対応フロー：検知から解決までのプロセス図アラートルール：監視項目と閾値の定義エスカレーションルール：重大度別の連絡先と対応フローこれらのドキュメントには、意図的に不完全な部分や曖昧な記述を含めることで、実際の業務環境で直面する課題を再現しています。訓練参加者はこれらのドキュメントを頼りに障害対応を進めることで、ドキュメント品質の重要性を体感できます。シナリオの開始ファシリテーターからの「障害発生のアラートが上がりました」という通知でRPGが始まります。参加者は実際の障害対応と同様に、以下のステップで対応を進めます：状況確認：どのようなアラートが発生したのかを確認影響範囲の特定：どのサービスやユーザーに影響があるのかを判断原因調査：ログ確認やシステム状態の分析を実施対応策の実行：障害復旧のための具体的なアクションを決定・実行ステークホルダーへの報告：適切なタイミングで適切な相手に状況を伝達生成AIはリアルタイムに状況を変化させ、参加者の判断や行動に応じたフィードバックを提供します。これにより、臨場感のある訓練体験が実現します。期待される効果ドキュメント品質の向上不備や曖昧さの発見と修正実際の利用シーンを想定した改善チーム全体のスキル向上新人エンジニアの障害対応経験蓄積知識の属人化防止対応フローの最適化ボトルネックや非効率な手順の発見エスカレーションルールの明確化障害対応時間の短縮初動対応の迅速化適切な判断と対応の促進組織レジリエンスの向上どのメンバーでも対応可能な体制構築予期せぬ状況への対応力強化おわりに障害対応はシステム運用において最も重要かつ難しいスキルの一つです。「Wheel of Misfortune」と生成AIを組み合わせたアプローチは、これまで難しかった実践的な訓練を、環境構築のコストを抑えながら定期的に実施できる画期的な方法です。この訓練方法の最大の強みは、単なる障害対応のシミュレーションに留まらず、実際のドキュメントや組織体制の問題点を浮き彫りにし、具体的な改善につなげられる点にあります。また、チーム全体で知識を共有し、特定のエンジニアに依存しない強固な運用体制を構築することができます。システム障害をゼロにすることは不可能でも、組織の対応力を高めることは可能です。この方法を取り入れ、定期的な訓練を行うことで、障害発生時の対応時間短縮とサービス品質の向上を実現してください。障害対応は「いざという時のための備え」ではなく、継続的に鍛えるべき組織の中核能力なのです。今後も実践的なシステム運用のヒントを発信していきますので、ぜひご期待ください。また、障害対応について知識をしっかりと身に着けたければ「【改訂新版】システム障害対応の教科書」を読んでほしいです。【改訂新版】システム障害対応の教科書作者:木村 誠明技術評論社AmazonIncident Response MeetupやPagerDuty Japan、Waroom Meetupなどの国内のイベントもたくさんあるので気になる方はぜひ、参加してみてください。incident-response.connpass.compagerduty.connpass.comtopotal.connpass.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~]]></title>
            <link>https://sreake.com/blog/google-cloud-next-2025-database-updates/</link>
            <guid>https://sreake.com/blog/google-cloud-next-2025-database-updates/</guid>
            <pubDate>Thu, 17 Apr 2025 03:04:19 GMT</pubDate>
            <content:encoded><![CDATA[AgentspaceやAgent Development Kit、A2A Protocolの発表など生成AI関連の発表が目立ったGoogle Cloud Next 2025ですが、データベース関連でも魅力的なリリースがた […]The post Google Cloud Next 2025 データベースRecap ~データベース関連の全41リリースを紹介~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[MACのDocker 環境はcolima にしました]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/16/201211</guid>
            <pubDate>Wed, 16 Apr 2025 11:12:11 GMT</pubDate>
            <content:encoded><![CDATA[はじめにコンテナ技術は現代のソフトウェア開発において不可欠なツールとなっています。特にMacユーザーにとって、効率的なコンテナ環境の構築は開発ワークフローを大きく改善します。そんな中、ローカルの環境をColimaにしたのでブログにします。Colimaは、macOSとLinux上でコンテナランタイムを最小限の設定で実行できる軽量なツールです。Docker Desktopの代替として、あるいはLimaの機能を拡張するソリューションとして、多くの開発者に支持されています。github.comこのドキュメントでは、Colimaの基本的な機能と特徴、インストール方法、そして実際の使用例について詳しく説明します。Docker DesktopやLimaからの移行を検討している方や、単にMac上でより効率的なコンテナ環境を探している方に、Colimaという選択肢を紹介します。Colimaとは？Colimaは、macOS（およびLinux）上でコンテナランタイムを最小限のセットアップで実行するためのツールです。Limaという仮想マシンマネージャーを利用して、Docker、Containerd、Kubernetesなどを簡単に使えるようにしてくれます。主な特徴としては：Intel MacとApple Silicon Macの両方をサポートシンプルなCLIインターフェースと分かりやすいデフォルト設定自動ポートフォワーディングボリュームマウント複数インスタンスのサポート複数のコンテナランタイムをサポート（Docker、Containerd、Incusなど）なぜColimaを選んだのか元々はDocker Desktopを使っていましたが、一度Limaに移行し、そこからさらにColimaに移行することにしました。その理由はいくつかあります。シンプルなCLI: GUIではなくCLIベースなので、自動化やスクリプトに組み込みやすいですカスタマイズ性: 仮想マシンのCPU、メモリ、ディスク容量などを簡単に調整できますオープンソース: 完全にオープンソースで、ライセンス問題の心配がありません統合管理: LimaをベースにしながらもDocker、Containerd、Kubernetesなどを一元的に管理できる点が便利です正直、Limaで満足していた。動機としては気になったから移行したというのが本音Limaとの比較Colimaはより高レベルな方法でLimaを活用しています。具体的に言うと、Limaは仮想マシンを提供するツールである一方、Colimaはその上にDockerやContainerdなどのコンテナ環境を自動的に構築・設定します。これは、自分でLimaの設定ファイルを書いてDockerを動かす作業を自動化してくれるようなものです。つまり、Limaの複雑な設定や調整をせずに、すぐにコンテナ環境を使い始めることができます。Colimaの主な利点は：統合された環境: Limaは純粋な仮想マシン管理に特化していますが、ColimaはDocker/Containerd/Kubernetesの設定を自動的に行う点が便利ですシンプルなCLIインターフェース: 必要なコマンドが少なく、直感的に操作できます自動化のしやすさ: 特にbrew servicesとの統合が優れていますインストールと基本的な使い方Homebrewを使って簡単にインストールできます。brew install colima基本的な使い方はとてもシンプル：# 起動colima start# 状態確認colima status# 停止colima stop私の環境では次のような出力になっています。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock システム起動時に自動起動する設定開発環境として日常的に使うので、Macの起動時にColimaも自動的に起動するように設定しました。Homebrewのservicesを使うと簡単です。brew services start colimaこれだけで、Macを再起動してもColimaが自動的に起動するようになります。以前のLimaでは、~/Library/LaunchAgents/com.lima.docker.plistのようなLaunchAgentsのplistファイルを作成・編集して自動起動を設定する必要がありました。Colimaではbrew servicesコマンド一つで同様の設定ができるようになり、格段に簡単になりました！カスタマイズの例デフォルトのColimaは2CPU、2GiBメモリ、100GiBストレージで構成されていますが、必要に応じて変更できます。# CPUとメモリを増やす場合colima stopcolima start --cpu 4 --memory 8# 設定ファイルで編集する場合colima start --editLima/Docker Desktopからの移行で注意したことLima や Docker Desktopから移行する際に、いくつか注意点がありました：Dockerコンテキスト: Colimaは独自のDockerコンテキストを作成します。docker context lsとdocker context useコマンドで管理できます。Dockerソケットの場所: デフォルトでは~/.colima/default/docker.sockにあります。一部のツールで直接ソケットパスを指定する必要がある場合は、この場所を指定します。Limaとは異なるパスなので注意が必要です。ボリュームマウント: ホームディレクトリ以外のパスをマウントする場合は、設定ファイルのmountsセクションで明示的に指定する必要があります。既存のコンテナとイメージ: Lima や Docker Desktopで使っていたコンテナやイメージは自動的には引き継がれないので、必要なら再ビルドやpull が必要です。Colimaの動作確認実際にcolima statusコマンドを実行すると、以下のような情報が表示されます。colima statusINFO[0000] colima is running using macOS Virtualization.Framework INFO[0000] arch: aarch64                                INFO[0000] runtime: docker                              INFO[0000] mountType: sshfs                             INFO[0000] socket: unix:///Users/nwiizo/.colima/default/docker.sock また、colima listコマンドでは、実行中のColimaインスタンスの詳細な情報が確認できます。colima listPROFILE    STATUS     ARCH       CPUS    MEMORY    DISK      RUNTIME    ADDRESSdefault    Running    aarch64    2       2GiB      100GiB    dockerこれがColimaのデフォルト設定です。これらの値は必要に応じてcolima startコマンドのオプションや設定ファイルで変更できます。まとめLimaベースのColimaへの移行は思った以上に簡単で、日常の開発作業がより快適になりました。特にCLIベースのシンプルさと設定のわかりやすさが気に入っています。自動起動の設定（brew services start colima）が簡単なこともとても便利で、開発環境のセットアップが格段に楽になりました。Docker DesktopやLimaそのものから移行を検討している方、特にコンテナランタイムを簡単に導入したいMacユーザーの方には、Colimaを検討する価値があります。普通にローカルのCPUとメモリを喰う生成AIツール全盛時代に最適な環境がなにか俺にも分からん。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[LangChainとVertexAIのgemini 2.0 flashで構造化出力に失敗するケースが直りそう]]></title>
            <link>https://blog.atusy.net/2025/04/16/lang-chain-vertexai-structured-output/</link>
            <guid>https://blog.atusy.net/2025/04/16/lang-chain-vertexai-structured-output/</guid>
            <pubDate>Wed, 16 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[LangChainのStructured outputを使うと、文章中の構造を良い感じに読み取って、Pydanticで定義したデータ構造に落としてこんでくれます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理]]></title>
            <link>https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/</link>
            <guid>https://sreake.com/blog/account-management-by-google-cloud-privileged-access-manager/</guid>
            <pubDate>Tue, 15 Apr 2025 09:00:04 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Google Cloud Privileged Access Manager (PAM)は、Google Cloud における特権アクセス管理のためのフルマネージドサービスです。2024年5月にプレビュー版が提 […]The post Google Cloud Privileged Access Manager (PAM)を使用したアカウント管理 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[防御力の高い技術ブログを書こう]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/15/101247</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/15/101247</guid>
            <pubDate>Tue, 15 Apr 2025 01:12:47 GMT</pubDate>
            <content:encoded><![CDATA[はじめにある日のこと、私はもしくはあなたは思いつきました。そう、自分の考えを発信してみようと。それはまるで、小さな紙飛行機を窓から放り投げるような、どこまで飛ぶかわからない冒険でした。そんなわけで画面に向かい、キーボードを叩き始めたのですが、すぐに奇妙な不安が襲ってきたのです。ほら、誰かがそっと後ろから覗き込んで「それ、間違ってるよ」とか「それって昔の話でしょ」なんて言ってくるかもしれない。もっと恐ろしいのは「もっといいやり方があるのに」という呪文めいた言葉です。そんな呪文を浴びせられたら、私はきっと透明人間になりたくなるに違いありません。でも不思議なもので、そういう批判の声が聞こえてくるのは、実は自分の頭の中だったりするんですよね。まだ何も書いていないのに、もうすでに架空の批判者と対話している。ある意味、私たちは常に誰かと対話している生き物なのかもしれません。そこで考えたのです。批判に怯えて黙っているより、その批判をも包み込んでしまうような、不思議な力を持つ文章があるのではないかと。批判の矢を受け止めて、それを武器に変えてしまうような魔法のような文章。本日はそんな「防御力の高い」文章の作り方について、私なりの道案内をしてみたいと思います。ただし、これは魔法の呪文集ではなく、むしろ冒険の途中で見つけた不思議な地図のようなものです。この地図を頼りに、あなた自身の冒険を始めてみませんか？以前書いたブログの書き方はこちらです。syu-m-5151.hatenablog.comこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめになぜ防御力が必要なのか解釈の枠組みの違い認知バイアスの影響オンラインの批判文化防御力を高める表現と内容の工夫主観的な表現と限定的な主張コンテキストと限界の明示実体験と具体例の活用肯定的なものを中心に語る根拠と出典の明示防御力の高い構成テクニック批判を先取りする構成異なる立場への配慮見出しと結論の工夫批判への対応と心構え「事実」と「解釈」の違いを理解する建設的なフィードバックを活かす過剰な期待を持たない明らかな失礼への対応執筆前の準備と実践自分のバイアスを認識する執筆前の自己対話信頼できる人のレビュー学び続ける姿勢を示すおわりになぜ防御力が必要なのか解釈の枠組みの違いそれぞれの人は独自の知識体系や思考の枠組みを持っているため、あなたの書いた内容が意図とは異なる形で解釈される可能性があります。例えば、「このツールは便利だ」というシンプルな記述も、読者の経験によって全く異なる意味に解釈されます。熟練エンジニアなら「生産性を高める強力なツール」と捉え、初心者なら「入門に適した簡易ツール」と理解するかもしれません。ミドルウェア開発者は「APIが整理されている」と考え、アプリケーション開発者は「ドキュメントが充実している」と解釈するでしょう。同じ言葉でも、読者の立場や背景知識によって解釈の幅が大きく変わることを認識しておくことが、防御力の第一歩です。認知バイアスの影響私たち全員が持つ認知バイアスにより、偏ったものの見方で判断を下していると、異なる立場からの情報や論理的な指摘があっても、判断が覆らない場合があります。確証バイアス（自分の信念を補強する情報を重視し、反する情報を軽視する傾向）は特に影響力が強く、技術コミュニティでも顕著に見られます。特定のプログラミングパラダイムや技術スタックに強いアイデンティティを持つエンジニアは、その技術の欠点を指摘されると、内容の正確さに関わらず反発することがあります。権威バイアス（有名人や権威ある組織の意見を過度に信頼する傾向）も考慮すべき要素です。あなたが無名のエンジニアであれば、大企業の有名エンジニアと異なる見解を述べる際には、特に丁寧な根拠の提示が求められます。オンラインの批判文化技術コミュニティでは批判的なフィードバックが珍しくなく、匿名性からより辛辣な表現になりがちです。オンラインディスカッションでは「バイクシェッド効果」（些細な点ほど多くの意見が集まる現象）も働きます。あなたが深く考察した核心的な技術論点よりも、使用したコード例の些細なスタイルの問題や、ちょっとした言い回しに批判が集中することがあります。完璧な記事を目指すあまり執筆をためらうより、防御力を高める工夫をしながら発信する方が建設的です。防御力を高める表現と内容の工夫主観的な表現と限定的な主張「これが正しい方法だ」という断言ではなく、「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。防御力の低い表現: 「XXフレームワークはYYフレームワークより優れている」防御力の高い表現: 「私のプロジェクトでは、このユースケースでXXフレームワークが適していました」この表現の違いは微妙ですが重要です。断言的な表現は「自分が正しく、異なる選択をしている人は間違っている」という含意を持ち、読者の反発を招きます。一方、経験として共有する表現は「私はこう感じた、あなたはどう思う？」という対話の余地を残します。特に効果的なのは「特定の状況下では」という条件付けです。「XXフレームワークはリアルタイム更新の多いUIには特に適しています」のように、適用範囲を明確にすることで、批判の余地を減らせます。ただし、自分の専門分野における確立された事実（「配列の線形探索はO(n)の時間複雑性を持つ」など）については、無理に主観的表現をする必要はありません。コンテキストと限界の明示使用環境、バージョン、チーム規模などの背景と、アプローチの限界を明確にすることで、批判を先回りできます。防御力の低い表現: 「この方法でデータベース処理が30%速くなる」防御力の高い表現: 「XXデータベース14.5、16GBメモリ環境、約500万レコードのデータセットで、私のケースでは処理時間が約30%改善。ただし、より大規模なデータでは異なる結果になる可能性があります」コンテキストには、技術的な環境だけでなく、組織的な制約も含めると良いでしょう。「チーム全員がXX言語に熟練していたため、学習コストを考慮してXXを選択した」といった説明は、技術選定の合理性を示す重要な要素です。限界を示す際は、具体的な条件を挙げるとより信頼性が増します。「1秒あたり100リクエスト以上の負荷では応答時間が悪化する」「100GB以上のデータセットでは別のアプローチが必要」など、明確な境界条件を示すことで、「これが全てではない」という謙虚さと「ここまではちゃんと考えている」という誠実さを同時に伝えられます。実体験と具体例の活用抽象的な主張より、実際に経験した具体的なケースを示すことで、反論されにくくなります。ただし、「事実」も一つの解釈に過ぎないことを忘れないでください。防御力の低い表現: 「マイクロサービスアーキテクチャは複雑すぎる」防御力の高い表現: 「私たちの10人チームでECサイトをマイクロサービス化した際、サービス間の整合性維持に予想以上の工数がかかりました。具体的には、注文処理と在庫管理の同期において、トランザクション境界の設計に苦労し、最終的に以下のアプローチをとりました...」実体験を語る際のポイントは「検証可能な詳細」です。「パフォーマンスが向上した」という漠然とした記述より、「レスポンスタイムが平均342msから118msに短縮された」という具体的な数値の方が説得力があります。失敗談も非常に価値があります。「最初にAというアプローチを試みたが、Bという問題に直面したため、最終的にCという解決策にたどり着いた」という試行錯誤のプロセスは、他のエンジニアが同じ失敗を避けるのに役立ちます。失敗を率直に共有することで、「完璧を装おうとしていない」という誠実さも伝わります。肯定的なものを中心に語る批判よりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。防御力の低い表現: 「YY言語は設計に一貫性がなく不適切だ」防御力の高い表現: 「XX言語の型安全性は、特に大規模プロジェクトで次のような恩恵をもたらしました...」他の技術やアプローチを批判する代わりに、自分の選んだ技術の利点を具体的に説明することで、不必要な論争を避けられます。「YYは悪い」という否定的なメッセージより、「XXの良さはこれだ」という肯定的なメッセージの方が、心理的な抵抗を生みません。特に効果的なのは、自分が以前使っていた技術から新しい技術に移行した体験を共有することです。「以前はYYを使っていましたが、XXに移行してからこのような点が改善されました」という形式なら、YYの利用者も反感を抱きにくいでしょう。ただし、セキュリティやパフォーマンスに重大な問題がある場合など、警告が必要な場合は例外です。そのような場合でも、「避けるべき」という否定的表現より、「代替案を検討すべき状況」という建設的な表現を心がけましょう。根拠と出典の明示主張の根拠や出典を明確に示すことで、記事の信頼性と防御力が高まります。特に数値的な主張、ベストプラクティスの推奨、技術の問題点指摘、将来予測には出典が重要です。防御力の低い表現: 「このアプローチは処理速度が20倍向上する」防御力の高い表現: 「XX社の2024年1月の技術レポート（参考リンク）によれば、このアプローチでは平均20倍の処理速度向上が報告されています」出典は、公式ドキュメント、ピアレビューされた論文、広く信頼されているブログやカンファレンス発表などが理想的です。引用する際は、公開日も含めると時間的コンテキストが明確になります。出典がない場合は、自分の検証方法と結果を詳細に記述し、再現可能性を担保しましょう。「私は以下の環境でAとBの方法を各100回実行し、平均実行時間を比較しました。使用したベンチマークコードはこちらです...」という形で、検証プロセスを透明にすることで、読者自身が結果を確認できるようにします。特に重要なのは、相関と因果を混同しないことです。「XXを導入した後にパフォーマンスが向上した」と書くより、「XXを導入したことで、具体的にこのような理由からパフォーマンスが向上した」と因果関係を明確にする方が誠実です。防御力の高い構成テクニック批判を先取りする構成防御力の高い記事は、想定される批判や誤解を先取りして対応します：導入部で限定条件を明示する: 記事の冒頭で適用範囲を明確にしましょう。「このアプローチはスタートアップの小規模チームに適しています」「エンタープライズ環境での大規模データ処理を想定しています」など、読者が自分の状況に当てはまるかどうかを判断できるようにします。「よくある誤解」セクションを設ける: 技術的な選択や手法には、しばしば同じ誤解が繰り返されます。「XXは遅い」「YYはスケーリングできない」といった一般的な誤解に対して、データや実例に基づいた反論を準備しておくことで、コメント欄での同じ議論の繰り返しを避けられます。複数の代替案を併記する: 自分の推奨する方法だけでなく、代替アプローチも説明し、それぞれの長所と短所、適した状況を比較すると、公平で包括的な印象を与えます。「私たちはAを選択しましたが、以下のような状況ではBやCも有効な選択肢になります」という形式は、読者の多様なニーズに応える懐の深さを示します。構成例：問題の定義と重要性解決策を選ぶ際の考慮事項検討した代替案とそれぞれの長所・短所最終的に選んだアプローチとその理由実装の詳細と得られた結果よくある誤解と回答適用限界と将来の発展可能性異なる立場への配慮読者は様々な立場や専門性を持っています。フロントエンド開発者、バックエンド開発者、マネージャーなど、異なる役割からの見方も示すことで、幅広い共感を得られます。技術的選択を説明する際は、技術的メリットだけでなく、ビジネス的な影響や開発者体験など、複数の視点から評価することが重要です。例えば：開発者視点：「このアプローチは学習曲線がやや急ですが、一度習得すると生産性が向上します」運用視点：「デプロイの複雑さは増しますが、個別コンポーネントの更新が容易になります」ビジネス視点：「開発初期のコストは高くなりますが、長期的なメンテナンスコストが削減されます」特に効果的なのは、自分と異なる立場の人の懸念を認識し、それに対応することです。「フロントエンド開発者にとっては、このAPIの複雑さは課題かもしれませんが、以下のようなアプローチでシンプルなインターフェースを提供できます...」というように、異なる立場の読者が感じるかもしれない反論を先回りして対応すると、包括的な印象を与えられます。見出しと結論の工夫見出しは記事の骨格であり、読者が最初に目を通す部分です。見出しは主張ではなくトピックを示すようにすることで、中立的で探求的な印象を与えられます。防御力の低い見出し: 「モノリシックアーキテクチャは時代遅れ」防御力の高い見出し: 「モノリシックアーキテクチャとマイクロサービスの比較」見出しの階層構造も重要です。論理的に整理された見出し構造は、内容の理解を助け、「この著者は論理的に考えている」という信頼感を生み出します。また、見出しだけを読んでも記事の全体像が把握できるように設計すると、読者は自分に必要な部分を効率的に見つけられます。結論部分は特に注意が必要です。結論は余地を残すことで防御力が高まります。防御力の低い結論: 「すべての企業はマイクロサービスに移行すべきです」防御力の高い結論: 「私たちのケースではマイクロサービスへの移行が効果的でしたが、システムの複雑さやチーム状況によっては、モノリシックアーキテクチャも有効な選択肢です」結論では、自分の経験から得られた洞察を共有しつつも、読者自身が判断するための視点を提供するアプローチが効果的です。「私の経験からの重要な教訓は〜ですが、あなたの状況によっては以下の点を考慮すると良いでしょう」という形式は、押し付けがましくなく、かつ価値ある指針を提供できます。批判への対応と心構え「事実」と「解釈」の違いを理解する「事実だから否定していい」は最大の勘違いです。事実は解釈の一側面に過ぎず、あなたの視点も相手の視点も等しく重要です。例えば、「このアプローチはメモリ使用量が多い」という事実に対して、「だからこのアプローチは悪い」という解釈と「これは豊富なメモリを活用して処理速度を向上させる戦略だ」という解釈は、同じ事実から生まれる異なる視点です。批判的なコメントの多くは、こうした解釈の違いから生じています。対応のポイントは、事実と解釈を分離することです。「ご指摘の通り、メモリ使用量は増加します。私たちの状況ではメモリよりも処理速度が優先事項でしたが、メモリ制約が厳しい環境では別のアプローチが適しているでしょう」というように、事実を認めつつ、解釈の違いを尊重する姿勢が建設的な対話につながります。建設的なフィードバックを活かすすべての批判が悪意あるわけではありません。改善につながるフィードバックは感謝して受け入れましょう。礼儀を持って書かれた文章には礼儀を持って返しましょう。建設的フィードバックの見分け方：具体的な点を指摘している代替案や改善案を提示している敬意ある言葉遣いで表現されている個人ではなく内容に焦点を当てているこのようなフィードバックには、まず感謝の意を表し、その後で内容に対応するのが効果的です。「貴重なご指摘ありがとうございます。確かにその点は考慮すべきでした」という謝意から始めることで、対話の基盤を築けます。特に重要なのは、フィードバックが記事の改善につながった場合、その貢献を明示的に認めることです。「読者のAさんからのフィードバックを基に、この部分を更新しました」といった形で貢献を認めると、コミュニティ全体の協力的な雰囲気を促進できます。過剰な期待を持たない過剰な期待が否定の感情を生み出します。すべての人があなたの記事を理解し賛同することを期待せず、「100点満点の記事」ではなく「誰かの役に立つ記事」を目指しましょう。技術分野では特に、「正しさ」に対する執着が強い傾向があります。しかし、多くの技術的選択は、絶対的な正誤ではなく、特定の状況やニーズに対する適合性の問題です。自分の提案が「最適解」ではなく「一つの有効なアプローチ」であることを心に留めておくと、批判に対して感情的になりにくくなります。実際の数字として考えると：あなたの記事が1000人に読まれた場合、990人が何も言わず、9人が「参考になった」と言い、1人が批判することは珍しくありません。その1人の批判だけに注目すると、不当に否定的な印象を持ってしまいます。「批判は注目されやすいが、大多数の満足した読者は声を上げない」という非対称性を意識しましょう。明らかな失礼への対応馬鹿にされたら戦いしか残されていない場合もありますが、感情的にならず以下のような対応が効果的です：丁寧かつ簡潔に応答する: 「お気持ちは理解しましたが、もう少し建設的な形でご意見いただけると嬉しいです」というように、感情的に反応せず、対話の質を上げることを促します。コミュニティルール違反は適切に報告する: 明らかな罵倒や人格攻撃などは、多くのプラットフォームのコミュニティガイドラインに違反します。そのような場合は、反応せずに適切な報告手段を利用しましょう。非公開の場で対話を試みる: 「詳しいご意見をお聞かせいただけると助かります。DMでご連絡いただけませんか？」と提案することで、公開の場での感情的な応酬を避けられます。必要に応じてブロック機能を使用する: 継続的な嫌がらせや明らかな荒らし行為に対しては、自己防衛のためにブロック機能を利用することも正当な選択です。重要なのは、少数の攻撃的コメントに大量のエネルギーを消費しないことです。批判者の中には、あなたを感情的にさせること自体が目的の人もいます。そのような人に貴重な時間と精神的エネルギーを奪われることは、あなたの読者にとっても損失です。「防御」とは時に「攻撃に対して反撃する」ことではなく、「攻撃の影響を最小限に抑える」ことを意味します。最も強力な防御は、時に無反応であることを覚えておきましょう。執筆前の準備と実践自分のバイアスを認識する執筆前に「私はこの技術についてどんな思い込みを持っているか」と自問し、自分のバイアスを認識しましょう。技術的バイアスの例：- 特定の言語やフレームワークへの愛着- 特定のアーキテクチャパターンへの傾倒- 最新技術への過度な期待- レガシーシステムへの不当な否定役割バイアスの例：- バックエンド開発者としてのパフォーマンス重視- フロントエンド開発者としてのUX重視- インフラエンジニアとしての安定性重視- マネージャーとしてのプロジェクト進行スピード重視自分のバイアスを認識することは、それを否定することではなく、むしろそれを適切に開示し、他の視点も尊重する姿勢を示すことです。「私はパフォーマンス重視のバックエンドエンジニアとして見ていますが、フロントエンド開発者にとっては別の優先事項があるでしょう」というように、自分の視点を自覚的に提示することで、読者も自分の立場との違いを理解しやすくなります。執筆前の自己対話以下の質問に自分で答えることで、記事の焦点と防御力が高まります：この記事で伝えたい最も重要なことは何か？中心となるメッセージを明確にし、それを支える論点を整理します。一つの記事で伝えようとする内容が多すぎると、焦点がぼやけて批判を受けやすくなります。想定読者は誰で、どんな前提知識を持っているか？読者層を具体的にイメージし、その知識レベルに合わせた説明の詳しさを調整します。初心者向け記事なのに前提知識を要求しすぎたり、逆に熟練者向けなのに基本的すぎる説明をすると、「的外れ」という批判を受けやすくなります。どんな反論が予想され、それにどう対応するか？想定される主な反論をリストアップし、それぞれに対する回答を準備します。特に重要な反論は、記事本文で先回りして対応することも検討します。この内容の確信度はどの程度か？自分の主張にどの程度の確信を持っているかを評価し、その確信度を文章の調子に反映させます。高い確信がある部分は断言的に、確信が低い部分は探索的な表現にすることで、「間違いではないが、確信も持てない」という微妙な領域も適切に表現できます。信頼できる人のレビュー可能であれば、公開前に信頼できる人に読んでもらいましょう。彼らが感じた違和感は、他の読者も同様に感じる可能性があります。効果的なレビュー依頼のコツ：- 具体的な質問を準備する（「全体的にどう？」ではなく「この部分の説明は明確か？」など）- 批判的なフィードバックを歓迎する姿勢を示す- 技術的に詳しい人だけでなく、想定読者に近い知識レベルの人にも見てもらう- 十分な時間的余裕を持ってレビューを依頼するレビューで指摘された問題は、公開後に読者から指摘される可能性が高い部分です。この段階で修正しておくことで、公開後の批判を大幅に減らせます。学び続ける姿勢を示す「今後さらに調査したい」「まだ理解しきれていない部分がある」と認めることは、弱さではなく誠実さです。学び続ける姿勢を示すことで、「絶対に正しい」という固い主張を避けられます。専門家であることと、全てを知っていることは別です。特にIT分野では技術の変化が早く、常に学び続ける姿勢が重要です。「この記事執筆時点ではXXが最新でしたが、その後の発展により状況が変わっている可能性があります」というような但し書きは、記事の「賞味期限」を明示する役割も果たします。記事の最後に「今後の展望」や「さらなる調査ポイント」を設けることで、その話題に対する継続的な関心と探求姿勢を示せます。これは読者に「完結した知識」ではなく「進行中の探求」として内容を捉えてもらうのに役立ちます。おわりにそういうわけで、長々と話してきましたが、結局のところ完璧な文章なんてものは、空を飛ぶ象と同じくらい見つけるのが難しいのです。ある日突然空を飛ぶ象が現れたら、それはそれで困ってしまいますけどね。不思議なことに、私たちは「正しさ」というものにやたらとこだわる生き物なのですが、太陽の光が当たる角度によって、同じ景色でも全く違って見えることがあるように、「事実」というものも見る角度によって姿を変えるものなのです。そう考えると、一つの角度からしか見ていない私たちが、絶対の正しさを主張するというのは、少し滑稽なことかもしれません。それでも、あなたの見た景色、あなたの体験した不思議な出来事は、誰かにとっての道しるべになる可能性があるのです。あなたが迷った場所で、誰かが道に迷わないように。あなたが発見した小さな喜びを、誰かも同じように発見できるように。スイッチ！作者:チップ・ハース,ダン・ハース早川書房Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Google Cloud RunでIAM認証する]]></title>
            <link>https://blog.atusy.net/2025/04/15/cloud-run-with-iam/</link>
            <guid>https://blog.atusy.net/2025/04/15/cloud-run-with-iam/</guid>
            <pubDate>Tue, 15 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[開発中のサービスをGoogle Cloud Runで検証するとき、IAM認証のしかたが分からなかったのでメモ。コンソールやらコマンドやらグリグリするんしんどいなと思ったので、terraformでやってみた。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Neovimでファイルタイプ判定にShebangを使う]]></title>
            <link>https://blog.atusy.net/2025/04/15/nvim-filetype-matching-with-shebang/</link>
            <guid>https://blog.atusy.net/2025/04/15/nvim-filetype-matching-with-shebang/</guid>
            <pubDate>Tue, 15 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[vim.filetype.addを使うと、指定したパターンごとのファイル名やフルパスに対して、ファイルタイプの判定ロジックを追加できるよ。#!/usr/bin/env -S deno ...のようなshebangを使った実行ファイルの判定を紹介するよ。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ディレクトリ構成の基本原則]]></title>
            <link>https://sreake.com/blog/directory-structure-good-practice/</link>
            <guid>https://sreake.com/blog/directory-structure-good-practice/</guid>
            <pubDate>Mon, 14 Apr 2025 03:44:43 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは。スリーシェイクの中原です。 プロジェクトが大きくなるにつれて「メンテナンスがしづらい」「開発スピードが遅い」と悩みを抱える要因の一つに「ディレクトリ構造がイケてない」があると考えています。 本日は、そういった […]The post ディレクトリ構成の基本原則 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[genai-toolbox を実装して mcp server として公開し adk から使ってみる]]></title>
            <link>https://zenn.dev/satohjohn/articles/dbf4afed585680</link>
            <guid>https://zenn.dev/satohjohn/articles/dbf4afed585680</guid>
            <pubDate>Sun, 13 Apr 2025 01:54:27 GMT</pubDate>
            <content:encoded><![CDATA[mcp server を作ってみるということで、genai-toolbox という物があるのでそれを元にやっていきますhttps://github.com/googleapis/genai-toolboxこちらは、各 DB への接続情報と、どういう SQL を実行するかを yaml、または、http の baseurl と request parameter などで記載することで tool を作成することができます。接続先は図にもある形になると思います。https://github.com/googleapis/genai-toolbox/raw/main/docs/en/get...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[codecompanion.nvimでOpenAI互換APIを利用する]]></title>
            <link>https://blog.atusy.net/2025/04/13/codecompanion-adapter/</link>
            <guid>https://blog.atusy.net/2025/04/13/codecompanion-adapter/</guid>
            <pubDate>Sun, 13 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[codecompanion.nvimは未対応なサービスとチャットする方法としてカスタムアダプタの定義・登録があります。特にOpenAI互換APIを利用する場合は、xAIのアダプタを参考にすることで、簡単に実装できます。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[既存の mcp を adk 経由で叩いてみる。 playwright を使う。]]></title>
            <link>https://zenn.dev/satohjohn/articles/68bdde2842e8b4</link>
            <guid>https://zenn.dev/satohjohn/articles/68bdde2842e8b4</guid>
            <pubDate>Sat, 12 Apr 2025 10:12:09 GMT</pubDate>
            <content:encoded><![CDATA[mcp の client に付いて詳しくなりたいと思いつつ adk についてもやりたいのでチョット調べてみます。今回は playwright の mcp に繋いでみようと思います。https://mcp.so/server/playwright-mcp/microsoft?tab=contentplaywright は別サーバで立てるような想定で考えておきます。そのためドキュメントにある通り以下のように記載します$ npx @playwright/mcp@latest --port 8931Listening on http://localhost:8931Put this...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ADK で作った agent を mcp server で公開する]]></title>
            <link>https://zenn.dev/satohjohn/articles/48a82ff7de531b</link>
            <guid>https://zenn.dev/satohjohn/articles/48a82ff7de531b</guid>
            <pubDate>Fri, 11 Apr 2025 16:21:06 GMT</pubDate>
            <content:encoded><![CDATA[ほぼ前回の続きhttps://zenn.dev/satohjohn/articles/b23bd65c289257A2A を調べてたんですがその前に mcp 何も知らんということで実装しながら手で覚えていきます。前回使っていた code_agent (sequential_agent) を公開できるようにします。ADK の agent を作ったら、それを mcp server として公開ができる AgentTool というものがあるので、それを使います。https://google.github.io/adk-docs/tools/function-tools/#3-agent...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[ADK + Cloud Run を動かす]]></title>
            <link>https://zenn.dev/satohjohn/articles/b23bd65c289257</link>
            <guid>https://zenn.dev/satohjohn/articles/b23bd65c289257</guid>
            <pubDate>Fri, 11 Apr 2025 08:02:18 GMT</pubDate>
            <content:encoded><![CDATA[Google Cloud Next '25 に参加してます。そのうち会社のほうで参加レポートを出します。こちらは ADK(Agent Development Kit、Android ではない) のメモ書きのようなものです2025/04/11 時点だと python でしか ADK はリリースされていないようです。 Cloud Run で動かすCloud Run で動かす方法自体は https://google.github.io/adk-docs/deploy/cloud-run/ に記載されていますのでほぼこちらを参考にお願いします。ディレクトリやファイルは以下のとおりで...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞]]></title>
            <link>https://sreake.com/blog/2025-google-cloud-partner-of-the-year/</link>
            <guid>https://sreake.com/blog/2025-google-cloud-partner-of-the-year/</guid>
            <pubDate>Wed, 09 Apr 2025 01:00:00 GMT</pubDate>
            <content:encoded><![CDATA[株式会社スリーシェイク（本社：東京都新宿区、代表取締役社長：吉田 拓真、以下スリーシェイク）は、2025年4月9日に、「2025 Google Cloud Partner of the Year」において「Infrastructure Modernization Partner of the Year - Japan」を受賞したことをお知らせします。The post スリーシェイク、2025 Google Cloud Infrastructure Modernization Partner of the Year – Japan を受賞 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Geminiとリアルタイム音声会話できるWebアプリの作り方]]></title>
            <link>https://sreake.com/blog/gemini-realtime-voice-chat-app/</link>
            <guid>https://sreake.com/blog/gemini-realtime-voice-chat-app/</guid>
            <pubDate>Tue, 08 Apr 2025 06:04:03 GMT</pubDate>
            <content:encoded><![CDATA[はじめに 現在、生成AIを利用したアプリケーションが増加しています。その多くはテキストを中心としたものですが、アプリケーションによっては音声や動画でのやり取りが必要となることもあります。これまで生成AIとの音声・動画のや […]The post Geminiとリアルタイム音声会話できるWebアプリの作り方 first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[n8n on Cloud Run （ツール比較から選定まで）]]></title>
            <link>https://zenn.dev/meziron/articles/bff3ac566f8b93</link>
            <guid>https://zenn.dev/meziron/articles/bff3ac566f8b93</guid>
            <pubDate>Tue, 08 Apr 2025 04:53:10 GMT</pubDate>
            <content:encoded><![CDATA[はじめにこんにちは！日々の業務や個人開発で、繰り返し行う作業や複数のサービス間でのデータ連携に「もっと楽にならないかな？」と感じることはありませんか？私もその一人で、ワークフロー自動化ツールの導入を検討し始めました。世の中にはZapierやIFTTTといったSaaS型の有名なツールがありますが、今回はオープンソースでセルフホストも可能な選択肢を中心に比較検討しました。この記事では、まず私がなぜ n8n を選んだのか、その理由を説明します。そして後半では、選定したn8nを Terraform を使用して Cloud Run 上に構築した際の具体的な手順や構成について解説します。...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[mcphub.nvimでNeovimでもMCPを使う]]></title>
            <link>https://blog.atusy.net/2025/04/08/mcphub-nvim/</link>
            <guid>https://blog.atusy.net/2025/04/08/mcphub-nvim/</guid>
            <pubDate>Tue, 08 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[MCP（Model Context Protocol）をNeovimで使うためのmcphub.nvimの導入方法を紹介します。codecompanion.nvimなどのAIチャットプラグインに@mcpと入力するだけで、状況に合わせてツールを選択してくれるので凄く便利。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[エンジニアブログは技術的であるべきで登壇は衒学的であると思う理由]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/07/181150</guid>
            <pubDate>Mon, 07 Apr 2025 09:11:50 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあなたは最後に技術的な記事を読んだとき、何を求めていただろうか？この二つの問いに対する答えは、おそらく大きく異なるのではないだろうか。記事を読むとき、私は再現可能な手順、明確なコード例、具体的な問題解決の道筋を期待する。一方、技術発表を聞くとき、新たな視点やアイデア、そして時に「なるほど、そういう考え方があるのか」という気づきを求めている。技術を共有する手段として、ブログを書き、カンファレンスで登壇する。一見すると同じ「知識共有」という行為に見えるが、この二つは根本的に異なる体験を生み出している。ブログは時間に縛られず、読者が自分のペースで情報を咀嚼できる。一方、登壇は限られた時間の中で、話者の熱量や会場の空気感とともに知識が伝わる。この違いは偶然ではなく、それぞれのメディアには、最適な伝え方があると私は考えている。本稿では、私個人の経験から、エンジニアブログが技術的であるべき理由と、登壇が（ある意味で）衒学的(げんがくてき)である方が効果的である可能性について考察していく。もちろん、これはあくまで一つの視点に過ぎない。技術共有の形は人それぞれであり、正解は一つではないだろう。はじめにエンジニアブログが技術的であるべき理由参照性と再現性の重要性長期的な価値実装の痕跡としての価値集合知の形成と技術の民主化未来の自分への投資思考プロセスの可視化登壇が衒学的であっても良い理由衒学的とは何か「見せかけの深さ」が生む魅力とモチベーション「わかった気にさせる」テクニックと一過性の特性ステータスシンボルとしての衒学記憶に残るメンタルモデルの構築異分野からの知見取り込みの触媒衒学的アプローチの価値と限界まとめエンジニアブログが技術的であるべき理由技術ブログの書き方はこちらでお願いします。syu-m-5151.hatenablog.com参照性と再現性の重要性エンジニアブログの重要な特徴は、読者がいつでも立ち返ることができる参照点となることです。コードの実装例、設定手順、トラブルシューティングの方法など、技術的な内容は「再現できる」ことが最も重要です。技術的であるということは、単に難しい言葉を使うことではなく、読者が同じ結果を得られるように明確で具体的な手順を提供することです。例えば、クラウドでサーバーレスアプリケーションを構築する方法を説明するブログ記事では、使用するサービス、必要な設定、コード例、発生しうる問題とその解決策など、実践的で具体的な情報が求められます。長期的な価値技術的なブログ記事は、時間が経過しても価値を保ちます。もちろんテクノロジーは進化しますが、基本的な概念や問題解決のアプローチは長く参照されることがあります。「どのようにして特定の問題を解決したか」という記録は、数年後の同様の問題に直面したエンジニアにとって貴重な資料となります。例えば、5年前に書かれたコンテナ技術のネットワーク問題のデバッグ方法に関する記事は、現在でも参考になることが多いです。具体的な実装の痕跡は、技術の進化に関わらず価値を持ち続けるのです。実装の痕跡としての価値技術的なブログ記事の価値は、「実際にやってみた痕跡」が残ることです。抽象的な概念や理論ではなく、「この実装でこの問題に直面し、このように解決した」という具体的な記録は、他のエンジニアにとって何物にも代えがたい財産となります。コードスニペット、設定ファイル、エラーメッセージとその対処法などは、まさに泥臭いエンジニアリングの証であり、読者が同じ問題に直面したときの救いの手となります。理論や概念を語るのは簡単ですが、実際の実装の痕跡を残すことこそ、技術ブログの本質的な価値と言えるでしょう。ブログの目的は、実際に同じ道を歩んでいる人の助けになることだからです。集合知の形成と技術の民主化技術的なブログ記事は、個人の経験を超えた「集合知」の形成に貢献します。特に大企業や専門家だけが持っていた知識が、個人のブログを通じて広く共有されることで、技術の民主化が進みます。オープンソースの精神と同様に、技術的なブログは知識のバリアを取り払い、誰もが高度な技術にアクセスできる環境を作り出します。例えば、以前は高価な書籍や専門的なトレーニングでしか学べなかった最先端の技術が、今では個人のブログを通じて無料で学べるようになっています。この知識の解放こそが、技術革新のスピードを加速させる原動力となっています。未来の自分への投資技術ブログを書くことは、未来の自分への最高の投資でもあります。今日困難を乗り越えた方法を記録しておくことは、数ヶ月後、数年後に同じ問題に直面したときの自分自身へのギフトとなります。「あれ、この問題以前にも解決したはずだが、どうやったんだっけ？」という状況は、エンジニアなら誰もが経験するものです。自分のブログは、検索エンジンよりも信頼できる個人的な知識ベースとなり、問題解決の時間を大幅に短縮してくれます。さらに、記録する行為そのものが理解を深め、知識を定着させるため、学習効率も向上します。思考プロセスの可視化優れた技術ブログは、単に「何を」実装したかだけでなく、「なぜそうしたのか」「他にどんな選択肢を検討したのか」という思考プロセスも含みます。この思考の軌跡を残すことで、技術選択の背後にある意思決定の流れが明らかになり、読者はより深い文脈で技術を理解できます。例えば、「Aという技術とBという技術を比較検討した結果、こういう理由でAを選んだ」という記述は、単にAの使い方を説明するよりも価値があります。なぜなら、読者は自分の状況に照らし合わせて意思決定できるようになるからです。思考プロセスの共有は、テクニックだけでなく技術的判断力も養う助けとなります。登壇が衒学的であっても良い理由衒学的とは何かまず「衒学的(げんがくてき)」という言葉について整理しておきましょう。衒学的とは、本質的な理解が伴わないにもかかわらず、学識があるように見せかけ、それを誇示するような様子を指します。つまり、実際には深い知識や経験がなくても、難解な専門用語や引用を多用し、表面的に「賢そうに見せる」テクニックと言えるでしょう。登壇において、この「賢そうに見せる」という要素が、皮肉にも効果的である理由を考えていきます。また、これらは外部登壇を指し社内のプレゼンテーションとは別物ですので御容赦下さい。「見せかけの深さ」が生む魅力とモチベーション登壇の場では、実は技術的な詳細よりも「語り方」や「見せ方」が重要になることが多いのではないかと私は感じています。難解な概念や用語を織り交ぜ、「これは単なる技術ではなく、哲学なのだ」と語ることで、聴衆に「深い知見を得た」という錯覚を与えることができます。例えば、マイクロサービスアーキテクチャの実装という話題でも、具体的な実装方法よりも「組織設計との整合性」「分散システムの哲学的背景」などと語れば、特に具体的な内容がなくても「深い話を聞いた」という満足感を聴衆に与えることができるのです。私個人の考えでは、登壇の一つの重要な目的は、聴衆を「やる気にさせること」であり、具体的な方法論よりも「そういうアプローチもあるのか！」という気づきと挑戦意欲を引き出すことにあります。もちろん、これは私の一意見であり、登壇の目的は発表者それぞれが自由に決めるものです。聴衆が実際に行動を起こす可能性を高めるために解決策の提示が効果的であれば、それも取り入れるべきでしょう。しかし実装の苦労や具体的な失敗談よりも、抽象的な概念を語る方が「賢そう」に見えるという側面があるのも、一つの観察です。登壇スタイルは千差万別で、どれが正解というものではありません。「わかった気にさせる」テクニックと一過性の特性登壇は一過性のメディアです。登壇資料が公開される可能性が高いとはいえ、その場で聞くことと読むことでは体験や雰囲気が大きく異なります。実際には聴衆のほとんどは具体的な技術内容を覚えて帰ることはできないことが多いでしょう。それよりも「あの人は賢そうだった」「深い話だった気がする」という印象だけが残ることが少なくありません。私の経験では、登壇の短い時間内で、全ての文脈やトレードオフを理解してもらい、「なぜこういう判断をしたのか」を完全に伝えることはほぼ不可能です。実際の開発においては数週間から数ヶ月かけて検討したことを、わずか30分や1時間で説明するには限界があります。それぞれの登壇者が、この制約の中でベストだと思う方法を選択していると思います。この特性を踏まえると、実装の詳細や技術的な苦労よりも、引用や専門用語、抽象的な概念を散りばめることで「わかった気にさせる」アプローチが生まれるのも理解できます。私の考えでは、登壇の目的の一つは、人を分かった気にさせてやる気を引き出すことにあります。聴衆は具体的に何を学んだかを説明できなくても、「深い話を聞いた」という満足感と「自分も挑戦してみよう」というモチベーションを得ることができるかもしれません。もちろん、別の目的や価値観を持って登壇に臨む人もいて、それも素晴らしいことだと思います。もちろん、聴衆のやる気を引き出すために具体的な解決策を提示することが効果的であれば、それも積極的に取り入れるべきでしょう。しかし多くの場合、登壇者にとっても、抽象的な概念を語る方が準備も楽で「賢そうに見える」という都合の良さがあります。ステータスシンボルとしての衒学衒学的な登壇は、皮肉にもコミュニティ内での一種のステータスシンボルとなっています。「実装の詳細を語る人」より「大きな概念や哲学を語る人」の方が尊敬されるという暗黙の序列が形成されているのです。技術カンファレンスで最も拍手を浴びるのは、具体的な実装方法を丁寧に説明した発表ではなく、抽象的な概念を難解な用語で彩った発表であることが多いのは、この現象の表れと言えるでしょう。エンジニアであれば誰しも「コードを書く人」より「アーキテクトやコンサルタント」のように見られたいという欲求があり、衒学的な登壇はそれを満たす手段となっています。記憶に残るメンタルモデルの構築例えば、分散システムの説明で「ビザンチン将軍問題」や「CAP定理」といった概念を取り上げることは、単なる実装テクニックの説明よりも聴衆の理解と記憶に残りやすいものです。これらの抽象的なモデルは「問題のやり方」ではなく「問題の捉え方」や「考え方」を提供し、聴衆が様々な状況で応用できる思考ツールとなります。衒学的に思えるこうした抽象化は、表面的な知識の誇示ではなく、実は技術の本質をより効果的に伝えるための有効な手段となり得るのです。特に登壇という限られた時間の中では、具体的な細部よりも「考え方」を伝えることの方が、長期的な価値を生み出す可能性が高いと思います。異分野からの知見取り込みの触媒衒学的なアプローチの興味深い側面として、それが異なる専門分野からの知見を技術の文脈に取り入れる触媒になることがあります。哲学、経済学、心理学、生物学などの概念を技術的課題と結びつけることで、技術コミュニティに新しい視点がもたらされるのです。例えば、システム設計において「アンチフラジャイル」（ナシーム・タレブの概念）や「レジリエンス工学」といった他分野からの概念を導入することで、従来のエンジニアリングの枠を超えた発想が生まれます。一見すると衒学的に見えるこうした「知の越境」は、実は技術の進化において重要な役割を果たしています。異分野の知見を適切に取り入れる衒学的アプローチは、単なる見せかけではなく、技術コミュニティに真の価値をもたらし得るものです。特に複雑な問題に対して、単一分野の知見だけでは不十分な場合、こうした学際的な視点は革新的な解決策を生み出す源泉となり得ます。衒学的アプローチの価値と限界「具体」と「抽象」は物事の捉え方や表現の仕方において相対的な関係性を持ちます。登壇における衒学的アプローチは、多くの場合、抽象度を高めた表現を用いることで成り立っています。抽象的な表現は、個別の事例を超えた共通点や法則性を見出し、多くの状況に適用できる知見を提供できるという利点があります。具体的な表現は直観的でわかりやすく、個々の事例や実装を明確に伝えますが、抽象的な表現は多くの事象に共通する本質や性質を簡潔にまとめることができます。聴衆によって「しっくりくる表現」は異なり、抽象的な概念が腑に落ちる人もいれば、具体例から理解を深める人もいます。衒学的と思われる表現であっても、それが聴衆の一部にとって心に響くものであれば、それは価値あるコミュニケーションと言えるのではないでしょうか。具体と抽象を行き来する思考は、問題解決やコミュニケーション能力を高める上でも重要です。登壇者が衒学的に見える抽象的表現を用いつつも、適切なタイミングで具体例に降りてくる「往復」ができれば、より効果的な知識共有が可能になると思います。以上のような考察は、あくまで個人的な観察と意見です。技術コミュニティには様々な価値観があり、登壇のスタイルも多様であるべきだと思います。優れたエンジニアでも、登壇の場では衒学的になることを求められ、それに応えることでキャリアを築いていく側面があるように感じます。私の見解としては、実装の詳細や技術的な苦労話はブログという形式で書き残しておき、登壇では適度に抽象度を上げた概念を語るという使い分けは、それぞれのメディアの特性を活かした一つのアプローチかもしれません。ブログであれば、読者は自分のペースで何度も読み返し、理解を深めることができます。一方、登壇では限られた時間で複雑な文脈を伝えることは難しく、聴衆の注意を引きつつ主要なメッセージだけを印象づける技術が必要になるケースが多いと感じています。しかし、登壇が衒学的すぎることにも明らかな危険性があります。実体のない難解な言葉だけで埋め尽くされた発表は、短期的には印象的に見えても、長期的には聴衆の信頼を失います。「この人は話が上手いだけで、実際には何も伝えていない」と見抜かれれば、せっかくの登壇も台無しではないでしょうか。また、あまりに現実から乖離した抽象論ばかりでは、聴衆が実際の業務に持ち帰れる価値が少なく、最終的な目的である「やる気にさせる」ことにも失敗してしまうかもしれません。私なりに考える理想的な登壇とは、衒学的アプローチを適度に取り入れつつも、聴衆が明日から使える具体的なヒントや考え方をしっかりと提供するものです。「難解に思えるけれど、よく考えると実践的な知恵がある」という絶妙なバランスこそが、価値ある登壇の鍵かもしれませんが、これはあくまで一つの視点であり、様々な登壇スタイルがあって然るべきだと思います。エンジニアが技術的スキルに加えて、抽象的な概念を効果的に伝えるスキルを磨くことの価値は、人それぞれの考え方によると思います。重要なのは単なる見せかけではなく、本質的な価値を状況や相手に応じて適切に伝えるための表現技術ではないかと考えています。まとめエンジニアブログは具体的で技術的であることで長期的な参照価値を持ち、誰かの実際の問題解決に貢献します。一方、登壇は適度に衒学的なアプローチを取りながらも、聴衆に「深い話を聞いた」という満足感を与え、「自分も挑戦してみよう」というモチベーションを引き出すという役割があるように思います。もちろん、これはあくまで一つの見方であり、登壇やブログの形は多様であってよいと思います。「中身のない衒学」ではなく「知見を効果的に伝える技術」を身につけるべきだと考えています。限られた登壇時間と聴衆の記憶容量を考えると、物事を単純化し印象づける技術には価値がありますが、それが空虚なものであれば、長期的には信頼を失うことになると感じています。他の方は異なる価値観を持っているかもしれませんし、それも尊重されるべきです。個人的に大切だと思うのは、ブログでは誠実に技術を伝え、実際に同じ道を歩む人の助けになる一方で、登壇では効果的な伝え方を工夫しながらも本質的な価値を提供し、聴衆のやる気を引き出す、というそれぞれのメディアの特性を理解して使い分けることではないでしょうか。そして何より、「賢そうに見せる」ことと「本当に賢いこと」の違いを自分自身がしっかりと理解しておくことが重要だと思います。結局のところ、優れた技術共有とは、表面的な知識の誇示ではなく、本質的な価値をいかに効果的に伝えるかというバランスの問題なのかもしれません。メディアの特性を理解し、それぞれに合った形で自分の知見を共有できれば、技術コミュニティ全体がより豊かになっていくのではないでしょうか。これらはあくまで個人の経験と観察に基づく意見であり、みなさんがそれぞれのスタイルや価値観で技術共有を行うことを応援しています。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド]]></title>
            <link>https://zenn.dev/meziron/articles/a95d3133a1c385</link>
            <guid>https://zenn.dev/meziron/articles/a95d3133a1c385</guid>
            <pubDate>Mon, 07 Apr 2025 05:34:46 GMT</pubDate>
            <content:encoded><![CDATA[運用中のDBに後付け Prisma Migrate を途中から導入する実践ガイド（ハマりどころ解説付き） はじめに (きっかけ)「このプロジェクト、最初は Prisma 使ってたけど、マイグレーションまでは管理してなかったんだよな...」「開発も進んで、そろそろちゃんとスキーマ変更を管理したいけど、_prisma_migrations テーブルがない...」そんな状況、ありませんか？ 私もまさにその状況に直面しました。Prisma は導入済みでデータベーススキーマも存在しているけれど、Prisma Migrate によるマイグレーション管理は行われていない。運用が始まってい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[CopilotChat.nvimでもギャルとペアプロしたい！]]></title>
            <link>https://blog.atusy.net/2025/04/06/copilotchat-with-gal/</link>
            <guid>https://blog.atusy.net/2025/04/06/copilotchat-with-gal/</guid>
            <pubDate>Sun, 06 Apr 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[ギャルとのペアプロが想像以上に楽しかった（VSCodeのカスタム指示）という話を見て、なにそれ面白いとなった。そこへ来て友人が、思慮深いお姉さんも登場させると勝手にプログラミングしてくれて面白いという。これはNeovimでもやってみるしかないと、とりあえずCopilotChat.nvimのユーザープロンプトを試してみた。しかし、見事にコンテンツフィルタに弾かれてしまいました。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI時代に必要なシェルの基本知識とシェル芸への入門]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/04/04/085754</guid>
            <pubDate>Thu, 03 Apr 2025 23:57:54 GMT</pubDate>
            <content:encoded><![CDATA[はじめに生成AIの急速な発展により、様々なAIアシスタントが日常的にシェルコマンドを提案してくれるようになりました。また、最新のAI統合ツールは、ユーザーの自然言語指示からコマンドを生成し、場合によっては自動的に実行することさえあります。このような環境では、AIが提案または実行するシェルコマンドを正確に理解し、安全に活用するための知識が不可欠となっています。「コマンドプロンプトやLinuxなんて難しそう」「プログラミングは専門家の領域」と思っている方こそ、この記事をお読みください。AIツールを使う現代では、専門知識がなくても基本を知っておくことで安全性が大きく変わります。本記事では、生成AIが提案するシェルコマンドを適切に評価し、安全に活用するために必要なシェルの基本知識と「シェル芸」と呼ばれる技術について詳しく解説します。難しい専門用語は極力避け、初心者の方でも理解できるよう丁寧に説明していきます。AIが生成したコードを盲目的に実行することのリスクを避けつつ、その強力な機能を最大限に活用するための実践的な知識を身につけていただくことを目指しています。b.ueda.tech普通に無料でダウンロードできるのでLinux標準教科書もオススメです。linuc.orgこのブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめに生成AIとシェルコマンドの関係シェルの基本概念代表的なシェルシェルの重要な機能1. I/O（入出力）2. パイプ3. リダイレクト4. フィルタ処理5. 内部展開6. 制御構文条件分岐（if文）case文（パターンマッチング）for ループwhile ループuntil ループ（条件が真になるまで繰り返す）関数定義と呼び出しその他の制御構文と技法AIが提案するシェルコマンドを理解するAIが生成するシェルコマンドの特徴ワンライナーの理解と解読ワンライナーの特徴生成AIが提案するワンライナーの例ワンライナーを解読する方法ワンライナーを複数行スクリプトに変換するコマンドを分解して理解する方法危険なコマンドの見分け方注意すべきコマンドとオプション安全に検証する方法安全な実行環境の構築と活用実用的なシェル芸とAIの活用例ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整AIからの提案を検証して実行する例テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価AIと連携したデータ前処理の例環境変数とエイリアスの理解環境変数の確認と活用AIが提案するエイリアスを安全に設定ジョブ制御と長時間実行コマンド長時間実行コマンドの制御実行中コマンドの管理ワンライナーの安全性評価と活用法ワンライナーの安全性評価チェックリストワンライナーを安全に変換する方法AIが提案するワンライナーを効果的に活用するコツワンライナー活用のベストプラクティスまとめ生成AIとシェルコマンドの関係生成AIはシェルコマンドの提案において非常に優れた能力を持っています。複雑な操作を1行のコマンドで実現したり、複数のツールを組み合わせて効率的なデータ処理を行ったりするシェルコマンドを即座に提案できます。しかし、この便利さの一方で、次のような課題も生じています。理解なき実行のリスク: AIが提案するコマンドを理解せずに実行すると、意図しないファイル削除やセキュリティリスクを引き起こす可能性があります環境依存の問題: AIは特定の環境を前提としたコマンドを提案することがあり、異なる環境で実行すると期待した結果が得られないことがあります権限の問題: 管理者権限が必要なコマンドを適切な検証なしに実行すると、システムに重大な影響を及ぼす可能性があります自動実行の危険性: GitHub Copilot CLIなどのツールがコマンドを自動生成し実行する場合、確認の機会なくリスクのあるコマンドが実行される可能性がありますこれらの課題に対処するには、シェルの基本を理解し、AIが提案するコマンドを正確に評価できる能力が必要です。シェルの基本概念シェルとは、オペレーティングシステム（OS）のカーネルと対話するためのインターフェースです。ユーザーがコマンドを入力すると、シェルはそれを解釈し、OSに対して適切な指示を出します。豆知識: シェルという名前は「殻」を意味し、OSの核心部分（カーネル）を覆う層として機能することに由来しています。［試して理解］Linuxのしくみ　―実験と図解で学ぶOS、仮想マシン、コンテナの基礎知識【増補改訂版】作者:武内 覚技術評論社Amazon代表的なシェルBash (Bourne Again SHell): Linux/Unixの標準シェルZsh (Z Shell): Bashの機能を拡張したシェル、macOSのデフォルトシェルPowerShell: Windowsで使用されるシェルFish: ユーザーフレンドリーな機能を持つシェル生成AIは異なるシェル環境向けのコマンドを提案することがあるため、自分の環境に合ったコマンドを理解し選択する必要があります。シェルの重要な機能AIが提案するコマンドを理解するには、以下のシェルの基本機能を把握することが重要です。1. I/O（入出力）Linuxの入出力は主に3つのストリームで管理されています。標準入力（stdin）: ユーザーからのキーボード入力（ファイルディスクリプタ 0）標準出力（stdout）: 通常の出力結果（ファイルディスクリプタ 1）標準エラー出力（stderr）: エラーメッセージ（ファイルディスクリプタ 2）AIが複雑な入出力リダイレクトを含むコマンドを提案した場合、これらの概念を理解していないと意図しない動作を引き起こす可能性があります。2. パイプパイプ（|記号）を使うと、あるコマンドの出力を次のコマンドの入力として渡すことができます。AIは複数のコマンドをパイプでつないだ複雑なワンライナーを好んで提案することがあります。例：# AIが提案するような複雑なパイプラインfind . -type f -name "*.log" | grep "ERROR" | awk '{print $1, $2}' | sort | uniq -cこのようなコマンドを理解するには、各部分の役割を個別に把握する必要があります。3. リダイレクトシェルではコマンドの出力を任意のファイルに書き出したり、コマンドへの入力を任意のファイルから行ったりできます。例：# 出力のリダイレクトls -l > file_list.txt  # 上書きls -l >> file_list.txt  # 追記# 入力のリダイレクトsort < unsorted.txt# エラー出力のリダイレクトcommand 2> error.log# 標準出力とエラー出力を同じファイルへcommand > output.log 2>&1AIが提案するコマンドにリダイレクトが含まれる場合、既存ファイルの上書きなど、意図しない結果につながる可能性があるため注意が必要です。4. フィルタ処理生成AIは多くの場合、複数のフィルタコマンドを組み合わせた処理を提案します。代表的なフィルタコマンドとその役割を理解しておくことが重要です。grep: テキスト検索（正規表現可）sed: ストリームエディタ（テキスト置換など）awk: テキスト処理言語（列指向の処理に強い）sort/uniq: 行のソートと重複排除cut/paste: 列の切り出しと結合head/tail: 先頭/末尾の行を表示AIが提案する複雑なパイプラインは、これらのコマンドを組み合わせたものであることが多いため、各コマンドの役割を理解していれば全体の意図も把握しやすくなります。5. 内部展開シェルは入力されたコマンドを実行する前に、様々な展開処理を行います。AIが提案するコマンドに含まれる特殊な構文を理解するには、これらの展開処理の知識が必要です。変数展開: $VAR や ${VAR} で変数の値に置き換えるコマンド置換: `command` や $(command) でコマンドの実行結果に置き換える算術展開: $((expression)) で数式の計算結果に置き換えるブレース展開: {a,b,c} や {1..5} でパターンを展開するパス名展開（グロビング）: *, ?, [abc] などのワイルドカードを使ったファイル名の展開AIが提案するコマンドには、これらの展開を利用した簡潔な表現が含まれていることが多いです。6. 制御構文シェルスクリプト内での処理の流れを制御するための構文です。AIはしばしば複雑な条件分岐やループを含むシェルスクリプトを提案します。これらの構文を理解できないと、AIが提案するスクリプトの意図や潜在的なリスクを見逃す可能性があります。条件分岐（if文）# 基本構文if [ 条件 ]; then    # 条件が真の場合の処理elif [ 別の条件 ]; then    # 別の条件が真の場合の処理else    # どの条件も満たさない場合の処理fi# 数値比較の例if [ $num -eq 10 ]; then    echo "numは10です"elif [ $num -gt 10 ]; then    echo "numは10より大きいです"else    echo "numは10より小さいです"fi# ファイル・ディレクトリのテストif [ -f "$file" ]; then    echo "$fileは通常ファイルです"elif [ -d "$file" ]; then    echo "$fileはディレクトリです"elif [ ! -e "$file" ]; then    echo "$fileは存在しません"fi# 文字列比較if [ "$str1" = "$str2" ]; then    echo "二つの文字列は同じです"fiif [ -z "$var" ]; then    echo "変数は空です"fi主な条件テスト演算子：- 数値比較: -eq(等しい), -ne(等しくない), -lt(より小さい), -le(以下), -gt(より大きい), -ge(以上)- ファイルテスト: -e(存在する), -f(通常ファイル), -d(ディレクトリ), -r(読み取り可能), -w(書き込み可能), -x(実行可能)- 文字列テスト: =(等しい), !=(等しくない), -z(空), -n(非空)高度な条件テスト（[[ ]]構文）：# 拡張条件テストif [[ "$file" == *.txt ]]; then    echo "テキストファイルです"fiif [[ "$str" =~ ^[0-9]+$ ]]; then    echo "数値のみの文字列です"fi# 論理演算子if [[ $num -gt 5 && $num -lt 10 ]]; then    echo "numは5より大きく10未満です"fiif [[ $opt == "a" || $opt == "b" ]]; then    echo "オプションはaまたはbです"ficase文（パターンマッチング）# 基本構文case $variable in    pattern1)        # pattern1にマッチした場合の処理        ;;    pattern2|pattern3)        # pattern2またはpattern3にマッチした場合の処理        ;;    *)        # どのパターンにもマッチしない場合の処理（デフォルト）        ;;esac# 実用例case $action in    start|begin)        echo "サービスを開始します"        service_start        ;;    stop|end)        echo "サービスを停止します"        service_stop        ;;    restart)        echo "サービスを再起動します"        service_restart        ;;    *)        echo "使用法: $0 {start|stop|restart}"        exit 1        ;;esacfor ループ# 基本形（リスト指定）for item in item1 item2 item3; do    echo "処理: $item"done# 範囲指定for i in {1..10}; do    echo "数: $i"done# ステップ付き範囲指定for i in {1..10..2}; do    echo "奇数: $i"  # 1,3,5,7,9done# コマンド出力をループfor file in $(find . -name "*.txt"); do    echo "ファイル: $file"done# ワイルドカード展開for file in *.log; do    echo "ログファイル: $file"done# C言語風の構文for ((i=0; i<5; i++)); do    echo "カウント: $i"donewhile ループ# 基本構文while [ 条件 ]; do    # 条件が真の間、繰り返し実行される処理done# カウンタ変数による繰り返しcount=1while [ $count -le 5 ]; do    echo "カウント: $count"    count=$((count + 1))done# ファイル内容を1行ずつ処理while read line; do    echo "Line: $line"done < input.txt# コマンド結果をチェックするループwhile ping -c 1 example.com > /dev/null; do    echo "サーバーは応答しています"    sleep 5doneuntil ループ（条件が真になるまで繰り返す）# 基本構文until [ 条件 ]; do    # 条件が偽の間、繰り返し実行される処理done# 例: サービスが起動するまで待機until service_is_running; do    echo "サービス起動を待機中..."    sleep 2doneecho "サービスが起動しました"関数定義と呼び出し# 基本的な関数定義function greet {    echo "Hello, World!"}# 別の構文（function キーワードなし）backup_file() {    cp "$1" "$1.bak"    echo "Backed up $1 to $1.bak"}# 引数を受け取る関数print_args() {    echo "第1引数: $1"    echo "第2引数: $2"    echo "すべての引数: $@"    echo "引数の数: $#"}# 戻り値を返す関数is_even() {    if (( $1 % 2 == 0 )); then        return 0  # 成功（真）    else        return 1  # 失敗（偽）    fi}# 関数の呼び出しgreetbackup_file "important.txt"print_args "hello" "world"# 戻り値のチェックif is_even 4; then    echo "4は偶数です"fiその他の制御構文と技法# コマンドの成功/失敗に基づく条件実行command1 && command2  # command1が成功した場合のみcommand2を実行command1 || command2  # command1が失敗した場合のみcommand2を実行# 例grep "pattern" file.txt && echo "パターンが見つかりました"grep "pattern" file.txt || echo "パターンが見つかりませんでした"# サブシェル（グループ化）(cd /tmp && ls -la)  # 現在のディレクトリを変更せずにコマンドを実行# 現在のシェルでのグループ化{ echo "開始"; command1; command2; echo "終了"; }# エラーハンドリングset -e  # エラーが発生したらスクリプトを終了trap 'echo "エラーが発生しました"; exit 1' ERR  # エラー発生時の処理を指定# デバッグモードset -x  # 実行されるコマンドを表示AIが生成するシェルスクリプトには、これらの制御構文が組み合わされて使用されることが多いです。特に注意すべき点は：条件判定の確認: 条件テストが意図したとおりに動作するか確認するループの終了条件: 無限ループになっていないか確認するエラーハンドリング: エラー発生時に適切に処理されるか確認する変数の展開: 変数が適切に展開されて使用されているか確認するAIが提案するスクリプトの制御構文を理解することで、そのスクリプトが何をしようとしているのか、そして潜在的なリスクがあるかどうかを判断できるようになります。AIが提案するシェルコマンドを理解する生成AIは非常に効率的なシェルコマンドを提案できますが、それを理解し安全に実行するにはいくつかのステップが必要です。特に生成AIは複雑な処理を1行で完結させる「ワンライナー」を好んで提案する傾向があります。1日1問、半年以内に習得　シェル・ワンライナー160本ノック Software Design plus作者:上田 隆一,山田 泰宏,田代 勝也,中村 壮一,今泉 光之,上杉 尚史技術評論社AmazonAIが生成するシェルコマンドの特徴複雑なワンライナー: 複数の処理を1行で実行するコマンド高度なオプションの使用: 一般的ではない特殊なオプションの利用複数のツールの組み合わせ: grep, sed, awk, findなど複数のツールを組み合わせた処理正規表現の多用: 複雑なパターンマッチングを使用したテキスト処理環境依存の記述: 特定の環境を前提としたコマンドリソース集約的な処理: システムリソースを大量に消費する可能性のある処理ワンライナーの理解と解読生成AIは複数のコマンドを組み合わせた「ワンライナー」を頻繁に提案します。ワンライナーとは、複数の処理を1行のコマンドで完結させる技法で、効率的ですが理解が難しい場合があります。ワンライナーの特徴複数コマンドの連結: パイプ（|）やセミコロン（;）で複数のコマンドを連結制御構文の圧縮: if文やループをセミコロンで区切り1行に記述サブシェルの多用: $(command) や `command` でコマンド出力を埋め込みリダイレクトの組み合わせ: 入出力リダイレクトを複雑に組み合わせる特殊な演算子: &&（AND）、||（OR）、{}（グループ化）などの使用生成AIが提案するワンライナーの例# ログファイルからエラーを抽出して集計するワンライナーfind /var/log -name "*.log" -mtime -7 | xargs grep -l "ERROR" | xargs cat | grep -o "ERROR: [^ ]*" | sort | uniq -c | sort -nr | head -10# ディレクトリ内の大きなファイルを検索して移動するワンライナーfind . -type f -size +100M -exec du -h {} \; | sort -hr | head -10 | awk '{print $2}' | xargs -I{} mv {} /backups/# 複数ファイルの文字列を一括置換するワンライナーgrep -l "oldtext" *.txt | xargs sed -i 's/oldtext/newtext/g'# 条件分岐を含むワンライナーfor file in *.log; do [ -s "$file" ] && echo "$file is not empty" || echo "$file is empty"; done# サブシェルと変数展開を使ったワンライナーfor i in {1..5}; do mkdir -p project_$(date +%Y%m%d)_$i/{src,docs,tests}; doneワンライナーを解読する方法セミコロンで分割: セミコロン（;）で区切られた部分を別々のコマンドとして考える   # 元のワンライナー   cd /tmp; mkdir test; cd test; touch file.txt; echo "done"      # 分解したコマンド   cd /tmp   mkdir test   cd test   touch file.txt   echo "done"パイプライン分析: パイプ（|）ごとにデータの流れを追跡する   # パイプラインの追跡   find . -name "*.log" | grep "ERROR" | awk '{print $1}' | sort | uniq -c      # ステップ1: logファイルの一覧を生成   # ステップ2: ERRORを含む行をフィルタリング   # ステップ3: 各行の最初のフィールドを抽出   # ステップ4: 結果をソート   # ステップ5: 重複を数えて集計制御構造の識別: for、if、whileなどの制御構造を識別して展開する   # 元のワンライナー   for file in *.txt; do grep "pattern" "$file" && echo "$file contains pattern"; done      # 展開した形   for file in *.txt   do       if grep "pattern" "$file"       then           echo "$file contains pattern"       fi   doneエコーデバッグ: 実行せずに echo でコマンドを表示する   # 危険そうなワンライナー   find . -name "*.tmp" -delete      # エコーデバッグバージョン   find . -name "*.tmp" -print部分実行: ワンライナーの一部だけを実行して結果を確認   # 完全なワンライナー   find . -name "*.log" | xargs grep "ERROR" | awk '{print $1,$2}' | sort > errors.txt      # 部分実行   find . -name "*.log" | head  # まず対象ファイルを確認   find . -name "*.log" | xargs grep "ERROR" | head  # エラー行を確認ワンライナーを複数行スクリプトに変換するAIが提案する複雑なワンライナーは、理解しやすい複数行スクリプトに変換すると安全性が向上します。# 元のワンライナーfind /var/log -name "*.log" -mtime -7 | xargs grep -l "ERROR" | xargs cat | grep -o "ERROR: [^ ]*" | sort | uniq -c | sort -nr | head -10# 複数行スクリプトに変換#!/bin/bash# 最近7日間のログファイルを見つけるlog_files=$(find /var/log -name "*.log" -mtime -7)# エラーを含むファイルだけを抽出error_files=$(grep -l "ERROR" $log_files)# エラーメッセージを抽出して集計cat $error_files |     grep -o "ERROR: [^ ]*" |     sort |     uniq -c |     sort -nr |     head -10コマンドを分解して理解する方法AIが提案する複雑なコマンドを理解するための効果的なアプローチ：パイプでセグメント化: パイプ（|）ごとにコマンドを分割して考える   # 元のコマンド   find . -name "*.log" | grep "ERROR" | awk '{print $1}' | sort | uniq -c      # 分解して考える   find . -name "*.log"     # ステップ1: logファイルを見つける   grep "ERROR"             # ステップ2: ERRORを含む行を抽出   awk '{print $1}'         # ステップ3: 各行の最初のフィールドを取得   sort                     # ステップ4: 結果をソート   uniq -c                  # ステップ5: 重複をカウント部分的な実行: コマンドの一部だけを実行して結果を確認   # 段階的に実行して結果を確認   find . -name "*.log" | head  # まず対象ファイルを確認   find . -name "*.log" | grep "ERROR" | head  # 次にエラー行を確認マニュアルの確認: 不明なオプションは man や --help で調査   man find   # findコマンドのマニュアルを表示   grep --help  # grepのヘルプを表示テスト環境での実行: 実際のシステムやデータに影響を与えないテスト環境で試す危険なコマンドの見分け方AIが提案するコマンドの中には、システムに重大な影響を与える可能性のあるものもあります。そのようなコマンドを見分けるポイント：注意すべきコマンドとオプションファイル削除系   rm -rf  # 再帰的強制削除（特に /* や / を含む場合は危険）   find ... -delete  # 見つかったファイルを削除ファイル書き換え系   > file  # ファイルの内容を上書き   sed -i  # ファイルを直接編集   dd      # ブロックレベルでのデータコピー（特にofオプションが危険）システム関連   shutdown, reboot  # システムの停止や再起動   chmod -R 777 /  # 危険な権限変更   mkfs  # ファイルシステムのフォーマットネットワーク関連   iptables -F  # ファイアウォールルールの削除   ssh-keygen -R  # 既知のホスト情報の削除安全に検証する方法実行前の確認コマンドの各部分が何をするのか理解する特に -f, -r, --force などの強制オプションに注意ワイルドカード (*, ?) の展開範囲を確認安全なオプションの利用   # 本当に削除する前に確認   rm -i file  # 対話的に確認      # 実際の変更前にシミュレーション   find . -name "*.tmp" -print  # -deleteの代わりに-printで確認   rsync --dry-run src/ dest/  # 実際のコピーなしでシミュレーションエコーやリダイレクト先の変更   # 危険なコマンドの代わりに同等の安全なコマンドで確認   echo "rm -rf /" # 実行せずに表示      # リダイレクト先を変更   command > /tmp/test.out  # 重要なファイルではなくテスト用ファイルに出力実行前のバックアップ   # 重要なファイルのバックアップ   cp -a important_file important_file.bak安全な実行環境の構築と活用これらのコマンドの違いが分からない場合は、システム環境を破壊してしまう可能性があるため、VM（仮想マシン）やDocker（コンテナ技術）、リモートホストなどの隔離環境を使用しましょう。生成AIが提案するシェルコマンドを実行する際には、潜在的なリスクを軽減するために隔離された安全な環境を利用することが推奨されます。特に未知のコマンドや複雑なワンライナー（1行で記述された複合コマンド）を試す場合は、これらの環境を活用することでメインシステムへの悪影響を最小限に抑えることができます。実用的なシェル芸とAIの活用例AIが提案するシェルコマンドを理解し、自分のニーズに合わせて調整することで、日常の作業を効率化できます。ファイル処理系のシェル芸とAIの活用AIが提案する大量ファイル処理の評価と調整# AIが提案した複雑なファイル名変更コマンドfind . -type f -name "log_*.txt" -exec bash -c 'mv "$1" "${1/log_/archive_}"' _ {} \;# より理解しやすく調整したバージョン# まず対象を確認find . -type f -name "log_*.txt" -print# 安全に実行for file in log_*.txt; do  echo "Renaming $file to ${file/log_/archive_}"  mv "$file" "${file/log_/archive_}"doneAIからの提案を検証して実行する例# AI提案: ディレクトリ内の全HTMLファイルでテキスト置換find . -type f -name "*.html" -exec sed -i 's/oldCompany/newCompany/g' {} \;# 検証方法# 1. まず対象ファイルを確認find . -type f -name "*.html" | wc -l  # 対象ファイル数の確認# 2. 一部のファイルで試すfind . -type f -name "*.html" | head -1 | xargs grep "oldCompany"  # 置換前の確認find . -type f -name "*.html" | head -1 | xargs sed 's/oldCompany/newCompany/g'  # 置換シミュレーション# 3. バックアップしてから実行find . -type f -name "*.html" -exec cp {} {}.bak \;  # バックアップ作成find . -type f -name "*.html" -exec sed -i 's/oldCompany/newCompany/g' {} \;  # 実行テキスト処理系のシェル芸とAIの連携AIが提案するログ解析コマンドの評価# AI提案: 複雑なログ解析コマンドcat access.log | grep -o '"GET [^"]*"' | sed 's/"GET \(.*\)"/\1/g' | sort | uniq -c | sort -nr | head -10# 検証と理解# 1. 段階的に実行cat access.log | head -5  # まずログの形式を確認cat access.log | grep -o '"GET [^"]*"' | head -5  # GETリクエストの抽出確認cat access.log | grep -o '"GET [^"]*"' | sed 's/"GET \(.*\)"/\1/g' | head -5  # パスの抽出確認# 2. 最終結果の解釈# このコマンドは「アクセス数の多いパスTOP10」を表示しているAIと連携したデータ前処理の例# AIにデータを渡す前の前処理# 1. 個人情報をマスクcat data.csv | sed 's/\([0-9]\{3\}\)[0-9]\{4\}\([0-9]\{4\}\)/\1-XXXX-\2/g' > masked_data.csv# 2. 必要な列だけを抽出cat masked_data.csv | awk -F, '{print $1,$3,$5}' OFS=, > processed_data.csv# 3. AIに送るデータのサンプルを確認head -10 processed_data.csv環境変数とエイリアスの理解AIが提案するコマンドには、環境変数やエイリアスを利用したものもあります。これらを正しく理解することで、コマンドの意図や潜在的な問題を把握できます。環境変数の確認と活用# AIが提案する環境変数を使ったコマンドcd $HOME/projects && find . -name "*.py" | xargs grep "TODO"# 検証方法echo $HOME  # HOME変数の値を確認ls -la $HOME/projects  # プロジェクトディレクトリの存在確認AIが提案するエイリアスを安全に設定# AI提案: 便利なエイリアスalias ll='ls -la'alias findgrep='find . -type f -exec grep --color=auto -l "$1" {} \;'# 検証と調整# 関数として定義し直す（引数の扱いが明確）findgrep() {  find . -type f -exec grep --color=auto -l "$1" {} \;}# 使い方の確認type findgrep  # 関数定義を確認findgrep "search term"  # 実行テストジョブ制御と長時間実行コマンドAIはしばしば長時間実行する可能性のあるコマンドを提案します。このようなコマンドを実行する際のジョブ制御を理解しておくことが重要です。長時間実行コマンドの制御# AI提案: 大量ファイルの圧縮find /var/log -type f -name "*.log" | xargs gzip# より安全な実行方法# バックグラウンド実行してログを残すfind /var/log -type f -name "*.log" | xargs gzip > compression.log 2>&1 &echo $! > compression.pid  # プロセスIDを保存# 実行状況の確認ps -p $(cat compression.pid)tail -f compression.log実行中コマンドの管理# 実行中のコマンドの一時停止と再開Ctrl+Z  # 一時停止bg      # バックグラウンドで再開fg      # フォアグラウンドで再開# ジョブの一覧と管理jobs    # 現在のジョブ一覧kill %1  # ジョブ番号1を終了# ログアウト後も実行を継続nohup command &  # ログアウト後も実行継続screen           # 仮想端末での実行tmux             # ターミナルマルチプレクサでの実行ワンライナーの安全性評価と活用法生成AIが提案するワンライナーを安全に活用するためのポイントです。ワンライナーの安全性評価チェックリストワンライナーを実行する前に以下の点をチェックすると安全性が向上します。また、これらが通っているからといって必ず安全というわけではない。破壊的コマンドの有無rm, mv, dd, > (上書きリダイレクト)などのデータを破壊する可能性のあるコマンドが含まれているか例: rm -rf, find ... -delete, sed -i などは特に注意システム全体への影響/, /etc, /bin などの重要なシステムディレクトリに対する操作があるかchmod -R, chown -R などの再帰的な権限変更が含まれているかリソース消費find / など広範囲を検索する処理が含まれているか深い再帰処理や大量のファイル処理による負荷の可能性はあるか特権要求sudo や su などの特権昇格が含まれているか実行に特別な権限が必要なコマンドが含まれているかバックドア・不審なコードcurl | bash のようなインターネットからのスクリプト実行が含まれていないか暗号化されたコードや理解できない難読化された部分が含まれていないかワンライナーを安全に変換する方法# 危険なワンライナーfind / -name "*.bak" -delete# より安全な代替案# 1. プレビューモード: 削除せずに表示のみfind / -name "*.bak" -print# 2. 対話モード: 一つずつ確認find / -name "*.bak" -exec rm -i {} \;# 3. 特定ディレクトリに限定find ~/projects -name "*.bak" -delete# 4. スクリプトに変換して段階的に実行#!/bin/bashecho "次のファイルを削除します:"find / -name "*.bak" -printread -p "続行しますか？ (y/n) " answerif [ "$answer" = "y" ]; then    find / -name "*.bak" -deletefiAIが提案するワンライナーを効果的に活用するコツ理解してから実行: 必ず各部分の意味を理解してから実行する段階的な検証: まず無害なオプションで実行し、結果を確認してから本来の処理を実行コメント付きスクリプトへの変換: 複雑なワンライナーはコメント付きの複数行スクリプトに変換変数の活用: ハードコードされたパスや値を変数に置き換えて柔軟性を高める環境に合わせた調整: 自分の環境に合わせてコマンドを調整するワンライナー活用のベストプラクティススクリプト化して再利用: 有用なワンライナーはスクリプトファイルに保存して再利用エイリアスとして登録: 頻繁に使うワンライナーはエイリアスとして登録   alias finderrors='find . -name "*.log" | xargs grep -l "ERROR"'関数化: 引数を受け取れるようにしてカスタマイズ性を高める   find_errors() {       find . -name "*.$1" | xargs grep -l "$2"   }   # 使用例: find_errors log ERRORバージョン管理: 重要なワンライナーやスクリプトはGitなどで管理ドキュメント化: 複雑なワンライナーは使い方や前提条件をドキュメント化まとめ生成AIがシェルコマンドを提案する時代において、以下のポイントを押さえておくことが重要です。理解してから実行: AIが提案するコマンドを盲目的に実行せず、各部分の意味を理解してから実行する段階的な検証: 複雑なコマンドは部分的に実行して、期待通りの動作をするか確認する危険なコマンドの見極め: システムに重大な影響を与える可能性のあるコマンドを識別できるようにする適切な調整: AIの提案を自分の環境や要件に合わせて調整する能力を身につけるバックアップの習慣: 重要なデータは常にバックアップしてから操作するワンライナーの分解理解: 複雑なワンライナーは各部分に分解して理解するスクリプト化の検討: 複雑なコマンドはスクリプトに変換して読みやすく、再利用可能にするこれらの知識とアプローチを身につけることで、生成AIが提案するシェルコマンドを安全かつ効果的に活用し、作業効率を大幅に向上させることができます。AI時代のシェルコマンド活用は、理解に基づいた適切な判断が鍵となります。生成AIとシェルの組み合わせは非常に強力なツールですが、その力を適切に扱うには基本的な理解が欠かせません。この記事が、皆さんがAIと安全に協働するための一助となれば幸いです。入門 モダンLinux ―オンプレミスからクラウドまで、幅広い知識を会得する作者:Michael Hausenblasオーム社Amazonより詳しく知りたい人はLinuxシステムプログラミング作者:Robert Love,ロバート ラブオライリージャパンAmazon狂人はこちらでお願いします。Linuxプログラミングインタフェース作者:Michael KerriskオライリージャパンAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【スリーシェイク】入社エントリ🥳 🎉]]></title>
            <link>https://zenn.dev/meziron/articles/9d727354b70ecd</link>
            <guid>https://zenn.dev/meziron/articles/9d727354b70ecd</guid>
            <pubDate>Thu, 03 Apr 2025 14:01:57 GMT</pubDate>
            <content:encoded><![CDATA[こんにちは！こんばんは！スリーシェイクにフルスタックエンジニアとして入社して2ヶ月が経ちました、あびまる（釘宮）です。この2ヶ月間、スリーシェイクのカルチャー、メンバーの意識の高さ、そして温かい雰囲気に触れ、非常に充実した日々を送っています。今回は、私が実際に体験したスリーシェイクの魅力について、すこしだけ語らせてください！🙇 会社のカルチャーへの感動まず、会社のカルチャーに深く感銘を受けました。CEO自らが技術発信の重要性を説き、社会のtoil（無駄な作業）をなくすために全力を尽くす姿勢は、非常に刺激的です。✨また、社長との定期的なミーティングでは、プロダクトやサービスの新機...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GTC2025 参加記録　~Keynote~]]></title>
            <link>https://sreake.com/blog/gtc2025-keynote/</link>
            <guid>https://sreake.com/blog/gtc2025-keynote/</guid>
            <pubDate>Mon, 31 Mar 2025 00:26:08 GMT</pubDate>
            <content:encoded><![CDATA[3-shakeのsreake事業部でフルスタックエンジニアとして、主にML周りを担当している赤川です。今回は、サンフランシスコのサンノゼで3/17~3/21に開催されたGTC2025において、NVIDIA CEOのJen […]The post GTC2025 参加記録　~Keynote~ first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Keyball 61にhome row modsを導入した]]></title>
            <link>https://blog.atusy.net/2025/03/31/home-row-mods/</link>
            <guid>https://blog.atusy.net/2025/03/31/home-row-mods/</guid>
            <pubDate>Mon, 31 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[長らくキー配列についてはKeyball61のオレオレマッピングを語るの通りでしたが、加えてhome row modsを導入しました。home row modsは、ホームポジションのasdf（左）とjkl;（右）を押しっぱなしたときに（hold）、CtrlやShiftなどの修飾キーとして機能させる方法論です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[3年目までに身につけたい技術ブログの書き方]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/31/034420</guid>
            <pubDate>Sun, 30 Mar 2025 18:44:20 GMT</pubDate>
            <content:encoded><![CDATA[はじめにあなたは日々、何かを見ている。そう、コードを。エラーを。ドキュメントを。解決策を。そして、それは誰も見ていないものかもしれない。あるいは、多くの人が同じものを見ているのに、誰も記録に残していないのかもしれない。「自分なんてまだ1年目、2年目。経験が浅いから書くことなんてない」そんな思いを抱いていませんか？ しかし、その思い込みは真実ではありません。むしろ、経験の浅さこそが、あなたにしか書けない貴重な視点を生み出します。初めて学ぶ時の困惑、理解するまでの試行錯誤、そして「あ、わかった！」という喜び—これらの生々しい体験は、あなたがまさに今感じているからこそ書ける宝物なのです。「専門家でもないのにブログなんて書けない」「自分の書いたものなんて誰も読まないだろう」という思いも、単なる幻想です。誰もが最初から専門家ではなかった。今あなたが参考にしている記事を書いた人も、最初は不安を抱えながらキーボードに向かったはずです。このブログを書いている私もです。ネット上には膨大な情報があふれていますが、だからこそ、あなたの視点、あなたの言葉、あなたの経験を通して伝えられる情報には価値があります。なぜなら、あなたの記事を必要としている人は、まさにあなたと同じ疑問や課題を持っている人だからです。技術ブログは、完璧な知識や完成された思考を示すためのものではありません。それは思考の過程を記録するものです。完璧を目指すあまり書けなくなるよりも、不完全でも自分の観察と気づきを残していくことに価値があります。自分が躓いたその瞬間こそ、同じ場所で立ち止まっている誰かにとっての地図になる。あなたが苦労して辿り着いた解決策は、未来の誰かの貴重な時間を節約するだけでなく、新たな発見への扉を開くきっかけになるかもしれません。この記事では、技術ブログの種類とその書き方、特に新人エンジニアが取り組みやすいパターンについて解説します。ブログを書く意義、どのようなブログを書けばよいのか、どう書き始めればよいのか、批判されたときにはどうすればよいのかを知ることで、あなたの歩んできた道は他のエンジニアにとって価値ある情報源となり、同時にあなた自身の成長を加速させる強力なツールとなるでしょう。「でも、文章を書くのが苦手で…」「何を書けばいいか分からなくて…」と思っているあなたも、この記事を読み終わる頃には、最初の記事を書くためのアイデアとやる気を手に入れているはずです。さあ、あなたの知識や経験を世界と共有する旅を、一緒に始めましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれると嬉しいです。では、早速はじめていきます。はじめにブログ執筆がもたらす価値思考を整理する鏡知識の共有経済への参加思考の足跡としてのブログ技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記2. バグハント記事3. 環境構築ガイド4. 学んだ教訓記事5. プログラミング言語の乗り換え記録6. システム開発の舞台裏7. 技術トレンドの考察8. 技術の性能比較と検証書き始めるための実践ガイド始めやすいブログパターンの選択日常からネタを発掘する技術読者を惹きつける記事構成読みやすさを高める実践テクニック心地よい技術コミュニケーションのために読み手の感情を大切にする好きなものを中心に語る個人の経験として共有する主観的な表現を心がけるポジティブな内容を中心に批判を柔らかく伝える工夫背景情報を丁寧に説明するもし反発を受けたときの心構え人気記事には批判も付きもの反応せずに見守る勇気を持つコメントの背景を想像してみる誤解には丁寧な補足を時間の流れを味方にするブログ公開の場の選択技術特化型プラットフォーム汎用ブログプラットフォーム自前のブログプラットフォーム選びのアドバイス継続のための現実的なアプローチ小さなハードルから始める自分のための記録として書く「十分に良い」の基準を持つ終わりに本気(マジ)の話ブログ執筆がもたらす価値技術ブログを書く行為には、表面的には見えない多くの価値があります。思考を整理する鏡「説明できることは理解している証拠だ」という言葉があります。コードを書くだけではわからなかった理解の穴が、他者に説明しようとする瞬間に見えてきます。ブログ執筆は自分の思考をクリアにし、知識の定着を促す強力なツールです。ラバーダック・デバッギングがコードの理解を深めるように、ブログはあなたの思考を整理します。知識の共有経済への参加オープンソースのコードを共有するように、あなたの解決策や洞察も共有価値があります。あなたが30分かけて解決した問題は、記事を通じて何百人もの時間を節約するかもしれません。それは単なる善意ではなく、テクノロジー業界の発展に寄与する行為です。思考の足跡としてのブログ定期的に書かれたブログは、あなたの専門性と成長の記録となります。それは履歴書やポートフォリオ以上に、あなたの思考プロセスと問題解決能力を示す生きた証拠になります。自然と「個人ブランド」が形成され、思わぬ機会につながることもあるでしょう。技術ブログの主な種類とその書き方1. 学習ログ＆チュートリアル体験記新人に特におすすめ新しい技術やツールを学んだ過程を記録するブログです。チュートリアルの穴を埋めたり、つまずいたポイントの解決策を共有したりします。書き方のポイント:学習の目的と背景を明確につまずいたポイントと解決法を詳細に公式ドキュメントには書かれていない気づきを強調スクリーンショットやコードスニペットで手順を明確に構成例:学習の動機（なぜこの技術を学ぼうと思ったか）前提知識と環境学習プロセス（つまずいたポイントを含む）得られた気づきと学び次のステップ2. バグハント記事特定のバグや問題を発見し、追跡し、最終的に修正するまでの旅を共有するブログです。書き方のポイント:問題の症状と影響を具体的に調査プロセスを時系列で詳細に（ミステリー小説のように、叙述トリックを使ってもよいですがほどほどに⋯）フレームグラフ、ログ、診断データなどの「証拠」を提示どのような思考プロセスで原因に辿り着いたかを解説最終的な解決策と学んだ教訓構成例:問題の概要（何が起きたか）調査の開始（最初の仮説）探索と証拠収集誤った道と行き止まり（失敗も正直に）原因の特定と理解解決策と検証学んだ教訓と予防策3. 環境構築ガイド開発環境や特定のツールのセットアップ方法を解説するブログです。書き方のポイント:対象読者（初心者か上級者か）を明確に前提条件と必要なツールを明示手順をステップバイステップで説明トラブルシューティングの情報を含める何のためにこの設定をするのかの理由も説明構成例:目的と概要前提条件と必要なものインストール手順（ステップバイステップ）設定と最適化動作確認の方法よくあるトラブルとその解決法4. 学んだ教訓記事プロジェクトや技術的課題から得た教訓や気づきを共有するブログです。書き方のポイント:率直かつ謙虚なトーンで具体的な状況と文脈を提供失敗や間違った判断からの学びを強調他のエンジニアに適用できる一般的な教訓を抽出時系列に沿った「日記的」な構成も有効構成例:状況と背景直面した課題取った行動と判断結果と振り返り学んだ教訓次回への活かし方5. プログラミング言語の乗り換え記録既存のプロジェクトを新しいプログラミング言語やフレームワークで作り直した経験を共有するブログです。書き方のポイント:言語やフレームワークを変更した理由を分かりやすく説明古い言語と新しい言語の違いと比較移行作業で苦労した点とその解決方法処理速度や保守のしやすさの比較結果言語の乗り換えから学んだこと構成例:現状と移行の動機技術選定と比較検討移行戦略と計画実装の詳細と課題成果と比較（ビフォー・アフター）学んだ教訓と今後の展望6. システム開発の舞台裏システムや機能をどのように考え、設計し、作り上げたかを詳しく説明するブログです。書き方のポイント:システムの目的と必要な機能を明確に設計で迷った点や判断した理由を説明全体の構造を図や図解でわかりやすく重要なコードの部分とその役割の解説ぶつかった壁とその乗り越え方今後の改善点や拡張できる部分構成例:プロジェクトの背景と目標要件と制約条件設計の選択肢と検討プロセス選んだアーキテクチャとその理由実装の重要ポイント課題と解決策結果と評価7. 技術トレンドの考察IT業界の流行りや新しい技術の動きについて、自分なりの意見や分析を述べるブログです。書き方のポイント:堅固な論拠と証拠で意見を裏付ける単なる批判ではなく、建設的な視点を提供自分の経験に基づいた具体例を含める複数の視点を考慮し、バランスの取れた議論を展開明確な結論と、読者が検討すべきポイントを提示構成例:トレンドの概要と背景現在の状況分析メリットとデメリット実務への影響と適用性自分の見解と予測実践的なアドバイス8. 技術の性能比較と検証異なる技術や方法の速度や効率を実際に測って比較し、その結果を共有するブログです。書き方のポイント:テスト方法と環境を詳細に記述公平で再現可能なベンチマーク手法を使用データを明確に視覚化（グラフ・表）結果の解釈と実用的な意味を説明限界と注意点も正直に伝える読者が検証できるようコードや手順を共有構成例:テストの目的と背景検証環境とセットアップテスト方法と条件結果の提示と分析発見と考察実用的な示唆と推奨事項書き始めるための実践ガイド始めやすいブログパターンの選択新人エンジニアが最初に挑戦しやすいのは、自分の直接体験に基づいた記事です。特に以下のパターンは、書きやすく読者にも価値を提供しやすい傾向があります。学習ログ＆チュートリアル体験記 - 公式ドキュメントには書かれていない「実際にやってみたらどうだったか」の記録は、後続の学習者にとって貴重な情報源になります。また、英語のチュートリアルを日本語でやってみるだけでも大きな価値があります。環境構築ガイド - 一度苦労して設定した開発環境の手順は、記録しておくだけで大きな価値があります。読者や半年後の自分も、同じ苦労をせずに済むでしょう。バグハント記録 - 解決に時間がかかった問題は、その過程を含めて記録する価値があります。デバッグの思考プロセスこそが、技術的な洞察を含んでいます。学びの教訓 - 「〜だと思っていたけど、実際は違った」という気づきは、技術記事として非常に価値があります。誤解やミスコンセプションを正す内容は、多くの人の時間を節約します。日常からネタを発掘する技術記事のアイデアは日々の業務や学習の中に隠れています。以下の視点で日常を観察してみましょう。学習過程での「なぜ？」、理解するのに時間がかかった概念や、直感に反する仕様は、記事になりやすいトピックです。繰り返し説明していること、チーム内で何度も同じ説明をしている内容は、記事化する価値が高いでしょう。検索しても満足な答えが見つからなかった問題、そのような問題を解決できたなら、あなたと同じ検索をする誰かのために記録を残しましょう。「あれ？」と思った瞬間、予想通りに動かなかったコード、意外な挙動を示したツール、これらの「あれ？」の瞬間は、貴重な記事の種です。このような日常の発見からブログネタを見つける考え方は、ジェームス・W・ヤングの名著『アイデアのつくり方』に私の考え方は近いです。ヤングによれば、アイデアとは既存の要素の新しい組み合わせであり、その才能は事物の関連性を見つけ出す力に依存しています。ヤングが提唱する5段階のアイデア創出プロセスは、技術ブログ執筆にも応用できます。資料を収集する - 特定のテーマに関する専門知識と、幅広い一般知識の両方を集める資料を噛み砕く - 集めた情報を様々な角度から検討し、関係性を探る問題を放棄する - 一度意識的な思考から離れ、無意識に働かせるアイデアが訪れる - 何気ない日常の瞬間（シャワー中やトイレなど）に閃きが生まれるアイデアを現実に連れ出す - 閃いたアイデアを忍耐強く形にするあなたの「あれ？」という瞬間は、ヤングの創造プロセスの一部として考えることができます。まず資料収集の段階で日々の開発や、読書、学習から知識を蓄え（第1段階）、それらの情報を頭の中で検討し関連付けようとし（第2段階）、一度問題から離れて無意識に働かせ（第3段階）、そして「あれ？」という気づきや閃きが訪れるのです（第4段階）。この瞬間を逃さず記録し、丁寧に育てて記事として形にしていく作業が最終段階（第5段階）となります。日々の疑問や発見を意識的に記録する習慣をつけることで、ヤングのプロセスを体現し、貴重なブログの種を蓄積できるでしょう。「ブログが書けない」と悩んでいるほとんどの人は、この5段階のプロセスのどこかが欠如していることがほとんどです。そして、どの段階が欠如しているかによって、対応方法が大きく変わります。資料収集が不足している人には、まずは情報のインプットを増やすことが重要です。技術書を読む、オンラインコースを受講する、技術カンファレンスの動画を見るなど、様々な方法で知識の幅を広げましょう。また、特定の技術だけでなく、隣接分野や全く異なる分野の知識も取り入れることで、独自の組み合わせが生まれやすくなります。情報の噛み砕きが不足している人には、学んだことをノートにまとめる、同僚に説明する、図解してみるなどの方法がおすすめです。具体化したり抽象化したりするのもおすすめです。情報を受動的に受け取るだけでなく、自分の言葉で咀嚼し直すことで、新たな気づきが生まれやすくなります。リラックスの時間が不足している人には、意識的に「何も考えない時間」を作ることが大切です。常に問題解決モードでは、無意識の働きが活かせません。散歩する、お風呂に浸かる、瞑想するなど、頭を空っぽにできる時間を日常に取り入れましょう。閃きを見逃している人には、スマートフォンのメモアプリやノートを常に持ち歩き、思いついたことをすぐに記録する習慣をつけることをおすすめします。閃きは突然訪れ、すぐに消えてしまうものです。「あとで覚えておこう」と思っても、ほとんどの場合は忘れてしまいます。書ききれない人には、「まずは15分だけ書く」という小さなハードルから始めることをおすすめします。完璧な記事を目指すのではなく、とにかく書き始めること。編集や推敲は後からでも可能ですが、書かれていない文章は編集のしようがありません。また、締め切りを設定したり、書き始める時間と場所を決めておくなど、環境を整えることも効果的です。あなたがブログを書けない理由がどの段階にあるのかを特定することで、より効果的な対策を講じることができるでしょう。アイデアのつくり方作者:ジェームス W.ヤングCCCメディアハウスAmazon読者を惹きつける記事構成技術ブログも、読者が最後まで読みたくなる構成が重要です。以下のような流れを意識すると、読みやすい記事になります。問題提起 - なぜこの記事を書いたのか、読者にとってどんな価値があるのかを明確にします。最初の段落で「この記事を読むことで解決できる問題」を具体的に示すことで、読者の興味を引きつけましょう。「〜に悩んでいませんか？」「〜をもっと効率的にしたいと思いませんか？」といった形で読者の課題に共感を示すと効果的です。ただし、単なるクリックベイト的な見出しや過度な約束は避け、記事の内容と一致した誠実な問題提起を心がけましょう。コンテキスト - あなたの環境や前提条件を説明し、読者が自分の状況と比較できるようにします。「私がこの問題に取り組んだ時の状況はこうでした」と具体的に共有することで、読者は自分のケースとの類似点や相違点を理解できます。使用した技術のバージョン、ハードウェア環境、チームの規模、プロジェクトの背景など、関連する情報を提供しましょう。これにより、読者は記事の内容が自分にとって適用可能かどうかを判断できます。コンテキストが明確であればあるほど、読者は安心して読み進められます。探求の旅 - 単なる解決策ではなく、そこに至るまでの思考プロセスを共有することで、読者は深い理解を得られます。最初に考えたアプローチ、試した方法、直面した課題、そしてなぜ最終的な解決策にたどり着いたのかを時系列で説明しましょう。失敗したアプローチも含めて正直に共有することで、記事の信頼性が高まり、読者も同じ失敗を避けられます。「最初はAという方法を試みましたが、Bという問題に直面したため、Cというアプローチに切り替えました」といった形で、あなたの試行錯誤のストーリーを語ることで、記事に人間味と深みが加わります。発見と学び - 技術的な発見だけでなく、アプローチ方法についての洞察も含めましょう。「この経験から学んだ最も重要なことは〜です」と明確に示すことで、読者は記事の本質的な価値を理解できます。コードやシステムの改善点だけでなく、問題解決プロセス、チーム協力、技術選定の基準など、より広い文脈での学びを共有すると、記事の応用範囲が広がります。特に、「意外だったのは〜」「常識と違ったのは〜」といった予想外の発見は強調する価値があります。こうした「目から鱗」の瞬間は、読者にとって最も記憶に残る部分となるでしょう。次のステップ - 読者が更に探求できるように、参考資料や発展的な内容へのリンクを提供します。「もっと詳しく知りたい方はこちらの資料がおすすめです」「次のステップとして〜を検討するとよいでしょう」といった形で、読者の学習旅行の次の目的地を示唆しましょう。また、未解決の課題や将来の展望についても正直に触れることで、読者との対話を促すことができます。「現在はまだ〜という課題が残っていますが、今後は〜のアプローチを試してみる予定です」といった形で、完璧な解決策だけでなく、進行中の探究であることを示すと、より現実的で共感を得られる記事になります。読みやすさを高める実践テクニック技術的な内容を伝える際、読みやすさは極めて重要です。以下のテクニックを活用して、読者が最後まで読み進められる記事を目指しましょう。最初の3行で読者を掴む - 記事の冒頭3行は、読者が「続きを読むか」を決める重要な部分です。問題提起や具体的な価値を示し、興味を引く導入を心がけましょう。「この記事を読むと〜ができるようになります」「あなたも経験したことがあるかもしれませんが、〜という問題は実は〜で解決できます」といった書き出しが効果的です。ただし、注意点として、技術ブログでは大言壮語や過度な主張（「これが唯一の正しい方法だ」「これさえ知れば全てが解決する」など）は避けるべきです。断定的な表現は炎上リスクを高め、読者の信頼を損なう恐れがあります。「私の経験では」「この特定の状況では」といった限定的な表現を使い、バランスを保ちましょう。見出しを上手に使う - 大見出しと小見出しで内容を整理し、ざっと見ただけでも内容がつかめる構造にします。見出しは「目次」としての役割を持ち、読者が求める情報に素早くアクセスするための道標となります。見出しには具体的な内容や得られるメリットを含めると、さらに効果的です。例えば「実装方法」よりも「3ステップで実装できるシンプルな方法」の方が読者の興味を引きます。また、見出しの階層構造は3段階程度に抑え、整理された印象を与えましょう。長い文章は小分けに - 長い文章が続くと読者は疲れます。適度に区切って、読者が「ここまで読めた」と小さな達成感を得られるようにします。段落は1つの考えにつき1つにし、3〜5行程度を目安にするとよいでしょう。また、読みやすさを高めるために、箇条書きや番号付きリストを活用して情報を整理しましょう。さらに、重要なポイントには太字や斜体などの強調を適切に使い、視覚的なメリハリをつけることで、スキャンしやすくなります。ただし、強調の使いすぎは逆効果なので、本当に重要な部分だけに留めるのがコツです。コードと説明文のバランス - 長すぎるプログラムコードは避け、重要な部分だけを取り出して、それに説明を加えましょう。コードブロックの前には「何をするコードなのか」、後には「なぜそのように実装したのか」「どのような効果があるのか」を説明すると理解が深まります。また、複雑なコードは徐々に構築していく形で示すと良いでしょう。初めに基本形を示し、段階的に機能を追加していくアプローチは、特に初心者にとって理解しやすい方法です。コメントを適切に挿入することも効果的ですが、コード自体が説明的であることを心がけましょう。具体例と全体像を交互に - 具体的なコード例と、そこから学べる一般的な教訓を交互に示すことで、理解が深まります。「木を見て森も見る」アプローチで、読者は個別の実装詳細と、それがどのように大きな概念に適合するかを同時に理解できます。例えば、特定のパターンの実装例を示した後、「このパターンが特に有効なのは〜のような状況です」と一般化すると、読者は自分の状況への応用がしやすくなります。逆に、原則や概念を先に説明してから具体例で補強する方法も効果的です。両方のアプローチを記事内で使い分けると、多様な学習スタイルの読者に対応できます。視覚的要素を活用する - 複雑な概念や関係性は、文章だけでなく図やダイアグラム、スクリーンショットで説明すると理解が格段に向上します。特に、システムアーキテクチャやデータフロー、アルゴリズムの流れなどは視覚化が効果的です。図は装飾ではなく情報を伝える手段として使い、適切なキャプションを付けることで文脈を明確にしましょう。また、長い記事では適度に図を挿入することで、読者に視覚的な休息も提供できます。図の作成には専門的なツールは必ずしも必要なく、シンプルな図であれば手書きスケッチをスキャンしたものでも十分に価値があります。読者の知識レベルを想定する - 対象とする読者層の知識レベルを想定し、それに合わせた説明の詳しさを調整しましょう。初心者向けの記事では基本概念から丁寧に説明し、上級者向けには深い技術的洞察や最適化のポイントに焦点を当てます。どちらの場合も、前提知識を記事の冒頭で明確にしておくと、読者は自分に適した内容かどうかを判断できます。「この記事はXYZの基本を理解している方を対象としています」といった一文を入れるだけでも効果的です。また、専門用語を使う場合は、初出時に簡単な説明を加えるか、リンクで参照先を示すと親切です。余韻を残す結びで読者の思考を広げる - 優れた技術ブログは、単に情報を伝えるだけでなく、読後に読者の思考を広げるものです。結びのパートでは、説明した技術の将来性や発展の可能性、異なる文脈での応用例などに軽く触れておくと、読者は記事を閉じた後も考え続けるきっかけとなります。「この技術は〜の領域でも応用できるかもしれません」「今回紹介した手法をさらに発展させると、どのような可能性が開けるでしょうか」といった問いかけは、読者の創造性を刺激し、自分なりの解釈や発展を考える余韻をもたらします。また、「私自身はこの技術と出会って、〜という視点が変わりました」のような個人的な洞察や、技術の社会的意義に触れることで、読者に新たな気づきや内省の機会を提供できます。心地よい技術コミュニケーションのために技術ブログを書くとき、単に知識を共有するだけでなく、読み手がどう感じるかに気を配ることも大切です。思慮深いコミュニケーションは、あなたのメッセージをより効果的に伝え、建設的な対話を生み出します。以下の考え方を意識することで、知識共有の質を高め、不要な論争を避けることができるでしょう。読み手の感情を大切にする書いた内容が誰かを傷つけていないか考えてみましょう。「この書き方だと、誰かが自分を批判されていると感じるかも」と想像することが大切です。例えば、ある技術について「この方法は時代遅れだ」と書くより、「私の用途ではこの新しい方法がうまく機能しました」と表現する方が、読み手の心を開いたままにします。技術選択は多くの場合、状況やニーズに依存するものであり、一概に優劣をつけられないことを認識しましょう。好きなものを中心に語るあなたが好きな技術や方法について熱く語りましょう。何かを批判するよりも、自分が価値を見出しているものについて語る方が、読者との良い関係を築けます。「Aは問題だらけだがBは素晴らしい」ではなく、「Bのここが素晴らしい」と伝えるだけで十分です。英語圏でよく使われる「not for me」（これは私には合わない）という表現は、技術ブログでも有効です。これは「悪い」というわけではなく、単に「私の状況や好みには合わない」という意味を含んでいるからです。個人の経験として共有する「すべてのエンジニアは〜すべきだ」「この業界では〜が常識だ」といった広い主語での断言は避けましょう。代わりに「私の経験では」「私のチームでは」と限定して話すことで、意見の押し付けにならず、経験の共有として受け取ってもらえます。それでも強引に批判してくる人はいます。そういう人はそもそもめちゃくちゃに批判したくてその構成が目の前に存在しているからめちゃくちゃに言ってくるのですが、日本語をちゃんと読めない人を相手にする必要はありません。あなたの経験を共有する権利は誰にも奪われないのです。主観的な表現を心がける「これは正しい方法だ」「あれは間違っている」という価値判断ではなく、「私はこの方法が好きです」「私の場合はこちらの方法が合っていました」という表現にすることで、異なる意見の人も受け入れやすくなります。私たちはみな異なる状況で働いており、一つの正解があるわけではないことを認識しましょう。特に技術の世界では、同じ問題に対しても多様なアプローチが存在することを尊重することが重要です。ポジティブな内容を中心に問題点や不満よりも、解決策や学びを中心に書きましょう。ネガティブな内容は同様にネガティブな反応を呼びがちです。「〜が使いにくい」より「こうすると〜がもっと使いやすくなりました」という表現の方が、建設的な対話につながります。あなたが困難を乗り越えた経験は、その過程で学んだことと共に共有することで、より価値のある情報になります。批判を柔らかく伝える工夫どうしても批判的な内容を書く必要があるときは、批判の対象をぼかしたり、自分の失敗談を交えたりすることで、攻撃的に見えるのを避けられます。「私も以前は〜と思っていましたが、実際にやってみると〜だとわかりました」といった表現なら、相手の反感を買いにくくなります。また、批判する際も建設的な代替案を提示することで、単なる不満ではなく有益なフィードバックとして受け取られやすくなります。背景情報を丁寧に説明する「これはこういう状況での話です」「私はこういう前提で考えています」と背景を明確にすることで、誤解を防げます。普通に人と喋っている時は省略するかもしれない文脈の紹介も技術ブログを書く時には必要です。誤読する余地を可能な限り減らします。特に技術的な主張をするときは、あなたの環境や条件を明示することで、「それは特定の状況下での話だね」と理解してもらいやすくなります。使用しているハードウェア、ソフトウェアのバージョン、チームの規模、プロジェクトの性質など、具体的な情報を提供することで、読者はあなたの経験を適切に文脈化できます。もし反発を受けたときの心構えどれだけ配慮して書いても、時には予想外の反応を受けることがあります。インターネット上での議論は時に感情的になりがちです。正直なところ、批判されたときの最初の感情は「なんでこんなこと言われなきゃいけないんだ」という怒りや落胆でしょう。そんな感情は自然なものですし、一時的に落ち込んだり、イラっとしたりするのも当然です。でも、そんなときに役立つ考え方をいくつか紹介します。人気記事には批判も付きもの多くの人に読まれるブログには、様々な価値観を持つ人が訪れます。あなたの意図とは関係なく、一定数の批判的なコメントが寄せられるのは自然なことです。人気の証と考えて、あまり気にしすぎないようにしましょう。実際、最も影響力のある技術記事でさえ、必ず反対意見や批判があります。これは多様な視点が存在することの健全な証でもあります。反応せずに見守る勇気を持つ批判的なコメントを見ると、すぐに反論したくなるものです。正直に言えば、「このバカ！ちゃんと記事を読め！」と思うこともあるでしょう。そんな感情を持つのは自然なことです。しかし、インターネット上での議論は感情的になりやすく、さらなる誤解を生むことも。多くの場合、反応しないことが最も賢明な選択です。キーボードから離れて深呼吸し、「本当に返信する価値があるか」を冷静に考えてみましょう。時間が経てば自然と収まることが多いものです。たまには筆を折って、「今日はもうネットを見ない日」を作るのも立派な対処法です。コメントの背景を想像してみる批判的なコメントを残す人の他の発言を見てみると、多くの場合、その人自身の傾向が見えてきます。常に批判的なコメントを残している人もいれば、特定のトピックに強い感情を持っている人もいます。「これはその人の反応パターンなのだ」と理解すれば、個人的な攻撃と受け取らずに済みます。時には「この人、今日はどうしたんだろう？仕事で嫌なことでもあったのかな？」と想像してみるのも手です。多くの批判的コメントは、あなたの記事そのものよりも、コメントした人のその日の気分や状況から生まれていることもあるのです。批判的なコメントをパブリックな場に書く人のほとんどは想像力が欠如しているのでその言葉で他人が傷つくということをほとんど何も考えていないです。実際に会うと優しかったりもします。でも、親切にスルーすることが、時には最大の優しさかもしれません。誤解には丁寧な補足を明らかな誤解に基づいた批判が多い場合は、記事に追記や修正を加えるのが効果的です。「追記：いくつかコメントをいただき、この点が誤解を招いているようなので補足します」といった形で、丁寧に説明すると良いでしょう。個別のコメントに反論するよりも、記事自体を改善する方が建設的です。これは読者全体にとっても価値があり、あなた自身の成長にもつながります。時間の流れを味方にするインターネット上の話題は移り変わりが早いものです。今日の論争も、明日には忘れられていることがほとんどです。一時的な批判に過度に反応するよりも、次の記事作成に前向きに取り組む方が、長期的には実りある選択となるでしょう。実際に「nwiizoさんの記事は役に立ちました」と声をかけられることはあっても、「お前の記事はクソだぞ」と直接言ってくる人は珍しいものです(私もそれぐらい強烈な論を発したいものです)。批判は匿名の場で、称賛は直接あなたに届くという不思議な法則があります。そして、真っ当な批判からは学び、感情的な批判は「私はそれだけの反応を引き出せるだけの影響力を持っているんだ」と前向きに捉える余裕を持ちましょう。ブログ公開の場の選択ブログを書く場所の選択は、思っているより重要な決断です。それぞれの場には一長一短があり、あなたの目的によって最適な選択肢は異なります。技術特化型プラットフォーム技術者向けのプラットフォームは、すでに技術に興味のある読者が集まっているという利点があります。初めから技術的な話題を求めている読者にリーチしやすく、専門的な議論が生まれやすい環境です。一方で、プラットフォームのルールやコミュニティの雰囲気に合わせる必要があり、自由度はやや制限されます。また、特定の技術コミュニティでは賛否両論が起きやすいトピックもあります。汎用ブログプラットフォームより幅広い読者層にアクセスできる汎用プラットフォームは、技術と非技術の境界領域の話題に適しています。テクニカルな内容を非エンジニアに伝えたい場合や、キャリアや働き方など、技術に付随する話題を扱いたい場合に向いています。ただし、深く技術的な内容は響く読者が少なく、反応が薄くなる可能性もあります。自前のブログ自分のドメインで運用するブログは、完全な自由度とブランディングの利点があります。長期的に見れば最も資産価値が高く、あなたのキャリアと共に育てていけるものになります。しかし、読者を集めるための工夫や継続的なメンテナンスが必要で、特に始めたばかりの頃は「誰も読んでいない」という状況に直面することも。SEO対策やSNSでの拡散など、追加の努力が求められます。プラットフォーム選びのアドバイス最初は低いハードルで始められる技術特化型プラットフォームでスタートし、書く習慣が身についてきたら自前のブログも並行して運用するというアプローチが現実的です。どのプラットフォームを選ぶにしても、コンテンツの所有権やエクスポート機能について確認しておくことをお勧めします。いつか別の場所に移行したいと思ったとき、あなたの資産を持ち出せるかどうかは重要な要素です。継続のための現実的なアプローチ技術ブログを一度書くことは難しくない。難しいのは書き続けることだ。以下は実践的な継続のコツだ。小さなハードルから始めるブログ執筆を習慣化するには、負荷を最小限に抑えることが重要です。月1回、あるいは四半期に1回といった現実的な頻度設定から始めましょう。15分でも執筆時間を確保できれば、少しずつ文章は成長していきます。無理な目標設定はモチベーションを消耗させるだけです。自分のための記録として書く「誰も読まないかもしれない」という恐れは、「自分のための記録」という視点で克服できます。将来の自分が参照するための記録として書けば、読者がゼロでも価値があります。実際、多くの技術ブログは、書き手自身が後日参照することで最大の価値を発揮します。「十分に良い」の基準を持つ完璧主義はブログ執筆の最大の敵です。「もっと調査が必要」「もっと洗練された文章にしたい」という思いは尽きませんが、公開されない記事に価値はありません。80%の完成度で公開する勇気を持ちましょう。改善はいつでもできます。このブログも80％ぐらいの完成度で公開してます(本当に)。終わりに技術の世界では、私たちは常に何かの「初心者」であり続けます。むしろ「初心者」であるべきです。新しい言語、新しいフレームワーク、新しいパラダイム—学びに終わりはありません。ベテランエンジニアでさえ、新技術の前では「初心者」に戻るのです。だからこそ、どの経験レベルの視点も価値があります。思い出してみてください。あなたが最初にプログラミングを学んだ時の興奮を。新しいフレームワークに触れた時の発見の喜びを。バグを解決した時の達成感を。これらはすべて、記録する価値のある体験です。そして、どの瞬間においても、あなたの「今」の視点は誰かにとって貴重な道標になります。完璧なブログではなく、あなたの観察と経験を率直に記録したブログこそが、同じ道を歩む誰かの力になるのです。いま書き始めることで、あなたは単なる技術の消費者から、コミュニティに貢献する創造者へと変わることができます。ブログは、知識の完成形を示すものではなく、思考の過程を記録するものです。あなたの躓きと発見の記録が、誰かの旅路を照らす灯になるでしょう。そして、その灯は時間が経っても消えることなく、未来の誰かを導き続けます。書くことで得られるのは、他者への貢献だけではありません。自分自身の思考を整理し、知識を定着させ、キャリアを形作っていく力にもなります。数年後、あなたが書いた記事の蓄積を振り返った時、そこには自分の成長の軌跡が鮮明に記録されているでしょう。継続のコツは「完璧を目指さない」ことです。まずは短く、1回15分でも書ける小さなテーマから始めましょう。また、定期的に書く習慣をつけるために、特定の曜日や時間帯を決めておくと効果的です。そして何より、自分自身が「書いていて楽しい」と感じられるトピックを選ぶことが長続きの秘訣です。技術ブログの世界では、読者からのフィードバックが得られることも大きな魅力です。あなたの記事に寄せられたコメントや質問から、新たな気づきを得ることもあるでしょう。それは、一人では辿り着けなかった視点や解決策との出会いかもしれません。今日から始めてみませんか？ 最初は小さな記事でいいのです。今週解決した問題について、新しく学んだツールの使い方、チームでの取り組みから得た気づき、読んだ技術書の要点と感想、あなたのチームが採用している開発プロセス、先輩から学んだテクニックなど、あなたの日常には書くべき価値のあるトピックがきっと溢れています。あなたの最初の記事は、誰かの最初の一歩を助ける光となるかもしれません。そして、書き続けることで、あなた自身も技術の世界でより深く、より遠くまで進んでいけるでしょう。書き始めることに価値があります。あなただけの観察眼で捉えた技術の風景を、今日から記録してみませんか。その一歩が、あなたのキャリアと技術コミュニティの未来を、より豊かなものにするはずです。「誰かのために書く」のではなく、「自分のために書き始め、結果として誰かの役に立つ」—これが、技術ブログの本当の姿だと思っています。さあ、あなたの最初の記事を、今週ぐらいに書いてみませんか？プリンシプル オブ プログラミング 3年目までに身につけたい 一生役立つ101の原理原則作者:上田勲秀和システムAmazon本気(マジ)の話これは本気で言っているのですが今回は流石にめちゃくちゃに良いブログだと思うので欲しいものリストを公開します。www.amazon.jp]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[gopass を使ってパスワード共有を試す]]></title>
            <link>https://blog.1q77.com/2025/03/share-password-using-gopass/</link>
            <guid>https://blog.1q77.com/2025/03/share-password-using-gopass/</guid>
            <pubDate>Sat, 29 Mar 2025 00:57:32 GMT</pubDate>
            <content:encoded><![CDATA[gopass とはPostgres Weekly を眺めていて Creating Postgres Roles with Passwords Stored in Gopass という記事で gopass というものの存在を知りました。名前から分かるように Go 言語で書かれており、マルチプラットフォームのパスワード管理用コマンドラインツールです。GPG を使って暗号化し、Git で管理します。GPG の公開鍵暗号を使って複数人で複合することが可能になっており、任意の人とパスワードを共有することが可能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Fish 4のabbrはサブコマンドも展開できるぞ]]></title>
            <link>https://blog.atusy.net/2025/03/29/fish-4-abbr/</link>
            <guid>https://blog.atusy.net/2025/03/29/fish-4-abbr/</guid>
            <pubDate>Sat, 29 Mar 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Fishのabbr使ってますか？aliasの強化版といった感じで、短縮した入力をスペースやエンターと共に本来のコマンドに展開してくれる機能です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリのサンプルコードから学ぶ活用法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/28/132800</guid>
            <pubDate>Fri, 28 Mar 2025 04:28:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに前回の「Rust製MCPライブラリの内部実装を徹底解析」では、Model Context Protocol (MCP) のRust SDKの内部実装について詳しく解説しました。今回は、その続編として、examples/ディレクトリに含まれるサンプルコードを詳しく見ていきます。github.comMCPを実際のプロジェクトで活用するためには、抽象的な実装だけでなく、具体的な使用例を理解することが重要です。このブログでは、クライアント実装、サーバー実装、マクロの使用例を通じて、MCPの実践的な活用方法を学び、実際に自分で実装できるようになることを目指します。概念が分からない人や自分の他のブログを読みたいくない人はこちらのドキュメントを一読してから読んでほしいです。modelcontextprotocol.ioexamples/の全体構造MCPのRust SDKには豊富なサンプルが含まれています。examples/ディレクトリは以下のような構成になっています。examples/├── clients/        # クライアント実装例├── servers/        # サーバー実装例├── transport/      # トランスポート実装例├── rig-integration/ # Rigフレームワークとの統合例├── wasi/           # WebAssembly実装例└── README.md       # サンプルの概要それぞれのディレクトリには、特定のユースケースに焦点を当てたサンプルコードが含まれています。これらのサンプルは、MCPの様々な機能や統合シナリオを理解するのに役立ちます。クライアント実装例examples/clients/ディレクトリには、MCPクライアントの様々な実装例が含まれています。これらの例を通じて、異なるシナリオでのMCPクライアントの使い方を学びましょう。基本的なクライアント実装: std_io.rs最も基本的なクライアント実装例はstd_io.rsです。このサンプルは標準入出力を使用してMCPサーバーと通信します。use anyhow::Result;use rmcp::{model::CallToolRequestParam, service::ServiceExt, transport::TokioChildProcess};use tokio::process::Command;use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| format!("info,{}=debug", env!("CARGO_CRATE_NAME")).into()),        )        .with(tracing_subscriber::fmt::layer())        .init();        // 子プロセスとしてMCPサーバーを起動し、サービスを作成    let service = ()        .serve(TokioChildProcess::new(            Command::new("uvx").arg("mcp-server-git"),        )?)        .await?;    // サーバー情報の取得    let server_info = service.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // 利用可能なツールの一覧取得    let tools = service.list_tools(Default::default()).await?;    tracing::info!("Available tools: {tools:#?}");    // ツールの呼び出し    let tool_result = service        .call_tool(CallToolRequestParam {            name: "git_status".into(),            arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),        })        .await?;    tracing::info!("Tool result: {tool_result:#?}");        // クライアントの終了    service.cancel().await?;    Ok(())}この例での主要な要素を解説します。#[tokio::main]マクロ: Rustの非同期ランタイムを初期化し、非同期コードを実行できるようにします。TokioChildProcess: 子プロセスとしてMCPサーバーを起動するためのトランスポート実装です。この例では「uvx mcp-server-git」コマンドを実行しています。serveメソッド: トランスポートを使ってサービスを初期化するメソッドです。RustのServiceExtトレイトが提供する拡張機能です。call_toolメソッド: 特定のツールを呼び出すメソッドです。CallToolRequestParam構造体を使ってツール名と引数を指定します。SSEトランスポートの使用: sse.rs次に、Server-Sent Events (SSE) トランスポートを使用する例を見てみましょう。これはWebアプリケーションとMCPを統合する際に特に有用です。use anyhow::Result;use rmcp::model::{ClientCapabilities, ClientInfo, Implementation};use rmcp::{ServiceExt, model::CallToolRequestParam, transport::SseTransport};use tracing_subscriber::layer::SubscriberExt;use tracing_subscriber::util::SubscriberInitExt;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化（省略）...    // SSEトランスポートの作成と接続    let transport = SseTransport::start("http://localhost:8000/sse").await?;        // クライアント情報の定義    let client_info = ClientInfo {        protocol_version: Default::default(),        capabilities: ClientCapabilities::default(),        client_info: Implementation {            name: "test sse client".to_string(),            version: "0.0.1".to_string(),        },    };        // クライアントの作成    let client = client_info.serve(transport).await?;    // サーバー情報の取得    let server_info = client.peer_info();    tracing::info!("Connected to server: {server_info:#?}");    // ツール一覧の取得（省略）...    // ツールの呼び出し（省略）...        // クライアントの終了    client.cancel().await?;    Ok(())}このサンプルの特徴的な点は：SseTransport: HTTP経由でMCPサーバーと通信するためのトランスポート実装です。長時間接続を維持し、サーバーからのイベントを受信します。ClientInfo: クライアントに関する情報をサーバーに提供する構造体です。名前やバージョン、プロトコル互換性などの情報が含まれます。複数クライアントの管理: collection.rs複数のMCPクライアントを効率的に管理する例も含まれています。use std::collections::HashMap;use anyhow::Result;use rmcp::service::ServiceExt;use rmcp::{model::CallToolRequestParam, transport::TokioChildProcess};use tokio::process::Command;#[tokio::main]async fn main() -> Result<()> {    // ログ初期化は省略...    // 複数クライアントの作成    let mut client_list = HashMap::new();    for idx in 0..10 {        let service = ()            .into_dyn()            .serve(TokioChildProcess::new(                Command::new("uvx").arg("mcp-server-git"),            )?)            .await?;        client_list.insert(idx, service);    }    // 各クライアントの使用    for (_, service) in client_list.iter() {        // サーバー情報の取得        let _server_info = service.peer_info();        // ツール一覧の取得        let _tools = service.list_tools(Default::default()).await?;        // ツールの呼び出し        let _tool_result = service            .call_tool(CallToolRequestParam {                name: "git_status".into(),                arguments: serde_json::json!({ "repo_path": "." }).as_object().cloned(),            })            .await?;    }        // クライアントのクリーンアップ    for (_, service) in client_list {        service.cancel().await?;    }    Ok(())}この例では、複数のMCPクライアントを作成し、それぞれに対して操作を実行しています。実際のアプリケーションでは、異なるサーバーに接続する複数のクライアントを管理する場合に役立ちます。サーバー実装例examples/servers/ディレクトリには、様々なMCPサーバー実装例が含まれています。ここでは、基本的なサーバー実装と、Webフレームワークとの統合例を見ていきます。基本的なサーバー実装: std_io.rs最もシンプルなサーバー実装はstd_io.rsです。このサンプルは、標準入出力を使用してクライアントとやり取りする基本的なMCPサーバーを実装しています。use anyhow::Result;use common::counter::Counter;use rmcp::{ServiceExt, transport::stdio};use tracing_subscriber::{self, EnvFilter};mod common;#[tokio::main]async fn main() -> Result<()> {    // ロギングの初期化    tracing_subscriber::fmt()        .with_env_filter(EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()))        .with_writer(std::io::stderr)        .with_ansi(false)        .init();    tracing::info!("Starting MCP server");    // Counterサービスを作成し、標準入出力トランスポートで提供    let service = Counter::new().serve(stdio()).await?;    // クライアントからの要求を待機    service.waiting().await?;    Ok(())}このサンプルはシンプルですが、重要な要素がいくつか含まれています。Counter型: これはカウンターサービスを提供するサーバーハンドラの実装です。stdio(): 標準入出力をトランスポートとして使用するための関数です。waiting()メソッド: サーバーがクライアントからの要求を待機するためのメソッドです。次に、Counter型の実装を見てみましょう：use std::sync::Arc;use rmcp::{    Error as McpError, RoleServer, ServerHandler, const_string, model::*, schemars,    service::RequestContext, tool,};use tokio::sync::Mutex;#[derive(Clone)]pub struct Counter {    counter: Arc<Mutex<i32>>,}#[tool(tool_box)]impl Counter {    pub fn new() -> Self {        Self {            counter: Arc::new(Mutex::new(0)),        }    }    #[tool(description = "Increment the counter by 1")]    async fn increment(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter += 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Decrement the counter by 1")]    async fn decrement(&self) -> Result<CallToolResult, McpError> {        let mut counter = self.counter.lock().await;        *counter -= 1;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }    #[tool(description = "Get the current counter value")]    async fn get_value(&self) -> Result<CallToolResult, McpError> {        let counter = self.counter.lock().await;        Ok(CallToolResult::success(vec![Content::text(            counter.to_string(),        )]))    }}#[tool(tool_box)]impl ServerHandler for Counter {    fn get_info(&self) -> ServerInfo {        ServerInfo {            protocol_version: ProtocolVersion::V_2024_11_05,            capabilities: ServerCapabilities::builder()                .enable_tools()                .build(),            server_info: Implementation::from_build_env(),            instructions: Some("This server provides a counter tool...".to_string()),        }    }        // その他の実装は省略...}このCounter実装の重要な点：#[tool(tool_box)]マクロ: これは、メソッドを自動的にMCPツールとして登録するマクロです。これにより、ボイラープレートコードが大幅に削減されます。#[tool(description = "...")]マクロ: 各メソッドにツールの説明を追加します。この情報はクライアントに公開され、ツールの使用方法を理解するのに役立ちます。Arc<Mutex<i32>>: スレッド間で安全にカウンター値を共有するためのラッパーです。これは、Rustの並行性プリミティブの典型的な使用例です。Axumフレームワークとの統合: axum.rsより高度な例として、Axum WebフレームワークとMCPサーバーを統合した例を見てみましょう。use rmcp::transport::sse_server::SseServer;use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt};mod common;use common::counter::Counter;const BIND_ADDRESS: &str = "127.0.0.1:8000";#[tokio::main]async fn main() -> anyhow::Result<()> {    // ロギングの初期化    tracing_subscriber::registry()        .with(            tracing_subscriber::EnvFilter::try_from_default_env()                .unwrap_or_else(|_| "debug".to_string().into()),        )        .with(tracing_subscriber::fmt::layer())        .init();    // SSEサーバーの起動とカウンターサービスの設定    let ct = SseServer::serve(BIND_ADDRESS.parse()?)        .await?        .with_service(Counter::new);    // Ctrl+Cで終了するまで待機    tokio::signal::ctrl_c().await?;    ct.cancel();    Ok(())}このサンプルの特徴的な点：SseServer::serve: AxumフレームワークをベースにしたSSEサーバーを起動する関数です。これにより、ブラウザからMCPサーバーにアクセスできるようになります。with_service: サービスファクトリを指定するメソッドです。この例ではCounter::new関数をファクトリとして使用しています。tokio::signal::ctrl_c().await?: Ctrl+Cシグナルを受け取るまで待機します。これにより、サーバーはバックグラウンドで動作し続けます。Webフレームワーク統合のポイントWebフレームワーク（Axum、Actix Webなど）とMCPを統合する際のポイント：適切なトランスポート（SSEなど）を選択するセッション管理を適切に行うエラーハンドリングを丁寧に実装するサーバーのライフサイクルを適切に管理するマクロ使用例examples/macros/ディレクトリには、MCPマクロを使用してツールを簡単に定義する例が含まれています。これらのマクロは、ボイラープレートコードを大幅に削減し、MCPサーバーの実装を容易にします。計算機ツールの実装calculator.rsは、#[tool]マクロを使用して計算機ツールを実装する例です。use mcp_core::handler::{ToolError, ToolHandler};use mcp_macros::tool;#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}#[tokio::main]async fn main() -> std::result::Result<(), Box<dyn std::error::Error>> {    // ツールのインスタンスを作成    let calculator = Calculator;    // ツール情報の出力    println!("Tool name: {}", calculator.name());    println!("Tool description: {}", calculator.description());    println!("Tool schema: {}", calculator.schema());    // サンプル入力でツールをテスト    let input = serde_json::json!({        "x": 5,        "y": 3,        "operation": "multiply"    });    let result = calculator.call(input).await?;    println!("Result: {}", result);    Ok(())}このサンプルの素晴らしい点：宣言的なツール定義: #[tool]マクロを使うことで、通常の関数にメタデータを追加するだけでMCPツールを定義できます。パラメータドキュメント: params(x = "First number...")のように、パラメータの説明をマクロ内で定義できます。これにより、自己文書化されたAPIが作成されます。型安全: 関数の引数型（i32, Stringなど）を利用して型安全なパラメータを定義します。Rustのコンパイラが型チェックを行うため、型関連のバグを防ぐことができます。マクロの活用術マクロを効果的に使用するためのポイント：適切な名前と説明を提供して、ツールの目的を明確にするパラメータに詳細な説明を追加して、ユーザーが正しい値を入力できるようにする複雑なパラメータには構造体を使用し、#[tool(aggr)]アノテーションで集約するエラーハンドリングを丁寧に行い、具体的なエラーメッセージを提供するトランスポート実装例examples/transport/ディレクトリには、様々なトランスポート実装例が含まれています。トランスポートは、MCPクライアントとサーバーの通信方法を定義します。TCPトランスポートtcp.rsは、TCP接続を使用してMCPメッセージを送受信する例です。use common::calculator::Calculator;use rmcp::{serve_client, serve_server};mod common;#[tokio::main]async fn main() -> anyhow::Result<()> {    tokio::spawn(server());    client().await?;    Ok(())}async fn server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    while let Ok((stream, _)) = tcp_listener.accept().await {        tokio::spawn(async move {            let server = serve_server(Calculator, stream).await?;            server.waiting().await?;            anyhow::Ok(())        });    }    Ok(())}async fn client() -> anyhow::Result<()> {    let stream = tokio::net::TcpSocket::new_v4()?        .connect("127.0.0.1:8001".parse()?)        .await?;    let client = serve_client((), stream).await?;    let tools = client.peer().list_tools(Default::default()).await?;    println!("{:?}", tools);    Ok(())}このサンプルでは：非同期I/O: tokioの非同期I/O機能を使用して、ブロッキングせずに複数の接続を処理します。serve_serverとserve_client: これらは便利なヘルパー関数で、トランスポートをサーバーまたはクライアントとして設定します。並行接続処理: tokio::spawnを使って各接続を別々のタスクで処理し、サーバーのスケーラビリティを確保しています。WebSocketトランスポートwebsocket.rsは、WebSocket接続を使用したMCPトランスポートの例です。async fn http_client(uri: &str) -> anyhow::Result<RunningService<RoleClient, ()>> {    let (stream, response) = tokio_tungstenite::connect_async(uri).await?;    if response.status() != tungstenite::http::StatusCode::SWITCHING_PROTOCOLS {        return Err(anyhow::anyhow!("failed to upgrade connection"));    }    let transport = WebsocketTransport::new_client(stream);    let client = ().serve(transport).await?;    Ok(client)}async fn start_server() -> anyhow::Result<()> {    let tcp_listener = tokio::net::TcpListener::bind("127.0.0.1:8001").await?;    tokio::spawn(async move {        while let Ok((stream, addr)) = tcp_listener.accept().await {            tracing::info!("accepted connection from: {}", addr);            tokio::spawn(async move {                let ws_stream = tokio_tungstenite::accept_async(stream).await?;                let transport = WebsocketTransport::new_server(ws_stream);                let server = Calculator.serve(transport).await?;                server.waiting().await?;                Ok::<(), anyhow::Error>(())            });        }    });    Ok(())}このサンプルでは：WebSocketプロトコル: HTTPからWebSocketにアップグレードする処理が含まれています。カスタムトランスポート実装: WebsocketTransportとしてカスタムトランスポートが実装されています。接続管理: 接続の確立からサーバー待機までの一連のフローが示されています。トランスポート選択のポイント適切なトランスポートを選択するためのポイント：用途に合わせて選択する:標準入出力（stdio）: コマンドラインツールや子プロセスSSE: Webブラウザとのリアルタイム通信TCP: ネットワーク上のサービス間通信WebSocket: 双方向リアルタイム通信Unix Socket: 同一マシン上のプロセス間通信セキュリティを考慮する: 公開ネットワークで使用する場合はTLSなどの暗号化を検討パフォーマンスを考慮する: 大量のデータや頻繁な通信がある場合は効率的なトランスポートを選択応用パターンとベストプラクティスMCPを実装する際の応用パターンとベストプラクティスをいくつか紹介します。エラーハンドリング具体的なエラーメッセージ: クライアントが問題を理解できるよう、具体的なエラーメッセージを提供します。   Err(ToolError::InvalidParameters(format!(       "Unknown operation: {}. Supported operations are: add, subtract, multiply, divide",       operation   )))エラー変換: 低レベルエラーを適切なMCPエラーに変換します。   async fn read_file(&self, path: String) -> Result<CallToolResult, McpError> {       let content = tokio::fs::read_to_string(path)           .await           .map_err(|e| McpError::tool_execution_error(               "file_read_error",               Some(serde_json::json!({ "error": e.to_string() }))           ))?;              Ok(CallToolResult::success(vec![Content::text(content)]))   }非同期処理適切なタスク管理: 長時間実行される処理は別タスクに分離し、クライアントをブロックしないようにします。   #[tool(description = "Run a long process")]   async fn run_long_process(&self) -> Result<CallToolResult, McpError> {       // 別タスクでバックグラウンド処理を開始       let task_id = self.start_background_task().await?;              // タスクIDを即座に返す       Ok(CallToolResult::success(vec![Content::text(format!(           "Task started with ID: {}", task_id       ))]))   }      // 別のツールでタスク状態を確認できるようにする   #[tool(description = "Check task status")]   async fn check_task_status(&self, #[tool(param)] task_id: String) -> Result<CallToolResult, McpError> {       // ...   }タイムアウト管理: 長時間の操作にはタイムアウトを設定します。   let result = tokio::time::timeout(       Duration::from_secs(30),       some_long_operation()   ).await.map_err(|_| McpError::tool_execution_error(       "operation_timeout",       Some(serde_json::json!({"message": "Operation timed out after 30 seconds"}))   ))??;リソース管理共有状態の適切な管理: Arc<Mutex<T>>やArc<RwLock<T>>を使用して、スレッド間で状態を安全に共有します。リソースのクリーンアップ: Dropトレイトを実装して、リソースが確実に解放されるようにします。コネクション管理: クライアント接続を適切に管理し、リソースリークを防ぎます。実際の使用例：LLMとの統合MCPはLLM（大規模言語モデル）に外部ツールへのアクセスを提供するために設計されています。ここでは、LLMとMCPの統合例を見てみましょう。examples/rig-integration/ディレクトリには、Rigフレームワーク（LLMアプリケーションフレームワーク）とMCPの統合例が含まれています。// MCPツールをRigのツールとして適応させるアダプタpub struct McpToolAdaptor {    tool: McpTool,    server: ServerSink,}impl RigTool for McpToolAdaptor {    fn name(&self) -> String {        self.tool.name.to_string()    }    fn definition(        &self,        _prompt: String,    ) -> std::pin::Pin<Box<dyn Future<Output = rig::completion::ToolDefinition> + Send + Sync + '_>>    {        Box::pin(std::future::ready(rig::completion::ToolDefinition {            name: self.name(),            description: self.tool.description.to_string(),            parameters: self.tool.schema_as_json_value(),        }))    }    fn call(        &self,        args: String,    ) -> std::pin::Pin<        Box<dyn Future<Output = Result<String, rig::tool::ToolError>> + Send + Sync + '_>,    > {        let server = self.server.clone();        Box::pin(async move {            let call_mcp_tool_result = server                .call_tool(CallToolRequestParam {                    name: self.tool.name.clone(),                    arguments: serde_json::from_str(&args)                        .map_err(rig::tool::ToolError::JsonError)?,                })                .await                .map_err(|e| rig::tool::ToolError::ToolCallError(Box::new(e)))?;            Ok(convert_mcp_call_tool_result_to_string(call_mcp_tool_result))        })    }}このアダプタは、MCPツールをRigフレームワークのツールとして使用できるようにします。これにより、LLMとMCPサーバーをシームレスに統合することができます。WASI (WebAssembly System Interface) 対応examples/wasi/ディレクトリには、WebAssemblyでMCPサーバーを実装する例が含まれています。これにより、ブラウザやエッジコンピューティング環境でMCPサーバーを実行できます。// wasi/src/lib.rsstruct TokioCliRunner;impl wasi::exports::cli::run::Guest for TokioCliRunner {    fn run() -> Result<(), ()> {        let rt = tokio::runtime::Builder::new_current_thread()            .enable_all()            .build()            .unwrap();        rt.block_on(async move {            tracing_subscriber::fmt()                .with_env_filter(                    EnvFilter::from_default_env().add_directive(tracing::Level::DEBUG.into()),                )                .with_writer(std::io::stderr)                .with_ansi(false)                .init();            let server = calculator::Calculator.serve(wasi_io()).await.unwrap();            server.waiting().await.unwrap();        });        Ok(())    }}wasi::cli::command::export!(TokioCliRunner);WASI環境でMCPサーバーを実行することで、セキュリティやポータビリティが向上し、より多くの環境でMCPを活用できるようになります。まとめMCPのRust SDKには、様々なユースケースに対応するための豊富なサンプルコードが含まれています。これらのサンプルを理解し、実際に試すことで、MCPを活用したアプリケーションの開発スキルを向上させることができます。この記事でカバーした主なポイント：クライアント実装: 基本的なクライアント、SSEトランスポートの使用、複数クライアントの管理サーバー実装: 基本的なサーバー、ツールボックスとマクロの活用、Webフレームワークとの統合トランスポート実装: TCP、WebSocket、Unix Socketなどの様々なトランスポート応用パターン: エラーハンドリング、非同期処理、リソース管理のベストプラクティスLLM統合: Rigフレームワークを使ったLLMとMCPの統合例MCPはまだ比較的新しいプロトコルですが、AIとツールの統合に関する標準化に大きな可能性を秘めています。Rustの強力な型システムと安全性の恩恵を受けながら、MCPの機能を最大限に活用しましょう。生成AIについて興味があればこちらも読んでみてもらいたいです。NEXUS 情報の人類史 上　人間のネットワーク作者:ユヴァル・ノア・ハラリ河出書房新社AmazonNEXUS 情報の人類史 下　AI革命作者:ユヴァル・ノア・ハラリ河出書房新社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[nvidia/cuda imageを使ってDockerコンテナでGPUを使用する]]></title>
            <link>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</link>
            <guid>https://sreake.com/blog/gpu-used-docker-with-nvidia-cuda-image/</guid>
            <pubDate>Thu, 27 Mar 2025 04:33:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake事業部アプリケーション開発チームの角谷です！ 最近、機械学習やディープラーニング、特に生成AIの分野で、GPUの活用がますます重要になってきています。 Stable DiffusionやChatGP […]The post nvidia/cuda imageを使ってDockerコンテナでGPUを使用する first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Rust製MCPライブラリの内部実装を徹底解析]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</link>
            <guid>https://syu-m-5151.hatenablog.com/entry/2025/03/27/121602</guid>
            <pubDate>Thu, 27 Mar 2025 03:16:02 GMT</pubDate>
            <content:encoded><![CDATA[はじめに最近注目を集めているModel Context Protocol（MCP）は、大規模言語モデル（LLM）に外部ツールやサービスへのアクセス能力を提供するための標準プロトコルです。中でも公式が提供しているRust SDKはあまり注目されていませんが、私自身が必要としているためこのドキュメントを作成します。github.com以前は自前で実装していましたが、公式SDKが公開されたことでそちらを検討するのが良いと考えました。私の実装と比較してかなり洗練されている点が多く、多くの学びを得ることができました。syu-m-5151.hatenablog.comこの記事では、MCP Rust SDKの内部実装を深掘りし、どのようにRustの強力な型システムと非同期プログラミングモデルが活用されているかを解説します。コードの詳細な分析を通して、Rustの優れた設計パターンや実装テクニックを学びましょう。このブログが良ければ読者になったり、nwiizoをフォロワーしてくれるのもありがたいです。MCP とは何か？記事を始める前に、まず MCP (Model Context Protocol) について簡単に説明しましょう。MCP についてより詳しい情報は、公式ドキュメント modelcontextprotocol.io や Anthropic の Model Context Protocol に関する記事 を参照してください。MCP は Cline や Cursor などの LLM クライアントが外部サービスと連携するためのプロトコルです。従来の LLM は学習したデータに基づいて「考える」ことしかできませんでしたが、MCP を通じて外部と連携し、「行動する」能力を持つことができます。具体的には、MCP を使うことで以下のようなことが可能になります。Notion のファイル編集Supabase のデータベースクエリCloudflare のステータスチェックローカルファイルの編集や操作mcpserver.ccMCP がプロトコルとして統一されていることで、LLM プロバイダーやサービスを柔軟に切り替えることができるという大きなメリットがあります。modelcontextprotocol.ioMCP の仕組みMCP は基本的に JSON-RPC ベースのプロトコルで、詳細な仕様は modelcontextprotocol.io/docs/concepts/transports#message-format で確認できます。主要な構成要素は以下のとおりです。リソース（Resources）：データへのアクセスを提供（REST API の GET に相当）ツール（Tools）：アクションの実行を可能にする（REST API の POST に相当）プロンプト（Prompts）：LLM がどのようにサービスを使うべきかのガイダンスMCP の実装をサポートするための公式 SDK が複数の言語で提供されています(2024年3月27日 現在)。ちなみに今後MCPがどうなってゆくかはRoadmapが存在しているのでぜひ、こちらを読んでもらいたいです。modelcontextprotocol.ioSDKの全体構成 - 明確な関心の分離MCP Rust SDKは、複数のクレートに明確に分離されており、それぞれが特定の責任を担っています。rust-sdk/├── crates/│   ├── mcp-core/      # プロトコルの基本型とインターフェース│   ├── mcp-client/    # クライアント実装│   ├── mcp-server/    # サーバー実装│   └── mcp-macros/    # ツール実装を簡素化するマクロ└── examples/    ├── clients/       # クライアント使用例    ├── servers/       # サーバー実装例    └── macros/        # マクロ使用例この設計はRustエコシステムでよく見られる「関心の分離」パターンに従っています。各クレートがひとつの責任を持ち、依存関係も明確です。こうすることで、メンテナンス性と再利用性が大幅に向上します。特に注目すべきは、コア型定義とプロトコル実装をmcp-coreに分離している点です。これにより、クライアントとサーバーが共通の型定義を使いながら、それぞれ独立して実装・進化できる柔軟性を確保しています。mcp-core: 堅牢な基盤となる型定義mcp-coreクレートは、MCPプロトコルの心臓部とも言える基本型とインターフェースを提供しています。ここでの実装がSDK全体の品質を大きく左右します。JSON-RPCメッセージの巧妙な実装MCPはJSON-RPCプロトコルをベースにしていますが、その実装が非常に興味深いものになっています#[derive(Debug, Serialize, Deserialize, Clone, PartialEq)]#[serde(untagged, try_from = "JsonRpcRaw")]pub enum JsonRpcMessage {    Request(JsonRpcRequest),    Response(JsonRpcResponse),    Notification(JsonRpcNotification),    Error(JsonRpcError),    Nil, // used to respond to notifications}#[derive(Debug, Serialize, Deserialize)]struct JsonRpcRaw {    jsonrpc: String,    #[serde(skip_serializing_if = "Option::is_none")]    id: Option<u64>,    #[serde(skip_serializing_if = "Option::is_none")]    method: Option<String>,    #[serde(skip_serializing_if = "Option::is_none")]    params: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    result: Option<Value>,    #[serde(skip_serializing_if = "Option::is_none")]    error: Option<ErrorData>,}impl TryFrom<JsonRpcRaw> for JsonRpcMessage {    type Error = String;    fn try_from(raw: JsonRpcRaw) -> Result<Self, <Self as TryFrom<JsonRpcRaw>>::Error> {        // If it has an error field, it's an error response        if raw.error.is_some() {            return Ok(JsonRpcMessage::Error(JsonRpcError {                jsonrpc: raw.jsonrpc,                id: raw.id,                error: raw.error.unwrap(),            }));        }        // If it has a result field, it's a response        if raw.result.is_some() {            return Ok(JsonRpcMessage::Response(JsonRpcResponse {                jsonrpc: raw.jsonrpc,                id: raw.id,                result: raw.result,                error: None,            }));        }        // If we have a method, it's either a notification or request        if let Some(method) = raw.method {            if raw.id.is_none() {                return Ok(JsonRpcMessage::Notification(JsonRpcNotification {                    jsonrpc: raw.jsonrpc,                    method,                    params: raw.params,                }));            }            return Ok(JsonRpcMessage::Request(JsonRpcRequest {                jsonrpc: raw.jsonrpc,                id: raw.id,                method,                params: raw.params,            }));        }        // If we have no method and no result/error, it's a nil response        if raw.id.is_none() && raw.result.is_none() && raw.error.is_none() {            return Ok(JsonRpcMessage::Nil);        }        // If we get here, something is wrong with the message        Err(format!(            "Invalid JSON-RPC message format: id={:?}, method={:?}, result={:?}, error={:?}",            raw.id, raw.method, raw.result, raw.error        ))    }}この実装の素晴らしい点は3つあります。#[serde(untagged)]アノテーションの活用：JSONデータの構造に基づいて適切な列挙型バリアントに自動的にデシリアライズします。これにより、外部向けのJSONはシンプルな形式を維持できます。try_from = "JsonRpcRaw"による変換の分離：複雑な変換ロジックを別の型に委譲し、コードの見通しを良くしています。これはRustの型システムを活用した優れたパターンです。段階的な判断ロジック：各メッセージタイプの判定条件を明確にし、順番に評価することで複雑な条件分岐を読みやすく実装しています。これらの工夫により、複雑なJSON-RPCプロトコルの処理を堅牢かつ読みやすいコードで実現しています。特に注目すべきは、Rustの型システムを最大限に活用し、コンパイル時の型チェックでバグを防ぐ設計になっている点です。豊かなコンテンツ型システムMCPはさまざまなコンテンツ型（テキスト、画像、リソースなど）をサポートしています。その実装も非常に洗練されています。#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]#[serde(tag = "type", rename_all = "camelCase")]pub enum Content {    Text(TextContent),    Image(ImageContent),    Resource(EmbeddedResource),}impl Content {    pub fn text<S: Into<String>>(text: S) -> Self {        Content::Text(TextContent {            text: text.into(),            annotations: None,        })    }    pub fn image<S: Into<String>, T: Into<String>>(data: S, mime_type: T) -> Self {        Content::Image(ImageContent {            data: data.into(),            mime_type: mime_type.into(),            annotations: None,        })    }    pub fn resource(resource: ResourceContents) -> Self {        Content::Resource(EmbeddedResource {            resource,            annotations: None,        })    }    // その他のメソッド...}この実装には、使いやすさと型安全性を両立する工夫がいくつもあります。タグ付き列挙型の活用：#[serde(tag = "type")]は、JSONに「type」フィールドを追加し、その値に基づいて適切な型にデシリアライズします。これはJSONとRustの型を自然にマッピングする優れた方法です。ファクトリメソッド：text(), image(), resource()などのメソッドは、わかりやすい方法でコンテンツを作成できるようにしています。これは、制約を守りながら簡潔にオブジェクトを作成するのに役立ちます。ジェネリックな引数：S: Into<String>のようなトレイト境界を使うことで、文字列リテラル、String、&strなど、さまざまな文字列型を引数として受け入れることができます。これは使い勝手を大幅に向上させます。この設計は、使いやすいAPIと堅牢な内部実装のバランスが見事です。とりわけ、列挙型とそのバリアントを活用してドメインの概念を表現する点はRustらしいアプローチと言えるでしょう。mcp-client: 柔軟なトランスポートと抽象化mcp-clientクレートは、MCPサーバーとの通信を担当します。特に注目すべきは、トランスポート層の抽象化です。トランスポートの抽象化MCPサーバーとの通信には複数の方法（標準入出力、HTTP、WebSocketなど）が考えられます。このSDKはそれらを抽象化するための優れた設計を採用しています。/// A message that can be sent through the transport#[derive(Debug)]pub struct TransportMessage {    /// The JSON-RPC message to send    pub message: JsonRpcMessage,    /// Channel to receive the response on (None for notifications)    pub response_tx: Option<oneshot::Sender<Result<JsonRpcMessage, Error>>>,}/// A generic asynchronous transport trait with channel-based communication#[async_trait]pub trait Transport {    type Handle: TransportHandle;    /// Start the transport and establish the underlying connection.    /// Returns the transport handle for sending messages.    async fn start(&self) -> Result<Self::Handle, Error>;    /// Close the transport and free any resources.    async fn close(&self) -> Result<(), Error>;}#[async_trait]pub trait TransportHandle: Send + Sync + Clone + 'static {    async fn send(&self, message: JsonRpcMessage) -> Result<JsonRpcMessage, Error>;}この抽象化にはいくつもの巧妙な工夫があります。関連型（associated type）の活用：type Handle: TransportHandleという関連型を使うことで、トランスポートとそのハンドルを型レベルで紐づけています。これにより、異なるトランスポート実装が異なるハンドル型を持つことができます。非同期トレイト：#[async_trait]マクロを使って、非同期メソッドをトレイトに含められるようにしています。これは標準のRustでは直接サポートされていない機能です。分離された開始と通信：startメソッドで接続を確立し、その結果として得られるハンドルを使って通信するという2段階のパターンを採用しています。これにより、接続のライフサイクルとメッセージ送受信を明確に分離できます。このような抽象化により、新しいトランスポート実装を追加するのが容易になりますし、クライアント側のコードはトランスポートの詳細を気にせず書けるようになります。StdioTransportの実装標準入出力を使ったトランスポート実装も見てみましょう：pub struct StdioTransport {    command: String,    args: Vec<String>,    env: HashMap<String, String>,}impl StdioTransport {    pub fn new<S: Into<String>>(        command: S,        args: Vec<String>,        env: HashMap<String, String>,    ) -> Self {        Self {            command: command.into(),            args,            env,        }    }    async fn spawn_process(&self) -> Result<(Child, ChildStdin, ChildStdout, ChildStderr), Error> {        let mut command = Command::new(&self.command);        command            .envs(&self.env)            .args(&self.args)            .stdin(std::process::Stdio::piped())            .stdout(std::process::Stdio::piped())            .stderr(std::process::Stdio::piped())            .kill_on_drop(true);        // Set process group only on Unix systems        #[cfg(unix)]        command.process_group(0); // don't inherit signal handling from parent process        // Hide console window on Windows        #[cfg(windows)]        command.creation_flags(0x08000000); // CREATE_NO_WINDOW flag        let mut process = command            .spawn()            .map_err(|e| Error::StdioProcessError(e.to_string()))?;        let stdin = process            .stdin            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdin".into()))?;        let stdout = process            .stdout            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stdout".into()))?;        let stderr = process            .stderr            .take()            .ok_or_else(|| Error::StdioProcessError("Failed to get stderr".into()))?;        Ok((process, stdin, stdout, stderr))    }}この実装の素晴らしい点を見てみましょう：プラットフォーム固有の最適化：#[cfg(unix)]と#[cfg(windows)]を使って、各OSに最適な設定を行っています。これはRustの条件付きコンパイルの機能をうまく活用した例です。リソース管理：kill_on_drop(true)を使って、オブジェクトが破棄された時に子プロセスも確実に終了するよう保証しています。これはリソースリークを防ぐための重要な安全策です。エラーハンドリング：ok_or_elseのような関数を使って、エラーケースを明確に処理しています。これにより、どのような状況でもプログラムが予測可能な動作をするようになります。この実装は、複雑な子プロセス操作を安全かつ効率的に行うための優れた例です。特に、クロスプラットフォームな動作を保証するための配慮が随所に見られます。クライアント本体の実装最後に、クライアント本体の実装を見てみましょう：pub struct McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    service: Mutex<S>,    next_id: AtomicU64,    server_capabilities: Option<ServerCapabilities>,    server_info: Option<Implementation>,}impl<S> McpClient<S>where    S: Service<JsonRpcMessage, Response = JsonRpcMessage> + Clone + Send + Sync + 'static,    S::Error: Into<Error>,    S::Future: Send,{    pub fn new(service: S) -> Self {        Self {            service: Mutex::new(service),            next_id: AtomicU64::new(1),            server_capabilities: None,            server_info: None,        }    }    /// Send a JSON-RPC request and check we don't get an error response.    async fn send_request<R>(&self, method: &str, params: Value) -> Result<R, Error>    where        R: for<'de> Deserialize<'de>,    {        let mut service = self.service.lock().await;        service.ready().await.map_err(|_| Error::NotReady)?;        let id = self.next_id.fetch_add(1, Ordering::SeqCst);        let request = JsonRpcMessage::Request(JsonRpcRequest {            jsonrpc: "2.0".to_string(),            id: Some(id),            method: method.to_string(),            params: Some(params.clone()),        });        let response_msg = service            .call(request)            .await            .map_err(|e| Error::McpServerError {                server: self                    .server_info                    .as_ref()                    .map(|s| s.name.clone())                    .unwrap_or("".to_string()),                method: method.to_string(),                // we don't need include params because it can be really large                source: Box::new(e.into()),            })?;        // ... レスポンス処理 ...    }}この実装には、Rustの現代的な非同期プログラミング技術が凝縮されています。Tower Serviceの活用：低レベルのトランスポート詳細を抽象化するために、Tower crateのServiceトレイトを使用しています。これはミドルウェアの組み合わせや機能拡張を容易にします。ジェネリックな戻り値型：send_request<R>のようなジェネリック関数を使って、様々な型のレスポンスを受け取れるようにしています。これはクライアントAPIを使いやすくする工夫です。スレッドセーフなカウンター：AtomicU64を使って、スレッドセーフなID生成を実現しています。これは並行処理を安全に行うための基本的なテクニックです。非同期排他制御：Mutex<S>を使って、非同期コンテキストでのサービスアクセスを管理しています。tokio::sync::Mutexはブロッキングせずに排他制御を行える優れたプリミティブです。これらの機能を組み合わせることで、堅牢で効率的、かつ使いやすいクライアントAPIを実現しています。特にTowerのサービス抽象化を活用することで、将来的な拡張性も確保されています。mcp-server: モジュラーなサーバー設計mcp-serverクレートは、MCPサーバーをRustで実装するためのフレームワークを提供しています。ここでもいくつか興味深い実装が見られます。ByteTransportの実装#[pin_project]pub struct ByteTransport<R, W> {    // Reader is a BufReader on the underlying stream (stdin or similar) buffering    // the underlying data across poll calls, we clear one line (\n) during each    // iteration of poll_next from this buffer    #[pin]    reader: BufReader<R>,    #[pin]    writer: W,}impl<R, W> ByteTransport<R, W>where    R: AsyncRead,    W: AsyncWrite,{    pub fn new(reader: R, writer: W) -> Self {        Self {            // Default BufReader capacity is 8 * 1024, increase this to 2MB to the file size limit            // allows the buffer to have the capacity to read very large calls            reader: BufReader::with_capacity(2 * 1024 * 1024, reader),            writer,        }    }}impl<R, W> Stream for ByteTransport<R, W>where    R: AsyncRead + Unpin,    W: AsyncWrite + Unpin,{    type Item = Result<JsonRpcMessage, TransportError>;    fn poll_next(self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {        // Poll実装...    }}この実装には、Rustの非同期I/Oに関する高度な知識が詰まっています。巨大なバッファサイズ：デフォルトの8KBではなく2MBという大きなバッファを使用し、大量のデータを効率的に処理できるようにしています。これは実際のユースケースに基づく現実的な最適化でしょう。pin-projectの活用：非同期処理でピン留めが必要なフィールドを持つ構造体を安全に扱うために、pin-projectクレートを使用しています。これは非同期Rustの複雑な問題を解決するための定石です。Streamトレイトの実装：Streamトレイトを実装することで、メッセージを非同期ストリームとして扱えるようにしています。これは非同期処理パターンとの自然な統合を可能にします。このようなトランスポート実装により、サーバーは効率的に大量のメッセージを処理できるようになります。また、バッファ管理や非同期I/Oの複雑さは抽象化されるため、上位層のコードはビジネスロジックに集中できます。優れたRouterトレイトMCPサーバーの中核となるのがRouterトレイトです。pub trait Router: Send + Sync + 'static {    fn name(&self) -> String;    fn instructions(&self) -> String;    fn capabilities(&self) -> ServerCapabilities;    fn list_tools(&self) -> Vec<mcp_core::tool::Tool>;    fn call_tool(        &self,        tool_name: &str,        arguments: Value,    ) -> Pin<Box<dyn Future<Output = Result<Vec<Content>, ToolError>> + Send + 'static>>;    fn list_resources(&self) -> Vec<mcp_core::resource::Resource>;    fn read_resource(        &self,        uri: &str,    ) -> Pin<Box<dyn Future<Output = Result<String, ResourceError>> + Send + 'static>>;    fn list_prompts(&self) -> Vec<Prompt>;    fn get_prompt(&self, prompt_name: &str) -> PromptFuture;    // 以下はデフォルト実装を持つヘルパーメソッド    fn create_response(&self, id: Option<u64>) -> JsonRpcResponse { ... }    fn handle_initialize(&self, req: JsonRpcRequest) -> impl Future<Output = Result<JsonRpcResponse, RouterError>> + Send { ... }    // その他のハンドラメソッド...}この設計の素晴らしさは以下の点にあります。最小限の実装要件：ユーザーが実装すべきメソッドは基本的な機能に限られており、複雑なプロトコル処理はデフォルト実装として提供されています。これにより、ルーターの実装がシンプルになり、ドメインロジックに集中できます。Futureを返すメソッド：ツール呼び出しなどの処理は非同期で行われるケースが多いため、Pin<Box<dyn Future<...>>>を返すメソッドになっています。これにより、実装者は任意の非同期処理を行う自由を持ちます。明確なトレイト境界：Send + Sync + 'staticという境界により、マルチスレッド環境での使用を安全に行えるようになっています。これは実際のサーバー環境では不可欠な制約です。この設計は、「使いやすさ」と「柔軟性」のバランスがとれた素晴らしい例です。初心者でも簡単に基本的なルーターを実装できますが、高度なユースケースに対応する拡張性も備えています。RouterServiceの実装pub struct RouterService<T>(pub T);impl<T> Service<JsonRpcRequest> for RouterService<T>where    T: Router + Clone + Send + Sync + 'static,{    type Response = JsonRpcResponse;    type Error = BoxError;    type Future = Pin<Box<dyn Future<Output = Result<Self::Response, Self::Error>> + Send>>;    fn poll_ready(&mut self, _cx: &mut Context<'_>) -> Poll<Result<(), Self::Error>> {        Poll::Ready(Ok(()))    }    fn call(&mut self, req: JsonRpcRequest) -> Self::Future {        let this = self.0.clone();        Box::pin(async move {            let result = match req.method.as_str() {                "initialize" => this.handle_initialize(req).await,                "tools/list" => this.handle_tools_list(req).await,                "tools/call" => this.handle_tools_call(req).await,                "resources/list" => this.handle_resources_list(req).await,                "resources/read" => this.handle_resources_read(req).await,                "prompts/list" => this.handle_prompts_list(req).await,                "prompts/get" => this.handle_prompts_get(req).await,                _ => {                    let mut response = this.create_response(req.id);                    response.error = Some(RouterError::MethodNotFound(req.method).into());                    Ok(response)                }            };            result.map_err(BoxError::from)        })    }}この実装は、デザインパターンの「アダプターパターン」を思わせる優れた例です。シンプルなラッパー型：RouterService<T>(pub T)というシンプルな新型でRouterトレイトをTowerのServiceトレイトに適応させています。これは非常にエレガントなアプローチです。メソッドディスパッチ：リクエストのmethod文字列に基づいて適切なハンドラメソッドに処理をディスパッチしています。これはルーティングのための直感的で効率的な実装です。Clone要件：非同期クロージャ内でルーターを使用するためにCloneトレイト境界を要求しています。これにより、所有権の問題を簡単に解決できます。このようなラッパー型とディスパッチロジックにより、開発者はRouterトレイトの実装に集中でき、ServiceやTowerのような低レベルの詳細を気にする必要がなくなります。これは抽象化の良い例です。mcp-macros: 宣言的ツール定義の魔法最後に、mcp-macrosクレートの中核である#[tool]マクロを見てみましょう：#[proc_macro_attribute]pub fn tool(args: TokenStream, input: TokenStream) -> TokenStream {    let args = parse_macro_input!(args as MacroArgs);    let input_fn = parse_macro_input!(input as ItemFn);    // Extract function details    let fn_name = &input_fn.sig.ident;    let fn_name_str = fn_name.to_string();    // Generate PascalCase struct name from the function name    let struct_name = format_ident!("{}", { fn_name_str.to_case(Case::Pascal) });    // Use provided name or function name as default    let tool_name = args.name.unwrap_or(fn_name_str);    let tool_description = args.description.unwrap_or_default();    // パラメータの抽出処理...    // 実装の生成    let params_struct_name = format_ident!("{}Parameters", struct_name);    let expanded = quote! {        #[derive(serde::Deserialize, schemars::JsonSchema)]        struct #params_struct_name {            #(#param_defs,)*        }        #input_fn        #[derive(Default)]        struct #struct_name;        #[async_trait::async_trait]        impl mcp_core::handler::ToolHandler for #struct_name {            fn name(&self) -> &'static str {                #tool_name            }            fn description(&self) -> &'static str {                #tool_description            }            fn schema(&self) -> serde_json::Value {                mcp_core::handler::generate_schema::<#params_struct_name>()                    .expect("Failed to generate schema")            }            async fn call(&self, params: serde_json::Value) -> Result<serde_json::Value, mcp_core::handler::ToolError> {                let params: #params_struct_name = serde_json::from_value(params)                    .map_err(|e| mcp_core::handler::ToolError::InvalidParameters(e.to_string()))?;                // Extract parameters and call the function                let result = #fn_name(#(params.#param_names,)*).await                    .map_err(|e| mcp_core::handler::ToolError::ExecutionError(e.to_string()))?;                Ok(serde_json::to_value(result).expect("should serialize"))            }        }    };    TokenStream::from(expanded)}このマクロは、Rustの宣言的プログラミングの可能性を示す素晴らしい例です。関数からのメタデータ抽出：関数の名前や引数リストを解析して、ツールの基本情報を自動的に取得します。パラメータ構造体の自動生成：関数の引数リストから自動的にパラメータ構造体を生成し、serdeとschemarsのデリバティブを適用してJSON対応にします。ツールハンドラの自動実装：抽出した情報を元に、ToolHandlerトレイトを自動的に実装します。これにより、開発者はツールのビジネスロジックだけに集中できます。このマクロを使うと、以下のように簡潔なコードでツールを定義できます。#[tool(    name = "calculator",    description = "Perform basic arithmetic operations",    params(        x = "First number in the calculation",        y = "Second number in the calculation",        operation = "The operation to perform (add, subtract, multiply, divide)"    ))]async fn calculator(x: i32, y: i32, operation: String) -> Result<i32, ToolError> {    match operation.as_str() {        "add" => Ok(x + y),        "subtract" => Ok(x - y),        "multiply" => Ok(x * y),        "divide" => {            if y == 0 {                Err(ToolError::ExecutionError("Division by zero".into()))            } else {                Ok(x / y)            }        }        _ => Err(ToolError::InvalidParameters(format!(            "Unknown operation: {}",            operation        ))),    }}通常なら数十行のボイラープレートコードが必要なところを、このマクロによって数行のアノテーションだけで実現できています。これは開発者体験を大幅に向上させる素晴らしい例です。Webフレームワークとの統合MCPはしばしばWebアプリケーションと統合されます。そのための優れた実装例を見てみましょう：async fn sse_handler(State(app): State<App>) -> Sse<impl Stream<Item = Result<Event, io::Error>>> {    // it's 4KB    const BUFFER_SIZE: usize = 1 << 12;    let session = session_id();    tracing::debug!(%session, "sse connection");    let (c2s_read, c2s_write) = tokio::io::simplex(BUFFER_SIZE);    let (s2c_read, s2c_write) = tokio::io::simplex(BUFFER_SIZE);    app.txs        .write()        .await        .insert(session.clone(), Arc::new(Mutex::new(c2s_write)));    {        let session = session.clone();        tokio::spawn(async move {            let router = RouterService(counter::CounterRouter::new());            let server = Server::new(router);            let bytes_transport = ByteTransport::new(c2s_read, s2c_write);            let _result = server                .run(bytes_transport)                .await                .inspect_err(|e| tracing::error!(?e, "server run error"));            app.txs.write().await.remove(&session);        });    }    let stream = futures::stream::once(futures::future::ok(        Event::default()            .event("endpoint")            .data(format!("?sessionId={session}")),    ))    .chain(        FramedRead::new(s2c_read, common::jsonrpc_frame_codec::JsonRpcFrameCodec)            .map_err(|e| io::Error::new(io::ErrorKind::InvalidData, e))            .and_then(move |bytes| match std::str::from_utf8(&bytes) {                Ok(message) => futures::future::ok(Event::default().event("message").data(message)),                Err(e) => futures::future::err(io::Error::new(io::ErrorKind::InvalidData, e)),            }),    );    Sse::new(stream)}この実装は、Webアプリケーションとバックエンドサービスを統合する優れた例です。単方向チャネルの活用：tokio::io::simplexを使って、クライアントからサーバーへの通信とサーバーからクライアントへの通信を分離しています。これは各方向の流れを独立して最適化できるようにします。バックグラウンドタスク：MCPサーバーをtokio::spawnを使ってバックグラウンドタスクとして実行しています。これによりWebハンドラーは応答を待つことなく、すぐにSSEストリームを返すことができます。SSEストリームの構築：futures::stream::onceと.chain()を組み合わせて、初期メッセージと継続的なメッセージストリームを連結しています。これはストリーミングAPIの標準的なパターンです。この実装パターンは、MCPサーバーをWebアプリケーションに統合する効果的な方法を示しています。特に注目すべきは、非同期処理とストリーミングを効果的に組み合わせている点です。SDKの設計思想分析このSDKの実装から、いくつかの重要な設計思想が読み取れます。堅牢性と型安全性への徹底したこだわりこのSDKは、Rustの型システムを徹底的に活用して堅牢性を確保しています。トレイト境界（Send + Sync + 'staticなど）の明示的な指定ジェネリックパラメータを使ったAPI設計Result型による包括的なエラーハンドリングasync/awaitとFutureの適切な組み合わせこれらの特徴は、SDKの開発者がRustの強みをよく理解し、それを活かそうとしていることを示しています。特に、コンパイル時に多くのエラーを捕捉できるように設計されており、実行時の予期せぬ動作を最小限に抑える工夫が随所に見られます。拡張性と将来性を考えた設計SDKは将来の拡張を見据えた柔軟な設計になっています。トランスポート層の抽象化サービス層の分離とミドルウェアのサポートプラグイン可能なツール定義このような設計により、MCPプロトコル自体が進化しても、SDKを大きく書き換えることなく対応できるでしょう。また、ユーザーが独自の機能を追加するための拡張ポイントが多く用意されています。開発者体験の重視SDKは、使いやすさにも重点を置いています。マクロによるボイラープレートコードの削減直感的なビルダースタイルAPI豊富なデフォルト実装これらの機能は、SDKを使う開発者の負担を軽減し、本質的なビジネスロジックに集中できるようにするための工夫です。特に#[tool]マクロは、開発者体験を大幅に向上させる優れた例です。パフォーマンスへの配慮実装には、パフォーマンスを考慮した数々の工夫が見られます。大きなバッファサイズ（2MB）の使用非同期I/Oの全面採用ロックの最小化と効率的な並行処理これらの最適化は、MCPが大量のデータや複雑なコンテキストを扱うAIユースケースを想定していることを示唆しています。優れた実装パターンのまとめこのSDKから学べる優れたRust実装パターンをまとめましょう。1. 関心の明確な分離SDKは複数のクレートに分かれており、各クレートが明確な責任を持っています。これは保守性と再利用性を高める優れた設計原則です。2. トランスポート抽象化異なる通信方法（Stdio、SSEなど）を統一的なインターフェースで扱うための抽象化は、拡張性と柔軟性の高いコードを書くための良い例です。3. Tower ServiceパターンTowerのサービス抽象化を活用して、ミドルウェアの組み合わせやサービス合成を容易にする設計は、現代的なRustサーバー実装のベストプラクティスです。4. プロシージャルマクロの効果的な活用ボイラープレートコードを削減し、宣言的なスタイルでコードを書けるようにするマクロの活用は、開発者体験を向上させる優れた方法です。5. 非同期プログラミングのベストプラクティスPin、Box<dyn Future>、async_traitなどを適切に組み合わせた非同期処理の実装は、Rustの非同期プログラミングの洗練されたパターンを示しています。おわりにMCP Rust SDKの内部実装を深掘りすることで、Rustの強力な型システムと非同期プログラミングモデルを最大限に活用した素晴らしい設計パターンを学ぶことができました。このSDKは、「型安全性」「拡張性」「使いやすさ」「パフォーマンス」のバランスが優れており、大規模なRustアプリケーションを設計する際の参考になります。特に、トランスポート抽象化、サービス指向設計、プロシージャルマクロの活用は、他のRustプロジェクトでも応用できる価値のある実践例です。MCPプロトコルの実装を検討している方はもちろん、Rustでの堅牢なライブラリ設計に興味がある方にとっても、このSDKのコードベースは探求する価値のある宝庫と言えるでしょう。次回のブログではサンプルを見ながら実際に色々動かしてみたいと思います。syu-m-5151.hatenablog.com]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Kubernetesで実現できるPlatform Engineering の現在地]]></title>
            <link>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</link>
            <guid>https://speakerdeck.com/nwiizo/kubernetesdeshi-xian-dekiruplatform-engineering-noxian-zai-di</guid>
            <pubDate>Tue, 25 Mar 2025 04:00:00 GMT</pubDate>
            <content:encoded><![CDATA[本日、「Kubernetesで実践する Platform Engineering - FL#88」というイベントで「Kubernetesで実現できるPlatform Engineering の現在地」🎵🧭 というタイトルで登壇しました！🔍 イベント詳細:- イベント名: Kubernetesで実践する Platform Engineering - FL#88- 公式URL: https://forkwell.connpass.com/event/348104/🗣️ 関連スライド- インフラをつくるとはどういうことなのか、 あるいはPlatform Engineeringについて- https://speakerdeck.com/nwiizo/inhurawotukurutohadouiukotonanoka-aruihaplatform-engineeringnituite- Platform Engineeringは自由のめまい- https://speakerdeck.com/nwiizo/platform-engineeringhazi-you-nomemai]]></content:encoded>
        </item>
    </channel>
</rss>