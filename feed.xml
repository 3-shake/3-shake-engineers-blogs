<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>3-shake Engineers' Blogs</title>
        <link>https://blog.3-shake.com</link>
        <description>3-shake に所属するエンジニアのブログ記事をまとめています。</description>
        <lastBuildDate>Mon, 22 Dec 2025 06:11:59 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>ja</language>
        <image>
            <title>3-shake Engineers' Blogs</title>
            <url>https://blog.3-shake.com/og.png</url>
            <link>https://blog.3-shake.com</link>
        </image>
        <copyright>3-shake Inc.</copyright>
        <item>
            <title><![CDATA[なぜ「何でも作れる時代」に私は作れないのか]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/22/135517</guid>
            <pubDate>Mon, 22 Dec 2025 04:55:17 GMT</pubDate>
            <content:encoded><![CDATA[はじめに年末、2025年を振り返る。フォロワーは7倍になった。副業も順調。書籍の執筆や翻訳にも関わった。登壇の依頼も増えた。どこからどう見ても、良い年だったはずだ。なのに、胸の奥に澱のようなものが溜まっている。コードは書いた。山ほど書いた。でもそれは、誰かに頼まれたコードだ。お金になるコード。評価されるコード。「これを作ってください」と言われて、「はい」と答えて、作ったコード。自分のためのOSSも、作った。公開もした。そこそこ使われもした。でも、そこそこ止まりだ。「これが俺の代表作です」と言えるものが、ない。スターはついた。ダウンロードもされた。いくつかは今でも自分で使っている。完走した。自分なりに頑張った。でも、「代表作」と呼べるインパクトには届かなかった。厄介なことに、nwiizoというアカウントは大きくなってしまった。フォロワーが増えた分、「代表作」のハードルも上がっている。昔なら「動くものを公開した」で満足できた。今は違う。期待値が上がった分、自分で自分の首を絞めている。でも、諦めたくない。代表作を持つソフトウェアエンジニアに憧れて、この道に入った。あの人みたいになりたい、と思った先輩たちがいる。彼らのようにはなれていない。でも、まだ諦めたくない。新しいプロジェクトを始めようとするたび、手が止まる。「既存のツールで十分じゃないか」「誰が使うんだ、これ」。もっともらしい問いを自分に投げかけて、そのまま手を下ろす。完走したプロジェクトはある。でも、次の一歩が踏み出せない。検証のふりをした、逃避だ。「作らなくていい理由」を探して、見つけて、安心している。AIは「どう作るか」を教えてくれる。でも「何を作るか」は教えてくれない。技術力はもうボトルネックじゃない。足りないのは、決断だ。覚悟だ。「これを作る」と宣言して、不確実性の中に飛び込む蛮勇だ。私は「隙間家具屋」を自称してきた。大きな家具は作らない。洗濯機と壁の間の収納。冷蔵庫の上のラック。誰も気にしないけれど、あると少し楽になる小さなもの。それを作るのが好きだった。はずだった。2025年、隙間を見つける目は曇っていなかった。手も動いた。完走もした。でも、「これだ」という手応えが残らなかった。副業は収入になる。登壇は評価される。ブログはフォロワーが増える。全部、目に見えるリターンがある。OSSは違う。作っても誰にも使われないかもしれない。時間を注いでも、何も返ってこないかもしれない。その「かもしれない」に怯えて、私は確実なほうへ流れやすかった。OSSは作った。完走もした。でも、賭け金を上げられなかった。時間を注ぎ込むより、確実なリターンがある副業や登壇に逃げた。結果、そこそこ止まり。「これだ」と言えるものは掴めなかった。問題は、才能がないことだけじゃない。問題は、狂えなかったことだ。どこにも振り切れなかった。副業も、登壇も、OSSも、全部やりたかった。全部にいい顔をして、どれにも本気を出せなかった。半端な賭け金には、半端なリターンしか返ってこない。当たり前のことだ。このブログでは、「狂って量をやって、そこから引き算する」ための思考法を書く。 speakerdeck.com結論を先に言う。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。ポジティブケイパビリティとネガティブケイパビリティ「ネガティブ・ケイパビリティ」という概念がある。不確実さ、不思議さ、疑いの中に、結論を急がずに留まる能力のことだ。これに対して、「ポジティブ・ケイパビリティ」というのもある。問題を分析し、解決策を導き、実行する能力だ。ゴールが明確なときに発揮される力。私はおそらくだがこれが得意だ。生成AIは、ポジティブケイパビリティを劇的に強化した。「このAPIを叩いて、結果をパースして、DBに保存するコードを書いて」と指示すれば、動くコードが出てくる。「このエラーメッセージの原因を調べて」と頼めば、調査結果が返ってくる。ゴールが明確なタスクは、AIとの協働で驚くほど速く片付く。私の2025年は、まさにこれだった。仕事のコードは書けた。クライアントから「これを作ってほしい」と言われれば、作れた。締め切りがあり、要件があり、ゴールが明確なタスクは、以前より速く終わるようになった。しかし、ネガティブケイパビリティは強化されなかった。むしろ、弱体化した気もする。 以前なら、分からないまま3日間コードを書き続けることができた。今は、30分詰まるとAIに聞いてしまう。「分からない」という状態に耐える筋力が、確実に落ちている。OSS開発には、ネガティブケイパビリティが必要だ。「何を作るか」は誰も教えてくれない。「これが正解」という保証はない。作っている途中で「これは違うかも」と思うことがある。それでも手を動かし続ける。完成するかどうか分からない。使われるかどうか分からない。その不確実さの中に留まり続ける力。生成AIに「何を作るべきか」と聞いても、答えは出ない。AIは優秀なアシスタントだが、ゴールを設定するのは人間の仕事だ。ゴールが明確な仕事が速く片付くようになった結果、私の中で奇妙なことが起きた。「答えがすぐに出る」ことに慣れてしまった。 仕事では、AIに聞けば数分で方向性が見える。それに慣れた脳は、「答えが出ない状態」に耐えられなくなっている。では、どうすれば不確実さに耐えられるのか。いくつかの仮説がある。ゴールを小さくする（「Kubernetesのログ管理を改善したい」ではなく「Podの再起動ログをSlackに送る」）。「完成」の定義を下げる（動けば完成、READMEは3行でいい）。公開してしまう（不確実性の一部が確定に変わる）。AIに頼らない時間を作る（自分で考える筋力を維持する）。「狂う」とは何か「狂う」という言葉を使うと、何か特別な才能や突飛な発想が必要に思える。しかし、私が考える「狂う」はもっと単純だ。狂うとは、常識的な量を超えて、時間と労力を注ぐことだ。天才的なアイデアは必要ない。奇抜な発想も必要ない。ただ、普通の人が「そこまでやらなくていいだろう」と思う量を投入する。これが狂うということだ。しかし、ここまで書いて気づいた。「量をやれ」というアドバイスは、ゴールが見えている人へのアドバイスだ。これはポジティブケイパビリティの話だ。「OSSを20個作れ」と言われても、「何を作るか」が決まっていなければ、手は動かない。私の問題は、量が足りないことではなく、ゴールが見えない状態に耐えられないことだった。ネガティブケイパビリティの欠如だ。だから、「狂う」にはもう1つの意味がある。答えが出ない状態に留まり続けることだ。「これが正解かどうか分からない」「誰にも使われないかもしれない」「もっといい方法があるかもしれない」。その不確実さの中で、それでも作り続ける。確信がないまま、手を動かし続ける。普通の人は、不確実さに耐えられない。「これで合ってる？」と誰かに確認したくなる。確認できないと、手が止まる。狂っている人は、確認しないまま走り続ける。生成AIは「確認」を容易にした。コードを書いたら、AIにレビューしてもらえる。設計を考えたら、AIに壁打ちしてもらえる。これは素晴らしいことだ。でも同時に、「確認なしで走り続ける」筋力が衰えた。量を積むことと、不確実性に耐えること。この2つは、実は表裏一体だ。量を積めば、その中から「これだ」というものが見えてくる。不確実性に耐えていれば、やがてゴールが見えてくる。どちらも「狂う」ことでしか到達できない。狂気の最も簡単な表現方法は、物量か時間を使うことだ。1日1時間を5年続ける。同じテーマのブログを100本書く。OSSを年間20個作る。なぜ20個か。月に1〜2個のペースだ。1つのツールを2週間で完成させる。完璧じゃなくていい。動けばいい。このペースなら、仕事をしながらでも無理がない。かつ、「そこそこ止まり」の自分とは明らかに違う場所に立てる。特別な才能がなくても、量を積めば、誰も追いつけない場所にたどり着く。ここで「衝動」という言葉を使いたい。不便を見つけたとき、「あ、これ自動化できそう」と思う。その瞬間、手が動き出す。誰に頼まれたわけでもない。でも、気づいたらコードを書いている。これが私にとっての衝動だ。「将来の夢」とは違う。他者の評価を求めている「有名なOSSメンテナになりたい」は、衝動ではない。衝動は、評価とは無関係に動く。10年経っても変わらない。「不便を見つけたら、すぐ直したくなる」。隙間家具を作るのは、この衝動の表れだ。問題は、この衝動を他者の目で覆い隠してしまうことだ。「作っても誰にも使われないかも」。そう考えた瞬間、衝動が埋もれる。2025年の私は、まさにこれだった。衝動は「発見」するものではなく「掘り出す」ものだ。他者の目や評価への恐れで覆い隠されている。それを掘り出すには、まず量をやる必要がある。考える前に手を動かす。作る前に悩まない。作った後に、何が自分を動かしているのかが見えてくる。まず量をやる私たちは、最初から量が足りない。2025年、私のOSSがそこそこ止まりだった理由は何か。作った。完走もした。でも、「代表作」と呼べるインパクトには届かなかった。振り返ると、1つに賭け切れていなかった。あれもこれもやろうとして、どれにも全力を注げなかった。「ゴールが見えないから突き抜けられない」と思っていた。でも、それは逆だ。一つに賭け切らないから、ゴールが見えない。作りはした。でも、広く浅く。一つに集中しなかったから、どれも「これだ」に辿り着けなかった。私の経験を話す。以前、「Kubernetesのログをなんとかしたい」という漠然とした不満があった。何を作ればいいか分からなかった。とりあえず、Podの再起動を検知するスクリプトを書いた。動いた。使ってみた。すると、「再起動の直前のログが見たい」という次の不満が見えた。それを解決するコードを足した。使ってみた。今度は「Slackに通知したい」という欲求が出てきた。最初に「Podの再起動時に直前のログをSlackに送るツール」というゴールが見えていたわけではない。作っているうちに、ゴールが形成されていった。ゴールは、作る前に見つかるものではない。作る過程で見えてくるものだ。量をやることで、初めて「自分が本当に作りたいもの」が浮かび上がる。完璧な1つより、動く20個。磨き上げた1つより、荒削りな50個。これが私の2026年の方針だ。物量で狂う。 OSSを年間20個作る。完璧じゃなくていい。動けばいい。20個作れば、1個くらいは当たる。当たらなくても、20個分の経験が残る。時間で狂う。 毎日30分、何かを作る時間を確保する。1年で小さなツールを20個作れば、5年で100個になる。100個のOSSを持っているエンジニアは、採用市場で見たことがない。試行で狂う。 1つのアイデアに固執しない。「これは違うな」と思ったら、すぐ次に行く。打席に立つ回数を増やす。三振しても気にしない。次の打席がある。私は30代で独身だ。守るべきものが少ない。狂えるうちに狂っておく。量をやることで、初めて見えてくるものがある。どのアイデアに自分の熱量が続くのか。どのツールが使われるのか。作る前に「どれが正解か」を考えても分からない。作った後に、結果が教えてくれる。量だけでは足りないからセンスを磨くここで反論が聞こえる。「量をやるだけなら、生成AIでもできるのでは？」正しい指摘だ。そして、もう1つ重要な変化がある。ソフトウェアは供給過多の時代に入った。あらゆる領域で「フロンティアの閉鎖」が起きている。かつてソフトウェアには未開拓の荒野があった。問題はそこら中に転がっていて、誰かが手を挙げて解決すれば、それだけで価値になった。参入障壁が高かったから、作れる人が少なかった。だから「作った」という事実そのものに希少性があった。今は違う。生成AIが参入障壁を破壊した。誰でも作れる。結果、供給が需要を超えた。ユーザーの時間と注意力が、ツールよりも希少になった。ツールが人を選ぶ時代から、人がツールを選ぶ時代へ。選ばれないツールは、存在しないのと同じだ。これは「量で勝てた時代の終焉」を意味する。かつての戦略は「とにかく作れ、出せ、数で勝負しろ」だった。今、その戦略は逆効果になりうる。大量の凡庸なツールを公開すると、ノイズを増やすだけで、作り手の信用を毀損する。つまり、量を公開しすぎることが、むしろマイナスになる時代が来ている。では、量をやる意味はどこにあるのか。ここで「センス」について考えたい。センスとは何か。私は、意味よりも先に、形式やリズムを感じ取る能力だと考えている。普通、私たちは物事を「これは何を意味するのか」で理解しようとする。コードを見て「このツールは何をするのか」と問う。ブログを読んで「著者は何を主張しているのか」と問う。意味を求める。でも、センスの本質はそこにない。センスとは、意味の手前にある「リズム」を感じ取ることだ。リズムとは、反復と差異の織り成すパターンのことだ。赤ちゃんが「いないいないばあ」で喜ぶのは、不在から存在への移行、つまり0→1のビートを感じているからだ。予測があり、裏切りがあり、また予測に戻る。この往復運動が快感を生む。あらゆる表現にリズムがある。音楽のビート。文章の緩急。コードの構造。APIの応答パターン。人間は意味を理解する前に、このリズムを身体で感じている。優れた表現は、セオリーを押さえた上で、あえてそこからはみ出す。 反復の中に絶妙な差異を混ぜている。予測可能でありながら、どこか予測を裏切る。この「ズレ」がセンスだ。ここで重要な逆説がある。完璧を目指すほど、センスは死ぬ。お手本を完璧に再現しようとすると、二つの問題が起きる。一つは、お手本との差異が「欠点」に見えてしまうこと。もう一つは、自分固有のリズムが消えてしまうこと。結果として、劣化コピーが生まれる。逆に、お手本から離れることを肯定すると、「ヘタウマ」が生まれる。完璧ではないが、作り手固有のリズムがある。技術的には未熟でも、個性がある。その個性が、使う人に刺さる。なぜ個性が刺さるのか。人間は、パターンを認識する生き物だからだ。完璧にパターン化されたものは、最初は心地よい。でも、すぐ飽きる。予測通りすぎて、刺激がない。一方、パターンから少しズレたものは、脳に引っかかる。「なぜここでこうなる？」という小さな疑問が生まれ、それが記憶に残る。AIは反復とパターンを生成できる。しかし、その人固有の「どうしようもなさ」は生成できない。「どうしようもなさ」とは何か。個人の癖、偏り、こだわり。論理では説明できない選好。なぜか惹かれるもの。なぜか避けたくなるもの。この非合理な偏りが、人間の表現に陰影を与える。私がツールを作るとき、そこには私の「どうしようもなさ」が刻まれる。なぜこの設計を選んだのか、論理的に説明できない部分がある。それは私の経験、私の好み、私の盲点が複合的に作用した結果だ。AIが同じ仕様で作っても、同じものにはならない。センスとは、リズムを感じ取る能力であり、同時に、自分固有のリズムを表現する能力でもある。では、どうやってセンスを磨くのか。答えは逆説的だ。量をやることだ。多様なものに触れると、最初は不安を感じる。「分からない」「理解できない」。この不安は、パターンを認識できていないサインだ。量を重ねると、パターンが見えてくる。不安が面白さに変換される。これがセンスが磨かれる過程だ。ここで矛盾が生じる。センスを磨くには量が必要だ。しかし、量を公開しすぎるとマイナスになる。答えは、「作る量」と「公開する量」を分けることだ。20個作る。でも、公開するのは、センスが良いと判断した5個だけ。残りの15個は、センスを磨くための練習だ。公開しない。でも、作ったことに意味がある。量をやることには、二重の意味がある。1つ目は、センスを磨くこと。多様なものを作ることで、「何が良くて何が良くないか」を判断する回路ができる。リズムを感じ取る力が育つ。2つ目は、自分の「どうしようもなさ」を発見すること。量をやると、自分のパターンが見えてくる。どういう問題に惹かれるか。どういう設計を好むか。それは私の固有性であり、AIには真似できない。だから、量をやる意味は「AIより速く作る」ことではない。量を通じて、リズムを感じ取る力と、自分固有のリズムを発見することだ。そして、センスが磨かれた後は、公開するものを厳選する。供給過多の時代に求められるのは、「たくさん作れる人」ではない。「たくさん作った上で、良いものだけを選べる人」だ。AIは「どう作るか」を効率化する。でも、「何を作るか」「どれを公開するか」「どう判断するか」は、量を経験した人間にしか分からない。そして引き算する量をやった。20個作った。では、20個全部を維持できるか。できない。私には経験がある。かつて、複数のプロジェクトを同時に走らせていた。イシューは溜まり、プルリクエストは放置され、READMEは古くなった。全部やろうとして、全部が死んだ。量をやることと、量を維持することは違う。 量をやるのは一時的な狂気だ。量を維持するのは持続的な負担だ。人間のリソースは有限だから、量をやった後には、引き算という別の問題が待っている。私たちは、量が満ちた後に引かなすぎる。 量をやった後は、容赦なく削る。使われないツールは捨てる。熱量が続かないプロジェクトはアーカイブする。失うのは「いつかやるかもしれない」という幻想だ。守れるのは「今、本当にやりたいこと」への集中だ。削らずに広げ続けた結果が2025年の私だ。副業も、登壇も、ブログも、OSSも、全部やった。全部それなりに成果は出た。でも、どれも「これが俺の本業だ」と言い切れない。器用貧乏の完成形だ。ここで「引き算」の思考法が必要になる。シーナ・アイエンガー氏の有名な実験では、24種類のジャムより、6種類に絞った方が購入率は高かった。選択肢が多すぎると、人は「選ぶ」という行為自体ができなくなる。選択の科学 コロンビア大学ビジネススクール特別講義 (文春文庫 S 13-1)作者:シーナ アイエンガー文藝春秋Amazonアイエンガー氏は『THINK BIGGER』で、選択肢が多すぎて選べないときの思考法を体系化した。その本質は「引き算」だ。課題を選ぶ、分解する、誰のためかを決める、材料を集める、何を作らないかを決める、他者の目で検証する。すべて「絞る」プロセスだ。THINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazon狂って量をやるフェーズでは、複数のアイデアが同時に走っている方が自然だ。順番通りに1つずつ片付けようとすると、むしろ手が止まる。どれかが熱を帯びてきたら、そこに集中する。足し算ではない。引き算だ。優れた開発者のOSSが失敗するのは、怠けているからではない。正しいことをしすぎるからだ。 ユーザーの声を聞く。機能を追加する。対応範囲を広げる。全部、正しいことだ。でも、正しいことを積み重ねた結果、複雑になり、重くなり、新しく登場したシンプルなツールに足元をすくわれる。私たちは「正しさ」に殺される。ユーザーの声を聞くのは正しい。だから聞く。機能を追加するのは正しい。だから追加する。テストを書くのは正しい。だから書く。ドキュメントを整えるのは正しい。だから整える。気づいたら、最初に解決したかった問題が見えなくなっている。正しいことの山に埋もれて、本質が窒息している。「正しさ」は麻薬だ。やればやるほど気持ちいい。やればやるほど、完成から遠ざかる。隙間家具を作るとは、引き算をすることだ。機能を削る。対象を絞る。スコープを小さくする。「これだけは解決する」を決め、残りは捨てる。生成AIを使うとき、この引き算が難しくなる。AIは指示すれば無限に足し算を提案してくる。「この機能も追加しましょうか」「こういうオプションもあると便利です」「エラーハンドリングをもっと丁寧にしましょう」。全部、正しい提案だ。でも、全部受け入れると、隙間家具は大きな家具になる。AIは足し算が得意だ。引き算は人間がやる。私がAIに「削らせる」ときに使う問いかけがある。「この機能がなくても、最小限の価値は提供できるか？」。答えがYESなら、その機能は削る候補だ。AIの提案を聞いたら、「本当に必要か？」と問い直す。これが、AIとの協働における引き算の基本姿勢だ。「何を作るか」を決める課題を選ぶ引き算の最初は、「何を作るか」を1つに決めることだ。私が2025年に「代表作」に届かなかった理由の1つは、課題が大きすぎたことだ。「Kubernetesのログ管理を改善したい」と思った。でも、それは「どのログ」「どう改善」「誰のため」が決まっていない。漠然としすぎていた。結果、インパクトのあるものが作れなかった。「作りたいものはあるけど、何から手をつければ...」という状態は、課題が大きすぎるか小さすぎるかのどちらかだ。大きすぎると作りきれない。小さすぎると作る意味がない。「1つのツールで完結する」サイズを探す。課題が大きすぎる例:「Kubernetesの代替」「CI/CDパイプライン全体の改善」「インフラ自動化ツール」課題が小さすぎる例:「kubectl getのラッパー」「特定のエラーメッセージを整形するスクリプト」ちょうどいい例:「Podが再起動したときに直前のログを保存するツール」「複数リポジトリのCIステータスを一覧表示するCLI」「Terraformの差分をSlackに見やすく投稿するBot」ちょうどいいサイズの見つけ方は、「自分が1〜3日かけて解決したこと」を思い出すことだ。それは、深みがある。かつ、1つのツールで完結する気がする。隙間を見つける大きなツールが解決していない小さな問題。それが「隙間」だ。Kubernetes（コンテナオーケストレーション）は素晴らしい。しかし、Kubernetesが解決していない問題は山ほどある。Podが再起動したとき、前後のログを自動でSlack に送りたい。これはKubernetesの仕事ではない。Terraform（インフラ構成管理）も素晴らしい。ただ、差分をSlackに見やすく投稿したい。これはTerraformの仕事ではない。GitHubも同様だ。複数リポジトリのCIステータスを一覧で見たい。これはGitHubの仕事ではない。隙間を見つけるヒントは5つある。自分の不便。「こういうツールが欲しいのに、ない」という体験。私が作った隙間家具の中で、最も使われたものは、自分自身の問題を解決するために作ったものだった。自分が不便を感じているとき、そこには片づけたい「用事」がある。でも、それを片づける手段がない。私のGithub リポジトリからのスクショここで疑問が浮かぶ。「自分の不便」が特殊すぎるときはどうするのか。自分だけが困っている問題を解決しても、誰も使わないのではないか。だから2026年、私はこう決めた。最初は特殊すぎて構わない。なぜなら、特殊な問題を解決するツールでも、自分が本当に使うなら完成する。「誰かが使うかも」で作ったツールは、途中で手が止まる。まず完成させることが最優先だ。公開してみれば、同じ問題を抱えている人が意外といることに気づく。特殊だと思っていた不便が、実は普遍的だったというケースは多い。仮に本当に特殊で誰も使わなくても、自分の問題は解決している。それで十分だ。繰り返しの手作業。同じコマンドを何度も打っている。同じ手順を何度も実行している。毎回「面倒だな」と思いながら、やっている。ここで立ち止まる。この問題は「自動化すべき問題」か、それとも「慣れるべき問題」か。ツール化することで、本当に人間の負荷は減るのか。自動化によって、別の複雑さを生んでいないか。判断基準は、その作業が月に何回・何分発生しているかだ。月に1回、5分で終わる作業なら、自動化ツールを作るより慣れた方が早い。週に10回、毎回10分かかる作業なら、自動化する価値がある。感覚で判断しない。数字で判断する。例えば、複数のGitHubリポジトリのCIステータスを確認するとき、1つずつページを開いていた。毎回、5分くらいかかる。週に5回やっていた。月に100分。年に1200分。ツールを作る価値がある。作った。5分が10秒になった。コンテキストスイッチ。ある情報を得るために、複数のツールを行き来している。Slackを見て、Grafanaを見て、ログを見て、またSlackに戻る。情報を一箇所に集めるツールを作れば、コンテキストスイッチが減る。頭の負荷が減る。判断が速くなる。暗黙知。「あの人に聞けば分かる」「Slackのどこかにある」「この手順は、前にやったことある人しか知らない」。暗黙知をツールに埋め込めば、誰でも同じことができるようになる。複雑さ。「このツールは高機能だけど、使いこなせない」「設定項目が多すぎて、何を設定すればいいか分からない」。高機能なツールが、その機能を使い切れていない人たちを置き去りにしている。彼らに、シンプルで分かりやすい選択肢を提供する。これも隙間家具の仕事だ。課題を分解する課題が決まったら、5つまでに分解する。私がよくやる失敗は、分解せずに作り始めることだ。「ログ保存ツールを作ろう」と思って、いきなりコードを書き始める。途中で「保存先どうしよう」「認証どうしよう」「エラーハンドリングどうしよう」と考え始める。そのたびに手が止まる。最初に分解しておけば、こうはならない。「〇〇を作ろう」だけでは手が動かない。サブ課題に分解して、5つまでに絞る。5つに絞るのは、正直、苦しい。あれもこれも入れたくなる。でも、ジャムの法則と同じだ。サブ課題を10個、20個と出すと、どれに注力すべきか分からなくなる。例: 「Podが再起動したときに直前のログを保存するツール」Podの再起動を検知する仕組み直前のログを取得する方法ログを保存する先（S3など）CLIのインターフェースエラーハンドリング分解した項目が、そのまま実装の順番になる。「これは本当に必要か？」と自問すると、いろいろ見えてくる。実は同じことをしている項目。なくても動く項目。別のツールに任せた方がいい項目。削ることで本質が見える。5つに分解したら、次に優先順位をつける。何を基準に「残す1つ」と「後回しにする4つ」を決めるか。私の基準は、「これがないと、ツールとして成立しない」だ。技術的な実現性でも、ユーザーの感動でも、自分の興味でもない。「ツールの存在意義に関わるか」だ。例えば、「Podの再起動を検知する仕組み」がなければ、ログ保存ツールは成立しない。これが最優先だ。「CLIのインターフェース」は後でもいい。最初はハードコードでも動く。ここまでで、「何を作るか」と「どう分解するか」が決まった。でも、まだ足りない。「誰のために作るか」が決まっていない。「誰のために作るか」を決める望みを比較する同じツールでも、誰向けに作るかで設計が変わる。自分用なら雑でいい。他人に使ってもらうなら、READMEが必要だ。コミュニティに貢献したいなら、テストも書く。私が2025年に「代表作」に届かなかったもう1つの理由は、「誰のため」が曖昧だったことだ。「これ、公開したら使ってもらえるかな」と考えた瞬間、設計が複雑になる。「あの人はこういう使い方するかも」「この環境もサポートした方がいいかも」。考えれば考えるほど、作るものが膨らむ。膨らめば膨らむほど、作れなくなる。3つの望みがある。自分が作りたいもの。ユーザーが使いたいもの。コミュニティへの貢献。全部満たそうとすると、どれも中途半端になる。だから2026年、私はこう決断する。まず自分の問題を解決するツールを作る。当たり前すぎるかもしれない。でも、これが私の経験則だ。自分が本当に困っている問題なら、熱量が出る。熱量のあるツールは、ユーザーにも伝わる。これは「プロダクト」ではなく「道具」として十分に割り切れているか。プロダクトは他者のためにある。道具は自分のためにある。隙間家具は道具だ。自分の問題を解決するために作る。他者が使ってくれたらラッキー、くらいの気持ちでいい。汎用性を上げようとして、複雑さを持ち込んでいないか。持ち込みがちだ。「S3だけじゃなくGCSにも対応しよう」「Kubernetes以外でも使えるようにしよう」。その瞬間、道具がプロダクトになろうとする。複雑さが増す。完成しなくなる。READMEは「思想」ではなく「使い方」を語っているか。思想を語りがちだ。「なぜこのツールが必要か」「どんな設計思想か」。でも、ユーザーが知りたいのは「どう使うか」だ。インストール方法、実行方法、オプション。これだけでいい。自分以外の利用者がゼロでも、このツールは成立しているか。成立している必要がある。自分の問題が解決しているなら、それで十分だ。他者が使うかどうかは、結果論だ。「まだ誰も使っていない人」を見る自分が不便を感じているとき、同じ不便を感じている人は他にもいる。片づけたい用事があるのに、それを片づける手段を持っていない人。私はこの人たちを「まだ誰も使っていない人」と呼んでいる。自分がその一人だったなら、同じ境遇の人が他にもいるだろう。隙間家具は、この人たちに届ける。ここで注意が必要だ。ツールを公開すると、ユーザーからフィードバックが来る。「この機能が欲しい」「ここが使いにくい」。これは嬉しい。でも、ここに罠がある。既存ユーザーの声を聞けば聞くほど、既存ユーザーのためのツールになる。そして、「まだ誰も使っていない人」を見落とす。既存ユーザーの声に応え続けると、隙間家具は大きな家具になろうとし始める。機能が増え、複雑になり、最初のシンプルさを失う。新規ユーザーが求めているのは、高機能ではなく「すぐ使える」「分かりやすい」だ。「声」と「用事」を区別するフィードバックを受けるとき、「声」と「用事」を区別する。私も失敗したことがある。あるCLIツールを公開したとき、「設定ファイルで動作を変えたい」というフィードバックを複数もらった。嬉しかった。使ってくれている人がいる。だから、設定ファイル機能を実装した。YAMLで書けるようにした。オプションを増やした。結果、設定項目が20個を超えた。新しいユーザーは「設定が多すぎて何を設定すればいいか分からない」と言い始めた。シンプルさが売りだったツールは、複雑なツールになっていた。「声」は、ユーザーが言語化したものだ。「この機能が欲しい」「ここが使いにくい」。「用事」は、ユーザーが本当に片づけたいことだ。なぜその機能が欲しいのか。なぜそこを使いにくいと感じるのか。この「なぜ」の先に、本当の用事がある。例えば、CLIツールに「YAML出力オプションが欲しい」というフィードバックが来たとする。声をそのまま受け取れば、--output yamlフラグを実装することになる。でも、「なぜYAMLが欲しいのか」を問うと、「他のツールにパイプしたい」「設定ファイルとして保存したい」という用事が見えてくる。用事が分かれば、YAMLだけでなくJSONでも解決できるだろう。あるいは、標準出力をそのままパイプできる設計にすれば、フォーマット変換はjqに任せられるだろう。「この機能が欲しい」と言われたら、「なぜ」を問う。その人の用事は何か。その用事を片づける方法は、言われた機能だけか。もっとシンプルな方法はないか。ツールがヒットすると、「汎用化」の要望が必ず来る。「S3だけでなくGCSにも対応して」「Kubernetes以外でも使えるようにして」。これに応えると、隙間家具は大きな家具になる。だから私は、こう決めている。READMEが複雑になるなら、その機能は入れない。機能を追加するとき、READMEがどう変わるかを見る。説明が長くなるなら、別のツールにする。READMEがシンプルなら、ツールもシンプルだ。これが私の制約であり、美学だ。ここまでで、「何を作るか」「誰のために作るか」が決まった。次は、作る前に調べる。調べて、削る箱の中と外を探すいきなり作り始めたくなる。でも、その前に下調べをする。私は以前、「これ、俺が作らなくても既存ツールで十分だな」と気づいて手を止めたことがある。それ自体は正しい判断だった。でも、その後「じゃあ俺の経験は何に使えるか」を考えなかった。既存ツールを調べて終わり。それでは何も生まれない。似たツールはあるか。どんなアプローチがあるか。先人の知恵を借りる。「箱の中」は同じ領域の情報だ。公式ドキュメント、他の人の同じテーマのツール、GitHub Issues、Stack Overflow。正確性を担保し、抜け漏れを防ぐ。「箱の外」は自分の経験だ。実際に試した結果、ハマったポイントと解決策、自分なりの工夫や改善。これがオリジナリティの源泉になる。ここで重要なのは、インプットだ。本を読む。既存のOSSのコードをちゃんと読む。何のライブラリが使われていて、どのように問題を解決しているかを理解する。これが「箱の中」を深く知ることだ。例えば、Kubernetesのログ保存ツールを作るなら、既存の類似ツールのコードを読む。どのKubernetesクライアントライブラリを使っているか。どうやってPodの再起動を検知しているか。ログの取得にはどのAPIを使っているか。保存先との接続はどう抽象化しているか。コードを読まずに作り始めると、車輪の再発明をする。既に解決されている問題を、苦労して解き直す。あるいは、先人が避けた落とし穴にハマる。インプットの具体例を挙げる。本を読む：技術書だけでなく、設計思想やアーキテクチャの本も読む。『A Philosophy of Software Design』『The Art of Unix Programming』。隙間家具を作る視点が変わる。OSSのコードを読む：GitHubで似たツールを探して、main.goやlib.rsを読む。README だけでなく、実装を見る。「なるほど、こう解決するのか」という発見がある。ライブラリの使い方を学ぶ：使おうとしているライブラリのexampleを全部読む。ドキュメントを端から端まで読む。「こんな機能もあったのか」という発見が、設計を変える。「既に同じようなツールがある」は気にしない。同じ課題を解決するツールでも、価値を出せる理由はある。環境が違う。文脈が違う。深さが違う。切り口が違う。あなたのツールにしかない価値は、あなたの環境で動いた事実、あなたがハマったポイント、あなたの言葉での説明だ。「n番煎じ」でも、あなたの経験を加えれば価値になる。「箱の外」の材料を増やすために、私が意識的にやっていることがある。「自分の仕事を観察する」だ。エンジニアリング以外のインプットも大事だが、それ以上に、自分が日常的にやっている作業を観察する。「今、何に時間を使っているか」「何に苛立っているか」「何を繰り返しているか」。この観察が、隙間を見つける材料になる。選択マップで削る材料が揃ったら、「何を作り、何を作らないか」を選ぶ。私は「全部入り」を目指しがちだ。ログ保存ツールを作るなら、S3もGCSもAzure Blobも対応したくなる。Slack通知もメール通知もつけたくなる。そうこうしているうちに、何も作れなくなる。選択マップとは、集めた選択肢を視覚的に整理し、最適な組み合わせを見つける方法だ。課題から分岐して選択肢を並べ、各選択肢のメリット・デメリットを可視化する。例: 「OOMKilled（メモリ不足による強制終了）の調査方法を紹介するツール」調査方法は複数ある。kubectl top（リソース使用状況確認）、Grafana（可視化ダッシュボード）、pprof（プロファイリングツール）、サードパーティツール。読者に最も役立つのはどれか。kubectl topは簡単ですぐ使えるが、瞬間値しか見られない。Grafanaは履歴を見られるが、セットアップが必要。pprofは詳細に分析できるが、設定が必要で学習コストは高い。選択結果：読者の多くは「まず何が起きてるか知りたい」→ kubectl top + Grafanaを中心に作る。pprofは発展編として軽く触れるか、別のツールにする。足し算の発想だと、全部の方法をサポートしようとする。焦点がぼやける。誰にも刺さらない。引き算の発想だと、「これだけは作る」を決める。残りは捨てる。刺さるツールになる。良いツールは「何を作らないか」で決まる。スコープを絞る勇気隙間家具は、特定の問題を解決する。汎用性を追求しない。「このコンテキストで、この問題を解決する」に集中する。例えば、「KubernetesのPodが再起動したとき、直前のログを自動でS3に保存するツール」。汎用的ではない。Kubernetesを使っていて、ログをS3に保存したい人だけを対象にする。でも、それでいい。特定の問題を、特定のコンテキストで、確実に解決する。これが隙間家具の価値だ。汎用性は、使われてから考えればいい。最初から汎用的に作ろうとすると、要件が膨らみ、複雑になり、いつまでも完成しない。ここまでで、何を作るか、誰のために作るか、何を作らないかが決まった。いよいよ作る。小さく作って、見せる第三の目で検証する作った。動いた。自分では完璧に見える。でも、それは危険なサインなんだ。私にも経験がある。あるCLIツールを作って、自分では「完璧だ」と思った。README も書いた。インストール方法も書いた。でも、同僚に見せたら「これ、何をするツールなの？」と聞かれた。私には当たり前すぎて、説明を省略していた。「前提知識がないと、何も分からない」。そのツールは結局、私しか使わなかった。使い方を説明する手間を惜しんだ結果だ。作った本人には見えない穴がある。「当然わかるでしょ」と省略している。専門用語を説明なしで使っている。論理の飛躍に気づかない。自分では完璧に見える。だから、他者に見せる。使ってもらう。フィードバックをもらう。隙間家具を必要としている人は、探していない。問題を抱えているが、解決策があるとは思っていない。だから、「検索してたどり着く」ことを期待できない。では、どうやって届けるか。自分の体験を語る。「私はこういう問題を抱えていた。だから、このツールを作った。」「まだ誰も使っていない人」は、同じ問題を抱えているだろう。ブログやTwitterで体験を語れば、「あ、自分もこの問題を抱えている」と思ってもらえる。READMEに機能を列挙するだけでは届かない。「なぜこのツールを作ったか」「どんな問題を解決するか」を語る。「まだ誰も使っていない人」は、自分の不便を言語化できていないことが多い。だから、状況を描写する。「毎朝、Slackを開いて、Grafanaに移動して、ログを確認して、またSlackに戻る...この作業、面倒じゃないですか？」。機能ではなく、状況を語る。「あ、それ自分だ」と思わせる。ツールの説明ではなく、問題の描写から始める。これが、言語化できていない不便に気づかせるストーリーテリングだ。入り口を簡単にするインストールが面倒だと、人は離れる。設定が複雑だと、人は離れる。最初の一歩を、できるだけ簡単にする。go install 一発でインストールできる。設定ファイルは最小限。デフォルトで動く。これが理想だ。なぜなら、新しいツールを試すとき、人は「動かすまでの時間」を無意識に測っている。5分で動かなければ、「また今度」になる。設定が多いツールは、5分では動かない。だから、試されずに終わる。パワーユーザーは細かい設定を求めるだろう。でも、パワーユーザーは「まだ誰も使っていない人」ではない。最初に届けるべきは、5分で動くシンプルさだ。新しいツールは、最初は既存のツールより「劣っている」ことが多い。機能が少ない。パフォーマンスが低い。でも、シンプルで、分かりやすくて、すぐに使える。それでいい。隙間家具は、シンプルでいい。1つのことを、確実にやる。それが、「まだ誰も使っていない人」に届く。「ジャムの法則」をインターフェースにも適用する。CLIツールなら、フラグを減らす。理想は、引数なしで動くこと。mytoolと打てば、最も一般的なユースケースが実行される。設定が必要なら、対話的に聞く。フラグは上級者向けのショートカットだ。最初から覚えてもらうものではない。選択肢を減らすことで、ユーザーは「考える」から「使う」にすぐ移れる。このツールは「技術的に正しい」より「現場で生き残る」設計になっているか。技術的に正しい設計は、しばしば複雑になる。すべてのエッジケースに対応する。すべてのエラーを丁寧にハンドリングする。でも、現場で使われるツールは、シンプルで、雑でも動く。エッジケースを切り捨てた理由を説明できるか。説明できる必要がある。「このケースは月に1回しか発生しない。手動で対応すればいい。だから、ツールでは対応しない。」こう言い切れるなら、切り捨てていい。例外処理より「何も起きないこと」を優先していないか。優先していい。エラーが発生したとき、丁寧なエラーメッセージを出すより、そもそもエラーが発生しない設計の方がいい。入力を厳しくする。想定外の状態を作らない。現場の雑さ・曖昧さ・不完全さを前提にできているか。現場は綺麗ではない。設定ファイルにtypoがある。環境変数が設定されていない。ネットワークが不安定。この雑さを前提に設計する。「完璧な環境でしか動かないツール」は、現場では使われない。小さく始める6ステップを踏んでも、完璧なツールは作れない。だから、小さく始める。最初から完璧なツールを作ろうとしない。自分の問題を解決するスクリプトから始める。それが動いたら、少し整えて公開する。私の場合、多くの隙間家具は、最初はただのシェルスクリプトだった。自分の問題を解決するために、ちょっと書いた。それが便利だったので、もう少し整えた。それを公開した。完璧を目指すと、いつまでも公開できない。「もう少し機能を追加してから」「もう少しドキュメントを整えてから」。そうこうしているうちに、作る気力がなくなる。動くものを、まず作る。公開する。使ってもらう。フィードバックをもらう。改善する。このサイクルを回す。隙間家具を1つ公開したら、終わりではない。むしろ、ここからが始まりだ。探索を続ける捨てやすく作るここからが、私が一番伝えたいことだ。隙間家具には寿命がある。状況が変われば、不要になる。だから、捨てやすく作る。このツールは「自分が将来保守したいコード」になっているか。正直に言えば、保守したくないコードの方が多い。だから、捨てやすく作る。保守したくなるほど愛着が湧くツールは、20個に1個くらいでいい。半年後の自分が読んで理解できる設計になっているか。なっていなくてもいい。半年後に必要なら、そのとき書き直せばいい。必要なければ、捨てればいい。機能追加ではなく「削除」するとしたら、どこを真っ先に消すか。この問いを常に持っておく。削除できる部分があるなら、それは最初から作らなくてよかった部分かもしれない。このコードは、使われなくなったときに綺麗に捨てられるか。捨てられる設計にしておく。依存を少なく。外部サービスとの結合を弱く。捨てるときに、誰にも迷惑がかからないように。私が作ったツールの中で、すでに捨てたものがある。Kubernetesをインストールするツールを作っていた。当時、Kubernetesのインストールは複雑で、手順を間違えると動かなかった。だから、自動化ツールを作った。便利だった。でも、kubeadmがリリースされて、インストールが簡略化された。ツールは不要になった。リポジトリをアーカイブした。悲しくはなかった。むしろ、「自分の問題意識は正しかった」と思えた。Kubernetesの開発者も同じ問題を認識していたのだから。このOSSは「本流に取り込まれる未来」を想定できているか。想定しておく。もしKubernetesやTerraform本体に同等機能が入ったら、どうするか。喜んで捨てる。それは「失敗した」のではなく「役目を終えた」のだ。本流に吸収されるために、意図的にやっていないことは何か。汎用化だ。本流は汎用的になろうとする。隙間家具は特殊なままでいい。特殊だから、本流が取り込みにくい。特殊だから、生き残れる。隙間家具は、状況が変われば不要になる。Kubernetesのバージョンが上がって、その問題が解決されるだろう。別のツールが登場して、より良い解決策を提供するだろう。だから、依存を少なく、シンプルに作る。捨てやすく作る。大きな家具は、捨てにくい。多くのリソースを投入している。多くの人が使っている。捨てることが難しい。隙間家具は、捨てやすい。役目を終えたら、捨てる。そして、新しい隙間を見つけて、新しい隙間家具を作る。「隙間」が「本流」に飲み込まれるリスクもある。Kubernetesのサイドカー機能が進化するように、プラットフォーム自体が隙間を埋めてしまうことがある。これに対する私の戦略は2つだ。1つ目は、捨てやすく作ること。本流に飲み込まれたら、素直に捨てる。自分の問題意識が正しかった証拠だと喜ぶ。2つ目は、本流が手を出さないニッチに特化すること。Kubernetesは汎用的になろうとする。だから、特定の会社の特定のワークフローに特化したツールは、本流が取り込みにくい。汎用化できないほど特殊なニッチを狙う。これも生存戦略だ。捨てたツールから得られる学びもある。単なる「失敗」で終わらせず、次の探索に活かせる知見を抽出する。私がやっているのは、「なぜこのツールは役目を終えたのか」を言語化することだ。本流に取り込まれたのか。別のツールが出てきたのか。そもそも問題設定が間違っていたのか。この分析が、次の隙間を見つける精度を上げる。「問題設定が間違っていた」が一番の学びだ。次は同じ間違いをしない。深化と探索隙間家具を1つ作ったら、終わりではない。隙間家具の開発には、2つの仕事がある。「深化」と「探索」だ。「深化」は、既存の隙間家具を改善すること。バグを直す。パフォーマンスを改善する。ドキュメントを整える。「探索」は、新しい隙間を見つけること。新しい用事を発見すること。新しい隙間家具を作ること。問題は、「深化」へ偏りやすいことだ。既存のツールへイシューが立つ。プルリクエストが来る。対応すると達成感がある。でも、これだけやっていると、最初に見つけた隙間だけを相手にし続けてしまう。競争のないところに宝がある。既存の競合がひしめく場所ではなく、誰も見ていない場所を探す。だから2026年、私はこう決めた。小さな実験を続ける。1つの隙間家具に全力を注ぐのではなく、複数の隙間家具を作り、どれが使われるか見る。全部が使われるわけではない。むしろ、使われないものの方が多い。でも、それでいい。使われなかったツールからも、学びがある。その学びが、次の探索に活きる。チーム開発での引き算ここまでの話は、一人で作る「隙間家具」を前提にしてきた。では、複数人で開発するときはどうか。「引き算の哲学」をチームで共有できるのか。私の経験では、スコープを最初に合意することが鍵だ。「このツールは何を解決し、何を解決しないか」を、開発を始める前にドキュメントへ書く。機能追加の提案が来たら、このドキュメントに立ち返る。「このスコープ外です」と言える根拠になる。チームでの合意形成は、一人のときより難しい。でも、「1つのREADMEで説明できる範囲」という制約は、チームでも使える。「この機能を追加したら、READMEはどう変わるか」を問う。READMEが複雑になるなら、その機能は入れないか、別のツールにする。この基準は、チームメンバー全員が判断できる。個人の好みではなく、客観的な基準だ。おわりにここまで読んでくれた人に、正直に書く。この文章を書きながら、私は何度も手を止めた。「こんなこと書いて意味あるのか」「誰が読むんだ」「もっといい構成があるんじゃないか」。書いている最中に、書くのをやめる理由を探している自分がいた。「代表作」に届かない理由と、まったく同じ構造だ。笑えない。2026年、私は隙間家具を20個作ると決めた。完璧じゃなくていい。動けばいい。使われなくてもいい。作ることそのものに意味がある。そう自分に言い聞かせている。本当にできるかは、分からない。来年の今頃、GitHubにリポジトリが20個並んでいる保証はどこにもない。また「時間がなかった」「優先順位が」と言い訳しているかもしれない。その可能性は、正直、かなり高い。でも、書いた。こうして宣言してしまった。「何を作ればいいか分からない」という人へ。それは正常だ。ゴールは最初から見えているものじゃない。作っているうちに、少しずつ輪郭が浮かんでくる。だから今日、30分だけ時間を取って、最近「面倒だな」と思った作業を1つ書き出してみてほしい。それを解決するスクリプトを書く。動いたら公開する。それだけでいい。20回繰り返す頃には、自分が本当に作りたいものが見えてくる。たぶん。見えてこなかったら、そのときはまた考える。ところで、ここまで偉そうに書いてきたが、私は孤独な独身男性だ。家族はいない。守るべきものが少ない分、狂いやすい環境にいるとも言える。歯止めをかけてくれる人がいない分、自分で自分を律する必要がある。友達との飯の予定。ジムの予約。強制的に「コードを書かない時間」を作らないと、際限なく沈んでいく。独身には独身の戦い方がある。OSSより大事なものはある。友達と話す時間。体を動かす時間。コードは逃げない。隙間家具はいつでも作れる。でも、友人との関係は放っておくと薄れる。健康は一度壊すと戻らない。狂うなら、余裕のあるときに狂え。順番を間違えると、人生ごと壊れる。......と、説教じみたことを書いたが、たぶん来年の今頃の私は、この文章を読み返して頭を抱えている。「狂う」とか言って、結局また「そこそこ」で終わったじゃないか、と。nwiizoというアカウントは、また少し大きくなっているだろう。「代表作」のハードルも、また少し上がっているだろう。自分で自分の首を絞める構造は変わらない。それでも、諦めたくない。憧れたエンジニアたちがいる。彼らのように、「これを作りました」と胸を張れる日が来るまで、手を動かし続ける。だから、書いておく。まず狂え。量をやれ。そして、量が満ちたら、容赦なく削れ。答えが出ない状態は、苦しい。でも、その苦しさの中を泳ぎ続けることでしか、本当に作りたいものは見つからない。完璧を待たない。不完全なまま公開する。恥をかく覚悟で、手を動かす。2026年は、そういう年にする。できるかどうかは知らない。でも、やると決めた。隙間を見つけたら、小さく狂おう。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考文献人生にコンセプトを (ちくまプリマー新書)作者:澤田智洋筑摩書房Amazonセンスは知識からはじまる作者:水野学朝日新聞出版Amazonセンスの哲学 (文春e-book)作者:千葉 雅也文藝春秋Amazon人生の経営戦略――自分の人生を自分で考えて生きるための戦略コンセプト２０作者:山口 周ダイヤモンド社Amazon「面白い！」を見つける　――物事の見え方が変わる発想法 (ちくまプリマー新書)作者:林雄司筑摩書房AmazonTHINK BIGGER 「最高の発想」を生む方法：コロンビア大学ビジネススクール特別講義 (NewsPicksパブリッシング)作者:シーナ・アイエンガーニューズピックスAmazonわかったつもり～読解力がつかない本当の原因～ (光文社新書)作者:西林 克彦光文社Amazon知ってるつもり　無知の科学 (ハヤカワ文庫NF)作者:スティーブン スローマン,フィリップ ファーンバック早川書房Amazon私が間違っているかもしれない作者:ビョルン・ナッティコ・リンデブラッド,キャロライン・バンクラー,ナビッド・モディリサンマーク出版Amazon不完全主義 限りある人生を上手に過ごす方法ノーブランド品Amazon不完全主義　限りある人生を上手に過ごす方法作者:オリバー・バークマンかんき出版Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon新版 いくつになっても、「ずっとやりたかったこと」をやりなさい。作者:ジュリア・キャメロン,エマ・ライブリーサンマーク出版Amazonいくつになっても恥をかける人になる【DL特典 恥克服ワークシート】作者:中川諒ディスカヴァー・トゥエンティワンAmazon増補改訂版 スマホ時代の哲学 なぜ不安や退屈をスマホで埋めてしまうのか (ディスカヴァー携書)作者:谷川嘉浩ディスカヴァー・トゥエンティワンAmazon自分とか、ないから。　教養としての東洋哲学作者:しんめいPサンクチュアリ出版Amazon人生のレールを外れる衝動のみつけかた (ちくまプリマー新書)作者:谷川嘉浩筑摩書房Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[決断をプロットし、全力で走り続けるためのプロジェクトドキュメント管理]]></title>
            <link>https://zenn.dev/kamos/articles/adr_documentation</link>
            <guid isPermaLink="false">https://zenn.dev/kamos/articles/adr_documentation</guid>
            <pubDate>Mon, 22 Dec 2025 03:55:55 GMT</pubDate>
            <content:encoded><![CDATA[!この文章は人間が書きました画像はGeminiを使って生成しました なぜ、私たちはドキュメントを求めるのか開発現場において、ドキュメント管理は永遠の課題だ。点在する情報、矛盾する記述、実装との乖離、記されない背景情報など、ドキュメントの陳腐化は様々な形で現れる。これらに立ち向かおうとしては、その管理コストの高さに圧倒される。効果が明確に見えにくく、長い時間のかかるドキュメント整備をやり切ることは難しく、多くの現場でドキュメントは放置され、陳腐化し続けている。今度こそドキュメントの整備をやり切ると決意し、絶望する前に考えてほしい。私たちはなぜドキュメントがほしいのか？欲しいも...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Visualizing Coupling in Rust Projects]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/152559</guid>
            <pubDate>Sun, 21 Dec 2025 06:25:59 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling Web UI - Self-diagnosis viewIntroduction"I really don't want to touch this module..."If you've been developing software long enough, you know this feeling. Every change breaks something else. Tests are painful to write. Understanding what the code even does feels impossible. These symptoms share a common root cause: modules that depend too heavily on each other—the problem of coupling.Coupling problems are insidious. They're hard to notice while you're writing code, only revealing themselves later when you wonder why changes are so difficult. What makes it worse is that even when you know "coupling is too tight," it's hard to see exactly where and how, or where to start fixing it.Looking back, I realize my understanding of coupling was quite shallow. I was making judgments based on vague feelings—"this seems tightly coupled" or "loose coupling is supposedly better"—but when I tried to articulate why, I couldn't explain it clearly.To address this lack of visibility, we need a way to measure coupling. But the traditional single axis of "strong vs. weak" isn't enough. The same "strong coupling" means different things depending on where it occurs and in what context.This brings us to Vlad Khononov's concept of "Balanced Coupling." It's a framework that evaluates coupling across three dimensions: strength, distance, and volatility, then assesses their balance. cargo-coupling is a tool I developed to implement this framework for Rust projects.Even as AI writes more of our code, this coupling metric becomes increasingly important. Regardless of who or what writes the code, humans still need to understand, maintain, and extend it. In fact, precisely because AI generates code, we need objective measures to evaluate its structure.Let's start with an overview of the tool, then explore the underlying concepts, and finally see how to use it in practice.What is cargo-coupling?cargo-coupling is a coupling analysis tool I developed for Rust projects.The inspiration came from Vlad Khononov's book "Balancing Coupling in Software Design." The challenges I had vaguely sensed about coupling design were systematically organized in this book. I was impressed by the framework that captures coupling through three dimensions—strength, distance, and volatility—and wanted to create a tool that makes this practical for Rust projects. I highly recommend picking up the book.The tool is available on GitHub. If you find it useful, I'd appreciate a star!GitHub:github.comcrates.io: https://crates.io/crates/cargo-couplingNow, let's challenge a common assumption."Coupling should be minimized"—isn't that what you believe?This tool doesn't aim to "reduce coupling." It aims to "design coupling appropriately." Why? Because coupling isn't inherently bad. Related functionality working closely together is natural. The problem is "strong coupling in inappropriate places" or "tight coupling between distant modules." This shift in perspective is at the heart of this tool.# Installationcargo install cargo-coupling# Basic usagecargo coupling ./srcAnalyzing Coupling Across Three DimensionsSo what exactly constitutes "appropriate coupling"?Traditional coupling analysis tends to think in terms of a single "strong/weak" axis. But stop and consider: strong coupling with an adjacent module versus strong coupling with a distant external library—shouldn't these mean different things? And coupling with code unchanged for five years versus coupling with code modified weekly—shouldn't these carry different risks?A single axis can't capture these differences. cargo-coupling measures coupling across three independent dimensions.1. Integration StrengthThe first dimension is "coupling strength"—how much modules know about each other's internals.Have you seen code like user.password_hash that directly accesses struct fields? That's the strongest form of coupling. Meanwhile, code that interacts through impl Trait works without knowing the other's internals. This difference gets quantified as a score. Level  Score  Description  Rust Example  Intrusive  1.00  Direct dependency on internal implementation  struct.field direct access  Functional  0.75  Dependency on function signatures  Method calls  Model  0.50  Dependency on data structures  Type definitions, type parameters  Contract  0.25  Interface/trait only  impl Trait 2. DistanceThe second dimension is "distance"—how far apart coupled modules are in the code's scope hierarchy.Functions within the same file working closely together is natural. But what if src/auth/login.rs directly references src/billing/invoice.rs? Or worse, depends on an external crate's internal structure? The farther the distance, the "heavier" that coupling becomes. Level  Score  Description  SameModule  0.25  Within the same file/module  DifferentModule  0.50  Different module in the same crate  DifferentCrate  1.00  External crate dependency 3. VolatilityThe third dimension is "volatility"—how frequently the code changes.Your project surely has stable modules untouched for over a year alongside modules modified weekly. Depending on stable code versus frequently changing code carries different risks. cargo-coupling automatically calculates this volatility from Git history. Level  Score  Changes in 6-month Git history  Low  0.00  0-2 changes  Medium  0.50  3-10 changes  High  1.00  11+ changes Calculating the Balance ScoreWe've covered the three dimensions. But if you're told "strength is 0.75," "distance is 0.50," "volatility is medium"—how do you judge whether this coupling is actually good or bad?cargo-coupling combines these three dimensions into a balance score. By consolidating three numbers into one score, you can intuitively assess whether coupling is appropriate.The concept is simple: multiply "strength-distance balance" by "volatility risk."ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACTThe first formula measures whether strength and distance are proportionate. Close distance can tolerate strong coupling; far distance should mean weak coupling. The second formula measures the combined risk of change frequency and coupling strength. Strong coupling with frequently changing code means higher risk of being affected by every change.The conclusions this formula leads to:Strong coupling + Close distance → Good: High cohesion with related functionality in one moduleWeak coupling + Far distance → Good: Loose coupling architecture with minimal inter-module dependenciesStrong coupling + Far distance → Bad: Global complexity where changes affect wide areasStrong coupling + High volatility → Bad: Change propagation risk where frequent changes cascadePractical UsageNow that we understand the theory, let's see how to use it on real projects. cargo-coupling offers multiple output formats depending on your needs.Summary Displaycargo coupling --summary ./srcExample output:Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9Hotspot AnalysisIdentify high-priority modules that need refactoring.cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rsImpact AnalysisExamine the impact scope when changing a specific module.cargo coupling --impact metrics ./srcWeb UI VisualizationVisualize coupling relationships with an interactive graph.cargo coupling --web ./srcA browser opens automatically, displaying an interactive graph using Cytoscape.js. Click nodes to see detailed information; problematic modules are color-coded.CI/CD IntegrationBeyond manual analysis, you can continuously monitor quality. Incorporating cargo-coupling as a quality gate enables early detection of coupling design degradation.cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actions example:- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcReturns exit code 1 when the grade falls below the threshold, making it easy to integrate into CI pipelines.AI IntegrationWhen using with Claude Code or GitHub Copilot, the --ai option is convenient.cargo coupling --ai ./srcOutput is formatted in an AI-friendly way, so you can paste it directly into AI tools to get refactoring suggestions.Detected Problem PatternsHaving covered usage, you might wonder what specific problems get detected. Here are the representative patterns cargo-coupling warns about.God ModuleA module with too many functions, types, or impls.Functions: 30+Types: 15+Impls: 20+High Efferent CouplingA module with too many dependencies. Default threshold is 20+ dependencies.High Afferent CouplingA module depended on by too many others. Default threshold is 30+ dependents.Cascading Change RiskThe combination of intrusive coupling and high volatility. A dangerous state where changes propagate across wide areas.Interpreting Health GradesDetection results are ultimately consolidated into a single grade representing overall project health. Grade  Description  S  Over-optimized. Might be over-refactored  A  Well-balanced. Ideal state  B  Healthy. Manageable condition  C  Room for improvement  D  Attention needed  F  Immediate action required Interestingly, S grade is considered "overdone." Why?Reducing coupling too much fragments code excessively, making the big picture harder to see. Have you experienced needing to open 10 files to trace a single operation, or getting lost in abstraction layers so deep you wonder "what does this actually do?"Coupling isn't simply "less is better." Balance is key.Library UsageBeyond the CLI tool, you can embed it in your own tools. cargo-coupling is also published as a library, allowing you to call analysis functions directly from code.use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST analysis    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git volatility analysis    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // Balance analysis    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}Performancecargo-coupling is designed to run fast even on large projects.Parallel AST analysis with RayonStream processing of Git historyBenchmarks: 655ms on tokio (488 files)Use the --no-git option to skip Git analysis for even faster operation.LimitationsWhile useful, this tool isn't omnipotent. Know these limitations before using it.External crate dependencies aren't analyzed: Dependencies on serde, tokio, etc. aren't analyzed since developers can't control themStatic analysis only: Runtime behavior and macro expansion aren't fully capturedGit history required: Volatility analysis needs Git history. Short history reduces accuracyConclusioncargo-coupling provides a practical approach of "choosing appropriate coupling" rather than the simplistic view that "coupling is bad."3-dimensional analysis: Considers strength, distance, and volatility simultaneouslyGit integration: Reflects actual change frequency as dataActionable suggestions: Presents concrete refactoring actionsMultiple output formats: Text/JSON/Web UI/AI-friendlyCI/CD integration: Automated checks as quality gatesYou don't need perfect design. With a pragmatic attitude that "80% improvement is enough," gradually improve your project's health.# Try it outcargo install cargo-couplingcargo coupling --summary ./srcJust visualizing coupling problems is the first step toward better design.The next time you feel "I really don't want to touch this module..."—that's no longer a vague anxiety. It's a tractable challenge you can analyze across three dimensions of strength, distance, and volatility, and translate into concrete improvement actions. That feeling isn't something to fear; it's the entry point to improvement.A related concept is "Complexity" from John Ousterhout's "A Philosophy of Software Design." It offers another valuable perspective and is well worth reading.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[A Beginner’s Guide to Pulumi: Provisioning Your First Infrastructure with Python]]></title>
            <link>https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/a-beginners-guide-to-pulumi-provisioning-your-first-infrastructure-with-python-1fd8b323f86d?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Sun, 21 Dec 2025 04:29:37 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[ おい、休め]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/21/092456</guid>
            <pubDate>Sun, 21 Dec 2025 00:24:56 GMT</pubDate>
            <content:encoded><![CDATA[はじめに金曜日の夜、ベッドの上でこの文章を書き始めている。先週の土日は何をしていたかと聞かれたら、たぶん「寝てた」と答える。嘘ではない。ベッドにいた時間は長かった。ただ、眠っていたかというと怪しい。スマホを持ったまま横になって、気づいたら夕方だった。そういう二日間だった。休んだのか、と聞かれると困る。体は動かしていない。仕事もしていない。だから休んだと言えば休んだのだろう。でも、回復したかというと、していない。月曜の朝を迎える自分は、金曜の夜の自分より確実に疲れている。 何もしていないのに。何もしていないから、かもしれない。30歳になった。エンジニアとして働いている。在宅勤務というやつだ。2025年、AIエージェントが当たり前になった時代を生きている。AIは文句を言わない。疲れたとも言わない。24時間動ける。私にはそれができない。コーヒーがないと朝は動けないし、金曜の午後は集中力が死んでいる。土日は「充電」と称してベッドに沈んでいる。それでも充電されない。この一年、ずっとそうだった。ある日、気づいたことがある。私は「休んでいる」んじゃなくて、「動けなくなっている」だけだった。充電じゃなくて、バッテリー切れの放置だった。「休んでいるのに休めていない」とは、「休んでいるのに休めていない」。変な問答である。矛盾しているように聞こえるが、多くの人がこの感覚を知っていると思う。週末を過ごしたはずなのに、月曜日の朝に疲れが残っている。肉体的には、労働的には、確かに「活動していない」。仕事をしていない。オフィスにいない。だから「休んでいる」となんとなく認識する。しかし脳は、休んでいない。ベッドに横になりながらスマホを見ている時、目は画面を追い、脳は情報を処理し、感情は刺激に反応し続けている。通知が来るたびに注意が引かれる。SNSのタイムラインをスクロールするたびに、微小な判断が積み重なる。「これは読む価値があるか」「これにいいねするか」「これに反応すべきか」。身体は止まっているが、脳は回り続けている。これが「休んでいるのに休めていない」の正体だ。情報を入れ続けると、脳は整理する暇がない。食べ続けて消化できない胃のように、頭がパンク状態になる。入力過多で、整理が追いついていない。なぜ本人は「休んでいるつもり」になってしまうのか厄介なのは、本人が気づいていないことだ。私もそうだった。「横になっている＝休んでいる」。この等式が、骨の髄まで染み込んでいる。かつて「休む」とは、物理的に動かないことを意味した。畑仕事を終えて家に帰り、座って何もしない。工場での労働を終えて、ソファに横になる。肉体労働の時代には、「動かない = 休息」という等式が成り立っていた。しかし現代のデスクワーク的な仕事は、主に脳を使う。特にエンジニアは、一日中座っている。肉体は動いていない。だから「仕事 = 動くこと」という図式が崩れている。そして「休息 = 動かないこと」という古い図式をそのまま適用すると、「横になってスマホを見ること」も休息にカウントされてしまう。肉体的には動いていないのだから。でも実際には、脳は仕事中と同じかそれ以上に動いている。休息の定義を更新する必要がある。現代において「休む」とは、脳への入力を減らすことだ。物理的な動きの有無ではなく、認知的な負荷の有無で判断すべきなのだ。この状態を言語化できないと、何がさらに悪化するのか「休んでいるのに休めていない」という感覚を言葉にできないと、さらに深刻な問題が起きる。まず、自己診断を誤る。「十分休んでいるはずなのに疲れている。だから自分は病気かもしれない」「自分は人より弱いのかもしれない」。実際には休息の質の問題なのに、自分の身体や精神に問題があると思い込んでしまう。次に、対処法を間違える。「もっと休めばいい」と考えて、さらに長時間ベッドでスマホを見る時間を増やす。これは逆効果だ。質の悪い休息を量で補おうとしても、回復はしない。そして最も深刻なのは、周囲に理解されないことだ。「週末何してたの？」「ずっと寝てた」「じゃあ休めたね」。この会話で、問題は見えなくなる。本人も「確かに休んだはずだ」と思い込み、周囲も「休んだのだから元気なはずだ」と期待する。「休んだ」という事実と、「休めた」という実感の乖離。これが現代の休息における新しい病だ。言語化できない問題は、解決できない。 だからまず、この状態に名前をつけることが重要だ。「偽りの休息」「見せかけの休息」「脳が休まらない休息」。何でもいい。言葉にすることで、初めて問題として認識できる。AIエージェント時代の疲労2025年、AIエージェントが本格的に動き始めた。Claude Code、Devin、Cursor Agent。これらは単なるツールではない。私たちと同じように考え、判断し、実行する存在になった。コードを書くだけでなく、何を書くべきかを考える。指示を待つだけでなく、自ら次のステップを提案する。この変化は、エンジニアの疲労の質を根本から変えた。AIは無限に働ける。私たちは有限だ。AIエージェントは疲れない。朝も夜も関係ない。週末も祝日も関係ない。感情の浮き沈みもない。モチベーションの低下もない。常に一定のパフォーマンスで、無限に働き続ける。私たちは、そうではない。8時間働けば疲れる。集中力は25分で途切れる。昼食を食べすぎると眠くなる。金曜日の午後は効率が落ちる。睡眠不足の翌日は判断を誤る。感情に左右される。体調に左右される。天気にすら左右される。この対比が、2025年の疲労を特殊なものにしている。かつて、比較対象は同僚だった。隣の席のエンジニアより速くコードを書けるか。チームの中で自分はどの位置にいるか。人間同士の比較だった。今、比較対象にAIが加わった。AIエージェントが一晩で書いたコードを見て、「自分が一週間かかることを、一晩でやった」と思う。AIが瞬時に出した答えを見て、「自分が一時間悩んだことを、数秒で解決した」と思う。無限と有限を比較している。もちろん、話はそう単純じゃない。AIにも限界がある。文脈を読み違える。ハルシネーションを起こす。「それっぽい嘘」を自信満々に言う。コードレビューなしでマージしたら、後で痛い目に遭う。AIが「無限に働ける」のは事実だが、「無限に正しい」わけではない。でも、そんなことは分かっている。分かっていても、比較してしまう。「比較しなければいい」と思ったこともある。でも、環境がそれを許さなかった。同じSlackチャンネルに、自分が1日かけて作ったPRと、AIが1時間で作ったPRが並んでいる。見た瞬間に、脳が勝手に比較する。「あっちの方が速い」と。そう思った時点で、もう比較している。これは意志の問題じゃない。環境の問題だ。同じ画面に並んで表示されている限り、見比べてしまう。見比べれば、負ける。負ければ、「自分は遅い」「自分は非効率だ」「自分は価値がない」と感じる。この感覚が、静かに、確実に、私たちを消耗させている。AIによって増えたのは「作業量」だけではなく、AIエージェントを使うと、作業は速くなる。コードの生成、ドキュメントの作成、調査の実行。これらは確かに効率化される。しかし、楽にはならない。夕方になると、頭が重い。コードを書く時間は減った。でも疲労感は増えている。増えたのは作業量じゃない。判断の回数だ。AIエージェントは大量の選択肢を提示する。コードの候補を10個出す。アプローチを5つ提案する。修正案を複数示す。これらを評価し、選択し、修正し、採用するかどうかを決めるのは人間だ。従来の仕事では、一つのタスクに対して一つの判断があった。自分で作るから、作成と判断が一体化していた。AIを使うと、この構造が変わる。AIが10個の選択肢を提示する。人間は10個を評価し、1つを選ぶ。あるいは「どれも違う」と判断して再生成を指示する。今度は別の10個が出てくる。また評価する。選ぶ。修正を指示する。一つのタスクに対して、判断の回数が爆発的に増える。思い当たることがある。午前中は「これがいい」「あれはダメ」とサクサク判断できる。でも夕方になると、どれを選んでいいか分からなくなる。「どれでもいいから決めてくれ」と思う。頭が重くなって、判断を先延ばしにしたくなる。これは、判断そのものに消耗があるということだ。人間が一日に下せる質の高い判断の数には限りがある。 判断を重ねるほど、後の判断の質は落ちる。AIは判断を代行してくれない。むしろ、判断すべき選択肢を増やす。だから、作業時間が減っても、認知的な消耗は増える。「便利になった」という感覚と、「楽になった」という現実は、必ずしも一致しない。「速くなった」と感じるのに、疲れは減らない。この乖離は危険だ。「速くなっている」と思い込んでいる限り、「なぜ疲れるのか」という問いにたどり着けない。AI疲れはスキル不足の問題ではないAI疲れを感じたとき、多くの人はこう考える。「自分のスキルが足りないからだ」「もっとAIを使いこなせるようになれば楽になる」。正直に言うと、私もそう思っていた。だから毎晩、新しいツールを試し、プロンプトを改善し、ワークフローを最適化した。でも楽にはならなかった。むしろ疲れた。ただ、ここで立ち止まって考えたい。私はこう思うようになった。それは違うんじゃないか、と。確かに、AIツールの使い方には習熟曲線がある。最初は戸惑う。慣れれば効率が上がる。しかし、ある程度習熟した後も、判断疲れは消えない。むしろ、AIを使いこなせるようになるほど、使う頻度が上がり、判断の回数も増える。AI疲れ ≠ スキル不足。AI疲れ = 判断疲れだ。 あなたが下手なんじゃない。ゲームのルールが変わったのだ。AIは人間の判断を代行しない。判断の対象を増やす。この構造的な問題は、スキルアップでは解決しない。解決策は、使い方を変えることだ。AIに全てを任せるのではなく、判断の負荷が高い場面では意識的に使わない。あるいは、AIの出力をそのまま採用する覚悟で使う（評価・修正のループを断ち切る）。しかしこれは、「AIを使いこなす」という文脈では語られない。だから多くのエンジニアは、スキル不足を疑い、さらに学習し、さらに使い、さらに疲れる。AI疲れの原因を正しく特定して認識することが、回復への第一歩だ。「恥」という名の監視システムエンジニアには、独特の恥の文化がある。Xを開く。誰かが「今週読んだ技術書3冊」と投稿している。誰かが「個人開発で新しいフレームワークを試した」と書いている。GitHubの草が青々と茂っている。日曜日の夜に。その瞬間、土日に何もしなかった自分が恥ずかしくなる。「エンジニアは勉強し続けなければならない」。これは真実だ。技術は進化する。学ばなければ置いていかれる。それは分かっている。でも、いつからか「土日に勉強するのが当たり前」になった。休日に技術書を読まないと不安になる。個人開発をしていないと焦る。Qiitaに何も投稿していない月があると、自分の価値が下がった気がする。私たちは「恥」に操られている。恥は、外部から強制されるものではない。誰かに「勉強しろ」と言われているわけではない。上司が土日の学習を義務付けているわけでもない。自分で自分を監視している。 SNSで他人の「充実した週末」を見て、勝手に比較して、勝手に恥じて、勝手に休めなくなっている。これが最も効率的な搾取システムだ。命令する必要がない。監視する必要がない。本人が勝手に自分を追い詰めてくれる。見せかけの「学習」が休息を奪う問題は、この「恥を避けるための学習」が、本当の意味での学習になっていないことだ。土曜日の朝、罪悪感から技術書を開く。でも頭に入ってこない。疲れているから。ページをめくるけど、内容が定着しない。それでも「読んだ」という事実が欲しくて、最後までめくる。これは学習ではない。休息でもない。どちらでもない時間だ。本当に学びたいときの読書と、恥を避けるための読書は、まったく別物だ。前者は楽しい。後者は苦痛だ。前者は定着する。後者は忘れる。恥を避けるために費やした土日は、学習にも休息にもならない。最悪の投資だ。 時間を使って、何も得られず、回復もしない。SNSで他人の土日を見るな。あれは広告だ。冷静に考えてほしい。Xに投稿される「充実した週末」は、全員の週末の平均ではない。投稿したくなるような週末だけが投稿される。何もしなかった週末は投稿されない。つまり、タイムラインに流れてくるのは、全エンジニアの「最も充実した瞬間」の集合体だ。それを自分の「普通の週末」と比較している。勝てるわけがない。他人の土日は広告だ。 広告と自分を比較して落ち込むのは、モデルの写真を見て自分の顔を恥じるのと同じだ。フィルターがかかっている。編集されている。現実ではない。恥を手放すことは、怠惰ではない「じゃあ勉強しなくていいのか」と思うかもしれない。そうではない。学びたいときに学べばいい。休みたいときに休めばいい。恥に駆動されるのをやめろ、と言っている。恥から学習すると、燃え尽きる。好奇心から学習すると、続く。この違いは大きい。土日に何もしなかった自分を、責めなくていい。月曜日に元気に働けるなら、それが正解だ。GitHubの草が生えていなくても、あなたの価値は変わらない。恥は、休息の最大の敵だ。 そして恥は、自分で自分にかけている呪いだ。縛りである。しかし、呪いは、気づいた瞬間に弱くなる。注意力が商品化されるとは、人生に何が起きることなのかふと考えた。なぜ、こんなに疲れているのか。答えの一つは、私たちの注意力が「商品」として売買されているということだ。スマホを開く。通知が来る。タップする。広告が表示される。スクロールする。また通知が来る。この一連の行動の中で、私たちの「注意力」は企業に売り渡されている。そして企業はその注意力を広告主に売る。注意力が奪われることは、なぜ「時間」以上の損失なのか「時間が奪われている」という表現は、まだ甘い。時間は、失っても取り戻せる可能性がある。今日の2時間を失っても、明日の2時間で何かができる。少なくとも、時間は均質に見える。しかし注意力は違う。注意力とは、「今この瞬間に何を経験するか」を決める力だ。何に注意を向けるかが、何を経験するかを決める。何を経験するかが、何を記憶するかを決める。何を記憶するかが、自分が誰であるかを決める。つまり、注意力を奪われることは、経験を奪われることであり、記憶を奪われることであり、最終的にはアイデンティティを奪われることだ。2時間スマホをスクロールして過ごした後、何が残っているか。私の場合、ほとんど何も覚えていない。「何を見てたっけ」と思い返しても、断片的な画像がぼんやり浮かぶだけ。時間は確かに過ぎた。でも経験は残っていない。一方で、友人と2時間話した後は違う。「あの話、面白かったな」「あのとき笑ったな」と、具体的な場面が残っている。同じ2時間でも、記憶への定着度がまるで違う。スマホを見ることも、一応は「経験」だ。でも、受け身で流れてくる情報を処理するだけの経験と、自分で選んだ活動に没頭する経験では、残り方が違う。受け身の時間は、砂に書いた文字のように消えていく。時間泥棒ではなく、人生泥棒だ。なぜ人は自分の注意力の価値に無自覚なのか注意力は、意識しないと見えない。お金は数字として見える。時間は時計として見える。しかし注意力は、どこにも可視化されていない。そして注意力は、「使っている」という感覚がない。お金を使うとき、財布が軽くなる感覚がある。時間を使うとき、時計が進む感覚がある。しかし注意力を使うとき、何かが減っていく感覚は薄い。ただ、気づいたら疲れている。さらに問題なのは、注意力を奪う側が、その事実を隠すインセンティブを持っていることだ。SNSは「つながり」を売り物にする。「あなたの大切な人とつながるためのツール」。しかし実際には、あなたの注意力を広告主に売るためのツールだ。この真実は、マーケティングでは語られない。だから私たちは、自分の注意力が商品になっていることに気づかない。気づかないまま、どんどん売り渡していく。この構造に気づいても、人はなぜ抗えないのか気づいても、抗えない。これが最も絶望的な部分だ。理由の一つは、脳の報酬系がハックされているからだ。通知が来る。ドーパミンが出る。確認する。また通知が来る。この「不定期な報酬」は、脳にとって最も中毒性が高い。スロットマシンと同じ原理だ。いつ当たるか分からないから、ずっと引き続けてしまう。理由のもう一つは、社会的なプレッシャーだ。みんなが使っている。使わないと取り残される。返信しないと失礼。既読をつけないと心配される。SNSから離れることは、社会から離れることのように感じられる。そして最後の理由は、代替手段がないことだ。仕事の連絡もスマホで来る。友人との約束もスマホで確認する。情報収集もスマホでする。スマホを捨てることは、現代社会で生きることを諦めることに近い。構造的な問題には、個人の意志力だけでは対抗できない。だからこそ、意識的な「デジタルデトックス」が必要になる。完全に離れることはできなくても、時間を区切って距離を取る。それが、今できる最大の抵抗だ。オンライン会議は、なぜ「効率的なのに疲れる」のかスマホから注意を奪われるだけではない。在宅勤務の日常には、もう一つの消耗源がある。オンライン会議だ。最初はただ素晴らしいと思った。移動時間がない。どこからでも参加できる。効率的だ、と。でも二年、三年と続けるうちに、何かがおかしいと気づいた。ある日、オンライン会議が5本続いた後、私は何も考えられなくなっていた。画面を閉じても、頭の中がぼんやりしている。簡単なメールすら書けない。対面で5本会議しても、こんなに消耗しなかった。何かが違う。対面では無意識に処理していた情報とは何か対面のコミュニケーションでは、膨大な情報が交換されている。言葉だけではない。表情、視線、姿勢、身振り、声のトーン、間の取り方、呼吸のリズム、空間的な距離感。これらの非言語情報が、コミュニケーションの大部分を占めている。そして重要なのは、これらの情報を無意識に処理しているということだ。対面で話しているとき、相手の表情を「分析」しているわけではない。自然と読み取っている。相手が不快そうなら、無意識に話し方を変える。相手が興味を持っていそうなら、無意識に詳しく説明する。この調整は、意識的な努力なしに行われている。オンライン会議では、この無意識の処理が機能しなくなる。画面越しでは、表情が見えにくい。解像度が低い。タイムラグがある。視線が合わない（カメラを見ると相手の目を見られない）。空間的な距離感がない。全員が同じサイズで画面に並んでいる。無意識に処理できていた情報を、意識的に処理しなければならなくなる。「この人は今、何を考えているのだろう」「この沈黙は同意なのか、困惑なのか」「自分の話は伝わっているのか」。対面なら自動的に分かることが、オンラインでは分からない。だから脳がフル回転して、推測し、分析し、判断する。これが、オンライン会議の疲労の正体だ。さらに、自分の顔が常に画面に映っている。鏡を見ながら会話しているようなもの。音声も微妙に不完全で、脳は余計な労力を使う。同じ1時間でも、処理している情報の密度が違う。だから疲れる。私はこの疲労を個人の問題だと思っていた。でも違った。組織の設計そのものが、この疲労を生み出している。振り返ると、非同期のコミュニケーションで済むことを、わざわざ会議で行っていた。私自身、「対話が必要な場面」に限定することで、オンライン会議の負荷を減らせた。ある日、仕事を一つ担当から外してもらった。「これ、ちょっと抱えすぎてます」と正直に言った。その週、少しだけ頭がクリアだった。「手放してもいい」と思えた瞬間だった。境界線が消えたとき、人間の回復機構はどう壊れるのか在宅勤務で最も失われたもの。それは「境界線」だ。帰りたいのに家に居る。オフィスに通っていた頃は、自然と境界線があった。家を出る。通勤する。オフィスに着く。仕事モードになる。仕事が終わる。オフィスを出る。通勤する。家に着く。オフモードになる。この物理的な移動が、心理的な切り替えを助けていた。在宅勤務では、その境界線が消えた。起きたらすぐに仕事。寝る直前まで仕事。仕事部屋と寝室が同じ。リビングがオフィス。どこでも働ける = どこにも逃げ場がない。物理的な移動は、なぜ心理的切り替えに効いていたのか通勤を嫌う人は多い。満員電車。渋滞。時間の無駄。その通りだ。しかし通勤には、見えない機能があった。通勤は「儀式」だった。人間の脳は、儀式を通じて状態を切り替える。朝のルーティン、食事の作法、寝る前の習慣。これらの儀式が、脳に「次のモードに入る」というシグナルを送る。通勤は、最も強力な儀式の一つだった。家という空間を離れ、別の空間に移動する。その過程で、脳は自然と「仕事モード」に切り替わっていた。帰宅時には逆のプロセスが起きていた。この儀式が消えると、脳は切り替えのタイミングを失う。「いつ仕事を始めるべきか」「いつ仕事を終えるべきか」が曖昧になる。そして気づけば、常に「なんとなく仕事モード」で過ごすことになる。常に仕事モードということは、常に回復モードに入れないということだ。境界線がない働き方は、どんな人に特に危険か特に危険なのは、責任感が強い人と仕事が好きな人だ。「まだできることがある」と思うと止められない。楽しいから止められない。境界線がないと、いつまでも「まだやれる」と思ってしまう。個人の工夫と、その限界着替える。仕事着から部屋着に。あいさつを声に出す。「お疲れ様でした」。これらの小さな儀式が、切り替えを助ける。しかし、限界がある。本来、境界線は環境によって与えられていた。それを個人の意志で維持し続けることは、それ自体が消耗を伴う。だから、環境そのものを変える必要がある。 仕事専用の部屋を作る。コワーキングスペースを使う。PCを別の部屋に置く。物理的に「できない」状態を作る。意志力に頼らない仕組みを作ること。それが、境界線を維持する現実的な方法だ。「疲れた」と感じるとき、本当に疲れているのはどこか「疲れた」と口にする。でも、どこが疲れているのか、自分でも分かっていない。疲れには三つの種類がある。「自律神経の疲れ」。自律神経とは、意識しなくても働く神経システムだ。活動モードを司る交感神経（心拍を上げ、筋肉を緊張させる）と、休息モードを司る副交感神経（心拍を下げ、消化を促す）がある。この二つのバランスが崩れている状態。常に緊張している。リラックスできない。眠れない。朝起きても疲れが取れない。「心の疲れ」。精神的な消耗。ストレス。不安。焦り。人間関係の疲れ。感情労働による消耗。「体の疲れ」。筋肉の疲労。運動不足による倦怠感。同じ姿勢での身体の凝り。自律神経・心・身体のどれが最初に壊れやすいのかこれは個人差があるが、現代のエンジニアにとって、最初に壊れやすいのは自律神経だ。理由は、自律神経の疲労が最も気づきにくいからだ。身体の疲れは分かりやすい。筋肉痛がある。だるさがある。明確な感覚として認識できる。心の疲れも、ある程度は分かる。「イライラする」「落ち込む」「やる気が出ない」。感情として表れる。しかし自律神経の疲れは、症状が曖昧だ。「なんとなく調子が悪い」「眠れない」「食欲がない」「息苦しい」。これらの症状は、他の原因でも起きる。だから「自律神経が疲れている」とは認識されにくい。そして気づかないまま酷使し続けると、ある日突然、限界を超える。動悸がする。めまいがする。パニック発作が起きる。ここまで来て初めて「何かがおかしい」と気づく。自律神経は悲鳴を上げない。気づいたときには、もう限界を超えている。なぜ現代のエンジニアは三重苦に陥りやすいのか問題は、これらが複雑に絡み合っていることだ。長時間のデスクワークで体が疲れる。動かないから血流が滞り、肩が凝り、腰が痛くなる。AIへのキャッチアップ、締め切りのプレッシャー、評価への不安で心が疲れる。オンライン会議の連続、境界線のない働き方、常時接続のプレッシャーで自律神経が疲れる。これらは独立していない。相互に影響し合う。身体が疲れると、心も疲れやすくなる。運動不足はうつ病のリスクを高める。心が疲れると、自律神経が乱れる。ストレスは交感神経を活性化させる。自律神経が乱れると、身体の回復力が落ちる。悪循環のスパイラル。一つの疲れが、他の二つを引き起こし、それがまた最初の疲れを悪化させる。このスパイラルに入ると、自力で抜け出すのは難しい。疲れを誤診すると、どんな「間違った休み」を選ぶのか疲れの種類を見極めずに休もうとすると、的外れな対処をしてしまう。身体が疲れているのに、心の休息を取ろうとする。例えば、運動不足で身体が固まっているのに、マッサージに行ったり、リラクゼーション音楽を聴いたりする。これは悪くないが、根本解決にならない。必要なのは軽い運動だ。心が疲れているのに、身体の休息を取ろうとする。例えば、人間関係のストレスで消耗しているのに、ひたすら寝ようとする。眠れない。眠れても回復しない。必要なのは、安全な場所で感情を吐き出すことだ。自律神経が疲れているのに、刺激で気分転換しようとする。例えば、交感神経が過剰に活性化しているのに、アクション映画を観たり、激しいゲームをしたりする。一時的に気が紛れても、神経はさらに疲弊する。必要なのは、静かな環境でぼんやりすることだ。自分の疲れの種類を見極めること。それが、正しく休むための第一歩だ。身体がシャットダウンする「動けなさ」は、怠惰と何が違うのかベッドから起き上がれない朝がある。やるべきことは分かっている。でも体が動かない。これは怠けているのか。それとも、何か別のことが起きているのか。自分の「動けなさ」について考えていくうちに、気づいたことがある。怠惰と「動けなさ」は、外から見ると同じに見える。でも中身はまったく違う。怠惰は「やる気がない」状態だ。やろうと思えばできる。でもやりたくない。シャットダウンは「動けない」状態だ。やろうと思っても、身体が言うことを聞かない。脳が「これ以上は危険だ」と判断して、強制的にブレーキをかけている。これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。身体を動かなくすることで、エネルギーを温存する。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。社会はなぜこの状態を「甘え」と誤認するのか問題は、シャットダウン状態が外から見ると「怠けている」ように見えることだ。ベッドから起き上がれない。仕事に行けない。何もする気力がない。社会は、これを「意志の問題」として捉えがちだ。「頑張れば動ける」「やる気がないだけ」「甘えている」。しかし、これは生理的な反応だ。動物が捕食者に捕まったとき、最後の防衛反応として「死んだふり」をすることがある。これがシャットダウン反応だ。身体を動かなくすることで、エネルギーを温存し、捕食者の関心を逸らす。人間も同じメカニズムを持っている。ストレスが大きすぎて、闘うことも逃げることもできないとき、身体がシャットダウンする。これは意志の問題ではない。脳が「これ以上は危険だ」と判断して、強制的に止めているのだ。怠惰との違いは明確だ。怠惰は「やる気がない」状態。やろうと思えばできる。シャットダウン状態は「動けない」状態。やろうと思っても、身体が言うことを聞かない。この区別ができないと、本人も周囲も対応を間違える。本人が自分を責めることで、状態はどう固定化されるのか最も危険なのは、本人が自分を責めることだ。「動けないのは自分が怠けているからだ」「意志が弱いからだ」「努力が足りないからだ」。この自己批判が、状態をさらに悪化させる。自己批判はストレスを生む。ストレスは交感神経を活性化させる。しかし、すでに疲弊した身体は交感神経の活性化に耐えられない。だから、また身体がシャットダウンする。「動けない → 自分を責める → ストレス増加 → さらに動けなくなる → さらに自分を責める」この悪循環が、状態を固定化する。回復するためには、この循環を断ち切る必要がある。そのためにはまず、「動けないのは意志の問題ではない」と理解することが重要だ。 自分を責めることをやめる。これが、回復への第一歩だ。この凍結状態から抜けるには、何が最初の一歩になるのかシャットダウン状態から抜け出すのは、簡単ではない。「頑張って動く」というアプローチは逆効果になりうる。有効なのは、身体への穏やかなアプローチだ。まず、安全を感じること。物理的に安全な場所にいる。誰にも批判されない。時間的なプレッシャーがない。この「安全の感覚」が、安心・つながりモードを呼び起こす。次に、身体を少しだけ動かすこと。激しい運動ではない。深呼吸。ゆっくりとしたストレッチ。5分の散歩。これらの穏やかな動きが、身体に「動いても大丈夫だ」というシグナルを送る。そして、人とのつながり。信頼できる人との会話。これらの社会的なつながりが、安心・つながりモードを呼び起こす。重要なのは、「頑張る」のではなく「許す」ことだ。動けない自分を責めない。ゆっくり回復することを許す。無理に何かを達成しようとしない。このスタンスが、凍結状態から抜け出すための土台になる。私自身、過去の失敗をいつまでも反芻して、自分を追い詰めていた時期がある。でも気づいた。忘れることは、逃げではない。 嫌な記憶を手放すことで、初めて前に進める。回復とは、忘れるべきものを忘れられるようになることでもある。なぜ「何もしない休み」が回復にならない場合があるのか休息も、量を追い求めるだけでは意味がない。「長時間休んだ」という事実よりも、「どう休んだか」という質の方がずっと重要だ。休息には二つのタイプがある。「パッシブレスト（消極的休養）」。何もしない。寝る。横になる。身体を動かさない。これは従来の「休息」のイメージだ。「アクティブレスト（積極的休養）」。軽く身体を動かす。散歩する。ストレッチする。ヨガをする。能動的に身体を使うことで回復する。どちらが正解か、ではない。どちらが自分に足りていないかが問題だ。ただ、直感に反するが、現代のエンジニアにはアクティブレストの方が足りていない場合が多い。パッシブレストが逆効果になる条件は何かパッシブレストが逆効果になるのは、以下のような場合だ。身体が動かなすぎているとき。一日中座っていて、血流が滞っている。筋肉が固まっている。この状態でさらに横になっても、血流は改善しない。疲労物質は排出されない。むしろ、さらに滞留する。脳だけが疲れているとき。身体は使っていない。脳だけが酷使されている。この状態で「何もしない」と、身体と脳のアンバランスが解消されない。脳を休めるには、逆に身体を動かす方が効果的な場合がある。横になりながら刺激を受けているとき。ベッドでスマホを見ている状態。身体は休んでいるが、脳は休んでいない。これは休息ではない。むしろ、最悪の組み合わせだ。社会的な孤立状態のとき。一人で何もしない時間が長すぎると、孤独感が増す。孤独は心身に悪影響を与える。パッシブレストが孤独を深めるなら、逆効果だ。アクティブレストは、なぜ自律神経に効くのかアクティブレストが効果的な理由は、生理学的に説明できる。血流が改善する。軽い運動は心拍数を適度に上げ、血液循環を促進する。これにより、筋肉に蓄積した疲労物質が排出される。新鮮な酸素と栄養が全身に行き渡る。自律神経のバランスが整う。適度な運動は、交感神経と副交感神経の切り替えをスムーズにする。運動中は交感神経が優位になり、運動後は副交感神経が優位になる。このリズムが、自律神経の柔軟性を高める。脳の状態が変わる。運動は脳内のセロトニンやエンドルフィンの分泌を促す。これらの神経伝達物質は、気分を改善し、ストレスを軽減する。「運動後に気分がスッキリする」のは、この効果だ。睡眠の質が向上する。日中に適度に身体を動かすと、夜の睡眠が深くなる。これにより、睡眠中の回復効率が上がる。アクティブレストは、受動的な休息では得られない回復効果をもたらす。「休んでいるのに疲れる」行動には共通点があるか「休んでいるつもりなのに疲れる」行動を分析すると、共通点が見えてくる。脳への入力が続いている。スマホ、テレビ、SNS。これらは「受動的」に見えるが、脳は常に情報を処理している。休息ではなく、低負荷の作業だ。身体が動いていない。座っている。横になっている。血流が滞る。筋肉が固まる。代謝が落ちる。社会的なつながりがない。一人で画面に向かっている。人との会話がない。孤独が深まる。達成感がない。ただ時間が過ぎるだけ。何も生み出していない。何も経験していない。虚しさが残る。能動的に選ばなかった時間は、記憶に残らない。後から振り返っても、「何をしていたんだっけ」と思い出せない。これらを逆転させれば、「本当に休まる休息」が見えてくる。脳への入力を減らす。画面から離れる。静かな環境に身を置く。身体を動かす。散歩する。ストレッチする。軽い運動をする。人とつながる。会話をする。一緒に過ごす。達成感を得る。小さなことでいい。料理を作る。掃除をする。何かを「やった」という感覚を持つ。選択的休養という考え方「休む」というと、どうしても「消極的」なイメージがある。何もしない。停止する。エネルギーを使わない。でも、より効果的な休養の形がある。自分で選ぶ休養だ。休息は空いた時間を埋めるものではない。休息は設計対象だ。どう休むかを、自分で決める。「そんな時間ないよ」と思うかもしれない。でも、選択的休養は時間の量ではなく質の問題だ。30分でもいい。自分で選んだ30分は、誰かに決められた2時間より回復効果がある。選択的休養とは、自分の意志で、自分のために選んだ活動のことだ。ポイントは「自分で選ぶ」ことにある。誰かに言われてやるのではない。義務感でやるのではない。「やるべき」だからやるのではない。自分が「やりたい」と思って選ぶ。この「選ぶ」という行為自体が、回復をもたらす。なぜ「自分で選ぶ」ことに意味があるのか現代の疲労の多くは、選択権を奪われていることから来ている。仕事では、やるべきことが決まっている。締め切りがある。上司の指示がある。クライアントの要望がある。自分で選ぶ余地が少ない。プライベートでも、「やるべきこと」に追われている。家事、育児、介護、人付き合い。「自分のため」ではなく「誰かのため」に時間を使う。そして「空いた時間」にスマホを見る。これも、実は選択ではない。アルゴリズムが見せたいものを見せられている。自分で選んでいるようで、選ばされている。常に誰かに決められた行動をしている。だからこそ、「自分で選ぶ」ことに価値がある。自分で選んだ活動をしているとき、脳は「自分の人生をコントロールしている」と感じる。この感覚が、ストレスを軽減し、回復を促進する。逆に、誰かに決められた行動をしているとき、脳は「コントロールを失っている」と感じる。これがストレスの原因になる。選択的休養とは、人生の主導権を握り直すことだ。 そしてこれは、何を覚えておくかだけでなく、何を忘れるかを選ぶことでもある。AIは全てを記憶できる。でも人間は違う。だからこそ、意識的に手放す。追いかけなくていい情報を捨てる。キャッチアップしなくていい技術を諦める。その余白に、自分だけの発想が生まれる。選択的休養の条件選択的休養が効果的であるためには、いくつかの条件がある。自分で決めた。誰かに言われてではなく、自分の意志で選ぶ。「やらなければ」ではなく「やりたい」という動機。仕事とは関係ない。スキルアップのための勉強は選択的休養ではない。仕事に役立つ読書も違う。仕事と完全に切り離された活動。なぜなら、仕事に関連している限り、「成果を出さなければ」というプレッシャーがつきまとうからだ。没頭できる。時間を忘れて集中できる。義務感ではなく、純粋な興味や楽しさで取り組める。成長の実感がある（任意）。必須ではないが、少しずつ上達していく実感があると、より効果的だ。仕事以外の領域で「できるようになった」という経験は、自己効力感を高める。私の場合、それは楽器を弾くことと、格闘技のジムに通うことだった。ギターを弾く時間は、仕事とは無関係で、自分で決めた活動で、時間を忘れて没頭でき、少しずつ上達していく実感がある。格闘技のジムには、別の効果がある。自分一人では無限に追い込めない。だから、真剣にやる以外に選択肢がない環境に身を置く。スパーリング中は、仕事のことなど考えていられない。相手のパンチを避けることに全神経を集中させている。休む時は、可能な限り忘れる。 この忘却を強制してくれる環境が、私には必要だった。なぜ「楽ではないこと」が回復になるのかここで一つの逆説に気づく。格闘技は楽ではない。むしろ苦しい。汗をかく。息が切れる。翌日は筋肉痛だ。苦しいのに、なぜかジムの帰り道は頭が軽い。通い続けるうちに、分かってきた。私が選んだ苦しみは、喜びになる。考えてみれば不思議だ。ホラー映画、激辛料理、過酷な登山。人は日常では避けるはずの「痛み」や「恐怖」に、わざわざ金と時間を払って近づく。私も格闘技に月謝を払っている。殴られに行っている。なぜか。「選んだ苦痛」と「押しつけられた苦痛」は、まったく別物だからだ。仕事のストレス、人間関係の摩擦、将来への不安。これらは望んでいない。避けたいのに避けられない。コントロールできない。だから消耗する。格闘技の苦しさは違う。私が選んだ。いつでもやめられる。コントロールできる。だから同じ「苦しい」でも、片方は消耗で、片方は回復になる。そしてもう一つ気づいたことがある。楽なだけの人生は、たぶんつまらない。苦しみを避け続けた先に、充実はない。ベッドでスマホを見続ける週末は、苦しみをゼロにしようとする試みだ。でもそれは、意味もゼロにしてしまう。何も残らない。月曜日に「週末何してた？」と聞かれて、答えられない。格闘技は苦しい。でも意味がある。だから回復する。「楽であること」と「良いこと」は違う。 私はこれを、身体で学んだ。「ギターや格闘技なんて、自分には無理だ」と思うかもしれない。でも、選択的休養の本質は特定の活動ではない。「仕事の自分」とは別の自分に会いに行くことだ。ランニングでも料理でも将棋でも絵でも釣りでもいい。重要なのは、「仕事に役立つかもしれない」という思考を捨てること。 役に立たなくていい。役に立たないからこそ、純粋に楽しめる。その純粋さが、回復をもたらす。もう一つ、見つけ方のコツがある。周りに勧められたものを、何も考えずに始めてみる。自分で選ぼうとすると、「合うかな」「続くかな」と考えすぎて動けなくなる。友人が「一緒にやろう」と誘ってくれたら、とりあえず乗ってみる。合わなければやめればいい。始める前に悩むより、始めてから判断する方がずっと早い。「役に立たない」と思って捨てたものの中に、自分を救うものがある。デジタルデトックスという実践ある日、スマホを置いて散歩に出た。1時間後、頭が軽かった。そこで気づいた。私の疲労の大きな部分は、デジタル機器から来ていた。 正確には、デジタル機器が境界線を消し、常時接続状態を作り、注意力を奪い続けていた。全ての疲労がデジタル由来ではないが、デジタルが他の疲労を増幅させている。だからこそ、「デジタルデトックス」が必要だ。大げさなことではない。スマホを別の部屋に置く。一日一時間、画面を見ない時間を作る。寝る前の一時間はスマホを触らない。これだけでも効果がある。最初は落ち着かない。通知が気になる。何かを見逃しているような気がする。FOMO（見逃すことへの恐怖）が襲ってくる。この不快感こそが「摩擦」だ。 そして摩擦があるからこそ、その先にある回復は本物になる。でも、数日続けると気づく。別に何も見逃していない。大抵のことは、後から確認しても問題ない。「今すぐ」反応しなければならないことなど、実際にはほとんどない。そして画面から離れた時間に、不思議なことが起きる。頭がクリアになる。創造性が戻ってくる。ぼんやりと考えごとをする余裕が生まれる。有限であることを受け入れ、有限であるからこそできることを大切にする。デジタルから離れた時間は、人間としての有限性を肯定する時間だ。スマホを置いた瞬間、世界は何も変わらない。でも、自分だけが少し回復する。みんな、もっと真剣に休む方法を考えた方がいい。働き方は語られる。生産性は語られる。キャリアは語られる。でも休み方は、ほとんど語られない。「休めばいい」で片付けられる。それは違う。どう働くかと同じくらい、どう休むかは設計が必要なのだ。孤独という敵在宅勤務を続けていると、ある問題に直面する。孤独だ。孤独は好きだと思っていた。一人で考える時間、一人でコードを書く時間、誰にも邪魔されない自由。それを選んで在宅勤務を続けてきた。思えば、昔からそうだった。初対面だけは愛想がいい。すぐに打ち解ける。でも、それ以上は仲良くならない。小学生の頃から「一番仲の良い友達」というものがいなかった。人のことを、どこかで信用しきれない。だから深い関係を避けてきた。孤独は、選んだというより、そうなっていた。でも気づいた。私が「孤独を好んでいる」と思っていたのは、実は「人間関係の疲れから逃げていた」だけかもしれない、と。オンライン会議で消耗する。Slackで気を遣う。だから一人でいたくなる。これは「孤独を選んでいる」のではなく、「疲弊して引きこもっている」だけだ。健全な孤独と、不健全な孤独は違う。健全な孤独は、充電された状態から自分を選ぶこと。不健全な孤独は、消耗した状態から逃避すること。安心している状態から選ぶ孤独は健全だ。身体がシャットダウンした凍結状態としての孤独は、危険信号だ。休むためには、時に人とつながる必要がある。 矛盾しているようだが、社会的なつながりが足りていない状態では、一人でいても回復しない。孤独を選んでいるのか、孤独に追い込まれているのか。この違いを見極めることが、回復の分岐点になる。有給休暇を取るということ去年、有給休暇を40日以上残したまま年度が終わった。「有給どれくらい残ってる？」「40日以上」「俺も」。この会話を何度もした。笑い話みたいに。でも笑えない。40日間、自分のための時間を放棄したということだ。プロジェクトが忙しい。休むと仕事が溜まる。チームに迷惑がかかる。そう言い聞かせてきた。でも本当の理由は違う気がする。「休む理由がない」と思っていた。体調が悪いわけでもない。旅行の予定があるわけでもない。だから働く。この発想自体がおかしかったのだ。ある日、何の予定もなく有給を取ってみた。朝起きて、コーヒーを淹れて、本を読んで、散歩して、昼寝して、夕方になった。何も生産しなかった。何も達成しなかった。でも、妙に満たされていた。気づいたのは、「理由がないから休まない」は、「理由がないと自分を大切にしない」と同じだということ。病気になるまで働いて、やっと休む権利を得る。それは順序が逆だ。リモートワークでは、この問題がさらに深刻になる。どこでも働けるから、どこにいても「働いていない自分」に罪悪感を覚える。有給を取っても、Slackが気になる。結局PCを開いてしまう。有給休暇の本質は、「働かない時間を作る」ことではない。「働かない自分を許す練習」だ。睡眠という基盤深夜2時。また技術記事を読んでいる。「これだけ読んだら寝よう」と思って開いたブラウザのタブが、気づけば15個になっている。一つ読むと、関連記事が気になる。そっちを開く。また関連記事が出てくる。無限ループだ。睡眠が大事なことくらい、知っている。知っていて、毎晩削っている。「知っている」と「できる」の間には、深い溝がある。ある時期、睡眠時間が4時間を切る日が続いた。最初は平気だった。むしろ「自分は少ない睡眠でも動ける」と思っていた。でも二週間くらいで、明らかにおかしくなった。簡単なコードでミスを連発する。同じ箇所を何度も読み返す。会議で人の話が頭に入ってこない。睡眠不足は、自分では気づけない。認知機能が落ちているから、「認知機能が落ちている」ことを認知できない。これが一番怖いところだ。酔っ払いが「俺は酔ってない」と言うのと同じ構造。睡眠不足の人間は、自分が睡眠不足だと正しく判断できない。睡眠中、脳は単に休んでいるのではない。日中に入ってきた情報を整理し、不要なものを捨て、必要なものを定着させている。この作業が追いつかないと、頭の中がゴミ屋敷になる。思考がまとまらない。創造性が消える。読んだ本の内容が腑に落ちるのは、読んだ直後ではない。数日後、ふと「あれはこういうことだったのか」と分かる瞬間がある。その熟成には、睡眠が必要だ。睡眠を削ることは、未来の自分から時間を前借りしている。 利息は高い。そして返済は、体調不良という形でやってくる。今夜削る2時間は、来週のどこかで4時間になって返ってくる。しかも最悪のタイミングで。「効率を手放す」とは、エンジニアにとってどんな覚悟か私たちエンジニアは、効率を追求することに慣れている。コードを最適化する。プロセスを改善する。無駄を省く。それが仕事だ。でも、休息に効率を求めてはいけない。「最も効率的な休息法は何か」「最短時間で最大の回復効果を得るには」「休息の ROI を最大化するには」こういう発想自体が、休息を台無しにする。余暇にまでROIを求める病一日中「効率」を考えている。その思考パターンが、仕事以外の時間にも染み出してくる。無意識のうちに「この行動の費用対効果は」と考えてしまう。時間の希少性。仕事が忙しい。自由な時間が少ない。だから、その貴重な時間を「最大限に活用したい」と思う。無駄にしたくない。効率的に楽しみたい。成果主義の内面化。成果で評価される環境に長くいると、「成果がなければ価値がない」という信念が内面化される。休息も「何かを得るため」に行うべきだと思ってしまう。不安の回避。何もしないことが怖い。生産性がない自分に価値がないと感じる。だから、休息さえも「生産的」にしようとする。非効率な時間は、どんな価値を回復させるのかしかし、非効率な時間には、効率では得られない価値がある。余白から、ふとしたひらめきが生まれる。このブログの構成も、散歩中にふと浮かんだ。何かを「考えよう」としているときではなく、何も考えていないときに、頭が勝手に整理を始める。そして不思議なことに、この整理の過程で、脳は細部を手放している。細部を忘れているからこそ、異なる記憶同士が自由につながる。全部を完璧に覚えていたら、新しい組み合わせは生まれない。ぼんやりしている時間は、無駄ではなかった。自分を取り戻す時間になる。何かを達成するためではなく、ただ存在する時間。その時間の中で、「自分は何が好きなのか」「自分は何を大切にしたいのか」という問いに向き合える。人間らしさを回復する。効率を追求するのは機械の得意分野だ。非効率を楽しめるのは、人間だけの特権だ。 AIは目標を与えられると、最短経路で達成しようとする。しかし人間は、わざと遠回りすることができる。意味のないおしゃべり、下手な楽器演奏、勝てないゲーム。この「わざと非効率を選ぶ」能力は、目標最適化しかできないAIには原理的に不可能だ。非効率の中にこそ、最適化では見つからない価値がある。関係性を深める。人間関係は効率化できない。信頼を築くには時間がかかる。無駄話をする。一緒に何もしない時間を過ごす。これらの「非効率」が、関係性を深める。だから、休息に効率を求めることをやめよう。先週、何の目的もなく街を散策した。1時間、何も生産しなかった。スマホも持たずに、ただ歩いた。帰ってきたとき、妙に頭がすっきりしていた。非効率な時間を、堂々と楽しもう。それが、AI時代を生き抜くための、逆説的な戦略だ。AIは「無駄」を理解できない。だから、無駄を楽しめる人間は、永遠に代替されない。おわりにこの文章を書き終えて、日曜日の夜が終わろうとしている。正直に言うと、書いている間もスマホを何度か見た。通知を確認した。Xを開いた。自分で書いた「デジタルデトックス」の章を読み返しながら、その直後にスマホに手を伸ばしている自分がいた。笑えない。笑えないけど、それが現実だ。私はこの文章を書いたからといって、来週から完璧に休めるようになるわけではない。たぶん来週も、ベッドでスマホを見ながら「休んだつもり」になる日がある。境界線を引けない日がある。格闘技のジムをサボる日がある。でも、少しだけ違うことがある。「休めていない」と気づけるようになった。「これは回復じゃなくて消耗だ」と言語化できるようになった。 それだけでも、前よりマシなのだと思う。たぶん。AIは無限に働ける。私は有限だ。この事実は変わらない。でも、有限であることを恨まなくなった。有限だから、選ばなければならない。選ぶから、何が大事か分かる。全部はできない。全部は追いつけない。それでいい。それに、正直なところ、こうも思っている。どうせAIはこれからもっと賢くなる。 私たちの無能さを、いずれAIが補ってくれる。足りない部分を埋めてくれる。追いつけなかった技術も、AIが代わりにやってくれるようになる。だったら、その日まで健康で元気でいることの方が大事じゃないか。 壊れた身体では、優秀なAIを使いこなすこともできない。だから、選択的に休んでほしい。休むことは、負けを認めることじゃない。降参でもない。 有限な人間として、まともに機能し続けるための、当たり前の行為だ。当たり前のことを、当たり前にやる。それがこんなに難しいとは思わなかった。明日の朝、目覚ましが鳴る。月曜日が始まる。たぶん私は、また疲れている。でも、今日よりは少しだけマシかもしれない。少しだけ、回復の仕方を知っているから。少しだけ、自分を責めずに済むから。おい、休め。これは誰かへの命令じゃない。自分への、しつこい呼びかけだ。何度も忘れて、何度も思い出す。それでいい。完璧に続けることより、何度でも思い出せることの方が大事だから。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍限りある時間の使い方作者:オリバー・バークマンかんき出版Amazonスタンフォード式　疲れない体作者:山田 知生サンマーク出版Amazon戦略的暇作者:森下彰大飛鳥新社Amazon休養学―あなたを疲れから救う作者:片野 秀樹東洋経済新報社Amazon疲労学: 毎日がんばるあなたのための作者:片野 秀樹東洋経済新報社Amazonスマホ脳（新潮新書） （『スマホ脳』シリーズ）作者:アンデシュ・ハンセン新潮社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazonワイド新版　思考の整理学 (単行本 --)作者:外山　滋比古筑摩書房Amazon新版　「読み」の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の整理学 (ちくま文庫)作者:外山滋比古筑摩書房Amazon忘却の効用　「忘れること」で脳は何を得るのか作者:スコット・A・スモール,寺町朋子白揚社Amazon苦痛の心理学:なぜ人は自ら苦しみを求めるのか作者:ポール・ブルーム草思社Amazon「恥」に操られる私たち　他者をおとしめて搾取する現代社会作者:キャシー・オニール白揚社Amazon社会は、静かにあなたを「呪う」　～思考と感情を侵食する“見えない力”の正体～ (小学館クリエイティブ)作者:鈴木祐小学館Amazon半うつ　憂鬱以上、うつ未満作者:平 光源サンマーク出版Amazon地に足をつけて生きろ！ 加速文化の重圧に対抗する7つの方法作者:スヴェン・ブリンクマンEvolvingAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[【宇宙】MultimodalUniverse を使って活動銀河核(AGN)の2クラス分類を作ってみる]]></title>
            <link>https://qiita.com/tozastation/items/09e118bf67e129813d00</link>
            <guid isPermaLink="false">https://qiita.com/tozastation/items/09e118bf67e129813d00</guid>
            <pubDate>Sat, 20 Dec 2025 22:06:44 GMT</pubDate>
            <content:encoded><![CDATA[この記事は 3-shake Advent Calendar 2025 の21日目の記事です。@tozastationです。普段はWebアプリを開発したり、そのアプリや学習ジョブが動く Kubernetes 基盤の面倒をみています。宇宙が好きなのとAI/MLの方たちがどうい...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[IAM Roles Anywhereを使ってオンプレKubernetesでExternal Secrets Operatorを試してみる]]></title>
            <link>https://qiita.com/yutaf11/items/703c7b875157ddf799fc</link>
            <guid isPermaLink="false">https://qiita.com/yutaf11/items/703c7b875157ddf799fc</guid>
            <pubDate>Sat, 20 Dec 2025 14:24:07 GMT</pubDate>
            <content:encoded><![CDATA[はじめにオンプレミスのKubernetesとAmazon EKSによるハイブリッド構成において、シークレット管理の統合は重要な課題の一つです。セキュリティと運用の一貫性を考慮すると、AWS Secrets Managerをシークレット情報のシングルソースとして利用する構...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[cargo-coupling: Rustプロジェクトの結合度を可視化する]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/20/195329</guid>
            <pubDate>Sat, 20 Dec 2025 10:53:29 GMT</pubDate>
            <content:encoded><![CDATA[cargo-coupling を自己診断した時のweb ui です。はじめに「このモジュール、なんか触りたくないな...」ソフトウェア開発をしていると、こんな感覚を覚えることがあります。変更するたびに他の箇所が壊れる、テストが書きにくい、そもそも何をしているのか把握しづらい。これらの症状には共通点があります。モジュール同士が過剰に依存し合っている、つまり結合（カップリング）の問題です。結合の問題は厄介です。コードを書いているときには気づきにくく、後から「なぜこんなに変更が大変なのか」と悩むことになります。さらに困るのは、「結合が強すぎる」と分かっても、具体的にどこがどう強いのか、どこから手をつければいいのかが見えにくいことです。振り返ってみると、私は結合に対する解像度がかなり低かったのではないでしょうか。「なんとなく密結合っぽい」「疎結合の方がいいらしい」という感覚で良し悪しを判断していた。でも、その感覚を言葉にしようとすると、うまく説明できない。この「見えにくさ」を解消するには、結合を測る物差しが必要です。しかし、従来の「強い/弱い」という1軸だけでは不十分でした。なぜなら、同じ「強い結合」でも、場所や状況によって意味が変わるからです。そこで注目したいのが、Vlad Khononovの「Balanced Coupling」という考え方です。結合を「強度」「距離」「変動性」の3つの軸で捉え、それらのバランスを評価するフレームワークです。今回紹介するcargo-couplingは、このフレームワークをRustプロジェクト向けに実装したツールです。AIがコードを書く時代になっても、この結合度という指標は重要性を増すはずです。なぜなら、コードを書く主体が誰であれ、そのコードを理解し、保守し、拡張するのは人間だからです。むしろAIが生成したコードだからこそ、その構造を客観的に評価できる物差しが必要になります。まずはツールの概要を見てから、その背景にある考え方、そして実際の使い方へと進んでいきましょう。cargo-couplingとはcargo-couplingは、私がRustプロジェクト向けに開発した結合度分析ツールです。このツールを作るきっかけになったのは、Vlad Khononovの著作「Balancing Coupling in Software Design」との出会いでした。結合設計について漠然と感じていた課題が、この本で体系的に整理されていたのです。「強度」「距離」「変動性」という3つの軸で結合を捉えるフレームワークに感銘を受け、これをRustプロジェクトで実際に使えるツールにしたいと考えました。書籍は翻訳も含めて読みやすいので、ぜひ手に取ってみてください。ソフトウェア設計の結合バランス　持続可能な成長を支えるモジュール化の原則 (impress top gearシリーズ)作者:Vlad KhononovインプレスAmazonツールはGitHubで公開しています。気に入ったらStarしていただけると励みになります。github.comcrates.ioからインストールできます。https://crates.io/crates/cargo-couplingcrates.ioここで、多くの人が持っている常識を一度疑ってみましょう。「結合は減らすべきだ」——そう思っていませんか？このツールは「結合を減らす」ことを目標にしていません。「結合を適切に設計する」ことを目標にしています。なぜなら、結合は本質的に悪ではないからです。関連する機能が密に連携するのは自然なことで、問題になるのは「不適切な場所での強い結合」や「遠く離れたモジュール間の密結合」です。この視点の転換が、このツールの核心です。# インストールcargo install cargo-coupling# 基本的な使い方cargo coupling ./src3つの次元で結合を分析では、「適切な結合」とは具体的に何を指すのでしょうか。従来の結合分析は「強い/弱い」の1軸で考えがちでした。しかし、ここで立ち止まって考えてみてください。同じ「強い結合」でも、すぐ隣のモジュールとの結合と、遠く離れた外部ライブラリとの結合では、意味が違うはずです。また、5年間ほとんど変更されていないコードとの結合と、毎週のように変更されるコードとの結合では、リスクが違うはずです。この違いを捉えるには、1軸では足りません。cargo-couplingは結合を3つの独立した次元で測定します。1. Integration Strength（結合強度）最初の軸は「結合強度」です。モジュール同士が「どれだけ互いの内部を知っているか」を表します。user.password_hashのように構造体のフィールドを直接触っているコード、見覚えがありませんか？これは最も強い結合です。一方、impl Traitを介してやり取りするコードは、相手の内部を知らなくても動作します。この違いをスコア化します。 レベル  スコア  説明  Rust例  Intrusive  1.00  内部実装に直接依存  struct.field 直接アクセス  Functional  0.75  関数シグネチャに依存  メソッド呼び出し  Model  0.50  データ構造に依存  型定義、型パラメータ  Contract  0.25  trait/インターフェースのみ  impl Trait 2. Distance（距離）2つ目の軸は「距離」です。結合されたモジュール同士が、コードのスコープ階層でどれだけ離れているかを表します。同じファイル内の関数同士が密に連携しているのは自然なことです。しかし、src/auth/login.rsがsrc/billing/invoice.rsを直接参照していたらどうでしょう？さらに、外部クレートの内部構造に依存していたら？距離が遠いほど、その結合の「重さ」は増します。 レベル  スコア  説明  SameModule  0.25  同一ファイル/モジュール内  DifferentModule  0.50  同一クレート内の別モジュール  DifferentCrate  1.00  外部クレートへの依存 3. Volatility（変動性）3つ目の軸は「変動性」です。「どれくらい頻繁に変更されるか」を表します。あなたのプロジェクトにも、1年以上触られていない安定したモジュールと、毎週のように修正が入るモジュールがあるはずです。安定したコードに依存するのと、頻繁に変わるコードに依存するのでは、リスクが違います。cargo-couplingはGit履歴からこの変動性を自動で計算します。 レベル  スコア  Git 6ヶ月での変更回数  Low  0.00  0-2回  Medium  0.50  3-10回  High  1.00  11回以上 バランススコアの計算ここまで3つの次元を見てきました。しかし、「強度が0.75」「距離が0.50」「変動性が中程度」とバラバラに言われても、結局この結合は良いのか悪いのか、判断しづらいですよね。そこでcargo-couplingは、これら3つの次元を組み合わせてバランススコアを計算します。3つの数値を1つのスコアにまとめることで、「この結合は適切か」を直感的に判断できるようになります。考え方はシンプルです。「強度と距離のバランス」と「変動性によるリスク」の2つを掛け合わせます。ALIGNMENT = 1.0 - |STRENGTH - (1.0 - DISTANCE)|VOLATILITY_IMPACT = 1.0 - (VOLATILITY × STRENGTH)BALANCE_SCORE = ALIGNMENT × VOLATILITY_IMPACT最初の式は「強度と距離が釣り合っているか」を測ります。距離が近ければ強結合でも問題なく、距離が遠ければ弱結合であるべきです。2番目の式は「変更頻度と結合強度の組み合わせリスク」を測ります。頻繁に変更されるコードと強く結合していると、変更のたびに影響を受けるリスクが高まります。この計算式が導く結論を整理すると、以下のようになります。強結合 + 近距離 → Good：関連機能が1つのモジュールにまとまった高凝集な状態弱結合 + 遠距離 → Good：モジュール間の依存が最小限な疎結合アーキテクチャ強結合 + 遠距離 → Bad：変更影響が広範囲に及ぶグローバル複雑性の状態強結合 + 高変動性 → Bad：頻繁な変更が連鎖的影響を生む変更波及リスク実際に使ってみる理論を理解したところで、実際のプロジェクトでどう使うかを見ていきましょう。cargo-couplingは目的に応じて複数の出力形式を用意しています。サマリー表示cargo coupling --summary ./src出力例は以下のとおりです。Coupling Analysis Summary:  Health Grade: B (Good)  Files: 14  Modules: 14  Couplings: 389  Balance Score: 0.83  Issues:    Medium: 2  Top Priority:    - [Medium] cargo-coupling::main → 21 dependencies    - [Medium] 21 dependents → cargo-coupling::cargo_coupling  Breakdown:    Internal: 33    External: 356    Balanced: 33    Needs Review: 0    Needs Refactoring: 0  Connascence:    Total: 807 (avg strength: 0.23)    High-strength: Position=2, Algorithm=2  APOSD Metrics:    Pass-Through Methods: 12 (simple delegation)    High Cognitive Load: 2 modules    Avg Module Depth: 7.9日本語出力日本語での出力も対応しています。cargo coupling --japanese ./srcカップリング分析: my-project━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━評価: B (Good) | スコア: 0.67/1.00 | モジュール数: 143次元分析:  結合強度: Contract 1% / Model 24% / Functional 66% / Intrusive 8%           (トレイト)   (型)      (関数)        (内部アクセス)  距離:     同一モジュール 6% / 別モジュール 2% / 外部 91%  変更頻度: 低 2% / 中 98% / 高 0%ホットスポット分析リファクタリングすべき優先度の高いモジュールを特定します。cargo coupling --hotspots ./src#1 my-project::main (Score: 55)   🟡 Medium: High Efferent Coupling   💡 What it means:      This module depends on too many other modules   ⚠️  Why it's a problem:      • Changes elsewhere may break this module      • Testing requires many mocks/stubs      • Hard to understand in isolation   🔧 How to fix:      Split into smaller modules with clear responsibilities      e.g., Split main.rs into cli.rs, config.rs, runner.rs影響分析特定のモジュールを変更したときの影響範囲を調べられます。cargo coupling --impact metrics ./srcWeb UIでの可視化インタラクティブなグラフで結合関係を可視化できます。cargo coupling --web ./srcブラウザが自動で開き、Cytoscape.jsを使った対話的なグラフが表示されます。ノードをクリックすると詳細情報が見られ、問題のあるモジュールは色分けされます。CI/CDでの活用手動で分析するだけでなく、継続的に品質を監視することもできます。cargo-couplingを品質ゲートとして組み込むと、結合設計の劣化を早期に検出できます。cargo coupling --check \  --min-grade=B \  --max-circular=0 \  ./srcGitHub Actionsの例は以下のとおりです。- name: Check coupling health  run: |    cargo coupling --check \      --min-grade=B \      --max-critical=0 \      ./srcグレードが基準を下回るとexit code 1を返すため、CIパイプラインに組み込めます。AI連携Claude CodeやGitHub Copilotと組み合わせて使う場合、--aiオプションが便利です。cargo coupling --ai ./srcAIフレンドリーな形式で出力されるので、そのままAIに貼り付けてリファクタリング提案を得られます。検出される問題パターンここまで使い方を見てきましたが、具体的にどんな問題が検出されるのか気になるところでしょう。cargo-couplingが警告する代表的なパターンを紹介します。God Module（神モジュール）関数、型、implが多すぎるモジュールです。関数: 30個以上型: 15個以上impl: 20個以上High Efferent Coupling（外向き結合過多）依存先が多すぎるモジュール。デフォルトでは20以上の依存で警告されます。High Afferent Coupling（内向き結合過多）依存されすぎているモジュール。デフォルトでは30以上の依存元で警告されます。Cascading Change Risk（変更波及リスク）侵入的結合（Intrusive）と高変動性（High Volatility）の組み合わせ。変更のたびに広範囲に影響が及ぶ危険な状態です。ヘルスグレードの解釈問題パターンの検出結果は、最終的に1つのグレードに集約されます。このグレードがプロジェクト全体の健全性を示します。 Grade  説明  S  Over-optimized。リファクタリングしすぎかも  A  Well-balanced。理想的な状態  B  Healthy。管理可能な状態  C  改善の余地あり  D  注意が必要  F  即刻対応が必要 興味深いのは、Sグレードが「やりすぎ」とされている点です。なぜでしょうか？結合を減らしすぎると、コードが細切れになりすぎて、かえって全体像が見えなくなります。1つの処理を追うために10個のファイルを開く必要があったり、抽象化のレイヤーが深すぎて「結局何をしているの？」と迷子になったり。そういう経験はありませんか？結合は「減らせばいい」という単純な話ではありません。バランスが大切なのです。ライブラリとしての利用CLIツールとして使うだけでなく、独自のツールに組み込むこともできます。cargo-couplingはライブラリとしても公開しているので、プログラムから直接分析機能を呼び出せます。use cargo_coupling::{    analyze_workspace,    analyze_project_balance_with_thresholds,    IssueThresholds,    VolatilityAnalyzer,};fn main() -> Result<(), Box<dyn std::error::Error>> {    // AST解析    let mut metrics = analyze_workspace(Path::new("./src"))?;    // Git変動性分析    let mut volatility = VolatilityAnalyzer::new(6);    volatility.analyze(Path::new("./src"))?;    metrics.file_changes = volatility.file_changes;    metrics.update_volatility_from_git();    // バランス分析    let report = analyze_project_balance_with_thresholds(        &metrics,        &IssueThresholds::default()    );    println!("Grade: {}", report.health_grade);    Ok(())}パフォーマンスcargo-couplingは、大規模プロジェクトでも高速に動作するよう設計されています。Rayonによる並列AST解析Git履歴のストリーム処理実績: tokio（488ファイル）で655ms--no-gitオプションを使えば、Git分析をスキップしてより高速に動作します。制限事項便利なツールですが、万能ではありません。使う前に知っておくべき制限があります。外部クレート依存は分析対象外: serde、tokioなどへの依存は分析されない。開発者がコントロールできない部分のため静的解析のみ: ランタイムの動作やマクロ展開は完全には捉えられないGit履歴が必要: Volatility分析にはGit履歴が必要。履歴が短いと精度が下がるまとめcargo-couplingは、「結合は悪」という単純な考え方ではなく、「適切な結合を選ぶ」という実用的なアプローチを提供します。3次元分析: 強度・距離・変動性を同時に考慮Git連携: 実際の変更頻度をデータとして反映実行可能な提案: 具体的なリファクタリングアクションを提示複数の出力形式: テキスト/JSON/Web UI/AIフレンドリーCI/CD統合: 品質ゲートとして自動チェック完璧な設計を目指す必要はありません。「80%の改善で十分」というプラグマティックな姿勢で、少しずつプロジェクトの健全性を高めていきましょう。# まずは試してみてくださいcargo install cargo-couplingcargo coupling --summary ./src結合の問題が可視化されるだけでも、設計改善の第一歩になります。次にあなたが「このモジュール、なんか触りたくないな...」と感じたとき、それはもう漠然とした不安ではありません。強度・距離・変動性という3つの軸で分析でき、具体的な改善アクションに落とし込める、対処可能な課題です。その感覚は、恐れではなく、改善の入り口なのです。似た概念にA Philosophy of Software DesignのComplexity がある。これも良い考え方なので一読をおすすめします。 speakerdeck.comA Philosophy of Software Design, 2nd Edition (English Edition)作者:Ousterhout, John K. ISSVWOAmazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Unmasking the Weak Points: Probing LLM Frontiers with garak]]></title>
            <link>https://daisuke1024akagawa.medium.com/unmasking-the-weak-points-probing-llm-frontiers-with-garak-50f4db714a62?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/unmasking-the-weak-points-probing-llm-frontiers-with-garak-50f4db714a62?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Sat, 20 Dec 2025 05:24:29 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[書いた方が良いの? BigQueryテーブルのカラム説明文の有無による生成AI機能の差異検証]]></title>
            <link>https://zenn.dev/nedoko_dok0dko/articles/a7124ea372eb91</link>
            <guid isPermaLink="false">https://zenn.dev/nedoko_dok0dko/articles/a7124ea372eb91</guid>
            <pubDate>Fri, 19 Dec 2025 15:00:02 GMT</pubDate>
            <content:encoded><![CDATA[※3-shake Advent Calendar 2025の20日目のエントリー記事です。皆さんこんにちは。2025年ももう終わりですね。今年は様々な所で生成AIの機能やサービスが登場しました。私はお仕事関連でGoogle Cloudを触ることが多かったのですが、AI関連の機能は追加や更新の早さが凄まじく「早すぎて…見えない!」となっていました。さて、今回はGoogle Cloudの提供しているBigQueryと言うサービスと生成AIにまつわるお話です。 想定読者BigQueryについて触ったことがあるBigQueryデータキャンバスの概要を知っているBigQue...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Master the AI Wave: 10 Tech Blogs That Keep You Ahead of the Curve]]></title>
            <link>https://daisuke1024akagawa.medium.com/master-the-ai-wave-10-tech-blogs-that-keep-you-ahead-of-the-curve-5cd0225ccc45?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/master-the-ai-wave-10-tech-blogs-that-keep-you-ahead-of-the-curve-5cd0225ccc45?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Fri, 19 Dec 2025 13:01:07 GMT</pubDate>
            <content:encoded><![CDATA[Today, I’ll let you know 10 amazing tech blogs you should read.Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[生成AI時代のMarp によるスライド環境の構築]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/19/183148</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/19/183148</guid>
            <pubDate>Fri, 19 Dec 2025 09:31:48 GMT</pubDate>
            <content:encoded><![CDATA[この記事は、3-shake Advent Calendar 2025 19日目のエントリ記事です。はじめにエンジニアがプレゼン資料を作るとき、PowerPointやKeynoteにもどかしさを感じることがあります。コードを書くようにスライドを作りたい。Gitでバージョン管理したい。テーマを一括で変更したい。Marpはこれらの願望を叶えるマークダウンベースのスライド生成ツールです。marp.appしかし生成AI時代の今、新しい課題が生まれています。AIにスライドの下書きを依頼できるようになった反面、「AIっぽいプレゼン」が量産されるようになりました。整然としすぎて、話者の思考が見えない資料です。この記事では、AIの力を借りつつ「自分のプレゼン」を取り戻す仕組みを紹介します。AIっぽいプレゼンの正体生成AIにプレゼン資料を依頼すると、だいたい同じ構成になります。「まず、次に、最後に」という接続詞。きれいに3項目並んだ箇条書き。当たり障りのない結論。これは決して間違っていません。しかし聴衆の記憶には残りません。なぜでしょうか。聴衆の脳は「予測を裏切られた瞬間」に活性化します。「まず、次に、最後に」という予定調和な構成では、脳は省エネモードで聞き流します。3項目の箇条書きを見た瞬間、聴衆は「ああ、3つあるのね」と思考を止めます。AIが生成するプレゼンは、統計的に最も頻出するパターンの再現です。だから誰が作っても似たような資料になります。Marpを選んだ理由はシンプルです。マークダウンはプレーンテキストなので、AIが直接編集でき、人間がTextlintやカスタムルールで機械的にチェックできます。PowerPointのようなバイナリ形式では「AI生成→ルール検証」の流れが困難です。Gitで差分管理でき、CSSでデザインを一括制御できる点も大きいです。プロジェクト構造実際に運用しているMarpプロジェクトの構造を紹介します。github.com3shake-marp-templates/├── templates/              # 再利用可能なテンプレート├── themes/                 # CSSテーマ├── slides/2025/           # 実際のプレゼンテーション├── assets/images/         # 画像資産└── .claude/               # Claude Code統合    ├── commands/          # スラッシュコマンド    ├── agents/            # 専門家エージェント    └── rules/             # 執筆ルールポイントは.claude/ディレクトリです。Claude Codeと統合することで、スライドのレビューを自動化しています。CommandsやSub-agentsの詳細については、以前の記事で解説しています。syu-m-5151.hatenablog.comMarpの基本設定.marprc.ymlでMarpを設定します。allowLocalFiles: truehtml: truemermaid: truebespoke:  progress: trueoptions:  engine: '@marp-team/marp-core'mermaid: trueでMermaid記法の図表が使えます。しかし正直なところ、PDFエクスポート時に崩れることがあります。重要な図は画像として用意するほうが安全です。package.jsonのスクリプトは以下の通りです。{  "scripts": {    "start": "marp -s . --html --allow-local-files",    "build": "marp --html --allow-local-files"  }}npm startでローカルサーバーが起動し、ファイル保存のたびに自動リロードされます。テーマによるブランディングCSSテーマで全スライドに統一感を持たせます。/* 3shake-theme.css */:root {  --3shake-blue: #4AADDD;  --3shake-blue-dark: #0a1929;  --3shake-yellow: #ECBE30;}section {  background: white;  font-family: 'Noto Sans JP', sans-serif;}/* 全スライドにロゴを自動配置 */section::after {  content: '';  background-image: url('../assets/images/logo.png');  position: absolute;  left: 30px;  bottom: 20px;}ロゴとページ番号が自動配置されます。プレゼン作成者はブランディングを意識する必要がなくなります。AIっぽさを排除するルールここからが本題かもです。.claude/rules/slide-writing.mdに以下の禁止事項を定義しています。箇条書きを3項目で揃えない（2つか4つにする）「まず、次に、最後に」という機械的な接続詞を使わない完全に等分な説明をしない（メリハリをつける）抽象的で当たり障りのない表現を避けるなぜ2つか4つなのか。 聴衆の「3つだろう」という予測を外すためです。2つなら対比が明確になり、4つなら網羅感が出ます。3つは「ちょうどいい」ゆえに印象へ残りません。意図的にパターンを崩すことで、聴衆の能動的な思考を促します。「PowerPointでも同じルールを適用できる」という反論があるでしょう。確かにその通りです。しかしPowerPointでは、このルールを機械的にチェックする手段がありません。Marpならテキストベースなので、「3項目の箇条書きを検出したら警告」というルールを自動実行できます。人間の意志力に頼らず、仕組みで品質を担保します。身体性の供給以前の記事で「AIに記事を書かせるとは何か」について書きました。プレゼンにも同じことが言えます。AIは構造化が得意です。しかし「身体性」は供給できません。ここで言う身体性とは、知識が「情報」から「経験」へと変容する過程で生じる一人称的な認知の軌跡です。たとえば「このツールを導入したら開発効率が上がった」という情報と、「導入時に設定で3時間ハマってドキュメントの不備に気づきPRを送った」という経験は別物です。プレゼンにおける身体性とは、「なぜこのトピックを選んだのか」「どこで躓いたのか」「何に感動したのか」という、話者固有の軌跡です。これはAIには生成できません。私の作業フローはこうです。伝えたいメッセージを箇条書きで書き出す（5-7個）各メッセージに「自分だけが語れる具体例」を追加AIにレビューを依頼し、構成を整える/review-slideで「3項目の箇条書き」「まず・次に」の指摘を確認指摘箇所を修正AIは足す。人間は削る。 AIは情報の網羅性を最適化しますが、プレゼンの核心は何を省くかにあります。「このトピックは聴衆の関心外」と判断するには、聴衆の反応を想像する力が必要です。この能力は現在のLLMには実装されていません。だからアウトラインは自分で考え、AIにはレビューを任せます。おわりにMarpとルールベースのチェック、そしてClaude Codeのエージェント。この組み合わせで実現したのは、「AIの力を借りながら、自分の思考を残す」環境です。完璧に整った資料より、少し不格好でも話者の考えが透けて見える資料のほうが、聴衆の記憶に残ります。AIが生成した「もっともらしい」スライドではなく、自分の経験に根ざした「本物の」スライドを作る。そのための環境がMarp×Claude Codeです。まずは既存のスライドを1枚だけMarkdown化してみてください。それがMarp×AI環境構築の第一歩です。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Claude Codeの Agent Skills は設定したほうがいい]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/19/173309</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/19/173309</guid>
            <pubDate>Fri, 19 Dec 2025 08:33:09 GMT</pubDate>
            <content:encoded><![CDATA[Claude Codeを使い始めて、様々な発信をしてきました。今回は「Agent Skills」について。これも設定しておくと、Claude Codeがグッと使いやすくなる機能です。Claude Code の settings.json は設定した方がいい - じゃあ、おうちで学べるClaude Code の CLAUDE.mdは設定した方がいい - じゃあ、おうちで学べるClaude Code の .claude/commands/**.md は設定した方がいい - じゃあ、おうちで学べるClaude CodeのHooksは設定したほうがいい - じゃあ、おうちで学べるClaude CodeのSubagentsは設定したほうがいい - じゃあ、おうちで学べるはじめに「このプロジェクトではpython-pptxを使ってスライドを作って」「SQLは必ずこのフォーマットで書いて」「コードレビューはこの観点でチェックして」。Claude Codeを使っていると、こういう説明を何度も繰り返すことになります。CLAUDE.mdに書けば解決すると感じるでしょう。しかしCLAUDE.mdに書いても、毎回読み込まれるとは限らない。commandsを作っても、手動で呼び出す必要がある。どちらも「繰り返し」を完全には解決してくれません。私自身、Rustプロジェクトの開発をClaude Codeに任せようとして、この問題に何度もぶつかりました。「ビルドはcargo fmtから始めて」「セキュリティチェックはOWASPの観点で」「テストは統合テストまで回して」。1回のセッションでは覚えてくれる。しかし新しいセッションを始めると、また最初から説明し直し。なぜこうなるのか。この問題の根本にあるのは、LLMのアーキテクチャ上の制約です。LLMはステートレスで、セッション間で記憶を保持しません。トークン制約とコスト制約があるため、すべての知識を常に保持できません。だから、毎回同じ説明が必要になります。Agent Skillsは、この制約を回避する仕組みです。すべての知識を常に持たせるのではなく、必要な時に必要な知識だけを読み込む。この発想の転換により、ステートレスなLLMでも「状態を持っているかのように」振る舞えます。一度Skillを作っておけば、関連するタスクで自動的にその知識が使われます。www.anthropic.comこのブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。他の設定との違い今まで紹介してきた機能との違いを整理しておきます。 機能  役割  例  CLAUDE.md  プロジェクトの文脈を伝える  「うちはTypeScriptで、こういうアーキテクチャ」  commands  手動で呼び出すショートカット  /test-and-commit で一連の作業を実行  Hooks  特定のイベントで自動実行  ファイル保存後に自動フォーマット  Subagents  専門家を自動で呼び出す  デバッグ時にdebugger subagentが起動  Rules  パス単位でルールを適用  src/api/**/*.tsにセキュリティルール  Agent Skills  専門知識をオンボーディング  PDF操作、Excel分析、独自ワークフロー Rulesについて補足: .claude/rules/ディレクトリに配置することで、特定の拡張子やディレクトリに対して細かいルールを適用できます。CLAUDE.mdがグローバルな設定なのに対し、Rulesは「このパスにはこのルール」という精密なスコープ設定が可能です。無駄なコンテキスト消費を抑えつつ、必要なルールだけを読み込ませる「段階的開示」の考え方に基づいています。Rulesについては別記事で詳しく書く予定です。表を見ると、各機能には明確な役割分担があります。CLAUDE.mdは文脈、commandsはショートカット、Hooksは自動化、Subagentsは専門家の呼び出し。では、Skillsは何が違うのか。ポイントは、Skillsが「Claudeができること自体を拡張する」点です。他の設定がClaudeの「使い方」を定義するのに対し、SkillsはClaudeの「専門知識」を拡張します。LLMの推論能力自体は変わりませんが、専門家の知識を注入することで出力品質が向上します。Agent Skillsとは何かAnthropicの公式ブログでは、Agent Skillsをこう説明しています。Building a skill for an agent is like putting together an onboarding guide for a new hire.（エージェントにSkillを作ることは、新入社員向けのオンボーディングガイドを作るようなものです）Skillは、指示・スクリプト・リソースをまとめたフォルダです。Claudeがタスクに応じて自動的に読み込み、その専門知識を活用します。platform.claude.comSkill に関しても公式ドキュメントが本当に良いのでオススメです。Anthropicはとりあえず、公式ドキュメントこれは標語にしてほしいです。platform.claude.comそれでも自分的にまとめたいので書かせていただきます。なぜSkillsが必要なのかClaude Codeは万能ですが、「特定のタスク」に最適化されていないことがあります。例えばPowerPointを作ろうとすると、どのライブラリを使うか迷います。フォーマットの細かい仕様を知らない。エッジケースでバグる。毎回試行錯誤が発生します。一方、Skillsがあれば違います。AnthropicのエンジニアがPowerPoint作成の最適解を徹底的に検証して、その知識をパッケージ化している。Claudeはそれを読み込んで、最初からプロとしての出力ができます。この辺は松本勇気さんの生成AI「戦力化」の教科書なんかもとても良いし今度、オライリーから翻訳本AIエンジニアリング―基盤モデルを用いたAIアプリケーション開発の基礎と実践もとても良い。Tool、Skills、MCPの違い混乱しやすいポイントを整理しておきます。Anthropicのブログ記事では、わかりやすいたとえが使われています。claude.comMCP is like having access to the aisles. Skills, meanwhile, are like an employee's expertise.（MCPは店の通路へのアクセス。Skillsは店員の専門知識。）壊れたキャビネットを直したいとき、ハードウェアストアに行けば木工用接着剤もクランプも蝶番も揃っています。しかし、何を買えばいいか、どう使えばいいかは別問題です。 概念  役割  たとえ  Tool  何ができるか（Capability）  店にある道具そのもの  MCP  道具へのアクセス（Connectivity）  店の通路に入ること  Skills  どう振る舞うか（Behavior）  道具の使い方を教える店員 Toolは「APIを叩く」「DBに接続する」「ファイルを操作する」といった個別の能力です。MCPはそれらのToolを統一規格で接続するアダプター。外部システムへの安全で標準化されたアクセスを提供します。そしてSkillsは「どう振る舞うか（Behavior）」まで定義します。複数のToolをどの順番で、どういう判断基準で使うか。Toolの使い方マニュアル付きで渡すのがSkillsです。MCPが接続性を提供し、Skillsがその接続性を効果的に使うための手続き的知識を提供する。両者は競合するものではなく、組み合わせることで真価を発揮します。この構造は、BDD（Behavior-Driven Development、振る舞い駆動開発）に似ています。BDDは単なるテスト手法ではなく、チーム全体の「対話」を促進し、ビジネス価値の高いソフトウェアを効率的に生み出すための開発アプローチです。TDD（テスト駆動開発）が「コードが正しく実装されているか」という開発者視点なのに対し、BDDは「システムが期待通りに振る舞うか」というユーザー・ビジネス視点で考えます。BDDでは、Gherkin記法を使って「Given-When-Then」形式でシナリオを書きます。Feature: ログイン機能  Scenario: ユーザーが正しいIDとパスワードでログインできる    Given ログインページが表示されている    When  正しいIDとパスワードを入力してログインボタンを押す    Then  ホームページにリダイレクトされるこのシナリオは、開発者だけでなく、QAエンジニア、プロダクトオーナー、ビジネス担当者など、全員が読めます。これが「生きた仕様書」として機能し、認識の齟齬を埋めます。Skillsも同じ構造を持っています。 BDD  Skills  Given（前提条件）  description（いつ起動するか）  When（アクション）  SKILL.md本文（何をするか）  Then（期待結果）  具体的な手順（どう振る舞うか） BDDがテストで「コードの振る舞い」を保証するように、SkillsはAIエージェントの「振る舞い」を保証します。BDDの本質的な価値は「ビジネス側とエンジニアの共通言語」でした。「3つのアミーゴ」（PO、開発者、QA）が対話し、全員が納得する仕様を作り上げます。Skillsも同じです。現場のドメインエキスパートがMarkdownで書いた手順は、そのままAIの振る舞いになります。つまり、Skillsは「AIエージェントのためのBDD」だと言えます。プログラミングなしで、自然言語で、AIの振る舞いを定義できます。Progressive Disclosure（段階的開示）Skillsの設計で最も重要な概念が「Progressive Disclosure（段階的開示）」です。これは「すべての情報を最初から渡すのではなく、必要になったタイミングで必要な情報だけを渡す」という設計原則です。なぜこの原則がSkillsに必要なのか。LLMには「コンテキストウィンドウ」という物理的な制約があります。Claude 3.5 Sonnetで約200Kトークン。これは多いようで、実際のタスクでは意外と消費が早い。コードファイルを10個読み込めば数万トークン、会話履歴が長くなればより消費される。ここに50個のSkillsの全内容（各5000トークン）を読み込んだら、250Kトークン。コンテキストが溢れます。だからSkillsは3段階で情報を開示します。これは「必要な時に必要な分だけ」というJust-In-Time戦略です。Level 1: メタデータ（常にロード） - 約100トークン/Skill---name: pdf-processingdescription: Extract text and tables from PDF files, fill forms, merge documents.---起動時に全Skillのname/descriptionだけ読み込みます。50個のSkillがあっても5000トークン程度。これでClaudeは「どんなSkillが使えるか」の全体像を把握できます。Level 2: 指示（トリガー時にロード） - 5000トークン以下が目安SKILL.mdの本文。「PDFを操作して」と言われたら、descriptionから「pdf-processingが関連する」と判断し、そのSKILL.mdを読み込みます。関係ないSkillは読み込まない。Level 3: リソース（必要時にロード） - 必要に応じて追加のファイル、スクリプト、リファレンス。SKILL.md内で「フォーム入力が必要ならFORMS.mdを参照」と書いておけば、そのタスクが発生したときだけ読み込みます。pdf-skill/├── SKILL.md              # Level 2: メイン指示├── FORMS.md              # Level 3: フォーム入力ガイド├── reference.md          # Level 3: APIリファレンス└── scripts/    └── fill_form.py      # Level 3: ユーティリティスクリプトこの設計の本質は「推論空間の段階的絞り込み」です。 Level 1で「使えるSkillの候補」を提示し、Level 2で「このタスクにはこの手順」を特定し、Level 3で「この具体的な操作にはこのリソース」を提供する。LLMの自由な推論を、段階的に制約していく。これがSkillsの賢さです。SkillsとSubagentsの使い分け「Skillsって、前に書いたSubagentsと同じじゃないですか」という声が聞こえてきます。確かに両方とも「専門知識をパッケージ化する」という点では似ています。しかし、コンテキストの扱い方に決定的な違いがあります。 観点  Skills  Subagents  コンテキスト  親と共有  独立  向いているタスク  継続的な作業、TDDなど  試行錯誤、調査タスク  状態の引き継ぎ  あり  なし（結果のみ返す） なぜこの違いが生まれるのか。 技術的には、Skillsは「現在のセッションにドキュメントを追加読み込みする」だけです。会話の流れ、ファイルの状態、変数の値、すべてが共有されたままです。一方、Subagentsは「新しいClaude Codeプロセスを起動する」に近い。独立したコンテキストウィンドウを持ち、親とは結果だけをやり取りします。Subagentsはコンテキストが独立しています。Claude Codeの中でClaude Codeを呼ぶようなもの。試行錯誤を伴うエラー調査みたいな「ごちゃごちゃした作業」をSubagentに任せると、親側のコンテキストが汚れません。なぜ「汚れない」ことが重要なのか。 コンテキストウィンドウは有限です。試行錯誤を10回繰り返すと、その10回分の履歴がコンテキストに残ります。成功した最終結果だけが欲しいのに、失敗した9回分も抱え込むことになる。Subagentなら、その試行錯誤は子プロセスの中で完結し、親には「結果：○○が原因でした」という要約だけが返ってきます。Skillsはコンテキストを共有します。テスト駆動開発をさせるとき、RED-GREEN-REFACTORのサイクルごとにコンテキストが分断されると困ります。「さっきテスト書いたよね」「なんでこの設計にしたんだっけ」という文脈を保持したまま作業を続けたい。そういうときはSkillsが向いています。なぜ「共有する」ことが重要なのか。 TDDは本質的に「対話」です。テストを書く→実装する→リファクタリングする、この流れの中で「なぜこのテストを書いたか」「なぜこの設計にしたか」という文脈が失われると、リファクタリングの方向性が定まりません。Skillsなら、この対話の文脈が保持されたまま、TDDの手順だけが注入されます。使い分けの判断基準はシンプルです。コンテキストを共有したい → Skillsコンテキストを独立させたい → Subagents迷ったときの指針: タスクの結果が「要約」で十分ならSubagent、結果だけでなく「過程」も重要ならSkillsです。エラー調査は「原因が分かればいい」のでSubagent。コードレビューは「なぜこの指摘をしたか」の文脈が後続の修正に影響するのでSkills。より詳しい使い分けについては、atusyさんの記事「Claude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する」が参考になります。利用可能なビルトインSkillsSkillsの概念は分かった。では、実際にどう使うのか。まずはAnthropicが提供しているビルトインSkillsから見てみましょう。 Skill  機能  PowerPoint (pptx)  プレゼンテーションの作成・編集・分析  Excel (xlsx)  スプレッドシートの作成・データ分析・チャート生成  Word (docx)  ドキュメントの作成・編集・トラック変更  PDF (pdf)  PDF生成・フォーム入力・マージ これはclaude.ai、Claude Code、Claude APIで利用可能です。基本的な使い方Claude Codeでの使い方Claude Codeでは、Skillsはファイルシステムベースで管理されます。配置場所： タイプ  パス  スコープ  個人  ~/.claude/skills/  全プロジェクト共通  プロジェクト  .claude/skills/  現在のプロジェクトのみ Skillを配置するだけで、Claude Codeが自動的に認識し、関連するタスクで使用します。APIでの使い方import anthropicclient = anthropic.Anthropic()response = client.beta.messages.create(    model="claude-sonnet-4-5-20250929",    max_tokens=4096,    betas=["code-execution-2025-08-25", "skills-2025-10-02"],    container={        "skills": [            {                "type": "anthropic",                "skill_id": "pptx",                "version": "latest"            }        ]    },    messages=[{        "role": "user",        "content": "再生可能エネルギーについて5枚のプレゼンを作成して"    }],    tools=[{        "type": "code_execution_20250825",        "name": "code_execution"    }])ポイントは以下の通りです。container.skillsでSkillを指定type: "anthropic"は公式Skilltoolsでcode_executionを有効化（Skillsの実行に必須）Beta headersが必要claude.aiでの使い方claude.aiでは、ビルトインSkillsはデフォルトで有効です。「PowerPointを作って」と言えば、自動的にPowerPoint Skillが起動します。カスタムSkillsは Settings > Features からZIPファイルでアップロードできます。カスタムSkillの作成ここからが本番です。自分専用のSkillを作る方法を説明します。基本構造Skillの最小構成はSKILL.mdファイル1つだけです。---name: my-custom-skilldescription: このSkillが何をするか、いつ使うべきかを説明。---# My Custom Skill## 指示[具体的な手順をここに書く]## 例[実際の使用例]必須フィールド：name: 小文字とハイフンのみ、64文字以内description: 何をするのか、いつ使うのかを説明。1024文字以内実用的なSkill例私が実際のプロジェクトで使っているSkillsを紹介します。例1: セキュリティレビュー.claude/skills/reviewing-security/SKILL.md:---name: reviewing-securitydescription: "OWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティス。脆弱性検出。Use when: セキュリティ、脆弱性、OWASP、認証、認可、監査を依頼された時。"---# セキュリティレビューOWASP API Security Top 10 (2023) と Rust セキュリティベストプラクティスに基づくレビュースキル。## OWASP チェック項目| ID | リスク | チェック内容 ||----|-------|-------------|| API1 | BOLA | tenant_id 検証、file_id との組み合わせ検証 || API2 | Broken Auth | gRPC メタデータ認証 || API3 | Property | レスポンスの不要情報 || API4 | Resource | ファイルサイズ制限、ページネーション |## Rust セキュリティ| 項目 | 検索パターン ||-----|-------------|| 依存関係脆弱性 | `cargo audit` || unsafe コード | `grep -rn "unsafe {" src/` || ハードコード認証情報 | `grep -rn "(password\|secret\|api_key)" src/` |descriptionに「Use when:」を明記しているのがポイントです。これでClaudeが「セキュリティレビューして」と言われたときに確実に起動します。例2: ビルドとテスト.claude/skills/building-and-testing/SKILL.md:---name: building-and-testingdescription: "Rustプロジェクトのビルドとテスト実行。フォーマットチェック、lint、ユニットテスト、ビルド確認を一括実行。Use when: ビルド、テスト、cargo test、チェック、確認を依頼された時。"---# ビルドとテスト## 実行手順1. フォーマットチェック: `cargo fmt --check`2. Lint実行: `cargo clippy -- -D warnings`3. ユニットテスト: `cargo test --workspace`4. ビルド確認: `cargo build --workspace`## 一括実行cargo fmt --check && cargo clippy -- -D warnings && cargo test --workspace && cargo build --workspaceシンプルですが、これだけで「テストして」と言えば毎回同じ手順を実行してくれます。例3: リファレンス参照型（QAチェック）Progressive Disclosureを活用して、参照ファイルを分割する例です。職種ごとにリファレンスを分けることで、必要な情報だけを読み込みます。.claude/skills/qa-check/├── SKILL.md└── reference/    ├── backend.md      # Rustバックエンドのチェック項目    ├── frontend.md     # フロントエンドのチェック項目    └── infra.md        # インフラのチェック項目.claude/skills/qa-check/SKILL.md:---name: qa-checkdescription: "コードレビュー・QAチェック。職種別のベストプラクティスを適用。Use when: レビュー、QA、品質チェック、コードチェックを依頼された時。"---# QAチェック職種別のリファレンスを参照してレビューを実施します。## リファレンス**Rust バックエンド** → See [reference/backend.md](reference/backend.md)**フロントエンド** → See [reference/frontend.md](reference/frontend.md)**インフラ** → See [reference/infra.md](reference/infra.md)## 実行手順1. 変更ファイルの拡張子・パスから対象領域を判定2. 該当するリファレンスを読み込む3. チェック項目に従ってレビュー実施4. 結果をCRITICAL/WARNING/INFOで分類して報告reference/backend.md（一部抜粋）:# Rust バックエンド QAチェック項目## エラーハンドリング- [ ] unwrap() を本番コードで使用していないか- [ ] Result型を適切に伝播しているか- [ ] カスタムエラー型を定義しているか## セキュリティ- [ ] SQLインジェクション対策（sqlxのバインドパラメータ使用）- [ ] 認証・認可のチェック漏れがないか- [ ] 機密情報のログ出力がないか## パフォーマンス- [ ] N+1クエリが発生していないか- [ ] 不要なclone()がないか- [ ] async/awaitの適切な使用「バックエンドのコードをレビューして」と言えばbackend.mdだけを読み込み、「インフラの設定をチェックして」と言えばinfra.mdだけを読み込みます。slash commandsとskillsの連携Skillsは自動で起動しますが、明示的に呼び出したいときもあります。そういうときはslash commandsと組み合わせると便利です。.claude/skills/git-commit/SKILL.md:---name: git-commitdescription: Stage meaningful diffs and create Conventional Commits with WHY-focused messages. Use when agent needs to commit code changes.---Execute `/git:commit` slash command.claude/commands/git/commit.md:# Git Commit変更をすべてコミットせずに、意味のある範囲でできるだけ小さくコミットする。commit logにはwhyを残す。...こうすると、Claudeが「コミットすべきだな」と判断したら自動でSkillが起動し、ユーザーが明示的に/git:commitを呼んでも同じ挙動になります。自動と手動の両方に対応できる設計です。Skillsのベストプラクティスなぜベストプラクティスが重要なのか。 Skillsは「書けば動く」ものではありません。書き方によって、起動率、出力の安定性、トークン効率が大きく変わります。ベストプラクティスは、多くの試行錯誤から導き出されたパターンです。これを知らずに始めると、同じ失敗を繰り返すことになります。1. 簡潔に書くコンテキストウィンドウは有限です。Claudeが既に知っていることを書く必要はありません。簡潔さが重要な理由は2つあります。 トークンが増えると問題が起きます。1つはコスト。APIの場合、入力トークンに課金されるので、冗長なSkillはそのまま支出増になります。もう1つは「ノイズ」。LLMは与えられた情報を全て考慮しようとします。本質的でない説明が多いと、重要な指示が埋もれて、出力品質が下がります。悪い例（冗長）：PDF (Portable Document Format) files are a common file format that containstext, images, and other content. To extract text from a PDF, you'll need touse a library. There are many libraries available for PDF processing...良い例（簡潔）：## Extract PDF textUse pdfplumber:---import pdfplumberwith pdfplumber.open("file.pdf") as pdf:    text = pdf.pages[0].extract_text()---2. 自由度を適切に設定タスクの性質によって指示の具体性を変えます。自由度の設計が重要な理由は単純です。 LLMは指示が曖昧だと「創造的に解釈」します。コードレビューなら創造性は歓迎ですが、DBマイグレーションで創造性を発揮されると困ります。タスクの「リスク」と「多様性の価値」を天秤にかけて、自由度を決めます。高自由度（テキスト指示）: 複数のアプローチが有効な場合## Code Review1. Analyze structure2. Check for bugs3. Suggest improvements低自由度（具体的スクリプト）: 操作がデリケートな場合。## Database MigrationRun exactly this script:---python scripts/migrate.py --verify --backup---Do not modify the command.3. フィードバックループを入れる複雑なワークフローでは検証ステップを入れます。フィードバックループが必要な理由があります。 LLMは「確信を持って間違える」ことがあります。10ステップのワークフローを一気に実行させると、ステップ3でミスしても気づかずステップ10まで進みます。検証ステップを挟むことで、早期に問題を検出し、修正コストを下げられます。## Document Editing Workflow1. Make edits to XML2. **Validate immediately**: `python validate.py`3. If validation fails:   - Review error message   - Fix issues   - Validate again4. **Only proceed when validation passes**5. Pack the document4. ネストを深くしない参照ファイルはSKILL.mdから1階層までに留めます。深すぎると部分的にしか読まれません。ネストが問題になる理由があります。 LLMは「参照先をどこまで読むか」を自分で判断します。A→B→C→Dとネストしていると、Bまで読んでCは読まない、という判断をすることがあります。重要な情報がDにあると、それが無視される。情報はフラットに配置して、確実に読まれるようにします。悪い例：SKILL.md → advanced.md → details.md → actual_info.md良い例：SKILL.md├── advanced.md├── reference.md└── examples.md100+の実戦投入可能なSkillsコミュニティが既に多くのSkillsを公開しています。github.com人気カテゴリ：Document Processing: docx, pdf, pptx, xlsxDevelopment & Code Tools: MCP Builder, Webapp Testing, Changelog GeneratorData & Analysis: CSV Data Summarizer, Root Cause TracingBusiness & Marketing: Lead Research Assistant, Competitive Ads ExtractorCreative & Media: Canvas Design, Theme Factory, Image Enhancerよくある失敗と対策Skillsを作り始めると、最初は思い通りに動かないことが多いです。よくある失敗パターンとその対策をまとめました。 問題  原因  対策  Skillがトリガーされない  descriptionが曖昧  「何をするか」と「いつ使うか」を明記  コンテキスト不足  SKILL.mdに情報が足りない  参照ファイルを追加  トークン消費が多すぎる  Progressive Disclosureしてない  情報を複数ファイルに分割  出力が不安定  自由度が高すぎる  具体的なテンプレートや例を追加  スクリプトエラー  エラーハンドリングが甘い  スクリプト内で明示的にエラー処理 セキュリティ上の注意点Skillsはフルユーザー権限で実行されます。信頼できないソースのSkillsは使わないでください。チェックすべきポイントは以下です。全ファイルを監査: SKILL.md、スクリプト、リソースをすべて確認外部接続に注意: 外部URLへアクセスするSkillは特にリスクが高い自分で作る or 公式を使う: 基本的にこの2択Skillsの限界と現実ここまでSkillsの使い方やベストプラクティスを紹介してきました。しかし正直に言うと、Skillsは万能ではありません。実際にシステム化しようとすると、いくつかの困難にぶつかります。限界がある理由は明確です。 Skillsは「LLMに追加の情報を渡す」仕組みです。LLMの推論能力自体を向上させるわけではありません。どれだけ精緻なSkillを書いても、LLMが誤解することはあるし、予期しない振る舞いをすることもあります。これはLLMの本質的な不確実性に起因する問題で、Skillsでは解決できません。時間目安: 最初のSkillを動かすまで1-2時間かかります。descriptionの調整、手順の修正、再テストのサイクルが必要だからです。2個目以降は30分程度になります。週3回以上使うタスクでないと元が取れないので、投資対効果を考えて作りましょう。定義ファイル地獄Skillsを整備していくと、管理すべきファイルが膨大になります。私のプロジェクトでは、こんな構造になりました。.claude/skills/├── building-and-testing/├── running-integration-tests/├── running-e2e-tests/├── running-mutation-tests/├── managing-docker-dev/├── working-with-branches/├── implementing-issues/├── checking-pr/├── reviewing-security/├── reviewing-quality/├── using-rust-patterns/├── using-sqlx-patterns/├── handling-errors/└── ... (50個のSkillフォルダ)「地獄」になる理由は、 Skillsがコードと違って静的解析できないからです。どのSkillがどのタスクで起動するかは、実際に動かしてみないと分からない。コードなら「この関数はどこから呼ばれているか」を検索できますが、Skillsの時は「このSkillはいつ起動するか」をLLMの判断に委ねています。依存関係がブラックボックスになるのです。50個のSkillがあると、どれがどの場面で起動するのか把握しきれなくなります。「なんでこのSkillが動いたんだ」という状況が発生します。結局、設計者がすべてのSkillの挙動を把握していないといけません。これは隠れたコストです。descriptionの試行錯誤Skillが起動するかどうかはdescriptionの書き方次第です。しかし「どう書けば起動するか」は試してみないと分かりません。試行錯誤が必要な理由は、 LLMが「意味」で判断するからです。プログラムのように「この文字列が含まれていたら起動」という決定論的なルールではありません。「code review」と書いても、ユーザーが「PRを見て」と言ったらLLMが「これはcode reviewのことだ」と解釈するかどうかはLLM次第です。LLMの判断基準は私たちには見えません。# 起動しなかった例description: Helps with code review.# 起動した例description: Performs code review. Use when reviewing pull requests, checking code quality, or before merging.「いつ使うか」を明示的に書かないと、Claudeが「このSkillを使うべきだ」と判断してくれません。でも、どこまで具体的に書けばいいのか。書きすぎると他のタスクで起動しなくなるし、曖昧だと意図しない場面で起動します。この塩梅を見つけるのに時間がかかります。これはプロンプトエンジニアリングの本質的な難しさと同じです。 「こう書けば必ずこう動く」という保証がない世界で、試行錯誤を通じて「だいたいこう動く」パターンを見つけていく。Skillsは設定ファイルの形をしていますが、実態はプロンプトエンジニアリングです。デバッグの難しさ「なぜこのSkillが起動しなかったのか」を知る手段が限られています。Claude Codeは内部でどのSkillを候補として検討し、なぜそれを選んだか（選ばなかったか）を教えてくれません。デバッグが難しい理由は、 LLMの判断過程が外部から観察できないからです。プログラムならブレークポイントを置いて変数の中身を確認できますが、LLMには「なぜこの判断をしたか」を聞く標準的なインターフェースがありません。ログを見ても「Skill Xを起動しました」という結果しか分からず、「なぜSkill YではなくXを選んだのか」は分かりません。結果として、「起動しない → descriptionを変える → また試す」のループを繰り返すことになります。プログラムのデバッグと違って、再現性も低い。同じプロンプトでも起動したりしなかったりします。これはLLMベースのシステム全般の課題です。 Skillsに限った話ではありません。LLMの判断を制御したいなら、その不確実性と付き合う覚悟が必要です。Skill同士の競合複数のSkillが似たようなdescriptionを持っていると、どちらが選ばれるか予測できません。競合が起きる理由は、 Skillの選択がLLMの「意味的な類似度判断」に依存しているからです。プログラムなら「優先度」を数値で指定できますが、Skillsにはそういう明示的な優先度設定がありません。LLMが「どちらがより適切か」を毎回判断しますが、その判断基準はコンテキスト依存で変わります。# Skill Adescription: Reviews code for security issues.# Skill Bdescription: Performs security audit on codebase.「セキュリティチェックして」と言ったとき、AとBのどちらが起動するか。両方起動することもあります。Skillが増えるほど、こういう競合が起きやすくなります。対策としては、Skillの責務を明確に分離するしかありません。 「security issues」と「security audit」が重複しているなら、片方を削除するか、descriptionで「Use when: PRの差分をレビューするとき」vs「Use when: プロジェクト全体を監査するとき」のように用途を分けます。これは設計段階で意識する必要があります。「作る、試す、正す」で育てるここまで限界をいくつも挙げてきました。descriptionの試行錯誤、デバッグの難しさ、Skill同士の競合。これだけ聞くと「やっぱり使わない方がいいのでは」と感じるだろう。しかし、限界があるからといって諦める必要はありません。ここで参考になるのが、市谷聡啓氏の『作る、試す、正す。アジャイルなモノづくりのための全体戦略』です。この本の核心は、「正しさ」を探すのではなく、「正しくなる状況」をつくるというアプローチです。私たちの仕事は「正しいSkillを作る」ことではない。「ソフトウェアが正しくなっていく状況」をSkillで設計することです。つまり、Skillの完成度を追い求めるのではなく、適切なタイミングでSkillが発動し、結果としてソフトウェアが正しい方向に進む——その「状況」を整えることが本質です。作る → 試す → 正す → 作る → 試す → 正す → ...作る: 最小限のSKILL.mdを書く試す: 実際に使ってみて、期待通りに動くか確認する正す: 動かなかった部分を修正し、descriptionを調整する「課題を言葉で確認するだけでは分かった気になる」と市谷氏は指摘しています。Skillsも同様で、頭の中で設計を完璧にしようとしても限界があります。実際に動かしてみて初めて、「このdescriptionでは起動しない」「この手順では不十分」という発見が得られます。私も最初のSkillは散々でした。descriptionが曖昧すぎて起動しない、手順が抽象的すぎて出力がブレる。でも何度か直していくうちに、「こう書けば確実に起動する」「この粒度で手順を書けば安定する」という感覚が掴めてきました。Skillsの価値は「完成品」ではなく「育てるプロセス」にあります。 descriptionの試行錯誤を通じて、私たちはLLMの「判断基準」を逆算的に学んでいる。Skillsは単なる設定ファイルではなく、LLMの振る舞いを観察し理解するための実験装置でもあるのです。まとめAgent Skillsは、LLMのステートレスな制約を回避し、専門知識を必要な時に注入する仕組みです。今まで紹介してきた設定（CLAUDE.md、commands、Hooks、Subagents）と組み合わせれば、Claude Codeの使い勝手は大きく変わります。CLAUDE.md: プロジェクトの文脈commands: 手動ショートカットHooks: 自動実行Subagents: 専門家の自動呼び出しSkills: 専門知識の注入 ← NEWこれらの設定を組み合わせることで、Claude Codeは単なるAIアシスタントから、チームの一員のように振る舞うツールへと変わります。Skillsが示唆するAIエンジニアリングの未来では、この変化は何を意味するのか。Skillsが示唆するのは、「AIエージェントの制御は、プロンプトではなくワークフローで行う時代になった」ということです。従来のLLM活用は「良いプロンプトを書く」スキルが中心でした。しかしSkillsの登場で、パラダイムが変わりました。これからのAIエンジニアリングは、「LLMにどう推論させるか」ではなく、「LLMの推論をどう制約し、どう組織の資産として蓄積するか」が問われます。暗黙知として個人の頭の中にあったワークフローが、SKILL.mdという明示的なドキュメントになる。これはチーム全体で共有・改善できる「組織の資産」になります。Skillsは単なる便利ツールではなく、ワークフローの形式知化を促す仕組みでもあるのです。万能ではありません。descriptionの試行錯誤は避けられないし、Skillが増えると管理コストも上がります。でも「作る、試す、正す」のサイクルを回せば、確実に生産性は上がります。Claude Codeが雑魚なんじゃない、設定してないだけ。設定すればちゃんと動いてくれます。今日から試せること記事を読んで「面白そう」と思ったら、まずこれを試してみてください。1. ビルトインSkillsを体験する（1分）claude.aiで「PowerPointで自己紹介スライドを作って」と言ってみてください。Skillsが自動で起動して、プロ級のスライドが生成されます。2. カスタムSkillの最小構成を作る（5分）mkdir -p ~/.claude/skills/hello-skill~/.claude/skills/hello-skill/SKILL.mdを作成します。---name: hello-skilldescription: Says hello in a fun way. Use when user asks for a greeting.---# Hello SkillWhen asked to greet, respond with a creative and fun greeting.Include an emoji and a short motivational message.Claude Codeを再起動して「挨拶して」と言ってみてください。Skillが起動するはずです。3. 既存のSkillsを眺める（10分）awesome-claude-skillsで、他の人が作ったSkillsを見てみてください。SKILL.mdの書き方の参考になります。参考資料Agent Skills - Anthropic Engineering BlogAgent Skills Overview - Claude DocsAgent Skills Best Practices - Claude DocsUsing Skills with the API - Claude Docsawesome-claude-skills - ComposioHQClaude Skills CookbookClaude Codeのユーザー設定プロンプトを使い分けてコンテキスト管理を最適化する - atusyClaude Skillsとは何か - r_kaga振る舞い駆動開発（BDD）とは？ - HQW!作る、試す、正す。 - 市谷聡啓Claude Skillsとは何なのか？Use Agent Skills in VS Code]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Datadog Error Tracking & Claude Code Action で アプリケーションエラーを(半)自動修正 / Datadog Error Tracking & Claude Code Action (semi-)auto-correct application errors]]></title>
            <link>https://speakerdeck.com/nomadblacky/datadog-error-tracking-and-claude-code-action-semi-auto-correct-application-errors</link>
            <guid isPermaLink="false">https://speakerdeck.com/nomadblacky/datadog-error-tracking-and-claude-code-action-semi-auto-correct-application-errors</guid>
            <pubDate>Fri, 19 Dec 2025 05:00:00 GMT</pubDate>
            <content:encoded><![CDATA[3-shake SRE Tech Talk #14 オンサイトhttps://3-shake.connpass.com/event/373259/]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[My Plans of how to spend the New Year’s holiday from 2025 to 2026]]></title>
            <link>https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/my-plans-of-how-to-spend-the-new-years-holiday-from-2025-to-2026-588104d21f71?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Thu, 18 Dec 2025 13:10:41 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Apache Commons Numbersとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_numbers</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_numbers</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:57 GMT</pubDate>
            <content:encoded><![CDATA[今回はApache Commons Numbersについて調べてみました。 今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Numbersとは？公式サイトによると、Apache Commons Numbers...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Commons Chainとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_commons_chain</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_commons_chain</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:56 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Commons Chainについて調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Commons Chainとは？公式サイトによると、Gang of Fourの責任連鎖パターン(chain ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Causewayとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_causeway_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_causeway_intro</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:56 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Causeway。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Apache Causewayとは？公式サイトによると、Apache Causeway™ enables domain-driven applicat...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Apache Avroとはなんなのか？]]></title>
            <link>https://zenn.dev/akasan/articles/apache_avro_serialization</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/apache_avro_serialization</guid>
            <pubDate>Thu, 18 Dec 2025 11:18:55 GMT</pubDate>
            <content:encoded><![CDATA[今回は、Apache Avro（以下、Avro）について調べてみました。今回も以下のツールを使って対象プロジェクトを決めました！https://zenn.dev/akasan/articles/7e30ad266c02c4※ 本企画に関する記事の目的は、それぞれのプロジェクトを本格的に深ぼるのではなく、プロジェクト名⇆どんな内容かをパッと思い出せるようにすることを目指します！※ とはいえ深ぼってみたいプロジェクトがあればどんどん複数連載になると思います。 Avroとは？公式サイトによると、Apache Avro™ is the leading serialization ...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[「自分の環境では動く」から解放される Nix Flake ]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/18/111500</guid>
            <pubDate>Thu, 18 Dec 2025 02:15:00 GMT</pubDate>
            <content:encoded><![CDATA[はじめに「自分の環境では動くんだけど...」という言葉を、何度聞いたことがあるだろうか。開発環境の差異は、これまで「手順書」「Docker」「asdf/anyenv」で解決を試みてきたが、いずれも時間経過で破綻する。手順書は陳腐化し、Dockerfileのベースイメージは変わり、asdfは言語ごとにツールが分散する。問題の本質は「環境の固定」ではなく「依存関係の完全な追跡」にあった。これを根本から解決するのが、純粋関数型パッケージマネージャ「Nix」と、その最新機能「Nix Flake」だ。これらの課題感については Infrastructure as Code, 3rd Edition が詳しく論じており、参考になる。2025年 俺が愛した本たち 技術書編 に入れれていなくて悲しいほどよい書籍である。オライリー・ジャパンさん 自分は翻訳の準備できてます！！！Infrastructure as Code: Designing and Delivering Dynamic Systems for the Cloud Age (English Edition)作者:Morris, KiefO'Reilly MediaAmazon本記事では、Nix Flake を使った開発環境の統一について、Docker との比較を交えながら包括的に解説する。実際に複数言語のプロジェクトで検証した結果も含めて、実践的な導入方法を紹介する。この記事で分かることNix Flake の基本概念と従来の Nix との違いDocker と Nix の使い分け・組み合わせ方各プログラミング言語（Rust, Go, Python, TypeScript）での開発環境の構築方法CI/CD との統合方法と direnv による自動環境切り替えNix とは何か純粋関数型パッケージマネージャNix は、従来のパッケージマネージャ（apt, brew, npm など）とは根本的に異なるアプローチを取る。その核心は「純粋関数型」（入力が同じなら出力も必ず同じになる仕組み）という概念にある。数学の関数と同様に、Nix では「同じ入力からは常に同じ出力が得られる」。パッケージのビルドに必要な全ての依存関係を明示的に指定し、外部環境に依存しない閉じた環境でビルドを行う。この仕組みにより、以下が保証される。再現性: 誰がいつどこでビルドしても、同じ結果が得られる分離性: システムの既存環境を汚さない共存性: 同じパッケージの異なるバージョンが同時に存在できるnixos.orgハッシュベースの依存管理Nix は全てのパッケージを /nix/store/ 以下にハッシュ付きで保存する。例えば、Node.js 20.10.0 は以下のようなパスに保存される。/nix/store/abc123...-nodejs-20.10.0/このハッシュは、パッケージのソースコード、ビルドスクリプト、全ての依存関係から計算される。つまり、依存関係が少しでも異なれば、異なるハッシュ（異なるパス）になる。これにより、バージョン競合が原理的に発生しない。Nix の核心概念Nix を理解するには、いくつかの重要な概念を押さえておく必要がある。Derivation（導出）Derivation はビルドレシピのようなもので、Nix の中核概念だ。「既存の store object から新しい store object を生成する純粋関数」と捉えれば理解しやすい。ビルドは sandboxed プロセスとして実行され、指定された入力のみを読み込み、決定論的に出力を生成する。Store（ストア）Store は /nix/store/ に存在するオブジェクトの集合だ。全てのパッケージ、ビルド成果物、依存関係がここに保存される。Store は不変（immutable）であり、一度書き込まれたオブジェクトは変更されない。Store PathStore path は store object の一意な識別子だ。例えば以下のような形式になる。/nix/store/a040m110amc4h71lds2jmr8qrkj2jhxd-git-2.38.1この長い文字列（a040m110...）は、パッケージの全ての入力から計算されたハッシュだ。入力が変われば、パスも変わる。これが Nix の再現性を支える基盤となっている。Realise（実現化）Realise は derivation を実際にビルドし、store path を valid な状態にすることだ。既にキャッシュにあればダウンロードされ、なければビルドが実行される。これらの概念については、公式マニュアルと用語集で詳しく解説されている。nix.devnix.devNix Flake とはFlake の基本構造Nix Flake は、Nix の最新機能であり、プロジェクトの依存関係を宣言的に管理する仕組みだ。従来の Nix には2つの問題があった。(1) NIX_PATH や <nixpkgs> などグローバルな状態に依存し、マシンごとに異なる結果を生む可能性があった。(2) 依存関係のバージョンを固定する標準的な方法を欠いていた。nix-channel の更新で環境が変わってしまうのだ。Flake は flake.lock でこれらを解決する。project/├── flake.nix          # プロジェクト定義├── flake.lock         # 依存関係のロックファイル└── src/               # ソースコードflake.nix は以下の構造を持つ。{  description = "プロジェクトの説明";  inputs = {    # 依存する外部 Flake を定義    nixpkgs.url = "github:nixos/nixpkgs?ref=nixpkgs-unstable";  };  outputs = { self, nixpkgs }: {    # 出力（devShells, packages, etc.）を定義  };}flake.lock による再現性flake.lock は npm の package-lock.json や Rust の Cargo.lock に相当する。全ての依存関係のコミットハッシュが固定されるため、時間が経っても同じ環境を再現できる。{  "nodes": {    "nixpkgs": {      "locked": {        "lastModified": 1702312524,        "narHash": "sha256-...",        "rev": "abc123...",        "type": "github"      }    }  }}Flake についての詳細は NixOS Wiki を参照してほしい。nixos.wikiDocker / コンテナエコシステムとの比較Nix と Docker は競合ではなく補完関係にある。Nix は「ビルド時の再現性」を、Docker は「ランタイムの分離とデプロイ」を担う。各ツールとの関係 ツール  役割  Nix との関係  Dockerfile  イメージビルド  Nix で置き換え可能（より再現性が高い）  Docker Compose  マルチコンテナ構成  devenv/process-compose で補完  Kubernetes  コンテナオーケストレーション  Nixidy/kubenix で統合可能  Helm  K8s パッケージ管理  nix-helm で Nix から利用可能  Skaffold  開発ワークフロー自動化  ビルドフェーズで Nix を使用可能 Dockerfile の課題と Nix の解決策Dockerfile は広く普及しているが、再現性に課題がある。# Dockerfile: 再現性の問題FROM python:3.12  # タグは可変RUN apt-get update && apt-get install -y curl  # バージョン固定なしRUN pip install requests  # バージョン固定なし# Nix: 完全な再現性{  packages.docker-image = pkgs.dockerTools.buildImage {    name = "my-app";    copyToRoot = pkgs.buildEnv {      name = "image-root";      paths = [ pkgs.python312 pkgs.curl pkgs.python312Packages.requests ];    };  };}Nix の優位点:- ビット単位で同一の結果を保証- 全ての依存を明示的に管理（暗黙の依存が混入しない）- パッケージ単位の効率的なキャッシュ- SBOM（Software Bill of Materials）の自動生成blog.replit.comwww.devzero.ioNix + Docker の組み合わせ両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。{  packages.docker-image = pkgs.dockerTools.buildLayeredImage {    name = "my-app";    tag = "latest";    contents = [ myApp pkgs.cacert ];    config.Cmd = [ "/bin/my-app" ];  };}各依存パッケージが独立したレイヤーになるため、パッケージAを更新してもパッケージBのレイヤーは再利用される。Dockerfile を書く必要がなく、Nix の宣言的な記述で完結する。flox.devKubernetes との統合: NixidyNixidy は Nix と Argo CD を組み合わせた GitOps ツールで、クラスター全体を NixOS のように管理できる。{  applications.nginx = {    namespace = "default";    helm.releases.nginx = {      chart = inputs.nixhelm.chartsDerivations.nginx;      values = { replicaCount = 3; service.type = "LoadBalancer"; };    };  };}nixidy.dev近年、ソフトウェアサプライチェーンのセキュリティが重視されている。ビルドの再現性と依存関係の透明性は「必須」になりつつある。Nix はビルドプロセス全体を宣言的に記述するため、SBOM の自動生成と来歴の追跡が容易だ。thenewstack.io実践：複数言語での開発環境構築flake-parts によるモジュール化複雑な Flake を管理しやすくするために、flake-parts を使う。これは NixOS モジュールシステムの考え方を Flake に適用したもので、設定を複数ファイルに分割できる。{  inputs = {    nixpkgs.url = "github:nixos/nixpkgs?ref=nixpkgs-unstable";    flake-parts.url = "github:hercules-ci/flake-parts";    treefmt-nix.url = "github:numtide/treefmt-nix";  };  outputs = { flake-parts, ... }@inputs:    flake-parts.lib.mkFlake { inherit inputs; } {      imports = [ inputs.treefmt-nix.flakeModule ];      systems = [ "aarch64-darwin" "aarch64-linux" "x86_64-linux" ];      perSystem = { config, pkgs, ... }: {        devShells.default = pkgs.mkShell {          packages = with pkgs; [            nodejs_22            config.treefmt.build.wrapper          ];        };        treefmt = {          projectRootFile = "flake.nix";          programs.prettier.enable = true;          programs.nixfmt.enable = true;        };      };    };}flake.partsRust 開発環境Rust プロジェクトでは、rust-overlay を使う。rustupなしで stable/nightly を切り替えられる。rust-analyzer や clippy も flake.nix で宣言的に管理できる。{  inputs.rust-overlay.url = "github:oxalica/rust-overlay";  perSystem = { pkgs, system, ... }:    let      overlayPkgs = import inputs.nixpkgs {        inherit system;        overlays = [ inputs.rust-overlay.overlays.default ];      };      rustToolchain = overlayPkgs.rust-bin.stable.latest.default.override {        extensions = [ "rust-src" "rust-analyzer" "clippy" ];      };    in {      devShells.default = pkgs.mkShell {        packages = [          rustToolchain          pkgs.cargo-watch          pkgs.cargo-edit        ];      };    };}github.comGo 開発環境{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      go      golangci-lint      gopls      delve    ];    env = {      CGO_ENABLED = "0";    };  };}Python 開発環境Python では uv との組み合わせを推奨する。Nix で Python 本体と uv を提供し、パッケージ管理は uv に任せる。pyenv/venv/pip の組み合わせより高速で、依存解決も確実だ。{  devShells.default = pkgs.mkShell {    packages = with pkgs; [      python312      uv      ruff      pyright    ];    env = {      UV_PROJECT_ENVIRONMENT = ".venv";    };  };}マルチ言語プロジェクト1つの Flake で複数の開発環境を提供できる。{  devShells = {    default = pkgs.mkShell {      packages = [ rustToolchain pkgs.go pkgs.nodejs_22 ];    };    rust = pkgs.mkShell { packages = [ rustToolchain ]; };    go = pkgs.mkShell { packages = [ pkgs.go ]; };    nodejs = pkgs.mkShell { packages = [ pkgs.nodejs_22 ]; };  };}使用時は以下のように選択できる。nix develop        # デフォルト（全言語）nix develop .#rust # Rust のみnix develop .#go   # Go のみ様々な言語向けのテンプレートが dev-templates リポジトリで公開されている。github.comdirenv との連携direnv とはdirenv は、ディレクトリごとに環境変数を自動で切り替えるツールだ。.envrc ファイルを配置したディレクトリに入ると自動的に環境がロードされ、離れるとアンロードされる。direnv.netnix-direnv のセットアップNix Flake と direnv を連携させるには、nix-direnv が必要だ。実際にセットアップした手順を紹介する。1. nix-direnv のインストール# Nix profile でインストールnix profile install nixpkgs#nix-direnv# インストール確認ls ~/.nix-profile/share/nix-direnv/# direnvrc が存在することを確認2. direnvrc の設定~/.config/direnv/direnvrc に以下を追加する。# nix-direnv を使用して Nix Flake 環境を高速にロード# キャッシュにより、シェル起動時の遅延を大幅に削減if [ -f "$HOME/.nix-profile/share/nix-direnv/direnvrc" ]; then  source "$HOME/.nix-profile/share/nix-direnv/direnvrc"elif [ -f "/nix/var/nix/profiles/default/share/nix-direnv/direnvrc" ]; then  source "/nix/var/nix/profiles/default/share/nix-direnv/direnvrc"elif [ -f "/run/current-system/sw/share/nix-direnv/direnvrc" ]; then  source "/run/current-system/sw/share/nix-direnv/direnvrc"fi3. シェルへの hook 追加使用しているシェルに応じて設定を追加する。# bash (~/.bashrc)eval "$(direnv hook bash)"# zsh (~/.zshrc)eval "$(direnv hook zsh)"# fish (~/.config/fish/config.fish)direnv hook fish | sourcegithub.comプロジェクトでの使用1. .envrc ファイルの作成プロジェクトルートに .envrc を作成する。# .envrc - 基本的な使い方use flakeより詳細な設定も可能だ。# .envrc - 詳細な設定例# nix-direnv を使用（高速・キャッシュ対応）use flake# 特定の devShell を使用する場合# use flake .#rust# 追加の環境変数export EDITOR="nvim"export MY_PROJECT_ENV="development"2. direnv の許可セキュリティのため、初回は明示的に許可が必要だ。cd my-projectdirenv allow動作確認実際に動作を確認した結果を示す。# direnv のステータス確認$ direnv statusdirenv exec path /opt/homebrew/bin/direnvDIRENV_CONFIG /Users/nwiizo/.config/direnvFound RC path /path/to/project/.envrcFound RC allowed 0Found RC allowPath /Users/nwiizo/.local/share/direnv/allow/...nix-direnv のキャッシュ機構nix-direnv は .direnv/ ディレクトリにキャッシュを作成する。実際のキャッシュ構造は以下のようになる。.direnv/├── bin/                    # 一時的なバイナリラッパー├── flake-inputs/           # 入力 Flake のキャッシュ├── flake-profile-*         # Nix Store へのシンボリックリンク└── flake-profile-*.rc      # 環境変数のキャッシュ（約86KB）キャッシュの効果flake-profile-* は Nix Store の実際のパッケージを指す例: /nix/store/l5rhpr6i98h3kvydy6gww5cvszmqi05a-nix-shell-env2回目以降のロードは数ミリ秒で完了nix-collect-garbage でもキャッシュは保護されるnix-direnv vs 標準 direnv 観点  nix-direnv  標準 direnv + use nix  初回ロード  同等（ビルドが必要）  同等  2回目以降  数ミリ秒  数秒〜数十秒  GC 耐性  保護される  削除される可能性  Flake 対応  ネイティブ  追加設定が必要  キャッシュサイズ  〜100KB/プロジェクト  なし マルチ言語プロジェクトでの設定複数の devShell を持つプロジェクトでは、以下のように使い分けられる。# .envrc# デフォルトで全言語環境をロードuse flake# または特定の言語環境のみロードする場合:# use flake .#rust# use flake .#go# use flake .#python# use flake .#nodejsトラブルシューティングdirenv が反応しない# シェルフックが設定されているか確認which direnvdirenv status# 許可されているか確認direnv allow環境がロードされない# .envrc の構文エラーをチェックdirenv edit# キャッシュをクリアして再構築rm -rf .direnvdirenv allowFlake が見つからない# flake.nix が Git に追加されているか確認git status flake.nixgit add flake.nix flake.lockDeterminate Systems のブログでは、direnv と Nix の連携について詳しく解説されている。determinate.systemsCI/CD との統合GitHub Actions での使用name: CI with Nix Flakeon: [push, pull_request]jobs:  build:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v4      # Nix インストール（Determinate Systems 推奨）      - uses: DeterminateSystems/nix-installer-action@main      # Magic Nix Cache でビルドを高速化      - uses: DeterminateSystems/magic-nix-cache-action@main      # Flake のチェック      - run: nix flake check      # フォーマットチェック      - run: nix develop --command treefmt --ci      # ビルド      - run: nix buildgithub.comCachix によるバイナリキャッシュCI でビルドした成果物を Cachix にプッシュすると、他の開発者やCI環境ではビルド済みバイナリをダウンロードするだけで済む。ビルド時間が大幅に短縮される。- uses: cachix/cachix-action@v15  with:    name: your-cache    authToken: '${{ secrets.CACHIX_AUTH_TOKEN }}'overlay によるカスタマイズパッケージのカスタマイズoverlay を使うと、既存のパッケージをカスタマイズしたり、独自のパッケージを追加したりできる。{  customOverlay = final: prev: {    # 既存パッケージをラップ    myGit = prev.writeShellScriptBin "git" ''      exec ${prev.git}/bin/git -c init.defaultBranch=main "$@"    '';    # カスタムスクリプト    project-init = prev.writeShellScriptBin "project-init" ''      echo "Initializing project..."      ${prev.git}/bin/git init      echo "# New Project" > README.md    '';  };}treefmt による統一フォーマット複数言語のフォーマッターを1つのコマンドで実行できる。{  treefmt = {    projectRootFile = "flake.nix";    programs = {      nixfmt.enable = true;      rustfmt.enable = true;      gofmt.enable = true;      prettier.enable = true;      ruff-format.enable = true;    };  };}treefmt      # 全ファイルをフォーマットtreefmt --ci # CI でのチェック（変更があればエラー）github.comトラブルシューティングexperimental-features エラーerror: experimental Nix feature 'nix-command' is disabled~/.config/nix/nix.conf に以下を追加する。experimental-features = nix-command flakesnix develop が遅い初回は依存関係のダウンロードとビルドに時間がかかる。2回目以降はキャッシュが効くため高速だ。Cachix を使うとより高速化できる。direnv が無限ループするFish shell を使っている場合、shellHook で exec fish を呼ばないように注意する。Flake が見つからないFlake ファイルは Git に追加されている必要がある。未追跡ファイルは Nix から見えない。git add flake.nix flake.lockまとめNix Flake を導入することで、開発環境の「再現性」「分離性」「共有性」を根本から改善できる。Docker とは競合ではなく補完関係にあり、両者を組み合わせることで「再現可能なビルド」と「ポータブルなデプロイ」を両立できる。導入の主なメリットをまとめる。開発環境のセットアップが nix develop の1コマンドにチーム全員が同じツールバージョンを使用CI と開発環境の乖離がなくなるフォーマットの一貫性を自動で保証Docker イメージのビルドも再現可能に学習コストは確かに高い。Nix言語の習得やStore/Derivationの概念理解には時間がかかる。しかし一度導入すれば、環境構築が1コマンドで完了する。「環境差異によるバグ」が原理的になくなり、CIと開発環境が同一になる。特に複数言語プロジェクトでは、rustup/pyenv/nvm/goenvの個別管理から解放され、単一のflake.nixで全ての言語ツールチェーンを統一できる。まずは小規模なサイドプロジェクトで試してみてほしい。nix flake init -t github:the-nix-way/dev-templates#rust ですぐに始められる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Interested in Self-Endless Advent Calendar?]]></title>
            <link>https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/interested-in-a-self-endless-advent-calendar-afc8ca9bf4b0?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 17 Dec 2025 13:29:58 GMT</pubDate>
            <content:encoded><![CDATA[I’ve been writing tech blog on Japanese tech blog media, Zenn, since April 18, 2025 everyday. I’ll share why I started this activity and…Continue reading on Medium »]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubで管理しているZennのファイル名を一括修正した話]]></title>
            <link>https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2</link>
            <guid isPermaLink="false">https://daisuke1024akagawa.medium.com/github%E3%81%A7%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6%E3%81%84%E3%82%8Bzenn%E3%81%AE%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB%E5%90%8D%E3%82%92%E4%B8%80%E6%8B%AC%E4%BF%AE%E6%AD%A3%E3%81%97%E3%81%9F%E8%A9%B1-2020c94f2e60?source=rss-c54ac439ad2b------2</guid>
            <pubDate>Wed, 17 Dec 2025 13:04:22 GMT</pubDate>
        </item>
        <item>
            <title><![CDATA[Aimシリーズ：OptunaとPytorch Lightningを組み合わせたMNIST実験管理]]></title>
            <link>https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/aim_optuna_lightning_mnist</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:24 GMT</pubDate>
            <content:encoded><![CDATA[今回はAimで実験管理を行いつつ、OptunaとPytorch Lightningを使ってMNISTの分類をしてみました。ぜひ過去の以下の記事を参考にしてください。https://zenn.dev/akasan/articles/6221f74bea622dhttps://zenn.dev/akasan/articles/a75361d039906f 早速実装 環境構築uvを使って以下で環境を構築します。uv init aim_optuna_lightning_mnist -p 3.12cd aim_optuna_lightning_mnistuv add aim l...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Aimシリーズ：入門してみた]]></title>
            <link>https://zenn.dev/akasan/articles/aim_ml_tracking_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/aim_ml_tracking_intro</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:23 GMT</pubDate>
            <content:encoded><![CDATA[今回から、Aimという実験管理ツールに入門してみます。※ 出張中につき、短編になります。 Aimとは？Aimとはオープンソースの実験管理ツールになります。Aimを利用すると実験を実行し、その結果発生する様々なメタデータを一元的に取り扱い、グラフィカルに解析することができます。Aimを利用することで以下のようなことが実現できます。MLパイプラインのロギングを可能にするUIを通してメタデータを比較分析できるML学習を効率的に実行可能実験管理のオーガナイズができるhttps://github.com/aimhubio/aim/ 早速使ってみる今回はGitHub上で提...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoを使ってOpenAIのエージェントを作成してみた]]></title>
            <link>https://zenn.dev/akasan/articles/agno_openai_agent_intro</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/agno_openai_agent_intro</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:23 GMT</pubDate>
            <content:encoded><![CDATA[今回はagnoのOpenAI連携機能を利用してエージェントを作ってみました。 agnoとは？agnoとはメモリや知識、ツールやリーズニングを実現するエージェントを実装するための軽量なフレームワークとなります。agnoを利用することで、推論エージェントやマルチモーダルエージェント、エージェントワークフローを構築できます。agnoはエージェントとチャットするための美しいUIやエージェントにサービスを提供する構築済みのFastAPIルート、そしてエージェントのパフォーマンスを監視・評価するためのツールも提供するとのことです。https://github.com/Akasan/agno...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[agnoのGuardrail機能を試してみた]]></title>
            <link>https://zenn.dev/akasan/articles/agno_guardrail_feature</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/agno_guardrail_feature</guid>
            <pubDate>Wed, 17 Dec 2025 11:15:22 GMT</pubDate>
            <content:encoded><![CDATA[今回は昨日に引き続きagnoを利用してみました。agnoではGuardrailの機能について提供しており、そのサンプルを通して挙動を確認してみようと思います。昨日のagnoの導入記事もぜひ合わせてご覧ください。https://zenn.dev/akasan/articles/80953b8e206dd0 早速使ってみる今回は以下のページを参考にサンプルを試してみます。https://docs.agno.com/concepts/agents/guardrails/overviewhttps://docs.agno.com/examples/concepts/agent/gua...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[GitHubで管理しているZennのファイル名を一括修正した話]]></title>
            <link>https://zenn.dev/akasan/articles/claude_code_zenn_title</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/claude_code_zenn_title</guid>
            <pubDate>Wed, 17 Dec 2025 11:00:00 GMT</pubDate>
            <content:encoded><![CDATA[私は普段Zennの投稿をGitHubで管理しているのですが、記事のファイル名を一括で更新したので、その内容を共有しようと思います。 どうやってZennの記事をGitHubで管理しているかZenn公式が出している以下の記事に載っている方法で管理しています。https://zenn.dev/zenn/articles/connect-to-githubまた、記事を作成するときはZennのCLIを利用しています。ZennのCLIについてはこちらを見ていただければ使い方がわかると思いいただければ使い方がわかると思います。私は入力を省略するため、以下のようなzenn_articleという...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[2025年版 私がAIエージェントと協働しながら学習する方法]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/17/121705</guid>
            <pubDate>Wed, 17 Dec 2025 03:17:05 GMT</pubDate>
            <content:encoded><![CDATA[労働こそが最高の学習だったあなたは最近、「成長している」と感じているだろうか。かつて、プログラマーにとって、労働こそが最高の学習の場だった。なぜか。労働には「摩擦」があったからだ。エラーが出る。原因がわからない。仮説を立てる。試す。失敗する。また試す。この摩擦の中で、経験が意味に変わっていた。労働は、経験を意味に変換する装置だった。以前の開発を思い出す。新しいフレームワークを覚えなければならない。エラーと格闘して、ドキュメントを読み漁って、やっと動いたとき。あの達成感は、単なる満足ではなかった。「なぜ動かなかったか」「どう直したか」「次に同じ問題が起きたらどうするか」——この因果の記憶が、脳に刻み込まれていた。困難を乗り越えた記録が、自分の中に残っていた。Claude Codeで開発している今、コードは書ける。動く。レビューも通る。Claude CodeはAnthropicが提供するAIエージェント型の開発ツールで、ターミナル上で動作し、コードの生成・編集・実行・デバッグまでを自然言語で指示できる。従来の「コード補完」とは次元が違う。プロジェクト全体を理解し、ファイルを横断して作業し、テストまで書いてくれる。開発のあり方が、根本から変わった。しかし、その便利さの裏で、何かがおかしくなっていた。コードは書ける。動く。レビューも通る。でも、後から「なぜそう書いたの？」と聞かれても、答えに淀む。自分が責任を持って出力したコードのはずなのに、説明しようとすると言葉が出てこない。因果を辿れない。「なぜこの実装なのか」「他の選択肢は何だったか」「どこで判断したか」——この記憶がない。このままでは「実装ガチャ」を回し続けるだけの存在になってしまう。先日、それを痛感する出来事があった。本番環境で障害が起きた。自分が2週間前に実装した機能だ。ログを見る。エラーメッセージを読む。でも、原因の見当がつかない。「この処理、どういう順序で動くんだっけ」と考える。思い出せない。自分で書いたコードなのに、頭の中でトレースできない。因果がわからない。結局、AIにコードを貼り付けて「このエラーの原因は？」と聞いた。答えは返ってきた。直った。しかし、自分では何も解決していない。2週間前の自分が書いたコードを、今日の自分が理解できていなかった。もしかして、あなたも同じ感覚を持っていないだろうか。最初は自分を責めた。集中力が落ちたのか。学習能力が衰えたのか。でも違った。労働と学習が、分離した。摩擦が消えた。経験が意味に変わる機会が消えた。厄介だったのは、見せかけ上の生産性は上がっていたことだ。タスクは消化されている。アウトプットも出ている。しかし、3ヶ月前にやった案件の技術スタックを聞かれても、ほとんど思い出せない。生産性は上がった。成長は止まった。労働から学習が抜け落ちていた。「成長していない」と感じるとき、私たちは何を失っているのか。成果と経験と理解は、同じものだろうか。違う。成果は外に出たもの。経験は時間の中で起きたこと。理解は内側に残ったもの。成果が出ても、経験を積んでも、理解が残らなければ成長は感じられない。失われているのは「苦労」ではない。「プロセスの記憶」だ。自分が何を考え、どこで躓き、どう乗り越えたか。この記憶が消えている。AIが生成したコードは動く。でも、そこに至るまでに自分が何を試し、何を捨て、何を選んだか——その記憶がない。なぜ過去の仕事を説明できないと不安になるのか。説明できないということは、プロセスの記憶がないということだ。記憶がないということは、自分の中で何も変化が起きていないということだ。成長実感とは、能力の増加ではない。自分の内部で変化が起きたと確認できる手応えだ。では、記憶に残らない仕事は価値がないのか。そうではない。成果としての価値はある。でも、自分を成長させる価値はない。成果は外に残る。成長は内に残る。両者は別物だ。これは集中力の問題ではなかった。前回の記事「2025年版 私がAIエージェントと協働しながら集中する方法」で書いた微観法は、集中の持ち方を変えてくれた。でも、学習の問題は別だった。集中できても、学べていなかったのだ。syu-m-5151.hatenablog.com『信長の野望』をやっているのに『戦国無双』のような強さを求めるのは違う、と言われるかもしれない。地道な内政と、爽快なアクション。求めているものが違う。でも正直なところ、私たちはいつだってエンジニアなのでエンジニア領域で無双したいのです。AI時代の3つの非対称性ここまで、私個人の経験として「労働と学習の分離」を語ってきた。でも、ここまで読んで、「これは自分だけの問題かもしれない。単に自分の学び方が下手なだけでは？」と思った人もいるだろう。そうではない。これは個人の問題ではない。構造の問題だ。なぜ労働と学習が分離してしまったのか。その構造を理解するには、AIがもたらした3つの非対称性を見る必要がある。詳しくは別の記事で書いたが、ここでも簡単に触れておきたい。syu-m-5151.hatenablog.com第一の非対称性：生産と理解の乖離。AIでコードを書く速度は上がった。でも、そのコードを修正しようとすると、予想以上に時間がかかる。システム内にコードが流入する速度と、人間がそれを理解する速度の間に、決定的なギャップが生まれている。第二の非対称性：生産量と成長の乖離。AIを使えば、経験1年目でも大量のコードを生産できる。PRの数も増える。でも半年後、1年後、エンジニアとしての地力はどうなっているだろうか。問題を自分で分析し、設計を考え、トレードオフを検討するプロセス。これがエンジニアの地力を育てる。AIに頼りすぎると、この思考プロセスそのものを外部化してしまう。第三の非対称性：経験の量と学びの質の乖離。毎日AIを使って100行のコードを書く経験を1年積んでも、そこから「AIへの依存」しか学ばなければ、地力にはつながらない。「何を経験したか」ではなく、「そこから何を学んだか」が重要なのだ。この3つの非対称性は、1つのシステムとして機能している。速く書けることを追求すれば、理解が追いつかなくなる。理解しないまま大量に生産すれば、思考力が育たない。経験を積んでも、そこから学ばなければ、成長は起きない。根底にあるメンタルモデル—「速さが価値」「量が成果」「経験が成長」—を変えない限り、どんな対症療法も一時的な効果しか生まない。ここまでで、外部から見た構造——AIと人間の関係性——は理解できた。しかし、これだけでは「なぜ学べないのか」の本当の理由は見えてこない。構造は外側の話だ。学習が起きるのは、私たちの脳の内側だ。では、この構造が私たちの脳に何をしているのか。もう少し掘り下げてみよう。脳が「処理」していない構造の問題は、最終的に脳の問題に帰着する。なぜ知識が残らないのか。しばらく自分を観察してみた。気づいたのは、AIエージェントと働いていると、認知的負荷が下がりすぎるということだ。認知的負荷とは、頭を使う度合いのことだ。問題を解くとき、脳は情報を処理し、比較し、判断する。この「頭を使う」プロセスが、認知的負荷を生む。負荷が下がること自体は、一見良いことに思える。楽に仕事ができる。疲れにくい。でも、学習の観点からは最悪だった。脳は適度な負荷がかからないと、情報を長期記憶に格納しない。「苦労せずに得た情報」は、脳にとって重要度が低いと判断される。楽に得た知識は、楽に消える。では、認知的負荷はどこからが「害」になるのか。問題は量ではない。質だ。認知的負荷には種類がある。タイピングの負荷。構文を思い出す負荷。そして、比較・判断・仮説といった意味処理の負荷。AIが減らしてくれるのは、すべての負荷だ。だが、害になるのは意味処理の負荷が消えたときだ。なぜ脳は負荷がないと学ばないのか。脳は「重要でない」と判断した情報を捨てる。重要かどうかの判断基準は、処理にかかった負荷だ。苦労して得た情報は重要。楽に得た情報は重要でない。意味処理の負荷が消えた瞬間、脳は「これは覚えなくていい」と判断する。記憶も学習も、起こらなくなる。「ちょうどよい負荷」は誰が決めるのか。AIではない。あなただ。負荷をAIに外注すると、脳は怠ける。怠けた脳は弱くなる。認知的負荷は削減対象ではない。設計対象だ。どの負荷を残し、どの負荷を外注するか。その設計を自分でしなければ、学習は起こらない。楽になることと、考えなくなることは同じか。違う。作業が楽になるのはいい。思考が楽になるのは危険だ。手を動かす負荷は減らしていい。意味を処理する負荷は、意図的に残せ。以前のプログラミングを思い出す。エラーが出る。ググる。ブログや公式ドキュメントを読む。試す。またエラー。別の方法を試す。やっと動く。このプロセス全体が、学習だった。途中で「わからない」状態に耐える必要があった。その「耐える時間」が、脳を鍛えていた。記憶を定着させていた。今はどうか。エラーが出る。AIに投げる。答えが返ってくる。動く。終わり。プロセスが消えた。プロセスが死ぬと、学習も死ぬ。考えてみてほしい。あなたが最後に「わからない」と感じたのは、いつだろうか。私は本当に思い出せなかった。AI時代において、「わからない」が絶滅したのだ。聞けば答えが返ってくる。どんな質問にも、それらしい回答が生成される。以前は「わからない」状態で立ち止まり、悩み、調べ、試行錯誤した。その時間が学習だった。今は「わからない」と感じる前に、答えが手に入る。「わからない状態」に耐える力こそ、学習に不可欠だ。わからない状態は不快だ。不確実性は脳にストレスを与える。だから、答えを求める。AIはその欲求を即座に満たしてくれる。だが、「わからない」は単なる欠如ではない。意味を構築するための空白だ。以前の学習を思い出してほしい。エラーが出て、原因がわからない。ドキュメントを読んでも、ピンとこない。仮説を立てて、試して、また失敗する。その空白の中で、脳は問題を構造化していた。何がわかっていて、何がわかっていないか。どこまでは正しくて、どこからが怪しいか。仮説を立て、壊し、更新する。このプロセスを通じて、人は「思考の型」と「判断の軸」を獲得してきた。わからない経験がなくなると、思考の型が育たない。問題をどう分解するか。仮説をどう立てるか。どの順番で検証するか。これは、わからない状態を何度も経験することでしか身につかない。答えが即座に与えられる世界では、この「思考の筋トレ」そのものが消える。AIはわからないと言わない。常に何かを返す。それが正しいかどうかは別として。人間だけが「わからない」を経験できる。その経験を捨てるのは、思考力を捨てることだ。でも、その「すぐわかる」が、実は思考力を奪っていた。自分一人で「じっくり」考える時間が消えた。わからないまま考え続ける能力。不確実性の中にとどまる能力。それが失われていく。「わからない」を経験しないまま、「わかった」に到達してしまう。ここまでは「わからない状態」の話だった。つまり、問題に直面したとき、AIがすぐに答えを出してしまうから、自分で考える時間がなくなるという話だ。でも、認知的負荷が下がる問題は、これだけではない。AIの答えを受け取って「わかった」と思った後にも、別の問題がある。コードへの解像度が下がるのだ。以前、自分で書いたコードは、補完もありながらちゃんと打ち込んでいた。変数名を決めるときに悩んだ。ループの終了条件を頭の中でシミュレートした。このif文の分岐は、こういうケースでtrueになる。この変数には、この時点でこの値が入っている。コードは指先から脳へ流れ込んでいた。AIが生成したコードは、目で見ているだけだ。なんとなく動く気がするから動かす。動く。テストも通る。でも、変数の1つに至るまで把握しているかと言われると、怪しい。コードが「通過」していく感覚。身体に染み込んでいない。見ているのに、触れていない。この違和感の正体は何か。自分で書いたコードと、AIが書いたコードは何が違うのか。結果は同じだろう。動作も同じだろう。でも、因果関係を自分で通ったかどうかが違う。自分で書いたコードには、因果の記憶がある。「この変数名、最初はdataにしようと思った。でも、後から読んだときに意味がわからなくなると思って、userResponseに変えた」。「このループ、最初はforで書いた。でも、副作用がないからmapの方がきれいだと思って書き直した」。迷い、選択し、決断した記憶。その因果を自分で通った記憶が、コードを「理解している」という感覚を生む。AIが生成したコードには、この因果がない。結果だけがある。「なぜこの変数名なのか」「なぜこの書き方なのか」。AIには理由があるのだろう。でも、その理由を自分で通っていない。書く・迷う・選ぶという行為を経ていないコードは、頭の中で「実行」されていない。なぜ説明できないと不安になるのか。説明できないということは、因果を再構成できないということだ。因果がわからないコードは、壊れたとき直せない。変更したとき、何が起きるか予測できない。「動くこと」と「わかること」は別だ。動くことは確認できる。わかることは、因果を辿れるかどうかで決まる。理解とは知識量ではない。因果を身体でトレースできるかどうかだ。「見ているが触っていない」とは、この状態だ。視覚的には認識している。でも、因果を身体で通過していない。だから、記憶に残らない。応用が利かない。自分のものにならない。解像度が低い理解は、何を引き起こすのか。判断ができなくなる。「この実装でいいのか」「この変更は安全か」。判断には、因果の理解が必要だ。因果がわからなければ、判断できない。判断できない人間は、AIの出力を受け入れるしかない。私は自分で書いたコードは、書く過程で何度も頭の中で実行している。「この変数がnullだったらどうなる」「このループは何回まわる」「この関数の戻り値は何型か」。無意識に検証している。AIが生成したコードには、この検証プロセスがない。結果、コードの「解像度」が違う。自分で書いたコードは、ズームインしてもくっきり見える。AIが生成したコードは、全体像はわかるが、細部がぼやけている。動くことは知っている。なぜ動くかは、よくわからない。解像度が低いと、記憶にも残りにくい。ぼんやりした情報は、脳に定着しない。そしてもう1つ、記憶を弱くする要因がある。解像度の問題とは別に、「思い出す」作業をしていないのだ。記憶を定着させるには、能動的に思い出す作業が必要だ。一度覚えたことを、何も見ずに思い出す。その「引き出す」作業が、記憶を強化する。でもAIと働いていると、思い出す必要がない。わからないときは聞けばいい。脳が「引き出す」練習をしなくなった。筋トレと同じだ。重いものを持ち上げないと筋肉はつかない。代わりに機械が持ち上げてくれたら、楽だけど、筋肉は衰える。AIは脳の代行業者だ。頼りすぎると、依頼主が衰える。何をしたか覚えていない、だから自分を過小評価するここまで、認知的負荷が下がることで起きる3つの問題を見てきた。「わからない」状態を経験しなくなること。コードへの解像度が下がること。そして、「思い出す」作業をしなくなること。これらは脳の内側で起きている問題だった。しかし、認知的負荷が下がることには、もう1つ厄介な副作用がある。脳の外側、つまり自分自身の認識に関わる問題だ。自分が何をしたのか覚えていないのだ。1日の終わりに「今日、何やったっけ？」と振り返る。AIと働いていると、驚くほど思い出せない。タスクは消化した。PRはマージされた。でも、何をどう解決したのか、記憶がぼんやりしている。なぜか。苦労しなかったからだ。痛みを伴わない経験は、砂に書いた文字だ。苦労は記憶のアンカーになる。あのエラーで3時間ハマった。あの設計で悩んで何度も書き直した。そういう「苦労の記憶」が、「自分がやった」という実感を生む。AIが苦労を肩代わりすると、このアンカーがなくなる。アンカーがないと、何が起きるか。自分を過小評価するようになる。「今日、大したことやってないな」と感じる。でも実際には、かなりの量のコードがマージされている。客観的には生産性が上がっているのに、主観的には「何もやっていない」気がする。成果と実感が乖離する。これは私だけの感覚ではない。知り合いのエンジニアと話していても、同じことを言う人が多い。「なんか最近、成長している実感がない」「仕事はこなせているけど、自分が何をやったか説明できない」。みんな同じ違和感を抱えている。感覚と現実が、乖離しているのだ。なぜ「何をしたか」を覚えていないと不安になるのか。自己評価はどこから生まれているのか。自己評価は、成果から生まれるのではない。「自分が困難にどう向き合ったか」という記憶から生まれる。あのバグを3時間かけて潰した。あの設計を何度も書き直した。あの障害対応で深夜まで粘った。こうした記憶が、「自分はやれる」という感覚を作る。苦労は自己評価の原材料だ。AIが苦労を肩代わりすると、何が起きるか。成果はある。でも、「自分がやった」という実感が残らない。困難と向き合った記憶がないから、自分を評価する材料がない。結果、成果が出ているのに自分を信じられなくなる。成果と達成感はなぜズレるのか。達成感は「困難を乗り越えた」という認識から生まれる。困難がなければ、達成感も生まれない。AIが困難を消してくれると、成果だけが残り、達成感は消える。成果と達成感の乖離。これがAI時代の新しい病だ。このズレは長期的に何を壊すのか。まず、挑戦を避けるようになる。「どうせAIがやってくれる」と思う。自分で考えることを放棄する。次に、自分を信じられなくなる。難しい問題に直面したとき、「自分にはできない」と感じる。かつて乗り越えた経験がないから、乗り越えられるイメージが湧かない。そして最後に、エンジニアとしてのアイデンティティが揺らぐ。「自分は何ができる人間なのか」がわからなくなる。成果は出ている。でも、それは自分の力なのか、AIの力なのか。区別がつかなくなる。達成の記憶がないなら、何かで補うしかない。では、何で補うのか。答えを先に言う。記録だ。達成の記憶がないなら、記録で作ればいい。苦労の記憶がないなら、躓きを記録で残せばいい。AIが消してしまう「プロセスの記憶」を、意図的に書き留める。それが私の出した答えだった。日報が労働と学習をつなぎ直したここまで読んで、「わかる、でもどうすればいいの？」と思っただろうか。私も同じだった。記録が大事だとわかっても、何をどう記録すればいいかわからなかった。行き詰まっていたとき、藁にもすがる思いで、ある習慣を始めた。日報だ。正直、日報は嫌いだった。面倒くさい。忙しい。後で書こうと思って忘れる。3日分まとめて書いて、何をやったか思い出せない。典型的なサボりパターンだった。何度も挫折した。でも、このままでは本当にまずいと思った。自分が書いたコードを説明できない。障害が起きても自分で解決できない。エンジニアとして、このまま衰えていくのか。その恐怖が、嫌いな日報を続けさせた。でも、日報の目的を変えてみた。上司への報告のためではなく、労働の中で生まれた曖昧さを捕まえるために書く。自分が何をわかっていて、何をわかっていないか。その現状を記録する仕組みだ。日報を続けて、衝撃的な事実に気づいた。その話は後で詳しく書く。でもその前に、一度立ち止まって考えたい。日報を書いて躓きを記録する。それは「学習」につながるはずだ。しかし、そもそも「学習する」とは何なのだろうか。この根本的な問いを考えないと、日報を書く意味も見えてこない。では、「学習する」とは、そもそも何なのでしょうか。この問いを考えるとき、私は為末大さんの『熟達論——人はいつまでも学び、成長できる』（新潮社、2023年）に大きな影響を受けました。400mハードルで日本記録を持つ「走る哲学者」が、様々な分野の達人たちとの対話を重ねて到達した方法論です。www.shinchosha.co.jp為末さんは、人が何かを学び、熟達していくプロセスには、分野を超えた普遍的な構造があると言います。陸上であれプログラミングであれ、学習のプロセスは同じです。技能と自分のどちらかだけを高めても成長できないと説きます。技能と自分は、切り離すことのできない「ひとつのもの」——つまり人間という総体として捉えるべきだと。この人間総体を高めていくことが、学習なのです。この考え方は、ソフトウェアエンジニアとしても腑に落ちます。プログラミングスキルだけを磨いても、良いエンジニアにはなれません。問題を分解する力、チームで働く力、技術を選ぶ判断力。技能と自分の総体が、エンジニアとしての実力です。為末さんによれば、学習には5つの段階があります。この5段階は「学習がどう進むか」を示す地図です。まず、その地図を見てみましょう。「遊（ゆう）」——学習の入口です。新しい技術に触れて、面白いから触る。効率は求めません。目的もありません。遊びとは主体的であり、面白さを伴い、不規則なもの。このモチベーションの源泉が、学習の入口になります。エンジニアなら、新しいフレームワークを触ってみる。ドキュメントを読む前に動かしてみる。「これ何ができるんだろう」と試す。壊してみる。変なパラメータを渡してみる。遊びが好奇心を育て、好奇心が学習を駆動します。「型（かた）」——基礎を身につける段階です。お手本を真似る。ドキュメント通りに書く。型とは「基盤となる最も基本的なもの」であり、個人差を超えて最も安定している普遍的なものです。型は丸呑みするもの。なぜそうするかはわからなくても、まず形から入ります。エンジニアなら、公式チュートリアルを写経する。ベストプラクティスをそのまま真似る。「なぜこう書くのか」は後回し。まず手が覚えるまで繰り返します。型が身体に入ると、考えなくても書けるようになります。「観（かん）」——構造を理解する段階です。「なぜこの書き方なのか」と問う。「見る」とは「分ける」こと。動作を分けて見ることで、技術を構造化します。ある技能は別の技能に支えられている。その関係性が見えてきます。エンジニアなら、コードの設計意図を読み取る。「この抽象化は何のためか」「このパターンはどこで使えるか」と問う。部分（関数）と全体（システム）の関係が見えます。観ができると、他人のコードから学べるようになります。また、コードを「意味の塊」として捉えられるようになります。初心者が「if文があって、関数呼び出しがあって...」と一行ずつ追う場面で、「これはトークン検証の処理だ」と全体を1つの塊として認識できる。塊で捉えるから、複雑なコードも把握できるのです。「心（しん）」——本質を掴む段階です。見極めた本質を軸に、自分なりに自由に動ける状態。いつでもニュートラルポジションに戻れるから、応用的な技術も試せます。中心を柔らかくつかむと、冒険できるようになります。エンジニアなら、技術の本質を掴んでいる状態です。「認証の本質は信頼の証明だ」とわかれば、JWT でも OAuth でも Session でも、状況に応じて選べます。心を掴むと、新しい技術もすぐ理解できます。また、具体的な事例から抽象的なパターンを抽出できます。「このエラーはnullチェック漏れ」という具体から「外部データは信頼しない」という原則へ昇華する。この抽象化ができると、問題を絞り込む力も育ちます。「Invalid token」というエラーを見て、「トークン生成か検証のどちらかが問題」と可能性を狭められる。原理原則を理解していれば、推論で問題にたどり着けるのです。「空（くう）」——学習の到達点です。制約から解き放たれて、技能が自然な形で表現できる状態。いわゆる「ゾーン」です。論理よりも勘が働く。そしてまた「遊」に戻る。学習は循環します。エンジニアなら、コードが自然に流れ出る状態です。設計を考えなくても、手が正しい方向に動く。深夜のデバッグで「なぜかここが怪しい」と直感が働く。空に達した技能は、意識せずに発揮されます。重要なのは、部分の学習が全体を高めるという構造です。「認証処理」という部分を学ぶと、「Webアプリケーション開発」という全体の質が上がります。そして全体の質が上がると、今度は別の部分——たとえば「データベース設計」——を学ぶ意欲が湧いてきます。部分と全体が相互に作用しながら、エンジニアとしての総体が高まっていく。この循環こそが、成長を楽しめる理由です。ここまでが、学習の地図です。でも、抽象的な説明だけでは実感が湧かないかもしれません。私自身の経験に当てはめてみましょう。以前、新しい技術を学ぶとき、何が起きていたでしょうか。ドキュメントを読む。知らない概念が出てくる。調べる。言葉の意味はわかった。でも、まだ腑に落ちない。実際にコードを書いてみる。動かない。なぜ動かないか考える。仮説を立てる。試す。また動かない。別の仮説を立てる。3時間が経つ。ようやく動いた。「ああ、こういうことか」。次からは同じ間違いをしなくなる。この過程で、学習の段階を登っていました。最初は遊びから入った。動かしてみる。壊してみる。次に型を学んだ。ドキュメントを読み、お手本通りに書いた。型を繰り返すうちに、「なぜ」が見えてきた。観の段階です。より深まると、パターンが見える。心の段階です。そして最後に、考えなくても手が動くようになる。摩擦が、学習を生んでいました。繰り返しが、成長を生んでいました。今は違います。AIに聞く。完璧なコードが返ってくる。動く。終わり。私は遊んでいません。型も知りません。観ることもありません。心を掴めません。当然、空には程遠い。結果は出ました。でも、自分の中に何も残っていません。成果だけが先に行き、自分は置き去りにされました。これがAI時代の問題の核心です。摩擦がないから、学べない。繰り返す機会がないから、成長しない。問題の核心は見えました。では、もう少し細かく見てみましょう。学習の5段階で、AIはどこを加速し、どこを壊しているのでしょうか。AIはどの段階を代替しやすいでしょうか。「型」です。正しい書き方、ベストプラクティス、パターンの適用。AIはこれらを高速に提供してくれます。初心者がいきなり熟練者と同じ「型」を使えるようになる。これ自体は悪くありません。では、AIが壊すのはどこでしょうか。「遊」と「観」です。特に「遊」のダメージは深刻です。「遊」が消えると何が起きるのでしょうか。遊びとは、目的なく触ること。壊してみること。限界を探ること。正解がすぐ手に入る環境では、不規則さ・寄り道・失敗が排除されます。効率を求めると、遊びは最初に切り捨てられます。しかし、遊びは単なる入口ではありません。型や観に進むためのエネルギー源でもあります。なぜでしょうか。「型」を学ぶのは退屈です。ドキュメント通りに書く。お手本を真似る。地味な作業です。この退屈に耐えられるのは、「遊」の段階で「面白い」という感覚を得ているからです。「この技術、面白い。だから、ちゃんと学びたい」。このモチベーションがなければ、「型」の段階で挫折します。「観」も同様です。「なぜこうするのか」と問うのは、好奇心がなければできません。好奇心は「遊」で育ちます。遊びがないと、「なぜ」を問う動機がない。「動くからいい」で終わります。遊びがないと、「面白いから学ぶ」がなくなります。「必要だから学ぶ」だけになる。必要性で駆動される学習は、必要がなくなった瞬間に止まります。遊びが失われると、学習への意欲そのものが枯れるのです。「観」も壊れやすい段階です。「なぜこうするのか」と問う前に、AIが答えを出してしまう。構造を自分で見出すプロセスがスキップされます。答えは知っている。でも、答えに至る道筋が見えない。観る力はどこで育つのでしょうか。自分で構造を発見する経験の中です。AIがその経験を奪います。型を飛ばすと、なぜ応用できないのでしょうか。型は「基盤となる最も基本的なもの」です。基盤がないと、その上に何も建てられません。AIが型を代替してくれると、基盤が自分の中にない。だから、少し変わった状況に対応できないのです。学習はなぜ循環構造なのでしょうか。「空」に達しても、また「遊」に戻ります。新しい領域を学ぶとき、再び遊びから始まる。この循環が止まらない限り、人は成長し続けます。AIが「遊」を奪うと、循環そのものが止まります。「心」と「空」は、そもそも到達しにくくなります。基盤となる「遊」と「観」が欠けているからです。本質を掴むには、周辺を十分に探索している必要があります。無意識に動けるようになるには、意識的に何度も繰り返した経験が必要です。AIは上層を加速しますが、基盤を掘り崩します。思い返せば、私が一番成長したのは「遊んでいた」時期でした。学生時代、深夜にLinuxをいじっていました。「このコマンドに変なオプションを渡したらどうなるんだろう」と試した。システムが壊れた。復旧に3時間かかった。でも、その3時間でファイルシステムの構造を理解しました。教科書を読むより、壊して直す方がずっと早く学べました。社会人になってからも、余裕があるときは遊んでいました。「この機能、公式ドキュメントにはこう書いてあるけど、本当にそうなのか」と検証した。ドキュメントが間違っていることもありました。公式が想定していないパターンを見つけることもありました。遊びは、ドキュメントの外側を教えてくれました。今はどうでしょうか。遊ぶ暇があったら、次のタスクをAIに投げています。効率的です。生産的です。でも、技術との「雑談」がなくなりました。目的のない探索がなくなりました。効率を追求した結果、学習の肥沃な土壌を捨てていたのです。遊びがないと、表面的な理解で終わります。ドキュメントに書いてあることは知っている。でも、書いていないことは知らない。想定外の状況に遭遇したとき、対処できません。遊んでいないから、技術の「手触り」がわからないのです。ここまで、学習の5段階と、AIがそれをどう壊すかを説明しました。問題は見えました。では、どうすればいいのでしょうか。答えは単純です。何がわかっていないのかを、見えるようにする。何が欠けているのか。どこで躓いているのか。それを捕まえる。見えれば、対策が打てます。学習の段階で言えば、自分が「遊」で止まっているのか、「型」が足りないのか、「観」ができていないのか。それを知る必要がある。しかし、AIと効率的に働いていると、自分がどこで止まっているかすら見えない。見えないものは改善できない。だから、見えるようにする仕組みが必要だ。そこで私は、先に触れた日報を本格的に活用することにしました。1週間続けて、衝撃を受けました。自分がこんなにも理解していなかったのか。金曜の夜、その週の日報を見返した。「わからない」と書いた項目を数えてみようと思った。月曜の分から順番に。1、2、3... 10を超えたあたりで、手が止まった。まだ火曜だった。水曜、木曜、金曜と続く。「なぜ」がわからないもの、「本質」が見えないもの。多すぎた。画面を見つめながら、胃のあたりがざわついた。正直、途中で数えるのをやめた。自分は理解の入口にすら立っていなかった。しばらく、椅子に座ったまま動けなかった。これが自分の実力なのか。毎日コードを書いて、PRをマージして、それなりにやっているつもりだった。でも、蓋を開けてみれば、理解の穴だらけだった。恥ずかしさ、情けなさ、少しの怒り。それらの混ざった感情が胸に込み上げてきた。でも、その夜、不思議と眠れた。これは希望でもあったからだ。自分の現状を捕まえさえすれば、次に進める。見えない敵は怖いが、見える敵は対策できる。何より、問題が見えた。見えないまま衰えていくより、ずっといい。だから、日報について詳しく説明したい。なぜ日報が効くのか。どう書けばいいのか。日報がなぜ「記録」以上の意味を持つのか。それを理解するには、日報が何を可視化しているかを知る必要がある。日報は単なるログではない。曖昧さを捕まえるためのセンサーだ。書くことは、なぜ理解を深めるのか。AIと働いていると、違和感は一瞬で消える。「なんかわからないな」と思った次の瞬間、AIに聞いている。違和感を感じている時間がない。日報に「なぜ:」と書こうとすると、その違和感を言語化しなければならない。「何がわからないのか」を言葉にする。この言語化のプロセスで、曖昧だった問題が明確になる。書くことは、理解を深める。なぜなら、書けないことは理解していないことだからだ。その場で書くことに意味はあるのか。ある。学習の起点は「わからなかった点」にある。しかし、「わからなかった」という感覚は、時間とともに薄れる。翌日には忘れている。1週間後には、何がわからなかったかすら思い出せない。日報は、躓きを時間差で消えない形に固定する。その場で書かないと、学習の種が消える。日報は何を可視化しているのか。自分が何をわかっていて、何をわかっていないか。どこで繰り返し躓いているか。どのパターンが苦手か。可視化されて初めて、対策が可能になる。見えないものは改善できない。日報は、見えないものを見えるようにする。なぜ「躓き」が重要なのか。躓きは、成長の種だ。スムーズにできたことからは、何も学べない。躓いたところに、学びがある。日報は、躓きを収集するシステムだ。躓きを記録し、パターンを見つけ、対策を打つ。このサイクルが学習を生む。日報がないと何が起きるのか。躓きが流れていく。同じところで何度も躓く。でも、躓いていることに気づかない。気づかないから、対策も打てない。日報がない状態は、センサーのない飛行だ。どこに向かっているかわからない。何が起きているかわからない。墜落してから、問題に気づく。では、日報には何を書けばいいのか。私がよく使うのは「なぜ:」と「試した:」だ。「なぜ:」——理由がわからなかったことを記録する。「なぜ: この実装パターンを選んだ理由」。表面的な理解で終わらせない。「試した:」——目的のない探索を記録する。「試した: このライブラリ、何ができるんだろう。ドキュメントを読まずに動かしてみた」。好奇心が動いた瞬間を残す。キーワードは自分で決めればいい。「写経:」「本質:」「ハマった:」など、必要に応じて増やせばいい。大事なのは、何がわからなかったかを捕まえること。記録することで、自分の躓きパターンが見えてくる。以前は、労働の中で自然と学んでいた。困難にぶつかり、格闘し、乗り越える。そのプロセスが、理解を深めてくれた。今は違う。AIが困難を消してくれるから、格闘する機会がない。だから、意識的に躓きを記録し、学習の種類を分類する必要がある。日報は、そのための道具だ。ここまでは日報の「考え方」を説明した。では、具体的にどう実装するのか。私はClaude Codeのカスタムslash commandsで日報システムを作った。詳しい実装は以前の記事に書いた。syu-m-5151.hatenablog.comClaude Codeには強力なカスタマイズ機能がある。CLAUDE.mdというMarkdownファイルをプロジェクトルートや~/.claude/に置くと、AIがそれを読み込んで動作を調整する。コーディング規約、プロジェクト固有のルール、よく使うパターンなどを書いておけば、AIがそれを参照しながら作業してくれる。また、~/.claude/commands/にMarkdownファイルを置くと、カスタムslash commandsとして使える。/nippo-addと打てば、日報追加用のプロンプトが実行される。AIを「自分専用の道具」に育てる仕組みだ。私の日報システムは3つのコマンドで構成される。/nippo-add - 作業中にその場で記録する。Issue番号や感情も一緒に書く。後から検索しやすくなる。/nippo-finalize - 1日の終わりに実行。散らばった記録をAIが整理して、読みやすい日報に仕上げる。/nippo-show - 日次・週次のサマリーを表示。繰り返し躓いているパターンを可視化する。コマンドファイルは ~/.claude/commands/ に置く。プロジェクトをまたいで使える。CLAUDE.mdにはプロジェクトの文脈を、commands/には繰り返し使う操作を。この2つで、AIは「汎用ツール」から「自分の相棒」に変わる。/nippo-add #456 JWTの検証ロジック実装開始/nippo-add #456 AIが書いたコード動いた。でもなぜRS256なのかわからない/nippo-add なぜ: RS256とHS256の違い/nippo-add 試した: JWTのペイロードに変なデータを入れたらどうなるかポイントは作業中に記録すること。1日の終わりにまとめて書こうとすると、何をやったか思い出せない。その場で書けば、摩擦がない。「なぜ:」「試した:」などのキーワードを入れておけば、後から抽出しやすい。自分がどこで躓いているか、一目でわかる。キーワードは何でもいい。「ハマった:」「理由:」でも、英語で「why:」でも構わない。大事なのは、自分が後から検索しやすく、学習のパターンを把握できること。正解はない。自分にしっくりくる言葉を見つければいい。日報を見返すと、同じ技術で同じ種類の躓きが繰り返されている。非同期処理では「なぜ」がわからない。エラーハンドリングでは「本質」が見えない。新しいライブラリでは「試した」が足りない。繰り返し出てくるということは、その部分で理解が止まっているということだ。弱点が見える。弱点が見えれば、対策が打てる。日報は、学習のガイドになった。日報のキーワードが学習のトリガーここまで、日報を使って躓きを「記録する」方法を説明した。しかし、記録しただけでは学習は起きない。記録は入口に過ぎない。日報に「なぜ:」「試した:」と書いたら、それは学習のトリガーだ。記録して終わりではない。そのまま次に進まない。徹底的にAIと対話する。なぜ「対話する」なのか。ここが重要だ。キーワードで記録した躓きは、「わかっていない」ということだ。わかっていないことを、わかるようにするには、どうすればいいか。自分で調べてもいい。でも、AIがいる。AIは、わからないことを説明してくれる。問題は、AIの説明を受動的に聞くか、能動的に引き出すか、だ。私のルールは単純だ。これらのキーワードを書いたら、その場で最低10分はAIと対話する。10分で理解できなければ、20分かける。理解できるまでやる。次のタスクには進まない。ただ、ここで重要な反論がある。「10分で理解できるわけがない」という反論だ。確かにそうだ。複雑な概念を10分で完全に理解するのは無理がある。でも、重要なのは「10分という制約を設けること」自体にある。制約があるから、「本当にわからないこと」だけに集中できる。制約がなければ、際限なく調べ続けて、結局何も身につかない。では、具体的にどう「徹底的に対話する」のか。ここが最も重要なところだ。「AIと対話する」と言っても、やり方次第で効果は天と地ほど違う。徹底的に対話する技術「AIと対話する」とは具体的にどういうことか。まず、よくある間違いから見てみよう。AIに「答えをもらう」ことと、AIと「徹底的に対話する」ことは、本質的に違う。答えは受動。対話は能動だ。答えをもらう：「このエラーを直して」→ 直るコードが返ってくる → 動く → 終わり。人間側の思考は、ほぼゼロだ。問題を投げて、解決策を受け取る。コピペする。動く。何も考えていない。徹底的に対話する：「このエラーの原因は何？」→「なぜそうなる？」→「他にも同じパターンはある？」→「どう防げる？」。人間側に思考が発生する。質問を組み立てる段階で、自分が何をわかっていないか考える。答えを聞いて、次の質問を考える。このサイクル全体で、脳が動いている。なぜ「教えて」では足りないのか。「教えて」は丸投げだ。AIは何かを返す。でも、それがあなたに必要な説明かどうかわからない。あなたが何を知っていて、何を知らないか、AIには見えない。だから、的外れな説明が返ってくることもある。説明を引き出す側に何が求められるか。自分の理解の輪郭を先に差し出すことだ。「私はここまでわかっている。でも、ここからがわからない」。この輪郭を示すことで、AIは適切な説明を返せる。そして、輪郭を示す行為自体が、すでに学習だ。自分が何をわかっていないか言語化する。これは思考を整理する作業だ。説明を引き出す行為は、どの段階で人間側の思考を必要とするか。最初から最後までだ。何を聞くか考える。聞いた答えを解釈する。次に何を聞くか決める。答えを自分の文脈に当てはめる。このすべてが、能動的な思考だ。答えをもらうだけなら、受動的でいい。説明を引き出すには、能動的でなければならない。なぜ「自分の言葉で書き直す」ことが理解の判定基準になるのか。AIの言葉をそのまま使えるなら、理解していなくてもコピペできる。自分の言葉に置き換えるには、一度、頭の中で「翻訳」する必要がある。翻訳には理解が必要だ。書き直せない説明は、理解ではない。説明できるとはどういう状態か。因果を辿れる状態だ。「なぜこうなるか」を自分の言葉で説明できる。別の人に質問されても、答えられる。説明できるようになって初めて、その知識は「使える」ようになる。この違いは学習速度にどう影響するか。答えをもらい続けると、学習速度はゼロに近づく。説明を引き出し続けると、学習速度は加速する。同じAIを使っても、使い方で学習効果は天と地ほど違う。最初は恥ずかしかった。「こんな基本的なことも知らないのか」と思われるのが怖かった。でも、AIは笑わない。何度聞いても呆れない。AIは、最高の学習パートナーだ。この発見が、学び方を変えた。ステップ1: 自分の理解を言語化するいきなり「教えて」と聞かない。まず自分が何をわかっていて、何がわからないかを言語化する。RS256とHS256について、私の現在の理解を確認させて。私の理解：- 両方ともJWTの署名アルゴリズム- HS256は「対称鍵」を使う（たぶん）- RS256は「非対称鍵」を使う（たぶん）わからないこと：- なぜRS256の方が「セキュア」と言われるのか- どういう場面でどちらを選ぶべきかこの理解は合ってる？こうすることで、AIは私の理解レベルに合わせた説明をしてくれる。輪郭を示す行為自体が、すでに学習だ。ステップ2: 「なぜ」を3回以上繰り返す表面的な理解で終わらせない。本質に到達するまで「なぜ」を繰り返す。なぜJWTの署名にRS256を使うの？→ 「秘密鍵と公開鍵を分離できるから」なぜ分離する必要があるの？→ 「検証側に秘密鍵を渡さなくて済むから」なぜ検証側に秘密鍵を渡すとまずいの？→ 「サービスが増えると秘密鍵を知る場所が増える。1箇所でも漏洩したら全体が危険になる」3回目の「なぜ」あたりから、本質的な理解が始まる。ここで「逆に、HS256を使うべきケースは？」「RS256のデメリットは？」と逆のケースも聞く。正解だけでなく不正解を知ることで、判断基準が明確になる。ステップ3: 自分の言葉で要約するここまで理解したら、AIの説明をコピペせず、自分の言葉で要約する。/nippo-add 振り返り: RS256 vs HS256 を理解した【本質】- HS256 = 共通鍵。署名も検証も同じ秘密を使う- RS256 = 公開鍵暗号。検証側に秘密を渡さなくて済む【使い分け】- モノリス → HS256で十分- マイクロサービス → RS256一択書き直せなかったら、まだ理解していない。もう一度ステップ1から繰り返す。復習のサイクルここまでで、2つのことを説明した。日報で躓きを記録すること。そして、その躓きについてAIと徹底的に対話すること。記録と対話。この2つで、学習は起きるはずだ。でも、実際にやってみると、これだけでは足りなかった。理解しても、忘れる。日報を書いた。AIと対話した。その場では理解した。「ああ、そういうことか」と納得した。でも1週間後、同じことでまた躓いている。「あれ、これ前にも調べなかったか？」。書いただけでは、脳に定着しない。同じ内容を間隔をあけて復習すると、記憶に残りやすい。だから復習のサイクルを作った。翌朝（5分）：前日の日報を見返す。見返すだけでいい。「ああ、これ昨日引っかかったやつだ」と思い出す。思い出す行為自体が、記憶を強化する。実際にやってみると、面白いことが起きた。朝、コーヒーを淹れながら昨日の日報を開く。「RS256とHS256の違い」という項目を見る。「えーと、RS256は公開鍵暗号で...」と頭の中で再生しようとする。すると、昨日は理解したはずなのに、もう曖昧になっている部分がある。忘れかけているタイミングで思い出すことが、記憶を強化する。これを毎朝やるだけで、定着率が全然違う。週末（30分）：その週の日報をまとめて確認。2回以上出てきた項目は、その場でAIと対話して理解を深める。理解できたらチェックを入れる。ある週末、日報を見返していて気づいた。「非同期処理」という項目が、月曜、水曜、金曜と3回出てきている。3回も「なぜ」がわからないと書いているのに、そのたびに次のタスクに進んでいた。繰り返し出てくるということは、その部分の理解が止まっているということだ。その週末、2時間かけてPromiseとasync/awaitを徹底的に理解した。翌週から、非同期処理で詰まることがなくなった。月末（1時間）：月間の傾向分析。3回以上出てきた項目は、根本的な知識の穴だ。書籍を買って体系的に学ぶ。月末の分析で、自分の弱点のパターンが見えてきた。私の場合、「認証・認可」「データベースの最適化」「インフラ周り」が繰り返し出てくる。これは断片的な理解では対応できない。体系的に学ぶ必要がある。だから、月末に1冊ずつ関連書籍を買うことにした。日報は、次に買うべき本を教えてくれる。学んだことは、忘れる。これは避けられない。忘却は敵ではない。思い出せないことが敵だ。日報は「思い出すためのフック」を作る作業だ。完璧に覚えようとしなくていい。戻れる仕組みを作ればいい。人間は意志を保てない。「毎日復習しよう」と決めても、忙しくなれば忘れる。だから仕組みを作る。日報システムは、学習の意志を外部化したものだ。意志に頼らず、習慣に組み込む。学習時間の設計ここまで、日報の書き方、AIとの対話の仕方、復習のサイクルを説明した。方法論は揃った。しかし、ここで当然の疑問が浮かぶ。「いつやるのか？」だ。日報を書く。復習する。わからないことはAIと対話する。週末にまとめて振り返る。どれも時間がかかる。全部やるのは大変そうだ。正直、私もそう思った。会社によっては、学習時間を労働時間としてカウントしてくれるところもある。成果を出すタイミングと学習するタイミングが違っても、それを認めてくれる環境もある。もしそういう会社にいるなら、堂々と労働時間内で学習すればいい。ただ、認めなければならない現実がある。成果を出す時間と、学習する時間は、同時には起きにくくなった。かつて労働は最高の学習だった。しかし今は違う。AIと協働する効率化されたプロセスの中では、学習に必要な「摩擦」が発生しない。タスクは完了する。成果物は出る。それでも、脳には何も残らない。効率の代償は、成長だった。これは構造的な問題だ。だから私は、一度分けることにした。成果を出す時間と学習する時間を、意識的に。成果を出す時間は、AIと一緒に効率よくタスクを消化する。学習する時間は、AIなしで、あるいはAIと徹底的に対話しながら、理解を深める。分けた上で、日報で再接続する。私の1週間はこうなっている。月曜 6:00-6:30：先週の日報を見返す。躓いている項目の中で、今週取り組むべきものを3つ選ぶ。カレンダーに学習時間をブロックする。「今週はこの3つを理解すれば、来週の開発が楽になるはず」。仮説を立て、検証し、修正する。学習も開発と同じだ。水曜 12:00-12:30：昼休みを使って、月曜に選んだ項目を深掘りする。わからないことをAIに問いかけ、徹底的に対話する時間だ。金曜 6:30-8:30：「素手の時間」。AIなしでコードを書く。「AIがあるのに使わないのは非効率だ」という反論があるだろう。確かに、短期的には非効率だ。でも、AIと働き続けていると、基礎力が衰える。使わない筋肉は、静かに萎える。基礎がわかっていれば、AIの出力を評価できる。基礎が怪しければ、動くまでガチャを回すだけになる。この時間にやることは3つある。日報で見つけた躓きをAIなしで調べる。小さなユーティリティ関数を手書きする。エラーメッセージを自力で読み解く。AIに聞けば5分で済むことを、30分かけてやる。この30分が、理解の深さを変える。最初の金曜日、2時間が永遠に感じた。簡単なはずの処理が書けない。「こんなことも自分でできないのか」と、情けなくなった。でも、2時間が終わったとき、達成感があった。自分の手で書いた。久しぶりの感覚だった。AIなしで書いてみると、「本当にわかっていること」と「AIに頼っていたこと」の境界が明確になる。自分の実力が、残酷なほど見える。見えるからこそ、対策が打てる。土曜 朝30分：週の振り返り。3つの項目は理解できたか。理解できなかったものは、来週に持ち越す。完璧を求めない。7割理解できれば、次に進む。最初は週3時間も取れないと思った。でも、試してみると、この3時間で週の残り37時間の労働効率が上がった。学習は消費ではない。複利で回収できる投資だ。理解が深まると、AIへの指示が的確になる。学習への投資は、労働の効率で回収できる。私の場合、成果を出すことと学ぶことが自然には重ならなくなった。だから意識的に交差点を作っている。日報が教えてくれる「次に学ぶべきこと」ここまで、学習の「方法」を説明した。日報で記録する。わからないことはAIと対話して理解を深める。復習する。学習時間を確保する。これで「どう学ぶか」は揃った。しかし、「何を学ぶか」は、まだ説明していない。時間は限られている。何を優先すべきか。闇雲に学んでも、効率が悪い。答えは、日報の中にある。日報を続けていると、躓きのパターンが見えてくる。同じ項目が繰り返し出てくる。認証。非同期処理。データベース。繰り返し出てくるということは、断片的な理解では足りないということだ。そこで、日報をインプットのガイドにする。月末に日報を見返して、3回以上出てきた項目を特定する。それに関連する学習リソースを選ぶ。日報は「次に何を学ぶべきか」を教えてくれる。私の場合、月に技術書を10冊、非技術書を10冊、合わせて20冊前後読んでいる。しかし、これは極端な例だ。最初は月1冊でも十分効果がある。大事なのは冊数ではなく、日報で見つけた躓きに関連する本を選ぶことだ。書籍の良いところは、最低限のクオリティが担保されていることだ。最高のブログは刺さる。でも、最低のブログを引くこともある。書籍は編集者の目を通っている。時間は有限だから、ハズレを引きたくない。日報で繰り返し出てくる躓きを見て、関連する技術書を選ぶ。書籍だけではない。公式ドキュメントやRFC、OSSのソースコードも読む。二次情報で満足せず、一次情報に戻る習慣。これが理解の深さを決める。使っているライブラリの実装を見ると、設計判断の理由がわかる。上級者向けだが、他社の障害報告書も参考になる。ポッドキャストも意外と効く。特にリモートワーカーにおすすめしたい。ちゃんと聞かなくていい。BGMのように流しておくだけでいい。リモートワークを続けていると、雑談が絶望的に下手になる。下手になると、雑談をしたくなくなる。したくなくなると、技術的なことを気軽に話す機会が減る。機会が減ると、間違った理解を指摘してもらえなくなる。悪循環だ。技術系ポッドキャストを聞いていると、エンジニア同士の会話のリズムが耳に残る。話題の引き出しも増える。Xで信用できるアカウントをフォローしておくのもいい。タイムラインを眺めているだけで、今何が話題になっているかがわかる。しかし、Xは使い方が難しい。今やアテンション・エコノミーのど真ん中で、みんなが揉めている。情報収集のつもりが、気づいたら論争を眺めて時間を溶かしていることがある。意識的に距離を取る必要がある。AIに聞けば答えは返ってくる。でも、体系的な理解は書籍や公式ドキュメントでないと得られない。AIは「この問題の解決策」を教えてくれる。書籍は「なぜその解決策が正しいか」を教えてくれる。AIとの協働で生まれた躓きを、AIの外で埋める。あなたの現在地を見つけるためにここまで、私がやってきたことを説明した。日報で躓きを記録する。AIと徹底的に対話する。復習のサイクルを回す。学習時間を確保する。日報から次に学ぶべきことを見つける。インプットを選ぶ。たくさんあるように見えるかもしれない。全部やる必要はない。でも、何かを始める必要はある。ここまで読んでくれたあなたに、問いかけたい。この1週間を振り返ってみてほしい。AIに聞いて解決したけど、なぜその解決策が正しいのか説明できない問題はなかっただろうか。同じ種類の問題に、何度も遭遇していないだろうか。コードは動いた。でも「なぜ動くのか」を同僚に説明できるだろうか。もし1つでも「怪しい」と感じるものがあれば、それがあなたの躓きだ。今日から日報に書き始めてほしい。日報を1週間続けたら、見返してみてほしい。何が繰り返し出てくるか。認証なのか、非同期処理なのか、データベースなのか。繰り返し出てくるものが、次に学ぶべきことだ。そのとき、インプットを意識的に選んでほしい。体系的に理解したいなら書籍。正確な仕様や実装の判断基準を知りたいなら公式ドキュメントやOSSのソースコード。リモートワーカーならポッドキャストもいい。Xで信用できるアカウントをフォローしておくのも悪くない。日報が「次に何を学ぶべきか」を教えてくれる。インプットは、日報を見て選ぶ。AIに聞けば答えは返ってくる。でも、「なぜその答えが正しいか」を理解するのは、AIの外でやる仕事だ。日報は、その仕事を始める場所を教えてくれる。おわりにここまで、私がやってきたことをすべて説明した。日報、AIとの対話の技術、復習のサイクル、学習時間の設計、インプットの選び方。これらは、私がAI時代に「学ぶ」ために見つけた方法だ。最後に、1つだけ伝えたいことがある。この記事で一番大事なことだ。ここまで読んで、気づいた人もいるだろう。私はCLAUDE.mdに学びを書き込んでいる。プロジェクトの文脈、コーディング規約、過去に得た知見。では、AIは賢くなっているのか。答えはNoだ。AIは何も学んでいない。CLAUDE.mdに書かれた内容は、セッションの最初に読み込まれる。でも、それは「学習」ではない。ただの「入力」だ。AIは前回の会話を覚えていない。経験を蓄積しない。「わからない」を経験しない。AIは、このブログが警告している「学ばない労働者」そのものだ。CLAUDE.mdを充実させれば、AIの出力は変わる。使い込むほど手に馴染む道具にはなる。でも、設定を書いたのは誰か。あなただ。試行錯誤したのは誰か。あなただ。AIが賢くなったように見えるのは、あなたが賢くなったからだ。学習とは、経験を意味に変換する行為だ。これが、この記事を通じて私がたどり着いた核心だ。AIは情報を処理できる。でも、AIにとってそれは「意味」を持たない。人間は違う。経験が意味になる。「あのバグを直した」という経験が、「自分はできる」という自信になる。経験を意味に変換できるのは、人間だけだ。AIと協働しながらも、熟達する主体であり続けるために必要な設計がある。遊びの時間を確保すること。目的のない探索がないと、好奇心が死ぬ。「わからない」状態を意図的に作ること。AIに聞けばすぐわかる。でも、あえて聞かない時間が思考力を維持する。記録を習慣にすること。書かないと忘れる。説明を練習すること。説明できなければ、理解していない。「素手」で戦う時間を持つこと。AIなしでコードを書く時間が、基礎力を維持する。これらに共通するのは、摩擦・記録・言語化だ。摩擦が経験を生む。記録が経験を残す。言語化が経験を意味に変える。AIはこの3つを肩代わりしてくれる。だから楽になる。でも、肩代わりさせると、人間は主体でなくなる。最後に、もう一度聞かせてほしい。あなたは最近、「成長している」と感じているだろうか。もし少しでも不安があるなら、今日から日報を開いてみてほしい。「なぜ:」「試した:」と書いてみてほしい。たった1行、それだけでいい。完璧な日報を書く必要はない。その不完全な1行が、次の1行を呼ぶ。そして、その積み重ねがあなたの脳を取り戻す。3日で挫折するだろう。私自身、何度も挫折した。でも、4日目にまた始めればいい。何度でもやり直せる。完璧に続けることより、何度でも再開できることの方が大事だ。1ヶ月後、あなたは変わっている。同僚に「この実装、どうしてこうしたの？」と聞かれたとき、淀みなく答えられる自分がいる。障害が起きたとき、自分のコードを頭の中でトレースできる自分がいる。日報を見返すと、「なぜ:」で埋まっていた項目が、少しずつ減っている。それが、成長の証だ。あなたの脳は、取り戻せる。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考書籍知性の未来―脳はいかに進化し、AIは何を変えるのか―作者:マックス・ベネット新潮社AmazonPLURALITY　対立を創造に変える、協働テクノロジーと民主主義の未来（サイボウズ式ブックス）作者:オードリー・タン,E・グレン・ワイルライツ社Amazon奪われた集中力: もう一度〝じっくり〟考えるための方法作者:ヨハン・ハリ作品社Amazon熟達論―人はいつまでも学び、成長できる―作者:為末大新潮社Amazon学びとは何か－〈探究人〉になるために (岩波新書)作者:今井 むつみ岩波書店Amazon学びをやめない生き方入門作者:中原淳,パーソル総合研究所,ベネッセ教育総合研究所テオリアAmazon私たちはどう学んでいるのか: 創発から見る認知の変化 (ちくまプリマー新書 403)作者:鈴木 宏昭筑摩書房Amazonシン読解力―学力と人生を決めるもうひとつの読み方作者:新井 紀子東洋経済新報社Amazon夏蜜柑とソクラテス作者:新井 紀子草思社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[最近読んでいて興味深かった記事紹介 Vol.4]]></title>
            <link>https://zenn.dev/akasan/articles/interesting_tech_blog_4</link>
            <guid isPermaLink="false">https://zenn.dev/akasan/articles/interesting_tech_blog_4</guid>
            <pubDate>Tue, 16 Dec 2025 13:14:53 GMT</pubDate>
            <content:encoded><![CDATA[今回で4回目の、最近読んで気になっている記事紹介になります！年末に向けて色々読んでいきたいので、最近見たものを紹介できればと思います！過去の記事は以下に載っていますので、ご興味ある方は是非ご覧ください。https://zenn.dev/akasan/scraps/97b063540d2372 Docker MCP Gateway:エージェントAIのためのオープンソースの安全なインフラストラクチャ私自身あまりMCPを利用できていないのが現状なのですが、dockerを利用してMCPをうまく運用するための方法をキャッチアップするために見ています！https://www.docker...]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[地球規模の「時間のずれ」を Cloud Spanner はどう解決したか]]></title>
            <link>https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</link>
            <guid isPermaLink="false">https://sreake.com/blog/how-cloud-spanner-deal-with-large-scale-time-diff/</guid>
            <pubDate>Tue, 16 Dec 2025 01:39:59 GMT</pubDate>
            <content:encoded><![CDATA[はじめに Sreake 事業部の芳賀雅樹 (@silasolla) です．普段はアプリケーションの開発支援を担当していますが，今回はその基盤となるデータベースの裏側の仕組みが気になり，深掘りしてみました． 早速ですが，G […]The post 地球規模の「時間のずれ」を Cloud Spanner はどう解決したか first appeared on sreake.com | 株式会社スリーシェイク.]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[AI時代の異常系テストについて考える]]></title>
            <link>https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</link>
            <guid isPermaLink="false">https://syu-m-5151.hatenablog.com/entry/2025/12/16/102227</guid>
            <pubDate>Tue, 16 Dec 2025 01:22:27 GMT</pubDate>
            <content:encoded><![CDATA[はじめに深夜2時、本番環境のアラートが鳴り響きます。外部APIがタイムアウトを返し始め、リトライが暴発し、システム全体が連鎖的に停止しました。原因を調べると、外部サービスの一時的な遅延でした。たった数秒の遅延が、なぜシステム全体を止めたのか。答えは単純です。「外部APIが遅延したらどうなるか」を、誰もテストしていなかったからです。私自身、このような障害を何度か経験してきました。コードをマージした翌朝にSlackが炎上していたこともあります。「なぜこのケースを考えなかったのか」と自分を責めながら、ホットフィックスを書いた夜もあります。そのたびに思います。あのとき、たった1つのテストを書いていれば。これは「異常系テスト」の不足が引き起こした障害です。正常系のテストは比較的書きやすいです。入力があり、期待する出力があり、それを検証します。しかし、プロダクション環境で本当に問題になるのは異常系です。ネットワークが切断されたとき、システムはどう振る舞うべきか。データベースがタイムアウトしたとき、ユーザーには何を伝えるべきか。想定外の入力が来たとき、エラーメッセージは適切か。こうした問いに答えるのが、異常系テストです。そして今、この異常系テストの世界が大きく変わりつつあります。2024年、AIがOpenSSLに20年間潜伏していた脆弱性を発見しました。人間が書いたファジング（ランダムなデータを入力してバグを探す手法）では見つけられなかった欠陥です。Google OSS-FuzzはAIによるファズターゲット生成で26件の脆弱性を発見し、既存の人間作成ターゲットから最大29%のカバレッジ向上を実現しました。人間だけでは見つけられなかった異常を、AIが発見する時代になりました。本記事では、この変化を踏まえて異常系テストの考え方をまとめました。まず基本的な技法を押さえ、その上でAIやカオスエンジニアリングといったものを紹介します。あの深夜のアラートを、未来の自分や読者が経験しなくて済むように。本題に入る前に本記事を読む前に、いくつか断っておきたいことがあります。私はテストの専門家ではありません。日々コードを書きながら、「この処理が失敗したらどうなるだろう」と考える、一人のエンジニアです。ここに書いてあることは、思いついたものをまとめただけなので不足もあるでしょう。実装しながら単体テストやエラーハンドリングを考える際のヒントとして使ってもらえればと思います。もう一つ、大事なことがあります。すべてのパターンをテストする必要はありません。過度なテストパターンは無駄な工数を生むだけではありません。テストが増えれば増えるほどCIの実行時間は長くなり、開発サイクルは遅くなります。テストコードを読んで理解するにも認知コストがかかります。テストが多すぎると、「このテストは何を確認しているのか」を把握するだけで疲弊してしまいます。テストのROI（投資対効果）を意識し、リスクの高い箇所に集中することが重要です。とはいえ、最近は生成AIのモデル精度が上がったおかげで、文脈を読み取ってテストコードを生成してくれるようになりました。「何をテストすべきか」を判断し、AIに生成を任せる。その使い分けが、今のエンジニアに求められています。そして、ここが難しいところなのですが、異常系テストがどれくらい必要かは、その人の経験に大きく依存します。本番障害で痛い目を見た人は「ここまでテストすべきだ」と感じます。幸運にも大きな障害を経験していない人は「そこまでやる必要があるのか」と思います。これは良い悪いではなく、思考の枠組みそのものが異なるのです。だからこそ、チームとして、組織として「どこまでの異常を許容するのか」を明確にしておく必要があります。暗黙の了解ではなく、言語化する。そうしないと、「テストが多すぎる」「テストが足りない」という不毛な議論が続くことになります。では、本題に入りましょう。異常系テストとは異常系テストとは、システムが想定外の状況に遭遇したとき、適切にエラーハンドリングできるかを検証するテストです。正常系テストが「うまくいくパス」を確認するのに対し、異常系テストは「うまくいかないパス」を確認します。異常系と一口に言っても、その原因はさまざまです。「どこから異常が来るか」という視点で整理すると、4つの観点に分けられます。入力値の異常: ユーザーやクライアントから来ます。空文字、境界値超過、不正な形式など状態の異常: システム内部のデータに起因します。リソースが見つからない、すでに処理済み、権限不足など環境の異常: 外部依存に起因します。ネットワーク障害、DB接続失敗、ディスク容量不足など競合の異常: 並行処理に起因します。同時更新、デッドロック、レースコンディションなどこの順番には意味があります。入力値の異常は最も頻繁に発生し、テストも書きやすいです。状態の異常はビジネスロジックと密接に関わります。環境の異常はテストが難しいですが、本番では必ず起きます。競合の異常は最も見つけにくく、再現も難しいです。つまり、テストの書きやすさと、問題の発見しにくさは、おおむね逆の関係にあります。それぞれについて見ていきましょう。入力値の異常フォームに全角スペースだけを入力して送信したら、システムがエラーを吐いた。そんな経験はないでしょうか。あるいは、絵文字を含む名前を登録しようとしたら、データベースエラーが返ってきた。ユーザーは悪意を持っていたわけではありません。ただ、開発者が「想定していなかった」だけです。どれだけ想像力を働かせても、ユーザーは必ずその想像の外側から来ます。ユーザーからの入力は信用できません。これはセキュリティの基本原則ですが、テストにおいても同様です。境界値分析（Boundary Value Analysis）境界値分析は、ソフトウェアテストの古典的な技法です。入力値の境界付近でエラーが発生しやすいという経験則に基づいています。# 例: 文字数制限が255文字の場合- 255文字 → 成功するべき- 256文字 → エラーになるべき- 0文字（空文字） → 要件によるよくある境界値のテストケース：最大値・最小値最大値+1・最小値-1ゼロ負の値（許可されていない場合）この技法は同値分割法（Equivalence Partitioning）と組み合わせて使うことが多いです。同値分割法では、入力値を「同じ振る舞いをするグループ」に分割し、各グループから代表値を選んでテストします。たとえば「1〜255文字」「256文字以上」「0文字」の3グループに分け、それぞれの代表値と境界値をテストします。現代のAPI開発では、境界値分析の対象は数値入力を超えて拡張されています。APIのページネーション制限（page size=99, 100, 101）、リクエストペイロードサイズ制限、タイムアウト閾値、レートリミットの境界などが現代的なBVA対象です。空値の扱い境界値の中でも、特に扱いが難しいのが「空」という概念です。空値の扱いは設計上の判断が必要になります。 値  検討ポイント  空文字 ""  許容するか、エラーにするか  スペースのみ "   "  トリムするか、エラーにするか  NULL  必須項目か、オプショナルか  undefined  デフォルト値を使うか テストを書くことで、こうした設計の曖昧さが明確になることがあります。「空文字を許容するか」という問いに対して、チームで合意を取る機会になります。ここで気づくべき重要なことがあります。異常系テストの気付きにくい価値は、バグを見つけることではありません。設計を問い直すことです。「この入力が来たらどうするか」という問いを立てることで、仕様の穴が見えます。テストを書く行為そのものが、システムの堅牢性を高めています。テストが通るかどうかは、実は二次的な問題なのです。文字種と特殊文字空値に続いて、もう一つ厄介なのが文字種です。日本語を扱うシステムでは、文字種のテストが特に重要になります。カタカナ・半角カタカナ環境依存文字（㈱、①など）サロゲートペア（𠮷野家の「𠮷」など）絵文字これらの文字が入力されたとき、システムがどう振る舞うかを確認します。データベースの文字コード設定やAPIのエンコーディングによっては、予期しない動作をすることがあります。セキュリティ関連の入力ここまでは「意図しない入力」の話でした。しかし、世の中には「意図的に悪意のある入力」を送りつけてくる人もいます。セキュリティ関連の入力値テストは、インジェクション攻撃（悪意のあるコードを入力に紛れ込ませる攻撃）への耐性を確認します。OWASP Testing Guideは、このようなセキュリティテストの標準的な指針を提供しています。XSS（クロスサイトスクリプティング）: <script>alert('XSS')</script> — Webページに悪意のあるスクリプトを埋め込む攻撃SQLインジェクション: '; DROP TABLE users;-- — データベースを不正に操作する攻撃コマンドインジェクション: ; rm -rf / — サーバーで不正なコマンドを実行させる攻撃パストラバーサル: ../../../etc/passwd — 本来アクセスできないファイルを読み取る攻撃インジェクション攻撃への対策はセキュリティテストの領域でもありますが、異常系テストとして「不正な入力が来たときにシステムが適切にエラーを返すか」を確認しておくことは重要です。エラー推測（Error Guessing）という経験ベースの技法も有効です。過去のバグ傾向から共通パターン（NullPointerException、ゼロ除算、日時パース問題など）を識別し、重点的にテストします。AIとファジングによる入力値テストここまで紹介した技法は、人間がテストケースを考えるものでした。しかし、人間の想像力には限界があります。そこで注目されているのが、ランダムな入力を自動生成してバグを探すファジング（Fuzzing）です。冒頭で触れたGoogle OSS-FuzzのAI活用は、まさにこの領域での成果です。AIが生成したファズターゲットにより26件の脆弱性が発見され、OpenSSLに20年間潜伏していた欠陥も見つかりました。人間が「こういう入力が来るかも」と想像する範囲を超えて、AIが異常な入力パターンを生成します。www.theregister.comもう一つ、Property-based testing（性質ベーステスト）という手法も企業での採用が加速しています。従来のテストは「入力Aに対して出力Bが返る」という具体的なペアを書きます。Property-based testingでは「どんな入力に対しても、この性質が成り立つ」という形で定義します。たとえば「リストをソートして逆順にしても、要素数は変わらない」といった性質です。Python向けのHypothesisは週間300万ダウンロードを超え、numpyやastropyなどの科学ライブラリでバグを発見した実績があります。QuickCheck（Haskell）、fast-check（JavaScript）、proptest（Rust）など、各言語でエコシステムが成熟しています。入力値の異常は、ユーザーから直接来るものでした。次に見るのは、システムの内部で起きる異常です。状態の異常「さっきまで動いていたのに」。この言葉に覚えはないでしょうか。ユーザーが画面を開いている間に、別のユーザーがデータを削除します。システムの状態は常に変化しています。画面に表示された瞬間、それはもう過去です。リソースの状態に関するテストでは、以下のようなケースを考慮します。存在しないリソース存在しないIDでアクセスしたときに、適切なエラー（404 Not Foundなど）が返ることを確認します。削除済みリソース削除されたリソースに再度アクセスしたときの動作を確認します。ユーザーがブックマークしていたページが、管理者によって削除されていた。よくある話です。「404 Not Found」で終わりなのか、「このコンテンツは削除されました」と丁寧に伝えるのか。論理削除と物理削除では挙動が異なります。論理削除なら「削除済み」というステータスを返せます。物理削除ならレコード自体が存在しないため、404を返すことになります。どちらの設計を採用しているかで、テストの期待値も変わります。処理中のリソース処理中（アップロード中、変換中など）のリソースにアクセスしたときの動作を確認します。「まだ準備ができていない」ことをクライアントに適切に伝えられるか。不正な状態遷移状態遷移が定義されているシステムでは、不正な遷移を試みたときの動作を確認します。# 例: 注文のステータス遷移作成 → 確定 → 発送 → 完了# 不正な遷移作成 → 完了（確定と発送をスキップ）完了 → 作成（逆方向の遷移）入力値の異常、状態の異常は、どちらもアプリケーション内部の話でした。しかし、システムは単独で動いているわけではありません。次は、システムの外側から来る異常を見ていきます。環境の異常環境の異常は、テストが最も難しい領域です。開発環境では再現しにくいですが、プロダクション環境では必ず発生します。ローカルで動いたからといって、本番で動く保証はありません。開発環境は、ある意味で嘘をつきます。ネットワークは常に安定し、データベースは常に応答し、ディスクは無限にあります。そんな理想的な環境でテストしても、現実の障害には備えられません。だからこそ、どういう異常が起こりうるかを知っておくことが重要です。近年ではChaos Engineering（カオスエンジニアリング）という手法が注目されています。Netflixが提唱したこのアプローチでは、本番環境に意図的に障害を注入し、システムの回復力を検証します。AWS Fault Injection ServiceやAzure Chaos Studioといったクラウドサービスも登場しています。これは上級者向けの手法ですが、まずは以下のような基本的な異常パターンを理解しておきましょう。ネットワーク障害通信経路の遮断タイムアウトオンライン→オフラインの遷移対応方法としては、タイムアウト設定、リトライ、サーキットブレーカーなどがあります。サーキットブレーカーとは、外部サービスへのリクエストが連続して失敗したとき、一時的にリクエストを遮断する仕組みです。電気のブレーカーが過電流を検知して回路を遮断するのと同じ発想で、障害の連鎖を防ぎます。データベース障害DB応答不可コネクションプール枯渇デッドロック対応方法としては、コネクションプールの適切な設定、リトライ、タイムアウトなどがあります。外部サービス障害API応答不可レートリミット予期しないレスポンス形式対応方法としては、サーキットブレーカー、フォールバック、キャッシュなどがあります。リソース枯渇ディスク容量不足メモリ不足ファイルディスクリプタ枯渇リソース枯渇は、テストで再現するより監視とアラートで早期に検知する方が現実的です。とはいえ、リソースが枯渇したときにシステムがどう振る舞うか（gracefulに停止するか、エラーメッセージを出すか）は、設計段階で決めておく必要があります。カオスエンジニアリングの実践「本番環境に障害を注入する？ 正気か？」。最初は誰もがそう思います。しかし、問いを変えてみましょう。「本番で障害が起きたとき、それが予期せぬものであることと、計画されたものであること、どちらがマシか？」カオスエンジニアリングの市場規模は2025年に23.6億ドル、2030年には35.1億ドルに達すると予測されています。もはやニッチな手法ではなく、エンタープライズ標準になりつつあります。www.mordorintelligence.comKubernetes環境ではLitmusChaosとChaos Meshが代表的なツールです。LitmusChaosはCNCFインキュベーティングプロジェクトとして活発に開発が続いています。Chaos MeshはPodChaos、NetworkChaos、IOChaos、StressChaosなど多様な障害タイプを提供します。hub.litmuschaos.ioGameDay（計画的なカオス実験演習）の実践も広がっています。まず最小の爆発半径（障害の影響範囲）から開始し、単一コンテナ→サービス→ゾーンと段階的にスケールアップします。本番環境を最初のターゲットにしてはなりません。レジリエンスパターン環境の異常に備えるには、コードにレジリエンスパターンを組み込む必要があります。先に紹介したサーキットブレーカーに加え、以下のパターンが重要です。Bulkhead（バルクヘッド）: 船の隔壁のように、リソースを区画化して一部の障害が全体に波及することを防ぎますRetry with Exponential Backoff（指数バックオフ付きリトライ）: 失敗したら1秒後、2秒後、4秒後…と間隔を広げてリトライします。リトライストームを防止しながら一時的障害から回復しますこれらのパターンを実装したら、カオスエンジニアリングで実際に障害を注入し、期待通りに動作するか検証します。パターンを実装しただけでは不十分で、テストして初めて信頼できます。ここまで、入力値、状態、環境の異常を見てきました。最後に残るのは、最も厄介な異常です。複数のユーザーが同時にシステムを使うときに起きる問題、競合の異常です。競合の異常「ローカルでは動いたのに」。開発者なら誰もが経験するこの言葉の裏には、しばしば競合の問題が潜んでいます。開発環境では自分一人しかアクセスしません。しかし本番環境では、何百人ものユーザーが同時にボタンを押します。本番は、常に渋滞しています。その渋滞の中で、単体テストでは見えなかった問題が姿を現します。複数のユーザーやプロセスが同時にリソースにアクセスすると、競合が発生しえます。これは単体テストでは見つけにくく、負荷テストや本番環境で初めて発覚することも多いです。だからこそ、「競合が起きたらどうなるか」を事前に設計しておくことが重要です。同時更新典型的なシナリオを考えてみましょう。1. ユーザーAがデータを取得2. ユーザーBが同じデータを取得3. ユーザーAが更新を実行4. ユーザーBが更新を実行 → どうなるべきか？ユーザーBの更新時点で、データはすでにユーザーAによって変更されています。このとき、システムはどう振る舞うべきでしょうか。主な対応方法は3つあります。楽観的ロック: データ取得時にバージョン番号を記録し、更新時に照合します。バージョンが変わっていれば「誰かが先に更新した」と判断し、後から更新しようとした側にエラーを返します悲観的ロック: 更新する意思を示した時点で排他ロックを取得し、他者は同じデータを更新できなくなります。確実ですが、ロック待ちによる遅延が発生しえます最後の更新が勝つ: 競合を検出せず、後から来た更新で上書きします。シンプルですが、先の更新は失われますどの方法を採用するかは、ビジネス要件によります。在庫数のように「先の更新が失われると困る」データには楽観的ロックか悲観的ロック、ユーザーのプロフィールのように「最新の状態が正」でよいデータには最後の更新が勝つ方式、といった使い分けになります。ボタン連打UIにおいて、ユーザーがボタンを連打した場合の動作を確認します。「送信ボタンを押したけど反応がない。もう一度押そう」。ユーザーは待ってくれません。ネットワークが遅いとき、ボタンが反応しないとき、人は本能的に連打します。「購入する」ボタンを連打したら2回購入されてしまった、という事故は避けたいところです。対応方法としては、デバウンス（一定時間内の連続クリックを1回とみなす）や、送信中はボタンを無効化する二重送信防止の仕組みがあります。サーバー側でも、同一リクエストを検出するためにリクエストIDを使った冪等性の担保を検討します。ここまで、4種類の異常（入力値、状態、環境、競合）を見てきました。これらの異常が発生したとき、システムは何らかのエラーを返す必要があります。では、どのようなエラーを返すべきでしょうか。次は、エラーレスポンスの設計について考えていきます。エラーレスポンスの設計異常系テストでは、「エラーが起きないこと」ではなく「適切なエラーが返ること」を検証します。エラーレスポンスの設計は、クライアント側のエラーハンドリングに大きく影響します。適切なエラーを返せば、呼び出し側は何が起きたかを判断し、適切に対処できます。ステータスコードの使い分けステータスコードとは、サーバーがクライアント（ブラウザやアプリ）に返す3桁の数字です。この数字を見れば、リクエストが成功したのか、失敗したのか、何が原因なのかが分かります。HTTPの場合：400 Bad Request: 入力値が不正401 Unauthorized: 認証失敗（ログインが必要）403 Forbidden: 権限不足（ログイン済みだがアクセス権がない）404 Not Found: リソースが存在しない409 Conflict: 競合（同時更新など）429 Too Many Requests: レートリミット（リクエストが多すぎる）500 Internal Server Error: サーバー内部エラー503 Service Unavailable: サービス利用不可（メンテナンス中など）gRPCの場合（gRPCはGoogleが開発した高速な通信方式）：INVALID_ARGUMENT: 入力値が不正NOT_FOUND: リソースが存在しないALREADY_EXISTS: リソースが既に存在FAILED_PRECONDITION: 前提条件不成立PERMISSION_DENIED: 権限不足RESOURCE_EXHAUSTED: リソース枯渇セキュリティ観点でのエラー設計他ユーザーのリソースへのアクセスには、エラーコードの選び方に注意が必要です。ここには、多くの開発者が見落としている盲点があります。素直に考えると、「存在するが権限がない」なら403 Forbiddenを返したくなります。HTTPの仕様としては正しいです。しかし、これには問題があります。攻撃者がIDを総当たりで試したとき、403が返れば「このIDのリソースは存在する」と分かってしまいます。つまり、正しいエラーコードを返すことが、セキュリティホールになるという逆説です。そこで、他ユーザーのリソースへのアクセスには404 Not Foundを返すという設計があります。「存在するが権限がない」と「存在しない」を区別できないようにすることで、攻撃者に情報を与えません。GitHubのプライベートリポジトリも、この設計を採用しています。権限のないリポジトリにアクセスすると、「存在しない」と表示されます。これは「嘘をつく」のではなく、「必要以上の情報を与えない」という設計です。エラーメッセージは親切であるべきですが、攻撃者にも親切である必要はありません。異常の種類と、返すべきエラーレスポンスが分かりました。では、実際にどうやってテストを書けばいいのでしょうか。ここからは、異常系テストの書き方について説明します。テストの書き方期待するエラーの検証異常系テストで最も基本的なのは、「期待するエラーが返ること」の検証です。正常系では「期待する結果が返ること」を確認しますが、異常系では「期待するエラーが返ること」を確認します。# 例: 存在しないリソースへのアクセスで404が返ることを検証def test_get_not_found():    response = client.get("/resources/nonexistent-id")    assert response.status_code == 404テストの独立性各テストは独立して実行できるようにします。テスト間でデータを共有しません。# テストごとに一意のIDを使用TEST_ID="test-$(date +%s)"クリーンアップテスト終了後は作成したリソースを削除します。テストデータが残っていると、次回のテスト実行に影響を与える可能性があります。テストピラミッドにおける異常系テストMike Cohnの伝統的なテストピラミッド（ユニット→インテグレーション→E2E）では「各要件に対し少なくとも2つのテスト、1つは正常系、1つは異常系」が原則です。Kent C. Doddsの「Testing Trophy」モデルでは、インテグレーションテストを重視します。「テストがソフトウェアの使用方法に似ているほど、より多くの信頼を与える」という原則のもと、インテグレーションテストはユニットテストが見逃すエラー（コンポーネント間の相互作用問題）を捕捉します。AIによるテスト生成「テストケースを考えるのが面倒」「どこまでカバーすればいいか分からない」。そんな悩みを抱えたことはないでしょうか。AIによるテスト生成は、この問題に一つの解を与えます。NVIDIAのHEPHフレームワークはLLM（大規模言語モデル）を用いてドキュメントからテストを自動生成します。Diffblue CoverはJavaコードの静的解析からユニットテストを生成します。qodo（旧Codium）はコード動作を分析してエッジケースを含むテストケースを生成します。これらのツールはエラーシナリオ、境界条件、例外処理パスを自動的に導出します。ただし、AIが生成したテストをそのまま使うのは危険です。「何をテストすべきか」の判断は人間がすべきであり、AIはその実装を支援するツールに過ぎません。テストの質を検証する：Mutation Testingテストを書きました。カバレッジも高いです。しかし、そのテストは本当にバグを見つけられるのでしょうか。Mutation testing（変異テスト）は、コードに意図的なバグを埋め込み、テストがそれを検出できるか評価する手法です。たとえばif (x > 0)をif (x >= 0)に変更します。この変更をテストが検出できなければ、そのテストには穴があります。PITest（Java）、Stryker Mutator（JS/TS/C#）、cargo-mutants（Rust）などのツールがCI/CDへの統合を進めています。cargo-mutantsはRustConf 2024で発表され、ソースコード変更なしで任意のRustプロジェクトに適用できます。 speakerdeck.com異常系テストの優先順位すべての異常をテストする時間はありません。リスクベースで優先順位をつけます。Priority 1（毎スプリント）: セキュリティ敏感入力（SQLインジェクション、XSS）、金融・トランザクション操作、認証・認可障害Priority 2（毎リリース）: コアビジネス機能のエラーパス、統合ポイント障害、境界値違反Priority 3（定期テスト）: 複雑なエラーハンドリングフロー、二次機能のエッジケースPriority 4（メジャーリリース前）: 安定したレガシー機能、低トラフィック機能のエラーハンドリングまとめ異常系テストは「何が起きたら困るか」を事前に洗い出し、システムが適切に対処できることを検証する作業です。本記事で紹介した内容を振り返ると、以下の5点が重要になります。すべてをテストする必要はない - リスクの高い箇所に集中します。テストにもROIがあります。チームで「どこまでの異常を許容するか」を言語化しておきましょうAIとツールを活用する - ファジング、Property-based testing、Mutation testingなど、人間の想像力を超える異常を発見する手法があります。AIによるテスト生成も現実的な選択肢になりました環境の異常にはカオスエンジニアリング - 本番環境で必ず起きる障害を、事前に計画して注入します。レジリエンスパターン（サーキットブレーカー、バルクヘッド、指数バックオフ）を実装し、実際にテストしますセキュリティ観点を忘れない - エラーメッセージやエラーコードが情報漏洩につながることがあります。403と404の使い分けはその典型例ですテストを書くことで設計が明確になる - 「空文字を許容するか」「同時更新をどう扱うか」といった曖昧だった仕様が、テストを書く過程で具体化されます異常系テストは面倒に感じることもあります。しかし、プロダクション環境で障害が発生してから対処するコストに比べれば、事前にテストを書くコストは安いです。深夜2時のアラート対応、原因調査、ホットフィックス、ポストモーテム。そのすべてを、1つのテストが防いでくれることがあります。障害が起きたら、その教訓をテストとして残す。それが本当の意味での振り返りです。異常系テストは、将来の自分を助けるための投資です。3ヶ月後の深夜2時、アラートが鳴らなかったとき、過去の自分へ感謝するでしょう。明日からできること大げさに考える必要はありません。次にコードを書くとき、1つだけ試してみてください。「この処理が失敗したら、何が起きるか」を考える。その問いを立てるだけで、異常系テストは始まっています。APIを呼ぶコードを書いたら、「このAPIがタイムアウトしたらどうなるか」と考えます。データベースに保存するコードを書いたら、「保存に失敗したらどうなるか」と考えます。その問いに対する答えをテストとして書く。それだけでいいのです。完璧を目指す必要はありません。昨日より1つだけ、システムを堅牢にする。その積み重ねが、深夜のアラートを1回減らし、ユーザーの信頼を1つ守ります。今日書いた1つのテストが、3ヶ月後の深夜2時を救います。AIがテスト生成を支援してくれる時代だからこそ、この「問いを立てる力」は人間にしかできない価値になります。3ヶ月後の深夜2時。あなたのスマートフォンは静かなままです。アラートは鳴りません。それは偶然ではありません。過去のあなたが書いた1つのテストが、その夜の安眠を守っています。このブログが良ければ読者になったり、nwiizoのXやGithubをフォローしてくれると嬉しいです。参考資料ソフトウェアテスト徹底指南書 〜開発の高品質と高スピードを両立させる実践アプローチ作者:井芹 洋輝技術評論社Amazon単体テストの考え方/使い方作者:Vladimir Khorikovマイナビ出版Amazon【この1冊でよくわかる】ソフトウェアテストの教科書　［増補改訂 第２版］作者:布施 昌弘,江添 智之,永井 努,三堀 雅也SBクリエイティブAmazonソフトウェアテスト技法練習帳 ~知識を経験に変える40問~作者:梅津 正洋,竹内 亜未,伊藤 由貴,浦山 さつき,佐々木 千絵美,高橋 理,武田 春恵,根本 紀之,藤沢 耕助,真鍋 俊之,山岡 悠,吉田 直史技術評論社Amazonテスト駆動開発作者:ＫｅｎｔＢｅｃｋオーム社Amazon知識ゼロから学ぶソフトウェアテスト 第3版 アジャイル・AI時代の必携教科書作者:高橋 寿一翔泳社Amazonフルスタックテスティング【リフロー型】 10のテスト手法で実践する高品質ソフトウェア開発作者:Gayathri Mohan翔泳社Amazonソフトウェア品質保証入門: 高品質を実現する考え方とマネジメントの要点作者:保田 勝通,奈良 隆正日科技連出版社Amazonソフトウェア品質保証の極意 ―経験者が語る、組織を強く進化させる勘所―オーム社Amazon生成AIによるソフトウェア開発 ―設計からテスト,マネジメントまでをすべて変革するLLM活用の実践体系―オーム社Amazon]]></content:encoded>
        </item>
        <item>
            <title><![CDATA[Cloud Spanner の記事を書きました (+ 技術的な蛇足)]]></title>
            <link>https://silasol.la/posts/2025-12-16-01_cloud-spanner/</link>
            <guid isPermaLink="false">https://silasol.la/posts/2025-12-16-01_cloud-spanner/</guid>
            <pubDate>Tue, 16 Dec 2025 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[Cloud Spanner のコアアーキテクチャについて，職場の Tech Blog 補足と技術的な余談 (Paxos, CAP 定理, NewSQL) をまとめました．]]></content:encoded>
        </item>
    </channel>
</rss>